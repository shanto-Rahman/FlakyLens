id,project,test_name,full_code,label,category
3,eclipse_xtext-core,RequestManagerTest.testRunWriteAfterRead,"@Test
public void testRunWriteAfterRead() {
    final Function1<CancelIndicator, Integer> _function = (CancelIndicator it) -> {
        return Integer.valueOf(this.sharedState.incrementAndGet());
    };
    this.requestManager.<Integer>runRead(_function);
    final Function0<Object> _function_1 = () -> {
        return null;
    };
    final Function2<CancelIndicator, Object, Integer> _function_2 = (CancelIndicator $0,Object $1) -> {
        int _xblockexpression = ((int) (0));
        {
            Assert.assertEquals(1, this.sharedState.get());
            _xblockexpression = this.sharedState.incrementAndGet();
        }
        return Integer.valueOf(_xblockexpression);
    };
    this.requestManager.<Object, Integer>runWrite(_function_1, _function_2).join();
    Assert.assertEquals(2, this.sharedState.get());
}",concurrency,1
21,palantir_atlasdb,extraSweepersGiveUpAfterFailingToAcquireEnoughTimes,"@Test
public void extraSweepersGiveUpAfterFailingToAcquireEnoughTimes() throws InterruptedException {
    int shards = 16;
    int sweepers = 4;
    int threads = shards / (sweepers / 2);
    TimelockService stickyLockService = createStickyLockService();
    createAndInitializeSweepersAndWaitForOneBackgroundIteration(sweepers, shards, threads, stickyLockService);
    ArgumentCaptor<LockRequest> captor = ArgumentCaptor.forClass(LockRequest.class);
    verify(stickyLockService, atLeast(shards * (shards / threads + 1) / 2 + shards * (threads * sweepers - shards)));
    verify(stickyLockService, atMost(shards * ((threads + 1) * sweepers - shards) - sweepers * (sweepers - 1) / 2));
    Set<String> requestedLockIds = captor.getAllValues().stream()
    .map(LockRequest::getLockDescriptors)
    .map(Iterables::getOnlyElement)
    .map(LockDescriptor::getLockIdAsString)
    .collect(Collectors.toSet());
    Set<String> expectedLockIds = IntStream.range(0, shards).boxed()
    .map(ShardAndStrategy::conservative)
    .map(ShardAndStrategy::toText)
    .collect(Collectors.toSet());
    assertThat(requestedLockIds).hasSameElementsAs(expectedLockIds);
}",concurrency,1
26,cloudfoundry_uaa,testMatchesSpeedTest,"@Test
public void testMatchesSpeedTest() throws Exception {
    int iterations = 15;
    String password = new RandomValueStringGenerator().generate();
    String encodedBcrypt = cachingPasswordEncoder.encode(password);
    long nanoStart = System.nanoTime();
    for (int i = 0; i < iterations; i++) {
        assertTrue(cachingPasswordEncoder.getPasswordEncoder().matches(password, encodedBcrypt));
        long nanoStop = System.nanoTime();
        long bcryptTime = nanoStop - nanoStart;
        nanoStart = System.nanoTime();
        for (int i = 0; i < iterations; i++) {
            nanoStop = System.nanoTime();
            long cacheTime = nanoStop - nanoStart;
            assertTrue(bcryptTime > (10 * cacheTime));
        }
    }
}",time,2
32,apache_druid,ResponseContextTest.serializeWithTruncateArrayTest,"@Test
public void serializeWithTruncateArrayTest() throws IOException {
    final ResponseContext ctx = ResponseContext.createEmpty();
    ctx.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3), interval(4), interval(5), interval(6)));
    ctx.put(EXTN_STRING_KEY, Strings.repeat(""x"", INTERVAL_LEN * 7));
    final DefaultObjectMapper objectMapper = new DefaultObjectMapper();
    final String fullString = objectMapper.writeValueAsString(ctx.getDelegate());
    final ResponseContext.SerializationResult res1 = ctx.serializeWith(objectMapper, Integer.MAX_VALUE);
    Assert.assertEquals(fullString, res1.getResult());
    final int maxLen = ((((INTERVAL_LEN * 4) + UNCOVERED_INTERVALS.getName().length()) + 4) + TRUNCATED.getName().length()) + 6;
    final ResponseContext.SerializationResult res2 = ctx.serializeWith(objectMapper, maxLen);
    final ResponseContext ctxCopy = ResponseContext.createEmpty();
    ctxCopy.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3)));
    ctxCopy.put(TRUNCATED, true);
    Assert.assertEquals(ctxCopy.getDelegate(), deserializeContext(res2.getResult(), objectMapper));
}",unordered collections,3
33,apache_kafka,shouldTogglePrepareForBulkLoadDuringRestoreCalls,"@Test
public void shouldTogglePrepareForBulkLoadDuringRestoreCalls() throws Exception {
    final List<KeyValue<byte[], byte[]>> entries = new ArrayList<>();
    entries.add(new KeyValue<>(""1"".getBytes(""UTF-8""), ""a"".getBytes(""UTF-8"")));
    entries.add(new KeyValue<>(""2"".getBytes(""UTF-8""), ""b"".getBytes(""UTF-8"")));
    entries.add(new KeyValue<>(""3"".getBytes(""UTF-8""), ""c"".getBytes(""UTF-8"")));
    final AtomicReference<Exception> conditionNotMet = new AtomicReference<>();
    final AtomicInteger conditionCheckCount = new AtomicInteger();
    Thread conditionCheckThread = new Thread(new Runnable() {
        @Override
        public void run() {
            assertRocksDBTurnsOnBulkLoading(conditionCheckCount, conditionNotMet);
            assertRockDBTurnsOffBulkLoad(conditionCheckCount, conditionNotMet);
        }
    });
    subject.init(context, subject);
    conditionCheckThread.start();
    context.restore(subject.name(), entries);
    conditionCheckThread.join(2000);
    assertTrue(conditionNotMet.get() == null);
    assertTrue(conditionCheckCount.get() == 2);
}",concurrency,1
45,Tencent_Firestorm,HealthCheckCoordinatorGrpcTest.healthCheckTest,"@Test
public void healthCheckTest() throws Exception {
    RssGetShuffleAssignmentsRequest request = new RssGetShuffleAssignmentsRequest(""1"", 1, 1, 1, 1, Sets.newHashSet(SHUFFLE_SERVER_VERSION));
    Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS);
    assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount());
    List<ServerNode> nodes = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION));
    assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount());
    assertEquals(2, nodes.size());
    RssGetShuffleAssignmentsResponse response = coordinatorClient.getShuffleAssignments(request);
    assertFalse(response.getPartitionToServers().isEmpty());
    for (ServerNode node : nodes) {
        assertTrue(node.isHealthy());
    }
    byte[] bytes = new byte[writeDataSize];
    new Random().nextBytes(bytes);
    try (final FileOutputStream out = new FileOutputStream(tempDataFile)) {
        out.write(bytes);
    }
    Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS);
    CoordinatorTestUtils.waitForRegister(coordinatorClient, 2);
    nodes = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION));
    for (ServerNode node : nodes) {
        assertFalse(node.isHealthy());
    }
    assertEquals(0, nodes.size());
    response = coordinatorClient.getShuffleAssignments(request);
    assertEquals(INTERNAL_ERROR, response.getStatusCode());
    tempDataFile.delete();
    int i = 0;
    do {
        Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS);
        nodes = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION));
        i++;
        if (i == 10) {
            fail();
        }
    } while (nodes.size() != 2 );
    for (ServerNode node : nodes) {
        assertTrue(node.isHealthy());
    }
    assertEquals(2, nodes.size());
    response = coordinatorClient.getShuffleAssignments(request);
    assertFalse(response.getPartitionToServers().isEmpty());
}",async wait,0
52,dropwizard_dropwizard,07dfaed697427e208d65049f80a5d1949833b7cd.testLogbackStatusPrinterPrintStreamIsRestoredToSystemOut,"@Test
public void testLogbackStatusPrinterPrintStreamIsRestoredToSystemOut() throws Exception {
    Field field = StatusPrinter.class.getDeclaredField(""ps"");
    field.setAccessible(true);
    PrintStream out = (PrintStream) field.get(null);
    assertThat(out).isSameAs(System.out);
}",test order dependency,4
60,apache_zookeeper,BookieClientTest.testWriteGaps,"@Test
public void testWriteGaps() throws Exception {
    final Object notifyObject = new Object();
    byte[] passwd = new byte[20];
    Arrays.fill(passwd, ((byte) ('a')));
    InetSocketAddress addr = new InetSocketAddress(""127.0.0.1"", port);
    ResultStruct arc = new ResultStruct();
    BookieClient bc = new BookieClient(new ClientConfiguration(), channelFactory, executor);
    ChannelBuffer bb;
    bb = createByteBuffer(1, 1, 1);
    bc.addEntry(addr, 1, passwd, 1, bb, wrcb, null, FLAG_NONE);
    synchronized(arc) {
        bc.readEntry(addr, 1, 1, recb, arc, FLAG_NONE);
        arc.wait(1000);
        assertEquals(0, arc.rc);
        assertEquals(1, arc.entry.getInt());
    }
    bb = createByteBuffer(2, 1, 2);
    bc.addEntry(addr, 1, passwd, 2, bb, wrcb, null, FLAG_NONE);
    bb = createByteBuffer(3, 1, 3);
    bc.addEntry(addr, 1, passwd, 3, bb, wrcb, null, FLAG_NONE);
    bb = createByteBuffer(5, 1, 5);
    bc.addEntry(addr, 1, passwd, 5, bb, wrcb, null, FLAG_NONE);
    bb = createByteBuffer(7, 1, 7);
    bc.addEntry(addr, 1, passwd, 7, bb, wrcb, null, FLAG_NONE);
    synchronized(notifyObject) {
        bb = createByteBuffer(11, 1, 11);
        bc.addEntry(addr, 1, passwd, 11, bb, wrcb, notifyObject, FLAG_NONE);
        notifyObject.wait();
    }
    synchronized(arc) {
        bc.readEntry(addr, 1, 6, recb, arc, FLAG_NONE);
        arc.wait(1000);
        assertEquals(NoSuchEntryException, arc.rc);
    }
    synchronized(arc) {
        bc.readEntry(addr, 1, 7, recb, arc, FLAG_NONE);
        arc.wait(1000);
        assertEquals(0, arc.rc);
        assertEquals(7, arc.entry.getInt());
    }
    synchronized(arc) {
        bc.readEntry(addr, 1, 1, recb, arc, FLAG_NONE);
        arc.wait(1000);
        assertEquals(0, arc.rc);
        assertEquals(1, arc.entry.getInt());
    }
    synchronized(arc) {
        bc.readEntry(addr, 1, 2, recb, arc, FLAG_NONE);
        arc.wait(1000);
        assertEquals(0, arc.rc);
        assertEquals(2, arc.entry.getInt());
    }
    synchronized(arc) {
        bc.readEntry(addr, 1, 3, recb, arc, FLAG_NONE);
        arc.wait(1000);
        assertEquals(0, arc.rc);
        assertEquals(3, arc.entry.getInt());
    }
    synchronized(arc) {
        bc.readEntry(addr, 1, 4, recb, arc, FLAG_NONE);
        arc.wait(1000);
        assertEquals(NoSuchEntryException, arc.rc);
    }
    synchronized(arc) {
        bc.readEntry(addr, 1, 11, recb, arc, FLAG_NONE);
        arc.wait(1000);
        assertEquals(0, arc.rc);
        assertEquals(11, arc.entry.getInt());
    }
    synchronized(arc) {
        bc.readEntry(addr, 1, 5, recb, arc, FLAG_NONE);
        arc.wait(1000);
        assertEquals(0, arc.rc);
        assertEquals(5, arc.entry.getInt());
    }
    synchronized(arc) {
        bc.readEntry(addr, 1, 10, recb, arc, FLAG_NONE);
        arc.wait(1000);
        assertEquals(NoSuchEntryException, arc.rc);
    }
    synchronized(arc) {
        bc.readEntry(addr, 1, 12, recb, arc, FLAG_NONE);
        arc.wait(1000);
        assertEquals(NoSuchEntryException, arc.rc);
    }
    synchronized(arc) {
        bc.readEntry(addr, 1, 13, recb, arc, FLAG_NONE);
        arc.wait(1000);
        assertEquals(NoSuchEntryException, arc.rc);
    }
}",async wait,0
61,graylog2_graylog2-server,indexCreationDateReturnsIndexCreationDateOfExistingIndexAsDateTime,"@Test
public void indexCreationDateReturnsIndexCreationDateOfExistingIndexAsDateTime() {
    final DateTime now = DateTime.now(DateTimeZone.UTC);
    final String indexName = client().createRandomIndex(""indices_it_"");
    final Optional<DateTime> indexCreationDate = indices.indexCreationDate(indexName);
    assertThat(indexCreationDate).isNotEmpty()
    .hasValueSatisfying(date -> Assertions.assertThat(date).isEqualToIgnoringMillis(now));
}",time,2
66,palantir_atlasdb,incrementUpperLimitIfOneMinuteElapsedSinceLastUpdate,"@Test
public void incrementUpperLimitIfOneMinuteElapsedSinceLastUpdate() throws InterruptedException {
    Clock clock = mock(Clock.class);
    when(clock.getTimeMillis()).thenReturn(0L, TWO_MINUTES_IN_MILLIS, 2 * TWO_MINUTES_IN_MILLIS, 3 * TWO_MINUTES_IN_MILLIS);
    TimestampBoundStore timestampBoundStore = initialTimestampBoundStore();
    PersistentTimestampService persistentTimestampService = PersistentTimestampService.create(timestampBoundStore, clock);
    persistentTimestampService.getFreshTimestamp();
    Thread.sleep(10);
    persistentTimestampService.getFreshTimestamp();
    Thread.sleep(10);
    verify(timestampBoundStore, atLeast(2)).storeUpperLimit(anyLong());
}",async wait,0
70,OpenLCB_OpenLCB_Java,MemoryConfigurationServiceInterfaceTest.testReadWithTimeoutInterleaved,"@Test
public void testReadWithTimeoutInterleaved() {
    int space = 0xfd;
    long address = 0x12345678;
    int length = 4;
    MemoryConfigurationService.McsReadHandler hnd = mock(McsReadHandler.class);
    MemoryConfigurationService.McsReadHandler hnd2 = mock(McsReadHandler.class);
    iface.getDatagramMeteringBuffer().setTimeout(30);
    iface.getMemoryConfigurationService().setTimeoutMillis(30);
    {
        iface.getMemoryConfigurationService().requestRead(farID, space, address, length, hnd);
        expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x78, 4 }));
        System.err.println(""Expect 'Never received reply' here -->"");
        delay(50);
        System.err.println(""<--"");
        verify(hnd).handleFailure(0x100);
        verifyNoMoreInteractions(hnd);
        iface.getMemoryConfigurationService().requestRead(farID, space, address + 1, length, hnd2);
        expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 }));
        sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80));
        consumeMessages();
        sendMessage(new DatagramRejectedMessage(farID, hereID, 0x2020));
        consumeMessages();
        System.err.println(""Expect 'unexpected response datagram' here -->"");
        sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x78, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID));
        System.err.println(""<--"");
        expectNoMessages();
        delay(50);
        expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 }));
        sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80));
        consumeMessages();
        sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80));
        consumeMessages();
        sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x79, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID));
        verify(hnd2).handleReadData(farID, space, address + 1, new byte[]{ ((byte) (0xaa)) });
        verifyNoMoreInteractions(hnd2);
    }
    System.err.println(""Sending another request..."");
    sendAnother(space, address + 5);
}",async wait,0
88,togglz_togglz,ZookeeperStateRepositoryTest.testZkNodeChangesUpdateFeatureState,"@Test
public void testZkNodeChangesUpdateFeatureState() throws Exception {
    setupTestWithEmptyDatastore();
    FeatureState savedFeatureState = new FeatureState(TestFeature.FEATURE);
    savedFeatureState.setStrategyId(ID);
    savedFeatureState.setParameter(PARAM_USERS, ""user1, user2, user3"");
    stateRepository.setFeatureState(savedFeatureState);
    FeatureState loadedFeatureState = stateRepository.getFeatureState(TestFeature.FEATURE);
    assertThat(reflectionEquals(savedFeatureState, loadedFeatureState), is(true));
    FeatureStateStorageWrapper externallySetStateWrapper = new FeatureStateStorageWrapper();
    FeatureState externallySetState = new FeatureState(TestFeature.FEATURE);
    ObjectMapper objectMapper = new ObjectMapper();
    final String json = objectMapper.writeValueAsString(externallySetStateWrapper);
    final CountDownLatch latch = new CountDownLatch(1);
    new Thread(new Runnable() {
        @Override
        public void run() {
            try {
                serverClientPair.client.setData().forPath(TEST_ZNODE + ""/FEATURE"", json.getBytes(""UTF-8""));
                latch.countDown();
            } catch (Exception e) {
                e.printStackTrace();
            }
        }
    }).start();
    latch.await(2, TimeUnit.SECONDS);
    Thread.sleep(25);
    loadedFeatureState = stateRepository.getFeatureState(TestFeature.FEATURE);
    assertThat(reflectionEquals(externallySetState, loadedFeatureState), is(true));
}",async wait,0
119,vert-x3_vertx-mongo-client,MongoClientTest.testWatch,"@Test
public void testWatch() throws Exception {
    final JsonArray operationTypes = new JsonArray(Arrays.asList(""insert"", ""update"", ""replace"", ""delete""));
    final JsonObject match = new JsonObject().put(""operationType"", new JsonObject().put(""$in"", operationTypes));
    final JsonArray pipeline = new JsonArray().add(new JsonObject().put(""$match"", match));
    final JsonObject fields = new JsonObject().put(""operationType"", true).put(""namespaceDocument"", true).put(""destinationNamespaceDocument"", true).put(""documentKey"", true).put(""updateDescription"", true).put(""fullDocument"", true);
    pipeline.add(new JsonObject().put(""$project"", fields));
    final String collection = randomCollection();
    final JsonObject doc = createDoc();
    final CountDownLatch latch = new CountDownLatch(4);
    final AtomicReference<ReadStream<ChangeStreamDocument<JsonObject>>> streamReference = new AtomicReference<>();
    mongoClient.createCollection(collection, onSuccess(( res) -> {
        ReadStream<ChangeStreamDocument<JsonObject>> stream = mongoClient.watch(collection, pipeline, true, 1).handler(( changeStreamDocument) -> {
            OperationType operationType = changeStreamDocument.getOperationType();
            assertNotNull(operationType);
            JsonObject fullDocument = changeStreamDocument.getFullDocument();
            switch (operationType.getValue()) {
                case ""insert"" :
                assertNotNull(fullDocument);
                assertNotNull(fullDocument.getString(MongoClientUpdateResult.ID_FIELD));
                assertEquals(""bar"", fullDocument.getString(""foo""));
                break;
                case ""update"" :
                assertNotNull(fullDocument);
                assertEquals(""updatedValue"", fullDocument.getString(""fieldToUpdate""));
                break;
                case ""replace"" :
                assertNotNull(fullDocument);
                assertEquals(""replacedValue"", fullDocument.getString(""fieldToReplace""));
                break;
                case ""delete"" :
                assertNull(fullDocument);
                break;
                default :
            }
            latch.countDown();
            if (latch.getCount() == 1) {
                mongoClient.removeDocuments(collection, new JsonObject());
            }
        }).endHandler(( v) -> assertEquals(0, latch.getCount())).exceptionHandler(this::fail).fetch(1);
        streamReference.set(stream);
        vertx.setTimer(50, ( v) -> {
            mongoClient.insert(collection, doc).compose(( idString) -> {
                doc.put(MongoClientUpdateResult.ID_FIELD, idString);
                doc.put(""fieldToUpdate"", ""updatedValue"");
                final JsonObject query = new JsonObject().put(MongoClientUpdateResult.ID_FIELD, idString);
                final JsonObject updateField = new JsonObject().put(""fieldToUpdate"", ""updatedValue"");
                return CompositeFuture.all(mongoClient.updateCollection(collection, query, new JsonObject().put(""$set"", updateField)), mongoClient.save(collection, doc.put(""fieldToReplace"", ""replacedValue"")));
            });
        });
    }));
    awaitLatch(latch);
    streamReference.get().handler(null);
}",time,2
124,spotify_docker-client,DefaultDockerClientTest.testListTaskWithCriteria,"@Test
public void testListTaskWithCriteria() throws Exception {
    requireDockerApiVersionAtLeast(""1.24"", ""swarm support"");
    final ServiceSpec spec = createServiceSpec(randomName());
    assertThat(sut.listTasks().size(), is(0));
    sut.createService(spec);
    await().until(numberOfTasks(sut), is(greaterThan(0)));
    final Task task = sut.listTasks().get(1);
    final List<Task> tasksWithId = sut.listTasks(Task.find().taskId(task.id()).build());
    assertThat(tasksWithId.size(), is(1));
    assertThat(tasksWithId.get(0), equalTo(task));
    final List<Task> tasksWithServiceName = sut.listTasks(Task.find().serviceName(spec.name()).build());
    assertThat(tasksWithServiceName.size(), is(greaterThanOrEqualTo(1)));
    final Set<String> taskIds = Sets.newHashSet(Lists.transform(tasksWithServiceName, new Function<Task, String>()));
    assertThat(task.id(), isIn(taskIds));
}",async wait,0
136,graylog2_graylog2-server,KafkaJournalTest.serverStatusUnthrottledIfJournalUtilizationIsLowerThanThreshold,"@Test
public void serverStatusUnthrottledIfJournalUtilizationIsLowerThanThreshold() throws Exception {
    serverStatus.throttle();
    final Size segmentSize = Size.kilobytes(1L);
    final KafkaJournal journal = new KafkaJournal(journalDirectory, scheduler, segmentSize, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus);
    journal.flushDirtyLogs();
    journal.cleanupLogs();
    assertThat(serverStatus.getLifecycle()).isEqualTo(RUNNING);
}",concurrency,1
143,apache_cassandra,ColumnFamilyStoreTest.testRemoveSuperColumn,"@Test
public void testRemoveSuperColumn() throws IOException, ExecutionException, InterruptedException {
    Table table = Table.open(""Table1"");
    ColumnFamilyStore store = table.getColumnFamilyStore(""Super1"");
    RowMutation rm;
    rm = new RowMutation(""Table1"", ""key1"");
    rm.add(""Super1:SC1:Column1"", ""asdf"".getBytes(), 0);
    rm.apply();
    store.forceBlockingFlush();
    rm = new RowMutation(""Table1"", ""key1"");
    rm.delete(""Super1:SC1"", 1);
    rm.apply();
    List<ColumnFamily> families = store.getColumnFamilies(""key1"", ""Super1"", new IdentityFilter());
    assert families.get(0).getAllColumns().first().getMarkedForDeleteAt() == 1;
    assert !families.get(1).getAllColumns().first().isMarkedForDelete();
    ColumnFamily resolved = ColumnFamily.resolve(families);
    assert resolved.getAllColumns().first().getMarkedForDeleteAt() == 1;
    Collection<IColumn> subColumns = resolved.getAllColumns().first().getSubColumns();
    assert subColumns.size() == 1;
    assert subColumns.iterator().next().timestamp() == 0;
    assertNull(ColumnFamilyStore.removeDeleted(resolved, Integer.MAX_VALUE));
}",async wait,0
156,opensource4you_astraea,MetricsTest.testBytes,"@Test
void testBytes() throws InterruptedException {
    final CountDownLatch countDownLatch = new CountDownLatch(1);
    final Metrics metrics = new Metrics();
    final LongAdder longAdder = new LongAdder();
    final long input = 100;
    final int loopCount = 10000;
    Thread adder = new Thread(() -> {
        try {
            countDownLatch.await();
        } catch (InterruptedException ignore) {
        }
        for (int i = 0; i < loopCount; ++i) {
            metrics.addBytes(input);
        }
    });
    Thread getter = new Thread(() -> {
        try {
            countDownLatch.await();
        } catch (InterruptedException ignore) {
        }
        for (int i = 0; i < loopCount; ++i) {
            longAdder.add(metrics.bytesThenReset());
        }
    });
    adder.start();
    getter.start();
    countDownLatch.countDown();
    adder.join();
    longAdder.add(metrics.bytesThenReset());
    Assertions.assertEquals(loopCount * input, longAdder.sum());
}",concurrency,1
171,tbsalling_aismessages,7b0c4c708b6bb9a6da3d5737bcad1857ade8a931.canHandleFragmentedMessageReceived,"@Test
public void canHandleFragmentedMessageReceived() {
    NMEAMessage fragmentedNMEAMessage1 = NMEAMessage.fromString(""!AIVDM,2,1,3,B,55DA><02=6wpPuID000qTf059@DlU<00000000171lMDD4q20LmDp3hB,0*27"");
    NMEAMessage fragmentedNMEAMessage2 = NMEAMessage.fromString(""!AIVDM,2,2,3,B,p=Mh00000000000,2*4C"");
    final ArgumentCaptor<AISMessage> aisMessage = new ArgumentCaptor<>();
    context.checking(new Expectations() {{
        oneOf(aisMessageHandler).accept(with(aisMessage.getMatcher()));
    }});
    aisMessageReceiver.accept(fragmentedNMEAMessage1);
    aisMessageReceiver.accept(fragmentedNMEAMessage2);
    assertEquals(AISMessageType.ShipAndVoyageRelatedData, aisMessage.getCapturedObject().getMessageType());
}",test order dependency,4
174,hwang-pku_ormlite-core,DatabaseFieldConfigTest.testFromDbField,"@Test
public void testFromDbField() throws Exception {
    Field[] fields = Foo.class.getDeclaredFields();
    assertTrue(fields.length >= 1);
    DatabaseFieldConfig config = DatabaseFieldConfig.fromField(databaseType, ""foo"", fields[0]);
    assertNotNull(config);
    assertTrue(config.isCanBeNull());
    assertEquals(fields[0].getName(), config.getFieldName());
}",unordered collections,3
180,finos_symphony-wdk,SendMessageIntegrationTest.sendMessageOnMessage,"@Test
void sendMessageOnMessage() throws Exception {
    final Workflow workflow = SwadlParser.fromYaml(getClass().getResourceAsStream(""/message/send-message-on-message.swadl.yaml""));
    final V4Message message = message(""Hello!"");
    engine.deploy(workflow);
    engine.onEvent(messageReceived(""/message""));
    when(messageService.send(anyString(), any(Message.class))).thenReturn(message);
    verify(messageService, timeout(5000)).send(anyString(), any(Message.class));
    assertThat(workflow).isExecuted().hasOutput(String.format(OUTPUTS_MSG_KEY, ""sendMessage1""), message).hasOutput(String.format(OUTPUTS_MSG_ID_KEY, ""sendMessage1""), message.getMessageId());
}",async wait,0
185,apache_struts,13d9053050c9e4fb2ef049db6a37d3f6eebf48fa.testProcessAction_ok.2,"@Test
public void testProcessAction_ok() {
    final Mock mockResponse = mock(ActionResponse.class);
    PortletMode mode = PortletMode.VIEW;
    Map<String, String> initParams = new HashMap<String, String>();
    initParams.put(""viewNamespace"", ""/view"");
    Map<String, String[]> requestParams = new HashMap<String, String[]>();
    requestParams.put(ACTION_PARAM, new String[] { ""/view/testAction"" });
    requestParams.put(MODE_PARAM, new String[] { mode.toString() });
    initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE,
    ""true"");
    initPortletConfig(initParams, new HashMap<String, Object>());
    initRequest(requestParams, new HashMap<String, Object>(),
    new HashMap<String, Object>(), PortletMode.VIEW,
    WindowState.NORMAL, true, null);
    setupActionFactory(""/view"", ""testAction"", ""success"",
    EasyMock.createNiceMock(ValueStack.class));
    try {
        dispatcher
        .setActionProxyFactory((ActionProxyFactory) mockActionFactory
        .proxy());
        dispatcher.init((PortletConfig) mockConfig.proxy());
        dispatcher.processAction((ActionRequest) mockRequest.proxy(),
        (ActionResponse) mockResponse.proxy());
    } catch (Exception e) {
        e.printStackTrace();
        fail(""Error occured"");
    }
}",test order dependency,4
186,apache_struts,13d9053050c9e4fb2ef049db6a37d3f6eebf48fa.testRender_ok,"@Test
public void testRender_ok() {
    final Mock mockResponse = mock(RenderResponse.class);
    mockResponse.stubs().method(ANYTHING);
    PortletMode mode = PortletMode.VIEW;
    Map<String, String[]> requestParams = new HashMap<String, String[]>();
    requestParams.put(ACTION_PARAM, new String[]{""/view/testAction""});
    requestParams.put(EVENT_ACTION, new String[]{""true""});
    requestParams.put(MODE_PARAM, new String[]{mode.toString()});
    Map<String, Object> sessionMap = new HashMap<String, Object>();
    Map<String, String> initParams = new HashMap<String, String>();
    initParams.put(""viewNamespace"", ""/view"");
    initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true"");
    initPortletConfig(initParams, new HashMap<String, Object>());
    initRequest(requestParams, new HashMap<String, Object>(), sessionMap, PortletMode.VIEW, WindowState.NORMAL, false, null);
    setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class));
    mockInvocation.expects(once()).method(""getStack"").will(
    returnValue(null));
    try {
        dispatcher
        .setActionProxyFactory((ActionProxyFactory) mockActionFactory
        .proxy());
        dispatcher.init((PortletConfig) mockConfig.proxy());
        dispatcher.render((RenderRequest) mockRequest.proxy(),
        (RenderResponse) mockResponse.proxy());
    } catch (Exception e) {
        e.printStackTrace();
        fail(""Error occured"");
    }
}",test order dependency,4
203,apache_cassandra,testTimeWindows,"@Test
public void testTimeWindows()
{
    Long tstamp1 = 1451001601000L;
    Long tstamp2 = 1451088001000L;
    Long lowHour = 1451001600000L;
    assertTrue(getWindowBoundsInMillis(TimeUnit.HOURS, 1, tstamp1).left.compareTo(lowHour) == 0);
    assertTrue(getWindowBoundsInMillis(TimeUnit.MINUTES, 1, tstamp1).left.compareTo(lowHour) == 0);
    assertTrue(getWindowBoundsInMillis(TimeUnit.DAYS, 1, tstamp1).left.compareTo(lowHour) == 0 );
    assertTrue(getWindowBoundsInMillis(TimeUnit.DAYS, 2, tstamp2).left.compareTo(lowHour) == 0);
    return;
}",time,2
206,apache_kafka,testGracefulClose,"@Test
public void testGracefulClose() throws Exception {
    int maxReceiveCountAfterClose = 0;
    for (int i = 6; i <= 100 && maxReceiveCountAfterClose < 5; i++) {
        int receiveCount = 0;
        KafkaChannel channel = createConnectionWithPendingReceives(i);
        selector.poll(1000);
        assertEquals(1, selector.completedReceives().size());
        server.closeConnections();
        while (selector.disconnected().isEmpty()) {
            selector.poll(1);
            receiveCount += selector.completedReceives().size();
            assertTrue(""Too many completed receives in one poll"", selector.completedReceives().size() <= 1);
        }
        assertEquals(channel.id(), selector.disconnected().keySet().iterator().next());
        maxReceiveCountAfterClose = Math.max(maxReceiveCountAfterClose, receiveCount);
    }
    assertTrue(""Too few receives after close: "" + maxReceiveCountAfterClose, maxReceiveCountAfterClose >= 5);
}",async wait,0
219,graylog2_graylog2-server,KafkaJournalTest.serverStatusThrottledIfJournalUtilizationIsHigherThanThreshold,"@Test
public void serverStatusThrottledIfJournalUtilizationIsHigherThanThreshold() throws Exception {
    serverStatus.running();
    final Size segmentSize = Size.kilobytes(1L);
    final KafkaJournal journal = new KafkaJournal(journalDirectory, scheduler, segmentSize, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus);
    createBulkChunks(journal, segmentSize, 4);
    journal.flushDirtyLogs();
    journal.cleanupLogs();
    assertThat(serverStatus.getLifecycle()).isEqualTo(THROTTLED);
}",concurrency,1
222,apache_struts,13d9053050c9e4fb2ef049db6a37d3f6eebf48fa.testProcessAction_ok,"@Test
public void testProcessAction_ok() {
    final Mock mockResponse = mock(ActionResponse.class);
    PortletMode mode = PortletMode.VIEW;
    Map<String, String> initParams = new HashMap<String, String>();
    initParams.put(""viewNamespace"", ""/view"");
    Map<String, String[]> requestParams = new HashMap<String, String[]>();
    requestParams.put(ACTION_PARAM, new String[]{""/view/testAction""});
    requestParams.put(MODE_PARAM, new String[]{mode.toString()});
    initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true"");
    initPortletConfig(initParams, new HashMap<String, Object>());
    initRequest(requestParams, new HashMap<String, Object>(), new HashMap<String, Object>(), PortletMode.VIEW, WindowState.NORMAL, true, null);
    setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class));
    try {
        dispatcher
        .setActionProxyFactory((ActionProxyFactory) mockActionFactory
        .proxy());
        dispatcher.init((PortletConfig) mockConfig.proxy());
        dispatcher.processAction((ActionRequest) mockRequest.proxy(),
        (ActionResponse) mockResponse.proxy());
    } catch (Exception e) {
        e.printStackTrace();
        fail(""Error occured"");
    }
}",test order dependency,4
235,CorfuDB_CorfuDB,StreamingIT.testStreamingPrevValue,"@Test
public void testStreamingPrevValue() throws Exception {
    Process corfuServer = runSinglePersistentServer(corfuSingleNodeHost, corfuStringNodePort);
    runtime = createRuntime(singleNodeEndpoint);
    CorfuStore store = new CorfuStore(runtime);
    String ns = ""test_namespace"";
    String tn = ""tableA"";
    Table<Uuid, SampleTableAMsg, Uuid> table = store.openTable(ns, tn, Uuid.class, SampleTableAMsg.class, Uuid.class, TableOptions.builder().build());
    PrevValueStreamer listenerCommon = new PrevValueStreamer<Uuid, SampleTableAMsg, Uuid>(store, ns, tn);
    store.subscribeListener(listenerCommon, ns, ""sample_streamer_1"", Collections.singletonList(tn));
    final int numRecords = PARAMETERS.NUM_ITERATIONS_LOW;
    for (int i = 0; i < numRecords; i++) {
        try (final TxnContext tx = store.txn(namespace)) {
            Uuid key = Uuid.newBuilder().setLsb(0).setMsb(0).build();
            SampleTableAMsg val = SampleTableAMsg.newBuilder().setPayload(""val"" + i).build();
            tx.putRecord(table, key, val, key);
            tx.commit();
        }
    }
    TimeUnit.MILLISECONDS.sleep(sleepTime);
    assertThat(listenerCommon.getRecordCount()).isEqualTo(numRecords);
    assertThat(shutdownCorfuServer(corfuServer)).isTrue();
}",async wait,0
274,jReddit_jReddit,KeyValueFormatterTest.testFormatMultipleUTF8,"@Test
public void testFormatMultipleUTF8() {
    HashMap<String, String> params = new HashMap<String, String>();
    params.put(""a "", ""b, "");
    params.put(""c"", ""32626&"");
    Assert.assertTrue(""a =b%2C+&c=32626%26"".equals(KeyValueFormatter.format(params, true)) || ""c=32626%26&a =b%2C+"".equals(KeyValueFormatter.format(params, true)));
}",unordered collections,3
276,tbsalling_aismessages,7b0c4c708b6bb9a6da3d5737bcad1857ade8a931.canHandleUnfragmentedMessageReceived,"@Test
public void canHandleUnfragmentedMessageReceived() {
    NMEAMessage unfragmentedNMEAMessage = NMEAMessage.fromString(""!AIVDM,1,1,,B,15MqdBP000G@qoLEi69PVGaN0D0=,0*3A"");
    final ArgumentCaptor<AISMessage> aisMessage = new ArgumentCaptor<>();
    context.checking(new Expectations() {{
        oneOf(aisMessageHandler).accept(with(aisMessage.getMatcher()));
    }});
    aisMessageReceiver.accept(unfragmentedNMEAMessage);
    assertEquals(AISMessageType.PositionReportClassAScheduled, aisMessage.getCapturedObject().getMessageType());
}",test order dependency,4
284,apache_cassandra,testWithMismatchingPending,"@Test
public void testWithMismatchingPending() throws Throwable
{
    try(Cluster cluster = init(Cluster.build(2).withConfig(config -> config.with(GOSSIP).with(NETWORK)).start()))
    {
        cluster.schemaChange(""create table "" + KEYSPACE + "".tbl (id int primary key, t int)"");
        insert(cluster.coordinator(1), 0, 100);
        cluster.forEach((node) -> node.flush(KEYSPACE));
        cluster.get(1).callOnInstance(repair(options(false)));
        insert(cluster.coordinator(1), 100, 100);
        cluster.forEach((node) -> node.flush(KEYSPACE));
        cluster.forEach((node) -> node.runOnInstance(() -> {
            ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl"");
            FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(cfs));
            cfs.disableAutoCompaction();
        }));
        cluster.get(1).callOnInstance(repair(options(false)));
        cluster.get(1).runOnInstance(() -> {
            ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl"");
            cfs.enableAutoCompaction();
            FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(cfs));
        });
        RepairResult rs = cluster.get(1).callOnInstance(repair(options(true)));
        assertTrue(rs.success);
        assertFalse(rs.wasInconsistent);
    }
}",concurrency,1
303,graylog2_graylog2-server,ContentPackTest.shouldDeserializeSerializedContentPack,"@Test
public void shouldDeserializeSerializedContentPack() throws Exception {
    final ContentPack contentPack = createTestContentPack();
    final URL contentPackURL = ContentPackTest.class.getResource(""expected_content_pack.json"");
    Path path = Paths.get(contentPackURL.toURI());
    String expectedJSON = String.join("""", Files.readAllLines(path)).replace(""\n"", """").replace(""\r"", """");
    final String jsonTxt = objectMapper.writeValueAsString(contentPack);
    assertThat(jsonTxt).isEqualTo(expectedJSON);
    final ContentPack readContentPack = objectMapper.readValue(jsonTxt, ContentPack.class);
    assertThat(readContentPack.id()).isEqualTo(contentPack.id());
    assertThat(readContentPack.version()).isEqualTo(contentPack.version());
    assertThat(readContentPack.revision()).isEqualTo(contentPack.revision());
}",unordered collections,3
309,apache_kafka,testForceMetadataRefreshForPatternSubscriptionDuringRebalance,"@Test
public void testForceMetadataRefreshForPatternSubscriptionDuringRebalance() {
    final String consumerId = ""consumer"";
    subscriptions.subscribe(Pattern.compile("".*""), rebalanceListener);
    client.updateMetadata(TestUtils.metadataUpdateWith(1, singletonMap(topic1, 1)));
    assertEquals(singleton(topic1), subscriptions.subscription());
    client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));
    coordinator.ensureCoordinatorReady(time.timer(Long.MAX_VALUE));
    client.prepareMetadataUpdate(metadataResponse);
    client.prepareResponse(joinGroupFollowerResponse(1, consumerId, ""leader"", Errors.NONE));
    client.prepareResponse(new MockClient.RequestMatcher() {
        @Override
        public boolean matches(AbstractRequest body) {
            SyncGroupRequest sync = (SyncGroupRequest) body;
            return sync.memberId().equals(consumerId) &&
            sync.generationId() == 1 &&
            sync.groupAssignment().isEmpty();
        }
    }, syncGroupResponse(singletonList(t1p), Errors.NONE));
    partitionAssignor.prepare(singletonMap(consumerId, singletonList(t1p)));
    coordinator.poll(time.timer(Long.MAX_VALUE));
    final Set<String> updatedSubscriptionSet = new HashSet<>(Arrays.asList(topic1, topic2));
    assertEquals(updatedSubscriptionSet, subscriptions.subscription());
    metadata.requestUpdate();
    client.poll(Long.MAX_VALUE, time.milliseconds());
    assertFalse(coordinator.rejoinNeededOrPending());
}",concurrency,1
310,apache_cassandra,testTrackMetadata_rowMarkerDelete,"@Test
public void testTrackMetadata_rowMarkerDelete() throws Throwable
{
    createTable(""CREATE TABLE %s (a int, PRIMARY KEY (a))"");
    ColumnFamilyStore cfs = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable());
    execute(""DELETE FROM %s USING TIMESTAMP 9999 WHERE a=1"");
    cfs.forceBlockingFlush();
    assertEquals(1, cfs.getLiveSSTables().size());
    StatsMetadata metadata = cfs.getLiveSSTables().iterator().next().getSSTableMetadata();
    assertEquals(9999, metadata.minTimestamp);
    assertEquals(9999, metadata.maxTimestamp);
    assertEquals(System.currentTimeMillis()/1000, metadata.maxLocalDeletionTime, 5);
    cfs.forceMajorCompaction();
    StatsMetadata metadata2 = cfs.getLiveSSTables().iterator().next().getSSTableMetadata();
    assertEquals(metadata.maxLocalDeletionTime, metadata2.maxLocalDeletionTime);
    assertEquals(metadata.minTimestamp, metadata2.minTimestamp);
    assertEquals(metadata.maxTimestamp, metadata2.maxTimestamp);
}",time,2
311,apache_cassandra,testTrackMetadata_rowTombstone,"@Test
public void testTrackMetadata_rowTombstone() throws Throwable
{
    createTable(""CREATE TABLE %s (a int, b int, c text, PRIMARY KEY (a, b))"");
    ColumnFamilyStore cfs = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable());
    execute(""DELETE FROM %s USING TIMESTAMP 9999 WHERE a = 1"");
    cfs.forceBlockingFlush();
    assertEquals(1, cfs.getLiveSSTables().size());
    StatsMetadata metadata = cfs.getLiveSSTables().iterator().next().getSSTableMetadata();
    assertEquals(9999, metadata.minTimestamp);
    assertEquals(9999, metadata.maxTimestamp);
    assertEquals(System.currentTimeMillis()/1000, metadata.maxLocalDeletionTime, 5);
    assertEquals(nowInSec(), metadata.maxLocalDeletionTime, DELTA);
    cfs.forceMajorCompaction();
    StatsMetadata metadata2 = cfs.getLiveSSTables().iterator().next().getSSTableMetadata();
    assertEquals(metadata.maxLocalDeletionTime, metadata2.maxLocalDeletionTime);
    assertEquals(metadata.minTimestamp, metadata2.minTimestamp);
    assertEquals(metadata.maxTimestamp, metadata2.maxTimestamp);
}",time,2
317,apache_druid,KafkaLookupExtractorFactoryTest.testStartStop,"@Test
public void testStartStop() {
    final KafkaStream<String, String> kafkaStream = PowerMock.createStrictMock(KafkaStream.class);
    final ConsumerIterator<String, String> consumerIterator = PowerMock.createStrictMock(ConsumerIterator.class);
    final ConsumerConnector consumerConnector = PowerMock.createStrictMock(ConsumerConnector.class);
    EasyMock.expect(consumerConnector.createMessageStreamsByFilter(EasyMock.anyObject(TopicFilter.class), EasyMock.anyInt(), EasyMock.eq(DEFAULT_STRING_DECODER), EasyMock.eq(DEFAULT_STRING_DECODER))).andReturn(ImmutableList.of(kafkaStream)).once();
    EasyMock.expect(kafkaStream.iterator()).andReturn(consumerIterator).anyTimes();
    EasyMock.expect(consumerIterator.hasNext()).andAnswer(getBlockingAnswer()).anyTimes();
    EasyMock.expect(cacheManager.createCache()).andReturn(cacheHandler).once();
    EasyMock.expect(cacheHandler.getCache()).andReturn(new ConcurrentHashMap<String, String>()).once();
    cacheHandler.close();
    EasyMock.expectLastCall();
    final AtomicBoolean threadWasInterrupted = new AtomicBoolean(false);
    consumerConnector.shutdown();
    EasyMock.expectLastCall().andAnswer(new IAnswer<Object>() {
        @Override
        public Object answer() {
            threadWasInterrupted.set(Thread.currentThread().isInterrupted());
            return null;
        }
    }).times(2);
    PowerMock.replay(cacheManager, cacheHandler, kafkaStream, consumerConnector, consumerIterator);
    final KafkaLookupExtractorFactory factory = new KafkaLookupExtractorFactory(cacheManager, TOPIC, ImmutableMap.of(""zookeeper.connect"", ""localhost""), 10000L, false) {
        @Override
        ConsumerConnector buildConnector(Properties properties) {
            return consumerConnector;
        }
    };
    Assert.assertTrue(factory.start());
    Assert.assertTrue(factory.close());
    Assert.assertTrue(factory.getFuture().isDone());
    Assert.assertFalse(threadWasInterrupted.get());
    PowerMock.verify(cacheManager, cacheHandler);
}",concurrency,1
319,liquibase_liquibase,DependencyUtilTest.testIndependentBranchesCase,"@Test
public void testIndependentBranchesCase() {
    graph.add(""a"", ""b"");
    graph.add(""b"", ""c1"");
    graph.add(""b"", ""c2"");
    graph.add(""o"", ""p1"");
    graph.add(""p1"", ""r1"");
    graph.add(""r1"", ""s"");
    graph.add(""o"", ""p2"");
    graph.add(""p2"", ""r2"");
    graph.add(""r2"", ""s2"");
    graph.add(""r2"", ""s3"");
    graph.add(""x"", ""y"");
    graph.computeDependencies();
    List<String> expected =
    Arrays.asList(""a"", ""o"", ""x"", ""b"", ""p1"", ""p2"", ""y"", ""c1"", ""c2"", ""r1"", ""r2"", ""s"", ""s2"", ""s3"");
    Assert.assertEquals(expected, dependencyOrder);
}",unordered collections,3
326,hwang-pku_ormlite-core,QueryBuilderTest.testQueryRaw,"@Test
public void testQueryRaw() throws Exception {
    Dao<Foo, Integer> dao = createDao(Foo.class, true);
    Foo foo = new Foo();
    foo.stringField = ""zipper"";
    dao.create(foo);
    QueryBuilder<Foo, Integer> qb = dao.queryBuilder();
    assertEquals(1, qb.countOf());
    GenericRawResults<String[]> results = qb.queryRaw();
    List<String[]> stringResults = results.getResults();
    assertEquals(1, stringResults.size());
    assertEquals(Integer.toString(foo.id), stringResults.get(0)[0]);
    assertEquals(foo.stringField, stringResults.get(0)[3]);
}",unordered collections,3
346,eclipse_jetty.project,project.MavenMetadataTest.testIsExpiredTimestampYesterday,"@Test
public void testIsExpiredTimestampYesterday() {
    LocalDateTime yesterday = LocalDateTime.now().minusDays(1);
    String timestamp = getTimestampFormatter().format(yesterday);
    assertTrue(MavenMetadata.isExpiredTimestamp(timestamp), ""Timestamp should be stale: "" + timestamp);
}",time,2
349,GoogleCloudPlatform_google-cloud-eclipse,CreateAppEngineStandardWtpProjectTest.testNoTestClassesInDeploymentAssembly,"@Test
public void testNoTestClassesInDeploymentAssembly()
throws InvocationTargetException, CoreException {
    CreateAppEngineWtpProject creator = new CreateAppEngineStandardWtpProject(config, adaptable);
    creator.execute(monitor);
    ProjectUtils.waitForProjects(project);
    assertNoTestClassesInDeploymentAssembly();
}
private void assertNoTestClassesInDeploymentAssembly() throws CoreException {
    StructureEdit core = StructureEdit.getStructureEditForRead(project);
    WorkbenchComponent component = core.getComponent();
    assertNotNull(component);
    boolean seenMainSourcePath = false;
    List<ComponentResource> resources = component.getResources();
    for (ComponentResource resource : resources) {
        assertFalse(containsSegment(resource.getSourcePath(), ""test""));
        if (resource.getSourcePath().equals(new Path(""/src/main/java""))
        && resource.getRuntimePath().equals(new Path(""/WEB-INF/classes""))) {
            seenMainSourcePath = true;
        }
    }
    assertTrue(seenMainSourcePath);
}",async wait,0
354,apache_struts,13d9053050c9e4fb2ef049db6a37d3f6eebf48fa.testRender_ok.2,"@Test
public void testRender_ok() {
    final Mock mockResponse = mock(RenderResponse.class);
    mockResponse.stubs().method(ANYTHING);
    PortletMode mode = PortletMode.VIEW;
    Map<String, String[]> requestParams = new HashMap<String, String[]>();
    requestParams.put(ACTION_PARAM, new String[] { ""/view/testAction"" });
    requestParams.put(EVENT_ACTION, new String[] { ""true"" });
    requestParams.put(MODE_PARAM, new String[] { mode.toString() });
    Map<String, Object> sessionMap = new HashMap<String, Object>();
    Map<String, String> initParams = new HashMap<String, String>();
    initParams.put(""viewNamespace"", ""/view"");
    initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE,
    ""true"");
    initPortletConfig(initParams, new HashMap<String, Object>());
    initRequest(requestParams, new HashMap<String, Object>(), sessionMap,
    PortletMode.VIEW, WindowState.NORMAL, false, null);
    setupActionFactory(""/view"", ""testAction"", ""success"",
    EasyMock.createNiceMock(ValueStack.class));
    mockInvocation.expects(once()).method(""getStack"")
    .will(returnValue(null));
    try {
        dispatcher
        .setActionProxyFactory((ActionProxyFactory) mockActionFactory
        .proxy());
        dispatcher.init((PortletConfig) mockConfig.proxy());
        dispatcher.render((RenderRequest) mockRequest.proxy(),
        (RenderResponse) mockResponse.proxy());
    } catch (Exception e) {
        e.printStackTrace();
        fail(""Error occured"");
    }
}",test order dependency,4
362,line_armeria,ServiceRequestCancellationTest.shouldCompleteLogWhenCancelledByClient,"@Test
void shouldCompleteLogWhenCancelledByClient(SessionProtocol protocol) {
    final ClientFactory factory = ClientFactory.builder().build();
    final WebClient client = WebClient.builder(server.uri(protocol)).factory(factory).build();
    final CompletableFuture<AggregatedHttpResponse> responseFuture = client.get(""/reset"").aggregate();
    await().untilAtomic(ctxRef, Matchers.notNullValue());
    factory.close();
    final RequestLog log = ctxRef.get().log().whenComplete().join();
    if (protocol.isMultiplex()) {
        assertThat(log.responseCause()).isInstanceOf(ClosedStreamException.class).hasMessageContaining(""received a RST_STREAM frame: CANCEL"");
        assertThatThrownBy(responseFuture::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedStreamException.class);
    } else {
        assertThat(log.responseCause()).isInstanceOf(ClosedSessionException.class);
        assertThatThrownBy(responseFuture::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedSessionException.class);
    }
}",test order dependency,4
366,GoogleCloudPlatform_google-cloud-eclipse,XmlValidatorTest.testValidate_badXml,"@Test
public void testValidate_badXml() throws IOException, CoreException {
    XmlValidator validator = new XmlValidator();
    validator.setHelper(new AppEngineWebXmlValidator());
    IFile file = createBogusProjectFile();
    byte[] badXml = BAD_XML.getBytes(StandardCharsets.UTF_8);
    validator.validate(file, badXml);
    IMarker[] emptyMarkers =
    ProjectUtils.waitUntilNoMarkersFound(file, PROBLEM, true, DEPTH_ZERO);
    ArrayAssertions.assertIsEmpty(emptyMarkers);
}",async wait,0
19420,eclipse_xtext-core,DeclarativeQualifiedNameConverterTest.getDelimiter,"	@Test public void testQualifiedNameConverter() throws Exception {
			public String getDelimiter() {
				return ""!"";
			}
",non-flaky,5
19421,eclipse_xtext-core,DeclarativeQualifiedNameConverterTest.getDelimiter,"	@Test public void testQualifiedNameConverter_emptyDelimiter() throws Exception {
			public String getDelimiter() {
				return """";
			}
",non-flaky,5
19422,eclipse_xtext-core,DeclarativeQualifiedNameConverterTest.getDelimiter,"	@Test public void testQualifiedNameConverter_nullDelimiter() throws Exception {
			public String getDelimiter() {
				return null;
			}
",non-flaky,5
19423,eclipse_xtext-core,QualifiedNameTest.testAppendNull,"	@Test public void testCreateNull() {
	public void testAppendNull() {
		try {
			QualifiedName.create().append((String) null);
			fail(""Exception expected"");
		} catch (IllegalArgumentException e) {}
	}
",non-flaky,5
19424,eclipse_xtext-core,QualifiedNameTest.apply,"	@Test public void testWrapper() throws Exception {
			public String apply(String from) {
				return from;
			}
",non-flaky,5
19425,eclipse_xtext-core,GenericModuleTest.bindDate,"	@Test public void testInstanceBinding() throws Exception {
			public Date bindDate() {
				return date;
			}
",non-flaky,5
19426,eclipse_xtext-core,GenericModuleTest.get,"	@Test public void testProviderClassDeactivation() throws Exception {
		public String get() {
			 return ""foo"";
		}
",non-flaky,5
19427,eclipse_xtext-core,GenericModuleTest.get,"	@Test public void testProviderInstanceBinding() throws Exception {
			public Date get() {
				return null;
			}
",non-flaky,5
19428,eclipse_xtext-core,GenericModuleTest.bindFoo,"	@Test public void testSingletonBinding() throws Exception {
			public Class<Foo> bindFoo() {
				return Foo.class;
			}
",non-flaky,5
19429,eclipse_xtext-core,GenericModuleTest.bindFoo,"	@Test public void testEagerSingletonBinding() throws Exception {
			public Class<Foo> bindFoo() {
				return Foo.class;
			}
",non-flaky,5
19430,eclipse_xtext-core,SerializationTest._testSerialize_03,"	@Test public void testSerialize_02() throws Exception {
	public void _testSerialize_03() throws Exception {
		model.setGenerated(GeneratedEnum.DIFFERENT_NAME);
		String result = serialize(model);
		assertEquals(""generated DifferentLiteral"", result);
	}
",non-flaky,5
19431,eclipse_xtext-core,AllContentsPerformanceTest.exec,"	@Test public void testXtextGrammarUoW() throws Exception {
			public Boolean exec(EObject state) throws Exception {
				callCount[0]++;
				return false;
			}
",non-flaky,5
19432,eclipse_xtext-core,XtextValidationTest.testBug322875_01,"	@Test
	public void testBug322875_01() throws Exception {
		String testGrammar = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'classpath:/org/eclipse/xtext/xtext/XtextValidationTest.ecore'  "" +
				"" import 'http://www.eclipse.org/2008/Xtext' as xtext\n"" +
				""Bug322875 returns Bug322875: referencesETypeFromClasspathPackage=[xtext::Grammar];"";
		XtextResource resource = getResourceFromStringAndExpect(testGrammar,1);
		assertFalse(resource.getErrors().toString(), resource.getErrors().isEmpty());
		assertBug322875(resource);
	}
",non-flaky,5
19433,eclipse_xtext-core,XtextValidationTest.testBug322875_01_b,"	@Test
	public void testBug322875_01_b() throws Exception {
		String testGrammar = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'http://www.eclipse.org/2008/Xtext' as xtext\n"" +
				"" import 'classpath:/org/eclipse/xtext/xtext/XtextValidationTest.ecore'  "" +
				""Bug322875 returns Bug322875: referencesETypeFromClasspathPackage=[xtext::Grammar];"";
		XtextResource resource = getResourceFromStringAndExpect(testGrammar,1);
		assertFalse(resource.getErrors().toString(), resource.getErrors().isEmpty());
		assertBug322875(resource);
	}
",non-flaky,5
19434,eclipse_xtext-core,XtextValidationTest.testBug322875_02,"	@Test
	public void testBug322875_02() throws Exception {
		URIConverter.URI_MAP.put(URI.createURI(""platform:/plugin/org.eclipse.emf.ecore/model/Ecore.ecore""), URI.createURI(getClass().getResource(""/model/Ecore.ecore"").toExternalForm()));
		String testGrammar = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'platform:/plugin/org.eclipse.emf.ecore/model/Ecore.ecore'  "" +
				""Model returns EClass: name=ID;"";
		XtextResource resource = getResourceFromString(testGrammar);
		Diagnostic diag = Diagnostician.INSTANCE.validate(resource.getContents().get(0));
		assertNotNull(""diag"", diag);
		assertEquals(diag.toString(), 0, diag.getChildren().size());
		assertEquals(""diag.isOk"", Diagnostic.OK, diag.getSeverity());
	}
",non-flaky,5
19435,eclipse_xtext-core,XtextValidationTest.testBug322875_04,"	@Test
	public void testBug322875_04() throws Exception {
		String testGrammarNsURI = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'http://www.eclipse.org/emf/2002/Ecore'  "" +
				""Model returns EClass: name=ID;"";
		String testGrammarPlatformPlugin = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'platform:/plugin/org.eclipse.emf.ecore/model/Ecore.ecore'  "" +
				""Model returns EClass: name=ID;"";
		XtextResource resourceOk = getResourceFromString(testGrammarNsURI);
		XtextResource resourceOk2 = (XtextResource) resourceOk.getResourceSet().createResource(URI.createURI(""unused.xtext""));
		resourceOk2.load(new StringInputStream(testGrammarPlatformPlugin), null);
		Diagnostic diagOK = Diagnostician.INSTANCE.validate(resourceOk.getContents().get(0));
		assertNotNull(""diag"", diagOK);
		assertEquals(diagOK.toString(), 0, diagOK.getChildren().size());
		diagOK = Diagnostician.INSTANCE.validate(resourceOk2.getContents().get(0));
		assertNotNull(""diag"", diagOK);
		assertEquals(diagOK.toString(), 0, diagOK.getChildren().size());
	}
",non-flaky,5
19436,eclipse_xtext-core,XtextValidationTest.testBug_280413_03,"	@Test
	public void testBug_280413_03() throws Exception {
		XtextResource resource = getResourceFromString(
				""grammar org.foo.Bar with org.eclipse.xtext.common.Terminals\n"" +
				""import 'classpath:/org/eclipse/xtext/Xtext.ecore' as xtext\n"" +
				""ParserRule returns xtext::ParserRule: name = ID;"");
		assertTrue(resource.getErrors().toString(), resource.getErrors().isEmpty());
		assertTrue(resource.getWarnings().toString(), resource.getWarnings().isEmpty());

		Diagnostic diag = Diagnostician.INSTANCE.validate(resource.getContents().get(0));
		assertNotNull(""diag"", diag);
		assertEquals(diag.getSeverity(), Diagnostic.OK);
		assertTrue(diag.getChildren().toString(), diag.getChildren().isEmpty());
	}
",non-flaky,5
19437,eclipse_xtext-core,XtextValidationTest.expectedContext,"	@Test public void testNegatedTokenNotEOF_2() throws Exception {
		String grammarAsText =
				""grammar test with org.eclipse.xtext.common.Terminals\n"" +
						""generate test 'http://test'\n"" +
						""A: foo=DUMMY;\n"" +
						""terminal DUMMY: !(EOF | ID);"";
		Grammar grammar = (Grammar) getModel(grammarAsText);
		XtextValidator validator = get(XtextValidator.class);
		ValidatingMessageAcceptor messageAcceptor = new ValidatingMessageAcceptor(null, true, false);
		TerminalRule terminal = (TerminalRule) grammar.getRules().get(1);
		NegatedToken token = (NegatedToken)terminal.getAlternatives();
		messageAcceptor.expectedContext(((Alternatives)token.getTerminal()).getElements().get(0));
		configureValidator(validator, messageAcceptor, token);
		validator.checkNegatedTokenNotEOF(token);
		messageAcceptor.validate();
	}

	public class ValidatingMessageAcceptor extends AbstractValidationMessageAcceptor {

		private final Set<EObject> contexts;
		private boolean error;
		private boolean warning;
		private boolean info;

		public ValidatingMessageAcceptor(EObject context, boolean error, boolean warning) {
			this.contexts = Sets.newHashSet();
			if (context != null)
				contexts.add(context);
			this.error = error;
			this.warning = warning;
		}
		
		public void expectedContext(EObject... contexts) {
			this.contexts.addAll(Arrays.asList(contexts));
		}
",non-flaky,5
19438,eclipse_xtext-core,TypeHierarchyHelperTest.testSimpeCase01,"	@Test
	public void testSimpeCase01() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		b.addSupertype(a);
		c.addSupertype(a);
		addAttribute(b, INT, ""f1"");
		addAttribute(c, INT, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19439,eclipse_xtext-core,TypeHierarchyHelperTest.testSimpeCase02,"	@Test
	public void testSimpeCase02() throws Exception {
		// no uplift for less than two children
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		b.addSupertype(a);
		addAttribute(b, INT, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19440,eclipse_xtext-core,TypeHierarchyHelperTest.testRecursiveUplift01,"	@Test
	public void testRecursiveUplift01() throws Exception {
		// no uplift for less than two children
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		EClassInfo d = addClass(""d"");
		EClassInfo e = addClass(""e"");
		b.addSupertype(a);
		c.addSupertype(a);
		d.addSupertype(c);
		e.addSupertype(c);

		addAttribute(b, INT, ""f1"");
		addAttribute(d, INT, ""f1"");
		addAttribute(e, INT, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
		assertEquals(1, d.getEClass().getEStructuralFeatures().size());
		assertEquals(1, e.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
		assertEquals(0, d.getEClass().getEStructuralFeatures().size());
		assertEquals(0, e.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19441,eclipse_xtext-core,TypeHierarchyHelperTest.testNikolaus,"	@Test
	public void testNikolaus() throws Exception {
		// no uplift for less than two children
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		EClassInfo d = addClass(""d"");
		EClassInfo e = addClass(""e"");
		b.addSupertype(a);
		c.addSupertype(a);
		d.addSupertype(b);
		d.addSupertype(c);
		e.addSupertype(b);
		e.addSupertype(c);

		addAttribute(b, STRING, ""f2"");
		addAttribute(c, STRING, ""f2"");
		addAttribute(d, INT, ""f1"");
		addAttribute(e, INT, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());
		assertEquals(1, d.getEClass().getEStructuralFeatures().size());
		assertEquals(1, e.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
		assertEquals(1, d.getEClass().getEStructuralFeatures().size());
		assertEquals(1, e.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19442,eclipse_xtext-core,TypeHierarchyHelperTest.testImcompatipleFeatures,"	@Test
	public void testImcompatipleFeatures() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		b.addSupertype(a);
		c.addSupertype(a);
		addAttribute(b, INT, ""f1"");
		addAttribute(c, STRING, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19443,eclipse_xtext-core,TypeHierarchyHelperTest.testReferences,"	@Test
	public void testReferences() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		EClassInfo d = addClass(""d"");
		b.addSupertype(a);
		c.addSupertype(a);
		addReference(b, d, ""r1"");
		addReference(c, d, ""r1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19444,eclipse_xtext-core,TypeHierarchyHelperTest.testConfigurationOfLiftedReference,"	@Test
	public void testConfigurationOfLiftedReference() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");

		b.addSupertype(a);
		c.addSupertype(a);
		EReference refB = addReference(b, a, ""ref"");
		refB.setContainment(true);
		EReference refC = addReference(c, a, ""ref"");
		refC.setContainment(true);

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());

		EReference refA = (EReference) a.getEClass().getEStructuralFeatures().get(0);
		assertTrue(refA.isContainment());
	}
",non-flaky,5
19445,eclipse_xtext-core,TypeHierarchyHelperTest.testDublicateDerivedFeature,"	@Test
	public void testDublicateDerivedFeature() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		b.addSupertype(a);
		c.addSupertype(b);
		addAttribute(a, INT, ""f"");
		addAttribute(c, INT, ""f"");

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		initializeHelper();
		helper.removeDuplicateDerivedFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
	}
",non-flaky,5
19446,eclipse_xtext-core,EClassInfoTest.testChangeable,"	@Test public void testContainsCompatibleFeature_01() throws Exception {
	public void testChangeable(){
		EcorePackage pack = EcorePackage.eINSTANCE;
		EClass eClass = pack.getEClass();
		EClassInfo objectUnderTest = new EClassifierInfo.EClassInfo(eClass, false, Collections.<String>emptySet(), null);
		EcoreFactory fac = EcoreFactory.eINSTANCE;
		EReference reference = fac.createEReference();
		reference.setName(""newReference"");
		reference.setEType(eClass);
		reference.setChangeable(true);
		reference.setContainment(true);
		eClass.getEStructuralFeatures().add(reference);
		assertEquals(true,objectUnderTest.containsCompatibleFeature(""newReference"", false, true, eClass, new StringBuilder()));
		reference.setChangeable(false);
		assertEquals(false,objectUnderTest.containsCompatibleFeature(""newReference"", false, true, eClass, new StringBuilder()));
	}
",non-flaky,5
19447,eclipse_xtext-core,PartialParserTest.performTest,"	@Test public void testEditGroupWithCardinality_03() throws Exception {
	public void performTest(String toBeDeleted) throws Exception {
		String grammarAsText = 
			""grammar TestLanguage with org.eclipse.xtext.common.Terminals\n"" +
			""generate test 'myEcoreModel'\n"" +
			""Root: value=Test;\n"" +
			""Test: ("" + toBeDeleted.trim() + "" 'foo')*;"";
		XtextResource resource = getResourceFromString(grammarAsText);
		Grammar g = (Grammar) resource.getContents().get(0);
		ParserRule rule = (ParserRule) g.getRules().get(1);
		assertEquals(""*"", rule.getAlternatives().getCardinality());
		resource.update(grammarAsText.indexOf(toBeDeleted), toBeDeleted.length(), """");
		// make sure we did a partial parse pass
		assertSame(rule, ((Grammar) resource.getContents().get(0)).getRules().get(1));
		assertEquals(""*"", rule.getAlternatives().getCardinality());
	}
",non-flaky,5
19448,eclipse_xtext-core,Bug287082Test.acceptWarning,"	@Test public void testBug285605() throws Exception {
	public void acceptWarning(String message, EObject object, EStructuralFeature feature, int index, String code,
			String... issueData) {
		if (code.equals(OverriddenValueInspector.ISSUE_CODE)) {
			String expectation = ""The assigned value of feature 'feature' will possibly override itself because it is used inside of a loop."";
			assertEquals(expectation, message);
		} else {
			super.acceptWarning(message, object, feature, index, code, issueData);
		}
	}
",non-flaky,5
19449,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testRelativeContext() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19450,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testRelativePath() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19451,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testReexports2() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19452,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testLocalElementsNotFromIndex() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19453,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testImportsWithoutWildcard() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19454,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testDuplicateImportsAreIgnored() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19455,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testUnambiguousImportAreShadowed_00() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19456,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testUnambiguousImportAreShadowed_01() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19457,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testUnambiguousImportAreShadowed_02() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
",non-flaky,5
19458,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testMultipleFiles() throws Exception {
			public Iterator<EObject> iterator() {
				return res1.getAllContents();
			}
",non-flaky,5
19459,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testResourceSetReferencingResourceSet() throws Exception {
			public Iterator<EObject> iterator() {
				return res1.getAllContents();
			}
",non-flaky,5
19460,eclipse_xtext-core,ImportedNamespaceAwareLocalScopeProviderTest.iterator,"	@Test public void testResourceSetReferencingResourceSet2() throws Exception {
			public Iterator<EObject> iterator() {
				return res2.getAllContents();
			}
",non-flaky,5
19461,eclipse_xtext-core,ScopeTest.iterator,"	@Test public void testLaziness() throws Exception {
				public Iterator<IEObjectDescription> iterator() {
					numberOfCalls++;
					return singleton(
							(IEObjectDescription) new EObjectDescription(QualifiedName.create(name),
									EcorePackage.Literals.EATTRIBUTE, null)).iterator();
				}
",non-flaky,5
19462,eclipse_xtext-core,DelegatingScopeProviderTest.testNoSuitableDelegate,"	@Test
	public void testNoSuitableDelegate() {
		TestableDelegatingScopeProvider testMe = new TestableDelegatingScopeProvider();
		testMe.setWrapper(this);
		Assert.assertEquals(1, testMe.invocationCount);
		
		IDelegatingScopeProvider.setWrapper(testMe, null);
		Assert.assertEquals(2, testMe.invocationCount);
	}
",non-flaky,5
19463,eclipse_xtext-core,DelegatingScopeProviderTest.testOneSuitableDelegate_01,"	@Test
	public void testOneSuitableDelegate_01() {
		TestableDelegatingScopeProvider root = new TestableDelegatingScopeProvider();
		TestableDelegatingScopeProvider delegating = new TestableDelegatingScopeProvider(root);
		
		delegating.setWrapper(this);
		Assert.assertEquals(1, delegating.invocationCount);
		Assert.assertEquals(1, root.invocationCount);
		
		IDelegatingScopeProvider.setWrapper(delegating, null);
		Assert.assertEquals(2, delegating.invocationCount);
		Assert.assertEquals(2, root.invocationCount);
	}
",non-flaky,5
19464,eclipse_xtext-core,DelegatingScopeProviderTest.getScope,"	@Test
	public void testOneSuitableDelegate_02() {
		final int[] invocationCount = new int[] { 0 };
		AbstractGlobalScopeDelegatingScopeProvider root = new AbstractGlobalScopeDelegatingScopeProvider() {
			
			@Override
			public IScope getScope(EObject context, EReference reference) {
				return IScope.NULLSCOPE;
			}
",non-flaky,5
19465,eclipse_xtext-core,DelegatingScopeProviderTest.getScope,"	@Test
	public void testTwoSuitableDelegates_02() {
		final int[] invocationCount = new int[] { 0 };
		AbstractGlobalScopeDelegatingScopeProvider first = new AbstractGlobalScopeDelegatingScopeProvider() {
			
			@Override
			public IScope getScope(EObject context, EReference reference) {
				return IScope.NULLSCOPE;
			}
",non-flaky,5
19466,eclipse_xtext-core,ImportScopeTest.getEObjectOrProxy,"	@Test public void testGetByEObject_01() throws Exception {
		public EObject getEObjectOrProxy() {
			EObject element = super.getEObjectOrProxy();
			InternalEObject result = (InternalEObject) EcoreFactory.eINSTANCE.create(element.eClass());
			result.eSetProxyURI(EcoreUtil.getURI(element));
			return result;
		}
",non-flaky,5
19467,eclipse_xtext-core,ProfilingTest.createInjector,"	@Test public void testSimple() throws Exception {
			public Injector createInjector() {
				return Guice.createInjector(new org.eclipse.xtext.index.IndexTestLanguageRuntimeModule(){
					@Override
					public java.lang.Class<? extends org.eclipse.xtext.scoping.IScopeProvider> bindIScopeProvider() {
						return OptimizedScopeProvider.class;
					}
				}
				);
			}
",non-flaky,5
19468,eclipse_xtext-core,Bug318343Test.tearDown,"	@Test public void testScopeContainsNotT2() throws Exception {
	public void tearDown() throws Exception {
		resource1 = null;
		resource2 = null;
		globalScopeProvider = null;
		super.tearDown();
		
	}
",non-flaky,5
19469,eclipse_xtext-core,ParseErrorHandlingTest.apply,"	@Test public void testBug236425() throws Exception {
			public Iterator<INode> iterator() {
				return Iterators.filter(node.getAsTreeIterable().iterator(), new Predicate<INode>() {
					@Override
					public boolean apply(INode input) {
						return input.getSyntaxErrorMessage() != null;
					}
",non-flaky,5
19470,eclipse_xtext-core,UriBasedReaderTest.configureFileExtensions,"	@Test public void testIssuesInOtherResource() throws Exception {
			public Injector createInjector() {
				return Guice.createInjector(new org.eclipse.xtext.XtextRuntimeModule() {
					@Override
					public void configureFileExtensions(Binder binder) {
						binder.bind(String.class).annotatedWith(Names.named(Constants.FILE_EXTENSIONS)).toInstance(""xtexterror"");
					}
",non-flaky,5
19471,eclipse_xtext-core,ReaderTest.apply,"	@Test public void testShadowingPathes() throws Exception {
			public boolean apply(EObject input) {
				return input.eResource().getURI().toString().contains(""folder%20""+uriContains);
			}
",non-flaky,5
19472,eclipse_xtext-core,PathTraverserTest.testNoneExistingFile,"	@Test
	public void testNoneExistingFile() throws Exception {
		String path = ""fileNotExists"";
		Set<URI> uris = new PathTraverser().findAllResourceUris(path, everythingButDummy);
		assertTrue(uris.isEmpty());
	}
",non-flaky,5
19473,eclipse_xtext-core,PathTraverserTest.testEmptyFolder,"	@Test
	public void testEmptyFolder() throws Exception {
		String path = pathTo(""emptyFolder"");
		Set<URI> uris = new PathTraverser().findAllResourceUris(path, everythingButDummy);
		assertTrue(uris.isEmpty());
	}
",non-flaky,5
19474,eclipse_xtext-core,PathTraverserTest.testNonEmptyFolder,"	@Test
	public void testNonEmptyFolder() throws Exception {
		String path = pathTo(""nonemptyFolder"");
		Set<URI> uris = new PathTraverser().findAllResourceUris(path, everythingButDummy);
		assertEquals(2, uris.size());
	}
",non-flaky,5
19475,eclipse_xtext-core,PathTraverserTest.testArchive,"	@Test
	public void testArchive() throws Exception {
		String path = pathTo(""nonemptyJar.jar"");
		Set<URI> uris = new PathTraverser().findAllResourceUris(path, everythingButDummy);
		assertEquals(3, uris.size());
	}
",non-flaky,5
19476,eclipse_xtext-core,AbstractReaderTest.matches,"	@Test public void testLoadMatchNone() throws Exception {
			public boolean matches(URI uri) {
				return false;
			}
",non-flaky,5
19477,eclipse_xtext-core,AbstractReaderTest.matches,"	@Test public void testLoadMatchAll() throws Exception {
			public boolean matches(URI uri) {
				return true;
			}
",non-flaky,5
19478,eclipse_xtext-core,AbstractReaderTest.pathTo,"	@Test public void testParseClassPath() throws Exception {
	public String pathTo(String string) throws Exception {
//		URL resource = getClass().getClassLoader().getResource();
		File base = new File(""./src/""+getClass().getName().replace('.', '/') + "".java"");
		URI fileURI = URI.createFileURI(base.getAbsolutePath());
//		System.out.println(fileURI);
		// this is a hack used in order to get a file URI for a bundleresource:/ URL
//		File f = (File) get(resource,""handler.bundleEntry.file"");
//		if (f!=null)
//			fileURI = URI.createFileURI(f.getAbsolutePath());
		
		URI fileURI2 = URI.createURI(string);
		return fileURI2.resolve(fileURI).toFileString();
	}
",non-flaky,5
19479,eclipse_xtext-core,CompositeNodeTest.iterator,"	@Test public void testGetLeafNodes_01() {
			public Iterator<INode> iterator() {
				return new AbstractIterator<INode>() {

					private BidiTreeIterator<AbstractNode> delegate = node.basicIterator();
					
					@Override
					protected INode computeNext() {
						if (delegate.hasPrevious())
							return delegate.previous();
						return endOfData();
					}
				};
			}
",non-flaky,5
19480,eclipse_xtext-core,LineAndColumnTest.testEmptyText,"	@Test
	public void testEmptyText() {
		assertLineAndColumn("""", 0, 1, 1);
	}
",non-flaky,5
19481,eclipse_xtext-core,LineAndColumnTest.testExceedsOffset,"	@Test(expected=IndexOutOfBoundsException.class)
	public void testExceedsOffset() {
		assertLineAndColumn("""", 1, -1, -1);
	}
",non-flaky,5
19482,eclipse_xtext-core,LineAndColumnTest.testNegativeOffset,"	@Test(expected=IndexOutOfBoundsException.class)
	public void testNegativeOffset() {
		assertLineAndColumn("""", -1, -1, -1);
	}
",non-flaky,5
19483,eclipse_xtext-core,LineAndColumnTest.testSingleCharText,"	@Test
	public void testSingleCharText() {
		assertLineAndColumn(""a"", 0, 1, 1);
		assertLineAndColumn(""a"", 1, 1, 2);
	}
",non-flaky,5
19484,eclipse_xtext-core,LineAndColumnTest.testTwoCharsText,"	@Test
	public void testTwoCharsText() {
		assertLineAndColumn(""ab"", 0, 1, 1);
		assertLineAndColumn(""ab"", 1, 1, 2);
		assertLineAndColumn(""ab"", 2, 1, 3);
	}
",non-flaky,5
19485,eclipse_xtext-core,LineAndColumnTest.testPointsToLineBreak,"	@Test
	public void testPointsToLineBreak() {
		assertLineAndColumn(""\n"", 0, 1, 1);
		assertLineAndColumn(""\r\n"", 0, 1, 1);
	}
",non-flaky,5
19486,eclipse_xtext-core,LineAndColumnTest.testPointsToBackslashNInWindowsLineBreak,"	@Test
	public void testPointsToBackslashNInWindowsLineBreak() {
		assertLineAndColumn(""\r\n"", 1, 1, 2);
		assertLineAndColumn(""a\r\n"", 2, 1, 3);
		assertLineAndColumn(""a\r\n"", 3, 2, 1);
	}
",non-flaky,5
19487,eclipse_xtext-core,LengthOffsetLineTest.setUp,"	@Test public void testErrors1() throws Exception {
	public void setUp() throws Exception {
		super.setUp();
		with(DummyTestLanguageStandaloneSetup.class);
	}
",non-flaky,5
19488,eclipse_xtext-core,SerializationUtilTest.testFillIdToEObjectMap,"	@Test
	public void testFillIdToEObjectMap() {
		EPackage pack = EcoreFactory.eINSTANCE.createEPackage();
		EClass root = createEClass(pack, ""Root"");
		EClass someType = createEClass(pack, ""SomeType"");

		EReference ref1 = addEReference(root, someType, ""ref1"", false);
		EReference ref2 = addEReference(root, someType, ""ref2"", true);

		EFactory factory = pack.getEFactoryInstance();
		EObject rootObject = factory.create(root);
		EObject someTypeObject1 = factory.create(someType);
		EObject someTypeObject2 = factory.create(someType);
		rootObject.eSet(ref1, someTypeObject1);
		rootObject.eSet(ref2, someTypeObject2);

		List<EObject> map = new ArrayList<>();
		SerializationUtil.fillIdToEObjectMap(rootObject, map);
		assertTrue(map.contains(rootObject));
		assertTrue(map.contains(someTypeObject1));
		assertFalse(map.contains(someTypeObject2));
		assertEquals(2, map.size());
	}
",non-flaky,5
19489,eclipse_xtext-core,SerializationUtilTest.testSyntaxErrorMessage,"	@Test
	public void testSyntaxErrorMessage() throws IOException {
		final String message = ""hi"";
		String [] issueCodes = { null, ""issue"" };
		String [][] issueDatas = { null, {null}, {""issue data""}};
		
		for (String[] issueData : issueDatas) {
			for (String issueCode : issueCodes) {
				SyntaxErrorMessage sem = new SyntaxErrorMessage(message, issueCode, issueData);
				ByteArrayOutputStream out = new ByteArrayOutputStream ();
				DataOutputStream dout = new DataOutputStream(out);
				SerializationUtil.writeSyntaxErrorMessage(dout, null, sem);
				dout.close();
				byte[] array = out.toByteArray();
				ByteArrayInputStream in = new ByteArrayInputStream(array); 
				DataInputStream din = new DataInputStream(in);
				SyntaxErrorMessage sem2 = SerializationUtil.readSyntaxErrorMessage(din, null);
				assertEquals(sem, sem2); 
			}
		}
		ByteArrayOutputStream out = new ByteArrayOutputStream ();
		DataOutputStream dout = new DataOutputStream(out);
		SerializationUtil.writeSyntaxErrorMessage(dout, null, null);
		dout.close();
		byte[] array = out.toByteArray();
		ByteArrayInputStream in = new ByteArrayInputStream(array); 
		DataInputStream din = new DataInputStream(in);
		SyntaxErrorMessage readMessage = SerializationUtil.readSyntaxErrorMessage(din, null);
		assertNull(readMessage);
	}
",non-flaky,5
19490,eclipse_xtext-core,EcoreUtil2Test.testClone_2,"	@Test
	public void testClone_2() throws Exception {
		ResourceSetImpl sourceSet = new DerivedStateAwareResourceSet();
		DerivedStateAwareResource resource = (DerivedStateAwareResource) sourceSet.createResource(URI
				.createURI(""http://derived.res""));
		boolean stateToCheck = !resource.isFullyInitialized();
		resource.setFullyInitialized(stateToCheck);
		
		Resource targetRes = EcoreUtil2.clone(new DerivedStateAwareResourceSet(), sourceSet).getResources().get(0);
		
		assertTrue(targetRes instanceof DerivedStateAwareResource);
		assertEquals(""FullyInitialized flag not copied "", stateToCheck, ((DerivedStateAwareResource) targetRes).isFullyInitialized());
	}
",non-flaky,5
19491,eclipse_xtext-core,ReadWriteAccessTest.uncaughtException,"	@Test public void testModifyAndRead() throws Exception {
			public void uncaughtException(Thread t, Throwable e) {
				exceptions.add(e);
			}
",non-flaky,5
19492,eclipse_xtext-core,Bug367679Test.testValidatorExists_0,"	@Test 
	public void testValidatorExists_0() {
		assertValidatorExists();
	}
",non-flaky,5
19493,eclipse_xtext-core,Bug367679Test.testValidatorExists_1,"	@Test 
	public void testValidatorExists_1() {
		assertValidatorExists();
	}
",non-flaky,5
19494,eclipse_xtext-core,JavaIoFileSystemAccessTest.testDirsAndFilesAreCreated,"	@Test
	public void testDirsAndFilesAreCreated() throws Exception {
		File dir = null;
		File textFile = null;
		File binFile = null;
		try {
			JavaIoFileSystemAccess fileSystemAccess = new JavaIoFileSystemAccess(
					IResourceServiceProvider.Registry.INSTANCE, new IEncodingProvider.Runtime());

			File tmpDir = configureFileSystemAccess(fileSystemAccess);
			fileSystemAccess.generateFile(""tmp/X"", ""XX"");
			fileSystemAccess.generateFile(""tmp/Y"", new StringInputStream(""\1\2\3""));

			dir = new File(tmpDir, ""tmp"");
			assertTrue(dir.exists());
			assertTrue(dir.isDirectory());

			textFile = new File(dir, ""X"");
			assertTrue(textFile.exists());
			assertTrue(textFile.isFile());
			assertEquals(""XX"", fileSystemAccess.readTextFile(""tmp/X""));

			binFile = new File(dir, ""Y"");
			assertTrue(binFile.exists());
			assertFalse(fileSystemAccess.isFile(""tmp"", IFileSystemAccess.DEFAULT_OUTPUT)); // isFile evaluates to false for directories
			assertTrue(fileSystemAccess.isFile(""tmp/Y"", IFileSystemAccess.DEFAULT_OUTPUT));
			assertTrue(binFile.isFile());
			InputStream stream = fileSystemAccess.readBinaryFile(""tmp/Y"");
			try {
				assertEquals(""\1\2\3"", new String(ByteStreams.toByteArray(stream)));
			} finally {
				stream.close();
			}

		} finally {
			try {
				if (textFile != null)
					textFile.delete();
			} finally {
				try {
					if (binFile != null)
						binFile.delete();
				} finally {
					if (dir != null)
						dir.delete();
				}
			}
		}
	}
",non-flaky,5
19495,eclipse_xtext-core,JavaIoFileSystemAccessTest.testURI,"	@Test
	public void testURI() throws Exception {
		JavaIoFileSystemAccess fileSystemAccess = new JavaIoFileSystemAccess();
		fileSystemAccess.setOutputPath(""testOutput"", ""/testDir"");
		URI uri = fileSystemAccess.getURI(""testFile"", ""testOutput"");
		String expectedUri = new File(new File(File.separator + ""testDir""), ""testFile"").toURI().toString();
		assertEquals(expectedUri, uri.toString());
	}
",non-flaky,5
19496,eclipse_xtext-core,JavaIoFileSystemAccessTest.getEncoding,"	@Test
	public void testEncoding() throws Exception {
		File file = null;
		FileInputStream fileInputStream = null;
		try {
			JavaIoFileSystemAccess fileSystemAccess = new JavaIoFileSystemAccess(
					IResourceServiceProvider.Registry.INSTANCE, new IEncodingProvider() {
						@Override
						public String getEncoding(URI uri) {
							return ""ISO-8859-1"";
						}
",non-flaky,5
19497,eclipse_xtext-core,JavaIoFileSystemAccessTest.testTraceIsCreated,"	@Test
	public void testTraceIsCreated() throws Exception {
		File file = null;
		try {

			JavaIoFileSystemAccess fileSystemAccess = new JavaIoFileSystemAccess(
					IResourceServiceProvider.Registry.INSTANCE, new IEncodingProvider.Runtime(),
					new TraceFileNameProvider(), new TraceRegionSerializer());

			File tmpDir = configureFileSystemAccess(fileSystemAccess);
			SourceRelativeURI uri = new SourceRelativeURI(URI.createURI(""foo/bar""));
			CharSequenceTraceWrapper wrapper = new CharSequenceTraceWrapper();
			fileSystemAccess.generateFile(""tmp/X"", wrapper.wrapWithTraceData(""XX"", uri, 0, 10, 0, 1));

			file = new File(tmpDir, ""tmp/X"");
			assertTrue(file.exists());
			assertTrue(file.isFile());
			assertEquals(""XX"", fileSystemAccess.readTextFile(""tmp/X""));

			file = new File(tmpDir, ""tmp/.X._trace"");
			assertTrue(file.exists());
			assertTrue(file.isFile());

		} finally {
			if (file != null)
				file.delete();
		}
	}
",non-flaky,5
19498,eclipse_xtext-core,TraceRegionTest.testConstructor,"	@Test
	public void testConstructor() {
		TraceRegion region = new TraceRegion(0, 1, 0, 0, true, 2, 3, 0, 0, null, newURI());
		assertEquals(0, region.getMyOffset());
		assertEquals(1, region.getMyLength());
		assertEquals(2, region.getMergedAssociatedLocation().getOffset());
		assertEquals(3, region.getMergedAssociatedLocation().getLength());
		assertEquals(newURI(), region.getAssociatedSrcRelativePath());
		assertNull(region.getParent());
		assertTrue(region.getNestedRegions().isEmpty());
	}
",non-flaky,5
19499,eclipse_xtext-core,TraceRegionTest.testConstructorWithParent,"	@Test
	public void testConstructorWithParent() {
		TraceRegion parent = new TraceRegion(0, 1, 0, 0, true, 2, 3, 0, 0, null, newURI());
		TraceRegion region = new TraceRegion(0, 1, 0, 0, true, 2, 3, 0, 0, parent, null);
		assertEquals(newURI(), region.getAssociatedSrcRelativePath());
		assertEquals(parent, region.getParent());
	}
",non-flaky,5
19500,eclipse_xtext-core,TraceRegionTest.testConstructorInvalidArgs_01,"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_01() {
		new TraceRegion(-1, 0, 0, 0, true, 0, 0, 0, 0, null, newURI());
	}
",non-flaky,5
19501,eclipse_xtext-core,TraceRegionTest.testConstructorInvalidArgs_02,"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_02() {
		new TraceRegion(0, -1, 0, 0, true, 0, 0, 0, 0, null, newURI());
	}
",non-flaky,5
19502,eclipse_xtext-core,TraceRegionTest.testConstructorInvalidArgs_03,"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_03() {
		new TraceRegion(0, 0, -1, 0, true, 0, 0, 0, 0, null, newURI());
	}
",non-flaky,5
19503,eclipse_xtext-core,TraceRegionTest.testConstructorInvalidArgs_04,"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_04() {
		new TraceRegion(0, 0, 0, -1, true, 0, 0, 0, 0, null, newURI());
	}
",non-flaky,5
19504,eclipse_xtext-core,TraceRegionTest.testConstructorInvalidArgs_05,"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_05() {
		new TraceRegion(0, 0, 0, 0, true, 0, 0, 0, 0, null, null);
	}
",non-flaky,5
19505,eclipse_xtext-core,TraceRegionTest.testLeafIterator_NoChildren,"	@Test
	public void testLeafIterator_NoChildren() {
		TraceRegion region = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, null, newURI());
		Iterator<AbstractTraceRegion> iter = region.leafIterator();
		assertEquals(Collections.singleton(region).iterator(), iter);
	}
",non-flaky,5
19506,eclipse_xtext-core,TraceRegionTest.testLeafIterator_OneChild,"	@Test
	public void testLeafIterator_OneChild() {
		TraceRegion parent = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion region = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Collections.singleton(region).iterator(), iter);
	}
",non-flaky,5
19507,eclipse_xtext-core,TraceRegionTest.testLeafIterator_GrandChild,"	@Test
	public void testLeafIterator_GrandChild() {
		TraceRegion root = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion parent = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, root, null);
		TraceRegion region = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Collections.singleton(region).iterator(), iter);
	}
",non-flaky,5
19508,eclipse_xtext-core,TraceRegionTest.testLeafIterator_TwoChildren_NoGaps,"	@Test
	public void testLeafIterator_TwoChildren_NoGaps() {
		TraceRegion parent = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, parent, null);
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19509,eclipse_xtext-core,TraceRegionTest.testLeafIterator_OneChild_LeftGap,"	@Test
	public void testLeafIterator_OneChild_LeftGap() {
		final TraceRegion parent = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		AbstractTraceRegion first = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(0, 1, 0, 1), true, new LocationData(2, 3, 0, 0, null), parent) {};
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19510,eclipse_xtext-core,TraceRegionTest.testLeafIterator_OneChild_RightGap,"	@Test
	public void testLeafIterator_OneChild_RightGap() {
		final TraceRegion parent = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		AbstractTraceRegion first = new TraceRegion(0, 1, 0, 1, true, 3, 4, 0, 0, parent, null);
		AbstractTraceRegion second = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(1, 1, 1, 2), true, new LocationData(2, 3, 0, 0, null), parent) {};
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19511,eclipse_xtext-core,TraceRegionTest.testLeafIterator_OneGrandChild_LeftGap,"	@Test
	public void testLeafIterator_OneGrandChild_LeftGap() {
		final TraceRegion root = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		AbstractTraceRegion first = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(0, 1, 0, 1), true, new LocationData(2, 3, 0, 0, null), root) {};
		TraceRegion parent = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, root, null);
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19512,eclipse_xtext-core,TraceRegionTest.testLeafIterator_OneGrandChild_RightGap,"	@Test
	public void testLeafIterator_OneGrandChild_RightGap() {
		final TraceRegion root = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion parent = new TraceRegion(0, 1, 0, 1, true, 3, 4, 0, 0, root, null);
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 3, 4, 0, 0, parent, null);
		AbstractTraceRegion second = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(1, 1, 1, 2), true, new LocationData(2, 3, 0, 0, null), root) {};
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19513,eclipse_xtext-core,TraceRegionTest.testLeafIterator_TwoGrandChildren_NoGaps_01,"	@Test
	public void testLeafIterator_TwoGrandChildren_NoGaps_01() {
		TraceRegion root = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion parent = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, root, null);
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, parent, null);
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19514,eclipse_xtext-core,TraceRegionTest.testLeafIterator_TwoGrandChildren_NoGaps_02,"	@Test
	public void testLeafIterator_TwoGrandChildren_NoGaps_02() {
		TraceRegion root = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion firstParent = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, root, null);
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, firstParent, null);
		TraceRegion secondParent = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, root, null);
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, secondParent, null);
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
",non-flaky,5
19515,eclipse_xtext-core,TraceRegionTest.testLeafIterator_TwoChildren_WithGaps,"	@Test
	public void testLeafIterator_TwoChildren_WithGaps() {
		final TraceRegion parent = new TraceRegion(0, 3, 0, 3, true, 2, 3, 0, 0, null, newURI());
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, parent, null);
		AbstractTraceRegion second = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(1, 1, 1, 2), true, new LocationData(2, 3, 0, 0, null), parent) {};
		AbstractTraceRegion third = new TraceRegion(2, 1, 2, 3, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Arrays.asList(first, second, third).iterator(), iter);
	}
",non-flaky,5
19516,eclipse_xtext-core,TraceRegionTest.testAnnotate_01,"	@Test
	public void testAnnotate_01() {
		TraceRegion region = new TraceRegion(0, 1, 0, 0, true, 2, 3, 0, 0, null, newURI());
		assertEquals(""<2:3[a]"", region.getAnnotatedString(""a""));
	}
",non-flaky,5
19517,eclipse_xtext-core,TraceRegionTest.testAnnotate_02,"	@Test
	public void testAnnotate_02() {
		TraceRegion region = new TraceRegion(1, 1, 0, 0, true, 2, 3, 0, 0, null, newURI());
		assertEquals(""a<2:3[b]c"", region.getAnnotatedString(""abc""));
	}
",non-flaky,5
19518,eclipse_xtext-core,TraceRegionTest.testAnnotate_03,"	@Test
	public void testAnnotate_03() {
		TraceRegion parent = new TraceRegion(0, 4, 0, 0, true, 1, 2, 0, 0, null, newURI());
		new TraceRegion(0, 1, 0, 0, true, 3, 4, 0, 0, parent, null);
		new TraceRegion(2, 1, 0, 0, true, 5, 6, 0, 0, parent, null);
		new TraceRegion(3, 1, 0, 0, true, 7, 8, 0, 0, parent, null);
		assertEquals(""<1:2[<3:4[a]b<5:6[c]<7:8[d]]e"", parent.getAnnotatedString(""abcde""));
	}
",non-flaky,5
19519,eclipse_xtext-core,TraceRegionTest.testAnnotate_04,"	@Test
	public void testAnnotate_04() {
		TraceRegion root = new TraceRegion(0, 4, 0, 0, true, 1, 2, 0, 0, null, newURI());
		TraceRegion parent = new TraceRegion(1, 2, 0, 0, true, 3, 4, 0, 0, root, null);
		new TraceRegion(2, 1, 0, 0, true, 5, 6, 0, 0, parent, null);
		assertEquals(""<1:2[a<3:4[b<5:6[c]]d]e"", root.getAnnotatedString(""abcde""));
	}
",non-flaky,5
38191,palantir_atlasdb,SchemasTest.testGetFullTableName,"    @Test
    public void testGetFullTableName() {
        MatcherAssert.assertThat(
                Schemas.getFullTableName(TABLE_NAME, NAMESPACE),
                Matchers.equalTo(NAMESPACE.getName() + ""."" + TABLE_NAME));
    }
",non-flaky,5
38192,palantir_atlasdb,SchemasTest.testGetFullTableNameLegacy,"    @Test
    public void testGetFullTableNameLegacy() {
        MatcherAssert.assertThat(
                Schemas.getFullTableName(TABLE_NAME, Namespace.create(""met"")),
                Matchers.equalTo(TABLE_NAME)
        );
    }
",non-flaky,5
38193,palantir_atlasdb,SchemasTest.testGetFullTableNameEmptyNamespace,"    @Test
    public void testGetFullTableNameEmptyNamespace() {
        MatcherAssert.assertThat(
                Schemas.getFullTableName(TABLE_NAME, Namespace.EMPTY_NAMESPACE),
                Matchers.equalTo(TABLE_NAME)
        );
    }
",non-flaky,5
38194,palantir_atlasdb,SchemasTest.testCreateTable,"    @Test
    public void testCreateTable() {
        mockery.checking(new Expectations(){{
            oneOf(kvs).createTables(with(tableMapContainsEntry(TABLE_REF, getSimpleTableDefinitionAsBytes(TABLE_REF))));
        }});
        Schemas.createTable(kvs, TABLE_REF, getSimpleTableDefinition(TABLE_REF));
    }
",non-flaky,5
38195,palantir_atlasdb,SchemasTest.testCreateTables,"    @Test
    public void testCreateTables() {
        TableReference tableName1 = TableReference.createWithEmptyNamespace(TABLE_NAME + ""1"");
        TableReference tableName2 = TableReference.createWithEmptyNamespace(TABLE_NAME + ""2"");
        mockery.checking(new Expectations(){{
            oneOf(kvs).createTables(with(tableMapContainsEntry(tableName1, getSimpleTableDefinitionAsBytes(tableName1))));
            oneOf(kvs).createTables(with(tableMapContainsEntry(tableName2, getSimpleTableDefinitionAsBytes(tableName2))));
        }});
        Map<TableReference, TableDefinition> tables = Maps.newHashMap();
        tables.put(tableName1, getSimpleTableDefinition(tableName1));
        tables.put(tableName2, getSimpleTableDefinition(tableName2));
        Schemas.createTables(kvs, tables);
    }
",non-flaky,5
38196,palantir_atlasdb,SchemasTest.testDeleteTable,"    @Test
    public void testDeleteTable() {
        mockery.checking(new Expectations(){{
            oneOf(kvs).dropTable(with(equal(TABLE_REF)));
        }});
        Schemas.deleteTable(kvs, TABLE_REF);
    }
",non-flaky,5
38197,palantir_atlasdb,SchemasTest.testDeleteTablesForSweepSchema,"    @Test
    public void testDeleteTablesForSweepSchema() {
        Set<TableReference> allTableNames = Sets.newHashSet();
        allTableNames.add(TableReference.createFromFullyQualifiedName(""sweep.progress""));
        allTableNames.add(TableReference.createFromFullyQualifiedName(""sweep.priority""));

        mockery.checking(new Expectations(){{
            oneOf(kvs).getAllTableNames(); will(returnValue(allTableNames));
            oneOf(kvs).dropTables(allTableNames);
            oneOf(kvs).getAllTableNames();
        }});
        Schemas.deleteTablesAndIndexes(SweepSchema.INSTANCE.getLatestSchema(), kvs);
    }
",non-flaky,5
38198,palantir_atlasdb,RocksDbKeyValuePerfTest.testWritePerf,"    @Test
    public void testWritePerf() throws ExecutionException, InterruptedException {
        final long startTime = System.currentTimeMillis();
        final Future<Pair<Long, Set<byte[]>>>
            f1 = submitWriteJob(0, BATCH_SIZE / 4),
            f2 = submitWriteJob(BATCH_SIZE / 4, BATCH_SIZE / 2),
            f3 = submitWriteJob(BATCH_SIZE / 2, 3 * BATCH_SIZE / 4),
            f4 = submitWriteJob(3 * BATCH_SIZE / 4, BATCH_SIZE);
        final long rawBytes = f1.get().lhSide
                              + f2.get().lhSide
                              + f3.get().lhSide
                              + f4.get().lhSide;
        final long elapsedTime = System.currentTimeMillis() - startTime;
        final double elapsedSeconds = elapsedTime / 1000.0;
        final double megs = rawBytes / (1024.0 * 1024.0);
        System.out.println(""MB = "" + megs);
        System.out.println(""MB/s = "" + (megs/elapsedSeconds));
    }
",non-flaky,5
38199,palantir_atlasdb,RocksDbKeyValueServiceTest.testCreate,"    @Test
    public void testCreate() {
        TableReference otherTable = TableReference.createWithEmptyNamespace(""yodog"");
        db.createTable(TABLE, AtlasDbConstants.EMPTY_TABLE_METADATA);
        db.createTable(otherTable, AtlasDbConstants.EMPTY_TABLE_METADATA);
        db.createTable(TRANSACTION_TABLE, AtlasDbConstants.EMPTY_TABLE_METADATA);
        assertEquals(ImmutableSet.of(TABLE, otherTable, TRANSACTION_TABLE),
                db.getAllTableNames());
    }
",non-flaky,5
38200,palantir_atlasdb,RocksDbKeyValueServiceTest.testReadNoExist,"    @Test
    public void testReadNoExist() {
        final Cell cell = Cell.create(""r1"".getBytes(), COMMIT_TS_COLUMN);
        final Map<Cell, Value> res = db.get(TABLE, ImmutableMap.of(cell, 1L));
        assertTrue(res.isEmpty());
    }
",non-flaky,5
38201,palantir_atlasdb,RocksDbKeyValueServiceTest.testReadGood,"    @Test
    public void testReadGood() {
        final Cell cell = Cell.create(""r1"".getBytes(), ""2"".getBytes());
        db.put(TABLE, ImmutableMap.of(cell, ""v1"".getBytes()), 1);
        final Map<Cell, Value> res = db.get(TABLE, ImmutableMap.of(cell, 2L));
        assertEquals(1, res.size());
        final Value value = res.get(cell);
        assertEquals(1, value.getTimestamp());
        assertEquals(""v1"", new String(value.getContents()));
    }
",non-flaky,5
38202,palantir_atlasdb,RocksDbKeyValueServiceTest.testReadGood2,"    @Test
    public void testReadGood2() {
        final Cell cell = Cell.create(""r1"".getBytes(), ""2"".getBytes());
        final Cell cell2 = Cell.create(""r"".getBytes(), ""12"".getBytes());
        db.put(TABLE, ImmutableMap.of(cell, ""v1"".getBytes()), 1000);
        db.put(TABLE, ImmutableMap.of(cell2, ""v2"".getBytes()), 1000);
        final Map<Cell, Value> res = db.get(TABLE, ImmutableMap.of(cell, 1001L));
        final Value value = res.get(cell);
        assertEquals(1000, value.getTimestamp());
        assertEquals(""v1"", new String(value.getContents()));
    }
",non-flaky,5
38203,palantir_atlasdb,RocksDbKeyValueServiceTest.testReadGood3,"    @Test
    public void testReadGood3() {
        final Cell cell = Cell.create(""r1"".getBytes(), COMMIT_TS_COLUMN);
        db.put(TABLE, ImmutableMap.of(cell, ""v1"".getBytes()), Long.MAX_VALUE - 3);
        final Map<Cell, Value> res = db.get(TABLE, ImmutableMap.of(cell, Long.MAX_VALUE - 2));
        final Value value = res.get(cell);
        assertEquals(Long.MAX_VALUE - 3, value.getTimestamp());
        assertEquals(""v1"", new String(value.getContents()));
    }
",non-flaky,5
38204,palantir_atlasdb,RocksDbKeyValueServiceTest.testReadGood4,"    @Test
    public void testReadGood4() {
        final Cell cell = Cell.create(""r,1"".getBytes(), "",c,1,"".getBytes());
        db.put(TABLE, ImmutableMap.of(cell, ""v,1"".getBytes()), 1);
        final Map<Cell, Value> res = db.get(TABLE, ImmutableMap.of(cell, 2L));
        final Value value = res.get(cell);
        assertEquals(1, value.getTimestamp());
        assertEquals(""v,1"", new String(value.getContents()));
    }
",non-flaky,5
38205,palantir_atlasdb,RocksDbKeyValueServiceTest.testReadBeforeTime,"    @Test
    public void testReadBeforeTime() {
        final Cell cell = Cell.create(""r1"".getBytes(), COMMIT_TS_COLUMN);
        db.put(TABLE, ImmutableMap.of(cell, ""v1"".getBytes()), 2);
        final Map<Cell, Value> res = db.get(TABLE, ImmutableMap.of(cell, 2L));
        assertTrue(res.isEmpty());
    }
",non-flaky,5
38206,palantir_atlasdb,RocksDbKeyValueServiceTest.testGetRow,"    @Test
    public void testGetRow() {
        final Cell cell = Cell.create(""r1"".getBytes(), ""c1"".getBytes());
        final Cell cell2 = Cell.create(""r1"".getBytes(), ""c2"".getBytes());
        db.put(TABLE, ImmutableMap.of(cell, ""v1"".getBytes()), 2);
        db.put(TABLE, ImmutableMap.of(cell2, ""v2"".getBytes()), 2);
        final Map<Cell, Value> rows = db.getRows(TABLE, ImmutableList.of(""r1"".getBytes()), ColumnSelection.all(), 3);
        assertEquals(2, rows.size());
    }
",non-flaky,5
38207,palantir_atlasdb,RocksDbKeyValueServiceTest.testGetRange,"    @Test
    public void testGetRange() {
        final Cell cell = Cell.create(""r1"".getBytes(), ""c1"".getBytes());
        final Cell cell2 = Cell.create(""r1"".getBytes(), ""c2"".getBytes());
        final Cell cell3 = Cell.create(""r2"".getBytes(), ""c2"".getBytes());
        db.put(TABLE, ImmutableMap.of(cell, ""v1"".getBytes()), 2);
        db.put(TABLE, ImmutableMap.of(cell2, ""v2"".getBytes()), 2);
        db.put(TABLE, ImmutableMap.of(cell3, ""v3"".getBytes()), 4);
        final RangeRequest range = RangeRequest.builder().endRowExclusive(""r2"".getBytes()).build();
        final ClosableIterator<? extends RowResult<Value>> it = db.getRange(TABLE, range, 10);
        try {
            final List<RowResult<Value>> list = Lists.newArrayList();
            Iterators.addAll(list, it);
            assertEquals(1, list.size());
            final Map<Cell, Value> rows = db.getRows(TABLE, ImmutableList.of(""r1"".getBytes()), ColumnSelection.all(), 3);
            assertEquals(2, rows.size());
            final RowResult<Value> row = list.iterator().next();
            final Map<Cell, Value> cellsFromRow = putAll(Maps.<Cell, Value>newHashMap(), row.getCells());
            assertEquals(rows, cellsFromRow);
        } finally {
            it.close();
        }
    }
",non-flaky,5
38208,palantir_atlasdb,RocksDbKeyValueServiceTest.testGetRange2,"    @Test
    public void testGetRange2() {
        final Cell cell = Cell.create("",r,1"".getBytes(), "",c,1,"".getBytes());
        db.put(TABLE, ImmutableMap.of(cell, ""v1"".getBytes()), 2);
        final RangeRequest range = RangeRequest.builder().build();
        final ClosableIterator<RowResult<Value>> it = db.getRange(TABLE, range, 10);
        try {
            final List<RowResult<Value>> list = Lists.newArrayList();
            Iterators.addAll(list, it);
            assertEquals(1, list.size());
            final RowResult<Value> row = list.iterator().next();
            final Map<Cell, Value> cellsFromRow = putAll(Maps.<Cell, Value>newHashMap(), row.getCells());
            final Map<Cell, Value> rows = db.getRows(TABLE, ImmutableList.of("",r,1"".getBytes()), ColumnSelection.all(), 3);
            assertEquals(rows, cellsFromRow);
        } finally {
            it.close();
        }
    }
",non-flaky,5
38209,palantir_atlasdb,RocksDbKeyValueServiceTest.testGetRowCellOverlap,"    @Test
    public void testGetRowCellOverlap() {
        final Cell cell = Cell.create(""12"".getBytes(), ""34"".getBytes());
        final Cell cell2 = Cell.create(""1"".getBytes(), ""23"".getBytes());
        db.put(TABLE, ImmutableMap.of(cell, ""v1"".getBytes()), 2);
        db.put(TABLE, ImmutableMap.of(cell2, ""v2"".getBytes()), 2);
        final Map<Cell, Value> rows = db.getRows(TABLE, ImmutableList.of(""12"".getBytes()), ColumnSelection.all(), 3);
        assertEquals(1, rows.size());
    }
",non-flaky,5
38210,palantir_atlasdb,RocksDbKeyValueServiceTest.testGetRangeCellOverlap,"    @Test
    public void testGetRangeCellOverlap() {
        final Cell cell = Cell.create(""12"".getBytes(), ""34"".getBytes());
        final Cell cell2 = Cell.create(""1"".getBytes(), ""235"".getBytes());
        db.put(TABLE, ImmutableMap.of(cell, ""v1"".getBytes()), 2);
        db.put(TABLE, ImmutableMap.of(cell2, ""v2"".getBytes()), 2);
        ClosableIterator<? extends RowResult<Value>> it = db.getRange(TABLE, RangeRequest.builder().build(), 3);
        try {
            assertEquals(2, Iterators.size(it));
        } finally {
            it.close();
        }
        it = db.getRange(TABLE, RangeRequest.builder().endRowExclusive(""12"".getBytes()).build(), 3);
        try {
            assertEquals(1, Iterators.size(it));
        } finally {
            it.close();
        }
        it = db.getRange(TABLE, RangeRequest.builder().startRowInclusive(""12"".getBytes()).build(), 3);
        try {
            assertEquals(1, Iterators.size(it));
        } finally {
            it.close();
        }
    }
",non-flaky,5
38211,palantir_atlasdb,RocksDbKeyValueServiceTest.testGetRangeCellOverlap2,"    @Test
    public void testGetRangeCellOverlap2() {
        final Cell cell = Cell.create(""1"".getBytes(), ""1"".getBytes());
        final Cell cell2 = Cell.create(""12"".getBytes(), ""0"".getBytes());
        final Cell cell3 = Cell.create(""1"".getBytes(), ""3"".getBytes());
        db.put(TABLE, ImmutableMap.of(cell, ""v1"".getBytes()), 2);
        db.put(TABLE, ImmutableMap.of(cell2, ""v2"".getBytes()), 2);
        db.put(TABLE, ImmutableMap.of(cell3, ""v3"".getBytes()), 2);
        final ClosableIterator<? extends RowResult<Value>> it = db.getRange(TABLE, RangeRequest.builder().build(), 3);
        try {
            assertEquals(2, Iterators.size(it));
        } finally {
            it.close();
        }
    }
",non-flaky,5
38212,palantir_atlasdb,RocksDbKeyValueServiceTest.testDoubleWriteToTransactionTable,"    @Test
    public void testDoubleWriteToTransactionTable() {
        db.createTable(TRANSACTION_TABLE, AtlasDbConstants.EMPTY_TABLE_METADATA);
        final Cell cell = Cell.create(""r1"".getBytes(), COMMIT_TS_COLUMN);
        db.putUnlessExists(TRANSACTION_TABLE, ImmutableMap.of(cell, ""v1"".getBytes()));
        try {
            db.putUnlessExists(TRANSACTION_TABLE, ImmutableMap.of(cell, ""v2"".getBytes()));
            fail();
        } catch (KeyAlreadyExistsException e) {
            // expected
        }
        final Map<Cell, Value> res = db.get(TRANSACTION_TABLE, ImmutableMap.of(cell, 1L));
        final Value value = res.get(cell);
        assertEquals(0L, value.getTimestamp());
        assertEquals(""v1"", new String(value.getContents()));
    }
",non-flaky,5
38213,palantir_atlasdb,RocksDbKeyValueServiceTest.testMetadata,"    @Test
    public void testMetadata() {
        db.putMetadataForTable(TABLE, ""yoyo"".getBytes());
        final byte[] meta = db.getMetadataForTable(TABLE);
        assertEquals(""yoyo"", new String(meta));
    }
",non-flaky,5
38214,palantir_atlasdb,RocksDbKeyValueServiceTest.testCreateTables,"    @Test
    public void testCreateTables() {
        db.putMetadataForTable(TABLE, ""yoyo"".getBytes());
        final byte[] meta = db.getMetadataForTable(TABLE);
        assertEquals(""yoyo"", new String(meta));
    }
",non-flaky,5
38215,palantir_atlasdb,RocksDbKeyValueServiceTest.testLockFile,"    @Test
    public void testLockFile() {
        try {
            RocksDbKeyValueService db2 = RocksDbKeyValueService.create(""testdb""); // tempted to make IBM DB2 joke
            assertTrue(""RocksDBKVS should protect against concurrent instances with a lock"", false);
        } catch (RuntimeException e) {
            assertTrue(""Unknown exception type thrown; expected IOException when two RocksDBs are pointed at same directory"", e.getCause() instanceof IOException);
        }
    }
",non-flaky,5
38216,palantir_atlasdb,TextUtilsTest.testProperCaseWord,"    @Test
    public void testProperCaseWord() throws Exception {
        String[] words = new String[] { ""AA102"", ""nw"", ""dog"", ""daVID CHiu"", ""yu-gi-oh rules"" };
        String[] results = new String[] { ""AA102"", ""Nw"", ""Dog"", ""David chiu"", ""Yu-gi-oh rules"" };
        for (int i=0; i < words.length; i++) {
            String result = TextUtils.properCaseWord(words[i]);
            assertEquals(results[i], result);
        }
    }
",non-flaky,5
38217,palantir_atlasdb,TextUtilsTest.testProperCaseWords,"    @Test
    public void testProperCaseWords() throws Exception {
        String[] words = new String[] { ""AA102"", ""nw"", ""dog"", ""daVID CHiu"", ""yu-gi-oh rules"",
                ""b.j. penn the great,shawn sherk""};
        String[] results = new String[] { ""AA102"", ""Nw"", ""Dog"", ""David Chiu"", ""Yu-Gi-Oh Rules"",
                ""B.J. Penn The Great,Shawn Sherk""};
        for (int i=0; i < words.length; i++) {
            String result = TextUtils.properCaseWords(words[i]);
            assertEquals(results[i], result);
        }
    }
",non-flaky,5
38218,palantir_atlasdb,TextUtilsTest.testPluralization,"    @Test
    public void testPluralization() throws Exception {
        assertEquals("""", TextUtils.pluralize(null));
        assertEquals("""", TextUtils.pluralize(""""));
        assertEquals(""dogs"", TextUtils.pluralize(""dog""));
        assertEquals(""keywords"", TextUtils.pluralize(""keywords""));
    }
",non-flaky,5
38219,palantir_atlasdb,TextUtilsTest.testStringForValue,"    @Test
    public void testStringForValue() throws Exception {
        assertEquals(""0"", TextUtils.getStringForValue(0.0));
        assertEquals(""5"", TextUtils.getStringForValue(5.0));
        assertEquals(""100"", TextUtils.getStringForValue(100.0));
        assertEquals(""9.2k"", TextUtils.getStringForValue(9204.0));
        assertEquals(""9.5k"", TextUtils.getStringForValue(9499.0));
        assertEquals(""10.0k"", TextUtils.getStringForValue(9999.0));
        assertEquals(""100k"", TextUtils.getStringForValue(99999.0));
        assertEquals(""100k"", TextUtils.getStringForValue(100000.0));
        assertEquals(""1.0M"", TextUtils.getStringForValue(1000000.0));
        assertEquals(""1.5M"", TextUtils.getStringForValue(1499999.0));
        assertEquals(""10M"", TextUtils.getStringForValue(10000000.0));
        assertEquals(""15M"", TextUtils.getStringForValue(14999999.0));
        assertEquals(""100M"", TextUtils.getStringForValue(100000000.0));
        assertEquals(""150M"", TextUtils.getStringForValue(149999990.0));
        assertEquals(""1.0B"", TextUtils.getStringForValue(1000000000.0));
        assertEquals(""1.5B"", TextUtils.getStringForValue(1499999900.0));
        assertEquals(""10B"", TextUtils.getStringForValue(10000000000.0));
        assertEquals(""15B"", TextUtils.getStringForValue(14999999000.0));
        assertEquals(""100B"", TextUtils.getStringForValue(100000000000.0));
        assertEquals(""150B"", TextUtils.getStringForValue(149999990000.0));
        assertEquals(""1.0T"", TextUtils.getStringForValue(1000000000000.0));
        assertEquals(""1.5T"", TextUtils.getStringForValue(1499999900000.0));
        assertEquals(""10T"", TextUtils.getStringForValue(10000000000000.0));
        assertEquals(""15T"", TextUtils.getStringForValue(14999999000000.0));
        assertEquals(""100T"", TextUtils.getStringForValue(100000000000000.0));
        assertEquals(""150T"", TextUtils.getStringForValue(149999990000000.0));
        assertEquals(""1.0e+15"", TextUtils.getStringForValue(1000000000000000.0));
        assertEquals(""1.5e+15"", TextUtils.getStringForValue(1499999900000000.0));

        assertEquals(""-5"", TextUtils.getStringForValue(-5.0));
        assertEquals(""-100"", TextUtils.getStringForValue(-100.0));
        assertEquals(""-9.2k"", TextUtils.getStringForValue(-9204.0));
        assertEquals(""-9.5k"", TextUtils.getStringForValue(-9499.0));
        assertEquals(""-10.0k"", TextUtils.getStringForValue(-9999.0));
        assertEquals(""-100k"", TextUtils.getStringForValue(-99999.0));
        assertEquals(""-100k"", TextUtils.getStringForValue(-100000.0));
        assertEquals(""-1.0M"", TextUtils.getStringForValue(-1000000.0));
        assertEquals(""-1.5M"", TextUtils.getStringForValue(-1499999.0));
        assertEquals(""-10M"", TextUtils.getStringForValue(-10000000.0));
        assertEquals(""-15M"", TextUtils.getStringForValue(-14999999.0));
        assertEquals(""-100M"", TextUtils.getStringForValue(-100000000.0));
        assertEquals(""-150M"", TextUtils.getStringForValue(-149999990.0));
        assertEquals(""-1.0B"", TextUtils.getStringForValue(-1000000000.0));
        assertEquals(""-1.5B"", TextUtils.getStringForValue(-1499999900.0));
        assertEquals(""-1.5B"", TextUtils.getStringForValue(-1500000001.0));
        assertEquals(""-10B"", TextUtils.getStringForValue(-10000000000.0));
        assertEquals(""-15B"", TextUtils.getStringForValue(-14999999000.0));
        assertEquals(""-100B"", TextUtils.getStringForValue(-100000000000.0));
        assertEquals(""-150B"", TextUtils.getStringForValue(-149999990000.0));
        assertEquals(""-1.0T"", TextUtils.getStringForValue(-1000000000000.0));
        assertEquals(""-1.5T"", TextUtils.getStringForValue(-1499999900000.0));
        assertEquals(""-10T"", TextUtils.getStringForValue(-10000000000000.0));
        assertEquals(""-15T"", TextUtils.getStringForValue(-14999999000000.0));
        assertEquals(""-100T"", TextUtils.getStringForValue(-100000000000000.0));
        assertEquals(""-150T"", TextUtils.getStringForValue(-149999990000000.0));
        assertEquals(""-1.0e+15"", TextUtils.getStringForValue(-1000000000000000.0));
        assertEquals(""-1.5e+15"", TextUtils.getStringForValue(-1499999900000000.0));
    }
",non-flaky,5
38220,palantir_atlasdb,TextUtilsTest.testRemoveAllWhitespace,"    @Test
    public void testRemoveAllWhitespace() {
        String before = ""  \r\n\n\r  \t FOOOooo\r\n\n\n\r\t\r o   \n"";
        String after = TextUtils.removeAllWhitespace(before);
        assertEquals(""FOOOoooo"", after);
    }
",non-flaky,5
38221,palantir_atlasdb,TextUtilsTest.testTruncateStringToCharLength,"    @Test
    public void testTruncateStringToCharLength() {
        String string = ""abcde"";
        assertEquals(string, TextUtils.truncateStringToCharLength(string, 5, ""...""));
        assertEquals(string, TextUtils.truncateStringToCharLength(string, 5, """"));
        assertEquals(string, TextUtils.truncateStringToCharLength(string, 6, ""...""));
        assertEquals(string, TextUtils.truncateStringToCharLength(string, 6, """"));
        assertEquals(""a..."", TextUtils.truncateStringToCharLength(string, 4, ""...""));
        assertEquals(""abcd"", TextUtils.truncateStringToCharLength(string, 4, """"));
    }
",non-flaky,5
38222,palantir_atlasdb,TextUtilsTest.testTruncateLabelString,"    @Test
    public void testTruncateLabelString() {
        // TODO(nackner): Add in more tests with UTF-8 characters, but they won't play nice with the
        // build or people's Eclipse clients even if commented out.
        String string = ""abcde"";
        assertEquals(string, TextUtils.truncateLabelString(string, 5));
        assertEquals(string, TextUtils.truncateLabelString(string, 6, ""...""));
        assertEquals(""a..."", TextUtils.truncateLabelString(string, 4, ""...""));
    }
",non-flaky,5
38223,palantir_atlasdb,TextUtilsTest.testPropertiesToXML,"    @Test
    public void testPropertiesToXML()
    {
        // simple string kv pair
        Properties p = new Properties();
        p.setProperty(""MY_CONFIG_KEY"", ""MY_CONFIG_VALUE"");
        String propertiesAsXML = TextUtils.storePropertiesToXMLString(p);
        assertNotNull(propertiesAsXML);
        p = TextUtils.loadPropertiesFromXMLString(propertiesAsXML);
        assertNotNull(p.getProperty(""MY_CONFIG_KEY""));
        assertEquals(""MY_CONFIG_VALUE"", p.getProperty(""MY_CONFIG_KEY""));

        // embedded config
        Properties pComplex = new Properties();
        pComplex.setProperty(""MY_SUB_CONFIG"", TextUtils.storePropertiesToXMLString(p));
        propertiesAsXML = TextUtils.storePropertiesToXMLString(pComplex);
        assertNotNull(propertiesAsXML);
        pComplex = TextUtils.loadPropertiesFromXMLString(propertiesAsXML);
        p = TextUtils.loadPropertiesFromXMLString(pComplex.getProperty(""MY_SUB_CONFIG""));
        assertNotNull(p.getProperty(""MY_CONFIG_KEY""));
        assertEquals(""MY_CONFIG_VALUE"", p.getProperty(""MY_CONFIG_KEY""));
    }
",non-flaky,5
38224,palantir_atlasdb,TextUtilsTest.testMaximalPrefix,"    @Test
    public void testMaximalPrefix() throws Exception{
        ArrayList<String> list1 = new ArrayList<String>(7);
        list1.add(""abcdef"");
        list1.add(""abcdefg"");
        list1.add(""abcdefgh"");
        list1.add(""abcd"");
        list1.add(""abcdefl58a"");
        list1.add(""abcdeeeeee"");
        list1.add(""abcde888"");
        assertEquals(""Wrong maximal prefix"",""abcd"",TextUtils.findMaximalPrefix(list1));

        list1.clear();
        assertEquals(""Should be empty string"","""",TextUtils.findMaximalPrefix(list1));
        assertEquals(""Should be empty string"","""",TextUtils.findMaximalPrefix(null));

        list1.add(""abcd"");
        assertEquals(""Should be abcd"",""abcd"",TextUtils.findMaximalPrefix(list1));
        list1.add(""efgh"");
        list1.add(""ifht"");

        assertEquals(""Should be empty string"","""",TextUtils.findMaximalPrefix(list1));
    }
",non-flaky,5
38225,palantir_atlasdb,TextUtilsTest.testHexConverter,"    @Test
    public void testHexConverter(){
        byte[] bytes = new byte[]{(byte)255, (byte)255, 0, 0};
        System.out.println(Arrays.toString(bytes) +"" -> 0x"" + TextUtils.byteArrayToHexString(bytes));
        assertEquals(""ffff0000"", TextUtils.byteArrayToHexString(bytes));
    }
",non-flaky,5
38226,palantir_atlasdb,TextUtilsTest.testParseDate,"    @Test
    public void testParseDate()
    {
        helperTestParseDate(new Date());
    }
",non-flaky,5
38227,palantir_atlasdb,TextUtilsTest.testParseDateFeb29,"    @Test
    public void testParseDateFeb29() {
        helperTestParseDate(new Date(2012 - 1900, 1, 29));
    }
",non-flaky,5
38228,palantir_atlasdb,TextUtilsTest.testcleanUTF8String,"    @Test
    public void testcleanUTF8String() throws Exception {
        String cleanString = ""Hello World"";
        String dirtyString = ""Hello\u0007World"";

        String cleanedString = TextUtils.cleanUTF8String(dirtyString);
        assertEquals(cleanString, cleanedString);
        assertEquals(cleanString, TextUtils.cleanUTF8String(cleanString));
    }
",non-flaky,5
38229,palantir_atlasdb,TextUtilsTest.testHashString,"    @Test
    public void testHashString() throws Exception {
        String testStr = null;
        long hash = TextUtils.hashString(testStr);
        assertEquals(0, hash);

        testStr = ""Allen cheats at Race for the Galaxy."";
        hash = TextUtils.hashString(testStr);
        assertEquals(1133932183, hash);
    }
",non-flaky,5
38230,palantir_atlasdb,TextUtilsTest.testEncodeDecodeStringUTF8,"    @Test
    public void testEncodeDecodeStringUTF8() throws Exception {
        String str = ""THIS IS A \u1234 TEST STRING"";
        byte[] bytes = TextUtils.convertStringToBytesUtf8(str);
        assertTrue(Arrays.equals(str.getBytes(""UTF-8""), bytes));
        assertEquals(str, TextUtils.convertBytesToStringUtf8(bytes));
    }
",non-flaky,5
38231,palantir_atlasdb,TextUtilsTest.testEscapeHtmlBasic,"    @Test
    public void testEscapeHtmlBasic() {
        String input1 = ""\""A\"" \""b\""; 1 < 2 && 3 > 2"";
        String output1 = ""&quot;A&quot; &quot;b&quot;; 1 &lt; 2 &amp;&amp; 3 &gt; 2"";
        assertTrue(output1.equals(TextUtils.escapeHtml(input1)));
    }
",non-flaky,5
38232,palantir_atlasdb,TextUtilsTest.testEscapeHtmlWhitespaceHandling,"    @Test
    public void testEscapeHtmlWhitespaceHandling() {
        String input2 = ""a b  c   d    e"";
        String output2 = ""a b &nbsp;c &nbsp; d &nbsp; &nbsp;e"";
        assertTrue(output2.equals(TextUtils.escapeHtml(input2)));

        String input3 = ""line 1\nline 2 \n\n line4"";
        String output3f = ""line 1<br/>line 2 <br/><br/> line4"";
        String output3t = ""line 1line 2  line4"";
        assertTrue(output3f.equals(TextUtils.escapeHtml(input3, false)));
        assertTrue(output3t.equals(TextUtils.escapeHtml(input3, true)));
    }
",non-flaky,5
38233,palantir_atlasdb,TextUtilsTest.testEscapeHtmlTwoByteUnicode,"    @Test
    public void testEscapeHtmlTwoByteUnicode() {
        assertTrue(""&#192;"".equals(TextUtils.escapeHtml(u00C0)));
        assertTrue(""&#256;"".equals(TextUtils.escapeHtml(u0100)));
        assertTrue(""&#288;"".equals(TextUtils.escapeHtml(u0120)));
    }
",non-flaky,5
38234,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRowColumnSelection,"    @Test
    public void testGetRowColumnSelection() {
        Cell cell1 = Cell.create(PtBytes.toBytes(""row""), PtBytes.toBytes(""col1""));
        Cell cell2 = Cell.create(PtBytes.toBytes(""row""), PtBytes.toBytes(""col2""));
        Cell cell3 = Cell.create(PtBytes.toBytes(""row""), PtBytes.toBytes(""col3""));
        byte[] val = PtBytes.toBytes(""val"");

        keyValueService.put(TEST_TABLE, ImmutableMap.of(cell1, val, cell2, val, cell3, val), 0);

        Map<Cell, Value> rows1 = keyValueService.getRows(
                TEST_TABLE,
                ImmutableSet.of(cell1.getRowName()),
                ColumnSelection.all(),
                1);
        Assert.assertEquals(ImmutableSet.of(cell1, cell2, cell3), rows1.keySet());

        Map<Cell, Value> rows2 = keyValueService.getRows(
                TEST_TABLE,
                ImmutableSet.of(cell1.getRowName()),
                ColumnSelection.create(ImmutableList.of(cell1.getColumnName())),
                1);
        assertEquals(ImmutableSet.of(cell1), rows2.keySet());

        Map<Cell, Value> rows3 = keyValueService.getRows(
                TEST_TABLE,
                ImmutableSet.of(cell1.getRowName()),
                ColumnSelection.create(ImmutableList.of(cell1.getColumnName(), cell3.getColumnName())),
                1);
        assertEquals(ImmutableSet.of(cell1, cell3), rows3.keySet());
        Map<Cell, Value> rows4 = keyValueService.getRows(
                TEST_TABLE,
                ImmutableSet.of(cell1.getRowName()),
                ColumnSelection.create(ImmutableList.<byte[]>of()),
                1);

        // This has changed recently - now empty column set means
        // that all columns are selected.
        assertEquals(ImmutableSet.of(cell1, cell2, cell3), rows4.keySet());
    }
",non-flaky,5
38235,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRowsAllColumns,"    @Test
    public void testGetRowsAllColumns() {
        putTestDataForSingleTimestamp();
        Map<Cell, Value> values = keyValueService.getRows(TEST_TABLE,
                                                          Arrays.asList(row1, row2),
                                                          ColumnSelection.all(),
                                                          TEST_TIMESTAMP + 1);
        assertEquals(4, values.size());
        assertEquals(null, values.get(Cell.create(row1, column1)));
        assertArrayEquals(value10, values.get(Cell.create(row1, column0)).getContents());
        assertArrayEquals(value12, values.get(Cell.create(row1, column2)).getContents());
        assertArrayEquals(value21, values.get(Cell.create(row2, column1)).getContents());
        assertArrayEquals(value22, values.get(Cell.create(row2, column2)).getContents());
    }
",non-flaky,5
38236,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRowsWhenMultipleVersions,"    @Test
    public void testGetRowsWhenMultipleVersions() {
        putTestDataForMultipleTimestamps();
        Map<Cell, Value> result = keyValueService.getRows(
                TEST_TABLE,
                ImmutableSet.of(row0),
                ColumnSelection.all(),
                TEST_TIMESTAMP + 1);
        assertEquals(1, result.size());
        assertTrue(result.containsKey(Cell.create(row0, column0)));
        assertTrue(result.containsValue(Value.create(value0_t0, TEST_TIMESTAMP)));

        result = keyValueService.getRows(
                TEST_TABLE,
                ImmutableSet.of(row0),
                ColumnSelection.all(),
                TEST_TIMESTAMP + 2);
        assertEquals(1, result.size());
        assertTrue(result.containsKey(Cell.create(row0, column0)));
        assertTrue(result.containsValue(Value.create(value0_t1, TEST_TIMESTAMP + 1)));
    }
",non-flaky,5
38237,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRowsWhenMultipleVersionsAndColumnsSelected,"    @Test
    public void testGetRowsWhenMultipleVersionsAndColumnsSelected() {
        putTestDataForMultipleTimestamps();
        Map<Cell, Value> result = keyValueService.getRows(
                TEST_TABLE,
                ImmutableSet.of(row0),
                ColumnSelection.create(ImmutableSet.of(column0)),
                TEST_TIMESTAMP + 1);
        assertEquals(1, result.size());
        assertTrue(result.containsKey(Cell.create(row0, column0)));
        assertTrue(result.containsValue(Value.create(value0_t0, TEST_TIMESTAMP)));

        result = keyValueService.getRows(
                TEST_TABLE,
                ImmutableSet.of(row0),
                ColumnSelection.create(ImmutableSet.of(column0)),
                TEST_TIMESTAMP + 2);
        assertEquals(1, result.size());
        assertTrue(result.containsKey(Cell.create(row0, column0)));
        assertTrue(result.containsValue(Value.create(value0_t1, TEST_TIMESTAMP + 1)));
    }
",non-flaky,5
38238,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetWhenMultipleVersions,"    @Test
    public void testGetWhenMultipleVersions() {
        putTestDataForMultipleTimestamps();
        Cell cell = Cell.create(row0, column0);
        Value val0 = Value.create(value0_t0, TEST_TIMESTAMP);
        Value val1 = Value.create(value0_t1, TEST_TIMESTAMP + 1);

        assertTrue(keyValueService.get(TEST_TABLE, ImmutableMap.of(cell, TEST_TIMESTAMP)).isEmpty());

        Map<Cell, Value> result = keyValueService.get(
                TEST_TABLE,
                ImmutableMap.of(cell, TEST_TIMESTAMP + 1));
        assertTrue(result.containsKey(cell));
        assertEquals(1, result.size());
        assertTrue(result.containsValue(val0));

        result = keyValueService.get(TEST_TABLE, ImmutableMap.of(cell, TEST_TIMESTAMP + 2));

        assertEquals(1, result.size());
        assertTrue(result.containsKey(cell));
        assertTrue(result.containsValue(val1));

        result = keyValueService.get(TEST_TABLE, ImmutableMap.of(cell, TEST_TIMESTAMP + 3));

        assertEquals(1, result.size());
        assertTrue(result.containsKey(cell));
        assertTrue(result.containsValue(val1));
    }
",non-flaky,5
38239,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRowsWithSelectedColumns,"    @Test
    public void testGetRowsWithSelectedColumns() {
        putTestDataForSingleTimestamp();
        ColumnSelection columns1and2 = ColumnSelection.create(Arrays.asList(column1, column2));
        Map<Cell, Value> values = keyValueService.getRows(TEST_TABLE,
                                                          Arrays.asList(row1, row2),
                                                          columns1and2,
                                                          TEST_TIMESTAMP + 1);
        assertEquals(3, values.size());
        assertEquals(null, values.get(Cell.create(row1, column0)));
        assertArrayEquals(value12, values.get(Cell.create(row1, column2)).getContents());
        assertArrayEquals(value21, values.get(Cell.create(row2, column1)).getContents());
        assertArrayEquals(value22, values.get(Cell.create(row2, column2)).getContents());
    }
",non-flaky,5
38240,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetLatestTimestamps,"    @Test
    public void testGetLatestTimestamps() {
        putTestDataForMultipleTimestamps();
        Map<Cell, Long> timestamps = keyValueService.getLatestTimestamps(TEST_TABLE,
                ImmutableMap.of(Cell.create(row0, column0), TEST_TIMESTAMP + 2));
        assertTrue(""Incorrect number of values returned."", timestamps.size() == 1);
        assertEquals(""Incorrect value returned."", new Long(TEST_TIMESTAMP + 1),
                timestamps.get(Cell.create(row0, column0)));
    }
",non-flaky,5
38241,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetWithMultipleVersions,"    @Test
    public void testGetWithMultipleVersions() {
        putTestDataForMultipleTimestamps();
        Map<Cell, Value> values = keyValueService.get(TEST_TABLE,
                ImmutableMap.of(Cell.create(row0, column0), TEST_TIMESTAMP + 2));
        assertTrue(""Incorrect number of values returned."", values.size() == 1);
        assertEquals(""Incorrect value returned."", Value.create(value0_t1, TEST_TIMESTAMP + 1),
                values.get(Cell.create(row0, column0)));
    }
",non-flaky,5
38242,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetAllTableNames,"    @Test
    public void testGetAllTableNames() {
        final TableReference anotherTable = TableReference.createWithEmptyNamespace(""AnotherTable"");
        assertEquals(1, keyValueService.getAllTableNames().size());
        assertEquals(TEST_TABLE, keyValueService.getAllTableNames().iterator().next());
        keyValueService.createTable(anotherTable, AtlasDbConstants.GENERIC_TABLE_METADATA);
        assertEquals(2, keyValueService.getAllTableNames().size());
        assertTrue(keyValueService.getAllTableNames().contains(anotherTable));
        assertTrue(keyValueService.getAllTableNames().contains(TEST_TABLE));
        keyValueService.dropTable(anotherTable);
        assertEquals(1, keyValueService.getAllTableNames().size());
        assertEquals(TEST_TABLE, keyValueService.getAllTableNames().iterator().next());
    }
",non-flaky,5
38243,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testTableMetadata,"    @Test
    public void testTableMetadata() {
        assertEquals(AtlasDbConstants.GENERIC_TABLE_METADATA.length, keyValueService.getMetadataForTable(TEST_TABLE).length);
        keyValueService.putMetadataForTable(TEST_TABLE, ArrayUtils.EMPTY_BYTE_ARRAY);
        assertEquals(0, keyValueService.getMetadataForTable(TEST_TABLE).length);
        keyValueService.putMetadataForTable(TEST_TABLE, metadata0);
        assertTrue(Arrays.equals(metadata0, keyValueService.getMetadataForTable(TEST_TABLE)));
    }
",non-flaky,5
38244,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRange,"    @Test
    public void testGetRange() {
        testGetRange(reverseRangesSupported());
    }
",non-flaky,5
38245,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetAllTimestamps,"    @Test
    public void testGetAllTimestamps() {
        putTestDataForMultipleTimestamps();
        final Cell cell = Cell.create(row0, column0);
        final Set<Cell> cellSet = ImmutableSet.of(cell);
        Multimap<Cell, Long> timestamps = keyValueService.getAllTimestamps(
                TEST_TABLE,
                cellSet,
                TEST_TIMESTAMP);
        assertEquals(0, timestamps.size());

        timestamps = keyValueService.getAllTimestamps(TEST_TABLE, cellSet, TEST_TIMESTAMP + 1);
        assertEquals(1, timestamps.size());
        assertTrue(timestamps.containsEntry(cell, TEST_TIMESTAMP));

        timestamps = keyValueService.getAllTimestamps(TEST_TABLE, cellSet, TEST_TIMESTAMP + 2);
        assertEquals(2, timestamps.size());
        assertTrue(timestamps.containsEntry(cell, TEST_TIMESTAMP));
        assertTrue(timestamps.containsEntry(cell, TEST_TIMESTAMP + 1));

        assertEquals(
                timestamps,
                keyValueService.getAllTimestamps(TEST_TABLE, cellSet, TEST_TIMESTAMP + 3));
    }
",non-flaky,5
38246,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testDelete,"    @Test
    public void testDelete() {
        putTestDataForSingleTimestamp();
        assertEquals(3, Iterators.size(keyValueService.getRange(
                TEST_TABLE,
                RangeRequest.all(),
                TEST_TIMESTAMP + 1)));
        keyValueService.delete(
                TEST_TABLE,
                ImmutableMultimap.of(Cell.create(row0, column0), TEST_TIMESTAMP));
        assertEquals(3, Iterators.size(keyValueService.getRange(
                TEST_TABLE,
                RangeRequest.all(),
                TEST_TIMESTAMP + 1)));
        keyValueService.delete(
                TEST_TABLE,
                ImmutableMultimap.of(Cell.create(row0, column1), TEST_TIMESTAMP));
        assertEquals(2, Iterators.size(keyValueService.getRange(
                TEST_TABLE,
                RangeRequest.all(),
                TEST_TIMESTAMP + 1)));
        keyValueService.delete(
                TEST_TABLE,
                ImmutableMultimap.of(Cell.create(row1, column0), TEST_TIMESTAMP));
        assertEquals(2, Iterators.size(keyValueService.getRange(
                TEST_TABLE,
                RangeRequest.all(),
                TEST_TIMESTAMP + 1)));
        keyValueService.delete(
                TEST_TABLE,
                ImmutableMultimap.of(Cell.create(row1, column2), TEST_TIMESTAMP));
        assertEquals(1, Iterators.size(keyValueService.getRange(
                TEST_TABLE,
                RangeRequest.all(),
                TEST_TIMESTAMP + 1)));
    }
",non-flaky,5
38247,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testDeleteMultipleVersions,"    @Test
    public void testDeleteMultipleVersions() {
        putTestDataForMultipleTimestamps();
        Cell cell = Cell.create(row0, column0);
        ClosableIterator<RowResult<Value>> result = keyValueService.getRange(
                TEST_TABLE,
                RangeRequest.all(),
                TEST_TIMESTAMP + 1);
        assertTrue(result.hasNext());

        keyValueService.delete(TEST_TABLE, ImmutableMultimap.of(cell, TEST_TIMESTAMP));

        result = keyValueService.getRange(TEST_TABLE, RangeRequest.all(), TEST_TIMESTAMP + 1);
        assertTrue(!result.hasNext());

        result = keyValueService.getRange(TEST_TABLE, RangeRequest.all(), TEST_TIMESTAMP + 2);
        assertTrue(result.hasNext());
    }
",non-flaky,5
38248,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testPutWithTimestamps,"    @Test
    public void testPutWithTimestamps() {
        putTestDataForMultipleTimestamps();
        final Cell cell = Cell.create(row0, column0);
        final Value val1 = Value.create(value0_t1, TEST_TIMESTAMP + 1);
        final Value val5 = Value.create(value0_t5, TEST_TIMESTAMP + 5);
        keyValueService.putWithTimestamps(TEST_TABLE, ImmutableMultimap.of(cell, val5));
        assertEquals(
                val5,
                keyValueService.get(TEST_TABLE, ImmutableMap.of(cell, TEST_TIMESTAMP + 6)).get(cell));
        assertEquals(
                val1,
                keyValueService.get(TEST_TABLE, ImmutableMap.of(cell, TEST_TIMESTAMP + 5)).get(cell));
        keyValueService.delete(TEST_TABLE, ImmutableMultimap.of(cell, TEST_TIMESTAMP + 5));
    }
",non-flaky,5
38249,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRangeWithHistory,"    @Test
    public void testGetRangeWithHistory() {
        testGetRangeWithHistory(false);
        if (reverseRangesSupported()) {
            testGetRangeWithHistory(true);
        }
    }
",non-flaky,5
38250,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRangeWithTimestamps,"    @Test
    public void testGetRangeWithTimestamps() {
        testGetRangeWithTimestamps(false);
        if (reverseRangesSupported()) {
            testGetRangeWithTimestamps(true);
        }
    }
",non-flaky,5
38251,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testKeyAlreadyExists,"    @Test
    public void testKeyAlreadyExists() {
        // Test that it does not throw some random exceptions
        putTestDataForSingleTimestamp();
        try {
            putTestDataForSingleTimestamp();
            // Legal
        } catch (KeyAlreadyExistsException e) {
            Assert.fail(""Must not throw when overwriting with same value!"");
        }

        keyValueService.putWithTimestamps(
                TEST_TABLE,
                ImmutableMultimap.of(
                        Cell.create(row0, column0),
                        Value.create(value00, TEST_TIMESTAMP + 1)));
        try {
            keyValueService.putWithTimestamps(
                    TEST_TABLE,
                    ImmutableMultimap.of(
                            Cell.create(row0, column0),
                            Value.create(value00, TEST_TIMESTAMP + 1)));
            // Legal
        } catch (KeyAlreadyExistsException e) {
            Assert.fail(""Must not throw when overwriting with same value!"");
        }

        try {
            keyValueService.putWithTimestamps(TEST_TABLE, ImmutableMultimap.of(Cell.create(row0, column0), Value.create(value01, TEST_TIMESTAMP + 1)));
            // Legal
        } catch (KeyAlreadyExistsException e) {
            // Legal
        }

        // The first try might not throw as putUnlessExists must only be exclusive with other putUnlessExists.
        try {
            keyValueService.putUnlessExists(TEST_TABLE, ImmutableMap.of(Cell.create(row0, column0), value00));
            // Legal
        } catch (KeyAlreadyExistsException e) {
            // Legal
        }

        try {
            keyValueService.putUnlessExists(TEST_TABLE, ImmutableMap.of(Cell.create(row0, column0), value00));
            Assert.fail(""putUnlessExists must throw when overwriting the same cell!"");
        } catch (KeyAlreadyExistsException e) {
            // Legal
        }
    }
",non-flaky,5
38252,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testAddGCSentinelValues,"    @Test
    public void testAddGCSentinelValues() {
        putTestDataForMultipleTimestamps();
        Cell cell = Cell.create(row0, column0);

        Multimap<Cell, Long> timestampsBefore = keyValueService.getAllTimestamps(TEST_TABLE, ImmutableSet.of(cell), Long.MAX_VALUE);
        assertEquals(2, timestampsBefore.size());
        assertTrue(!timestampsBefore.containsEntry(cell, Value.INVALID_VALUE_TIMESTAMP));

        keyValueService.addGarbageCollectionSentinelValues(TEST_TABLE, ImmutableSet.of(cell));

        Multimap<Cell, Long> timestampsAfter1 = keyValueService.getAllTimestamps(TEST_TABLE, ImmutableSet.of(cell), Long.MAX_VALUE);
        assertEquals(3, timestampsAfter1.size());
        assertTrue(timestampsAfter1.containsEntry(cell, Value.INVALID_VALUE_TIMESTAMP));

        keyValueService.addGarbageCollectionSentinelValues(TEST_TABLE, ImmutableSet.of(cell));

        Multimap<Cell, Long> timestampsAfter2 = keyValueService.getAllTimestamps(TEST_TABLE, ImmutableSet.of(cell), Long.MAX_VALUE);
        assertEquals(3, timestampsAfter2.size());
        assertTrue(timestampsAfter2.containsEntry(cell, Value.INVALID_VALUE_TIMESTAMP));
    }
",non-flaky,5
38253,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRangeThrowsOnError,"    @Test
    public void testGetRangeThrowsOnError() {
        try {
            keyValueService.getRange(TEST_NONEXISTING_TABLE, RangeRequest.all(), Long.MAX_VALUE).hasNext();
            Assert.fail(""getRange must throw on failure"");
        } catch (RuntimeException e) {
            // Expected
        }
    }
",non-flaky,5
38254,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRangeWithHistoryThrowsOnError,"    @Test
    public void testGetRangeWithHistoryThrowsOnError() {
        try {
            keyValueService.getRangeWithHistory(TEST_NONEXISTING_TABLE, RangeRequest.all(), Long.MAX_VALUE).hasNext();
            Assert.fail(""getRangeWithHistory must throw on failure"");
        } catch (RuntimeException e) {
            // Expected
        }
    }
",non-flaky,5
38255,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRangeOfTimestampsThrowsOnError,"    @Test
    public void testGetRangeOfTimestampsThrowsOnError() {
        try {
            keyValueService.getRangeOfTimestamps(TEST_NONEXISTING_TABLE, RangeRequest.all(), Long.MAX_VALUE).hasNext();
            Assert.fail(""getRangeOfTimestamps must throw on failure"");
        } catch (RuntimeException e) {
            // Expected
        }
    }
",non-flaky,5
38256,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testCannotModifyValuesAfterWrite,"    @Test
    public void testCannotModifyValuesAfterWrite() {
        byte[] data = new byte[1];
        byte[] unmodifiedData = Arrays.copyOf(data, data.length);

        Cell cell = Cell.create(row0, column0);

        Value val = Value.create(data, TEST_TIMESTAMP + 1);

        keyValueService.putWithTimestamps(TEST_TABLE, ImmutableMultimap.of(cell, val));

        data[0] = (byte) 50;

        assertThat(keyValueService.get(TEST_TABLE, ImmutableMap.of(cell, TEST_TIMESTAMP + 3)).get(cell).getContents(),
                is(unmodifiedData));

        keyValueService.delete(TEST_TABLE, ImmutableMultimap.of(cell, TEST_TIMESTAMP + 1));
    }
",non-flaky,5
38257,palantir_atlasdb,AbstractSerializableTransactionTest.testClassicWriteSkew,"    @Test
    public void testClassicWriteSkew() {
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", ""100"");
        put(t0, ""row2"", ""col1"", ""100"");
        t0.commit();

        Transaction t1 = startTransaction();
        Transaction t2 = startTransaction();
        withdrawMoney(t1, true, false);
        withdrawMoney(t2, false, false);

        t1.commit();
        try {
            t2.commit();
            fail();
        } catch (TransactionSerializableConflictException e) {
            // this is expectecd to throw because it is a write skew
        }
    }
",non-flaky,5
38258,palantir_atlasdb,AbstractSerializableTransactionTest.testClassicWriteSkew2,"    @Test
    public void testClassicWriteSkew2() {
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", ""100"");
        put(t0, ""row2"", ""col1"", ""100"");
        t0.commit();

        Transaction t1 = startTransaction();
        Transaction t2 = startTransaction();
        withdrawMoney(t1, true, false);
        withdrawMoney(t2, false, false);

        t2.commit();
        try {
            t1.commit();
            fail();
        } catch (TransactionSerializableConflictException e) {
            // this is expectecd to throw because it is a write skew
        }
    }
",non-flaky,5
38259,palantir_atlasdb,AbstractSerializableTransactionTest.call,"    @Test(expected=TransactionFailedRetriableException.class)
    public void testConcurrentWriteSkew() throws InterruptedException, BrokenBarrierException {
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", ""100"");
        put(t0, ""row2"", ""col1"", ""100"");
        t0.commit();

        final CyclicBarrier barrier = new CyclicBarrier(2);

        final Transaction t1 = startTransaction();
        ExecutorService exec = PTExecutors.newCachedThreadPool();
        Future<?> f = exec.submit( new Callable<Void>() {
            @Override
            public Void call() throws Exception {
                withdrawMoney(t1, true, false);
                barrier.await();
                t1.commit();
                return null;
            }
",non-flaky,5
38260,palantir_atlasdb,AbstractSerializableTransactionTest.testClassicWriteSkewCell,"    @Test
    public void testClassicWriteSkewCell() {
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", ""100"");
        put(t0, ""row2"", ""col1"", ""100"");
        t0.commit();

        Transaction t1 = startTransaction();
        Transaction t2 = startTransaction();
        withdrawMoney(t1, true, true);
        withdrawMoney(t2, false, true);

        t1.commit();
        try {
            t2.commit();
            fail();
        } catch (TransactionSerializableConflictException e) {
            // this is expectecd to throw because it is a write skew
        }
    }
",non-flaky,5
38261,palantir_atlasdb,AbstractSerializableTransactionTest.testClassicWriteSkew2Cell,"    @Test
    public void testClassicWriteSkew2Cell() {
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", ""100"");
        put(t0, ""row2"", ""col1"", ""100"");
        t0.commit();

        Transaction t1 = startTransaction();
        Transaction t2 = startTransaction();
        withdrawMoney(t1, true, true);
        withdrawMoney(t2, false, true);

        t2.commit();
        try {
            t1.commit();
            fail();
        } catch (TransactionSerializableConflictException e) {
            // this is expectecd to throw because it is a write skew
        }
    }
",non-flaky,5
38262,palantir_atlasdb,AbstractSerializableTransactionTest.call,"    @Test(expected=TransactionFailedRetriableException.class)
    public void testConcurrentWriteSkewCell() throws InterruptedException, BrokenBarrierException {
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", ""100"");
        put(t0, ""row2"", ""col1"", ""100"");
        t0.commit();

        final CyclicBarrier barrier = new CyclicBarrier(2);

        final Transaction t1 = startTransaction();
        ExecutorService exec = PTExecutors.newCachedThreadPool();
        Future<?> f = exec.submit( new Callable<Void>() {
            @Override
            public Void call() throws Exception {
                withdrawMoney(t1, true, true);
                barrier.await();
                t1.commit();
                return null;
            }
",non-flaky,5
38263,palantir_atlasdb,AbstractSerializableTransactionTest.testCycleWithReadOnly,"    @Test
    public void testCycleWithReadOnly() {
        // readOnly has a r/w dep on t2 and t2 has a r/w on t1 and t1 has a w/r dep on readOnly
        // This creates a cycle that is valid under SI, but not SSI
        // The main issue is that readOnly reads an invalid state of the world. because it reads the updated value of
        // t1, but the old value of t2.

        String initialValue = ""100"";
        String newValue = ""101"";
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", initialValue);
        put(t0, ""row2"", ""col1"", initialValue);
        t0.commit();

        Transaction t1 = startTransaction();
        put(t1, ""row1"", ""col1"", newValue);
        Transaction t2 = startTransaction();
        String row1Get = get(t2, ""row1"", ""col1"");
        assertEquals(initialValue, row1Get);
        put(t2, ""row2"", ""col1"", row1Get);

        t1.commit();
        Transaction readOnly = startTransaction();
        assertEquals(newValue, get(readOnly, ""row1"", ""col1""));
        assertEquals(initialValue, get(readOnly, ""row2"", ""col1""));

        try {
            t2.commit();
            fail();
        } catch (TransactionSerializableConflictException e) {
            // this is expectecd to throw because it is a write skew
        }
    }
",non-flaky,5
38264,palantir_atlasdb,AbstractSerializableTransactionTest.testLargerCycleWithReadOnly,"    @Test
    public void testLargerCycleWithReadOnly() {
        String initialValue = ""100"";
        String newValue = ""101"";
        String newValue2 = ""102"";
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", initialValue);
        put(t0, ""row2"", ""col1"", initialValue);
        t0.commit();

        Transaction t1 = startTransaction();
        put(t1, ""row1"", ""col1"", newValue);
        Transaction t2 = startTransaction();
        String row1Get = get(t2, ""row1"", ""col1"");
        assertEquals(initialValue, row1Get);
        put(t2, ""row2"", ""col1"", row1Get);

        t1.commit();
        Transaction t3 = startTransaction();
        put(t3, ""row1"", ""col1"", newValue2);
        t3.commit();
        Transaction readOnly = startTransaction();
        assertEquals(newValue2, get(readOnly, ""row1"", ""col1""));
        assertEquals(initialValue, get(readOnly, ""row2"", ""col1""));

        try {
            t2.commit();
            fail();
        } catch (TransactionSerializableConflictException e) {
            // this is expectecd to throw because it is a write skew
        }
    }
",non-flaky,5
38265,palantir_atlasdb,AbstractSerializableTransactionTest.testNonPhantomRead,"    @Test
    public void testNonPhantomRead() {
        String initialValue = ""100"";
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", initialValue);
        put(t0, ""row2"", ""col1"", initialValue);
        t0.commit();

        Transaction t1 = startTransaction();
        RowResult<byte[]> first = BatchingVisitables.getFirst(t1.getRange(TEST_TABLE, RangeRequest.builder().build()));
        put(t1, ""row22"", ""col1"", initialValue);

        Transaction t2 = startTransaction();
        put(t2, ""row11"", ""col1"", initialValue);
        t2.commit();

        t1.commit();
    }
",non-flaky,5
38266,palantir_atlasdb,AbstractSerializableTransactionTest.testPhantomReadFail,"    @Test
    public void testPhantomReadFail() {
        String initialValue = ""100"";
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", initialValue);
        put(t0, ""row2"", ""col1"", initialValue);
        t0.commit();

        Transaction t1 = startTransaction();
        RowResult<byte[]> first = BatchingVisitables.getFirst(t1.getRange(TEST_TABLE, RangeRequest.builder().build()));
        put(t1, ""row22"", ""col1"", initialValue);

        Transaction t2 = startTransaction();
        put(t2, ""row0"", ""col1"", initialValue);
        t2.commit();

        try {
            t1.commit();
            fail();
        } catch (TransactionSerializableConflictException e) {
            // this is expectecd to throw because it is a write skew
        }
    }
",non-flaky,5
38267,palantir_atlasdb,AbstractSerializableTransactionTest.testPhantomReadFail2,"    @Test
    public void testPhantomReadFail2() {
        String initialValue = ""100"";
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", initialValue);
        put(t0, ""row2"", ""col1"", initialValue);
        t0.commit();

        Transaction t1 = startTransaction();
        BatchingVisitables.copyToList(t1.getRange(TEST_TABLE, RangeRequest.builder().build()));
        put(t1, ""row22"", ""col1"", initialValue);

        Transaction t2 = startTransaction();
        put(t2, ""row3"", ""col1"", initialValue);
        t2.commit();

        try {
            t1.commit();
            fail();
        } catch (TransactionSerializableConflictException e) {
            // this is expectecd to throw because it is a write skew
        }
    }
",non-flaky,5
38268,palantir_atlasdb,AbstractSerializableTransactionTest.testCellReadWriteFailure,"    @Test
    public void testCellReadWriteFailure() {
        String initialValue = ""100"";
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", initialValue);
        put(t0, ""row2"", ""col1"", initialValue);
        t0.commit();

        Transaction t1 = startTransaction();
        BatchingVisitables.copyToList(t1.getRange(TEST_TABLE, RangeRequest.builder().build()));
        put(t1, ""row22"", ""col1"", initialValue);

        Transaction t2 = startTransaction();
        put(t2, ""row3"", ""col1"", initialValue);
        t2.commit();

        try {
            t1.commit();
            fail();
        } catch (TransactionSerializableConflictException e) {
            // this is expectecd to throw because it is a write skew
        }
    }
",non-flaky,5
38269,palantir_atlasdb,AbstractSerializableTransactionTest.testCellReadWriteFailure2,"    @Test
    public void testCellReadWriteFailure2() {
        String initialValue = ""100"";
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", initialValue);
        put(t0, ""row2"", ""col1"", initialValue);
        t0.commit();

        Transaction t1 = startTransaction();
        BatchingVisitables.copyToList(t1.getRange(TEST_TABLE, RangeRequest.builder().build()));
        put(t1, ""row22"", ""col1"", initialValue);

        Transaction t2 = startTransaction();
        put(t2, ""row2"", ""col1"", ""101"");
        t2.commit();

        try {
            t1.commit();
            fail();
        } catch (TransactionSerializableConflictException e) {
            // this is expectecd to throw because it is a write skew
        }
    }
",non-flaky,5
38270,palantir_atlasdb,AbstractSerializableTransactionTest.testColumnSelection,"    @Test
    public void testColumnSelection() {
        String initialValue = ""100"";
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", initialValue);
        put(t0, ""row1"", ""col2"", initialValue);
        put(t0, ""row2"", ""col1"", initialValue);
        t0.commit();

        Transaction t1 = startTransaction();
        BatchingVisitables.copyToList(t1.getRange(TEST_TABLE, RangeRequest.builder().retainColumns(ImmutableList.of(PtBytes.toBytes(""col1""))).build()));
        get(t1, ""row1"", ""col2"");

        // We need to do at least one put so we don't get caught by the read only code path
        put(t1, ""row22"", ""col2"", initialValue);

        t1.commit();
    }
",non-flaky,5
38271,palantir_atlasdb,AbstractSerializableTransactionTest.testColumnSelection2,"    @Test
    public void testColumnSelection2() {
        String initialValue = ""100"";
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", initialValue);
        put(t0, ""row1"", ""col2"", initialValue);
        put(t0, ""row2"", ""col1"", initialValue);
        t0.commit();

        Transaction t1 = startTransaction();
        BatchingVisitables.copyToList(t1.getRange(TEST_TABLE, RangeRequest.builder().retainColumns(ImmutableList.of(PtBytes.toBytes(""col1""))).build()));
        BatchingVisitables.copyToList(t1.getRange(TEST_TABLE, RangeRequest.builder().retainColumns(ImmutableList.of(PtBytes.toBytes(""col2""))).build()));

        // We need to do at least one put so we don't get caught by the read only code path
        put(t1, ""row22"", ""col2"", initialValue);

        t1.commit();
    }
",non-flaky,5
38272,palantir_atlasdb,AbstractTransactionTest.testBigValue,"    @Test
    public void testBigValue() {
        byte[] bytes = new byte[64*1024];
        new Random().nextBytes(bytes);
        String encodeHexString = BaseEncoding.base16().lowerCase().encode(bytes);
        putDirect(""row1"", ""col1"", encodeHexString, 0);
        Pair<String, Long> pair = getDirect(""row1"", ""col1"", 1);
        Assert.assertEquals(0L, (long)pair.getRhSide());
        assertEquals(encodeHexString, pair.getLhSide());
    }
",non-flaky,5
38273,palantir_atlasdb,AbstractTransactionTest.testSpecialValues,"    @Test
    public void testSpecialValues() {
        String eight = ""00000000"";
        String sixteen = eight + eight;
        putDirect(""row1"", ""col1"", eight, 0);
        putDirect(""row2"", ""col1"", sixteen, 0);
        Pair<String, Long> direct1 = getDirect(""row1"", ""col1"", 1);
        assertEquals(eight, direct1.lhSide);
        Pair<String, Long> direct2 = getDirect(""row2"", ""col1"", 1);
        assertEquals(sixteen, direct2.lhSide);
    }
",non-flaky,5
38274,palantir_atlasdb,AbstractTransactionTest.testKeyValueRows,"    @Test
    public void testKeyValueRows() {
        putDirect(""row1"", ""col1"", ""v1"", 0);
        Pair<String, Long> pair = getDirect(""row1"", ""col1"", 1);
        assertEquals(0L, (long)pair.getRhSide());
        assertEquals(""v1"", pair.getLhSide());

        putDirect(""row1"", ""col1"", ""v2"", 2);
        pair = getDirect(""row1"", ""col1"", 2);
        assertEquals(0L, (long)pair.getRhSide());
        assertEquals(""v1"", pair.getLhSide());

        pair = getDirect(""row1"", ""col1"", 3);
        assertEquals(2L, (long)pair.getRhSide());
        assertEquals(""v2"", pair.getLhSide());
    }
",non-flaky,5
38275,palantir_atlasdb,AbstractTransactionTest.testPrimaryKeyViolation,"    @Test
    public void testPrimaryKeyViolation() {
        Cell cell = Cell.create(""r1"".getBytes(), TransactionConstants.COMMIT_TS_COLUMN);
        keyValueService.putUnlessExists(TransactionConstants.TRANSACTION_TABLE,
            ImmutableMap.of(cell, ""v1"".getBytes()));
        try {
            keyValueService.putUnlessExists(TransactionConstants.TRANSACTION_TABLE,
                ImmutableMap.of(cell, ""v2"".getBytes()));
            fail();
        } catch (KeyAlreadyExistsException e) {
            //expected
        }
    }
",non-flaky,5
38276,palantir_atlasdb,AbstractTransactionTest.testEmptyValue,"    @Test
    public void testEmptyValue() {
        putDirect(""row1"", ""col1"", ""v1"", 0);
        Pair<String, Long> pair = getDirect(""row1"", ""col1"", 1);
        assertEquals(0L, (long)pair.getRhSide());
        assertEquals(""v1"", pair.getLhSide());

        putDirect(""row1"", ""col1"", """", 2);
        pair = getDirect(""row1"", ""col1"", 2);
        assertEquals(0L, (long)pair.getRhSide());
        assertEquals(""v1"", pair.getLhSide());

        pair = getDirect(""row1"", ""col1"", 3);
        assertEquals(2L, (long)pair.getRhSide());
        assertEquals("""", pair.getLhSide());
    }
",non-flaky,5
38277,palantir_atlasdb,AbstractTransactionTest.testKeyValueRange,"    @Test
    public void testKeyValueRange() {
        putDirect(""row1"", ""col1"", ""v1"", 0);
        putDirect(""row1"", ""col2"", ""v2"", 2);
        putDirect(""row1"", ""col4"", ""v5"", 3);
        putDirect(""row1a"", ""col4"", ""v5"", 100);
        putDirect(""row2"", ""col2"", ""v3"", 1);
        putDirect(""row2"", ""col4"", ""v4"", 6);

        ImmutableList<RowResult<Value>> list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, RangeRequest.builder().build(), 1));
        assertEquals(1, list.size());
        RowResult<Value> row = list.iterator().next();
        assertEquals(1, row.getColumns().size());

        list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, RangeRequest.builder().build(), 2));
        assertEquals(2, list.size());
        row = list.iterator().next();
        assertEquals(1, row.getColumns().size());

        list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, RangeRequest.builder().build(), 3));
        assertEquals(2, list.size());
        row = list.iterator().next();
        assertEquals(2, row.getColumns().size());

        list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, RangeRequest.builder().endRowExclusive(PtBytes.toBytes(""row2"")).build(), 3));
        assertEquals(1, list.size());
        row = list.iterator().next();
        assertEquals(2, row.getColumns().size());

        list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, RangeRequest.builder().startRowInclusive(PtBytes.toBytes(""row1a"")).build(), 3));
        assertEquals(1, list.size());
        row = list.iterator().next();
        assertEquals(1, row.getColumns().size());
    }
",non-flaky,5
38278,palantir_atlasdb,AbstractTransactionTest.testKeyValueEmptyRange,"    @Test
    public void testKeyValueEmptyRange() {
        putDirect(""row1"", ""col1"", ""v1"", 0);

        byte[] rowBytes = PtBytes.toBytes(""row1"");
        ImmutableList<RowResult<Value>> list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, RangeRequest.builder().startRowInclusive(rowBytes).endRowExclusive(rowBytes).build(), 1));
        assertTrue(list.isEmpty());
    }
",non-flaky,5
38279,palantir_atlasdb,AbstractTransactionTest.testKeyValueRangeColumnSelection,"    @Test
    public void testKeyValueRangeColumnSelection() {
        putDirect(""row1"", ""col1"", ""v1"", 0);
        putDirect(""row1"", ""col2"", ""v2"", 2);
        putDirect(""row1"", ""col4"", ""v5"", 3);
        putDirect(""row1a"", ""col4"", ""v5"", 100);
        putDirect(""row2"", ""col2"", ""v3"", 1);
        putDirect(""row2"", ""col4"", ""v4"", 6);

        List<byte[]> selectedColumns = ImmutableList.of(PtBytes.toBytes(""col2""));
        RangeRequest simpleRange = RangeRequest.builder().retainColumns(ColumnSelection.create(selectedColumns)).build();
        ImmutableList<RowResult<Value>> list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, simpleRange, 1));
        assertEquals(0, list.size());

        list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, simpleRange, 2));
        assertEquals(1, list.size());
        RowResult<Value> row = list.iterator().next();
        assertEquals(1, row.getColumns().size());

        list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, simpleRange, 3));
        assertEquals(2, list.size());
        row = list.iterator().next();
        assertEquals(1, row.getColumns().size());

        list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, simpleRange.getBuilder().endRowExclusive(PtBytes.toBytes(""row2"")).build(), 3));
        assertEquals(1, list.size());
        row = list.iterator().next();
        assertEquals(1, row.getColumns().size());

        list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, simpleRange.getBuilder().startRowInclusive(PtBytes.toBytes(""row1a"")).build(), 3));
        assertEquals(1, list.size());
        row = list.iterator().next();
        assertEquals(1, row.getColumns().size());
    }
",non-flaky,5
38280,palantir_atlasdb,AbstractTransactionTest.testKeyValueRangeWithDeletes,"    @Test
    public void testKeyValueRangeWithDeletes() {
        putDirect(""row1"", ""col1"", """", 0);

        ImmutableList<RowResult<Value>> list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, RangeRequest.builder().build(), 1));
        assertEquals(1, list.size());
        RowResult<Value> row = list.iterator().next();
        assertEquals(1, row.getColumns().size());
    }
",non-flaky,5
38281,palantir_atlasdb,AbstractTransactionTest.testKeyValueRanges,"    @Test
    public void testKeyValueRanges() {
        putDirect(""row1"", ""col1"", """", 0);
        putDirect(""row2"", ""col1"", """", 0);
        putDirect(""row2"", ""col2"", """", 0);

        Map<RangeRequest, TokenBackedBasicResultsPage<RowResult<Value>, byte[]>> ranges = keyValueService.getFirstBatchForRanges(TEST_TABLE, ImmutableList.of(RangeRequest.builder().build(), RangeRequest.builder().build()), 1);
        assertTrue(ranges.size() >= 1);
    }
",non-flaky,5
38282,palantir_atlasdb,AbstractTransactionTest.testKeyValueRanges2,"    @Test
    public void testKeyValueRanges2() {
        putDirect(""row1"", ""col1"", """", 0);
        putDirect(""row2"", ""col1"", """", 0);
        putDirect(""row2"", ""col2"", """", 0);

        final RangeRequest allRange = RangeRequest.builder().build();
        final RangeRequest oneRange = RangeRequest.builder().startRowInclusive(""row2"".getBytes()).build();
        final RangeRequest allRangeBatch = RangeRequest.builder().batchHint(3).build();
        Map<RangeRequest, TokenBackedBasicResultsPage<RowResult<Value>, byte[]>> ranges = keyValueService.getFirstBatchForRanges(TEST_TABLE, ImmutableList.of(allRange, oneRange, allRangeBatch), 1);
        assertTrue(ranges.get(allRange).getResults().size()>=1);
        assertEquals(2, ranges.get(allRangeBatch).getResults().size());
        assertFalse(ranges.get(allRangeBatch).moreResultsAvailable());
        assertEquals(1, ranges.get(oneRange).getResults().size());
    }
",non-flaky,5
38283,palantir_atlasdb,AbstractTransactionTest.testKeyValueRangesMany3,"    @Test
    public void testKeyValueRangesMany3() {
        putDirect(""row1"", ""col1"", """", 0);
        putDirect(""row2"", ""col1"", """", 0);
        putDirect(""row2"", ""col2"", """", 0);

        RangeRequest allRange = RangeRequest.builder().prefixRange(""row1"".getBytes()).batchHint(3).build();
        for (int i = 0 ; i < 1000 ; i++) {
            ClosableIterator<RowResult<Value>> range = keyValueService.getRange(TEST_TABLE, allRange, 1);
            ImmutableList<RowResult<Value>> list = ImmutableList.copyOf(range);
            assertEquals(1, list.size());
        }
    }
",non-flaky,5
38284,palantir_atlasdb,AbstractTransactionTest.testKeyValueRangeReverse,"    @Test
    public void testKeyValueRangeReverse() {
        if (!supportsReverse()) {
            return;
        }
        putDirect(""row1"", ""col1"", """", 0);
        putDirect(""row2"", ""col1"", """", 0);
        putDirect(""row2"", ""col2"", """", 0);

        RangeRequest allRange = RangeRequest.reverseBuilder().batchHint(3).build();
        ClosableIterator<RowResult<Value>> range = keyValueService.getRange(TEST_TABLE, allRange, 1);
        ImmutableList<RowResult<Value>> list = ImmutableList.copyOf(range);
        assertEquals(2, list.size());
        assertEquals(""row2"", PtBytes.toString(list.iterator().next().getRowName()));
    }
",non-flaky,5
38285,palantir_atlasdb,AbstractTransactionTest.testRangePagingBatches,"    @Test
    public void testRangePagingBatches() {
        int totalPuts = 101;
        for (int i = 0 ; i < totalPuts ; i++) {
            putDirect(""row""+i, ""col1"", ""v1"", 0);
        }

        Map<RangeRequest, TokenBackedBasicResultsPage<RowResult<Value>, byte[]>> ranges = keyValueService.getFirstBatchForRanges(TEST_TABLE, Iterables.limit(Iterables.cycle(RangeRequest.builder().batchHint(1000).build()), 100), 1);
        assertEquals(1, ranges.keySet().size());
        assertEquals(totalPuts, ranges.values().iterator().next().getResults().size());
    }
",non-flaky,5
38286,palantir_atlasdb,AbstractTransactionTest.testRangePagingBatchesReverse,"    @Test
    public void testRangePagingBatchesReverse() {
        if (!supportsReverse()) {
            return;
        }
        int totalPuts = 101;
        for (int i = 0 ; i < totalPuts ; i++) {
            putDirect(""row""+i, ""col1"", ""v1"", 0);
        }

        Map<RangeRequest, TokenBackedBasicResultsPage<RowResult<Value>, byte[]>> ranges = keyValueService.getFirstBatchForRanges(TEST_TABLE, Iterables.limit(Iterables.cycle(RangeRequest.reverseBuilder().batchHint(1000).build()), 100), 1);
        assertEquals(1, ranges.keySet().size());
        assertEquals(totalPuts, ranges.values().iterator().next().getResults().size());
    }
",non-flaky,5
38287,palantir_atlasdb,AbstractTransactionTest.testRangePagingBatchSizeOne,"    @Test
    public void testRangePagingBatchSizeOne() {
        int totalPuts = 100;
        for (int i = 0 ; i < totalPuts ; i++) {
            putDirect(""row""+i, ""col1"", ""v1"", 0);
        }

        RangeRequest rangeRequest = RangeRequest.builder().batchHint(1).build();
        Map<RangeRequest, TokenBackedBasicResultsPage<RowResult<Value>, byte[]>> ranges = keyValueService.getFirstBatchForRanges(TEST_TABLE, Iterables.limit(Iterables.cycle(rangeRequest), 100), 1);
        assertEquals(1, ranges.keySet().size());
        assertEquals(1, ranges.values().iterator().next().getResults().size());
        assertEquals(""row0"", PtBytes.toString(ranges.values().iterator().next().getResults().iterator().next().getRowName()));
    }
",non-flaky,5
38288,palantir_atlasdb,AbstractTransactionTest.testRangePagingBatchSizeOneReverse,"    @Test
    public void testRangePagingBatchSizeOneReverse() {
        if (!supportsReverse()) {
            return;
        }
        int totalPuts = 100;
        for (int i = 0 ; i < totalPuts ; i++) {
            putDirect(""row""+i, ""col1"", ""v1"", 0);
        }

        RangeRequest rangeRequest = RangeRequest.reverseBuilder().batchHint(1).build();
        Map<RangeRequest, TokenBackedBasicResultsPage<RowResult<Value>, byte[]>> ranges = keyValueService.getFirstBatchForRanges(TEST_TABLE, Iterables.limit(Iterables.cycle(rangeRequest), 100), 1);
        assertEquals(1, ranges.keySet().size());
        assertEquals(1, ranges.values().iterator().next().getResults().size());
        assertEquals(""row99"", PtBytes.toString(ranges.values().iterator().next().getResults().iterator().next().getRowName()));
    }
",non-flaky,5
38289,palantir_atlasdb,AbstractTransactionTest.testRangePageBatchSizeOne,"    @Test
    public void testRangePageBatchSizeOne() {
        RangeRequest rangeRequest = RangeRequest.builder().batchHint(1).build();
        Map<RangeRequest, TokenBackedBasicResultsPage<RowResult<Value>, byte[]>> ranges = keyValueService.getFirstBatchForRanges(TEST_TABLE, Collections.singleton(rangeRequest), 1);
        assertEquals(1, ranges.keySet().size());
        assertEquals(0, ranges.values().iterator().next().getResults().size());
        assertEquals(false, ranges.values().iterator().next().moreResultsAvailable());
    }
",non-flaky,5
38290,palantir_atlasdb,AbstractTransactionTest.testRangeAfterTimestmap,"    @Test
    public void testRangeAfterTimestmap() {
        putDirect(""row1"", ""col2"", """", 5);
        putDirect(""row2"", ""col2"", """", 0);
        RangeRequest rangeRequest = RangeRequest.builder().batchHint(1).build();
        Map<RangeRequest, TokenBackedBasicResultsPage<RowResult<Value>, byte[]>> ranges = keyValueService.getFirstBatchForRanges(TEST_TABLE, Collections.singleton(rangeRequest), 1);
        assertEquals(1, ranges.keySet().size());
        TokenBackedBasicResultsPage<RowResult<Value>, byte[]> page = ranges.values().iterator().next();
        assertTrue(!page.getResults().isEmpty() || page.moreResultsAvailable());
    }
",non-flaky,5
53127,cloudfoundry_uaa,UaaMetricsEmitterIT.assert_generic_metrics,"    @Test
    public void assert_generic_metrics() throws IOException {
        String data1 = firstBatch.get(statsDKey);
        String data2 = secondBatch.get(statsDKey);

        assertNotNull(""Expected to find message for:'"" + statsDKey + ""' in the first batch."", data1);
        long first = IntegrationTestUtils.getStatsDValueFromMessage(data1);
        assertThat(statsDKey + "" first value must have a positive value."", first, greaterThanOrEqualTo(0l));

        assertNotNull(""Expected to find message for:'""+statsDKey+""' in the second batch."", data2);
        long second = IntegrationTestUtils.getStatsDValueFromMessage(data2);
        assertThat(statsDKey + "" second value must have a positive value."", second, greaterThanOrEqualTo(0l));
    }
",non-flaky,5
53128,cloudfoundry_uaa,UaaMetricsScheduledTest.emittingMetrics_Is_Scheduled,"    @Test
    public void emittingMetrics_Is_Scheduled() throws Exception {
        Scheduled schedulerAnnotation = uaaMetricsEmitter.getClass().getMethod(""emitMetrics"").getAnnotation(Scheduled.class);
        Assert.assertEquals(5000, schedulerAnnotation.fixedRate());
    }
",non-flaky,5
53129,cloudfoundry_uaa,MBeanMapTests.testListDomain,"    @Test
    public void testListDomain() throws Exception {
        Set<ObjectName> names = server.queryNames(ObjectName.getInstance(""java.lang:type=Runtime,*""), null);
        System.err.println(names);
        assertTrue(names.size() == 1);
        MBeanMap result = new MBeanMap(server, names.iterator().next());
        @SuppressWarnings(""unchecked"")
        Map<String,String>  properties = (Map<String, String>) result.get(""system_properties"");
        assertTrue(properties.containsKey(""java.vm.version""));
    }
",non-flaky,5
53130,cloudfoundry_uaa,UaaMetricsEmitterTests.auditService_metrics_emitted,"    @Test
    public void auditService_metrics_emitted() throws Exception {
        Mockito.when(metricsUtils.pullUpMap(""cloudfoundry.identity"", ""*"", server)).thenReturn((Map)mBeanMap2);
        uaaMetricsEmitter.emitMetrics();
        Mockito.verify(statsDClient).gauge(""audit_service.user_authentication_count"", 3);
        Mockito.verify(statsDClient).gauge(""audit_service.user_not_found_count"", 1);
        Mockito.verify(statsDClient).gauge(""audit_service.principal_authentication_failure_count"", 4);
        Mockito.verify(statsDClient).gauge(""audit_service.principal_not_found_count"", 5);
        Mockito.verify(statsDClient).gauge(""audit_service.user_authentication_failure_count"", 6);
        Mockito.verify(statsDClient).gauge(""audit_service.client_authentication_count"", 7);
        Mockito.verify(statsDClient).gauge(""audit_service.client_authentication_failure_count"", 42);
    }
",non-flaky,5
53131,cloudfoundry_uaa,UaaMetricsEmitterTests.requestCount_metrics_emitted,"    @Test
    public void requestCount_metrics_emitted() throws Exception {
        Mockito.when(metricsUtils.getUaaMetrics(any())).thenReturn(uaaMetrics1, uaaMetrics2);
        uaaMetricsEmitter.emitGlobalRequestMetrics();
        Mockito.verify(statsDClient).count(""requests.global.completed.count"", 3087l);
        Mockito.verify(statsDClient).gauge(""requests.global.completed.time"", 29l);
        Mockito.verify(statsDClient).count(""requests.global.unhealthy.count"", 1l);
        Mockito.verify(statsDClient).gauge(""requests.global.unhealthy.time"", 4318l);
        Mockito.verify(statsDClient).count(""requests.global.status_1xx.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_2xx.count"", 2148l);
        Mockito.verify(statsDClient).count(""requests.global.status_3xx.count"", 763l);
        Mockito.verify(statsDClient).count(""requests.global.status_4xx.count"", 175l);
        Mockito.verify(statsDClient).count(""requests.global.status_5xx.count"", 1l);
        Mockito.verify(statsDClient).gauge(""server.inflight.count"", 3l);
        Mockito.verify(statsDClient).gauge(""server.up.time"", 12349843l);
        Mockito.verify(statsDClient).gauge(""server.idle.time"", 12349l);
        Mockito.verify(statsDClient).count(""database.global.completed.count"", 83797l);
        Mockito.verify(statsDClient).gauge(""database.global.completed.time"", 0l);
        Mockito.verify(statsDClient).count(""database.global.unhealthy.count"", 17549l);
        Mockito.verify(statsDClient).gauge(""database.global.unhealthy.time"", 0l);
        reset(statsDClient);
        uaaMetricsEmitter.emitGlobalRequestMetrics();
        Mockito.verify(statsDClient).count(""requests.global.completed.count"", 4l);
        Mockito.verify(statsDClient).count(""requests.global.unhealthy.count"", 1l);
        Mockito.verify(statsDClient).count(""requests.global.status_1xx.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_2xx.count"", 1l);
        Mockito.verify(statsDClient).count(""requests.global.status_3xx.count"", 1l);
        Mockito.verify(statsDClient).count(""requests.global.status_4xx.count"", 1l);
        Mockito.verify(statsDClient).count(""requests.global.status_5xx.count"", 1l);
        Mockito.verify(statsDClient).count(""database.global.completed.count"", 2l);
        Mockito.verify(statsDClient).count(""database.global.unhealthy.count"", 5l);
        reset(statsDClient);
        uaaMetricsEmitter.emitGlobalRequestMetrics();
        Mockito.verify(statsDClient).count(""requests.global.completed.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.unhealthy.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_1xx.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_2xx.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_3xx.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_4xx.count"", 0l);
        Mockito.verify(statsDClient).count(""requests.global.status_5xx.count"", 0l);
        Mockito.verify(statsDClient).count(""database.global.completed.count"", 0l);
        Mockito.verify(statsDClient).count(""database.global.unhealthy.count"", 0l);
    }
",non-flaky,5
53132,cloudfoundry_uaa,UaaMetricsEmitterTests.test_delta_method,"    @Test
    public void test_delta_method() {
        String name = ""metric.name"";
        assertEquals(5l, uaaMetricsEmitter.getMetricDelta(name, 5l));
        assertEquals(0l, uaaMetricsEmitter.getMetricDelta(name, 5l));
        assertEquals(3l, uaaMetricsEmitter.getMetricDelta(name, 8l));
    }
",non-flaky,5
53133,cloudfoundry_uaa,UaaMetricsEmitterTests.vm_vitals,"    @Test
    public void vm_vitals() {
        uaaMetricsEmitter.emitVmVitals();
        Mockito.verify(statsDClient).gauge(eq(""vitals.vm.cpu.count""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.vm.cpu.load""), geq(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.vm.memory.total""), geq(134217728l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.vm.memory.committed""), geq(1l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.vm.memory.free""), geq(1l));
    }
",non-flaky,5
53134,cloudfoundry_uaa,UaaMetricsEmitterTests.perUrlGroup_request_metrics,"    @Test
    public void perUrlGroup_request_metrics() throws Exception {
        Mockito.when(metricsUtils.getUaaMetrics(any())).thenReturn(uaaMetrics1);
        uaaMetricsEmitter.emitUrlGroupRequestMetrics();
        Mockito.verify(statsDClient).gauge(eq(""requests.ui.completed.count""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""requests.ui.completed.time""), geq(300l));

        Mockito.verify(statsDClient).gauge(eq(""requests.static-content.completed.count""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""requests.static-content.completed.time""), geq(23l));
    }
",non-flaky,5
53135,cloudfoundry_uaa,UaaMetricsEmitterTests.testNotifications,"    @Test
    public void testNotifications() {
        uaaMetricsEmitter.enableNotification();
        emitter.sendNotification(new Notification(""/api"", 45L, 0));
        Mockito.verify(statsDClient).time(""requests.api.latency"", 45L);
    }
",non-flaky,5
53136,cloudfoundry_uaa,UaaMetricsEmitterTests.jvm_vitals,"    @Test
    public void jvm_vitals() {
        uaaMetricsEmitter.emitJvmVitals();
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.cpu.load""), and(geq(0l), leq(100l)));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.thread.count""), and(gt(1l), leq(1000l)));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.heap.init""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.heap.committed""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.heap.used""), gt(0l));
        //Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.heap.max""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.non-heap.init""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.non-heap.committed""), gt(0l));
        Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.non-heap.used""), gt(0l));
        //Mockito.verify(statsDClient).gauge(eq(""vitals.jvm.non-heap.max""), gt(0l));
    }
",non-flaky,5
53137,cloudfoundry_uaa,UaaMetricsEmitterTests.auditService_metricValues_areNull,"    @Test
    public void auditService_metricValues_areNull() throws Exception {
        mBeanMap1.put(""user_authentication_count"", null);
        Mockito.when(metricsUtils.pullUpMap(""cloudfoundry.identity"", ""*"", server)).thenReturn((Map)mBeanMap2);
        uaaMetricsEmitter.emitMetrics();
        Mockito.verify(statsDClient).gauge(""audit_service.user_not_found_count"", 1);
        Mockito.verify(statsDClient, times(6)).gauge(anyString(), anyLong());
    }
",non-flaky,5
53138,cloudfoundry_uaa,UaaMetricsEmitterTests.auditService_Key_isNull,"    @Test
    public void auditService_Key_isNull () throws Exception {
        mBeanMap2.put(""UaaAudit"", null);
        Mockito.when(metricsUtils.pullUpMap(""cloudfoundry.identity"", ""*"", server)).thenReturn((Map)mBeanMap2);
        uaaMetricsEmitter.emitMetrics();
        Mockito.verify(statsDClient, times(0)).gauge(anyString(), anyLong());
    }
",non-flaky,5
53139,cloudfoundry_uaa,ApiControllerTests.testNoUser,"    @Test
    public void testNoUser() throws Exception {
        controller.setInfo(new ClassPathResource(""info.tmpl""));
        HashMap<String, Object> model = new HashMap<String, Object>();
        View view = controller.info(model, null);
        MockHttpServletResponse response = new MockHttpServletResponse();
        view.render(model, new MockHttpServletRequest(), response);
        String content = response.getContentAsString();
        assertFalse(""Wrong content: "" + content, content.contains(""\""user\""""));
    }
",non-flaky,5
53140,cloudfoundry_uaa,ApiControllerTests.testWithUser,"    @Test
    public void testWithUser() throws Exception {
        controller.setInfo(new ClassPathResource(""info.tmpl""));
        HashMap<String, Object> model = new HashMap<String, Object>();
        View view = controller.info(model, new UsernamePasswordAuthenticationToken(testAccounts.getUserName(), ""<NONE>""));
        MockHttpServletResponse response = new MockHttpServletResponse();
        view.render(model, new MockHttpServletRequest(), response);
        String content = response.getContentAsString();
        assertTrue(""Wrong content: "" + content, content.contains(""\n  \""user\"": \""""+testAccounts.getUserName()+""\""""));
    }
",non-flaky,5
53141,cloudfoundry_uaa,AppsIntegrationTests.testHappyDay,"    @Test
    public void testHappyDay() throws Exception {

        RestOperations restTemplate = serverRunning.createRestTemplate();
        ResponseEntity<String> response = restTemplate.getForEntity(serverRunning.getUrl(""/api/apps""), String.class);
        // first make sure the resource is actually protected.
        assertNotSame(HttpStatus.OK, response.getStatusCode());
        HttpHeaders approvalHeaders = new HttpHeaders();
        OAuth2AccessToken accessToken = context.getAccessToken();
        approvalHeaders.set(""Authorization"", ""bearer "" + accessToken.getValue());

        ResponseEntity<String> result = serverRunning.getForString(""/api/apps"");
        assertEquals(HttpStatus.OK, result.getStatusCode());
        String body = result.getBody();
        assertTrue(""Wrong response: "" + body, body.contains(""dsyerapi.cloudfoundry.com""));

    }
",non-flaky,5
53142,cloudfoundry_uaa,SamlConfigTest.testIsRequestSigned,"    @Test
    public void testIsRequestSigned() throws Exception {
        assertTrue(config.isRequestSigned());
    }
",non-flaky,5
53143,cloudfoundry_uaa,SamlConfigTest.legacy_key_is_part_of_map,"    @Test
    public void legacy_key_is_part_of_map() {
        config.setPrivateKey(privateKey);
        config.setPrivateKeyPassword(passphrase);
        config.setCertificate(certificate);
        Map<String, SamlKey> keys = config.getKeys();
        assertEquals(1, keys.size());
        assertNotNull(keys.get(LEGACY_KEY_ID));
        assertEquals(privateKey, keys.get(LEGACY_KEY_ID).getKey());
        assertEquals(passphrase, keys.get(LEGACY_KEY_ID).getPassphrase());
        assertEquals(certificate, keys.get(LEGACY_KEY_ID).getCertificate());
    }
",non-flaky,5
53144,cloudfoundry_uaa,SamlConfigTest.addActiveKey,"    @Test
    public void addActiveKey() {
        SamlKey key = new SamlKey(privateKey, passphrase, certificate);
        String keyId = ""testKeyId"";
        config.addAndActivateKey(keyId, key);
        Map<String, SamlKey> keys = config.getKeys();
        assertNotNull(keys);
        assertEquals(1, keys.size());
        assertEquals(keyId, config.getActiveKeyId());
        assertNotNull(keys.get(keyId));
        assertEquals(privateKey, keys.get(keyId).getKey());
        assertEquals(passphrase, keys.get(keyId).getPassphrase());
        assertEquals(certificate, keys.get(keyId).getCertificate());
    }
",non-flaky,5
53145,cloudfoundry_uaa,SamlConfigTest.addNonActive,"    @Test
    public void addNonActive() {
        addActiveKey();
        SamlKey key = new SamlKey(privateKey, passphrase, certificate);
        String keyId = ""nonActiveKeyId"";
        config.addKey(keyId, key);
        Map<String, SamlKey> keys = config.getKeys();
        assertNotNull(keys);
        assertEquals(2, keys.size());
        assertNotEquals(keyId, config.getActiveKeyId());
        assertNotNull(keys.get(keyId));
        assertEquals(privateKey, keys.get(keyId).getKey());
        assertEquals(passphrase, keys.get(keyId).getPassphrase());
        assertEquals(certificate, keys.get(keyId).getCertificate());
    }
",non-flaky,5
53146,cloudfoundry_uaa,SamlConfigTest.map_is_not_null_by_default,"    @Test
    public void map_is_not_null_by_default() {
        Map<String, SamlKey> keys = config.getKeys();
        assertNotNull(keys);
        assertEquals(0, keys.size());
        assertNull(config.getActiveKeyId());
    }
",non-flaky,5
53147,cloudfoundry_uaa,SamlConfigTest.testIsWantAssertionSigned,"    @Test
    public void testIsWantAssertionSigned() throws Exception {
        assertTrue(config.isWantAssertionSigned());
    }
",non-flaky,5
53148,cloudfoundry_uaa,SamlConfigTest.testSetKeyAndCert,"    @Test
    public void testSetKeyAndCert() throws CertificateException {
        config.setPrivateKey(privateKey);
        config.setPrivateKeyPassword(passphrase);
        config.setCertificate(certificate);
        assertEquals(privateKey, config.getPrivateKey());
        assertEquals(passphrase, config.getPrivateKeyPassword());
    }
",non-flaky,5
53149,cloudfoundry_uaa,SamlConfigTest.read_old_json_works,"    @Test
    public void read_old_json_works() throws Exception {
        read_json(oldJson);
        assertEquals(privateKey, config.getPrivateKey());
        assertEquals(passphrase, config.getPrivateKeyPassword());
        assertEquals(certificate, config.getCertificate());
    }
",non-flaky,5
53150,cloudfoundry_uaa,SamlConfigTest.to_json_ignores_legacy_values,"    @Test
    public void to_json_ignores_legacy_values() throws Exception {
        read_json(oldJson);
        String json = JsonUtils.writeValueAsString(config);
        read_json(json);
        assertEquals(privateKey, config.getPrivateKey());
        assertEquals(passphrase, config.getPrivateKeyPassword());
        assertEquals(certificate, config.getCertificate());
    }
",non-flaky,5
53151,cloudfoundry_uaa,SamlConfigTest.keys_are_not_modifiable,"    @Test
    public void keys_are_not_modifiable() {
        read_json(oldJson);
        exception.expect(UnsupportedOperationException.class);
        config.getKeys().clear();
    }
",non-flaky,5
53152,cloudfoundry_uaa,SamlConfigTest.can_clear_keys,"    @Test
    public void can_clear_keys() {
        read_json(oldJson);
        assertEquals(1, config.getKeys().size());
        assertNotNull(config.getActiveKeyId());
        config.setKeys(EMPTY_MAP);
        assertEquals(0, config.getKeys().size());
        assertNull(config.getActiveKeyId());
    }
",non-flaky,5
53153,cloudfoundry_uaa,TokenPolicyTest.json_has_expected_properties,"    @Test
    public void json_has_expected_properties() throws Exception {
        TokenPolicy tokenPolicy = new TokenPolicy();
        tokenPolicy.setAccessTokenValidity(1234);
        tokenPolicy.setRefreshTokenValidity(9876);
        tokenPolicy.setKeys(Collections.singletonMap(""aKeyId"", ""KeyKeyKey""));

        String json = JsonUtils.writeValueAsString(tokenPolicy);
        Map properties = JsonUtils.readValue(json, Map.class);

        assertNotNull(properties);
        assertEquals(1234, properties.get(""accessTokenValidity""));
        assertEquals(9876, properties.get(""refreshTokenValidity""));
        assertNotNull(properties.get(""keys""));
        Map keys = (Map) properties.get(""keys"");
        assertNotNull(keys);
        assertEquals(keys.size(), 1);
        assertEquals(""KeyKeyKey"", ((Map) keys.get(""aKeyId"")).get(""signingKey""));
    }
",non-flaky,5
53154,cloudfoundry_uaa,TokenPolicyTest.test_default_values,"    @Test
    public void test_default_values() throws Exception {
        TokenPolicy policy = new TokenPolicy();
        assertFalse(policy.isRefreshTokenUnique());
        assertFalse(policy.isJwtRevocable());
        assertEquals(TokenConstants.TokenFormat.JWT.getStringValue(), policy.getRefreshTokenFormat());
    }
",non-flaky,5
53155,cloudfoundry_uaa,TokenPolicyTest.nullSigningKey,"    @Test(expected = IllegalArgumentException.class)
    public void nullSigningKey() throws Exception {
        TokenPolicy tokenPolicy = new TokenPolicy();
        tokenPolicy.setKeys(Collections.singletonMap(""key-id"", null));
    }
",non-flaky,5
53156,cloudfoundry_uaa,TokenPolicyTest.emptySigningKey,"    @Test(expected = IllegalArgumentException.class)
    public void emptySigningKey() throws Exception {
        TokenPolicy tokenPolicy = new TokenPolicy();
        tokenPolicy.setKeys(Collections.singletonMap(""key-id"", ""             ""));
    }
",non-flaky,5
53157,cloudfoundry_uaa,TokenPolicyTest.nullKeyId,"    @Test(expected = IllegalArgumentException.class)
    public void nullKeyId() throws Exception {
        TokenPolicy tokenPolicy = new TokenPolicy();
        tokenPolicy.setKeys(Collections.singletonMap(null, ""signing-key""));
    }
",non-flaky,5
53158,cloudfoundry_uaa,TokenPolicyTest.emptyKeyId,"    @Test(expected = IllegalArgumentException.class)
    public void emptyKeyId() throws Exception {
        TokenPolicy tokenPolicy = new TokenPolicy();
        tokenPolicy.setKeys(Collections.singletonMap("" "", ""signing-key""));
    }
",non-flaky,5
53159,cloudfoundry_uaa,TokenPolicyTest.deserializationOfTokenPolicyWithVerificationKey_doesNotFail,"    @Test
    public void deserializationOfTokenPolicyWithVerificationKey_doesNotFail() {
        String jsonTokenPolicy = ""{\""keys\"":{\""key-id-1\"":{\""verificationKey\"":\""some-verification-key-1\"",\""signingKey\"":\""some-signing-key-1\""}}}"";
        TokenPolicy tokenPolicy = JsonUtils.readValue(jsonTokenPolicy, TokenPolicy.class);
        assertEquals(tokenPolicy.getKeys().get(""key-id-1""), ""some-signing-key-1"");
    }
",non-flaky,5
53160,cloudfoundry_uaa,TokenPolicyTest.tokenPolicy_whenInvalidUniquenessValue_throwsException,"    @Test
    public void tokenPolicy_whenInvalidUniquenessValue_throwsException() throws Exception {

        TokenPolicy tokenPolicy = new TokenPolicy();
        expectedException.expect(IllegalArgumentException.class);
        expectedException.expectMessage(""Invalid refresh token format invalid. Acceptable values are: [opaque, jwt]"");

        tokenPolicy.setRefreshTokenFormat(""invalid"");
    }
",non-flaky,5
53161,cloudfoundry_uaa,TokenPolicyTest.deserializationOfTokenPolicyWithNoActiveKeyIdWithMultipleKeys_doesNotFail,"    @Test
    public void deserializationOfTokenPolicyWithNoActiveKeyIdWithMultipleKeys_doesNotFail() {
        String jsonTokenPolicy = ""{\""keys\"":{\""key-id-1\"":{\""signingKey\"":\""some-signing-key-1\""},\""key-id-2\"":{\""signingKey\"":\""some-signing-key-2\""}}}"";
        TokenPolicy tokenPolicy = JsonUtils.readValue(jsonTokenPolicy, TokenPolicy.class);
        assertEquals(tokenPolicy.getKeys().get(""key-id-1""), ""some-signing-key-1"");
        assertEquals(tokenPolicy.getKeys().get(""key-id-2""), ""some-signing-key-2"");
    }
",non-flaky,5
53162,cloudfoundry_uaa,ScimGroupTests.testDeSerializeWithoutDescription,"    @Test
    public void testDeSerializeWithoutDescription() {
        group = JsonUtils.readValue(GROUP_BEFORE_DESCRIPTION, ScimGroup.class);
        assertEquals(""id"", group.getId());
        assertEquals(""name"", group.getDisplayName());
        assertEquals(""zoneId"", group.getZoneId());
        assertNull(group.getDescription());
    }
",non-flaky,5
53163,cloudfoundry_uaa,ScimGroupTests.testSerializeWithDescription,"    @Test
    public void testSerializeWithDescription() {
        group.setDescription(""description"");
        String json = JsonUtils.writeValueAsString(group);
        group = JsonUtils.readValue(json, ScimGroup.class);
        assertEquals(""id"", group.getId());
        assertEquals(""name"", group.getDisplayName());
        assertEquals(""zoneId"", group.getZoneId());
        assertEquals(""description"", group.getDescription());
    }
",non-flaky,5
53164,cloudfoundry_uaa,ScimGroupTests.testPatch,"    @Test
    public void testPatch(){
        group.patch(patch);
        assertEquals(patch.getId(), group.getId());
        assertEquals(""NewName"",group.getDisplayName());
        assertEquals(""NewDescription"", group.getDescription());
    }
",non-flaky,5
53165,cloudfoundry_uaa,ScimGroupTests.testPatchZoneIdFails,"    @Test
    public void testPatchZoneIdFails(){
        group.setZoneId(""uaa"");
        patch.setZoneId(""zoneid"");

        assertTrue(group.getZoneId().equals(""uaa""));
        assertTrue(patch.getZoneId().equals(""zoneid""));

        group.patch(patch);

        assertTrue(group.getZoneId().equals(""uaa""));
        assertTrue(patch.getZoneId().equals(""zoneid""));
    }
",non-flaky,5
53166,cloudfoundry_uaa,ScimGroupTests.testPatchDeleteMetaAttributes,"    @Test
    public void testPatchDeleteMetaAttributes(){
        assertEquals(""description"", group.getDescription());
        String[] attributes = new String[]{""description""};
        patch.getMeta().setAttributes(attributes);
        group.patch(patch);
        assertEquals(""NewDescription"", group.getDescription());

        patch.setDescription(null);
        group.patch(patch);
        assertNull(group.getDescription());
    }
",non-flaky,5
53167,cloudfoundry_uaa,ScimGroupTests.testDropDisplayName,"    @Test
    public void testDropDisplayName(){
        patch.setDisplayName(""NewDisplayName"");
        group.setDisplayName(""display"");
        assertEquals(""display"", group.getDisplayName());
        String[] attributes = new String[]{""displayname""};
        patch.getMeta().setAttributes(attributes);
        group.patch(patch);
        assertEquals(""NewDisplayName"", group.getDisplayName());

        patch.setDisplayName(null);
        group.patch(patch);
        assertNull(group.getDisplayName());
    }
",non-flaky,5
53168,cloudfoundry_uaa,ScimGroupTests.cant_drop_zone_id,"    @Test(expected = IllegalArgumentException.class)
    public void cant_drop_zone_id() {
        patch.getMeta().setAttributes(new String[] {""zoneID""});
        group.patch(patch);
    }
",non-flaky,5
53169,cloudfoundry_uaa,ScimGroupTests.cant_drop_id,"    @Test(expected = IllegalArgumentException.class)
    public void cant_drop_id() {
        patch.getMeta().setAttributes(new String[] {""id""});
        group.patch(patch);
    }
",non-flaky,5
53170,cloudfoundry_uaa,ScimGroupTests.testDropAllMembers,"    @Test
    public void testDropAllMembers(){
        group.setMembers(Arrays.asList(member1, member2, member3));
        assertEquals(3, group.getMembers().size());
        patch.getMeta().setAttributes(new String[] {""members""});
        group.patch(patch);
        assertEquals(0, group.getMembers().size());
    }
",non-flaky,5
53171,cloudfoundry_uaa,ScimGroupTests.testDropOneMembers,"    @Test
    public void testDropOneMembers(){
        group.setMembers(Arrays.asList(member1, member2, member3));
        ScimGroupMember member = new ScimGroupMember(member1.getMemberId());
        member.setOperation(""DELETE"");
        patch.setMembers(Arrays.asList(
            member
        ));
        group.patch(patch);
        assertEquals(2, group.getMembers().size());
    }
",non-flaky,5
53172,cloudfoundry_uaa,ScimGroupTests.testDropAllMembersUsingOperation,"    @Test
    public void testDropAllMembersUsingOperation() {
        member1.setOperation(""delete"");
        member2.setOperation(""delete"");
        member3.setOperation(""delete"");
        group.setMembers(Arrays.asList(member1, member2, member3));
        patch.setMembers(group.getMembers());
        assertEquals(3, group.getMembers().size());
        group.patch(patch);
        assertEquals(0, group.getMembers().size());

    }
",non-flaky,5
53173,cloudfoundry_uaa,ScimGroupTests.testAddAllMembers,"    @Test
    public void testAddAllMembers() {
        patch.setMembers(Arrays.asList(member1, member2, member3));
        group.setMembers(emptyList());
        assertEquals(0, group.getMembers().size());
        group.patch(patch);
        assertEquals(3, group.getMembers().size());

    }
",non-flaky,5
53174,cloudfoundry_uaa,ScimGroupTests.testAddOneMember,"    @Test
    public void testAddOneMember() {
        patch.setMembers(Arrays.asList(member1));
        group.setMembers(Arrays.asList(member2, member3));
        assertEquals(2, group.getMembers().size());
        group.patch(patch);
        assertEquals(3, group.getMembers().size());

    }
",non-flaky,5
53175,cloudfoundry_uaa,ScimGroupTests.test_toString,"    @Test
    public void test_toString() {
        group.toString();
    }
",non-flaky,5
53176,cloudfoundry_uaa,JsonDateDeserializerTest.testParsing,"    @Test
    public void testParsing() throws IOException, ParseException {
        Date d = JsonDateDeserializer.getDate(testDateString, new JsonLocation(null, 22, 0, 0));
        Assert.assertEquals(new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"").parse(testDateString).getTime(), (long) d.getTime());
    }
",non-flaky,5
53177,cloudfoundry_uaa,JsonDateDeserializerTest.testParsingParallel,"    @Test
    public void testParsingParallel() throws IOException, InterruptedException {
        Thread[] threadArray = new Thread[1000];
        for (int i = 0; i < 1000; i++) {

            threadArray[i] = new Thread(() -> {
                try {
                    Date d = JsonDateDeserializer.getDate(testDateString, new JsonLocation(null, 22, 0, 0));
                    if(new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"").parse(testDateString).getTime() != d.getTime())
                    {
                        throw new Exception(""Unexpected date"");
                    }
                } catch (Exception e) {
                    exceptionOccured = e;
                }
            });
        }
        for (int i = 0; i < 1000; i++) {
            threadArray[i].start();
        }
        for (int i = 0; i < 1000; i++) {
            threadArray[i].join();
        }
        Assert.assertNull(exceptionOccured);
    }
",non-flaky,5
53178,cloudfoundry_uaa,JsonDateSerializerTest.testFormatting,"    @Test
    public void testFormatting() throws IOException, ParseException {
        Date now = new Date();
        ByteArrayOutputStream bos = new ByteArrayOutputStream();
        JsonGenerator gen = new JsonFactory().createGenerator(bos);
        new JsonDateSerializer().serialize(now, gen, null);
        gen.close();
        Assert.assertEquals(String.format(""\""%s\"""", new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"").format(now)),
                bos.toString());
    }
",non-flaky,5
53179,cloudfoundry_uaa,JsonDateSerializerTest.testFormattingParallel,"    @Test
    public void testFormattingParallel() throws IOException, InterruptedException {
        Thread[] threadArray = new Thread[1000];
        for (int i = 0; i < 1000; i++) {

            threadArray[i] = new Thread(() -> {
                try {
                    Date now = new Date();
                    ByteArrayOutputStream bos = new ByteArrayOutputStream();
                    JsonGenerator gen = new JsonFactory().createGenerator(bos);
                    new JsonDateSerializer().serialize(now, gen, null);
                    gen.close();
                    if (!String.format(""\""%s\"""", new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm:ss.SSS'Z'"").format(now))
                            .equals(bos.toString())) {
                        throw new Exception(""Unexpected date"");
                    }

                } catch (Exception e) {
                    exceptionOccured = e;
                }
            });
        }
        for (

                int i = 0; i < 1000; i++) {
            threadArray[i].start();
        }
        for (int i = 0; i < 1000; i++) {
            threadArray[i].join();
        }
        Assert.assertNull(exceptionOccured);
    }
",non-flaky,5
53180,cloudfoundry_uaa,MfaProviderTest.testSerialize,"    @Test
    public void testSerialize() {

        MfaProvider<GoogleMfaProviderConfig> provider = createValidGoogleMfaProvider();
        provider.setCreated(new Date());
        provider.setLastModified(new Date());
        String string = JsonUtils.writeValueAsString(provider);
        JsonNode output = JsonUtils.readTree(JsonUtils.writeValueAsString(provider));
        assertEquals(output.get(""type"").textValue(), MfaProvider.MfaProviderType.GOOGLE_AUTHENTICATOR.toValue());
        JsonNode config = output.get(""config"");
        assertEquals(config.get(""issuer"").textValue(), ""current-zone"");
        assertEquals(config.get(""providerDescription"").textValue(), ""config description"");
    }
",non-flaky,5
53181,cloudfoundry_uaa,MfaProviderTest.testDeserialize,"    @Test
    public void testDeserialize() {
        String json = ""{\n"" +
                ""  \""type\"" : \""google-authenticator\"",\n"" +
                ""  \""config\"" : {\n"" +
                ""    \""providerDescription\"" : \""ddd\"",\n"" +
                ""    \""issuer\"": \""issuer\"",\n"" +
                ""    \""algorithm\"": \""SHA256\"",\n"" +
                ""    \""digits\"": 8, \n"" +
                ""    \""duration\"": 32 \n"" +
                ""  },\n"" +
                ""  \""name\"" : \""UAA Provider\"",  \n"" +
                ""  \""active\"" : true\n"" +
                ""}"";

        MfaProvider<GoogleMfaProviderConfig> provider = JsonUtils.readValue(json, MfaProvider.class);

        assertEquals(MfaProvider.MfaProviderType.GOOGLE_AUTHENTICATOR, provider.getType());
        assertEquals(""UAA Provider"", provider.getName());
        GoogleMfaProviderConfig config = provider.getConfig();
        assertEquals(""issuer"", config.getIssuer());
        assertEquals(""ddd"", config.getProviderDescription());
    }
",non-flaky,5
53182,cloudfoundry_uaa,MfaProviderTest.testDeserializeInvalidType,"    @Test
    public void testDeserializeInvalidType() {
        String json = ""{\n"" +
                ""  \""type\"" : \""invalid-type\"",\n"" +
                ""  \""config\"" : {\n"" +
                ""    \""providerDescription\"" : \""ddd\"",\n"" +
                ""    \""issuer\"": \""issuer\"",\n"" +
                ""    \""algorithm\"": \""SHA256\"",\n"" +
                ""    \""digits\"": 8, \n"" +
                ""    \""duration\"": 32 \n"" +
                ""  },\n"" +
                ""  \""name\"" : \""UAA Provider\"" \n"" +
                ""}"";

        MfaProvider<GoogleMfaProviderConfig> provider = JsonUtils.readValue(json, MfaProvider.class);

        assertEquals(null, provider.getType());
        assertEquals(""UAA Provider"", provider.getName());
        assertNull(provider.getConfig());
    }
",non-flaky,5
53183,cloudfoundry_uaa,MfaProviderTest.validateProviderActiveSetDefaultToTrue,"    @Test
    public void validateProviderActiveSetDefaultToTrue() {
        MfaProvider provider = createValidGoogleMfaProvider();
    }
",non-flaky,5
53184,cloudfoundry_uaa,GoogleMfaProviderConfigTest.testDefaultConfig,"    @Test
    public void testDefaultConfig() {
        config = new GoogleMfaProviderConfig();
        assertThat(config.getProviderDescription(), is(nullValue()));
        assertThat(config.getIssuer(), is(nullValue()));
    }
",non-flaky,5
53185,cloudfoundry_uaa,OpenIdConfigurationTests.testDefaultClaims,"    @Test
    public void testDefaultClaims() {
        assertEquals(""issuer"", defaultConfig.getIssuer());
        assertEquals(""/uaa/oauth/authorize"", defaultConfig.getAuthUrl());
        assertEquals(""/uaa/oauth/token"", defaultConfig.getTokenUrl());
        assertArrayEquals(new String[]{""client_secret_basic"", ""client_secret_post""}, defaultConfig.getTokenAMR());
        assertArrayEquals(new String[]{""RS256"", ""HS256""}, defaultConfig.getTokenEndpointAuthSigningValues());
        assertEquals(""/uaa/userinfo"", defaultConfig.getUserInfoUrl());
        assertEquals(""/uaa/token_keys"", defaultConfig.getJwksUri());
        assertArrayEquals(new String[]{""openid"", ""profile"", ""email"", ""phone"", ""roles"", ""user_attributes""}, defaultConfig.getScopes());
        assertArrayEquals(new String[]{""code"", ""code id_token"", ""id_token"", ""token id_token""}, defaultConfig.getResponseTypes());
        assertArrayEquals(new String[]{""public""}, defaultConfig.getSubjectTypesSupported());
        assertArrayEquals(new String[]{""RS256"", ""HS256""}, defaultConfig.getIdTokenSigningAlgValues());
        assertArrayEquals(new String[]{""none""}, defaultConfig.getRequestObjectSigningAlgValues());
        assertArrayEquals(new String[]{""normal""}, defaultConfig.getClaimTypesSupported());
        assertArrayEquals(
            new String[]{
                ""sub"", ""user_name"", ""origin"", ""iss"", ""auth_time"",
                ""amr"", ""acr"", ""client_id"", ""aud"", ""zid"", ""grant_type"",
                ""user_id"", ""azp"", ""scope"", ""exp"", ""iat"", ""jti"", ""rev_sig"",
                ""cid"", ""given_name"", ""family_name"", ""phone_number"", ""email""},
            defaultConfig.getClaimsSupported()
        );
        assertFalse(defaultConfig.isClaimsParameterSupported());
        assertEquals(""http://docs.cloudfoundry.org/api/uaa/"", defaultConfig.getServiceDocumentation());
        assertArrayEquals(new String[]{""en-US""}, defaultConfig.getUiLocalesSupported());
    }
",non-flaky,5
53186,cloudfoundry_uaa,UserInfoResponseJsonTests.deserializeTest,"    @Test
    public void deserializeTest() {
        UserInfoResponse response = JsonUtils.readValue(json, UserInfoResponse.class);
        assertEquals(""olds@vmware.com"", response.getEmail());
        assertEquals(""Dale"", response.getGivenName());
        assertEquals(""Olds"", response.getFamilyName());
        assertEquals(""Dale Olds"", response.getFullName());
        assertEquals(""8505551234"", response.getPhoneNumber());
        assertEquals(""12345"", response.getUserId());
        assertEquals(""12345"", response.getSub());
        assertEquals(""olds"", response.getUserName());
        assertEquals(true, response.isEmailVerified());

        assertThat(
            response.getUserAttributes().get(""Key 1""),
            hasItems(CoreMatchers.is(""Val 11""), CoreMatchers.is(""Val 12""))
        );
        assertThat(
            response.getUserAttributes().get(""Key 2""),
            hasItems(CoreMatchers.is(""Val 21""), CoreMatchers.is(""Val 22""))
        );

        assertThat(
            response.getRoles(),
            hasItems(
                CoreMatchers.is(""role12""),
                CoreMatchers.is(""role54""),
                CoreMatchers.is(""role134""),
                CoreMatchers.is(""role812"")
            )
        );
        assertEquals(Long.valueOf(1000L), response.previousLogonSuccess);
    }
",non-flaky,5
53187,cloudfoundry_uaa,UserInfoResponseJsonTests.serializeTest,"    @Test
    public void serializeTest() {
        UserInfoResponse response = JsonUtils.readValue(json, UserInfoResponse.class);
        json = JsonUtils.writeValueAsString(response);
        deserializeTest();
    }
",non-flaky,5
53188,cloudfoundry_uaa,ExternalIdentityProviderDefinitionTest.testEquals,"    @Test
    public void testEquals() {
        ExternalIdentityProviderDefinition definition1 = new ExternalIdentityProviderDefinition();
        definition1.setAddShadowUserOnLogin(true);
        ExternalIdentityProviderDefinition definition2 = new ExternalIdentityProviderDefinition();
        definition2.setAddShadowUserOnLogin(false);

        assertNotEquals(definition1, definition2);
        definition2.setAddShadowUserOnLogin(true);
        assertEquals(definition1, definition2);
    }
",non-flaky,5
53189,cloudfoundry_uaa,ExternalIdentityProviderDefinitionTest.testDefaultValueForStoreCustomAttributes,"    @Test
    public void testDefaultValueForStoreCustomAttributes() {
        assertTrue(definition.isStoreCustomAttributes());
    }
",non-flaky,5
53190,cloudfoundry_uaa,ExternalIdentityProviderDefinitionTest.testEquals2,"    @Test
    public void testEquals2() {
        ExternalIdentityProviderDefinition def = new ExternalIdentityProviderDefinition();
        def.setStoreCustomAttributes(false);
        assertFalse(definition.equals(def));
    }
",non-flaky,5
53191,cloudfoundry_uaa,OIDCIdentityProviderDefinitionTests.serialize_discovery_url,"    @Test
    public void serialize_discovery_url() throws MalformedURLException {
        OIDCIdentityProviderDefinition def = JsonUtils.readValue(defaultJson, OIDCIdentityProviderDefinition.class);
        assertNull(def.getDiscoveryUrl());
        def.setDiscoveryUrl(new URL(url));
        assertEquals(url, def.getDiscoveryUrl().toString());
        String json = JsonUtils.writeValueAsString(def);
        def = JsonUtils.readValue(json, OIDCIdentityProviderDefinition.class);
        assertEquals(url, def.getDiscoveryUrl().toString());
    }
",non-flaky,5
53192,cloudfoundry_uaa,OIDCIdentityProviderDefinitionTests.serialize_prompts,"    @Test
    public void serialize_prompts() {
        OIDCIdentityProviderDefinition def = JsonUtils.readValue(defaultJson, OIDCIdentityProviderDefinition.class);
        assertNull(def.getPrompts());
        List<Prompt> prompts = Arrays.asList(new Prompt(""username"", ""text"", ""Email""),
                new Prompt(""password"", ""password"", ""Password""),
                new Prompt(""passcode"", ""password"", ""Temporary Authentication Code (Get on at /passcode)""));
        def.setPrompts(prompts);
        String json = JsonUtils.writeValueAsString(def);
        def = JsonUtils.readValue(json, OIDCIdentityProviderDefinition.class);
        assertEquals(prompts, def.getPrompts());
    }
",non-flaky,5
53193,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testQRCodeScreen,"    @Test
    public void testQRCodeScreen() throws Exception {
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        String imageSrc = webDriver.findElement(By.id(""qr"")).getAttribute(""src"");

        String secretKey = getSecretFromQrImageString(imageSrc);

        webDriver.findElement(By.id(""Next"")).click();
        verifyCodeOnRegistration(secretKey, ""/"");
    }
",non-flaky,5
53194,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.force_password_happens_after_MFA,"    @Test
    public void force_password_happens_after_MFA() throws Exception {
        IntegrationTestUtils.updateUserToForcePasswordChange(
            getRestTemplate(),
            baseUrl,
            adminAccessToken,
            user.getId(),
            mfaZone.getId()
        );

        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        String imageSrc = webDriver.findElement(By.id(""qr"")).getAttribute(""src"");

        String secretKey = getSecretFromQrImageString(imageSrc);

        webDriver.findElement(By.id(""Next"")).click();
        verifyCodeOnRegistration(secretKey, ""/force_password_change"");


    }
",non-flaky,5
53195,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testQRCodeScreenAfterRegistrationDeletion,"    @Test
    public void testQRCodeScreenAfterRegistrationDeletion() throws Exception {
        // register mfa for user and logout
        testQRCodeScreen();
        webDriver.get(zoneUrl + ""/logout.do"");

        // retrieve user id and delete mfa registration
        RestTemplate client = getRestTemplate();
        HttpHeaders headers = new HttpHeaders();
        headers.add(""Authorization"", ""Bearer "" + zoneAdminToken);
        headers.add(""X-Identity-Zone-Id"", mfaZone.getId());
        headers.add(""Content-Type"", ""application/json"");
        Map<String, String> uriParams = new HashMap<>();
        uriParams.put(""filter"",""userName eq \""""+username+""\"""");
        ResponseEntity<Map> exchange = client.exchange(serverRunning.getUrl(""/Users?attributes=id&filter={filter}""), HttpMethod.GET, new HttpEntity<Void>(
            headers), Map.class, uriParams);
        String userId = (String) ((Map)((java.util.List) exchange.getBody().get(""resources"")).get(0)).get(""id"");

        client.exchange(serverRunning.getUrl(""/Users/{userId}/mfa""), HttpMethod.DELETE, new HttpEntity<Void>(
            headers), Map.class, userId);

        // user login should end up at mfa registration page
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());
    }
",non-flaky,5
53196,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testMfaRegisterPageWithoutLoggingIn,"    @Test
    public void testMfaRegisterPageWithoutLoggingIn() {
        webDriver.get(zoneUrl + ""/logout.do"");
        webDriver.get(zoneUrl + ""/login/mfa/register"");
        assertEquals(zoneUrl + ""/login"", webDriver.getCurrentUrl());
    }
",non-flaky,5
53197,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testMfaVerifyPageWithoutLoggingIn,"    @Test
    public void testMfaVerifyPageWithoutLoggingIn() {
        webDriver.get(zoneUrl + ""/logout.do"");
        webDriver.get(zoneUrl + ""/login/mfa/verify"");
        assertEquals(zoneUrl + ""/login"", webDriver.getCurrentUrl());
    }
",non-flaky,5
53198,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testQRCodeValidation,"    @Test
    public void testQRCodeValidation() {
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        webDriver.findElement(By.id(""Next"")).click();
        assertEquals(zoneUrl + ""/login/mfa/verify"", webDriver.getCurrentUrl());
        webDriver.findElement(By.name(""code"")).sendKeys(""1111111111111111112222"");

        webDriver.findElement(By.id(""verify_code_btn"")).click();
        assertEquals(""Incorrect code, please try again."", webDriver.findElement(By.cssSelector(""form .error-color"")).getText());
    }
",non-flaky,5
53199,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.checkAccessForTotpPage,"    @Test
    public void checkAccessForTotpPage() throws Exception {
        webDriver.get(zoneUrl + ""/logout.do"");
        webDriver.manage().deleteAllCookies();
        webDriver.get(zoneUrl + ""/login/mfa/register"");
        assertEquals(zoneUrl + ""/login"", webDriver.getCurrentUrl());
    }
",non-flaky,5
53200,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testDisplayIdentityZoneNameOnRegisterPage,"    @Test
    public void testDisplayIdentityZoneNameOnRegisterPage() {
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        assertEquals(webDriver.findElement(By.id(""mfa-identity-zone"")).getText(), mfaZone.getName());
    }
",non-flaky,5
53201,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testDisplayIdentityZoneNameOnVerifyPage,"    @Test
    public void testDisplayIdentityZoneNameOnVerifyPage() {
        performLogin(username);
        webDriver.findElement(By.id(""Next"")).click();

        assertEquals(zoneUrl + ""/login/mfa/verify"", webDriver.getCurrentUrl());
        assertEquals(webDriver.findElement(By.id(""mfa-identity-zone"")).getText(), mfaZone.getName());

        webDriver.findElement(By.id(""verify_code_btn"")).click();
        assertEquals(webDriver.findElement(By.id(""mfa-identity-zone"")).getText(), mfaZone.getName());
    }
",non-flaky,5
53202,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testManualMfaRegistrationFlow,"    @Test
    public void testManualMfaRegistrationFlow() {
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        webDriver.findElement(By.linkText(""manual setup instructions"")).click();

        assertEquals(zoneUrl + ""/login/mfa/manual"", webDriver.getCurrentUrl());

        String key = webDriver.findElement(By.id(""key"")).getText();
        String account = webDriver.findElement(By.id(""account"")).getText();
        assertFalse(""secret not found"", key.isEmpty());
        assertFalse(""account not found"", account.isEmpty());

        webDriver.findElement(By.id(""Next"")).click();
        assertEquals(zoneUrl + ""/login/mfa/verify"", webDriver.getCurrentUrl());

        verifyCodeOnRegistration(key, ""/"");
    }
",non-flaky,5
53203,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testQRCodeScreen_ClickManualAndReturn,"    @Test
    public void testQRCodeScreen_ClickManualAndReturn() throws Exception{
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        webDriver.findElement(By.linkText(""manual setup instructions"")).click();
        assertEquals(zoneUrl + ""/login/mfa/manual"", webDriver.getCurrentUrl());

        webDriver.findElement(By.id(""Back"")).click();
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        String imageSrc = webDriver.findElement(By.id(""qr"")).getAttribute(""src"");

        String secretKey = getSecretFromQrImageString(imageSrc);

        webDriver.findElement(By.id(""Next"")).click();
        verifyCodeOnRegistration(secretKey, ""/"");
    }
",non-flaky,5
53204,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testManualMfaRegistrationFlow_ClickBackAndManual,"    @Test
    public void testManualMfaRegistrationFlow_ClickBackAndManual() {
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        webDriver.findElement(By.linkText(""manual setup instructions"")).click();
        assertEquals(zoneUrl + ""/login/mfa/manual"", webDriver.getCurrentUrl());

        webDriver.findElement(By.id(""Back"")).click();
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        webDriver.findElement(By.linkText(""manual setup instructions"")).click();
        assertEquals(zoneUrl + ""/login/mfa/manual"", webDriver.getCurrentUrl());

        String key = webDriver.findElement(By.id(""key"")).getText();
        String account = webDriver.findElement(By.id(""account"")).getText();
        assertFalse(""secret not found"", key.isEmpty());
        assertFalse(""account not found"", account.isEmpty());

        webDriver.findElement(By.id(""Next"")).click();
        assertEquals(zoneUrl + ""/login/mfa/verify"", webDriver.getCurrentUrl());

        verifyCodeOnRegistration(key, ""/"");
    }
",non-flaky,5
53205,cloudfoundry_uaa,TotpMfaEndpointIntegrationTests.testQRCodeScreen_ClickManualClickNextClickBack,"    @Test
    public void testQRCodeScreen_ClickManualClickNextClickBack() throws Exception{
        performLogin(username);
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        webDriver.findElement(By.linkText(""manual setup instructions"")).click();
        assertEquals(zoneUrl + ""/login/mfa/manual"", webDriver.getCurrentUrl());

        webDriver.findElement(By.id(""Next"")).click();
        assertEquals(zoneUrl + ""/login/mfa/verify"", webDriver.getCurrentUrl());

        webDriver.findElement(By.id(""Back"")).click();
        assertEquals(zoneUrl + ""/login/mfa/register"", webDriver.getCurrentUrl());

        String imageSrc = webDriver.findElement(By.id(""qr"")).getAttribute(""src"");

        String secretKey = getSecretFromQrImageString(imageSrc);

        assertFalse(""secret not found"", secretKey.isEmpty());

        webDriver.findElement(By.id(""Next"")).click();
        verifyCodeOnRegistration(secretKey, ""/"");
    }
",non-flaky,5
53206,cloudfoundry_uaa,CfAuthenticationTests.testDefaultScopes,"    @Test
    public void testDefaultScopes() {
        params.set(
                        ""credentials"",
                        String.format(""{\""username\"":\""%s\"",\""password\"":\""%s\""}"", testAccounts.getUserName(),
                                        testAccounts.getPassword()));
        ResponseEntity<Void> response = serverRunning.postForResponse(serverRunning.getAuthorizationUri(), headers,
                        params);
        assertEquals(HttpStatus.FOUND, response.getStatusCode());
        String location = response.getHeaders().getLocation().toString();
        assertTrue(""Not authenticated (no access token): "" + location, location.contains(""access_token""));
    }
",non-flaky,5
53207,cloudfoundry_uaa,CfAuthenticationTests.testInvalidScopes,"    @Test
    public void testInvalidScopes() {
        params.set(
                        ""credentials"",
                        String.format(""{\""username\"":\""%s\"",\""password\"":\""%s\""}"", testAccounts.getUserName(),
                                        testAccounts.getPassword()));
        params.set(""scope"", ""read"");
        ResponseEntity<Void> response = serverRunning.postForResponse(serverRunning.getAuthorizationUri(), headers,
                        params);
        assertEquals(HttpStatus.FOUND, response.getStatusCode());
        String location = response.getHeaders().getLocation().toString();
        // System.err.println(location);
        assertTrue(location.startsWith(params.getFirst(""redirect_uri"")));
        assertTrue(location.contains(""error=invalid_scope""));
        assertFalse(location.contains(""credentials=""));
    }
",non-flaky,5
53208,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.getGroupsWithoutAttributesReturnsAllData,"    @Test
    public void getGroupsWithoutAttributesReturnsAllData() {
        @SuppressWarnings(""rawtypes"")
        ResponseEntity<Map> response = client.getForEntity(serverRunning.getUrl(groupEndpoint), Map.class);

        @SuppressWarnings(""rawtypes"")
        Map results = response.getBody();
        assertEquals(HttpStatus.OK, response.getStatusCode());
        assertTrue(""There should be more than zero users"", (Integer) results.get(""totalResults"") > 0);
        assertTrue(""There should be some resources"", ((Collection<?>) results.get(""resources"")).size() > 0);
        @SuppressWarnings(""rawtypes"")
        Map firstGroup = (Map) ((List) results.get(""resources"")).get(0);
        assertTrue(firstGroup.containsKey(""id""));
        assertTrue(firstGroup.containsKey(""displayName""));
        assertTrue(firstGroup.containsKey(""schemas""));
        assertTrue(firstGroup.containsKey(""meta""));
    }
",non-flaky,5
53209,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.createGroupSucceeds,"    @Test
    public void createGroupSucceeds() throws Exception {
        ScimGroup g1 = createGroup(CFID);
        // Check we can GET the group
        ScimGroup g2 = client.getForObject(serverRunning.getUrl(groupEndpoint + ""/{id}""), ScimGroup.class, g1.getId());
        assertEquals(g1, g2);
    }
",non-flaky,5
53210,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.createGroupWithMembersSucceeds,"    @Test
    public void createGroupWithMembersSucceeds() {
        ScimGroup g1 = createGroup(CFID, JOEL, DALE, VIDYA);
        // Check we can GET the group
        ScimGroup g2 = client.getForObject(serverRunning.getUrl(groupEndpoint + ""/{id}""), ScimGroup.class, g1.getId());
        assertEquals(g1, g2);
        assertEquals(3, g2.getMembers().size());
        assertTrue(g2.getMembers().contains(JOEL));
        assertTrue(g2.getMembers().contains(DALE));
        assertTrue(g2.getMembers().contains(VIDYA));

        // check that User.groups is updated
        validateUserGroups(JOEL.getMemberId(), CFID);
        validateUserGroups(DALE.getMemberId(), CFID);
        validateUserGroups(VIDYA.getMemberId(), CFID);
    }
",non-flaky,5
53211,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.createGroupWithInvalidMembersFailsCorrectly,"    @Test
    public void createGroupWithInvalidMembersFailsCorrectly() {
        ScimGroup g = new ScimGroup(null, CFID, IdentityZoneHolder.get().getId());
        ScimGroupMember m2 = new ScimGroupMember(""wrongid"");
        g.setMembers(Arrays.asList(VIDYA, m2));

        @SuppressWarnings(""rawtypes"")
        ResponseEntity<Map> r = client.postForEntity(serverRunning.getUrl(groupEndpoint), g, Map.class);
        @SuppressWarnings(""unchecked"")
        Map<String, String> g1 = r.getBody();
        assertEquals(HttpStatus.BAD_REQUEST, r.getStatusCode());
        assertTrue(g1.containsKey(""error""));
        assertTrue(g1.containsKey(""message""));
        assertTrue(g1.get(""message"").contains(""Invalid group member""));

        // check that the group was not created
        @SuppressWarnings(""unchecked"")
        Map<String, String> g2 = client.getForObject(
            serverRunning.getUrl(groupEndpoint + ""?filter=displayName eq \""{name}\""""), Map.class, CFID);
        assertTrue(g2.containsKey(""totalResults""));
        assertEquals(0, g2.get(""totalResults""));
    }
",non-flaky,5
53212,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.createGroupWithMemberGroupSucceeds,"    @Test
    public void createGroupWithMemberGroupSucceeds() {
        ScimGroup g1 = createGroup(CFID, VIDYA);
        ScimGroupMember m2 = new ScimGroupMember(g1.getId(), ScimGroupMember.Type.GROUP);
        ScimGroup g2 = createGroup(CF_DEV, m2);

        // Check we can GET the group
        ScimGroup g3 = client.getForObject(serverRunning.getUrl(groupEndpoint + ""/{id}""), ScimGroup.class, g2.getId());
        assertEquals(g2, g3);
        assertEquals(1, g3.getMembers().size());
        assertTrue(g3.getMembers().contains(m2));

        // check that User.groups is updated
        validateUserGroups(VIDYA.getMemberId(), CFID, CF_DEV);
    }
",non-flaky,5
53213,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.createExistingGroupFailsCorrectly,"    @Test
    public void createExistingGroupFailsCorrectly() {
        ScimGroup g1 = createGroup(CFID);
        @SuppressWarnings(""unchecked"")
        Map<String, String> g2 = client.postForEntity(serverRunning.getUrl(groupEndpoint), g1, Map.class).getBody();
        assertTrue(g2.containsKey(""error""));
        assertEquals(""scim_resource_already_exists"", g2.get(""error""));
    }
",non-flaky,5
53214,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.deleteGroupUpdatesUser,"    @Test
    public void deleteGroupUpdatesUser() {
        ScimGroup g1 = createGroup(DELETE_ME, DALE, VIDYA);
        validateUserGroups(DALE.getMemberId(), DELETE_ME);
        validateUserGroups(VIDYA.getMemberId(), DELETE_ME);

        deleteResource(groupEndpoint, g1.getId());

        // check that the group does not exist anymore
        @SuppressWarnings(""unchecked"")
        Map<String, Object> g2 = client.getForObject(
            serverRunning.getUrl(groupEndpoint + ""?filter=displayName eq \""{name}\""""), Map.class, DELETE_ME);
        assertTrue(g2.containsKey(""totalResults""));
        assertEquals(0, g2.get(""totalResults""));

        // check that group membership is updated
        validateUserGroups(DALE.getMemberId());
        validateUserGroups(VIDYA.getMemberId());
    }
",non-flaky,5
53215,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.deleteNonExistentGroupFailsCorrectly,"    @Test
    public void deleteNonExistentGroupFailsCorrectly() {
        @SuppressWarnings(""unchecked"")
        Map<String, Object> g = deleteResource(groupEndpoint, DELETE_ME).getBody();
        assertTrue(g.containsKey(""error""));
        assertEquals(""scim_resource_not_found"", g.get(""error""));
    }
",non-flaky,5
53216,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.deleteMemberGroupUpdatesGroup,"    @Test
    public void deleteMemberGroupUpdatesGroup() {
        ScimGroup g1 = createGroup(CFID, VIDYA);
        ScimGroupMember m2 = new ScimGroupMember(g1.getId(), ScimGroupMember.Type.GROUP);
        ScimGroup g2 = createGroup(CF_DEV, DALE, m2);
        assertTrue(g2.getMembers().contains(m2));
        validateUserGroups(VIDYA.getMemberId(), CFID, CF_DEV);

        deleteResource(groupEndpoint, g1.getId());

        // check that parent group is updated
        ScimGroup g3 = client.getForObject(serverRunning.getUrl(groupEndpoint + ""/{id}""), ScimGroup.class, g2.getId());
        assertEquals(1, g3.getMembers().size());
        assertFalse(g3.getMembers().contains(m2));
    }
",non-flaky,5
53217,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.testDeleteMemberUserUpdatesGroups,"    @Test
    public void testDeleteMemberUserUpdatesGroups() {
        ScimGroupMember toDelete = new ScimGroupMember(createUser(DELETE_ME, ""Passwo3d"").getId());
        ScimGroup g1 = createGroup(CFID, JOEL, DALE, toDelete);
        ScimGroup g2 = createGroup(CF_MGR, DALE, toDelete);
        deleteResource(userEndpoint, toDelete.getMemberId());

        // check that membership has been updated
        ScimGroup g3 = client.getForObject(serverRunning.getUrl(groupEndpoint + ""/{id}""), ScimGroup.class, g1.getId());
        assertEquals(2, g3.getMembers().size());
        assertFalse(g3.getMembers().contains(toDelete));

        g3 = client.getForObject(serverRunning.getUrl(groupEndpoint + ""/{id}""), ScimGroup.class, g2.getId());
        assertEquals(1, g3.getMembers().size());
        assertFalse(g3.getMembers().contains(toDelete));
    }
",non-flaky,5
53218,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.testUpdateGroupUpdatesMemberUsers,"    @Test
    public void testUpdateGroupUpdatesMemberUsers() {
        ScimGroup g1 = createGroup(CFID, JOEL, VIDYA);
        ScimGroup g2 = createGroup(CF_MGR, DALE);
        ScimGroupMember m1 = new ScimGroupMember(g1.getId(), ScimGroupMember.Type.GROUP);
        ScimGroupMember m2 = new ScimGroupMember(g2.getId(), ScimGroupMember.Type.GROUP);
        ScimGroup g3 = createGroup(CF_DEV, m1, m2);

        validateUserGroups(JOEL.getMemberId(), CFID, CF_DEV);
        validateUserGroups(VIDYA.getMemberId(), CFID, CF_DEV);
        validateUserGroups(DALE.getMemberId(), CF_MGR, CF_DEV);

        ScimGroup g4 = updateGroup(g3.getId(), ""new_name"", m1);

        // check that we did not create a new group, but only updated the
        // existing one
        assertEquals(g3, g4);
        // check that member users were updated
        validateUserGroups(DALE.getMemberId(), CF_MGR);
        validateUserGroups(JOEL.getMemberId(), CFID, ""new_name"");
        validateUserGroups(VIDYA.getMemberId(), CFID, ""new_name"");
    }
",non-flaky,5
53219,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.testAccessTokenReflectsGroupMembership,"    @Test
    public void testAccessTokenReflectsGroupMembership() throws Exception {

        createTestClient(DELETE_ME, ""secret"", CFID);
        ScimUser user = createUser(DELETE_ME, ""Passwo3d"");
        createGroup(CFID, new ScimGroupMember(user.getId()));
        OAuth2AccessToken token = getAccessToken(DELETE_ME, ""secret"", DELETE_ME, ""Passwo3d"");
        assertTrue(""Wrong token: "" + token, token.getScope().contains(CFID));

        deleteTestClient(DELETE_ME);
        deleteResource(userEndpoint, user.getId());

    }
",non-flaky,5
53220,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.testAccessTokenReflectsGroupMembershipForPasswordGrant,"    @Test
    public void testAccessTokenReflectsGroupMembershipForPasswordGrant() throws Exception {

        createTestClient(DELETE_ME, ""secret"", CFID);
        ScimUser user = createUser(DELETE_ME, ""Passwo3d"");
        createGroup(CFID, new ScimGroupMember(user.getId()));
        OAuth2AccessToken token = getAccessTokenWithPassword(DELETE_ME, ""secret"", DELETE_ME, ""Passwo3d"");
        assertTrue(""Wrong token: "" + token, token.getScope().contains(CFID));

        deleteTestClient(DELETE_ME);
        deleteResource(userEndpoint, user.getId());

    }
",non-flaky,5
53221,cloudfoundry_uaa,ScimGroupEndpointsIntegrationTests.testExtremeGroupPagination,"    @Test
    public void testExtremeGroupPagination() {
        for (int i = 0; i < 502; i++) {
            ScimUser user = createUser(""deleteme_"" + new RandomValueStringGenerator().generate().toLowerCase(), ""Passwo3d"");
            scimGroups.add(createGroup(""cfid_"" + new RandomValueStringGenerator().generate().toLowerCase(), new ScimGroupMember(user.getId())));
        }

        ResponseEntity<Map> response = client.getForEntity(serverRunning.getUrl(groupEndpoint + ""?count=502""), Map.class);

        Map results = response.getBody();
        assertThat(response.getStatusCode(), is(HttpStatus.OK));
        assertThat((Integer) results.get(""totalResults""), greaterThan(500));
        assertThat((List<?>) results.get(""resources""), hasSize(500));
        assertThat(results.get(""itemsPerPage""), is(500));
        assertThat(results.get(""startIndex""), is(1));

    }
",non-flaky,5
53222,cloudfoundry_uaa,SamlLoginIT.testContentTypes,"    @Test
    public void testContentTypes() {
        String loginUrl = baseUrl + ""/login"";
        HttpHeaders jsonHeaders = new HttpHeaders();
        jsonHeaders.add(""Accept"", ""application/json"");
        ResponseEntity<Map> jsonResponseEntity = restOperations.exchange(loginUrl,
            HttpMethod.GET,
            new HttpEntity<>(jsonHeaders),
            Map.class);
        assertThat(jsonResponseEntity.getHeaders().get(""Content-Type"").get(0), containsString(APPLICATION_JSON_VALUE));

        HttpHeaders htmlHeaders = new HttpHeaders();
        htmlHeaders.add(""Accept"", ""text/html"");
        ResponseEntity<Void> htmlResponseEntity = restOperations.exchange(loginUrl,
            HttpMethod.GET,
            new HttpEntity<>(htmlHeaders),
            Void.class);
        assertThat(htmlResponseEntity.getHeaders().get(""Content-Type"").get(0), containsString(TEXT_HTML_VALUE));

        HttpHeaders defaultHeaders = new HttpHeaders();
        defaultHeaders.add(""Accept"", ""*/*"");
        ResponseEntity<Void> defaultResponseEntity = restOperations.exchange(loginUrl,
            HttpMethod.GET,
            new HttpEntity<>(defaultHeaders),
            Void.class);
        assertThat(defaultResponseEntity.getHeaders().get(""Content-Type"").get(0), containsString(TEXT_HTML_VALUE));
    }
",non-flaky,5
53223,cloudfoundry_uaa,SamlLoginIT.testSimpleSamlPhpPasscodeRedirect,"    @Test
    public void testSimpleSamlPhpPasscodeRedirect() throws Exception {
        testSimpleSamlLogin(""/passcode"", ""Temporary Authentication Code"");
    }
",non-flaky,5
53224,cloudfoundry_uaa,SamlLoginIT.testSimpleSamlLoginWithAddShadowUserOnLoginFalse,"    @Test
    public void testSimpleSamlLoginWithAddShadowUserOnLoginFalse() throws Exception {
        // Deleting marissa@test.org from simplesamlphp because previous SAML authentications automatically
        // create a UAA user with the email address as the username.
        deleteUser(SAML_ORIGIN, testAccounts.getEmail());

        IdentityProvider provider = IntegrationTestUtils.createIdentityProvider(SAML_ORIGIN, false, baseUrl, serverRunning);
        String clientId = ""app-addnew-false""+ new RandomValueStringGenerator().generate();
        String redirectUri = ""http://nosuchhostname:0/nosuchendpoint"";
        BaseClientDetails client = createClientAndSpecifyProvider(clientId, provider, redirectUri);

        String firstUrl = ""/oauth/authorize?""
                + ""client_id="" + clientId
                + ""&response_type=code""
                + ""&redirect_uri="" + URLEncoder.encode(redirectUri, ""UTF-8"");

        webDriver.get(baseUrl + firstUrl);
        webDriver.findElement(By.xpath(""//h2[contains(text(), 'Enter your username and password')]""));
        webDriver.findElement(By.name(""username"")).clear();
        webDriver.findElement(By.name(""username"")).sendKeys(testAccounts.getUserName());
        webDriver.findElement(By.name(""password"")).sendKeys(testAccounts.getPassword());
        webDriver.findElement(By.xpath(""//input[@value='Login']"")).click();

        // We need to verify the last request URL through the performance log because the redirect
        // URI does not exist. When the webDriver follows the non-existent redirect URI it receives a
        // connection refused error so webDriver.getCurrentURL() will remain as the SAML IdP URL.

        List<LogEntry> logEntries = webDriver.manage().logs().get(LogType.PERFORMANCE).getAll();
        List<String> logMessages = logEntries.stream().map(logEntry -> logEntry.getMessage()).collect(Collectors.toList());

        assertThat(logMessages, hasItem(containsString(redirectUri + ""?error=access_denied&error_description=SAML+user+does+not+exist.+You+can+correct+this+by+creating+a+shadow+user+for+the+SAML+user."")));
    }
",non-flaky,5
53225,cloudfoundry_uaa,SamlLoginIT.failureResponseFromSamlIDP_showErrorFromSaml,"    @Test
    public void failureResponseFromSamlIDP_showErrorFromSaml() throws Exception {
        String zoneId = ""testzone3"";
        String zoneUrl = baseUrl.replace(""localhost"",zoneId+"".localhost"");

        //identity client token
        RestTemplate identityClient = IntegrationTestUtils.getClientCredentialsTemplate(
            IntegrationTestUtils.getClientCredentialsResource(baseUrl, new String[]{""zones.write"", ""zones.read"", ""scim.zones""}, ""identity"", ""identitysecret"")
        );
        RestTemplate adminClient = IntegrationTestUtils.getClientCredentialsTemplate(
            IntegrationTestUtils.getClientCredentialsResource(baseUrl, new String[0], ""admin"", ""adminsecret"")
        );
        //create the zone

        IntegrationTestUtils.createZoneOrUpdateSubdomain(identityClient, baseUrl, zoneId, zoneId, null);

        //create a zone admin user
        String email = new RandomValueStringGenerator().generate() +""@samltesting.org"";
        ScimUser user = IntegrationTestUtils.createUser(adminClient, baseUrl,email ,""firstname"", ""lastname"", email, true);
        String groupId = IntegrationTestUtils.findGroupId(adminClient, baseUrl, ""zones."" + zoneId + "".admin"");
        IntegrationTestUtils.addMemberToGroup(adminClient, baseUrl, user.getId(), groupId);

        //get the zone admin token
        String zoneAdminToken =
            IntegrationTestUtils.getAccessTokenByAuthCode(serverRunning,
                UaaTestAccounts.standard(serverRunning),
                ""identity"",
                ""identitysecret"",
                email,
                ""secr3T"");

        SamlIdentityProviderDefinition samlIdentityProviderDefinition = createSimplePHPSamlIDP(SAML_ORIGIN, ""testzone3"");
        IdentityProvider provider = new IdentityProvider();
        provider.setIdentityZoneId(zoneId);
        provider.setType(OriginKeys.SAML);
        provider.setActive(true);
        provider.setConfig(samlIdentityProviderDefinition);
        provider.setOriginKey(samlIdentityProviderDefinition.getIdpEntityAlias());
        provider.setName(""simplesamlphp for testzone2"");

        IntegrationTestUtils.createOrUpdateProvider(zoneAdminToken, baseUrl, provider);

        webDriver.get(zoneUrl);
        webDriver.findElement(By.linkText(""Login with Simple SAML PHP(simplesamlphp)"")).click();
        webDriver.findElement(By.xpath(""//h2[contains(text(), 'Enter your username and password')]""));
        webDriver.findElement(By.name(""username"")).clear();
        webDriver.findElement(By.name(""username"")).sendKeys(testAccounts.getUserName());
        webDriver.findElement(By.name(""password"")).sendKeys(testAccounts.getPassword());
        webDriver.findElement(By.xpath(""//input[@value='Login']"")).click();

        assertEquals(""No local entity found for alias invalid, verify your configuration."", webDriver.findElement(By.cssSelector(""h2"")).getText());
    }
",non-flaky,5
53226,cloudfoundry_uaa,SamlLoginIT.testSimpleSamlPhpLogin,"    @Test
    public void testSimpleSamlPhpLogin() throws Exception {
        Long beforeTest = System.currentTimeMillis();
        testSimpleSamlLogin(""/login"", ""Where to?"");
        Long afterTest = System.currentTimeMillis();
        String zoneAdminToken = IntegrationTestUtils.getClientCredentialsToken(serverRunning, ""admin"", ""adminsecret"");
        ScimUser user = IntegrationTestUtils.getUser(zoneAdminToken, baseUrl, SAML_ORIGIN, testAccounts.getEmail());
        IntegrationTestUtils.validateUserLastLogon(user, beforeTest, afterTest);
    }
",non-flaky,5
60862,apache_druid,DistinctCountTopNQueryTest.testTopNWithDistinctCountAgg,"  @Test
  public void testTopNWithDistinctCountAgg() throws Exception
  {
    TopNQueryEngine engine = new TopNQueryEngine(pool);

    IncrementalIndex index = new OnheapIncrementalIndex.Builder()
        .setIndexSchema(
            new IncrementalIndexSchema.Builder()
                .withQueryGranularity(Granularities.SECOND)
                .withMetrics(new CountAggregatorFactory(""cnt""))
                .build()
        )
        .setMaxRowCount(1000)
        .build();

    String visitor_id = ""visitor_id"";
    String client_type = ""client_type"";
    DateTime time = DateTimes.of(""2016-03-04T00:00:00.000Z"");
    long timestamp = time.getMillis();
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""0"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""1"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""2"", client_type, ""android"")
        )
    );

    TopNQuery query = new TopNQueryBuilder().dataSource(QueryRunnerTestHelper.DATA_SOURCE)
                          .granularity(QueryRunnerTestHelper.ALL_GRAN)
                          .intervals(QueryRunnerTestHelper.FULL_ON_INTERVAL_SPEC)
                          .dimension(client_type)
                          .metric(""UV"")
                          .threshold(10)
                          .aggregators(
                              QueryRunnerTestHelper.ROWS_COUNT,
                              new DistinctCountAggregatorFactory(""UV"", visitor_id, null)
                          )
                          .build();

    final Iterable<Result<TopNResultValue>> results =
        engine.query(query, new IncrementalIndexStorageAdapter(index), null).toList();

    List<Result<TopNResultValue>> expectedResults = Collections.singletonList(
        new Result<>(
            time,
            new TopNResultValue(
                Arrays.<Map<String, Object>>asList(
                    ImmutableMap.of(
                        client_type, ""iphone"",
                        ""UV"", 2L,
                        ""rows"", 2L
                    ),
                    ImmutableMap.of(
                        client_type, ""android"",
                        ""UV"", 1L,
                        ""rows"", 1L
                    )
                )
            )
        )
    );
    TestHelper.assertExpectedResults(expectedResults, results);
  }
",non-flaky,5
60863,apache_druid,DistinctCountTimeseriesQueryTest.testTimeseriesWithDistinctCountAgg,"  @Test
  public void testTimeseriesWithDistinctCountAgg() throws Exception
  {
    TimeseriesQueryEngine engine = new TimeseriesQueryEngine();

    IncrementalIndex index = new OnheapIncrementalIndex.Builder()
        .setIndexSchema(
            new IncrementalIndexSchema.Builder()
                .withQueryGranularity(Granularities.SECOND)
                .withMetrics(new CountAggregatorFactory(""cnt""))
                .build()
        )
        .setMaxRowCount(1000)
        .build();

    String visitor_id = ""visitor_id"";
    String client_type = ""client_type"";
    DateTime time = DateTimes.of(""2016-03-04T00:00:00.000Z"");
    long timestamp = time.getMillis();
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""0"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""1"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""2"", client_type, ""android"")
        )
    );

    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()
                                  .dataSource(QueryRunnerTestHelper.DATA_SOURCE)
                                  .granularity(QueryRunnerTestHelper.ALL_GRAN)
                                  .intervals(QueryRunnerTestHelper.FULL_ON_INTERVAL_SPEC)
                                  .aggregators(
                                      Lists.newArrayList(
                                          QueryRunnerTestHelper.ROWS_COUNT,
                                          new DistinctCountAggregatorFactory(""UV"", visitor_id, null)
                                      )
                                  )
                                  .build();

    final Iterable<Result<TimeseriesResultValue>> results =
        engine.process(query, new IncrementalIndexStorageAdapter(index)).toList();

    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(
        new Result<>(
            time,
            new TimeseriesResultValue(
                ImmutableMap.of(""UV"", 3, ""rows"", 3L)
            )
        )
    );
    TestHelper.assertExpectedResults(expectedResults, results);
  }
",non-flaky,5
60864,apache_druid,DistinctCountGroupByQueryTest.testGroupByWithDistinctCountAgg,"  @Test
  public void testGroupByWithDistinctCountAgg() throws Exception
  {
    IncrementalIndex index = new OnheapIncrementalIndex.Builder()
        .setIndexSchema(
            new IncrementalIndexSchema.Builder()
                .withQueryGranularity(Granularities.SECOND)
                .withMetrics(new CountAggregatorFactory(""cnt""))
                .build()
        )
        .setConcurrentEventAdd(true)
        .setMaxRowCount(1000)
        .build();

    String visitor_id = ""visitor_id"";
    String client_type = ""client_type"";
    long timestamp = DateTimes.of(""2010-01-01"").getMillis();
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""0"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp + 1,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""1"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp + 2,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""2"", client_type, ""android"")
        )
    );

    GroupByQuery query = new GroupByQuery.Builder()
        .setDataSource(QueryRunnerTestHelper.DATA_SOURCE)
        .setGranularity(QueryRunnerTestHelper.ALL_GRAN)
        .setDimensions(new DefaultDimensionSpec(
            client_type,
            client_type
        ))
        .setInterval(QueryRunnerTestHelper.FULL_ON_INTERVAL_SPEC)
        .setLimitSpec(
            new DefaultLimitSpec(
                Collections.singletonList(new OrderByColumnSpec(client_type, OrderByColumnSpec.Direction.DESCENDING)),
                10
            )
        )
        .setAggregatorSpecs(QueryRunnerTestHelper.ROWS_COUNT, new DistinctCountAggregatorFactory(""UV"", visitor_id, null))
        .build();
    final Segment incrementalIndexSegment = new IncrementalIndexSegment(index, null);

    Iterable<ResultRow> results = GroupByQueryRunnerTestHelper.runQuery(
        factory,
        factory.createRunner(incrementalIndexSegment),
        query
    );

    List<ResultRow> expectedResults = Arrays.asList(
        GroupByQueryRunnerTestHelper.createExpectedRow(
            query,
            ""1970-01-01T00:00:00.000Z"",
            client_type, ""iphone"",
            ""UV"", 2L,
            ""rows"", 2L
        ),
        GroupByQueryRunnerTestHelper.createExpectedRow(
            query,
            ""1970-01-01T00:00:00.000Z"",
            client_type, ""android"",
            ""UV"", 1L,
            ""rows"", 1L
        )
    );
    TestHelper.assertExpectedObjects(expectedResults, results, ""distinct-count"");
  }
",non-flaky,5
60865,apache_druid,RedisCacheConfigTest.testClusterPriority,"  @Test
  public void testClusterPriority() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(""{\""expiration\"": 1000,""
                                                 + ""\""cluster\"": {""
                                                 + ""\""nodes\"": \""127.0.0.1:6379\""""
                                                 + ""},""
                                                 + ""\""host\"": \""127.0.0.1\"",""
                                                 + ""\""port\"": 6379""
                                                 + ""}"", RedisCacheConfig.class);

    try (Cache cache = RedisCacheFactory.create(fromJson)) {
      Assert.assertTrue(cache instanceof RedisClusterCache);
    }
  }
",non-flaky,5
60866,apache_druid,RedisCacheConfigTest.testClusterInvalidNode,"  @Test
  public void testClusterInvalidNode() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(
        ""{\""expiration\"": 1000,""
        + ""\""cluster\"": {""
        + ""\""nodes\"": \""127.0.0.1\"""" //<===Invalid Node
        + ""}""
        + ""}"",
        RedisCacheConfig.class
    );

    expectedException.expect(new ExceptionMatcher(
        IAE.class,
        new StartWithMatcher(""Invalid redis cluster"")
    ));
    RedisCacheFactory.create(fromJson);
  }
",non-flaky,5
60867,apache_druid,RedisCacheConfigTest.testClusterLackOfPort,"  @Test
  public void testClusterLackOfPort() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(
        ""{\""expiration\"":1000,""
        + ""\""cluster\"": {""
        + ""\""nodes\"": \""127.0.0.1:\""""
        + ""}""
        + ""}"",
        RedisCacheConfig.class
    );

    expectedException.expect(new ExceptionMatcher(
        IAE.class,
        new StartWithMatcher(""Invalid port"")
    ));
    RedisCacheFactory.create(fromJson);
  }
",non-flaky,5
60868,apache_druid,RedisCacheConfigTest.testInvalidClusterNodePort0,"  @Test
  public void testInvalidClusterNodePort0() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(
        ""{\""expiration\"": 1000,""
        + ""\""cluster\"": {""
        + ""\""nodes\"": \""127.0.0.1:0\"""" //<===Invalid Port
        + ""}""
        + ""}"",
        RedisCacheConfig.class
    );

    expectedException.expect(new ExceptionMatcher(
        IAE.class,
        new ContainsMatcher(""Invalid port"")
    ));
    RedisCacheFactory.create(fromJson);
  }
",non-flaky,5
60869,apache_druid,RedisCacheConfigTest.testInvalidClusterNodePort65536,"  @Test
  public void testInvalidClusterNodePort65536() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(
        ""{\""expiration\"": 1000,""
        + ""\""cluster\"": {""
        + ""\""nodes\"": \""127.0.0.1:65536\"""" //<===Invalid Port
        + ""}""
        + ""}"",
        RedisCacheConfig.class
    );

    expectedException.expect(new ExceptionMatcher(
        IAE.class,
        new ContainsMatcher(""Invalid port"")
    ));
    RedisCacheFactory.create(fromJson);
  }
",non-flaky,5
60870,apache_druid,RedisCacheConfigTest.testNoClusterAndHost,"  @Test
  public void testNoClusterAndHost() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(
        ""{\""expiration\"": 1000""
        + ""}"",
        RedisCacheConfig.class
    );

    expectedException.expect(new ExceptionMatcher(
        IAE.class,
        new ContainsMatcher(""no redis server"")
    ));
    RedisCacheFactory.create(fromJson);
  }
",non-flaky,5
60871,apache_druid,RedisClusterCacheTest.testConfig,"  @Test
  public void testConfig() throws JsonProcessingException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(""{\""expiration\"": 1000}"", RedisCacheConfig.class);
    Assert.assertEquals(1, fromJson.getExpiration().getSeconds());

    fromJson = mapper.readValue(""{\""expiration\"": \""PT1H\""}"", RedisCacheConfig.class);
    Assert.assertEquals(3600, fromJson.getExpiration().getSeconds());
  }
",non-flaky,5
60872,apache_druid,RedisClusterCacheTest.testCache,"  @Test
  public void testCache()
  {
    Assert.assertNull(cache.get(new Cache.NamedKey(""the"", HI)));

    Cache.NamedKey key1 = new Cache.NamedKey(""the"", HI);
    Cache.NamedKey key2 = new Cache.NamedKey(""the"", HO);
    Cache.NamedKey key3 = new Cache.NamedKey(""a"", HI);
    Cache.NamedKey notExist = new Cache.NamedKey(""notExist"", HI);

    //test put and get
    cache.put(key1, new byte[]{1, 2, 3, 4});
    cache.put(key2, new byte[]{2, 3, 4, 5});
    cache.put(key3, new byte[]{3, 4, 5, 6});
    Assert.assertEquals(0x01020304, Ints.fromByteArray(cache.get(key1)));
    Assert.assertEquals(0x02030405, Ints.fromByteArray(cache.get(key2)));
    Assert.assertEquals(0x03040506, Ints.fromByteArray(cache.get(key3)));
    Assert.assertEquals(0x03040506, Ints.fromByteArray(cache.get(key3)));
    Assert.assertNull(cache.get(notExist));

    this.mgetCount.set(0);

    //test multi get
    Map<Cache.NamedKey, byte[]> result = cache.getBulk(
        Lists.newArrayList(
            key1,
            key2,
            key3,
            notExist
        )
    );

    // these 4 keys are distributed among different nodes, so there should be 4 times call of MGET
    Assert.assertEquals(mgetCount.get(), 4);
    Assert.assertEquals(result.size(), 3);
    Assert.assertEquals(0x01020304, Ints.fromByteArray(result.get(key1)));
    Assert.assertEquals(0x02030405, Ints.fromByteArray(result.get(key2)));
    Assert.assertEquals(0x03040506, Ints.fromByteArray(result.get(key3)));
  }
",non-flaky,5
60873,apache_druid,RedisStandaloneCacheTest.testBasicInjection,"  @Test
  public void testBasicInjection() throws Exception
  {
    String json = ""{ \""host\"": \""localhost\"", \""port\"": 6379, \""expiration\"": 3600}"";
    final RedisCacheConfig config = new ObjectMapper().readValue(json, RedisCacheConfig.class);

    Injector injector = Initialization.makeInjectorWithModules(
        GuiceInjectors.makeStartupInjector(), ImmutableList.of(
            binder -> {
              binder.bindConstant().annotatedWith(Names.named(""serviceName"")).to(""druid/test/redis"");
              binder.bindConstant().annotatedWith(Names.named(""servicePort"")).to(0);
              binder.bindConstant().annotatedWith(Names.named(""tlsServicePort"")).to(-1);

              binder.bindConstant().annotatedWith(Names.named(""host"")).to(""localhost"");
              binder.bindConstant().annotatedWith(Names.named(""port"")).to(6379);

              binder.bind(RedisCacheConfig.class).toInstance(config);
              binder.bind(Cache.class).toProvider(RedisCacheProviderWithConfig.class).in(ManageLifecycle.class);
            }
        )
    );
    Lifecycle lifecycle = injector.getInstance(Lifecycle.class);
    lifecycle.start();
    try {
      Cache cache = injector.getInstance(Cache.class);
      Assert.assertEquals(RedisStandaloneCache.class, cache.getClass());
    }
    finally {
      lifecycle.stop();
    }
  }
",non-flaky,5
60874,apache_druid,RedisStandaloneCacheTest.testSimpleInjection,"  @Test
  public void testSimpleInjection()
  {
    final String uuid = UUID.randomUUID().toString();
    System.setProperty(uuid + "".type"", ""redis"");
    final Injector injector = Initialization.makeInjectorWithModules(
        GuiceInjectors.makeStartupInjector(), ImmutableList.of(
            binder -> {
              binder.bindConstant().annotatedWith(Names.named(""serviceName"")).to(""druid/test/redis"");
              binder.bindConstant().annotatedWith(Names.named(""servicePort"")).to(0);
              binder.bindConstant().annotatedWith(Names.named(""tlsServicePort"")).to(-1);

              binder.bind(Cache.class).toProvider(CacheProvider.class);
              JsonConfigProvider.bind(binder, uuid, CacheProvider.class);
            }
        )
    );
    final CacheProvider cacheProvider = injector.getInstance(CacheProvider.class);
    Assert.assertNotNull(cacheProvider);
    Assert.assertEquals(RedisCacheProvider.class, cacheProvider.getClass());
  }
",non-flaky,5
60875,apache_druid,RedisStandaloneCacheTest.testSanity,"  @Test
  public void testSanity()
  {
    Assert.assertNull(cache.get(new Cache.NamedKey(""a"", HI)));
    put(cache, ""a"", HI, 0);
    Assert.assertEquals(0, get(cache, ""a"", HI));
    Assert.assertNull(cache.get(new Cache.NamedKey(""the"", HI)));

    put(cache, ""the"", HI, 1);
    Assert.assertEquals(0, get(cache, ""a"", HI));
    Assert.assertEquals(1, get(cache, ""the"", HI));

    put(cache, ""the"", HO, 10);
    Assert.assertEquals(0, get(cache, ""a"", HI));
    Assert.assertNull(cache.get(new Cache.NamedKey(""a"", HO)));
    Assert.assertEquals(1, get(cache, ""the"", HI));
    Assert.assertEquals(10, get(cache, ""the"", HO));

    cache.close(""the"");
    Assert.assertEquals(0, get(cache, ""a"", HI));
    Assert.assertNull(cache.get(new Cache.NamedKey(""a"", HO)));
  }
",non-flaky,5
60876,apache_druid,RedisStandaloneCacheTest.testGetBulk,"  @Test
  public void testGetBulk()
  {
    Assert.assertNull(cache.get(new Cache.NamedKey(""the"", HI)));

    put(cache, ""the"", HI, 1);
    put(cache, ""the"", HO, 10);

    Cache.NamedKey key1 = new Cache.NamedKey(""the"", HI);
    Cache.NamedKey key2 = new Cache.NamedKey(""the"", HO);
    Cache.NamedKey key3 = new Cache.NamedKey(""a"", HI);

    Map<Cache.NamedKey, byte[]> result = cache.getBulk(
        Lists.newArrayList(
            key1,
            key2,
            key3
        )
    );

    Assert.assertEquals(1, Ints.fromByteArray(result.get(key1)));
    Assert.assertEquals(10, Ints.fromByteArray(result.get(key2)));
    Assert.assertEquals(null, result.get(key3));
  }
",non-flaky,5
60877,apache_druid,InfluxParserTest.testParse,"  @Test
  public void testParse(String name, String input, Parsed expected)
  {
    Parser<String, Object> parser = new InfluxParser(null);
    Map<String, Object> parsed = parser.parseToMap(input);
    MatcherAssert.assertThat(
        ""correct measurement name"",
        parsed.get(""measurement""),
        Matchers.equalTo(expected.measurement)
    );
    MatcherAssert.assertThat(
        ""correct timestamp"",
        parsed.get(InfluxParser.TIMESTAMP_KEY),
        Matchers.equalTo(expected.timestamp)
    );
    expected.kv.forEach((k, v) -> MatcherAssert.assertThat(""correct field "" + k, parsed.get(k), Matchers.equalTo(v)));
    parsed.remove(""measurement"");
    parsed.remove(InfluxParser.TIMESTAMP_KEY);
    MatcherAssert.assertThat(""No extra keys in parsed data"", parsed.keySet(), Matchers.equalTo(expected.kv.keySet()));
  }
",non-flaky,5
60878,apache_druid,InfluxParserTest.testParseWhitelistPass,"  @Test
  public void testParseWhitelistPass()
  {
    Parser<String, Object> parser = new InfluxParser(Sets.newHashSet(""cpu""));
    String input = ""cpu,host=foo.bar.baz,region=us-east,application=echo pct_idle=99.3,pct_user=88.8,m1_load=2 1465839830100400200"";
    Map<String, Object> parsed = parser.parseToMap(input);
    MatcherAssert.assertThat(parsed.get(""measurement""), Matchers.equalTo(""cpu""));
  }
",non-flaky,5
60879,apache_druid,InfluxParserTest.testParseWhitelistFail,"  @Test
  public void testParseWhitelistFail()
  {
    Parser<String, Object> parser = new InfluxParser(Sets.newHashSet(""mem""));
    String input = ""cpu,host=foo.bar.baz,region=us-east,application=echo pct_idle=99.3,pct_user=88.8,m1_load=2 1465839830100400200"";
    try {
      parser.parseToMap(input);
    }
    catch (ParseException t) {
      MatcherAssert.assertThat(t, Matchers.isA(ParseException.class));
      return;
    }

    Assert.fail(""Exception not thrown"");
  }
",non-flaky,5
60880,apache_druid,InfluxParserTest.testParseFailures,"  @Test
  public void testParseFailures(Pair<String, String> testCase)
  {
    Parser<String, Object> parser = new InfluxParser(null);
    try {
      parser.parseToMap(testCase.rhs);
    }
    catch (ParseException t) {
      MatcherAssert.assertThat(t, Matchers.isA(ParseException.class));
      return;
    }

    Assert.fail(testCase.rhs + "": exception not thrown"");
  }
",non-flaky,5
60881,apache_druid,MaterializedViewSupervisorTest.testCheckSegments,"  @Test
  public void testCheckSegments() throws IOException
  {
    Set<DataSegment> baseSegments = Sets.newHashSet(
        new DataSegment(
            ""base"",
            Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""),
            ""2015-01-02"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        ),
        new DataSegment(
            ""base"",
            Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
            ""2015-01-03"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        ),
        new DataSegment(
            ""base"",
            Intervals.of(""2015-01-03T00Z/2015-01-04T00Z""),
            ""2015-01-04"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        )
    );
    Set<DataSegment> derivativeSegments = Sets.newHashSet(
        new DataSegment(
            derivativeDatasourceName,
            Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""),
            ""2015-01-02"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        ),
        new DataSegment(
            derivativeDatasourceName,
            Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
            ""3015-01-01"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        )
    );
    indexerMetadataStorageCoordinator.announceHistoricalSegments(baseSegments);
    indexerMetadataStorageCoordinator.announceHistoricalSegments(derivativeSegments);
    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();
    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.absent()).anyTimes();
    EasyMock.expect(taskStorage.getActiveTasks()).andReturn(ImmutableList.of()).anyTimes();
    Pair<SortedMap<Interval, String>, Map<Interval, List<DataSegment>>> toBuildInterval = supervisor.checkSegments();
    Set<Interval> expectedToBuildInterval = Sets.newHashSet(Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""));
    Map<Interval, List<DataSegment>> expectedSegments = new HashMap<>();
    expectedSegments.put(
        Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""),
        Collections.singletonList(
            new DataSegment(
                ""base"",
                Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""),
                ""2015-01-02"",
                ImmutableMap.of(),
                ImmutableList.of(""dim1"", ""dim2""),
                ImmutableList.of(""m1""),
                new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
                9,
                1024
            )
        )
    );
    expectedSegments.put(
        Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
        Collections.singletonList(
            new DataSegment(
                ""base"",
                Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
                ""2015-01-03"",
                ImmutableMap.of(),
                ImmutableList.of(""dim1"", ""dim2""),
                ImmutableList.of(""m1""),
                new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
                9,
                1024
            )
        )
    );
    Assert.assertEquals(expectedToBuildInterval, toBuildInterval.lhs.keySet());
    Assert.assertEquals(expectedSegments, toBuildInterval.rhs);
  }
",non-flaky,5
60882,apache_druid,MaterializedViewSupervisorTest.testCheckSegmentsAndSubmitTasks,"  @Test
  public void testCheckSegmentsAndSubmitTasks() throws IOException
  {
    Set<DataSegment> baseSegments = Sets.newHashSet(
        new DataSegment(
            ""base"",
            Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
            ""2015-01-03"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        )
    );
    indexerMetadataStorageCoordinator.announceHistoricalSegments(baseSegments);
    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();
    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.absent()).anyTimes();
    EasyMock.expect(taskStorage.getActiveTasks()).andReturn(ImmutableList.of()).anyTimes();
    EasyMock.expect(taskStorage.getStatus(""test_task1""))
            .andReturn(Optional.of(TaskStatus.failure(""test_task1"", ""Dummy task status failure err message"")))
            .anyTimes();
    EasyMock.expect(taskStorage.getStatus(""test_task2""))
            .andReturn(Optional.of(TaskStatus.running(""test_task2"")))
            .anyTimes();
    EasyMock.replay(taskStorage);

    Pair<Map<Interval, HadoopIndexTask>, Map<Interval, String>> runningTasksPair = supervisor.getRunningTasks();
    Map<Interval, HadoopIndexTask> runningTasks = runningTasksPair.lhs;
    Map<Interval, String> runningVersion = runningTasksPair.rhs;

    DataSchema dataSchema = new DataSchema(
        ""test_datasource"",
        null,
        null,
        null,
        TransformSpec.NONE,
        objectMapper
    );
    HadoopIOConfig hadoopIOConfig = new HadoopIOConfig(new HashMap<>(), null, null);
    HadoopIngestionSpec spec = new HadoopIngestionSpec(dataSchema, hadoopIOConfig, null);
    HadoopIndexTask task1 = new HadoopIndexTask(
        ""test_task1"",
        spec,
        null,
        null,
        null,
        objectMapper,
        null,
        null,
        null
    );
    runningTasks.put(Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""), task1);
    runningVersion.put(Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""), ""test_version1"");

    HadoopIndexTask task2 = new HadoopIndexTask(
        ""test_task2"",
        spec,
        null,
        null,
        null,
        objectMapper,
        null,
        null,
        null
    );
    runningTasks.put(Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""), task2);
    runningVersion.put(Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""), ""test_version2"");

    supervisor.checkSegmentsAndSubmitTasks();

    Map<Interval, HadoopIndexTask> expectedRunningTasks = new HashMap<>();
    Map<Interval, String> expectedRunningVersion = new HashMap<>();
    expectedRunningTasks.put(Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""), task2);
    expectedRunningVersion.put(Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""), ""test_version2"");

    Assert.assertEquals(expectedRunningTasks, runningTasks);
    Assert.assertEquals(expectedRunningVersion, runningVersion);

  }
",non-flaky,5
60883,apache_druid,MaterializedViewSupervisorTest.testCreateTask,"  @Test
  public void testCreateTask()
  {
    List<DataSegment> baseSegments = Collections.singletonList(
        new DataSegment(
            ""base"",
            Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
            ""2015-01-03"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        )
    );

    HadoopIndexTask task = spec.createTask(
        Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
        ""2015-01-03"",
        baseSegments
    );

    Assert.assertNotNull(task);
  }
",non-flaky,5
60884,apache_druid,MaterializedViewSupervisorTest.testSuspendedDoesntRun,"  @Test
  public void testSuspendedDoesntRun()
  {
    MaterializedViewSupervisorSpec suspended = new MaterializedViewSupervisorSpec(
        ""base"",
        new DimensionsSpec(Collections.singletonList(new StringDimensionSchema(""dim"")), null, null),
        new AggregatorFactory[]{new LongSumAggregatorFactory(""m1"", ""m1"")},
        HadoopTuningConfig.makeDefaultTuningConfig(),
        null,
        null,
        null,
        null,
        null,
        true,
        objectMapper,
        taskMaster,
        taskStorage,
        metadataSupervisorManager,
        sqlSegmentsMetadataManager,
        indexerMetadataStorageCoordinator,
        new MaterializedViewTaskConfig(),
        EasyMock.createMock(AuthorizerMapper.class),
        EasyMock.createMock(ChatHandlerProvider.class),
        new SupervisorStateManagerConfig()
    );
    MaterializedViewSupervisor supervisor = (MaterializedViewSupervisor) suspended.createSupervisor();

    // mock IndexerSQLMetadataStorageCoordinator to ensure that retrieveDataSourceMetadata is not called
    // which will be true if truly suspended, since this is the first operation of the 'run' method otherwise
    IndexerSQLMetadataStorageCoordinator mock = EasyMock.createMock(IndexerSQLMetadataStorageCoordinator.class);
    EasyMock.expect(mock.retrieveDataSourceMetadata(suspended.getDataSourceName()))
            .andAnswer(() -> {
              Assert.fail();
              return null;
            })
            .anyTimes();

    EasyMock.replay(mock);
    supervisor.run();
  }
",non-flaky,5
60885,apache_druid,DerivativeDataSourceMetadataTest.testEmptyBaseDataSource,"  @Test
  public void testEmptyBaseDataSource()
  {
    expectedException.expect(CoreMatchers.instanceOf(IllegalArgumentException.class));
    expectedException.expectMessage(
        ""baseDataSource cannot be null or empty. Please provide a baseDataSource.""
    );
    String baseDataSource = """";
    Set<String> dims = Sets.newHashSet(""dim1"", ""dim2"", ""dim3"");
    Set<String> metrics = Sets.newHashSet(""cost"");
    DerivativeDataSourceMetadata metadata = new DerivativeDataSourceMetadata(baseDataSource, dims, metrics);
  }
",non-flaky,5
60886,apache_druid,DerivativeDataSourceMetadataTest.testNullBaseDataSource,"  @Test
  public void testNullBaseDataSource()
  {
    expectedException.expect(CoreMatchers.instanceOf(IllegalArgumentException.class));
    expectedException.expectMessage(
        ""baseDataSource cannot be null or empty. Please provide a baseDataSource.""
    );
    String baseDataSource = null;
    Set<String> dims = Sets.newHashSet(""dim1"", ""dim2"", ""dim3"");
    Set<String> metrics = Sets.newHashSet(""cost"");
    DerivativeDataSourceMetadata metadata = new DerivativeDataSourceMetadata(baseDataSource, dims, metrics);
  }
",non-flaky,5
60887,apache_druid,MaterializedViewSupervisorSpecTest.testSupervisorSerialization,"  @Test
  public void testSupervisorSerialization() throws IOException
  {
    String supervisorStr = ""{\n"" +
                           ""  \""type\"" : \""derivativeDataSource\"",\n"" +
                           ""  \""baseDataSource\"": \""wikiticker\"",\n"" +
                           ""  \""dimensionsSpec\"":{\n"" +
                           ""            \""dimensions\"" : [\n"" +
                           ""              \""isUnpatrolled\"",\n"" +
                           ""              \""metroCode\"",\n"" +
                           ""              \""namespace\"",\n"" +
                           ""              \""page\"",\n"" +
                           ""              \""regionIsoCode\"",\n"" +
                           ""              \""regionName\"",\n"" +
                           ""              \""user\""\n"" +
                           ""            ]\n"" +
                           ""          },\n"" +
                           ""    \""metricsSpec\"" : [\n"" +
                           ""        {\n"" +
                           ""          \""name\"" : \""count\"",\n"" +
                           ""          \""type\"" : \""count\""\n"" +
                           ""        },\n"" +
                           ""        {\n"" +
                           ""          \""name\"" : \""added\"",\n"" +
                           ""          \""type\"" : \""longSum\"",\n"" +
                           ""          \""fieldName\"" : \""added\""\n"" +
                           ""        }\n"" +
                           ""      ],\n"" +
                           ""  \""tuningConfig\"": {\n"" +
                           ""      \""type\"" : \""hadoop\""\n"" +
                           ""  }\n"" +
                           ""}"";
    MaterializedViewSupervisorSpec expected = new MaterializedViewSupervisorSpec(
        ""wikiticker"",
        new DimensionsSpec(
            Lists.newArrayList(
                new StringDimensionSchema(""isUnpatrolled""),
                new StringDimensionSchema(""metroCode""),
                new StringDimensionSchema(""namespace""),
                new StringDimensionSchema(""page""),
                new StringDimensionSchema(""regionIsoCode""),
                new StringDimensionSchema(""regionName""),
                new StringDimensionSchema(""user"")
            ),
            null,
            null
        ),
        new AggregatorFactory[]{
            new CountAggregatorFactory(""count""),
            new LongSumAggregatorFactory(""added"", ""added"")
        },
        HadoopTuningConfig.makeDefaultTuningConfig(),
        null,
        null,
        null,
        null,
        null,
        false,
        objectMapper,
        null,
        null,
        null,
        null,
        null,
        new MaterializedViewTaskConfig(),
        EasyMock.createMock(AuthorizerMapper.class),
        new NoopChatHandlerProvider(),
        new SupervisorStateManagerConfig()
    );
    MaterializedViewSupervisorSpec spec = objectMapper.readValue(supervisorStr, MaterializedViewSupervisorSpec.class);
    Assert.assertEquals(expected.getBaseDataSource(), spec.getBaseDataSource());
    Assert.assertEquals(expected.getId(), spec.getId());
    Assert.assertEquals(expected.getDataSourceName(), spec.getDataSourceName());
    Assert.assertEquals(expected.getDimensions(), spec.getDimensions());
    Assert.assertEquals(expected.getMetrics(), spec.getMetrics());
  }
",non-flaky,5
60888,apache_druid,MaterializedViewSupervisorSpecTest.call,"  @Test
  public void testMaterializedViewSupervisorSpecCreated()
  {
    Exception ex = null;

    try {
      MaterializedViewSupervisorSpec spec = new MaterializedViewSupervisorSpec(
              ""wikiticker"",
              new DimensionsSpec(
                      Lists.newArrayList(
                              new StringDimensionSchema(""isUnpatrolled""),
                              new StringDimensionSchema(""metroCode""),
                              new StringDimensionSchema(""namespace""),
                              new StringDimensionSchema(""page""),
                              new StringDimensionSchema(""regionIsoCode""),
                              new StringDimensionSchema(""regionName""),
                              new StringDimensionSchema(""user"")
                      ),
                      null,
                      null
              ),
              new AggregatorFactory[]{
                  new CountAggregatorFactory(""count""),
                  new LongSumAggregatorFactory(""added"", ""added"")
              },
              HadoopTuningConfig.makeDefaultTuningConfig(),
              null,
              null,
              null,
              null,
              null,
              false,
              objectMapper,
              null,
              null,
              null,
              null,
              null,
              new MaterializedViewTaskConfig(),
              EasyMock.createMock(AuthorizerMapper.class),
              new NoopChatHandlerProvider(),
              new SupervisorStateManagerConfig()
      );
      Supervisor supervisor = spec.createSupervisor();
      Assert.assertTrue(supervisor instanceof MaterializedViewSupervisor);

      SupervisorTaskAutoScaler autoscaler = spec.createAutoscaler(supervisor);
      Assert.assertNull(autoscaler);

      try {
        supervisor.computeLagStats();
      }
      catch (Exception e) {
        Assert.assertTrue(e instanceof UnsupportedOperationException);
      }

      try {
        int count = supervisor.getActiveTaskGroupsCount();
      }
      catch (Exception e) {
        Assert.assertTrue(e instanceof UnsupportedOperationException);
      }

      Callable<Integer> noop = new Callable<Integer>() {
        @Override
        public Integer call()
        {
          return -1;
        }
",non-flaky,5
60889,apache_druid,MaterializedViewSupervisorSpecTest.testSuspendResuume,"  @Test
  public void testSuspendResuume() throws IOException
  {
    String supervisorStr = ""{\n"" +
                           ""  \""type\"" : \""derivativeDataSource\"",\n"" +
                           ""  \""baseDataSource\"": \""wikiticker\"",\n"" +
                           ""  \""dimensionsSpec\"":{\n"" +
                           ""            \""dimensions\"" : [\n"" +
                           ""              \""isUnpatrolled\"",\n"" +
                           ""              \""metroCode\"",\n"" +
                           ""              \""namespace\"",\n"" +
                           ""              \""page\"",\n"" +
                           ""              \""regionIsoCode\"",\n"" +
                           ""              \""regionName\"",\n"" +
                           ""              \""user\""\n"" +
                           ""            ]\n"" +
                           ""          },\n"" +
                           ""    \""metricsSpec\"" : [\n"" +
                           ""        {\n"" +
                           ""          \""name\"" : \""count\"",\n"" +
                           ""          \""type\"" : \""count\""\n"" +
                           ""        },\n"" +
                           ""        {\n"" +
                           ""          \""name\"" : \""added\"",\n"" +
                           ""          \""type\"" : \""longSum\"",\n"" +
                           ""          \""fieldName\"" : \""added\""\n"" +
                           ""        }\n"" +
                           ""      ],\n"" +
                           ""  \""tuningConfig\"": {\n"" +
                           ""      \""type\"" : \""hadoop\""\n"" +
                           ""  }\n"" +
                           ""}"";

    MaterializedViewSupervisorSpec spec = objectMapper.readValue(supervisorStr, MaterializedViewSupervisorSpec.class);
    Assert.assertFalse(spec.isSuspended());

    String suspendedSerialized = objectMapper.writeValueAsString(spec.createSuspendedSpec());
    MaterializedViewSupervisorSpec suspendedSpec = objectMapper.readValue(
        suspendedSerialized,
        MaterializedViewSupervisorSpec.class
    );
    Assert.assertTrue(suspendedSpec.isSuspended());

    String runningSerialized = objectMapper.writeValueAsString(spec.createRunningSpec());
    MaterializedViewSupervisorSpec runningSpec = objectMapper.readValue(
        runningSerialized,
        MaterializedViewSupervisorSpec.class
    );
    Assert.assertFalse(runningSpec.isSuspended());
  }
",non-flaky,5
60890,apache_druid,MaterializedViewSupervisorSpecTest.testEmptyBaseDataSource,"  @Test
  public void testEmptyBaseDataSource()
  {
    expectedException.expect(CoreMatchers.instanceOf(IllegalArgumentException.class));
    expectedException.expectMessage(
        ""baseDataSource cannot be null or empty. Please provide a baseDataSource.""
    );
    //noinspection ResultOfObjectAllocationIgnored (this method call will trigger the expected exception)
    new MaterializedViewSupervisorSpec(
        """",
        new DimensionsSpec(
            Lists.newArrayList(
                new StringDimensionSchema(""isUnpatrolled""),
                new StringDimensionSchema(""metroCode""),
                new StringDimensionSchema(""namespace""),
                new StringDimensionSchema(""page""),
                new StringDimensionSchema(""regionIsoCode""),
                new StringDimensionSchema(""regionName""),
                new StringDimensionSchema(""user"")
            ),
            null,
            null
        ),
        new AggregatorFactory[]{
            new CountAggregatorFactory(""count""),
            new LongSumAggregatorFactory(""added"", ""added"")
        },
        HadoopTuningConfig.makeDefaultTuningConfig(),
        null,
        null,
        null,
        null,
        null,
        false,
        objectMapper,
        null,
        null,
        null,
        null,
        null,
        new MaterializedViewTaskConfig(),
        EasyMock.createMock(AuthorizerMapper.class),
        new NoopChatHandlerProvider(),
        new SupervisorStateManagerConfig()
    );
  }
",non-flaky,5
60891,apache_druid,MaterializedViewSupervisorSpecTest.testNullBaseDataSource,"  @Test
  public void testNullBaseDataSource()
  {
    expectedException.expect(CoreMatchers.instanceOf(IllegalArgumentException.class));
    expectedException.expectMessage(
        ""baseDataSource cannot be null or empty. Please provide a baseDataSource.""
    );
    //noinspection ResultOfObjectAllocationIgnored (this method call will trigger the expected exception)
    new MaterializedViewSupervisorSpec(
        null,
        new DimensionsSpec(
            Lists.newArrayList(
                new StringDimensionSchema(""isUnpatrolled""),
                new StringDimensionSchema(""metroCode""),
                new StringDimensionSchema(""namespace""),
                new StringDimensionSchema(""page""),
                new StringDimensionSchema(""regionIsoCode""),
                new StringDimensionSchema(""regionName""),
                new StringDimensionSchema(""user"")
            ),
            null,
            null
        ),
        new AggregatorFactory[]{
            new CountAggregatorFactory(""count""),
            new LongSumAggregatorFactory(""added"", ""added"")
        },
        HadoopTuningConfig.makeDefaultTuningConfig(),
        null,
        null,
        null,
        null,
        null,
        false,
        objectMapper,
        null,
        null,
        null,
        null,
        null,
        new MaterializedViewTaskConfig(),
        EasyMock.createMock(AuthorizerMapper.class),
        new NoopChatHandlerProvider(),
        new SupervisorStateManagerConfig()
    );
  }
",non-flaky,5
60892,apache_druid,KafkaEmitterTest.testKafkaEmitter,"  @Test(timeout = 15_000)
  public void testKafkaEmitter() throws InterruptedException
  {
    final List<ServiceMetricEvent> serviceMetricEvents = ImmutableList.of(
        ServiceMetricEvent.builder().build(""m1"", 1).build(""service"", ""host"")
    );

    final List<AlertEvent> alertEvents = ImmutableList.of(
        new AlertEvent(""service"", ""host"", ""description"")
    );

    final List<RequestLogEvent> requestLogEvents = ImmutableList.of(
        DefaultRequestLogEventBuilderFactory.instance().createRequestLogEventBuilder(""requests"",
            RequestLogLine.forSql("""", null, DateTimes.nowUtc(), null, new QueryStats(ImmutableMap.of()))
        ).build(""service"", ""host"")
    );

    int totalEvents = serviceMetricEvents.size() + alertEvents.size() + requestLogEvents.size();
    int totalEventsExcludingRequestLogEvents = totalEvents - requestLogEvents.size();

    final CountDownLatch countDownSentEvents = new CountDownLatch(
        requestTopic == null ? totalEventsExcludingRequestLogEvents : totalEvents);
    final KafkaProducer<String, String> producer = EasyMock.createStrictMock(KafkaProducer.class);
    final KafkaEmitter kafkaEmitter = new KafkaEmitter(
        new KafkaEmitterConfig("""", ""metrics"", ""alerts"", requestTopic, ""test-cluster"", null),
        new ObjectMapper()
    )
    {
      @Override
      protected Producer<String, String> setKafkaProducer()
      {
        return producer;
      }

      @Override
      protected void sendToKafka(final String topic, MemoryBoundLinkedBlockingQueue<String> recordQueue,
          Callback callback
      )
      {
        countDownSentEvents.countDown();
        super.sendToKafka(topic, recordQueue, callback);
      }
    };

    EasyMock.expect(producer.send(EasyMock.anyObject(), EasyMock.anyObject())).andReturn(null)
        .times(requestTopic == null ? totalEventsExcludingRequestLogEvents : totalEvents);
    EasyMock.replay(producer);
    kafkaEmitter.start();

    for (Event event : serviceMetricEvents) {
      kafkaEmitter.emit(event);
    }
    for (Event event : alertEvents) {
      kafkaEmitter.emit(event);
    }
    for (Event event : requestLogEvents) {
      kafkaEmitter.emit(event);
    }
    countDownSentEvents.await();

    Assert.assertEquals(0, kafkaEmitter.getMetricLostCount());
    Assert.assertEquals(0, kafkaEmitter.getAlertLostCount());
    Assert.assertEquals(requestTopic == null ? requestLogEvents.size() : 0, kafkaEmitter.getRequestLostCount());
    Assert.assertEquals(0, kafkaEmitter.getInvalidLostCount());

    while (true) {
      try {
        EasyMock.verify(producer);
        break;
      }
      catch (Throwable e) {
        // although the latch may have count down, producer.send may not have been called yet in KafkaEmitter
        // so wait for sometime before verifying the mock
        Thread.sleep(100);
        // just continue
      }
    }
  }
",non-flaky,5
60893,apache_druid,KafkaEmitterConfigTest.testSerDeserKafkaEmitterConfig,"  @Test
  public void testSerDeserKafkaEmitterConfig() throws IOException
  {
    KafkaEmitterConfig kafkaEmitterConfig = new KafkaEmitterConfig(""hostname"", ""metricTest"",
        ""alertTest"", ""requestTest"",
        ""clusterNameTest"", ImmutableMap.<String, String>builder()
        .put(""testKey"", ""testValue"").build()
    );
    String kafkaEmitterConfigString = mapper.writeValueAsString(kafkaEmitterConfig);
    KafkaEmitterConfig kafkaEmitterConfigExpected = mapper.readerFor(KafkaEmitterConfig.class)
        .readValue(kafkaEmitterConfigString);
    Assert.assertEquals(kafkaEmitterConfigExpected, kafkaEmitterConfig);
  }
",non-flaky,5
60894,apache_druid,KafkaEmitterConfigTest.testSerDeserKafkaEmitterConfigNullRequestTopic,"  @Test
  public void testSerDeserKafkaEmitterConfigNullRequestTopic() throws IOException
  {
    KafkaEmitterConfig kafkaEmitterConfig = new KafkaEmitterConfig(""hostname"", ""metricTest"",
        ""alertTest"", null,
        ""clusterNameTest"", ImmutableMap.<String, String>builder()
        .put(""testKey"", ""testValue"").build()
    );
    String kafkaEmitterConfigString = mapper.writeValueAsString(kafkaEmitterConfig);
    KafkaEmitterConfig kafkaEmitterConfigExpected = mapper.readerFor(KafkaEmitterConfig.class)
        .readValue(kafkaEmitterConfigString);
    Assert.assertEquals(kafkaEmitterConfigExpected, kafkaEmitterConfig);
  }
",non-flaky,5
60895,apache_druid,KafkaEmitterConfigTest.testSerDeNotRequiredKafkaProducerConfig,"  @Test
  public void testSerDeNotRequiredKafkaProducerConfig()
  {
    KafkaEmitterConfig kafkaEmitterConfig = new KafkaEmitterConfig(""localhost:9092"", ""metricTest"",
        ""alertTest"", null,
        ""clusterNameTest"", null
    );
    try {
      @SuppressWarnings(""unused"")
      KafkaEmitter emitter = new KafkaEmitter(kafkaEmitterConfig, mapper);
    }
    catch (NullPointerException e) {
      Assert.fail();
    }
  }
",non-flaky,5
60896,apache_druid,KafkaEmitterConfigTest.testJacksonModules,"  @Test
  public void testJacksonModules()
  {
    Assert.assertTrue(new KafkaEmitterModule().getJacksonModules().isEmpty());
  }
",non-flaky,5
60897,apache_druid,ThriftInputRowParserTest.testGetThriftClass,"  @Test
  public void testGetThriftClass() throws Exception
  {
    ThriftInputRowParser parser1 = new ThriftInputRowParser(
        parseSpec,
        ""example/book.jar"",
        ""org.apache.druid.data.input.thrift.Book""
    );
    Assert.assertEquals(""org.apache.druid.data.input.thrift.Book"", parser1.getThriftClass().getName());

    ThriftInputRowParser parser2 = new ThriftInputRowParser(parseSpec, null, ""org.apache.druid.data.input.thrift.Book"");
    Assert.assertEquals(""org.apache.druid.data.input.thrift.Book"", parser2.getThriftClass().getName());
  }
",non-flaky,5
60898,apache_druid,ThriftInputRowParserTest.testParse,"  @Test
  public void testParse() throws Exception
  {
    ThriftInputRowParser parser = new ThriftInputRowParser(
        parseSpec,
        ""example/book.jar"",
        ""org.apache.druid.data.input.thrift.Book""
    );
    Book book = new Book().setDate(""2016-08-29"").setPrice(19.9).setTitle(""title"")
                          .setAuthor(new Author().setFirstName(""first"").setLastName(""last""));

    TSerializer serializer;
    byte[] bytes;

    // 1. compact
    serializer = new TSerializer(new TCompactProtocol.Factory());
    bytes = serializer.serialize(book);
    serializationAndTest(parser, bytes);

    // 2. binary + base64
    serializer = new TSerializer(new TBinaryProtocol.Factory());
    serializationAndTest(parser, StringUtils.encodeBase64(serializer.serialize(book)));

    // 3. json
    serializer = new TSerializer(new TJSONProtocol.Factory());
    bytes = serializer.serialize(book);
    serializationAndTest(parser, bytes);
  }
",non-flaky,5
60899,apache_druid,ThriftInputRowParserTest.testDisableJavaScript,"  @Test
  public void testDisableJavaScript()
  {
    final JavaScriptParseSpec parseSpec = new JavaScriptParseSpec(
        new TimestampSpec(""timestamp"", ""auto"", null),
        new DimensionsSpec(
            DimensionsSpec.getDefaultSchemas(
                ImmutableList.of(
                    ""dim1"",
                    ""dim2""
                )
            ),
            null,
            null
        ),
        ""func"",
        new JavaScriptConfig(false)
    );
    ThriftInputRowParser parser = new ThriftInputRowParser(
        parseSpec,
        ""example/book.jar"",
        ""org.apache.druid.data.input.thrift.Book""
    );

    expectedException.expect(CoreMatchers.instanceOf(IllegalStateException.class));
    expectedException.expectMessage(""JavaScript is disabled"");

    //noinspection ResultOfMethodCallIgnored (this method call will trigger the expected exception)
    parser.parseBatch(ByteBuffer.allocate(1)).get(0);
  }
",non-flaky,5
60900,apache_druid,MovingAverageIterableTest.testNext,"  @Test
  public void testNext()
  {

    List<DimensionSpec> dims = Arrays.asList(
        new DefaultDimensionSpec(GENDER, GENDER),
        new DefaultDimensionSpec(AGE, AGE),
        new DefaultDimensionSpec(COUNTRY, COUNTRY)
    );

    Sequence<RowBucket> dayBuckets = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Arrays.asList(
            new MapBasedRow(JAN_1, DIMS1),
            new MapBasedRow(JAN_1, DIMS2)
        )),
        new RowBucket(JAN_2, Collections.singletonList(
            new MapBasedRow(JAN_2, DIMS1)
        )),
        new RowBucket(JAN_3, Collections.emptyList()),
        new RowBucket(JAN_4, Arrays.asList(
            new MapBasedRow(JAN_4, DIMS2),
            new MapBasedRow(JAN_4, DIMS3)
        ))
    ));

    Iterable<Row> iterable = new MovingAverageIterable(
        dayBuckets,
        dims,
        Collections.singletonList(new ConstantAveragerFactory(""noop"", 1, 1.1f)),
        Collections.emptyList(),
        Collections.emptyList()
    );

    Iterator<Row> iter = iterable.iterator();

    Assert.assertTrue(iter.hasNext());
    Row r = iter.next();
    Assert.assertEquals(JAN_1, r.getTimestamp());
    Assert.assertEquals(""m"", r.getRaw(GENDER));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_1, r.getTimestamp());
    Assert.assertEquals(""f"", r.getRaw(GENDER));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_2, r.getTimestamp());
    Assert.assertEquals(""m"", r.getRaw(GENDER));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_2, r.getTimestamp());
    Assert.assertEquals(""f"", r.getRaw(GENDER));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Row r2 = r;
    Assert.assertEquals(JAN_3, r.getTimestamp());
    Assert.assertEquals(""US"", r.getRaw(COUNTRY));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_3, r.getTimestamp());
    Assert.assertEquals(""US"", r.getRaw(COUNTRY));
    Assert.assertThat(r.getRaw(AGE), CoreMatchers.not(CoreMatchers.equalTo(r2.getRaw(AGE))));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_4, r.getTimestamp());
    Assert.assertEquals(""f"", r.getRaw(GENDER));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_4, r.getTimestamp());
    Assert.assertEquals(""u"", r.getRaw(GENDER));

    Assert.assertTrue(iter.hasNext());
    r = iter.next();
    Assert.assertEquals(JAN_4, r.getTimestamp());
    Assert.assertEquals(""m"", r.getRaw(GENDER));

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60901,apache_druid,MovingAverageIterableTest.testAveraging,"  @Test
  public void testAveraging()
  {

    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();
    Map<String, Object> event3 = new HashMap<>();
    Map<String, Object> event4 = new HashMap<>();

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    Row row1 = new MapBasedRow(JAN_1, event1);

    event2.put(""gender"", ""m"");
    event2.put(""pageViews"", 20L);
    Row row2 = new MapBasedRow(JAN_2, event2);

    event3.put(""gender"", ""m"");
    event3.put(""pageViews"", 30L);
    Row row3 = new MapBasedRow(JAN_3, event3);

    event4.put(""gender"", ""f"");
    event4.put(""pageViews"", 40L);
    Row row4 = new MapBasedRow(JAN_3, event4);

    float retval = 14.5f;

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.singletonList(row1)),
        new RowBucket(JAN_2, Collections.singletonList(row2)),
        new RowBucket(JAN_3, Arrays.asList(row3, row4))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Arrays.asList(
            new ConstantAveragerFactory(""costPageViews"", 7, retval),
            new LongMeanAveragerFactory(""movingAvgPageViews"", 7, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row caResult = iter.next();

    Assert.assertEquals(JAN_1, caResult.getTimestamp());
    Assert.assertEquals(""m"", (caResult.getDimension(""gender"")).get(0));
    Assert.assertEquals(retval, caResult.getMetric(""costPageViews"").floatValue(), 0.0f);
    Assert.assertEquals(1.4285715f, caResult.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    caResult = iter.next();
    Assert.assertEquals(""m"", (caResult.getDimension(""gender"")).get(0));
    Assert.assertEquals(4.285714f, caResult.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    caResult = iter.next();
    Assert.assertEquals(""m"", (caResult.getDimension(""gender"")).get(0));
    Assert.assertEquals(8.571428f, caResult.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    caResult = iter.next();
    Assert.assertEquals(""f"", (caResult.getDimension(""gender"")).get(0));
    Assert.assertEquals(5.714285850f, caResult.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertFalse(iter.hasNext());

  }
",non-flaky,5
60902,apache_druid,MovingAverageIterableTest.testCompleteData,"  @Test
  public void testCompleteData()
  {

    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();
    Map<String, Object> event3 = new HashMap<>();

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    event2.put(""gender"", ""f"");
    event2.put(""pageViews"", 20L);
    event3.put(""gender"", ""u"");
    event3.put(""pageViews"", 30L);

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    Row jan1Row1 = new MapBasedRow(JAN_1, event1);
    Row jan1Row2 = new MapBasedRow(JAN_1, event2);
    Row jan1Row3 = new MapBasedRow(JAN_1, event3);

    Row jan2Row1 = new MapBasedRow(JAN_2, event1);
    Row jan2Row2 = new MapBasedRow(JAN_2, event2);
    Row jan2Row3 = new MapBasedRow(JAN_2, event3);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Arrays.asList(jan1Row1, jan1Row2, jan1Row3)),
        new RowBucket(JAN_2, Arrays.asList(jan2Row1, jan2Row2, jan2Row3))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 2, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertFalse(iter.hasNext());

  }
",non-flaky,5
60903,apache_druid,MovingAverageIterableTest.testMissingDataAtBeginning,"  @Test
  public void testMissingDataAtBeginning()
  {

    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();
    Map<String, Object> event3 = new HashMap<>();

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    event2.put(""gender"", ""f"");
    event2.put(""pageViews"", 20L);
    event3.put(""gender"", ""u"");
    event3.put(""pageViews"", 30L);

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    Row jan1Row1 = new MapBasedRow(JAN_1, event1);

    Row jan2Row1 = new MapBasedRow(JAN_2, event1);
    Row jan2Row2 = new MapBasedRow(JAN_2, event2);
    Row jan2Row3 = new MapBasedRow(JAN_2, event3);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.singletonList(jan1Row1)),
        new RowBucket(JAN_2, Arrays.asList(jan2Row1, jan2Row2, jan2Row3))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 2, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60904,apache_druid,MovingAverageIterableTest.testMissingDataAtTheEnd,"  @Test
  public void testMissingDataAtTheEnd()
  {

    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();
    Map<String, Object> event3 = new HashMap<>();

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    event2.put(""gender"", ""f"");
    event2.put(""pageViews"", 20L);
    event3.put(""gender"", ""u"");
    event3.put(""pageViews"", 30L);

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    Row jan1Row1 = new MapBasedRow(JAN_1, event1);
    Row jan1Row2 = new MapBasedRow(JAN_1, event2);
    Row jan1Row3 = new MapBasedRow(JAN_1, event3);
    Row jan2Row1 = new MapBasedRow(JAN_2, event1);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Arrays.asList(jan1Row1, jan1Row2, jan1Row3)),
        new RowBucket(JAN_2, Collections.singletonList(jan2Row1))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 2, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60905,apache_druid,MovingAverageIterableTest.testMissingDataAtMiddle,"  @Test
  public void testMissingDataAtMiddle()
  {

    Map<String, Object> eventM = new HashMap<>();
    Map<String, Object> eventF = new HashMap<>();
    Map<String, Object> eventU = new HashMap<>();

    eventM.put(""gender"", ""m"");
    eventM.put(""pageViews"", 10L);
    eventF.put(""gender"", ""f"");
    eventF.put(""pageViews"", 20L);
    eventU.put(""gender"", ""u"");
    eventU.put(""pageViews"", 30L);

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    Row jan1Row1M = new MapBasedRow(JAN_1, eventM);
    Row jan1Row2F = new MapBasedRow(JAN_1, eventF);
    Row jan1Row3U = new MapBasedRow(JAN_1, eventU);
    Row jan2Row1M = new MapBasedRow(JAN_2, eventM);
    Row jan3Row1M = new MapBasedRow(JAN_3, eventM);
    Row jan3Row2F = new MapBasedRow(JAN_3, eventF);
    Row jan3Row3U = new MapBasedRow(JAN_3, eventU);
    Row jan4Row1M = new MapBasedRow(JAN_4, eventM);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Arrays.asList(jan1Row1M, jan1Row2F, jan1Row3U)),
        new RowBucket(JAN_2, Collections.singletonList(jan2Row1M)),
        new RowBucket(JAN_3, Arrays.asList(jan3Row1M, jan3Row2F, jan3Row3U)),
        new RowBucket(JAN_4, Collections.singletonList(jan4Row1M))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 3, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    // Jan 1
    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_1, (result.getTimestamp()));

    // Jan 2
    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_2, (result.getTimestamp()));

    // Jan 3
    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_3, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_3, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_3, (result.getTimestamp()));

    // Jan 4
    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_4, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""u"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_4, (result.getTimestamp()));

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""f"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(JAN_4, (result.getTimestamp()));

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60906,apache_druid,MovingAverageIterableTest.testMissingDaysAtBegining,"  @Test
  public void testMissingDaysAtBegining()
  {

    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    Row row1 = new MapBasedRow(JAN_3, event1);

    event2.put(""gender"", ""m"");
    event2.put(""pageViews"", 20L);
    Row row2 = new MapBasedRow(JAN_4, event2);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.emptyList()),
        new RowBucket(JAN_2, Collections.emptyList()),
        new RowBucket(JAN_3, Collections.singletonList(row1)),
        new RowBucket(JAN_4, Collections.singletonList(row2))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 4, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(7.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60907,apache_druid,MovingAverageIterableTest.testMissingDaysInMiddle,"  @Test
  public void testMissingDaysInMiddle()
  {
    System.setProperty(""druid.generic.useDefaultValueForNull"", ""true"");
    NullHandling.initializeForTests();
    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    Row row1 = new MapBasedRow(JAN_1, event1);

    event2.put(""gender"", ""m"");
    event2.put(""pageViews"", 20L);
    Row row2 = new MapBasedRow(JAN_4, event2);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.singletonList(row1)),
        new RowBucket(JAN_2, Collections.emptyList()),
        new RowBucket(JAN_3, Collections.emptyList()),
        new RowBucket(JAN_4, Collections.singletonList(row2))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 4, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(7.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60908,apache_druid,MovingAverageIterableTest.testWithFilteredAggregation,"  @Test
  public void testWithFilteredAggregation()
  {

    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    Row row1 = new MapBasedRow(JAN_1, event1);

    event2.put(""gender"", ""m"");
    event2.put(""pageViews"", 20L);
    Row row2 = new MapBasedRow(JAN_4, event2);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.singletonList(row1)),
        new RowBucket(JAN_2, Collections.emptyList()),
        new RowBucket(JAN_3, Collections.emptyList()),
        new RowBucket(JAN_4, Collections.singletonList(row2))
    ));

    AveragerFactory averagerfactory = new LongMeanAveragerFactory(""movingAvgPageViews"", 4, 1, ""pageViews"");
    AggregatorFactory aggregatorFactory = new LongSumAggregatorFactory(""pageViews"", ""pageViews"");
    DimFilter filter = new SelectorDimFilter(""gender"", ""m"", null);
    FilteredAggregatorFactory filteredAggregatorFactory = new FilteredAggregatorFactory(aggregatorFactory, filter);

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(averagerfactory),
        Collections.emptyList(),
        Collections.singletonList(filteredAggregatorFactory)
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(7.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60909,apache_druid,MovingAverageIterableTest.testMissingDaysAtEnd,"  @Test
  public void testMissingDaysAtEnd()
  {
    System.setProperty(""druid.generic.useDefaultValueForNull"", ""true"");
    NullHandling.initializeForTests();
    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    Row row1 = new MapBasedRow(JAN_1, event1);

    event2.put(""gender"", ""m"");
    event2.put(""pageViews"", 20L);
    Row row2 = new MapBasedRow(JAN_2, event2);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.singletonList(row1)),
        new RowBucket(JAN_2, Collections.singletonList(row2)),
        new RowBucket(JAN_3, Collections.emptyList()),
        new RowBucket(JAN_4, Collections.emptyList()),
        new RowBucket(JAN_5, Collections.emptyList()),
        new RowBucket(JAN_6, Collections.emptyList())
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 4, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();

    Assert.assertEquals(JAN_1, result.getTimestamp());
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(JAN_2, result.getTimestamp());
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(7.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(JAN_3, result.getTimestamp());
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(7.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(JAN_4, result.getTimestamp());
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(7.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(JAN_5, result.getTimestamp());
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(5.0f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(JAN_6, result.getTimestamp());
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(0.0f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
60910,apache_druid,PostAveragerAggregatorCalculatorTest.testApply,"  @Test
  public void testApply()
  {
    event.put(""count"", 10.0);
    event.put(""avgCount"", 12.0);

    Row result = pac.apply(row);

    Assert.assertEquals(10.0f / 12.0f, result.getMetric(""avgCountRatio"").floatValue(), 0.0);
  }
",non-flaky,5
60911,apache_druid,PostAveragerAggregatorCalculatorTest.testApplyMissingColumn,"  @Test
  public void testApplyMissingColumn()
  {
    event.put(""count"", 10.0);

    Row result = pac.apply(row);

    Assert.assertEquals(0.0, result.getMetric(""avgCountRatio"").floatValue(), 0.0);
    Assert.assertNull(result.getRaw(""avgCountRatio""));
  }
",non-flaky,5
60912,apache_druid,DoubleMaxAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new DoubleMaxAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), CoreMatchers.instanceOf(DoubleMaxAverager.class));
  }
",non-flaky,5
60913,apache_druid,DoubleMinAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new DoubleMinAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(DoubleMinAverager.class));
  }
",non-flaky,5
60914,apache_druid,DoubleSumAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new DoubleSumAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(DoubleSumAverager.class));
  }
",non-flaky,5
60915,apache_druid,LongMaxAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new LongMaxAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(LongMaxAverager.class));
  }
",non-flaky,5
60916,apache_druid,LongMeanNoNullAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new LongMeanNoNullAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(LongMeanNoNullAverager.class));
  }
",non-flaky,5
60917,apache_druid,LongMinAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new LongMinAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(LongMinAverager.class));
  }
",non-flaky,5
60918,apache_druid,DoubleSumAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new DoubleSumAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(0.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(6.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", new Integer(0)), new HashMap<>());
    Assert.assertEquals(6.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 2.5), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    Assert.assertEquals(6.5, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(4.0, avg.computeResult(), 0.0);

  }
",non-flaky,5
60919,apache_druid,LongMeanNoNullAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new LongMeanNoNullAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(Double.NaN, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);
  }
",non-flaky,5
60920,apache_druid,DoubleMaxAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new DoubleMaxAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(Double.NEGATIVE_INFINITY, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", -1.1e100), new HashMap<>());
    Assert.assertEquals(-1.1e100, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    Assert.assertEquals(1.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 1), new HashMap<>());
    Assert.assertEquals(1.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 5.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    Assert.assertEquals(5.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);
  }
",non-flaky,5
60921,apache_druid,DoubleMeanAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new DoubleMeanAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(0.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(1.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(4.0 / 3, avg.computeResult(), 0.0);
  }
",non-flaky,5
60922,apache_druid,DoubleMeanNoNullAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new DoubleMeanNoNullAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(DoubleMeanNoNullAverager.class));
  }
",non-flaky,5
60923,apache_druid,BaseAveragerFactoryTest.testGetDependentFields,"  @Test
  public void testGetDependentFields()
  {
    List<String> dependentFields = fac.getDependentFields();
    Assert.assertEquals(1, dependentFields.size());
    Assert.assertEquals(""field"", dependentFields.get(0));
  }
",non-flaky,5
60924,apache_druid,BaseAveragerFactoryTest.testFinalization,"  @Test
  public void testFinalization()
  {
    Long input = 5L;
    Assert.assertEquals(input, fac.finalizeComputation(input));
  }
",non-flaky,5
60925,apache_druid,DoubleMeanNoNullAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new DoubleMeanNoNullAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(Double.NaN, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    // testing cycleSize functionality
    BaseAverager<Number, Double> averager = new DoubleMeanNoNullAverager(14, ""test"", ""field"", 7);

    averager.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    Assert.assertEquals(2.0, averager.computeResult(), 0.0);

    averager.addElement(Collections.singletonMap(""field"", 4.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 5.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 6.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 7.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 8.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 9.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", null), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 11.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 12.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 13.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 14.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 15.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 16.0), new HashMap<>());

    Assert.assertEquals(7.5, averager.computeResult(), 0.0);

    averager.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(8.5, averager.computeResult(), 0.0);
  }
",non-flaky,5
60926,apache_druid,LongSumAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Long> avg = new LongSumAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(0.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(6.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3), new HashMap<>());
    Assert.assertEquals(9.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    Assert.assertEquals(6.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(4.0, avg.computeResult(), 0.0);
  }
",non-flaky,5
60927,apache_druid,LongMeanAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new LongMeanAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(LongMeanAverager.class));
  }
",non-flaky,5
60928,apache_druid,LongSumAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new LongSumAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(LongSumAverager.class));
  }
",non-flaky,5
60929,apache_druid,DoubleMeanAveragerWithPeriodTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> averager = new DoubleMeanAverager(14, ""test"", ""field"", 7);

    averager.addElement(Collections.singletonMap(""field"", 7.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 4.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 5.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 6.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 7.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 4.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 5.0), new HashMap<>());
    averager.addElement(Collections.singletonMap(""field"", 6.0), new HashMap<>());

    Assert.assertEquals(7, averager.computeResult(), 0.0); // (7+7)/2

    averager.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(1, averager.computeResult(), 0.0); // (1+1)/2

    BaseAverager<Number, Double> averager1 = new DoubleMeanAverager(14, ""test"", ""field"", 3);

    averager1.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    averager1.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());

    Assert.assertEquals(1, averager1.computeResult(), 0.0); // (1+1+1+1+1)/5

    Assert.assertEquals(2, averager1.computeResult(), 0.0); // (2+2+2+2+2)/5

    Assert.assertEquals(13.0 / 5, averager1.computeResult(), 0.0); // (3+3+3+3+1)/5
  }
",non-flaky,5
60930,apache_druid,BaseAveragerTest.testBaseAverager,"  @Test
  public void testBaseAverager()
  {
    BaseAverager<Integer, Integer> avg = new TestAverager(Integer.class, 5, ""test"", ""field"", 1);

    Assert.assertEquals(""test"", avg.getName());
    Assert.assertEquals(5, avg.getNumBuckets());
    Assert.assertEquals(5, avg.getBuckets().length);
    Assert.assertTrue(avg.getBuckets().getClass().isArray());
  }
",non-flaky,5
60931,apache_druid,BaseAveragerTest.testAddElement,"  @Test
  public void testAddElement()
  {
    BaseAverager<Integer, Integer> avg = new TestAverager(Integer.class, 3, ""test"", ""field"", 1);
    Object[] buckets = avg.getBuckets();

    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());
    Assert.assertEquals(1, buckets[0]);
    Assert.assertNull(buckets[1]);
    Assert.assertNull(buckets[2]);

    avg.addElement(Collections.singletonMap(""field"", 2), Collections.emptyMap());
    Assert.assertEquals(1, buckets[0]);
    Assert.assertEquals(2, buckets[1]);
    Assert.assertNull(buckets[2]);

    avg.addElement(Collections.singletonMap(""field"", 3), Collections.emptyMap());
    Assert.assertEquals(1, buckets[0]);
    Assert.assertEquals(2, buckets[1]);
    Assert.assertEquals(3, buckets[2]);

    avg.addElement(Collections.singletonMap(""field"", 4), Collections.emptyMap());
    Assert.assertEquals(4, buckets[0]);
    Assert.assertEquals(2, buckets[1]);
    Assert.assertEquals(3, buckets[2]);
  }
",non-flaky,5
60932,apache_druid,BaseAveragerTest.testSkip,"  @Test
  public void testSkip()
  {
    BaseAverager<Integer, Integer> avg = new TestAverager(Integer.class, 3, ""test"", ""field"", 1);
    Object[] buckets = avg.getBuckets();

    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());
    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());
    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());

    Assert.assertEquals(1, buckets[0]);
    Assert.assertEquals(1, buckets[1]);
    Assert.assertEquals(1, buckets[2]);

    avg.skip();
    Assert.assertNull(buckets[0]);
    Assert.assertNotNull(buckets[1]);
    Assert.assertNotNull(buckets[2]);

    avg.skip();
    Assert.assertNull(buckets[0]);
    Assert.assertNull(buckets[1]);
    Assert.assertNotNull(buckets[2]);

    avg.skip();
    Assert.assertNull(buckets[0]);
    Assert.assertNull(buckets[1]);
    Assert.assertNull(buckets[2]);

    // poke some test data into the array
    buckets[0] = 1;

    avg.skip();
    Assert.assertNull(buckets[0]);
    Assert.assertNull(buckets[1]);
    Assert.assertNull(buckets[2]);
  }
",non-flaky,5
60933,apache_druid,BaseAveragerTest.testHasData,"  @Test
  public void testHasData()
  {
    BaseAverager<Integer, Integer> avg = new TestAverager(Integer.class, 3, ""test"", ""field"", 1);

    Assert.assertFalse(avg.hasData());

    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());
    Assert.assertTrue(avg.hasData());

    avg.skip();
    avg.skip();
    avg.skip();

    Assert.assertFalse(avg.hasData());
  }
",non-flaky,5
60934,apache_druid,BaseAveragerTest.testGetResult,"  @Test
  public void testGetResult()
  {
    BaseAverager<Integer, Integer> avg = new TestAverager(Integer.class, 3, ""test"", ""field"", 1);

    Assert.assertNull(avg.getResult());

    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());
    Assert.assertEquals(Integer.valueOf(1), avg.getResult());
  }
",non-flaky,5
60935,apache_druid,DoubleMeanAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new DoubleMeanAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(DoubleMeanAverager.class));
  }
",non-flaky,5
60936,apache_druid,DoubleMinAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new DoubleMinAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(Double.POSITIVE_INFINITY, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", -1.1e100), new HashMap<>());
    Assert.assertEquals(-1.1e100, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    Assert.assertEquals(-1.1e100, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", new Integer(1)), new HashMap<>());
    Assert.assertEquals(-1.1e100, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 5.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.skip();
    avg.skip();
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);
  }
",non-flaky,5
60937,apache_druid,LongMeanAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new LongMeanAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(0.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(1.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(4.0 / 3, avg.computeResult(), 0.0);
  }
",non-flaky,5
60938,apache_druid,LongMaxAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Long> avg = new LongMaxAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(Long.MIN_VALUE, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", -1000000L), new HashMap<>());
    Assert.assertEquals(-1000000, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", 1L), new HashMap<>());
    Assert.assertEquals(1, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", 1), new HashMap<>());
    Assert.assertEquals(1, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", 5L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    Assert.assertEquals(5, (long) avg.computeResult());

    avg.skip();
    Assert.assertEquals(3, (long) avg.computeResult());
  }
",non-flaky,5
60939,apache_druid,LongMinAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Long> avg = new LongMinAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(Long.MAX_VALUE, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", -10000L), new HashMap<>());
    Assert.assertEquals(-10000, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", 1L), new HashMap<>());
    Assert.assertEquals(-10000, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", 1000), new HashMap<>());
    Assert.assertEquals(-10000, (long) avg.computeResult());

    avg.addElement(Collections.singletonMap(""field"", 5L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(2, (long) avg.computeResult());

    avg.skip();
    avg.skip();
    Assert.assertEquals(3, (long) avg.computeResult());
  }
",non-flaky,5
60940,apache_druid,MovingAverageQueryTest.getDruidServers,"  @Test
  public void testQuery() throws IOException
  {
    Query<?> query = jsonMapper.readValue(getQueryString(), Query.class);
    Assert.assertThat(query, IsInstanceOf.instanceOf(getExpectedQueryType()));

    List<MapBasedRow> expectedResults = jsonMapper.readValue(getExpectedResultString(), getExpectedResultType());
    Assert.assertNotNull(expectedResults);
    Assert.assertThat(expectedResults, IsInstanceOf.instanceOf(List.class));

    CachingClusteredClient baseClient = new CachingClusteredClient(
        warehouse,
        new TimelineServerView()
        {
          @Override
          public Optional<? extends TimelineLookup<String, ServerSelector>> getTimeline(DataSourceAnalysis analysis)
          {
            return Optional.empty();
          }

          @Override
          public List<ImmutableDruidServer> getDruidServers()
          {
            return null;
          }
",non-flaky,5
60941,apache_druid,RowBucketIterableTest.testCompleteData,"  @Test
  public void testCompleteData()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_M_10);
    rows.add(JAN_4_M_10);

    List<Row> expectedDay1 = Collections.singletonList(JAN_1_M_10);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_M_10);
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60942,apache_druid,RowBucketIterableTest.testApplyLastDaySingleRow,"  @Test
  public void testApplyLastDaySingleRow()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    List<Row> expectedDay1 = Arrays.asList(JAN_1_M_10, JAN_1_F_20);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_F_20);
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_1_F_20);
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_F_20);
    rows.add(JAN_4_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60943,apache_druid,RowBucketIterableTest.testApplyLastDayMultipleRows,"  @Test
  public void testApplyLastDayMultipleRows()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    List<Row> expectedDay1 = Arrays.asList(JAN_1_M_10, JAN_1_F_20);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_F_20);
    List<Row> expectedDay4 = Arrays.asList(JAN_4_M_10, JAN_4_F_20, JAN_4_U_30);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_1_F_20);
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_F_20);
    rows.add(JAN_4_M_10);
    rows.add(JAN_4_F_20);
    rows.add(JAN_4_U_30);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60944,apache_druid,RowBucketIterableTest.testSingleDaySingleRow,"  @Test
  public void testSingleDaySingleRow()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_1);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);

    List<Row> expectedDay1 = Collections.singletonList(JAN_1_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());
    Assert.assertEquals(JAN_1, actual.getDateTime());
  }
",non-flaky,5
60945,apache_druid,RowBucketIterableTest.testSingleDayMultipleRow,"  @Test
  public void testSingleDayMultipleRow()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_1);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_1_F_20);
    rows.add(JAN_1_U_30);

    List<Row> expectedDay1 = Arrays.asList(JAN_1_M_10, JAN_1_F_20, JAN_1_U_30);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());
  }
",non-flaky,5
60946,apache_druid,RowBucketIterableTest.testMissingDaysAtBegining,"  @Test
  public void testMissingDaysAtBegining()
  {
    List<Row> expectedDay1 = Collections.emptyList();
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_2);

    rows = new ArrayList<>();
    rows.add(JAN_2_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());
  }
",non-flaky,5
60947,apache_druid,RowBucketIterableTest.testMissingDaysAtBeginingFollowedByMultipleRow,"  @Test
  public void testMissingDaysAtBeginingFollowedByMultipleRow()
  {
    List<Row> expectedDay1 = Collections.emptyList();
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_M_10);
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    rows = new ArrayList<>();
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_M_10);
    rows.add(JAN_4_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60948,apache_druid,RowBucketIterableTest.testMissingDaysAtBeginingAndAtTheEnd,"  @Test
  public void testMissingDaysAtBeginingAndAtTheEnd()
  {
    List<Row> expectedDay1 = Collections.emptyList();
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_M_10);
    List<Row> expectedDay4 = Collections.emptyList();

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    rows = new ArrayList<>();
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60949,apache_druid,RowBucketIterableTest.testMultipleMissingDays,"  @Test
  public void testMultipleMissingDays()
  {
    List<Row> expectedDay1 = Collections.emptyList();
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.emptyList();
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    rows = new ArrayList<>();
    rows.add(JAN_2_M_10);
    rows.add(JAN_4_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60950,apache_druid,RowBucketIterableTest.testMultipleMissingDaysMultipleRowAtTheEnd,"  @Test
  public void testMultipleMissingDaysMultipleRowAtTheEnd()
  {
    List<Row> expectedDay1 = Collections.emptyList();
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.emptyList();
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);
    List<Row> expectedDay5 = Collections.singletonList(JAN_5_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_5);

    rows = new ArrayList<>();
    rows.add(JAN_2_M_10);
    rows.add(JAN_4_M_10);
    rows.add(JAN_5_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_5, actual.getDateTime());
    Assert.assertEquals(expectedDay5, actual.getRows());
  }
",non-flaky,5
60951,apache_druid,RowBucketIterableTest.testMissingDaysInMiddleOneRow,"  @Test
  public void testMissingDaysInMiddleOneRow()
  {
    List<Row> expectedDay1 = Collections.singletonList(JAN_1_M_10);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.emptyList();
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_2_M_10);
    rows.add(JAN_4_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60952,apache_druid,RowBucketIterableTest.testMissingDaysInMiddleMultipleRow,"  @Test
  public void testMissingDaysInMiddleMultipleRow()
  {
    List<Row> expectedDay1 = Collections.singletonList(JAN_1_M_10);
    List<Row> expectedDay2 = Collections.emptyList();
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_M_10);
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_3_M_10);
    rows.add(JAN_4_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60953,apache_druid,RowBucketIterableTest.testApplyLastDayNoRows,"  @Test
  public void testApplyLastDayNoRows()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    List<Row> expectedDay1 = Arrays.asList(JAN_1_M_10, JAN_1_F_20);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_F_20);
    List<Row> expectedDay4 = Collections.emptyList();

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_1_F_20);
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_F_20);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60954,apache_druid,RowBucketIterableTest.testApplyLastTwoDayNoRows,"  @Test
  public void testApplyLastTwoDayNoRows()
  {
    List<Row> expectedDay1 = Arrays.asList(JAN_1_M_10, JAN_1_F_20);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.emptyList();
    List<Row> expectedDay4 = Collections.emptyList();

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_1_F_20);
    rows.add(JAN_2_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_4, actual.getDateTime());
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
60955,apache_druid,RowBucketIterableTest.testApplyMultipleInterval,"  @Test
  public void testApplyMultipleInterval()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);
    intervals.add(INTERVAL_JAN_6_8);

    List<Row> expectedDay1 = Arrays.asList(JAN_1_M_10, JAN_1_F_20);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_F_20);
    List<Row> expectedDay4 = Arrays.asList(JAN_4_M_10, JAN_4_F_20, JAN_4_U_30);
    List<Row> expectedDay6 = Collections.singletonList(JAN_6_M_10);
    List<Row> expectedDay7 = Collections.singletonList(JAN_7_F_20);
    List<Row> expectedDay8 = Collections.singletonList(JAN_8_U_30);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_1_F_20);
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_F_20);
    rows.add(JAN_4_M_10);
    rows.add(JAN_4_F_20);
    rows.add(JAN_4_U_30);
    rows.add(JAN_6_M_10);
    rows.add(JAN_7_F_20);
    rows.add(JAN_8_U_30);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay4, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay6, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay7, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay8, actual.getRows());
  }
",non-flaky,5
60956,apache_druid,RowBucketIterableTest.testNodata,"  @Test
  public void testNodata()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);
    intervals.add(INTERVAL_JAN_6_8);

    rows = new ArrayList<>();

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    Assert.assertTrue(iter.hasNext());
    RowBucket actual = iter.next();
    Assert.assertEquals(Collections.emptyList(), actual.getRows());
  }
",non-flaky,5
60957,apache_druid,TDigestSketchAggregatorFactoryTest.testResultArraySignature,"  @Test
  public void testResultArraySignature()
  {
    final TimeseriesQuery query =
        Druids.newTimeseriesQueryBuilder()
              .dataSource(""dummy"")
              .intervals(""2000/3000"")
              .granularity(Granularities.HOUR)
              .aggregators(
                  new CountAggregatorFactory(""count""),
                  new TDigestSketchAggregatorFactory(""tdigest"", ""col"", null)
              )
              .postAggregators(
                  new FieldAccessPostAggregator(""tdigest-access"", ""tdigest""),
                  new FinalizingFieldAccessPostAggregator(""tdigest-finalize"", ""tdigest"")
              )
              .build();

    Assert.assertEquals(
        RowSignature.builder()
                    .addTimeColumn()
                    .add(""count"", ColumnType.LONG)
                    .add(""tdigest"", TDigestSketchAggregatorFactory.TYPE)
                    .add(""tdigest-access"", TDigestSketchAggregatorFactory.TYPE)
                    .add(""tdigest-finalize"", TDigestSketchAggregatorFactory.TYPE)
                    .build(),
        new TimeseriesQueryQueryToolChest().resultArraySignature(query)
    );
  }
",non-flaky,5
60958,apache_druid,TDigestSketchToQuantilePostAggregatorTest.testSerde,"  @Test
  public void testSerde() throws Exception
  {
    TDigestSketchToQuantilePostAggregator there =
        new TDigestSketchToQuantilePostAggregator(""post"", new ConstantPostAggregator("""", 100), 0.5);

    DefaultObjectMapper mapper = new DefaultObjectMapper();
    TDigestSketchToQuantilePostAggregator andBackAgain = mapper.readValue(
        mapper.writeValueAsString(there),
        TDigestSketchToQuantilePostAggregator.class
    );

    Assert.assertEquals(there, andBackAgain);
    Assert.assertArrayEquals(there.getCacheKey(), andBackAgain.getCacheKey());
    Assert.assertEquals(there.getDependentFields(), andBackAgain.getDependentFields());
  }
",non-flaky,5
60959,apache_druid,TDigestSketchToQuantilePostAggregatorTest.testToString,"  @Test
  public void testToString()
  {
    PostAggregator postAgg =
        new TDigestSketchToQuantilePostAggregator(""post"", new ConstantPostAggregator("""", 100), 0.5);

    Assert.assertEquals(
        ""TDigestSketchToQuantilePostAggregator{name='post', field=ConstantPostAggregator{name='', constantValue=100}, fraction=0.5}"",
        postAgg.toString()
    );
  }
",non-flaky,5
60960,apache_druid,TDigestSketchToQuantilePostAggregatorTest.testEquals,"  @Test
  public void testEquals()
  {
    EqualsVerifier.forClass(TDigestSketchToQuantilePostAggregator.class)
                  .withNonnullFields(""name"", ""field"", ""fraction"")
                  .usingGetClass()
                  .verify();
  }
",non-flaky,5
60961,apache_druid,TDigestSketchToQuantilesPostAggregatorTest.testSerde,"  @Test
  public void testSerde() throws Exception
  {
    TDigestSketchToQuantilesPostAggregator there =
        new TDigestSketchToQuantilesPostAggregator(""post"", new ConstantPostAggregator("""", 100), new double[]{0.25, 0.75});

    DefaultObjectMapper mapper = new DefaultObjectMapper();
    TDigestSketchToQuantilesPostAggregator andBackAgain = mapper.readValue(
        mapper.writeValueAsString(there),
        TDigestSketchToQuantilesPostAggregator.class
    );

    Assert.assertEquals(there, andBackAgain);
    Assert.assertArrayEquals(there.getCacheKey(), andBackAgain.getCacheKey());
    Assert.assertEquals(there.getDependentFields(), andBackAgain.getDependentFields());
  }
",non-flaky,5
70765,apache_kafka,StartAndStopCounterTest.shouldRecordStarts,"    @Test
    public void shouldRecordStarts() {
        assertEquals(0, counter.starts());
        counter.recordStart();
        assertEquals(1, counter.starts());
        counter.recordStart();
        assertEquals(2, counter.starts());
        assertEquals(2, counter.starts());
    }
",non-flaky,5
70766,apache_kafka,StartAndStopCounterTest.shouldRecordStops,"    @Test
    public void shouldRecordStops() {
        assertEquals(0, counter.stops());
        counter.recordStop();
        assertEquals(1, counter.stops());
        counter.recordStop();
        assertEquals(2, counter.stops());
        assertEquals(2, counter.stops());
    }
",non-flaky,5
70767,apache_kafka,StartAndStopCounterTest.shouldExpectRestarts,"    @Test
    public void shouldExpectRestarts() throws Exception {
        waiters = Executors.newSingleThreadExecutor();

        latch = counter.expectedRestarts(1);
        Future<Boolean> future = asyncAwait(100, TimeUnit.MILLISECONDS);

        clock.sleep(1000);
        counter.recordStop();
        counter.recordStart();
        assertTrue(future.get(200, TimeUnit.MILLISECONDS));
        assertTrue(future.isDone());
    }
",non-flaky,5
70768,apache_kafka,StartAndStopCounterTest.shouldFailToWaitForRestartThatNeverHappens,"    @Test
    public void shouldFailToWaitForRestartThatNeverHappens() throws Exception {
        waiters = Executors.newSingleThreadExecutor();

        latch = counter.expectedRestarts(1);
        Future<Boolean> future = asyncAwait(100, TimeUnit.MILLISECONDS);

        clock.sleep(1000);
        // Record a stop but NOT a start
        counter.recordStop();
        assertFalse(future.get(200, TimeUnit.MILLISECONDS));
        assertTrue(future.isDone());
    }
",non-flaky,5
70769,apache_kafka,ConnectWorkerIntegrationTest.testAddAndRemoveWorker,"    @Test
    public void testAddAndRemoveWorker() throws Exception {
        connect = connectBuilder.build();
        // start the clusters
        connect.start();

        int numTasks = 4;
        // create test topic
        connect.kafka().createTopic(""test-topic"", NUM_TOPIC_PARTITIONS);

        // setup up props for the sink connector
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(numTasks));
        props.put(""throughput"", String.valueOf(1));
        props.put(""messages.per.poll"", String.valueOf(10));
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());

        waitForCondition(() -> assertWorkersUp(NUM_WORKERS).orElse(false),
                WORKER_SETUP_DURATION_MS, ""Initial group of workers did not start in time."");

        // start a source connector
        connect.configureConnector(CONNECTOR_NAME, props);

        waitForCondition(() -> assertConnectorAndTasksRunning(CONNECTOR_NAME, numTasks).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");

        WorkerHandle extraWorker = connect.addWorker();

        waitForCondition(() -> assertWorkersUp(NUM_WORKERS + 1).orElse(false),
                WORKER_SETUP_DURATION_MS, ""Expanded group of workers did not start in time."");

        waitForCondition(() -> assertConnectorAndTasksRunning(CONNECTOR_NAME, numTasks).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks are not all in running state."");

        Set<WorkerHandle> workers = connect.activeWorkers();
        assertTrue(workers.contains(extraWorker));

        connect.removeWorker(extraWorker);

        waitForCondition(() -> assertWorkersUp(NUM_WORKERS).orElse(false) && !assertWorkersUp(NUM_WORKERS + 1).orElse(false),
                WORKER_SETUP_DURATION_MS, ""Group of workers did not shrink in time."");

        workers = connect.activeWorkers();
        assertFalse(workers.contains(extraWorker));
    }
",non-flaky,5
70770,apache_kafka,ConnectWorkerIntegrationTest.testRestartFailedTask,"    @Test
    public void testRestartFailedTask() throws Exception {
        connect = connectBuilder.build();
        // start the clusters
        connect.start();

        int numTasks = 1;

        // Properties for the source connector. The task should fail at startup due to the bad broker address.
        Map<String, String> connectorProps = new HashMap<>();
        connectorProps.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getName());
        connectorProps.put(TASKS_MAX_CONFIG, Objects.toString(numTasks));
        connectorProps.put(CONNECTOR_CLIENT_PRODUCER_OVERRIDES_PREFIX + BOOTSTRAP_SERVERS_CONFIG, ""nobrokerrunningatthisaddress"");

        waitForCondition(() -> assertWorkersUp(NUM_WORKERS).orElse(false),
                WORKER_SETUP_DURATION_MS, ""Initial group of workers did not start in time."");

        // Try to start the connector and its single task.
        connect.configureConnector(CONNECTOR_NAME, connectorProps);

        waitForCondition(() -> assertConnectorTasksFailed(CONNECTOR_NAME, numTasks).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not fail in time"");

        // Reconfigure the connector without the bad broker address.
        connectorProps.remove(CONNECTOR_CLIENT_PRODUCER_OVERRIDES_PREFIX + BOOTSTRAP_SERVERS_CONFIG);
        connect.configureConnector(CONNECTOR_NAME, connectorProps);

        // Restart the failed task
        String taskRestartEndpoint = connect.endpointForResource(
            String.format(""connectors/%s/tasks/0/restart"", CONNECTOR_NAME));
        connect.executePost(taskRestartEndpoint, """", Collections.emptyMap());

        // Ensure the task started successfully this time
        waitForCondition(() -> assertConnectorAndTasksRunning(CONNECTOR_NAME, numTasks).orElse(false),
            CONNECTOR_SETUP_DURATION_MS, ""Connector tasks are not all in running state."");
    }
",non-flaky,5
70771,apache_kafka,ConnectWorkerIntegrationTest.testBrokerCoordinator,"    @Test
    public void testBrokerCoordinator() throws Exception {
        workerProps.put(DistributedConfig.SCHEDULED_REBALANCE_MAX_DELAY_MS_CONFIG, String.valueOf(5000));
        connect = connectBuilder.workerProps(workerProps).build();
        // start the clusters
        connect.start();
        int numTasks = 4;
        // create test topic
        connect.kafka().createTopic(""test-topic"", NUM_TOPIC_PARTITIONS);

        // setup up props for the sink connector
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(numTasks));
        props.put(""topic"", ""test-topic"");
        props.put(""throughput"", String.valueOf(1));
        props.put(""messages.per.poll"", String.valueOf(10));
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());

        waitForCondition(() -> assertWorkersUp(NUM_WORKERS).orElse(false),
                WORKER_SETUP_DURATION_MS, ""Initial group of workers did not start in time."");

        // start a source connector
        connect.configureConnector(CONNECTOR_NAME, props);

        waitForCondition(() -> assertConnectorAndTasksRunning(CONNECTOR_NAME, numTasks).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");

        connect.kafka().stopOnlyKafka();

        waitForCondition(() -> assertWorkersUp(NUM_WORKERS).orElse(false),
                WORKER_SETUP_DURATION_MS, ""Group of workers did not remain the same after broker shutdown"");

        // Allow for the workers to discover that the coordinator is unavailable, wait is
        // heartbeat timeout * 2 + 4sec
        Thread.sleep(TimeUnit.SECONDS.toMillis(10));

        connect.kafka().startOnlyKafkaOnSamePorts();

        // Allow for the kafka brokers to come back online
        Thread.sleep(TimeUnit.SECONDS.toMillis(10));

        waitForCondition(() -> assertWorkersUp(NUM_WORKERS).orElse(false),
                WORKER_SETUP_DURATION_MS, ""Group of workers did not remain the same within the ""
                        + ""designated time."");

        // Allow for the workers to rebalance and reach a steady state
        Thread.sleep(TimeUnit.SECONDS.toMillis(10));

        waitForCondition(() -> assertConnectorAndTasksRunning(CONNECTOR_NAME, numTasks).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");
    }
",non-flaky,5
70772,apache_kafka,RebalanceSourceConnectorsIntegrationTest.testStartTwoConnectors,"    @Test
    public void testStartTwoConnectors() throws Exception {
        // create test topic
        connect.kafka().createTopic(TOPIC_NAME, NUM_TOPIC_PARTITIONS);

        // setup up props for the source connector
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));
        props.put(""throughput"", String.valueOf(1));
        props.put(""messages.per.poll"", String.valueOf(10));
        props.put(TOPIC_CONFIG, TOPIC_NAME);
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());

        // start a source connector
        connect.configureConnector(CONNECTOR_NAME, props);

        waitForCondition(() -> this.assertConnectorAndTasksRunning(CONNECTOR_NAME, NUM_TASKS).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");

        // start a source connector
        connect.configureConnector(""another-source"", props);

        waitForCondition(() -> this.assertConnectorAndTasksRunning(CONNECTOR_NAME, NUM_TASKS).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");

        waitForCondition(() -> this.assertConnectorAndTasksRunning(""another-source"", 4).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");
    }
",non-flaky,5
70773,apache_kafka,RebalanceSourceConnectorsIntegrationTest.testReconfigConnector,"    @Test
    public void testReconfigConnector() throws Exception {
        ConnectorHandle connectorHandle = RuntimeHandles.get().connectorHandle(CONNECTOR_NAME);

        // create test topic
        String anotherTopic = ""another-topic"";
        connect.kafka().createTopic(TOPIC_NAME, NUM_TOPIC_PARTITIONS);
        connect.kafka().createTopic(anotherTopic, NUM_TOPIC_PARTITIONS);

        // setup up props for the source connector
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));
        props.put(""throughput"", String.valueOf(1));
        props.put(""messages.per.poll"", String.valueOf(10));
        props.put(TOPIC_CONFIG, TOPIC_NAME);
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());

        // start a source connector
        connect.configureConnector(CONNECTOR_NAME, props);

        waitForCondition(() -> this.assertConnectorAndTasksRunning(CONNECTOR_NAME, NUM_TASKS).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");

        int numRecordsProduced = 100;
        long recordTransferDurationMs = TimeUnit.SECONDS.toMillis(30);

        // consume all records from the source topic or fail, to ensure that they were correctly produced
        int recordNum = connect.kafka().consume(numRecordsProduced, recordTransferDurationMs, TOPIC_NAME).count();
        assertTrue(""Not enough records produced by source connector. Expected at least: "" + numRecordsProduced + "" + but got "" + recordNum,
                recordNum >= numRecordsProduced);

        // expect that we're going to restart the connector and its tasks
        StartAndStopLatch restartLatch = connectorHandle.expectedStarts(1);

        // Reconfigure the source connector by changing the Kafka topic used as output
        props.put(TOPIC_CONFIG, anotherTopic);
        connect.configureConnector(CONNECTOR_NAME, props);

        // Wait for the connector *and tasks* to be restarted
        assertTrue(""Failed to alter connector configuration and see connector and tasks restart ""
                   + ""within "" + CONNECTOR_SETUP_DURATION_MS + ""ms"",
                restartLatch.await(CONNECTOR_SETUP_DURATION_MS, TimeUnit.MILLISECONDS));

        // And wait for the Connect to show the connectors and tasks are running
        waitForCondition(() -> this.assertConnectorAndTasksRunning(CONNECTOR_NAME, NUM_TASKS).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");

        // consume all records from the source topic or fail, to ensure that they were correctly produced
        recordNum = connect.kafka().consume(numRecordsProduced, recordTransferDurationMs, anotherTopic).count();
        assertTrue(""Not enough records produced by source connector. Expected at least: "" + numRecordsProduced + "" + but got "" + recordNum,
                recordNum >= numRecordsProduced);
    }
",non-flaky,5
70774,apache_kafka,RebalanceSourceConnectorsIntegrationTest.testDeleteConnector,"    @Test
    public void testDeleteConnector() throws Exception {
        // create test topic
        connect.kafka().createTopic(TOPIC_NAME, NUM_TOPIC_PARTITIONS);

        // setup up props for the source connector
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));
        props.put(""throughput"", String.valueOf(1));
        props.put(""messages.per.poll"", String.valueOf(10));
        props.put(TOPIC_CONFIG, TOPIC_NAME);
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());

        waitForCondition(() -> this.assertWorkersUp(3),
                WORKER_SETUP_DURATION_MS, ""Connect workers did not start in time."");

        // start a source connector
        IntStream.range(0, 4).forEachOrdered(
            i -> {
                try {
                    connect.configureConnector(CONNECTOR_NAME + i, props);
                } catch (IOException e) {
                    throw new ConnectException(e);
                }
            });

        waitForCondition(() -> this.assertConnectorAndTasksRunning(CONNECTOR_NAME + 3, NUM_TASKS).orElse(true),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");

        // delete connector
        connect.deleteConnector(CONNECTOR_NAME + 3);

        waitForCondition(() -> !this.assertConnectorAndTasksRunning(CONNECTOR_NAME + 3, NUM_TASKS).orElse(true),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not stop in time."");

        waitForCondition(this::assertConnectorAndTasksAreUnique,
                WORKER_SETUP_DURATION_MS, ""Connect and tasks are imbalanced between the workers."");
    }
",non-flaky,5
70775,apache_kafka,RebalanceSourceConnectorsIntegrationTest.testAddingWorker,"    @Test
    public void testAddingWorker() throws Exception {
        // create test topic
        connect.kafka().createTopic(TOPIC_NAME, NUM_TOPIC_PARTITIONS);

        // setup up props for the source connector
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));
        props.put(""throughput"", String.valueOf(1));
        props.put(""messages.per.poll"", String.valueOf(10));
        props.put(TOPIC_CONFIG, TOPIC_NAME);
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());

        waitForCondition(() -> this.assertWorkersUp(3),
                WORKER_SETUP_DURATION_MS, ""Connect workers did not start in time."");

        // start a source connector
        IntStream.range(0, 4).forEachOrdered(
            i -> {
                try {
                    connect.configureConnector(CONNECTOR_NAME + i, props);
                } catch (IOException e) {
                    throw new ConnectException(e);
                }
            });

        waitForCondition(() -> this.assertConnectorAndTasksRunning(CONNECTOR_NAME + 3, NUM_TASKS).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");

        connect.addWorker();

        waitForCondition(() -> this.assertWorkersUp(4),
                WORKER_SETUP_DURATION_MS, ""Connect workers did not start in time."");

        waitForCondition(() -> this.assertConnectorAndTasksRunning(CONNECTOR_NAME + 3, NUM_TASKS).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");

        waitForCondition(this::assertConnectorAndTasksAreUnique,
                WORKER_SETUP_DURATION_MS, ""Connect and tasks are imbalanced between the workers."");
    }
",non-flaky,5
70776,apache_kafka,RebalanceSourceConnectorsIntegrationTest.testRemovingWorker,"    @Test
    public void testRemovingWorker() throws Exception {
        // create test topic
        connect.kafka().createTopic(TOPIC_NAME, NUM_TOPIC_PARTITIONS);

        // setup up props for the source connector
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));
        props.put(""throughput"", String.valueOf(1));
        props.put(""messages.per.poll"", String.valueOf(10));
        props.put(TOPIC_CONFIG, TOPIC_NAME);
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());

        waitForCondition(() -> this.assertWorkersUp(3),
                WORKER_SETUP_DURATION_MS, ""Connect workers did not start in time."");

        // start a source connector
        IntStream.range(0, 4).forEachOrdered(
            i -> {
                try {
                    connect.configureConnector(CONNECTOR_NAME + i, props);
                } catch (IOException e) {
                    throw new ConnectException(e);
                }
            });

        waitForCondition(() -> this.assertConnectorAndTasksRunning(CONNECTOR_NAME + 3, NUM_TASKS).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");

        connect.removeWorker();

        waitForCondition(() -> this.assertWorkersUp(2),
                WORKER_SETUP_DURATION_MS, ""Connect workers did not start in time."");

        waitForCondition(this::assertConnectorAndTasksAreUnique,
                WORKER_SETUP_DURATION_MS, ""Connect and tasks are imbalanced between the workers."");
    }
",non-flaky,5
70777,apache_kafka,SessionedProtocolIntegrationTest.ensureInternalEndpointIsSecured,"    @Test
    public void ensureInternalEndpointIsSecured() throws Throwable {
        final String connectorTasksEndpoint = connect.endpointForResource(String.format(
            ""connectors/%s/tasks"",
            CONNECTOR_NAME
        ));
        final Map<String, String> emptyHeaders = new HashMap<>();
        final Map<String, String> invalidSignatureHeaders = new HashMap<>();
        invalidSignatureHeaders.put(SIGNATURE_HEADER, ""S2Fma2Flc3F1ZQ=="");
        invalidSignatureHeaders.put(SIGNATURE_ALGORITHM_HEADER, ""HmacSHA256"");

        // We haven't created the connector yet, but this should still return a 400 instead of a 404
        // if the endpoint is secured
        log.info(
            ""Making a POST request to the {} endpoint with no connector started and no signature header; "" 
                + ""expecting 400 error response"",
            connectorTasksEndpoint
        );
        assertEquals(
            BAD_REQUEST.getStatusCode(),
            connect.executePost(connectorTasksEndpoint, ""[]"", emptyHeaders)
        );

        // Try again, but with an invalid signature
        log.info(
            ""Making a POST request to the {} endpoint with no connector started and an invalid signature header; ""
                + ""expecting 403 error response"",
            connectorTasksEndpoint
        );
        assertEquals(
            FORBIDDEN.getStatusCode(),
            connect.executePost(connectorTasksEndpoint, ""[]"", invalidSignatureHeaders)
        );

        // Create the connector now
        // setup up props for the sink connector
        Map<String, String> connectorProps = new HashMap<>();
        connectorProps.put(CONNECTOR_CLASS_CONFIG, MonitorableSinkConnector.class.getSimpleName());
        connectorProps.put(TASKS_MAX_CONFIG, String.valueOf(1));
        connectorProps.put(TOPICS_CONFIG, ""test-topic"");
        connectorProps.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        connectorProps.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());

        // start a sink connector
        log.info(""Starting the {} connector"", CONNECTOR_NAME);
        StartAndStopLatch startLatch = connectorHandle.expectedStarts(1);
        connect.configureConnector(CONNECTOR_NAME, connectorProps);
        startLatch.await(CONNECTOR_SETUP_DURATION_MS, TimeUnit.MILLISECONDS);


        // Verify the exact same behavior, after starting the connector

        // We haven't created the connector yet, but this should still return a 400 instead of a 404
        // if the endpoint is secured
        log.info(
            ""Making a POST request to the {} endpoint with the connector started and no signature header; ""
                + ""expecting 400 error response"",
            connectorTasksEndpoint
        );
        assertEquals(
            BAD_REQUEST.getStatusCode(),
            connect.executePost(connectorTasksEndpoint, ""[]"", emptyHeaders)
        );

        // Try again, but with an invalid signature
        log.info(
            ""Making a POST request to the {} endpoint with the connector started and an invalid signature header; ""
                + ""expecting 403 error response"",
            connectorTasksEndpoint
        );
        assertEquals(
            FORBIDDEN.getStatusCode(),
            connect.executePost(connectorTasksEndpoint, ""[]"", invalidSignatureHeaders)
        );
    }
",non-flaky,5
70778,apache_kafka,ErrorHandlingIntegrationTest.testSkipRetryAndDLQWithHeaders,"    @Test
    public void testSkipRetryAndDLQWithHeaders() throws Exception {
        // create test topic
        connect.kafka().createTopic(""test-topic"");

        // setup connector config
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSinkConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));
        props.put(TOPICS_CONFIG, ""test-topic"");
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(TRANSFORMS_CONFIG, ""failing_transform"");
        props.put(""transforms.failing_transform.type"", FaultyPassthrough.class.getName());

        // log all errors, along with message metadata
        props.put(ERRORS_LOG_ENABLE_CONFIG, ""true"");
        props.put(ERRORS_LOG_INCLUDE_MESSAGES_CONFIG, ""true"");

        // produce bad messages into dead letter queue
        props.put(DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC);
        props.put(DLQ_CONTEXT_HEADERS_ENABLE_CONFIG, ""true"");
        props.put(DLQ_TOPIC_REPLICATION_FACTOR_CONFIG, ""1"");

        // tolerate all erros
        props.put(ERRORS_TOLERANCE_CONFIG, ""all"");

        // retry for up to one second
        props.put(ERRORS_RETRY_TIMEOUT_CONFIG, ""1000"");

        // set expected records to successfully reach the task
        connectorHandle.taskHandle(TASK_ID).expectedRecords(EXPECTED_CORRECT_RECORDS);

        connect.configureConnector(CONNECTOR_NAME, props);

        waitForCondition(this::checkForPartitionAssignment,
                CONNECTOR_SETUP_DURATION_MS,
                ""Connector task was not assigned a partition."");

        // produce some strings into test topic
        for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {
            connect.kafka().produce(""test-topic"", ""key-"" + i, ""value-"" + i);
        }

        // consume all records from test topic
        log.info(""Consuming records from test topic"");
        int i = 0;
        for (ConsumerRecord<byte[], byte[]> rec : connect.kafka().consume(NUM_RECORDS_PRODUCED, CONSUME_MAX_DURATION_MS, ""test-topic"")) {
            String k = new String(rec.key());
            String v = new String(rec.value());
            log.debug(""Consumed record (key='{}', value='{}') from topic {}"", k, v, rec.topic());
            assertEquals(""Unexpected key"", k, ""key-"" + i);
            assertEquals(""Unexpected value"", v, ""value-"" + i);
            i++;
        }

        // wait for records to reach the task
        connectorHandle.taskHandle(TASK_ID).awaitRecords(CONSUME_MAX_DURATION_MS);

        // consume failed records from dead letter queue topic
        log.info(""Consuming records from test topic"");
        ConsumerRecords<byte[], byte[]> messages = connect.kafka().consume(EXPECTED_INCORRECT_RECORDS, CONSUME_MAX_DURATION_MS, DLQ_TOPIC);
        for (ConsumerRecord<byte[], byte[]> recs : messages) {
            log.debug(""Consumed record (key={}, value={}) from dead letter queue topic {}"",
                    new String(recs.key()), new String(recs.value()), DLQ_TOPIC);
            assertTrue(recs.headers().toArray().length > 0);
            assertValue(""test-topic"", recs.headers(), ERROR_HEADER_ORIG_TOPIC);
            assertValue(RetriableException.class.getName(), recs.headers(), ERROR_HEADER_EXCEPTION);
            assertValue(""Error when value='value-7'"", recs.headers(), ERROR_HEADER_EXCEPTION_MESSAGE);
        }

        connect.deleteConnector(CONNECTOR_NAME);
    }
",non-flaky,5
70779,apache_kafka,ConnectorClientPolicyIntegrationTest.testCreateWithOverridesForNonePolicy,"    @Test
    public void testCreateWithOverridesForNonePolicy() throws Exception {
        Map<String, String> props = basicConnectorConfig();
        props.put(ConnectorConfig.CONNECTOR_CLIENT_CONSUMER_OVERRIDES_PREFIX + SaslConfigs.SASL_JAAS_CONFIG, ""sasl"");
        assertFailCreateConnector(""None"", props);
    }
",non-flaky,5
70780,apache_kafka,ConnectorClientPolicyIntegrationTest.testCreateWithNotAllowedOverridesForPrincipalPolicy,"    @Test
    public void testCreateWithNotAllowedOverridesForPrincipalPolicy() throws Exception {
        Map<String, String> props = basicConnectorConfig();
        props.put(ConnectorConfig.CONNECTOR_CLIENT_CONSUMER_OVERRIDES_PREFIX + SaslConfigs.SASL_JAAS_CONFIG, ""sasl"");
        props.put(ConnectorConfig.CONNECTOR_CLIENT_CONSUMER_OVERRIDES_PREFIX + ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, ""latest"");
        assertFailCreateConnector(""Principal"", props);
    }
",non-flaky,5
70781,apache_kafka,ConnectorClientPolicyIntegrationTest.testCreateWithAllowedOverridesForPrincipalPolicy,"    @Test
    public void testCreateWithAllowedOverridesForPrincipalPolicy() throws Exception {
        Map<String, String> props = basicConnectorConfig();
        props.put(ConnectorConfig.CONNECTOR_CLIENT_CONSUMER_OVERRIDES_PREFIX + CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, ""PLAIN"");
        assertPassCreateConnector(""Principal"", props);
    }
",non-flaky,5
70782,apache_kafka,ConnectorClientPolicyIntegrationTest.testCreateWithAllowedOverridesForAllPolicy,"    @Test
    public void testCreateWithAllowedOverridesForAllPolicy() throws Exception {
        // setup up props for the sink connector
        Map<String, String> props = basicConnectorConfig();
        props.put(ConnectorConfig.CONNECTOR_CLIENT_CONSUMER_OVERRIDES_PREFIX + CommonClientConfigs.CLIENT_ID_CONFIG, ""test"");
        assertPassCreateConnector(""All"", props);
    }
",non-flaky,5
70783,apache_kafka,StartAndStopLatchTest.shouldReturnFalseWhenAwaitingForStartToNeverComplete,"    @Test
    public void shouldReturnFalseWhenAwaitingForStartToNeverComplete() throws Throwable {
        latch = new StartAndStopLatch(1, 1, this::complete, dependents, clock);
        future = asyncAwait(100);
        clock.sleep(10);
        assertFalse(future.get(200, TimeUnit.MILLISECONDS));
        assertTrue(future.isDone());
    }
",non-flaky,5
70784,apache_kafka,StartAndStopLatchTest.shouldReturnFalseWhenAwaitingForStopToNeverComplete,"    @Test
    public void shouldReturnFalseWhenAwaitingForStopToNeverComplete() throws Throwable {
        latch = new StartAndStopLatch(1, 1, this::complete, dependents, clock);
        future = asyncAwait(100);
        latch.recordStart();
        clock.sleep(10);
        assertFalse(future.get(200, TimeUnit.MILLISECONDS));
        assertTrue(future.isDone());
    }
",non-flaky,5
70785,apache_kafka,StartAndStopLatchTest.shouldReturnTrueWhenAwaitingForStartAndStopToComplete,"    @Test
    public void shouldReturnTrueWhenAwaitingForStartAndStopToComplete() throws Throwable {
        latch = new StartAndStopLatch(1, 1, this::complete, dependents, clock);
        future = asyncAwait(100);
        latch.recordStart();
        latch.recordStop();
        clock.sleep(10);
        assertTrue(future.get(200, TimeUnit.MILLISECONDS));
        assertTrue(future.isDone());
    }
",non-flaky,5
70786,apache_kafka,StartAndStopLatchTest.shouldReturnFalseWhenAwaitingForDependentLatchToComplete,"    @Test
    public void shouldReturnFalseWhenAwaitingForDependentLatchToComplete() throws Throwable {
        StartAndStopLatch depLatch = new StartAndStopLatch(1, 1, this::complete, null, clock);
        dependents = Collections.singletonList(depLatch);
        latch = new StartAndStopLatch(1, 1, this::complete, dependents, clock);

        future = asyncAwait(100);
        latch.recordStart();
        latch.recordStop();
        clock.sleep(10);
        assertFalse(future.get(200, TimeUnit.MILLISECONDS));
        assertTrue(future.isDone());
    }
",non-flaky,5
70787,apache_kafka,StartAndStopLatchTest.shouldReturnTrueWhenAwaitingForStartAndStopAndDependentLatch,"    @Test
    public void shouldReturnTrueWhenAwaitingForStartAndStopAndDependentLatch() throws Throwable {
        StartAndStopLatch depLatch = new StartAndStopLatch(1, 1, this::complete, null, clock);
        dependents = Collections.singletonList(depLatch);
        latch = new StartAndStopLatch(1, 1, this::complete, dependents, clock);

        future = asyncAwait(100);
        latch.recordStart();
        latch.recordStop();
        depLatch.recordStart();
        depLatch.recordStop();
        clock.sleep(10);
        assertTrue(future.get(200, TimeUnit.MILLISECONDS));
        assertTrue(future.isDone());
    }
",non-flaky,5
70788,apache_kafka,ExampleConnectIntegrationTest.testSinkConnector,"    @Test
    public void testSinkConnector() throws Exception {
        // create test topic
        connect.kafka().createTopic(""test-topic"", NUM_TOPIC_PARTITIONS);

        // setup up props for the sink connector
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSinkConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));
        props.put(TOPICS_CONFIG, ""test-topic"");
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());

        // expect all records to be consumed by the connector
        connectorHandle.expectedRecords(NUM_RECORDS_PRODUCED);

        // expect all records to be consumed by the connector
        connectorHandle.expectedCommits(NUM_RECORDS_PRODUCED);

        // start a sink connector
        connect.configureConnector(CONNECTOR_NAME, props);

        waitForCondition(this::checkForPartitionAssignment,
                CONNECTOR_SETUP_DURATION_MS,
                ""Connector tasks were not assigned a partition each."");

        // produce some messages into source topic partitions
        for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {
            connect.kafka().produce(""test-topic"", i % NUM_TOPIC_PARTITIONS, ""key"", ""simple-message-value-"" + i);
        }

        // consume all records from the source topic or fail, to ensure that they were correctly produced.
        assertEquals(""Unexpected number of records consumed"", NUM_RECORDS_PRODUCED,
                connect.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, ""test-topic"").count());

        // wait for the connector tasks to consume all records.
        connectorHandle.awaitRecords(RECORD_TRANSFER_DURATION_MS);

        // wait for the connector tasks to commit all records.
        connectorHandle.awaitCommits(RECORD_TRANSFER_DURATION_MS);

        // delete connector
        connect.deleteConnector(CONNECTOR_NAME);
    }
",non-flaky,5
70789,apache_kafka,ExampleConnectIntegrationTest.testSourceConnector,"    @Test
    public void testSourceConnector() throws Exception {
        // create test topic
        connect.kafka().createTopic(""test-topic"", NUM_TOPIC_PARTITIONS);

        // setup up props for the sink connector
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));
        props.put(""topic"", ""test-topic"");
        props.put(""throughput"", String.valueOf(500));
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());

        // expect all records to be produced by the connector
        connectorHandle.expectedRecords(NUM_RECORDS_PRODUCED);

        // expect all records to be produced by the connector
        connectorHandle.expectedCommits(NUM_RECORDS_PRODUCED);

        // start a source connector
        connect.configureConnector(CONNECTOR_NAME, props);

        // wait for the connector tasks to produce enough records
        connectorHandle.awaitRecords(RECORD_TRANSFER_DURATION_MS);

        // wait for the connector tasks to commit enough records
        connectorHandle.awaitCommits(RECORD_TRANSFER_DURATION_MS);

        // consume all records from the source topic or fail, to ensure that they were correctly produced
        int recordNum = connect.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, ""test-topic"").count();
        assertTrue(""Not enough records produced by source connector. Expected at least: "" + NUM_RECORDS_PRODUCED + "" + but got "" + recordNum,
                recordNum >= NUM_RECORDS_PRODUCED);

        // delete connector
        connect.deleteConnector(CONNECTOR_NAME);
    }
",non-flaky,5
70790,apache_kafka,RestExtensionIntegrationTest.testRestExtensionApi,"    @Test
    public void testRestExtensionApi() throws IOException, InterruptedException {
        // setup Connect worker properties
        Map<String, String> workerProps = new HashMap<>();
        workerProps.put(REST_EXTENSION_CLASSES_CONFIG, IntegrationTestRestExtension.class.getName());

        // build a Connect cluster backed by Kafka and Zk
        connect = new EmbeddedConnectCluster.Builder()
            .name(""connect-cluster"")
            .numWorkers(1)
            .numBrokers(1)
            .workerProps(workerProps)
            .build();

        // start the clusters
        connect.start();

        WorkerHandle worker = connect.workers().stream()
            .findFirst()
            .orElseThrow(() -> new AssertionError(""At least one worker handle should be available""));

        waitForCondition(
            this::extensionIsRegistered,
            REST_EXTENSION_REGISTRATION_TIMEOUT_MS,
            ""REST extension was never registered""
        );

        ConnectorHandle connectorHandle = RuntimeHandles.get().connectorHandle(""test-conn"");
        try {
            // setup up props for the connector
            Map<String, String> connectorProps = new HashMap<>();
            connectorProps.put(CONNECTOR_CLASS_CONFIG, MonitorableSinkConnector.class.getSimpleName());
            connectorProps.put(TASKS_MAX_CONFIG, String.valueOf(1));
            connectorProps.put(TOPICS_CONFIG, ""test-topic"");

            // start a connector
            connectorHandle.taskHandle(connectorHandle.name() + ""-0"");
            StartAndStopLatch connectorStartLatch = connectorHandle.expectedStarts(1);
            connect.configureConnector(connectorHandle.name(), connectorProps);
            connectorStartLatch.await(CONNECTOR_HEALTH_AND_CONFIG_TIMEOUT_MS, TimeUnit.MILLISECONDS);

            String workerId = String.format(""%s:%d"", worker.url().getHost(), worker.url().getPort());
            ConnectorHealth expectedHealth = new ConnectorHealth(
                connectorHandle.name(),
                new ConnectorState(
                    ""RUNNING"",
                    workerId,
                    null
                ),
                Collections.singletonMap(
                    0,
                    new TaskState(0, ""RUNNING"", workerId, null)
                ),
                ConnectorType.SINK
            );

            connectorProps.put(NAME_CONFIG, connectorHandle.name());

            // Test the REST extension API; specifically, that the connector's health and configuration
            // are available to the REST extension we registered and that they contain expected values
            waitForCondition(
                () -> verifyConnectorHealthAndConfig(connectorHandle.name(), expectedHealth, connectorProps),
                CONNECTOR_HEALTH_AND_CONFIG_TIMEOUT_MS,
                ""Connector health and/or config was never accessible by the REST extension""
            );
        } finally {
            RuntimeHandles.get().deleteConnector(connectorHandle.name());
        }
    }
",non-flaky,5
70791,apache_kafka,DelegatingClassLoaderTest.testWhiteListedManifestResources,"    @Test
    public void testWhiteListedManifestResources() {
        assertTrue(
            DelegatingClassLoader.serviceLoaderManifestForPlugin(""META-INF/services/org.apache.kafka.connect.rest.ConnectRestExtension""));
        assertTrue(
            DelegatingClassLoader.serviceLoaderManifestForPlugin(""META-INF/services/org.apache.kafka.common.config.provider.ConfigProvider""));
    }
",non-flaky,5
70792,apache_kafka,DelegatingClassLoaderTest.testOtherResources,"    @Test
    public void testOtherResources() {
        assertFalse(
            DelegatingClassLoader.serviceLoaderManifestForPlugin(""META-INF/services/org.apache.kafka.connect.transforms.Transformation""));
        assertFalse(DelegatingClassLoader.serviceLoaderManifestForPlugin(""resource/version.properties""));
    }
",non-flaky,5
70793,apache_kafka,DelegatingClassLoaderTest.testLoadingUnloadedPluginClass,"    @Test(expected = ClassNotFoundException.class)
    public void testLoadingUnloadedPluginClass() throws ClassNotFoundException {
        TestPlugins.assertAvailable();
        DelegatingClassLoader classLoader = new DelegatingClassLoader(Collections.emptyList());
        classLoader.initLoaders();
        for (String pluginClassName : TestPlugins.pluginClasses()) {
            classLoader.loadClass(pluginClassName);
        }
    }
",non-flaky,5
70794,apache_kafka,DelegatingClassLoaderTest.testLoadingPluginClass,"    @Test
    public void testLoadingPluginClass() throws ClassNotFoundException {
        TestPlugins.assertAvailable();
        DelegatingClassLoader classLoader = new DelegatingClassLoader(TestPlugins.pluginPath());
        classLoader.initLoaders();
        for (String pluginClassName : TestPlugins.pluginClasses()) {
            assertNotNull(classLoader.loadClass(pluginClassName));
            assertNotNull(classLoader.pluginClassLoader(pluginClassName));
        }
    }
",non-flaky,5
70795,apache_kafka,PluginUtilsTest.testJavaLibraryClasses,"    @Test
    public void testJavaLibraryClasses() {
        assertFalse(PluginUtils.shouldLoadInIsolation(""java.""));
        assertFalse(PluginUtils.shouldLoadInIsolation(""java.lang.Object""));
        assertFalse(PluginUtils.shouldLoadInIsolation(""java.lang.String""));
        assertFalse(PluginUtils.shouldLoadInIsolation(""java.util.HashMap$Entry""));
        assertFalse(PluginUtils.shouldLoadInIsolation(""java.io.Serializable""));
        assertFalse(PluginUtils.shouldLoadInIsolation(""javax.rmi.""));
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""javax.management.loading.ClassLoaderRepository"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(""org.omg.CORBA.""));
        assertFalse(PluginUtils.shouldLoadInIsolation(""org.omg.CORBA.Object""));
        assertFalse(PluginUtils.shouldLoadInIsolation(""org.w3c.dom.""));
        assertFalse(PluginUtils.shouldLoadInIsolation(""org.w3c.dom.traversal.TreeWalker""));
        assertFalse(PluginUtils.shouldLoadInIsolation(""org.xml.sax.""));
        assertFalse(PluginUtils.shouldLoadInIsolation(""org.xml.sax.EntityResolver""));
    }
",non-flaky,5
70796,apache_kafka,PluginUtilsTest.testThirdPartyClasses,"    @Test
    public void testThirdPartyClasses() {
        assertFalse(PluginUtils.shouldLoadInIsolation(""org.slf4j.""));
        assertFalse(PluginUtils.shouldLoadInIsolation(""org.slf4j.LoggerFactory""));
    }
",non-flaky,5
70797,apache_kafka,PluginUtilsTest.testConnectFrameworkClasses,"    @Test
    public void testConnectFrameworkClasses() {
        assertFalse(PluginUtils.shouldLoadInIsolation(""org.apache.kafka.common.""));
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.common.config.AbstractConfig"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.common.config.ConfigDef$Type"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.common.serialization.Deserializer"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(""org.apache.kafka.connect.""));
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.connector.Connector"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.source.SourceConnector"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.sink.SinkConnector"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(""org.apache.kafka.connect.connector.Task""));
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.source.SourceTask"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(""org.apache.kafka.connect.sink.SinkTask""));
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.transforms.Transformation"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.storage.Converter"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.storage.OffsetBackingStore"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.clients.producer.ProducerConfig"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.clients.consumer.ConsumerConfig"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.clients.admin.KafkaAdminClient"")
        );
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.rest.ConnectRestExtension"")
        );
    }
",non-flaky,5
70798,apache_kafka,PluginUtilsTest.testAllowedConnectFrameworkClasses,"    @Test
    public void testAllowedConnectFrameworkClasses() {
        assertTrue(PluginUtils.shouldLoadInIsolation(""org.apache.kafka.connect.transforms.""));
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.transforms.ExtractField"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.transforms.ExtractField$Key"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(""org.apache.kafka.connect.json.""));
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.json.JsonConverter"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.json.JsonConverter$21"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(""org.apache.kafka.connect.file.""));
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.file.FileStreamSourceTask"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.file.FileStreamSinkConnector"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.mirror.MirrorSourceTask"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.mirror.MirrorSourceConnector"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(""org.apache.kafka.connect.converters.""));
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.converters.ByteArrayConverter"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.converters.DoubleConverter"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.converters.FloatConverter"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.converters.IntegerConverter"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.converters.LongConverter"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.converters.ShortConverter"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.storage.StringConverter"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.storage.SimpleHeaderConverter"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
            ""org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension""
        ));
    }
",non-flaky,5
70799,apache_kafka,PluginUtilsTest.testClientConfigProvider,"    @Test
    public void testClientConfigProvider() {
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.common.config.provider.ConfigProvider"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.common.config.provider.FileConfigProvider"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.common.config.provider.FutureConfigProvider"")
        );
    }
",non-flaky,5
70800,apache_kafka,PluginUtilsTest.testConnectorClientConfigOverridePolicy,"    @Test
    public void testConnectorClientConfigOverridePolicy() {
        assertFalse(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.connector.policy.ConnectorClientConfigOverridePolicy"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.connector.policy.AbstractConnectorClientConfigOverridePolicy"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy"")
        );
        assertTrue(PluginUtils.shouldLoadInIsolation(
                ""org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy"")
        );
    }
",non-flaky,5
70801,apache_kafka,PluginUtilsTest.testEmptyPluginUrls,"    @Test
    public void testEmptyPluginUrls() throws Exception {
        assertEquals(Collections.<Path>emptyList(), PluginUtils.pluginUrls(pluginPath));
    }
",non-flaky,5
70802,apache_kafka,PluginUtilsTest.testEmptyStructurePluginUrls,"    @Test
    public void testEmptyStructurePluginUrls() throws Exception {
        createBasicDirectoryLayout();
        assertEquals(Collections.<Path>emptyList(), PluginUtils.pluginUrls(pluginPath));
    }
",non-flaky,5
70803,apache_kafka,PluginUtilsTest.testPluginUrlsWithJars,"    @Test
    public void testPluginUrlsWithJars() throws Exception {
        createBasicDirectoryLayout();

        List<Path> expectedUrls = createBasicExpectedUrls();

        assertUrls(expectedUrls, PluginUtils.pluginUrls(pluginPath));
    }
",non-flaky,5
70804,apache_kafka,PluginUtilsTest.testOrderOfPluginUrlsWithJars,"    @Test
    public void testOrderOfPluginUrlsWithJars() throws Exception {
        createBasicDirectoryLayout();
        // Here this method is just used to create the files. The result is not used.
        createBasicExpectedUrls();

        List<Path> actual = PluginUtils.pluginUrls(pluginPath);
        // 'simple-transform.jar' is created first. In many cases, without sorting within the
        // PluginUtils, this jar will be placed before 'another-transform.jar'. However this is
        // not guaranteed because a DirectoryStream does not maintain a certain order in its
        // results. Besides this test case, sorted order in every call to assertUrls below.
        int i = Arrays.toString(actual.toArray()).indexOf(""another-transform.jar"");
        int j = Arrays.toString(actual.toArray()).indexOf(""simple-transform.jar"");
        assertTrue(i < j);
    }
",non-flaky,5
70805,apache_kafka,PluginUtilsTest.testPluginUrlsWithZips,"    @Test
    public void testPluginUrlsWithZips() throws Exception {
        createBasicDirectoryLayout();

        List<Path> expectedUrls = new ArrayList<>();
        expectedUrls.add(Files.createFile(pluginPath.resolve(""connectorA/my-sink.zip"")));
        expectedUrls.add(Files.createFile(pluginPath.resolve(""connectorB/a-source.zip"")));
        expectedUrls.add(Files.createFile(pluginPath.resolve(""transformC/simple-transform.zip"")));
        expectedUrls.add(Files.createFile(
                pluginPath.resolve(""transformC/deps/another-transform.zip""))
        );

        assertUrls(expectedUrls, PluginUtils.pluginUrls(pluginPath));
    }
",non-flaky,5
70806,apache_kafka,PluginUtilsTest.testPluginUrlsWithClasses,"    @Test
    public void testPluginUrlsWithClasses() throws Exception {
        Files.createDirectories(pluginPath.resolve(""org/apache/kafka/converters""));
        Files.createDirectories(pluginPath.resolve(""com/mycompany/transforms""));
        Files.createDirectories(pluginPath.resolve(""edu/research/connectors""));
        Files.createFile(pluginPath.resolve(""org/apache/kafka/converters/README.txt""));
        Files.createFile(pluginPath.resolve(""org/apache/kafka/converters/AlienFormat.class""));
        Files.createDirectories(pluginPath.resolve(""com/mycompany/transforms/Blackhole.class""));
        Files.createDirectories(pluginPath.resolve(""edu/research/connectors/HalSink.class""));

        List<Path> expectedUrls = new ArrayList<>();
        expectedUrls.add(pluginPath);

        assertUrls(expectedUrls, PluginUtils.pluginUrls(pluginPath));
    }
",non-flaky,5
70807,apache_kafka,PluginUtilsTest.testPluginUrlsWithAbsoluteSymlink,"    @Test
    public void testPluginUrlsWithAbsoluteSymlink() throws Exception {
        createBasicDirectoryLayout();

        Path anotherPath = rootDir.newFolder(""moreplugins"").toPath().toRealPath();
        Files.createDirectories(anotherPath.resolve(""connectorB-deps""));
        Files.createSymbolicLink(
                pluginPath.resolve(""connectorB/deps/symlink""),
                anotherPath.resolve(""connectorB-deps"")
        );

        List<Path> expectedUrls = createBasicExpectedUrls();
        expectedUrls.add(Files.createFile(anotherPath.resolve(""connectorB-deps/converter.jar"")));

        assertUrls(expectedUrls, PluginUtils.pluginUrls(pluginPath));
    }
",non-flaky,5
70808,apache_kafka,PluginUtilsTest.testPluginUrlsWithRelativeSymlinkBackwards,"    @Test
    public void testPluginUrlsWithRelativeSymlinkBackwards() throws Exception {
        createBasicDirectoryLayout();

        Path anotherPath = rootDir.newFolder(""moreplugins"").toPath().toRealPath();
        Files.createDirectories(anotherPath.resolve(""connectorB-deps""));
        Files.createSymbolicLink(
                pluginPath.resolve(""connectorB/deps/symlink""),
                Paths.get(""../../../moreplugins/connectorB-deps"")
        );

        List<Path> expectedUrls = createBasicExpectedUrls();
        expectedUrls.add(Files.createFile(anotherPath.resolve(""connectorB-deps/converter.jar"")));

        assertUrls(expectedUrls, PluginUtils.pluginUrls(pluginPath));
    }
",non-flaky,5
70809,apache_kafka,PluginUtilsTest.testPluginUrlsWithRelativeSymlinkForwards,"    @Test
    public void testPluginUrlsWithRelativeSymlinkForwards() throws Exception {
        // Since this test case defines a relative symlink within an already included path, the main
        // assertion of this test is absence of exceptions and correct resolution of paths.
        createBasicDirectoryLayout();
        Files.createDirectories(pluginPath.resolve(""connectorB/deps/more""));
        Files.createSymbolicLink(
                pluginPath.resolve(""connectorB/deps/symlink""),
                Paths.get(""more"")
        );

        List<Path> expectedUrls = createBasicExpectedUrls();
        expectedUrls.add(
                Files.createFile(pluginPath.resolve(""connectorB/deps/more/converter.jar""))
        );

        assertUrls(expectedUrls, PluginUtils.pluginUrls(pluginPath));
    }
",non-flaky,5
70810,apache_kafka,PluginsTest.shouldInstantiateAndConfigureConverters,"    @Test
    public void shouldInstantiateAndConfigureConverters() {
        instantiateAndConfigureConverter(WorkerConfig.KEY_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.CURRENT_CLASSLOADER);
        // Validate extra configs got passed through to overridden converters
        assertEquals(""true"", converter.configs.get(JsonConverterConfig.SCHEMAS_ENABLE_CONFIG));
        assertEquals(""foo1"", converter.configs.get(""extra.config""));

        instantiateAndConfigureConverter(WorkerConfig.VALUE_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.PLUGINS);
        // Validate extra configs got passed through to overridden converters
        assertEquals(""true"", converter.configs.get(JsonConverterConfig.SCHEMAS_ENABLE_CONFIG));
        assertEquals(""foo2"", converter.configs.get(""extra.config""));
    }
",non-flaky,5
70811,apache_kafka,PluginsTest.shouldInstantiateAndConfigureInternalConverters,"    @Test
    public void shouldInstantiateAndConfigureInternalConverters() {
        instantiateAndConfigureInternalConverter(WorkerConfig.INTERNAL_KEY_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.CURRENT_CLASSLOADER);
        // Validate schemas.enable is defaulted to false for internal converter
        assertEquals(false, internalConverter.configs.get(JsonConverterConfig.SCHEMAS_ENABLE_CONFIG));
        // Validate internal converter properties can still be set
        assertEquals(""bar1"", internalConverter.configs.get(""extra.config""));

        instantiateAndConfigureInternalConverter(WorkerConfig.INTERNAL_VALUE_CONVERTER_CLASS_CONFIG, ClassLoaderUsage.PLUGINS);
        // Validate schemas.enable is defaulted to false for internal converter
        assertEquals(false, internalConverter.configs.get(JsonConverterConfig.SCHEMAS_ENABLE_CONFIG));
        // Validate internal converter properties can still be set
        assertEquals(""bar2"", internalConverter.configs.get(""extra.config""));
    }
",non-flaky,5
70812,apache_kafka,PluginsTest.shouldInstantiateAndConfigureExplicitlySetHeaderConverterWithCurrentClassLoader,"    @Test
    public void shouldInstantiateAndConfigureExplicitlySetHeaderConverterWithCurrentClassLoader() {
        assertNotNull(props.get(WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG));
        HeaderConverter headerConverter = plugins.newHeaderConverter(config,
                                                                     WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG,
                                                                     ClassLoaderUsage.CURRENT_CLASSLOADER);
        assertNotNull(headerConverter);
        assertTrue(headerConverter instanceof TestHeaderConverter);
        this.headerConverter = (TestHeaderConverter) headerConverter;

        // Validate extra configs got passed through to overridden converters
        assertConverterType(ConverterType.HEADER, this.headerConverter.configs);
        assertEquals(""baz"", this.headerConverter.configs.get(""extra.config""));

        headerConverter = plugins.newHeaderConverter(config,
                                                     WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG,
                                                     ClassLoaderUsage.PLUGINS);
        assertNotNull(headerConverter);
        assertTrue(headerConverter instanceof TestHeaderConverter);
        this.headerConverter = (TestHeaderConverter) headerConverter;

        // Validate extra configs got passed through to overridden converters
        assertConverterType(ConverterType.HEADER, this.headerConverter.configs);
        assertEquals(""baz"", this.headerConverter.configs.get(""extra.config""));
    }
",non-flaky,5
70813,apache_kafka,PluginsTest.shouldInstantiateAndConfigureConnectRestExtension,"    @Test
    public void shouldInstantiateAndConfigureConnectRestExtension() {
        props.put(WorkerConfig.REST_EXTENSION_CLASSES_CONFIG,
                  TestConnectRestExtension.class.getName());
        createConfig();

        List<ConnectRestExtension> connectRestExtensions =
            plugins.newPlugins(config.getList(WorkerConfig.REST_EXTENSION_CLASSES_CONFIG),
                               config,
                               ConnectRestExtension.class);
        assertNotNull(connectRestExtensions);
        assertEquals(""One Rest Extension expected"", 1, connectRestExtensions.size());
        assertNotNull(connectRestExtensions.get(0));
        assertTrue(""Should be instance of TestConnectRestExtension"",
                   connectRestExtensions.get(0) instanceof TestConnectRestExtension);
        assertNotNull(((TestConnectRestExtension) connectRestExtensions.get(0)).configs);
        assertEquals(config.originals(),
                     ((TestConnectRestExtension) connectRestExtensions.get(0)).configs);
    }
",non-flaky,5
70814,apache_kafka,PluginsTest.shouldInstantiateAndConfigureDefaultHeaderConverter,"    @Test
    public void shouldInstantiateAndConfigureDefaultHeaderConverter() {
        props.remove(WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG);
        createConfig();

        // Because it's not explicitly set on the supplied configuration, the logic to use the current classloader for the connector
        // will exit immediately, and so this method always returns null
        HeaderConverter headerConverter = plugins.newHeaderConverter(config,
                                                                     WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG,
                                                                     ClassLoaderUsage.CURRENT_CLASSLOADER);
        assertNull(headerConverter);
        // But we should always find it (or the worker's default) when using the plugins classloader ...
        headerConverter = plugins.newHeaderConverter(config,
                                                     WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG,
                                                     ClassLoaderUsage.PLUGINS);
        assertNotNull(headerConverter);
        assertTrue(headerConverter instanceof SimpleHeaderConverter);
    }
",non-flaky,5
70815,apache_kafka,PluginsTest.shouldThrowIfPluginThrows,"    @Test(expected = ConnectException.class)
    public void shouldThrowIfPluginThrows() {
        TestPlugins.assertAvailable();

        plugins.newPlugin(
            TestPlugins.ALWAYS_THROW_EXCEPTION,
            new AbstractConfig(new ConfigDef(), Collections.emptyMap()),
            Converter.class
        );
    }
",non-flaky,5
70816,apache_kafka,PluginsTest.shouldShareStaticValuesBetweenSamePlugin,"    @Test
    public void shouldShareStaticValuesBetweenSamePlugin() {
        // Plugins are not isolated from other instances of their own class.
        TestPlugins.assertAvailable();
        Converter firstPlugin = plugins.newPlugin(
            TestPlugins.ALIASED_STATIC_FIELD,
            new AbstractConfig(new ConfigDef(), Collections.emptyMap()),
            Converter.class
        );

        assertInstanceOf(SamplingTestPlugin.class, firstPlugin, ""Cannot collect samples"");

        Converter secondPlugin = plugins.newPlugin(
            TestPlugins.ALIASED_STATIC_FIELD,
            new AbstractConfig(new ConfigDef(), Collections.emptyMap()),
            Converter.class
        );

        assertInstanceOf(SamplingTestPlugin.class, secondPlugin, ""Cannot collect samples"");
        assertSame(
            ((SamplingTestPlugin) firstPlugin).otherSamples(),
            ((SamplingTestPlugin) secondPlugin).otherSamples()
        );
    }
",non-flaky,5
70817,apache_kafka,PluginsTest.newPluginShouldServiceLoadWithPluginClassLoader,"    @Test
    public void newPluginShouldServiceLoadWithPluginClassLoader() {
        TestPlugins.assertAvailable();
        Converter plugin = plugins.newPlugin(
            TestPlugins.SERVICE_LOADER,
            new AbstractConfig(new ConfigDef(), Collections.emptyMap()),
            Converter.class
        );

        assertInstanceOf(SamplingTestPlugin.class, plugin, ""Cannot collect samples"");
        Map<String, SamplingTestPlugin> samples = ((SamplingTestPlugin) plugin).flatten();
        // Assert that the service loaded subclass is found in both environments
        assertTrue(samples.containsKey(""ServiceLoadedSubclass.static""));
        assertTrue(samples.containsKey(""ServiceLoadedSubclass.dynamic""));
        assertPluginClassLoaderAlwaysActive(samples);
    }
",non-flaky,5
70818,apache_kafka,PluginsTest.newPluginShouldInstantiateWithPluginClassLoader,"    @Test
    public void newPluginShouldInstantiateWithPluginClassLoader() {
        TestPlugins.assertAvailable();
        Converter plugin = plugins.newPlugin(
            TestPlugins.ALIASED_STATIC_FIELD,
            new AbstractConfig(new ConfigDef(), Collections.emptyMap()),
            Converter.class
        );

        assertInstanceOf(SamplingTestPlugin.class, plugin, ""Cannot collect samples"");
        Map<String, SamplingTestPlugin> samples = ((SamplingTestPlugin) plugin).flatten();
        assertPluginClassLoaderAlwaysActive(samples);
    }
",non-flaky,5
70819,apache_kafka,PluginsTest.shouldFailToFindConverterInCurrentClassloader,"    @Test(expected = ConfigException.class)
    public void shouldFailToFindConverterInCurrentClassloader() {
        TestPlugins.assertAvailable();
        props.put(WorkerConfig.KEY_CONVERTER_CLASS_CONFIG, TestPlugins.SAMPLING_CONVERTER);
        createConfig();
    }
",non-flaky,5
70820,apache_kafka,PluginsTest.newConverterShouldConfigureWithPluginClassLoader,"    @Test
    public void newConverterShouldConfigureWithPluginClassLoader() {
        TestPlugins.assertAvailable();
        props.put(WorkerConfig.KEY_CONVERTER_CLASS_CONFIG, TestPlugins.SAMPLING_CONVERTER);
        ClassLoader classLoader = plugins.delegatingLoader().pluginClassLoader(TestPlugins.SAMPLING_CONVERTER);
        ClassLoader savedLoader = Plugins.compareAndSwapLoaders(classLoader);
        createConfig();
        Plugins.compareAndSwapLoaders(savedLoader);

        Converter plugin = plugins.newConverter(
            config,
            WorkerConfig.KEY_CONVERTER_CLASS_CONFIG,
            ClassLoaderUsage.PLUGINS
        );

        assertInstanceOf(SamplingTestPlugin.class, plugin, ""Cannot collect samples"");
        Map<String, SamplingTestPlugin> samples = ((SamplingTestPlugin) plugin).flatten();
        assertTrue(samples.containsKey(""configure""));
        assertPluginClassLoaderAlwaysActive(samples);
    }
",non-flaky,5
70821,apache_kafka,PluginsTest.newConfigProviderShouldConfigureWithPluginClassLoader,"    @Test
    public void newConfigProviderShouldConfigureWithPluginClassLoader() {
        TestPlugins.assertAvailable();
        String providerPrefix = ""some.provider"";
        props.put(providerPrefix + "".class"", TestPlugins.SAMPLING_CONFIG_PROVIDER);

        PluginClassLoader classLoader = plugins.delegatingLoader().pluginClassLoader(TestPlugins.SAMPLING_CONFIG_PROVIDER);
        assertNotNull(classLoader);
        ClassLoader savedLoader = Plugins.compareAndSwapLoaders(classLoader);
        createConfig();
        Plugins.compareAndSwapLoaders(savedLoader);

        ConfigProvider plugin = plugins.newConfigProvider(
            config,
            providerPrefix,
            ClassLoaderUsage.PLUGINS
        );

        assertInstanceOf(SamplingTestPlugin.class, plugin, ""Cannot collect samples"");
        Map<String, SamplingTestPlugin> samples = ((SamplingTestPlugin) plugin).flatten();
        assertTrue(samples.containsKey(""configure""));
        assertPluginClassLoaderAlwaysActive(samples);
    }
",non-flaky,5
70822,apache_kafka,PluginsTest.newHeaderConverterShouldConfigureWithPluginClassLoader,"    @Test
    public void newHeaderConverterShouldConfigureWithPluginClassLoader() {
        TestPlugins.assertAvailable();
        props.put(WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG, TestPlugins.SAMPLING_HEADER_CONVERTER);
        ClassLoader classLoader = plugins.delegatingLoader().pluginClassLoader(TestPlugins.SAMPLING_HEADER_CONVERTER);
        ClassLoader savedLoader = Plugins.compareAndSwapLoaders(classLoader);
        createConfig();
        Plugins.compareAndSwapLoaders(savedLoader);

        HeaderConverter plugin = plugins.newHeaderConverter(
            config,
            WorkerConfig.HEADER_CONVERTER_CLASS_CONFIG,
            ClassLoaderUsage.PLUGINS
        );

        assertInstanceOf(SamplingTestPlugin.class, plugin, ""Cannot collect samples"");
        Map<String, SamplingTestPlugin> samples = ((SamplingTestPlugin) plugin).flatten();
        assertTrue(samples.containsKey(""configure"")); // HeaderConverter::configure was called
        assertPluginClassLoaderAlwaysActive(samples);
    }
",non-flaky,5
70823,apache_kafka,PluginsTest.newPluginsShouldConfigureWithPluginClassLoader,"    @Test
    public void newPluginsShouldConfigureWithPluginClassLoader() {
        TestPlugins.assertAvailable();
        List<Configurable> configurables = plugins.newPlugins(
            Collections.singletonList(TestPlugins.SAMPLING_CONFIGURABLE),
            config,
            Configurable.class
        );
        assertEquals(1, configurables.size());
        Configurable plugin = configurables.get(0);

        assertInstanceOf(SamplingTestPlugin.class, plugin, ""Cannot collect samples"");
        Map<String, SamplingTestPlugin> samples = ((SamplingTestPlugin) plugin).flatten();
        assertTrue(samples.containsKey(""configure"")); // Configurable::configure was called
        assertPluginClassLoaderAlwaysActive(samples);
    }
",non-flaky,5
70824,apache_kafka,PluginDescTest.testRegularPluginDesc,"    @Test
    public void testRegularPluginDesc() {
        PluginDesc<Connector> connectorDesc = new PluginDesc<>(
                Connector.class,
                regularVersion,
                pluginLoader
        );

        assertPluginDesc(connectorDesc, Connector.class, regularVersion, pluginLoader.location());

        PluginDesc<Converter> converterDesc = new PluginDesc<>(
                Converter.class,
                snaphotVersion,
                pluginLoader
        );

        assertPluginDesc(converterDesc, Converter.class, snaphotVersion, pluginLoader.location());

        PluginDesc<Transformation> transformDesc = new PluginDesc<>(
                Transformation.class,
                noVersion,
                pluginLoader
        );

        assertPluginDesc(transformDesc, Transformation.class, noVersion, pluginLoader.location());
    }
",non-flaky,5
70825,apache_kafka,PluginDescTest.testPluginDescWithSystemClassLoader,"    @Test
    public void testPluginDescWithSystemClassLoader() {
        String location = ""classpath"";
        PluginDesc<SinkConnector> connectorDesc = new PluginDesc<>(
                SinkConnector.class,
                regularVersion,
                systemLoader
        );

        assertPluginDesc(connectorDesc, SinkConnector.class, regularVersion, location);

        PluginDesc<Converter> converterDesc = new PluginDesc<>(
                Converter.class,
                snaphotVersion,
                systemLoader
        );

        assertPluginDesc(converterDesc, Converter.class, snaphotVersion, location);

        PluginDesc<Transformation> transformDesc = new PluginDesc<>(
                Transformation.class,
                noVersion,
                systemLoader
        );

        assertPluginDesc(transformDesc, Transformation.class, noVersion, location);
    }
",non-flaky,5
70826,apache_kafka,PluginDescTest.testPluginDescWithNullVersion,"    @Test
    public void testPluginDescWithNullVersion() {
        String nullVersion = ""null"";
        PluginDesc<SourceConnector> connectorDesc = new PluginDesc<>(
                SourceConnector.class,
                null,
                pluginLoader
        );

        assertPluginDesc(
                connectorDesc,
                SourceConnector.class,
                nullVersion,
                pluginLoader.location()
        );

        String location = ""classpath"";
        PluginDesc<Converter> converterDesc = new PluginDesc<>(
                Converter.class,
                null,
                systemLoader
        );

        assertPluginDesc(converterDesc, Converter.class, nullVersion, location);
    }
",non-flaky,5
70827,apache_kafka,PluginDescTest.testPluginDescEquality,"    @Test
    public void testPluginDescEquality() {
        PluginDesc<Connector> connectorDescPluginPath = new PluginDesc<>(
                Connector.class,
                snaphotVersion,
                pluginLoader
        );

        PluginDesc<Connector> connectorDescClasspath = new PluginDesc<>(
                Connector.class,
                snaphotVersion,
                systemLoader
        );

        assertEquals(connectorDescPluginPath, connectorDescClasspath);
        assertEquals(connectorDescPluginPath.hashCode(), connectorDescClasspath.hashCode());

        PluginDesc<Converter> converterDescPluginPath = new PluginDesc<>(
                Converter.class,
                noVersion,
                pluginLoader
        );

        PluginDesc<Converter> converterDescClasspath = new PluginDesc<>(
                Converter.class,
                noVersion,
                systemLoader
        );

        assertEquals(converterDescPluginPath, converterDescClasspath);
        assertEquals(converterDescPluginPath.hashCode(), converterDescClasspath.hashCode());

        PluginDesc<Transformation> transformDescPluginPath = new PluginDesc<>(
                Transformation.class,
                null,
                pluginLoader
        );

        PluginDesc<Transformation> transformDescClasspath = new PluginDesc<>(
                Transformation.class,
                noVersion,
                pluginLoader
        );

        assertNotEquals(transformDescPluginPath, transformDescClasspath);
    }
",non-flaky,5
70828,apache_kafka,PluginDescTest.testPluginDescComparison,"    @Test
    public void testPluginDescComparison() {
        PluginDesc<Connector> connectorDescPluginPath = new PluginDesc<>(
                Connector.class,
                regularVersion,
                pluginLoader
        );

        PluginDesc<Connector> connectorDescClasspath = new PluginDesc<>(
                Connector.class,
                newerVersion,
                systemLoader
        );

        assertNewer(connectorDescPluginPath, connectorDescClasspath);

        PluginDesc<Converter> converterDescPluginPath = new PluginDesc<>(
                Converter.class,
                noVersion,
                pluginLoader
        );

        PluginDesc<Converter> converterDescClasspath = new PluginDesc<>(
                Converter.class,
                snaphotVersion,
                systemLoader
        );

        assertNewer(converterDescPluginPath, converterDescClasspath);

        PluginDesc<Transformation> transformDescPluginPath = new PluginDesc<>(
                Transformation.class,
                null,
                pluginLoader
        );

        PluginDesc<Transformation> transformDescClasspath = new PluginDesc<>(
                Transformation.class,
                regularVersion,
                systemLoader
        );

        assertNewer(transformDescPluginPath, transformDescClasspath);
    }
",non-flaky,5
70829,apache_kafka,WorkerConfigTest.testAdminListenersConfigAllowedValues,"    @Test
    public void testAdminListenersConfigAllowedValues() {
        Map<String, String> props = baseProps();

        // no value set for ""admin.listeners""
        WorkerConfig config = new WorkerConfig(WorkerConfig.baseConfigDef(), props);
        assertNull(""Default value should be null."", config.getList(WorkerConfig.ADMIN_LISTENERS_CONFIG));

        props.put(WorkerConfig.ADMIN_LISTENERS_CONFIG, """");
        config = new WorkerConfig(WorkerConfig.baseConfigDef(), props);
        assertTrue(config.getList(WorkerConfig.ADMIN_LISTENERS_CONFIG).isEmpty());

        props.put(WorkerConfig.ADMIN_LISTENERS_CONFIG, ""http://a.b:9999, https://a.b:7812"");
        config = new WorkerConfig(WorkerConfig.baseConfigDef(), props);
        assertEquals(config.getList(WorkerConfig.ADMIN_LISTENERS_CONFIG), Arrays.asList(""http://a.b:9999"", ""https://a.b:7812""));

        new WorkerConfig(WorkerConfig.baseConfigDef(), props);
    }
",non-flaky,5
70830,apache_kafka,WorkerConfigTest.testAdminListenersNotAllowingEmptyStrings,"    @Test(expected = ConfigException.class)
    public void testAdminListenersNotAllowingEmptyStrings() {
        Map<String, String> props = baseProps();
        props.put(WorkerConfig.ADMIN_LISTENERS_CONFIG, ""http://a.b:9999,"");
        new WorkerConfig(WorkerConfig.baseConfigDef(), props);
    }
",non-flaky,5
70831,apache_kafka,WorkerConfigTest.testAdminListenersNotAllowingBlankStrings,"    @Test(expected = ConfigException.class)
    public void testAdminListenersNotAllowingBlankStrings() {
        Map<String, String> props = baseProps();
        props.put(WorkerConfig.ADMIN_LISTENERS_CONFIG, ""http://a.b:9999, ,https://a.b:9999"");
        new WorkerConfig(WorkerConfig.baseConfigDef(), props);
    }
",non-flaky,5
70832,apache_kafka,WorkerSourceTaskTest.answer,"    @Test
    public void testStartPaused() throws Exception {
        final CountDownLatch pauseLatch = new CountDownLatch(1);

        createWorkerTask(TargetState.PAUSED);

        statusListener.onPause(taskId);
        EasyMock.expectLastCall().andAnswer(new IAnswer<Void>() {
            @Override
            public Void answer() throws Throwable {
                pauseLatch.countDown();
                return null;
            }
",non-flaky,5
70833,apache_kafka,WorkerSourceTaskTest.testPause,"    @Test
    public void testPause() throws Exception {
        createWorkerTask();

        sourceTask.initialize(EasyMock.anyObject(SourceTaskContext.class));
        EasyMock.expectLastCall();
        sourceTask.start(TASK_PROPS);
        EasyMock.expectLastCall();
        statusListener.onStartup(taskId);
        EasyMock.expectLastCall();

        AtomicInteger count = new AtomicInteger(0);
        CountDownLatch pollLatch = expectPolls(10, count);
        // In this test, we don't flush, so nothing goes any further than the offset writer

        statusListener.onPause(taskId);
        EasyMock.expectLastCall();

        sourceTask.stop();
        EasyMock.expectLastCall();
        expectOffsetFlush(true);

        statusListener.onShutdown(taskId);
        EasyMock.expectLastCall();

        producer.close(EasyMock.anyObject(Duration.class));
        EasyMock.expectLastCall();

        transformationChain.close();
        EasyMock.expectLastCall();

        PowerMock.replayAll();

        workerTask.initialize(TASK_CONFIG);
        Future<?> taskFuture = executor.submit(workerTask);
        assertTrue(awaitLatch(pollLatch));

        workerTask.transitionTo(TargetState.PAUSED);

        int priorCount = count.get();
        Thread.sleep(100);

        // since the transition is observed asynchronously, the count could be off by one loop iteration
        assertTrue(count.get() - priorCount <= 1);

        workerTask.stop();
        assertTrue(workerTask.awaitStop(1000));

        taskFuture.get();

        PowerMock.verifyAll();
    }
",non-flaky,5
70834,apache_kafka,WorkerSourceTaskTest.testPollsInBackground,"    @Test
    public void testPollsInBackground() throws Exception {
        createWorkerTask();

        sourceTask.initialize(EasyMock.anyObject(SourceTaskContext.class));
        EasyMock.expectLastCall();
        sourceTask.start(TASK_PROPS);
        EasyMock.expectLastCall();
        statusListener.onStartup(taskId);
        EasyMock.expectLastCall();

        final CountDownLatch pollLatch = expectPolls(10);
        // In this test, we don't flush, so nothing goes any further than the offset writer

        sourceTask.stop();
        EasyMock.expectLastCall();
        expectOffsetFlush(true);

        statusListener.onShutdown(taskId);
        EasyMock.expectLastCall();

        producer.close(EasyMock.anyObject(Duration.class));
        EasyMock.expectLastCall();

        transformationChain.close();
        EasyMock.expectLastCall();

        PowerMock.replayAll();

        workerTask.initialize(TASK_CONFIG);
        Future<?> taskFuture = executor.submit(workerTask);

        assertTrue(awaitLatch(pollLatch));
        workerTask.stop();
        assertTrue(workerTask.awaitStop(1000));

        taskFuture.get();
        assertPollMetrics(10);

        PowerMock.verifyAll();
    }
",non-flaky,5
70835,apache_kafka,WorkerSourceTaskTest.answer,"    @Test
    public void testFailureInPoll() throws Exception {
        createWorkerTask();

        sourceTask.initialize(EasyMock.anyObject(SourceTaskContext.class));
        EasyMock.expectLastCall();
        sourceTask.start(TASK_PROPS);
        EasyMock.expectLastCall();
        statusListener.onStartup(taskId);
        EasyMock.expectLastCall();

        final CountDownLatch pollLatch = new CountDownLatch(1);
        final RuntimeException exception = new RuntimeException();
        EasyMock.expect(sourceTask.poll()).andAnswer(new IAnswer<List<SourceRecord>>() {
            @Override
            public List<SourceRecord> answer() throws Throwable {
                pollLatch.countDown();
                throw exception;
            }
",non-flaky,5
70836,apache_kafka,WorkerSourceTaskTest.testPollReturnsNoRecords,"    @Test
    public void testPollReturnsNoRecords() throws Exception {
        // Test that the task handles an empty list of records
        createWorkerTask();

        sourceTask.initialize(EasyMock.anyObject(SourceTaskContext.class));
        EasyMock.expectLastCall();
        sourceTask.start(TASK_PROPS);
        EasyMock.expectLastCall();
        statusListener.onStartup(taskId);
        EasyMock.expectLastCall();

        // We'll wait for some data, then trigger a flush
        final CountDownLatch pollLatch = expectEmptyPolls(1, new AtomicInteger());
        expectOffsetFlush(true);

        sourceTask.stop();
        EasyMock.expectLastCall();
        expectOffsetFlush(true);

        statusListener.onShutdown(taskId);
        EasyMock.expectLastCall();

        producer.close(EasyMock.anyObject(Duration.class));
        EasyMock.expectLastCall();

        transformationChain.close();
        EasyMock.expectLastCall();

        PowerMock.replayAll();

        workerTask.initialize(TASK_CONFIG);
        Future<?> taskFuture = executor.submit(workerTask);

        assertTrue(awaitLatch(pollLatch));
        assertTrue(workerTask.commitOffsets());
        workerTask.stop();
        assertTrue(workerTask.awaitStop(1000));

        taskFuture.get();
        assertPollMetrics(0);

        PowerMock.verifyAll();
    }
",non-flaky,5
70837,apache_kafka,WorkerSourceTaskTest.testCommit,"    @Test
    public void testCommit() throws Exception {
        // Test that the task commits properly when prompted
        createWorkerTask();

        sourceTask.initialize(EasyMock.anyObject(SourceTaskContext.class));
        EasyMock.expectLastCall();
        sourceTask.start(TASK_PROPS);
        EasyMock.expectLastCall();
        statusListener.onStartup(taskId);
        EasyMock.expectLastCall();

        // We'll wait for some data, then trigger a flush
        final CountDownLatch pollLatch = expectPolls(1);
        expectOffsetFlush(true);

        sourceTask.stop();
        EasyMock.expectLastCall();
        expectOffsetFlush(true);

        statusListener.onShutdown(taskId);
        EasyMock.expectLastCall();

        producer.close(EasyMock.anyObject(Duration.class));
        EasyMock.expectLastCall();

        transformationChain.close();
        EasyMock.expectLastCall();

        PowerMock.replayAll();

        workerTask.initialize(TASK_CONFIG);
        Future<?> taskFuture = executor.submit(workerTask);

        assertTrue(awaitLatch(pollLatch));
        assertTrue(workerTask.commitOffsets());
        workerTask.stop();
        assertTrue(workerTask.awaitStop(1000));

        taskFuture.get();
        assertPollMetrics(1);

        PowerMock.verifyAll();
    }
",non-flaky,5
70838,apache_kafka,WorkerSourceTaskTest.testCommitFailure,"    @Test
    public void testCommitFailure() throws Exception {
        // Test that the task commits properly when prompted
        createWorkerTask();

        sourceTask.initialize(EasyMock.anyObject(SourceTaskContext.class));
        EasyMock.expectLastCall();
        sourceTask.start(TASK_PROPS);
        EasyMock.expectLastCall();
        statusListener.onStartup(taskId);
        EasyMock.expectLastCall();

        // We'll wait for some data, then trigger a flush
        final CountDownLatch pollLatch = expectPolls(1);
        expectOffsetFlush(true);

        sourceTask.stop();
        EasyMock.expectLastCall();
        expectOffsetFlush(false);

        statusListener.onShutdown(taskId);
        EasyMock.expectLastCall();

        producer.close(EasyMock.anyObject(Duration.class));
        EasyMock.expectLastCall();

        transformationChain.close();
        EasyMock.expectLastCall();

        PowerMock.replayAll();

        workerTask.initialize(TASK_CONFIG);
        Future<?> taskFuture = executor.submit(workerTask);

        assertTrue(awaitLatch(pollLatch));
        assertTrue(workerTask.commitOffsets());
        workerTask.stop();
        assertTrue(workerTask.awaitStop(1000));

        taskFuture.get();
        assertPollMetrics(1);

        PowerMock.verifyAll();
    }
",non-flaky,5
70839,apache_kafka,WorkerSourceTaskTest.testSendRecordsConvertsData,"    @Test
    public void testSendRecordsConvertsData() throws Exception {
        createWorkerTask();

        List<SourceRecord> records = new ArrayList<>();
        // Can just use the same record for key and value
        records.add(new SourceRecord(PARTITION, OFFSET, ""topic"", null, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD));

        Capture<ProducerRecord<byte[], byte[]>> sent = expectSendRecordAnyTimes();

        PowerMock.replayAll();

        Whitebox.setInternalState(workerTask, ""toSend"", records);
        Whitebox.invokeMethod(workerTask, ""sendRecords"");
        assertEquals(SERIALIZED_KEY, sent.getValue().key());
        assertEquals(SERIALIZED_RECORD, sent.getValue().value());

        PowerMock.verifyAll();
    }
",non-flaky,5
70840,apache_kafka,WorkerSourceTaskTest.testSendRecordsPropagatesTimestamp,"    @Test
    public void testSendRecordsPropagatesTimestamp() throws Exception {
        final Long timestamp = System.currentTimeMillis();

        createWorkerTask();

        List<SourceRecord> records = Collections.singletonList(
                new SourceRecord(PARTITION, OFFSET, ""topic"", null, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD, timestamp)
        );

        Capture<ProducerRecord<byte[], byte[]>> sent = expectSendRecordAnyTimes();

        PowerMock.replayAll();

        Whitebox.setInternalState(workerTask, ""toSend"", records);
        Whitebox.invokeMethod(workerTask, ""sendRecords"");
        assertEquals(timestamp, sent.getValue().timestamp());

        PowerMock.verifyAll();
    }
",non-flaky,5
70841,apache_kafka,WorkerSourceTaskTest.testSendRecordsCorruptTimestamp,"    @Test(expected = InvalidRecordException.class)
    public void testSendRecordsCorruptTimestamp() throws Exception {
        final Long timestamp = -3L;
        createWorkerTask();

        List<SourceRecord> records = Collections.singletonList(
                new SourceRecord(PARTITION, OFFSET, ""topic"", null, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD, timestamp)
        );

        Capture<ProducerRecord<byte[], byte[]>> sent = expectSendRecordAnyTimes();

        PowerMock.replayAll();

        Whitebox.setInternalState(workerTask, ""toSend"", records);
        Whitebox.invokeMethod(workerTask, ""sendRecords"");
        assertEquals(null, sent.getValue().timestamp());

        PowerMock.verifyAll();
    }
",non-flaky,5
70842,apache_kafka,WorkerSourceTaskTest.testSendRecordsNoTimestamp,"    @Test
    public void testSendRecordsNoTimestamp() throws Exception {
        final Long timestamp = -1L;
        createWorkerTask();

        List<SourceRecord> records = Collections.singletonList(
                new SourceRecord(PARTITION, OFFSET, ""topic"", null, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD, timestamp)
        );

        Capture<ProducerRecord<byte[], byte[]>> sent = expectSendRecordAnyTimes();

        PowerMock.replayAll();

        Whitebox.setInternalState(workerTask, ""toSend"", records);
        Whitebox.invokeMethod(workerTask, ""sendRecords"");
        assertEquals(null, sent.getValue().timestamp());

        PowerMock.verifyAll();
    }
",non-flaky,5
70843,apache_kafka,WorkerSourceTaskTest.testSendRecordsRetries,"    @Test
    public void testSendRecordsRetries() throws Exception {
        createWorkerTask();

        // Differentiate only by Kafka partition so we can reuse conversion expectations
        SourceRecord record1 = new SourceRecord(PARTITION, OFFSET, ""topic"", 1, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD);
        SourceRecord record2 = new SourceRecord(PARTITION, OFFSET, ""topic"", 2, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD);
        SourceRecord record3 = new SourceRecord(PARTITION, OFFSET, ""topic"", 3, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD);

        // First round
        expectSendRecordOnce(false);
        // Any Producer retriable exception should work here
        expectSendRecordSyncFailure(new org.apache.kafka.common.errors.TimeoutException(""retriable sync failure""));

        // Second round
        expectSendRecordOnce(true);
        expectSendRecordOnce(false);

        PowerMock.replayAll();

        // Try to send 3, make first pass, second fail. Should save last two
        Whitebox.setInternalState(workerTask, ""toSend"", Arrays.asList(record1, record2, record3));
        Whitebox.invokeMethod(workerTask, ""sendRecords"");
        assertEquals(true, Whitebox.getInternalState(workerTask, ""lastSendFailed""));
        assertEquals(Arrays.asList(record2, record3), Whitebox.getInternalState(workerTask, ""toSend""));

        // Next they all succeed
        Whitebox.invokeMethod(workerTask, ""sendRecords"");
        assertEquals(false, Whitebox.getInternalState(workerTask, ""lastSendFailed""));
        assertNull(Whitebox.getInternalState(workerTask, ""toSend""));

        PowerMock.verifyAll();
    }
",non-flaky,5
70844,apache_kafka,WorkerSourceTaskTest.testSendRecordsProducerCallbackFail,"    @Test(expected = ConnectException.class)
    public void testSendRecordsProducerCallbackFail() throws Exception {
        createWorkerTask();

        SourceRecord record1 = new SourceRecord(PARTITION, OFFSET, ""topic"", 1, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD);
        SourceRecord record2 = new SourceRecord(PARTITION, OFFSET, ""topic"", 2, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD);

        expectSendRecordProducerCallbackFail();

        PowerMock.replayAll();

        Whitebox.setInternalState(workerTask, ""toSend"", Arrays.asList(record1, record2));
        Whitebox.invokeMethod(workerTask, ""sendRecords"");
    }
",non-flaky,5
70845,apache_kafka,WorkerSourceTaskTest.testSendRecordsTaskCommitRecordFail,"    @Test
    public void testSendRecordsTaskCommitRecordFail() throws Exception {
        createWorkerTask();

        // Differentiate only by Kafka partition so we can reuse conversion expectations
        SourceRecord record1 = new SourceRecord(PARTITION, OFFSET, ""topic"", 1, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD);
        SourceRecord record2 = new SourceRecord(PARTITION, OFFSET, ""topic"", 2, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD);
        SourceRecord record3 = new SourceRecord(PARTITION, OFFSET, ""topic"", 3, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD);

        // Source task commit record failure will not cause the task to abort
        expectSendRecordOnce(false);
        expectSendRecordTaskCommitRecordFail(false, false);
        expectSendRecordOnce(false);

        PowerMock.replayAll();

        Whitebox.setInternalState(workerTask, ""toSend"", Arrays.asList(record1, record2, record3));
        Whitebox.invokeMethod(workerTask, ""sendRecords"");
        assertEquals(false, Whitebox.getInternalState(workerTask, ""lastSendFailed""));
        assertNull(Whitebox.getInternalState(workerTask, ""toSend""));

        PowerMock.verifyAll();
    }
",non-flaky,5
70846,apache_kafka,WorkerSourceTaskTest.answer,"    @Test
    public void testSlowTaskStart() throws Exception {
        final CountDownLatch startupLatch = new CountDownLatch(1);
        final CountDownLatch finishStartupLatch = new CountDownLatch(1);

        createWorkerTask();

        sourceTask.initialize(EasyMock.anyObject(SourceTaskContext.class));
        EasyMock.expectLastCall();
        sourceTask.start(TASK_PROPS);
        EasyMock.expectLastCall().andAnswer(new IAnswer<Object>() {
            @Override
            public Object answer() throws Throwable {
                startupLatch.countDown();
                assertTrue(awaitLatch(finishStartupLatch));
                return null;
            }
",non-flaky,5
70847,apache_kafka,WorkerSourceTaskTest.testCancel,"    @Test
    public void testCancel() {
        createWorkerTask();

        offsetReader.close();
        PowerMock.expectLastCall();

        PowerMock.replayAll();

        workerTask.cancel();

        PowerMock.verifyAll();
    }
",non-flaky,5
70848,apache_kafka,WorkerSourceTaskTest.testMetricsGroup,"    @Test
    public void testMetricsGroup() {
        SourceTaskMetricsGroup group = new SourceTaskMetricsGroup(taskId, metrics);
        SourceTaskMetricsGroup group1 = new SourceTaskMetricsGroup(taskId1, metrics);
        for (int i = 0; i != 10; ++i) {
            group.recordPoll(100, 1000 + i * 100);
            group.recordWrite(10);
        }
        for (int i = 0; i != 20; ++i) {
            group1.recordPoll(100, 1000 + i * 100);
            group1.recordWrite(10);
        }
        assertEquals(1900.0, metrics.currentMetricValueAsDouble(group.metricGroup(), ""poll-batch-max-time-ms""), 0.001d);
        assertEquals(1450.0, metrics.currentMetricValueAsDouble(group.metricGroup(), ""poll-batch-avg-time-ms""), 0.001d);
        assertEquals(33.333, metrics.currentMetricValueAsDouble(group.metricGroup(), ""source-record-poll-rate""), 0.001d);
        assertEquals(1000, metrics.currentMetricValueAsDouble(group.metricGroup(), ""source-record-poll-total""), 0.001d);
        assertEquals(3.3333, metrics.currentMetricValueAsDouble(group.metricGroup(), ""source-record-write-rate""), 0.001d);
        assertEquals(100, metrics.currentMetricValueAsDouble(group.metricGroup(), ""source-record-write-total""), 0.001d);
        assertEquals(900.0, metrics.currentMetricValueAsDouble(group.metricGroup(), ""source-record-active-count""), 0.001d);

        // Close the group
        group.close();

        for (MetricName metricName : group.metricGroup().metrics().metrics().keySet()) {
            // Metrics for this group should no longer exist
            assertFalse(group.metricGroup().groupId().includes(metricName));
        }
        // Sensors for this group should no longer exist
        assertNull(group.metricGroup().metrics().getSensor(""sink-record-read""));
        assertNull(group.metricGroup().metrics().getSensor(""sink-record-send""));
        assertNull(group.metricGroup().metrics().getSensor(""sink-record-active-count""));
        assertNull(group.metricGroup().metrics().getSensor(""partition-count""));
        assertNull(group.metricGroup().metrics().getSensor(""offset-seq-number""));
        assertNull(group.metricGroup().metrics().getSensor(""offset-commit-completion""));
        assertNull(group.metricGroup().metrics().getSensor(""offset-commit-completion-skip""));
        assertNull(group.metricGroup().metrics().getSensor(""put-batch-time""));

        assertEquals(2900.0, metrics.currentMetricValueAsDouble(group1.metricGroup(), ""poll-batch-max-time-ms""), 0.001d);
        assertEquals(1950.0, metrics.currentMetricValueAsDouble(group1.metricGroup(), ""poll-batch-avg-time-ms""), 0.001d);
        assertEquals(66.667, metrics.currentMetricValueAsDouble(group1.metricGroup(), ""source-record-poll-rate""), 0.001d);
        assertEquals(2000, metrics.currentMetricValueAsDouble(group1.metricGroup(), ""source-record-poll-total""), 0.001d);
        assertEquals(6.667, metrics.currentMetricValueAsDouble(group1.metricGroup(), ""source-record-write-rate""), 0.001d);
        assertEquals(200, metrics.currentMetricValueAsDouble(group1.metricGroup(), ""source-record-write-total""), 0.001d);
        assertEquals(1800.0, metrics.currentMetricValueAsDouble(group1.metricGroup(), ""source-record-active-count""), 0.001d);
    }
",non-flaky,5
70849,apache_kafka,WorkerSourceTaskTest.testHeaders,"    @Test
    public void testHeaders() throws Exception {
        Headers headers = new RecordHeaders();
        headers.add(""header_key"", ""header_value"".getBytes());

        org.apache.kafka.connect.header.Headers connectHeaders = new ConnectHeaders();
        connectHeaders.add(""header_key"", new SchemaAndValue(Schema.STRING_SCHEMA, ""header_value""));

        createWorkerTask();

        List<SourceRecord> records = new ArrayList<>();
        records.add(new SourceRecord(PARTITION, OFFSET, ""topic"", null, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD, null, connectHeaders));

        Capture<ProducerRecord<byte[], byte[]>> sent = expectSendRecord(true, false, true, true, true, headers);

        PowerMock.replayAll();

        Whitebox.setInternalState(workerTask, ""toSend"", records);
        Whitebox.invokeMethod(workerTask, ""sendRecords"");
        assertEquals(SERIALIZED_KEY, sent.getValue().key());
        assertEquals(SERIALIZED_RECORD, sent.getValue().value());
        assertEquals(headers, sent.getValue().headers());

        PowerMock.verifyAll();
    }
",non-flaky,5
70850,apache_kafka,WorkerSourceTaskTest.testHeadersWithCustomConverter,"    @Test
    public void testHeadersWithCustomConverter() throws Exception {
        StringConverter stringConverter = new StringConverter();
        TestConverterWithHeaders testConverter = new TestConverterWithHeaders();

        createWorkerTask(TargetState.STARTED, stringConverter, testConverter, stringConverter);

        List<SourceRecord> records = new ArrayList<>();

        String stringA = ""rvztr tkrfrgp"";
        org.apache.kafka.connect.header.Headers headersA = new ConnectHeaders();
        String encodingA = ""latin2"";
        headersA.addString(""encoding"", encodingA);

        records.add(new SourceRecord(PARTITION, OFFSET, ""topic"", null, Schema.STRING_SCHEMA, ""a"", Schema.STRING_SCHEMA, stringA, null, headersA));

        String stringB = "" "";
        org.apache.kafka.connect.header.Headers headersB = new ConnectHeaders();
        String encodingB = ""koi8_r"";
        headersB.addString(""encoding"", encodingB);

        records.add(new SourceRecord(PARTITION, OFFSET, ""topic"", null, Schema.STRING_SCHEMA, ""b"", Schema.STRING_SCHEMA, stringB, null, headersB));

        Capture<ProducerRecord<byte[], byte[]>> sentRecordA = expectSendRecord(false, false, true, true, false, null);
        Capture<ProducerRecord<byte[], byte[]>> sentRecordB = expectSendRecord(false, false, true, true, false, null);

        PowerMock.replayAll();

        Whitebox.setInternalState(workerTask, ""toSend"", records);
        Whitebox.invokeMethod(workerTask, ""sendRecords"");

        assertEquals(ByteBuffer.wrap(""a"".getBytes()), ByteBuffer.wrap(sentRecordA.getValue().key()));
        assertEquals(
            ByteBuffer.wrap(stringA.getBytes(encodingA)),
            ByteBuffer.wrap(sentRecordA.getValue().value())
        );
        assertEquals(encodingA, new String(sentRecordA.getValue().headers().lastHeader(""encoding"").value()));

        assertEquals(ByteBuffer.wrap(""b"".getBytes()), ByteBuffer.wrap(sentRecordB.getValue().key()));
        assertEquals(
            ByteBuffer.wrap(stringB.getBytes(encodingB)),
            ByteBuffer.wrap(sentRecordB.getValue().value())
        );
        assertEquals(encodingB, new String(sentRecordB.getValue().headers().lastHeader(""encoding"").value()));

        PowerMock.verifyAll();
    }
",non-flaky,5
70851,apache_kafka,TransformationConfigTest.testEmbeddedConfigCast,"    @Test
    public void testEmbeddedConfigCast() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", Cast.Value.class.getName());
        connProps.put(""transforms.example.spec"", ""int8"");

        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
70852,apache_kafka,TransformationConfigTest.testEmbeddedConfigExtractField,"    @Test
    public void testEmbeddedConfigExtractField() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", ExtractField.Value.class.getName());
        connProps.put(""transforms.example.field"", ""field"");

        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
70853,apache_kafka,TransformationConfigTest.testEmbeddedConfigFlatten,"    @Test
    public void testEmbeddedConfigFlatten() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", Flatten.Value.class.getName());

        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
70854,apache_kafka,TransformationConfigTest.testEmbeddedConfigHoistField,"    @Test
    public void testEmbeddedConfigHoistField() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", HoistField.Value.class.getName());
        connProps.put(""transforms.example.field"", ""field"");

        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
70855,apache_kafka,TransformationConfigTest.testEmbeddedConfigInsertField,"    @Test
    public void testEmbeddedConfigInsertField() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", InsertField.Value.class.getName());

        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
70856,apache_kafka,TransformationConfigTest.testEmbeddedConfigMaskField,"    @Test
    public void testEmbeddedConfigMaskField() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", MaskField.Value.class.getName());
        connProps.put(""transforms.example.fields"", ""field"");


        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
70857,apache_kafka,TransformationConfigTest.testEmbeddedConfigRegexRouter,"    @Test
    public void testEmbeddedConfigRegexRouter() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", RegexRouter.class.getName());
        connProps.put(""transforms.example.regex"", ""(.*)"");
        connProps.put(""transforms.example.replacement"", ""prefix-$1"");

        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
70858,apache_kafka,TransformationConfigTest.testEmbeddedConfigReplaceField,"    @Test
    public void testEmbeddedConfigReplaceField() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", ReplaceField.Value.class.getName());

        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
70859,apache_kafka,TransformationConfigTest.testEmbeddedConfigSetSchemaMetadata,"    @Test
    public void testEmbeddedConfigSetSchemaMetadata() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", SetSchemaMetadata.Value.class.getName());

        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
70860,apache_kafka,TransformationConfigTest.testEmbeddedConfigTimestampConverter,"    @Test
    public void testEmbeddedConfigTimestampConverter() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", TimestampConverter.Value.class.getName());
        connProps.put(""transforms.example.target.type"", ""unix"");

        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
70861,apache_kafka,TransformationConfigTest.testEmbeddedConfigTimestampRouter,"    @Test
    public void testEmbeddedConfigTimestampRouter() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", TimestampRouter.class.getName());

        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
70862,apache_kafka,TransformationConfigTest.testEmbeddedConfigValueToKey,"    @Test
    public void testEmbeddedConfigValueToKey() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", ValueToKey.class.getName());
        connProps.put(""transforms.example.fields"", ""field"");

        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
70863,apache_kafka,StateTrackerTest.currentStateIsNullWhenNotInitialized,"    @Test
    public void currentStateIsNullWhenNotInitialized() {
        assertNull(tracker.currentState());
    }
",non-flaky,5
70864,apache_kafka,StateTrackerTest.currentState,"    @Test
    public void currentState() {
        for (State state : State.values()) {
            tracker.changeState(state, time.milliseconds());
            assertEquals(state, tracker.currentState());
        }
    }
",non-flaky,5
76920,Tencent_Firestorm,RssShuffleUtilsTest.compressionTest,"  @Test
  public void compressionTest() {
    List<Integer> testSizes = Lists.newArrayList(
        1, 1024, 128 * 1024, 512 * 1024, 1024 * 1024, 4 * 1024 * 1024);
    for (int size : testSizes) {
      singleTest(size);
    }
  }
",non-flaky,5
76921,Tencent_Firestorm,RssShuffleUtilsTest.odfsConfigurationTest,"  @Test
  public void odfsConfigurationTest() {
    SparkConf conf = new SparkConf();
    Configuration conf1 = RssShuffleUtils.newHadoopConfiguration(conf);
    assertFalse(conf1.getBoolean(""dfs.namenode.odfs.enable"", false));
    assertEquals(""org.apache.hadoop.fs.Hdfs"", conf1.get(""fs.AbstractFileSystem.hdfs.impl""));

    conf.set(RssClientConfig.RSS_OZONE_DFS_NAMENODE_ODFS_ENABLE, ""true"");
    conf1 = RssShuffleUtils.newHadoopConfiguration(conf);
    assertTrue(conf1.getBoolean(""dfs.namenode.odfs.enable"", false));
    assertEquals(""org.apache.hadoop.odfs.HdfsOdfsFilesystem"", conf1.get(""fs.hdfs.impl""));
    assertEquals(""org.apache.hadoop.odfs.HdfsOdfs"", conf1.get(""fs.AbstractFileSystem.hdfs.impl""));

    conf.set(RssClientConfig.RSS_OZONE_FS_HDFS_IMPL, ""expect_odfs_impl"");
    conf.set(RssClientConfig.RSS_OZONE_FS_ABSTRACT_FILE_SYSTEM_HDFS_IMPL, ""expect_odfs_abstract_impl"");
    conf1 = RssShuffleUtils.newHadoopConfiguration(conf);
    assertEquals(""expect_odfs_impl"", conf1.get(""fs.hdfs.impl""));
    assertEquals(""expect_odfs_abstract_impl"", conf1.get(""fs.AbstractFileSystem.hdfs.impl""));
  }
",non-flaky,5
76922,Tencent_Firestorm,RssShuffleDataIteratorTest.readTest1,"  @Test
  public void readTest1() throws Exception {
    String basePath = HDFS_URI + ""readTest1"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test1"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 5, expectedData,
        blockIdBitmap, ""key"", KRYO_SERIALIZER, 0);

    RssShuffleDataIterator rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);

    validateResult(rssShuffleDataIterator, expectedData, 10);

    blockIdBitmap.add(ClientUtils.getBlockId(0, 0, Constants.MAX_SEQUENCE_NO));
    rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);
    int recNum = 0;
    try {
      // can't find all expected block id, data loss
      while (rssShuffleDataIterator.hasNext()) {
        rssShuffleDataIterator.next();
        recNum++;
      }
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().startsWith(""Blocks read inconsistent:""));
    }
    assertEquals(10, recNum);
  }
",non-flaky,5
76923,Tencent_Firestorm,RssShuffleDataIteratorTest.readTest2,"  @Test
  public void readTest2() throws Exception {
    String basePath = HDFS_URI + ""readTest2"";
    HdfsShuffleWriteHandler writeHandler1 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test2_1"", conf);
    HdfsShuffleWriteHandler writeHandler2 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test2_2"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler1, 2, 5, expectedData,
        blockIdBitmap, ""key1"", KRYO_SERIALIZER, 0);
    writeTestData(writeHandler2, 2, 5, expectedData,
        blockIdBitmap, ""key2"", KRYO_SERIALIZER, 0);

    RssShuffleDataIterator rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);

    validateResult(rssShuffleDataIterator, expectedData, 20);
    assertEquals(20, rssShuffleDataIterator.getShuffleReadMetrics().recordsRead());
    assertEquals(256, rssShuffleDataIterator.getShuffleReadMetrics().remoteBytesRead());
    assertTrue(rssShuffleDataIterator.getShuffleReadMetrics().fetchWaitTime() > 0);
  }
",non-flaky,5
76924,Tencent_Firestorm,RssShuffleDataIteratorTest.readTest3,"  @Test
  public void readTest3() throws Exception {
    String basePath = HDFS_URI + ""readTest3"";
    HdfsShuffleWriteHandler writeHandler1 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test3_1"", conf);
    HdfsShuffleWriteHandler writeHandler2 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test3_2"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler1, 2, 5, expectedData,
        blockIdBitmap, ""key1"", KRYO_SERIALIZER, 0);
    writeTestData(writeHandler2, 2, 5, expectedData,
        blockIdBitmap, ""key2"", KRYO_SERIALIZER, 0);

    // duplicate file created, it should be used in product environment
    String shuffleFolder = basePath + ""/appId/0/0-1"";
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_1_0.data""), fs,
        new Path(shuffleFolder + ""/test3_1_0.cp.data""), false, conf);
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_1_0.index""), fs,
        new Path(shuffleFolder + ""/test3_1_0.cp.index""), false, conf);
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_2_0.data""), fs,
        new Path(shuffleFolder + ""/test3_2_0.cp.data""), false, conf);
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_2_0.index""), fs,
        new Path(shuffleFolder + ""/test3_2_0.cp.index""), false, conf);

    RssShuffleDataIterator rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);

    validateResult(rssShuffleDataIterator, expectedData, 20);
  }
",non-flaky,5
76925,Tencent_Firestorm,RssShuffleDataIteratorTest.readTest4,"  @Test
  public void readTest4() throws Exception {
    String basePath = HDFS_URI + ""readTest4"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test1"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 5, expectedData,
        blockIdBitmap, ""key"", KRYO_SERIALIZER, 0);

    RssShuffleDataIterator rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);
    // data file is deleted after iterator initialization
    Path dataFile = new Path(basePath + ""/appId/0/0-1/test1_0.data"");
    fs.delete(dataFile, true);
    // sleep to wait delete operation
    Thread.sleep(10000);
    try {
      fs.listStatus(dataFile);
      fail(""Index file should be deleted"");
    } catch (Exception e) {
    }

    try {
      while (rssShuffleDataIterator.hasNext()) {
        rssShuffleDataIterator.next();
      }
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().startsWith(""Blocks read inconsistent: expected""));
    }
  }
",non-flaky,5
76926,Tencent_Firestorm,RssShuffleDataIteratorTest.readTest5,"  @Test
  public void readTest5() throws Exception {
    String basePath = HDFS_URI + ""readTest5"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 5, expectedData,
        blockIdBitmap, ""key"", KRYO_SERIALIZER, 0);

    RssShuffleDataIterator rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);
    // index file is deleted after iterator initialization, it should be ok, all index infos are read already
    Path indexFile = new Path(basePath + ""/appId/0/0-1/test.index"");
    fs.delete(indexFile, true);
    // sleep to wait delete operation
    Thread.sleep(10000);
    try {
      fs.listStatus(indexFile);
      fail(""Index file should be deleted"");
    } catch (Exception e) {
    }
    validateResult(rssShuffleDataIterator, expectedData, 10);
  }
",non-flaky,5
76927,Tencent_Firestorm,RssShuffleDataIteratorTest.readTest7,"  @Test
  public void readTest7() throws Exception {
    String basePath = HDFS_URI + ""readTest7"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 5, expectedData,
        blockIdBitmap, ""key"", KRYO_SERIALIZER, 0);

    RssShuffleDataIterator rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);

    // crc32 is incorrect
    try (MockedStatic<ChecksumUtils> checksumUtilsMock = Mockito.mockStatic(ChecksumUtils.class)) {
      checksumUtilsMock.when(() -> ChecksumUtils.getCrc32((ByteBuffer) any())).thenReturn(-1L);
      try {
        while (rssShuffleDataIterator.hasNext()) {
          rssShuffleDataIterator.next();
        }
        fail(EXPECTED_EXCEPTION_MESSAGE);
      } catch (Exception e) {
        assertTrue(e.getMessage().startsWith(""Unexpected crc value""));
      }
    }
  }
",non-flaky,5
76928,Tencent_Firestorm,WriteBufferTest.test,"  @Test
  public void test() {
    WriterBuffer wb = new WriterBuffer(32);
    assertEquals(0, wb.getMemoryUsed());
    assertEquals(0, wb.getDataLength());

    serializeData(""key"", ""value"");
    // size of serialized kv is 12
    wb.addRecord(serializedData, serializedDataLength);
    assertEquals(32, wb.getMemoryUsed());
    assertEquals(12, wb.getDataLength());
    wb.addRecord(serializedData, serializedDataLength);
    assertEquals(32, wb.getMemoryUsed());
    // case: data size < output buffer size, when getData(), [] + buffer with 24b = 24b
    assertEquals(24, wb.getData().length);
    wb.addRecord(serializedData, serializedDataLength);
    // case: data size > output buffer size, when getData(), [1 buffer] + buffer with 12 = 36b
    assertEquals(36, wb.getData().length);
    assertEquals(64, wb.getMemoryUsed());
    wb.addRecord(serializedData, serializedDataLength);
    wb.addRecord(serializedData, serializedDataLength);
    // case: data size > output buffer size, when getData(), 2 buffer + output with 12b = 60b
    assertEquals(60, wb.getData().length);
    assertEquals(96, wb.getMemoryUsed());

    wb = new WriterBuffer(32);

    serializeData(""key1111111111111111111111111111"", ""value222222222222222222222222222"");
    wb.addRecord(serializedData, serializedDataLength);
    assertEquals(67, wb.getMemoryUsed());
    assertEquals(67, wb.getDataLength());

    serializeData(""key"", ""value"");
    wb.addRecord(serializedData, serializedDataLength);
    // 67 + 32
    assertEquals(99, wb.getMemoryUsed());
    // 67 + 12
    assertEquals(79, wb.getDataLength());
    assertEquals(79, wb.getData().length);

    wb.addRecord(serializedData, serializedDataLength);
    assertEquals(99, wb.getMemoryUsed());
    assertEquals(91, wb.getDataLength());
    assertEquals(91, wb.getData().length);
  }
",non-flaky,5
76929,Tencent_Firestorm,WriteBufferManagerTest.addRecordTest,"  @Test
  public void addRecordTest() {
    SparkConf conf = getConf();
    WriteBufferManager wbm = createManager(conf);
    wbm.setShuffleWriteMetrics(new ShuffleWriteMetrics());
    String testKey = ""Key"";
    String testValue = ""Value"";
    List<ShuffleBlockInfo> result = wbm.addRecord(0, testKey, testValue);
    // single buffer is not full, there is no data return
    assertEquals(0, result.size());
    assertEquals(512, wbm.getAllocatedBytes());
    assertEquals(32, wbm.getUsedBytes());
    assertEquals(0, wbm.getInSendListBytes());
    assertEquals(1, wbm.getBuffers().size());
    wbm.addRecord(0, testKey, testValue);
    wbm.addRecord(0, testKey, testValue);
    wbm.addRecord(0, testKey, testValue);
    result = wbm.addRecord(0, testKey, testValue);
    // single buffer is full
    assertEquals(1, result.size());
    assertEquals(512, wbm.getAllocatedBytes());
    assertEquals(96, wbm.getUsedBytes());
    assertEquals(96, wbm.getInSendListBytes());
    assertEquals(0, wbm.getBuffers().size());
    wbm.addRecord(0, testKey, testValue);
    wbm.addRecord(1, testKey, testValue);
    wbm.addRecord(2, testKey, testValue);
    // single buffer is not full, and less than spill size
    assertEquals(512, wbm.getAllocatedBytes());
    assertEquals(192, wbm.getUsedBytes());
    assertEquals(96, wbm.getInSendListBytes());
    assertEquals(3, wbm.getBuffers().size());
    // all buffer size > spill size
    wbm.addRecord(3, testKey, testValue);
    wbm.addRecord(4, testKey, testValue);
    result = wbm.addRecord(5, testKey, testValue);
    assertEquals(6, result.size());
    assertEquals(512, wbm.getAllocatedBytes());
    assertEquals(288, wbm.getUsedBytes());
    assertEquals(288, wbm.getInSendListBytes());
    assertEquals(0, wbm.getBuffers().size());
    // free memory
    wbm.freeAllocatedMemory(96);
    assertEquals(416, wbm.getAllocatedBytes());
    assertEquals(192, wbm.getUsedBytes());
    assertEquals(192, wbm.getInSendListBytes());

    assertEquals(11, wbm.getShuffleWriteMetrics().recordsWritten());
    assertTrue(wbm.getShuffleWriteMetrics().bytesWritten() > 0);

    wbm.freeAllocatedMemory(192);
    wbm.addRecord(0, testKey, testValue);
    wbm.addRecord(1, testKey, testValue);
    wbm.addRecord(2, testKey, testValue);
    result = wbm.clear();
    assertEquals(3, result.size());
    assertEquals(224, wbm.getAllocatedBytes());
    assertEquals(96, wbm.getUsedBytes());
    assertEquals(96, wbm.getInSendListBytes());
  }
",non-flaky,5
76930,Tencent_Firestorm,WriteBufferManagerTest.createBlockIdTest,"  @Test
  public void createBlockIdTest() {
    SparkConf conf = getConf();
    WriteBufferManager wbm = createManager(conf);
    WriterBuffer mockWriterBuffer = mock(WriterBuffer.class);
    when(mockWriterBuffer.getData()).thenReturn(new byte[]{});
    when(mockWriterBuffer.getMemoryUsed()).thenReturn(0);
    ShuffleBlockInfo sbi = wbm.createShuffleBlock(0, mockWriterBuffer);
    // seqNo = 0, partitionId = 0, taskId = 0
    assertEquals(0L, sbi.getBlockId());

    // seqNo = 1, partitionId = 0, taskId = 0
    sbi = wbm.createShuffleBlock(0, mockWriterBuffer);
    assertEquals(17592186044416L, sbi.getBlockId());

    // seqNo = 0, partitionId = 1, taskId = 0
    sbi = wbm.createShuffleBlock(1, mockWriterBuffer);
    assertEquals(1048576L, sbi.getBlockId());

    // seqNo = 1, partitionId = 1, taskId = 0
    sbi = wbm.createShuffleBlock(1, mockWriterBuffer);
    assertEquals(17592187092992L, sbi.getBlockId());
  }
",non-flaky,5
76931,Tencent_Firestorm,RssShuffleReaderTest.readTest,"  @Test
  public void readTest() throws Exception {

    String basePath = HDFS_URI + ""readTest1"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 0, basePath, ""test"", conf);
    HdfsShuffleWriteHandler writeHandler1 =
        new HdfsShuffleWriteHandler(""appId"", 0, 1, 1, basePath, ""test"", conf);

    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    writeTestData(writeHandler, 2, 5, expectedData,
        blockIdBitmap, ""key"", KRYO_SERIALIZER, 0);



    TaskContext contextMock = mock(TaskContext.class);
    RssShuffleHandle handleMock = mock(RssShuffleHandle.class);
    ShuffleDependency dependencyMock = mock(ShuffleDependency.class);
    when(handleMock.getAppId()).thenReturn(""appId"");
    when(handleMock.getDependency()).thenReturn(dependencyMock);
    when(handleMock.getShuffleId()).thenReturn(1);
    when(dependencyMock.serializer()).thenReturn(KRYO_SERIALIZER);
    when(contextMock.attemptNumber()).thenReturn(1);
    when(contextMock.taskAttemptId()).thenReturn(1L);
    when(contextMock.taskMetrics()).thenReturn(new TaskMetrics());
    doNothing().when(contextMock).killTaskIfInterrupted();
    when(dependencyMock.aggregator()).thenReturn(Option.empty());
    when(dependencyMock.keyOrdering()).thenReturn(Option.empty());
    when(dependencyMock.mapSideCombine()).thenReturn(false);

    Map<Integer, Roaring64NavigableMap> partitionToExpectBlocks = Maps.newHashMap();
    partitionToExpectBlocks.put(0, blockIdBitmap);
    RssShuffleReader rssShuffleReaderSpy = spy(new RssShuffleReader<String, String>(
        0,
        1,
        0,
        Integer.MAX_VALUE,
        contextMock,
        handleMock,
        basePath,
        1000,
        conf,
        StorageType.HDFS.name(),
        1000,
        1,
        partitionToExpectBlocks,
        taskIdBitmap,
        new ShuffleReadMetrics()));
    validateResult(rssShuffleReaderSpy.read(), expectedData, 10);

    writeTestData(writeHandler1, 2, 4, expectedData,
        blockIdBitmap1, ""another_key"", KRYO_SERIALIZER, 1);
    partitionToExpectBlocks.put(1, blockIdBitmap1);
    RssShuffleReader rssShuffleReaderSpy1 = spy(new RssShuffleReader<String, String>(
        0,
        2,
        0,
        Integer.MAX_VALUE,
        contextMock,
        handleMock,
        basePath,
        1000,
        conf,
        StorageType.HDFS.name(),
        1000,
        2,
        partitionToExpectBlocks,
        taskIdBitmap,
        new ShuffleReadMetrics()));
    validateResult(rssShuffleReaderSpy1.read(), expectedData, 18);

    RssShuffleReader rssShuffleReaderSpy2 = spy(new RssShuffleReader<String, String>(
        0,
        2,
        0,
        Integer.MAX_VALUE,
        contextMock,
        handleMock,
        basePath,
        1000,
        conf,
        StorageType.HDFS.name(),
        1000,
        2,
        partitionToExpectBlocks,
        Roaring64NavigableMap.bitmapOf(),
        new ShuffleReadMetrics()));
    validateResult(rssShuffleReaderSpy2.read(), Maps.newHashMap(), 0);
  }
",non-flaky,5
76932,Tencent_Firestorm,RssShuffleWriterTest.checkBlockSendResultTest,"  @Test
  public void checkBlockSendResultTest() {
    SparkConf conf = new SparkConf();
    conf.setAppName(""testApp"")
        .setMaster(""local[2]"")
        .set(RssClientConfig.RSS_TEST_FLAG, ""true"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_TIMEOUT, ""10000"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_INTERVAL, ""1000"")
        .set(RssClientConfig.RSS_COORDINATOR_QUORUM, ""127.0.0.1:12345,127.0.0.1:12346"");
    // init SparkContext
    SparkContext sc = SparkContext.getOrCreate(conf);
    Map<String, Set<Long>> failBlocks = Maps.newConcurrentMap();
    Map<String, Set<Long>> successBlocks = Maps.newConcurrentMap();
    Serializer kryoSerializer = new KryoSerializer(conf);
    RssShuffleManager manager = TestUtils.createShuffleManager(
        conf,
        false,
        null,
        successBlocks,
        failBlocks);

    ShuffleWriteClient mockShuffleWriteClient = mock(ShuffleWriteClient.class);
    Partitioner mockPartitioner = mock(Partitioner.class);
    RssShuffleHandle mockHandle = mock(RssShuffleHandle.class);
    ShuffleDependency mockDependency = mock(ShuffleDependency.class);
    when(mockHandle.getDependency()).thenReturn(mockDependency);
    when(mockPartitioner.numPartitions()).thenReturn(2);
    TaskMemoryManager mockTaskMemoryManager = mock(TaskMemoryManager.class);
    when(mockHandle.getPartitionToServers()).thenReturn(Maps.newHashMap());
    when(mockDependency.partitioner()).thenReturn(mockPartitioner);

    BufferManagerOptions bufferOptions = new BufferManagerOptions(conf);
    WriteBufferManager bufferManager = new WriteBufferManager(
        0, 0, bufferOptions, kryoSerializer,
        Maps.newHashMap(), mockTaskMemoryManager, new ShuffleWriteMetrics());
    WriteBufferManager bufferManagerSpy = spy(bufferManager);

    RssShuffleWriter rssShuffleWriter = new RssShuffleWriter(""appId"", 0, ""taskId"", 1L,
        bufferManagerSpy, (new TaskMetrics()).shuffleWriteMetrics(),
        manager, conf, mockShuffleWriteClient, mockHandle);
    doReturn(1000000L).when(bufferManagerSpy).acquireMemory(anyLong());

    // case 1: all blocks are sent successfully
    successBlocks.put(""taskId"", Sets.newHashSet(1L, 2L, 3L));
    rssShuffleWriter.checkBlockSendResult(Sets.newHashSet(1L, 2L, 3L));
    successBlocks.clear();

    // case 2: partial blocks aren't sent before spark.rss.writer.send.check.timeout,
    // Runtime exception will be thrown
    successBlocks.put(""taskId"", Sets.newHashSet(1L, 2L));
    thrown.expect(RuntimeException.class);
    thrown.expectMessage(StringStartsWith.startsWith(""Timeout:""));
    rssShuffleWriter.checkBlockSendResult(Sets.newHashSet(1L, 2L, 3L));
    successBlocks.clear();

    // case 3: partial blocks are sent failed, Runtime exception will be thrown
    successBlocks.put(""taskId"", Sets.newHashSet(1L, 2L));
    failBlocks.put(""taskId"", Sets.newHashSet(3L));
    thrown.expect(RuntimeException.class);
    thrown.expectMessage(StringStartsWith.startsWith(""Send failed:""));
    rssShuffleWriter.checkBlockSendResult(Sets.newHashSet(1L, 2L, 3L));
    successBlocks.clear();
    failBlocks.clear();

    sc.stop();
  }
",non-flaky,5
76933,Tencent_Firestorm,RssShuffleWriterTest.onReceive,"  @Test
  public void writeTest() throws Exception {
    SparkConf conf = new SparkConf();
    conf.setAppName(""testApp"").setMaster(""local[2]"")
        .set(RssClientConfig.RSS_WRITER_SERIALIZER_BUFFER_SIZE, ""32"")
        .set(RssClientConfig.RSS_WRITER_BUFFER_SIZE, ""32"")
        .set(RssClientConfig.RSS_TEST_FLAG, ""true"")
        .set(RssClientConfig.RSS_WRITER_BUFFER_SEGMENT_SIZE, ""64"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_TIMEOUT, ""10000"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_INTERVAL, ""1000"")
        .set(RssClientConfig.RSS_WRITER_BUFFER_SPILL_SIZE, ""128"")
        .set(RssClientConfig.RSS_COORDINATOR_QUORUM, ""127.0.0.1:12345,127.0.0.1:12346"");
    // init SparkContext
    List<ShuffleBlockInfo> shuffleBlockInfos = Lists.newArrayList();
    SparkContext sc = SparkContext.getOrCreate(conf);
    Map<String, Set<Long>> successBlockIds = Maps.newConcurrentMap();
    EventLoop<AddBlockEvent> testLoop = new EventLoop<AddBlockEvent>(""test"") {
      @Override
      public void onReceive(AddBlockEvent event) {
        assertEquals(""taskId"", event.getTaskId());
        shuffleBlockInfos.addAll(event.getShuffleDataInfoList());
        Set<Long> blockIds = event.getShuffleDataInfoList().parallelStream()
            .map(sdi -> sdi.getBlockId()).collect(Collectors.toSet());
        successBlockIds.putIfAbsent(event.getTaskId(), Sets.newConcurrentHashSet());
        successBlockIds.get(event.getTaskId()).addAll(blockIds);
      }
",non-flaky,5
76934,Tencent_Firestorm,RssShuffleWriterTest.onReceive,"  @Test
  public void postBlockEventTest() throws Exception {
    WriteBufferManager mockBufferManager = mock(WriteBufferManager.class);
    ShuffleDependency mockDependency = mock(ShuffleDependency.class);
    ShuffleWriteMetrics mockMetrics = mock(ShuffleWriteMetrics.class);
    Partitioner mockPartitioner = mock(Partitioner.class);
    when(mockDependency.partitioner()).thenReturn(mockPartitioner);
    SparkConf sparkConf = new SparkConf();
    when(mockPartitioner.numPartitions()).thenReturn(2);
    List<AddBlockEvent> events = Lists.newArrayList();

    EventLoop<AddBlockEvent> eventLoop = new EventLoop<AddBlockEvent>(""test"") {
      @Override
      public void onReceive(AddBlockEvent event) {
        events.add(event);
      }
",non-flaky,5
76935,Tencent_Firestorm,RssShuffleReaderTest.readTest,"  @Test
  public void readTest() throws Exception {

    String basePath = HDFS_URI + ""readTest1"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
     writeTestData(writeHandler, 2, 5, expectedData,
        blockIdBitmap, ""key"", KRYO_SERIALIZER, 0);

    TaskContext contextMock = mock(TaskContext.class);
    RssShuffleHandle handleMock = mock(RssShuffleHandle.class);
    ShuffleDependency dependencyMock = mock(ShuffleDependency.class);
    when(handleMock.getAppId()).thenReturn(""appId"");
    when(handleMock.getShuffleId()).thenReturn(1);
    when(handleMock.getDependency()).thenReturn(dependencyMock);
    when(dependencyMock.serializer()).thenReturn(KRYO_SERIALIZER);
    when(contextMock.taskAttemptId()).thenReturn(1L);
    when(contextMock.attemptNumber()).thenReturn(1);
    when(contextMock.taskMetrics()).thenReturn(new TaskMetrics());
    doNothing().when(contextMock).killTaskIfInterrupted();
    when(dependencyMock.mapSideCombine()).thenReturn(false);
    when(dependencyMock.aggregator()).thenReturn(Option.empty());
    when(dependencyMock.keyOrdering()).thenReturn(Option.empty());

    RssShuffleReader rssShuffleReaderSpy = spy(new RssShuffleReader<String, String>(0, 1, contextMock,
        handleMock, basePath, 1000, conf, StorageType.HDFS.name(),
        1000, 2, 10, blockIdBitmap, taskIdBitmap));

    validateResult(rssShuffleReaderSpy.read(), expectedData, 10);
  }
",non-flaky,5
76936,Tencent_Firestorm,RssShuffleWriterTest.checkBlockSendResultTest,"  @Test
  public void checkBlockSendResultTest() {
    SparkConf conf = new SparkConf();
    conf.setAppName(""testApp"")
        .setMaster(""local[2]"")
        .set(RssClientConfig.RSS_TEST_FLAG, ""true"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_TIMEOUT, ""10000"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_INTERVAL, ""1000"")
        .set(RssClientConfig.RSS_COORDINATOR_QUORUM, ""127.0.0.1:12345,127.0.0.1:12346"");
    // init SparkContext
    SparkContext sc = SparkContext.getOrCreate(conf);
    RssShuffleManager manager = new RssShuffleManager(conf, false);

    Serializer kryoSerializer = new KryoSerializer(conf);
    ShuffleWriteClient mockShuffleWriteClient = mock(ShuffleWriteClient.class);
    Partitioner mockPartitioner = mock(Partitioner.class);
    ShuffleDependency mockDependency = mock(ShuffleDependency.class);
    RssShuffleHandle mockHandle = mock(RssShuffleHandle.class);
    when(mockHandle.getDependency()).thenReturn(mockDependency);
    when(mockDependency.partitioner()).thenReturn(mockPartitioner);
    when(mockPartitioner.numPartitions()).thenReturn(2);
    when(mockHandle.getPartitionToServers()).thenReturn(Maps.newHashMap());
    TaskMemoryManager mockTaskMemoryManager = mock(TaskMemoryManager.class);

    BufferManagerOptions bufferOptions = new BufferManagerOptions(conf);
    WriteBufferManager bufferManager = new WriteBufferManager(
        0, 0, bufferOptions, kryoSerializer,
        Maps.newHashMap(), mockTaskMemoryManager, new ShuffleWriteMetrics());
    WriteBufferManager bufferManagerSpy = spy(bufferManager);
    doReturn(1000000L).when(bufferManagerSpy).acquireMemory(anyLong());

    RssShuffleWriter rssShuffleWriter = new RssShuffleWriter(""appId"", 0, ""taskId"", 1L,
        bufferManagerSpy, (new TaskMetrics()).shuffleWriteMetrics(),
        manager, conf, mockShuffleWriteClient, mockHandle);

    // case 1: all blocks are sent successfully
    manager.addSuccessBlockIds(""taskId"", Sets.newHashSet(1L, 2L, 3L));
    rssShuffleWriter.checkBlockSendResult(Sets.newHashSet(1L, 2L, 3L));
    manager.clearCachedBlockIds();

    // case 2: partial blocks aren't sent before spark.rss.writer.send.check.timeout,
    // Runtime exception will be thrown
    manager.addSuccessBlockIds(""taskId"", Sets.newHashSet(1L, 2L));
    thrown.expect(RuntimeException.class);
    thrown.expectMessage(StringStartsWith.startsWith(""Timeout:""));
    rssShuffleWriter.checkBlockSendResult(Sets.newHashSet(1L, 2L, 3L));

    manager.clearCachedBlockIds();

    // case 3: partial blocks are sent failed, Runtime exception will be thrown
    manager.addSuccessBlockIds(""taskId"", Sets.newHashSet(1L, 2L));
    manager.addFailedBlockIds(""taskId"", Sets.newHashSet(3L));
    thrown.expect(RuntimeException.class);
    thrown.expectMessage(StringStartsWith.startsWith(""Send failed:""));
    rssShuffleWriter.checkBlockSendResult(Sets.newHashSet(1L, 2L, 3L));
    manager.clearCachedBlockIds();

    sc.stop();
  }
",non-flaky,5
76937,Tencent_Firestorm,RssShuffleWriterTest.onReceive,"  @Test
  public void writeTest() throws Exception {
    SparkConf conf = new SparkConf();
    conf.setAppName(""testApp"").setMaster(""local[2]"")
        .set(RssClientConfig.RSS_TEST_FLAG, ""true"")
        .set(RssClientConfig.RSS_WRITER_BUFFER_SIZE, ""32"")
        .set(RssClientConfig.RSS_WRITER_SERIALIZER_BUFFER_SIZE, ""32"")
        .set(RssClientConfig.RSS_WRITER_BUFFER_SEGMENT_SIZE, ""64"")
        .set(RssClientConfig.RSS_WRITER_BUFFER_SPILL_SIZE, ""128"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_TIMEOUT, ""10000"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_INTERVAL, ""1000"")
        .set(RssClientConfig.RSS_COORDINATOR_QUORUM, ""127.0.0.1:12345,127.0.0.1:12346"");
    // init SparkContext
    SparkContext sc = SparkContext.getOrCreate(conf);
    RssShuffleManager manager = new RssShuffleManager(conf, false);
    List<ShuffleBlockInfo> shuffleBlockInfos = Lists.newArrayList();

    manager.setEventLoop(new EventLoop<AddBlockEvent>(""test"") {
      @Override
      public void onReceive(AddBlockEvent event) {
        assertEquals(""taskId"", event.getTaskId());
        shuffleBlockInfos.addAll(event.getShuffleDataInfoList());
        Set<Long> blockIds = event.getShuffleDataInfoList().parallelStream()
            .map(sdi -> sdi.getBlockId()).collect(Collectors.toSet());
        manager.addSuccessBlockIds(event.getTaskId(), blockIds);
      }
",non-flaky,5
76938,Tencent_Firestorm,RssShuffleWriterTest.onReceive,"  @Test
  public void postBlockEventTest() throws Exception {
    WriteBufferManager mockBufferManager = mock(WriteBufferManager.class);
    ShuffleWriteMetrics mockMetrics = mock(ShuffleWriteMetrics.class);
    ShuffleDependency mockDependency = mock(ShuffleDependency.class);
    Partitioner mockPartitioner = mock(Partitioner.class);
    RssShuffleManager mockShuffleManager = mock(RssShuffleManager.class);
    when(mockDependency.partitioner()).thenReturn(mockPartitioner);
    when(mockPartitioner.numPartitions()).thenReturn(2);
    List<AddBlockEvent> events = Lists.newArrayList();

    EventLoop<AddBlockEvent> eventLoop = new EventLoop<AddBlockEvent>(""test"") {
      @Override
      public void onReceive(AddBlockEvent event) {
        events.add(event);
      }
",non-flaky,5
76939,Tencent_Firestorm,ClientUtilsTest.getBlockIdTest,"  @Test
  public void getBlockIdTest() {
    // max value of blockId
    assertEquals(
        new Long(9223372036854775807L), ClientUtils.getBlockId(16777215, 1048575, 524287));
    // just a random test
    assertEquals(
        new Long(1759218709299300L), ClientUtils.getBlockId(100, 100, 100));
    // min value of blockId
    assertEquals(
        new Long(0L), ClientUtils.getBlockId(0, 0, 0));
    try {
      ClientUtils.getBlockId(16777216, 0, 0);
      fail(EXCEPTION_EXPECTED);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Can't support partitionId[16777216], the max value should be 16777215""));
    }
    try {
      ClientUtils.getBlockId(0, 1048576, 0);
      fail(EXCEPTION_EXPECTED);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Can't support taskAttemptId[1048576], the max value should be 1048575""));
    }
    try {
      ClientUtils.getBlockId(0, 0, 524288);
      fail(EXCEPTION_EXPECTED);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Can't support sequence[524288], the max value should be 524287""));
    }
  }
",non-flaky,5
76940,Tencent_Firestorm,ClientUtilsTest.getBitmapNumTest,"  @Test
  public void getBitmapNumTest() {
    // max value of taskNum, partitionNum, blockNumPerTaskPerPartition, it is unexpected in real job
    assertEquals(
        2147483647, ClientUtils.getBitmapNum(Integer.MAX_VALUE, Integer.MAX_VALUE, 1000000, 100000000L));
    // taskNum * partitionNum * blockNumPerTaskPerPartition / blockNumPerBitmap > 0
    assertEquals(
        5001, ClientUtils.getBitmapNum(100000, 100000, 50, 100000000L));
    // taskNum * partitionNum * blockNumPerTaskPerPartition / blockNumPerBitmap = 0
    assertEquals(
        1, ClientUtils.getBitmapNum(1999, 1999, 50, 100000000L));
    try {
      ClientUtils.getBitmapNum(1, 1, 1, 19999999L);
      fail(EXCEPTION_EXPECTED);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""blockNumPerBitmap should be greater than""));
    }
    try {
      ClientUtils.getBitmapNum(1, 1, 1000001, 20000000L);
      fail(EXCEPTION_EXPECTED);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""blockNumPerTaskPerPartition should be less than""));
    }
  }
",non-flaky,5
76941,Tencent_Firestorm,ShuffleReadClientImplTest.readTest1,"  @Test
  public void readTest1() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest1"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 1, 1, basePath, ""test1"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 30, 0, expectedData,
        blockIdBitmap);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 100, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    blockIdBitmap.addLong(Constants.MAX_TASK_ATTEMPT_ID - 1);
    taskIdBitmap.addLong(Constants.MAX_TASK_ATTEMPT_ID - 1);
    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 100, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());
    TestUtils.validateResult(readClient, expectedData);
    try {
      // can't find all expected block id, data loss
      readClient.checkProcessedBlockIds();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Blocks read inconsistent:""));
    } finally {
      readClient.close();
    }
  }
",non-flaky,5
76942,Tencent_Firestorm,ShuffleReadClientImplTest.readTest2,"  @Test
  public void readTest2() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest2"";
    HdfsShuffleWriteHandler writeHandler1 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test2_1"", conf);
    HdfsShuffleWriteHandler writeHandler2 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test2_2"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler1, 2, 30, 0, expectedData, blockIdBitmap);
    writeTestData(writeHandler2, 2, 30, 0, expectedData, blockIdBitmap);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
",non-flaky,5
76943,Tencent_Firestorm,ShuffleReadClientImplTest.readTest3,"  @Test
  public void readTest3() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest3"";
    HdfsShuffleWriteHandler writeHandler1 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test3_1"", conf);
    HdfsShuffleWriteHandler writeHandler2 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test3_2"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler1, 2, 30, 0, expectedData, blockIdBitmap);
    writeTestData(writeHandler2, 2, 30, 0, expectedData, blockIdBitmap);

    // duplicate file created, it should be used in product environment
    String shuffleFolder = basePath + ""/appId/0/0-1"";
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_1_0.data""), fs,
        new Path(basePath + ""/test3_1.cp.data""), false, conf);
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_1_0.index""), fs,
        new Path(basePath + ""/test3_1.cp.index""), false, conf);
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_2_0.data""), fs,
        new Path(basePath + ""/test3_2.cp.data""), false, conf);
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_2_0.index""), fs,
        new Path(basePath + ""/test3_2.cp.index""), false, conf);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
",non-flaky,5
76944,Tencent_Firestorm,ShuffleReadClientImplTest.readTest4,"  @Test
  public void readTest4() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest4"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test1"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 30, 0, expectedData, blockIdBitmap);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());
    Path dataFile = new Path(basePath + ""/appId/0/0-1/test1_0.data"");
    // data file is deleted after readClient checkExpectedBlockIds
    fs.delete(new Path(basePath + ""/appId/0/0-1/test1_0.data""), true);
    // sleep to wait delete operation
    Thread.sleep(10000);

    assertNull(readClient.readShuffleBlockData());
    try {
      fs.listStatus(dataFile);
      fail(""Index file should be deleted"");
    } catch (Exception e) {
    }

    try {
      readClient.checkProcessedBlockIds();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().startsWith(""Blocks read inconsistent: expected""));
    }
    readClient.close();
  }
",non-flaky,5
76945,Tencent_Firestorm,ShuffleReadClientImplTest.readTest5,"  @Test
  public void readTest5() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest5"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 30, 0, expectedData, blockIdBitmap);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());
    // index file is deleted after iterator initialization, it should be ok, all index infos are read already
    Path indexFile = new Path(basePath + ""/appId/0/0-1/test.index"");
    fs.delete(indexFile, true);
    readClient.close();

    assertNull(readClient.readShuffleBlockData());
  }
",non-flaky,5
76946,Tencent_Firestorm,ShuffleReadClientImplTest.readTest7,"  @Test
  public void readTest7() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest7"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<Long, byte[]> expectedData1 = Maps.newHashMap();
    Map<Long, byte[]> expectedData2 = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 10, 30, 0, expectedData1, blockIdBitmap1);

    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    writeTestData(writeHandler, 10, 30, 0, expectedData2, blockIdBitmap2);

    writeTestData(writeHandler, 10, 30, 0, expectedData1, blockIdBitmap1);

    ShuffleReadClientImpl readClient1 = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 0, 100, 2, 10, 100,
        basePath, blockIdBitmap1, taskIdBitmap, Lists.newArrayList(), new Configuration());
    ShuffleReadClientImpl readClient2 = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 100,
        basePath, blockIdBitmap2, taskIdBitmap, Lists.newArrayList(), new Configuration());
    TestUtils.validateResult(readClient1, expectedData1);
    readClient1.checkProcessedBlockIds();
    readClient1.close();

    TestUtils.validateResult(readClient2, expectedData2);
    readClient2.checkProcessedBlockIds();
    readClient2.close();
  }
",non-flaky,5
76947,Tencent_Firestorm,ShuffleReadClientImplTest.readTest8,"  @Test
  public void readTest8() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest8"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 30, 0, expectedData, blockIdBitmap);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());
    // crc32 is incorrect
    try (MockedStatic<ChecksumUtils> checksumUtilsMock = Mockito.mockStatic(ChecksumUtils.class)) {
      checksumUtilsMock.when(() -> ChecksumUtils.getCrc32((ByteBuffer) any())).thenReturn(-1L);
      try {
        ByteBuffer bb = readClient.readShuffleBlockData().getByteBuffer();
        while (bb != null) {
          bb = readClient.readShuffleBlockData().getByteBuffer();
        }
        fail(EXPECTED_EXCEPTION_MESSAGE);
      } catch (Exception e) {
        assertTrue(e.getMessage().startsWith(""Unexpected crc value""));
      }
    }
    readClient.close();
  }
",non-flaky,5
76948,Tencent_Firestorm,ShuffleReadClientImplTest.readTest9,"  @Test
  public void readTest9() {
    // empty data
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        ""basePath"", Roaring64NavigableMap.bitmapOf(), Roaring64NavigableMap.bitmapOf(),
        Lists.newArrayList(), new Configuration());
    assertNull(readClient.readShuffleBlockData());
    readClient.checkProcessedBlockIds();
  }
",non-flaky,5
76949,Tencent_Firestorm,ShuffleReadClientImplTest.readTest10,"  @Test
  public void readTest10() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest10"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 5, 30, 0, expectedData, blockIdBitmap);
    Roaring64NavigableMap wrongBlockIdBitmap = Roaring64NavigableMap.bitmapOf();
    LongIterator iter = blockIdBitmap.getLongIterator();
    while (iter.hasNext()) {
      wrongBlockIdBitmap.addLong(iter.next() + (1 << Constants.TASK_ATTEMPT_ID_MAX_LENGTH));
    }

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 0, 100, 2, 10, 100,
        basePath, wrongBlockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());
    assertNull(readClient.readShuffleBlockData());
    try {
      readClient.checkProcessedBlockIds();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Blocks read inconsistent:""));
    }
  }
",non-flaky,5
76950,Tencent_Firestorm,ShuffleReadClientImplTest.readTest11,"  @Test
  public void readTest11() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest11"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 1, 1, basePath, ""test1"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 10, 30, 0, expectedData, blockIdBitmap);

    // test with different indexReadLimit to validate result
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 1, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 2, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 3, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 10, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 11, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
",non-flaky,5
76951,Tencent_Firestorm,ShuffleReadClientImplTest.readTest12,"  @Test
  public void readTest12() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest12"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 1, 1, basePath, ""test1"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0, 1);
    writeTestData(writeHandler, 5, 30, 0, expectedData, blockIdBitmap);
    writeTestData(writeHandler, 5, 30, 1, expectedData, blockIdBitmap);
    writeTestData(writeHandler, 5, 30, 2, Maps.newHashMap(), blockIdBitmap);

    // unexpected taskAttemptId should be filtered
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 100, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    assertEquals(15, readClient.getProcessedBlockIds().getLongCardinality());
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
",non-flaky,5
76952,Tencent_Firestorm,ShuffleReadClientImplTest.readTest13,"  @Test
  public void readTest13() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest13"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 1, 1, basePath, ""test1"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0, 3);
    writeTestData(writeHandler, 5, 30, 0, expectedData, blockIdBitmap);
    // test case: data generated by speculation task without report result
    writeTestData(writeHandler, 5, 30, 1, Maps.newHashMap(), Roaring64NavigableMap.bitmapOf());
    // test case: data generated by speculation task with report result
    writeTestData(writeHandler, 5, 30, 2, Maps.newHashMap(), blockIdBitmap);
    writeTestData(writeHandler, 5, 30, 3, expectedData, blockIdBitmap);

    // unexpected taskAttemptId should be filtered
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 100, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    assertEquals(20, readClient.getProcessedBlockIds().getLongCardinality());
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
",non-flaky,5
76953,Tencent_Firestorm,ShuffleReadClientImplTest.readTest14,"  @Test
  public void readTest14() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest14"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 1, 1, basePath, ""test1"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0, 2);
    writeDuplicatedData(writeHandler, 5, 30, 0, expectedData, blockIdBitmap);
    writeTestData(writeHandler, 5, 30, 1, Maps.newHashMap(), Roaring64NavigableMap.bitmapOf());
    writeTestData(writeHandler, 5, 30, 2, expectedData, blockIdBitmap);

    // unexpected taskAttemptId should be filtered
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 100, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    assertEquals(15, readClient.getProcessedBlockIds().getLongCardinality());
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
",non-flaky,5
76954,Tencent_Firestorm,ShuffleWriteClientImplTest.testSendData,"  @Test
  public void testSendData() {
    ShuffleWriteClientImpl shuffleWriteClient =
        new ShuffleWriteClientImpl(""GRPC"", 3, 2000, 4);
    ShuffleServerClient mockShuffleServerClient = mock(ShuffleServerClient.class);
    ShuffleWriteClientImpl spyClient = spy(shuffleWriteClient);
    doReturn(mockShuffleServerClient).when(spyClient).getShuffleServerClient(any());
    when(mockShuffleServerClient.sendShuffleData(any())).thenReturn(
        new RssSendShuffleDataResponse(ResponseStatusCode.NO_BUFFER));

    List<ShuffleServerInfo> shuffleServerInfoList =
        Lists.newArrayList(new ShuffleServerInfo(""id"", ""host"", 0));
    List<ShuffleBlockInfo> shuffleBlockInfoList = Lists.newArrayList(new ShuffleBlockInfo(
        0, 0, 10, 10, 10, new byte[]{1}, shuffleServerInfoList, 10, 100, 0));
    SendShuffleDataResult result = spyClient.sendShuffleData(""appId"", shuffleBlockInfoList);

    assertTrue(result.getFailedBlockIds().contains(10L));
  }
",non-flaky,5
76955,Tencent_Firestorm,JettyServerTest.jettyServerTest,"  @Test
  public void jettyServerTest() throws FileNotFoundException {
    RssBaseConf conf = new RssBaseConf();
    conf.setString(""rss.jetty.http.port"", ""9527"");
    JettyServer jettyServer = new JettyServer(conf);
    Server server = jettyServer.getServer();

    assertEquals(4, server.getBeans().size());
    assertEquals(30000, server.getStopTimeout());
    assertTrue(server.getThreadPool() instanceof ExecutorThreadPool);

    assertEquals(1, server.getConnectors().length);
    assertEquals(server, server.getHandler().getServer());
    assertTrue(server.getConnectors()[0] instanceof ServerConnector);
    ServerConnector connector = (ServerConnector) server.getConnectors()[0];
    assertEquals(9527, connector.getPort());

    assertEquals(1, server.getHandlers().length);
    Handler handler = server.getHandler();
    assertTrue(handler instanceof ServletContextHandler);
  }
",non-flaky,5
76956,Tencent_Firestorm,JettyServerTest.jettyServerStartTest,"  @Test
  public void jettyServerStartTest() throws Exception {
    try {
      RssBaseConf conf = new RssBaseConf();
      conf.setString(""rss.jetty.http.port"", ""9527"");
      JettyServer jettyServer1 = new JettyServer(conf);
      JettyServer jettyServer2 = new JettyServer(conf);
      jettyServer1.start();

      ExitUtils.disableSystemExit();
      final String expectMessage = ""Fail to start jetty http server"";
      final int expectStatus = 1;
      try {
        jettyServer2.start();
      } catch (Exception e) {
        assertEquals(expectMessage, e.getMessage());
        assertEquals(expectStatus, ((ExitException) e).getStatus());
      }

      final Thread t = new Thread(null, () -> {
        throw new AssertionError(""TestUncaughtException"");
      }, ""testThread"");
      t.start();
      t.join();
    } catch (Exception e) {
      e.printStackTrace();
      fail();
    }

  }
",non-flaky,5
76957,Tencent_Firestorm,ConfigOptionTest.testBasicTypes,"  @Test
  public void testBasicTypes() {
    final ConfigOption<Integer> intConfig = ConfigOptions
        .key(""rss.key1"")
        .intType()
        .defaultValue(1000)
        .withDescription(""Int config key1"");
    assertSame(Integer.class, intConfig.getClazz());
    assertEquals(1000, (int) intConfig.defaultValue());
    assertEquals(""Int config key1"", intConfig.description());

    final ConfigOption<Long> longConfig = ConfigOptions
        .key(""rss.key2"")
        .longType()
        .defaultValue(1999L);
    assertTrue(longConfig.hasDefaultValue());
    assertEquals(1999L, (long) longConfig.defaultValue());

    final ConfigOption<String> stringConfig = ConfigOptions
        .key(""rss.key3"")
        .stringType()
        .noDefaultValue();
    assertFalse(stringConfig.hasDefaultValue());
    assertEquals("""", stringConfig.description());

    final ConfigOption<Boolean> booleanConfig = ConfigOptions
        .key(""key4"")
        .booleanType()
        .defaultValue(false)
        .withDescription(""Boolean config key"");
    assertFalse(booleanConfig.defaultValue());
    assertEquals(""Boolean config key"", booleanConfig.description());

    final ConfigOption<Integer> positiveInt = ConfigOptions
        .key(""key5"")
        .intType()
        .checkValue((v) -> {return v > 0;}, ""The value of key5 must be positive"")
        .defaultValue(1)
        .withDescription(""Positive integer key"");
    RssBaseConf conf = new RssBaseConf();
    conf.set(positiveInt, -1);
    boolean isException = false;
    try {
      conf.get(positiveInt);
    } catch (IllegalArgumentException ie) {
      isException = true;
      assertTrue(ie.getMessage().contains(""The value of key5 must be positive""));
    }
    assertTrue(isException);
    conf.set(positiveInt, 1);
    try {
      conf.get(positiveInt);
    } catch (IllegalArgumentException ie) {
      fail();
    }
  }
",non-flaky,5
76958,Tencent_Firestorm,RssConfTest.testOptionWithDefault,"    @Test
    public void testOptionWithDefault() {
        RssConf cfg = new RssConf();
        cfg.setInteger(""int-key"", 11);
        cfg.setString(""string-key"", ""abc"");

        ConfigOption<String> presentStringOption = ConfigOptions
                .key(""string-key"")
                .stringType()
                .defaultValue(""my-beautiful-default"");
        ConfigOption<Integer> presentIntOption = ConfigOptions
                .key(""int-key"")
                .intType()
                .defaultValue(87);

        assertEquals(""abc"", cfg.getString(presentStringOption));
        assertEquals(""abc"", cfg.getValue(presentStringOption));

        assertEquals(11, cfg.getInteger(presentIntOption));
        assertEquals(""11"", cfg.getValue(presentIntOption));
    }
",non-flaky,5
76959,Tencent_Firestorm,RssConfTest.testSetStringAndGetConcreteType,"    @Test
    public void testSetStringAndGetConcreteType() {
        RssConf conf = new RssConf();
        conf.setString(""boolean-type"", ""true"");
        conf.setString(""int-type"", ""1111"");
        conf.setString(""long-type"", ""1000"");
        assertTrue(conf.getBoolean(""boolean-type"", false));
        assertEquals(conf.getInteger(""int-type"", 100), 1111);
        assertEquals(conf.getLong(""long-type"", 222L), 1000L);
    }
",non-flaky,5
76960,Tencent_Firestorm,RssConfTest.testOptionWithNoDefault,"    @Test
    public void testOptionWithNoDefault() {
        RssConf cfg = new RssConf();
        cfg.setInteger(""int-key"", 11);
        cfg.setString(""string-key"", ""abc"");

        ConfigOption<String> presentStringOption = ConfigOptions
                .key(""string-key"")
                .stringType()
                .noDefaultValue();

        assertEquals(""abc"", cfg.getString(presentStringOption));
        assertEquals(""abc"", cfg.getValue(presentStringOption));

        // test getting default when no value is present

        ConfigOption<String> stringOption = ConfigOptions
                .key(""test"")
                .stringType()
                .noDefaultValue();

        // getting strings for null should work
        assertNull(cfg.getValue(stringOption));
        assertNull(cfg.getString(stringOption));

        // overriding the null default should work
        assertEquals(""override"", cfg.getString(stringOption, ""override""));
    }
",non-flaky,5
76961,Tencent_Firestorm,ChecksumUtilsTest.crc32TestWithByte,"  @Test
  public void crc32TestWithByte() {
    byte[] data = new byte[32 * 1024 * 1024];
    new Random().nextBytes(data);
    CRC32 crc32 = new CRC32();
    crc32.update(data);
    long expected = crc32.getValue();
    assertEquals(expected, ChecksumUtils.getCrc32(data));

    data = new byte[32 * 1024];
    new Random().nextBytes(data);
    crc32 = new CRC32();
    crc32.update(data);
    expected = crc32.getValue();
    assertEquals(expected, ChecksumUtils.getCrc32(data));
  }
",non-flaky,5
76962,Tencent_Firestorm,ChecksumUtilsTest.crc32TestWithByteBuff,"  @Test
  public void crc32TestWithByteBuff() throws Exception {
    int length = 32 * 1024 * 1024;
    byte[] data = new byte[length];
    new Random().nextBytes(data);

    String tempDir = Files.createTempDirectory(""rss"").toString();
    File file = new File(tempDir, ""crc_test.txt"");
    file.createNewFile();
    file.deleteOnExit();

    try (FileOutputStream outputStream = new FileOutputStream(file)) {
      outputStream.write(data);
    }

    long expectedChecksum = ChecksumUtils.getCrc32(data);

    // test direct ByteBuffer
    Path path = Paths.get(file.getAbsolutePath());
    FileChannel fileChannel = FileChannel.open(path);
    ByteBuffer buffer = ByteBuffer.allocateDirect(length);
    int bytesRead = fileChannel.read(buffer);
    fileChannel.close();
    assertEquals(length, bytesRead);
    buffer.flip();
    assertEquals(expectedChecksum, ChecksumUtils.getCrc32(buffer));
    assertEquals(length, buffer.position());

    // test heap ByteBuffer
    path = Paths.get(file.getAbsolutePath());
    fileChannel = FileChannel.open(path);
    buffer = ByteBuffer.allocate(length);
    bytesRead = fileChannel.read(buffer);
    fileChannel.close();
    assertEquals(length, bytesRead);
    buffer.flip();
    assertEquals(expectedChecksum, ChecksumUtils.getCrc32(buffer));

  }
",non-flaky,5
76963,Tencent_Firestorm,RssUtilsTest.testGetPropertiesFromFile,"  @Test
  public void testGetPropertiesFromFile() {
    final String filePath = Objects.requireNonNull(
        getClass().getClassLoader().getResource(""rss-defaults.conf"")).getFile();
    Map<String, String> properties = RssUtils.getPropertiesFromFile(filePath);
    assertEquals(""12121"", properties.get(""rss.coordinator.port""));
    assertEquals(""155"", properties.get(""rss.server.heartbeat.interval""));
    assertEquals(""true"", properties.get(""rss.x.y.z""));
    assertEquals(""-XX:+PrintGCDetails-Dkey=value-Dnumbers=\""one two three\"""",
        properties.get(""rss.a.b.c.extraJavaOptions""));
  }
",non-flaky,5
76964,Tencent_Firestorm,RssUtilsTest.testGetHostIp,"  @Test
  public void testGetHostIp() {
    try {
      String address = InetAddress.getLocalHost().getHostAddress();
      String realIp = RssUtils.getHostIp();
      assertNotEquals(""127.0.0.1"", realIp);
      if (!address.equals(""127.0.0.1"")) {
        assertEquals(address, realIp);
      }
    } catch (Exception e) {
      fail(e.getMessage());
    }
  }
",non-flaky,5
76965,Tencent_Firestorm,RssUtilsTest.testSerializeBitmap,"  @Test
  public void testSerializeBitmap() throws Exception {
    Roaring64NavigableMap bitmap1 = Roaring64NavigableMap.bitmapOf(1, 2, 100, 10000);
    byte[] bytes = RssUtils.serializeBitMap(bitmap1);
    Roaring64NavigableMap bitmap2 = RssUtils.deserializeBitMap(bytes);
    assertEquals(bitmap1, bitmap2);
    assertEquals(Roaring64NavigableMap.bitmapOf(), RssUtils.deserializeBitMap(new byte[]{}));
  }
",non-flaky,5
76966,Tencent_Firestorm,RssUtilsTest.testShuffleIndexSegment,"  @Test
  public void testShuffleIndexSegment() {
    ShuffleIndexResult shuffleIndexResult = new ShuffleIndexResult();
    List<ShuffleDataSegment> shuffleDataSegments =
        RssUtils.transIndexDataToSegments(shuffleIndexResult, 1000);
    assertTrue(shuffleDataSegments.isEmpty());

    int readBufferSize = 32;
    int totalLength = 0;
    List<BufferSegment> bufferSegments = Lists.newArrayList();
    int[] dataSegmentLength = new int[]{32, 16, 10, 32, 6};

    for (int i = 0; i < dataSegmentLength.length; ++i) {
      long offset = totalLength;
      int length = dataSegmentLength[i];
      bufferSegments.add(new BufferSegment(i, offset, length, i, i, i));
      totalLength += length;
    }

    // those 5 segment's data length are [32, 16, 10, 32, 6] so the index should be
    // split into 3 ShuffleDataSegment, which are [32, 16 + 10 + 32, 6]
    int expectedTotalSegmentNum = 3;
    ByteBuffer byteBuffer = ByteBuffer.allocate(5 * 40);

    for (BufferSegment bufferSegment : bufferSegments) {
      byteBuffer.putLong(bufferSegment.getOffset());
      byteBuffer.putInt(bufferSegment.getLength());
      byteBuffer.putInt(bufferSegment.getUncompressLength());
      byteBuffer.putLong(bufferSegment.getCrc());
      byteBuffer.putLong(bufferSegment.getBlockId());
      byteBuffer.putLong(bufferSegment.getTaskAttemptId());
    }

    byte[] data = byteBuffer.array();
    shuffleDataSegments = RssUtils.transIndexDataToSegments(new ShuffleIndexResult(data), readBufferSize);
    assertEquals(expectedTotalSegmentNum, shuffleDataSegments.size());

    assertEquals(0, shuffleDataSegments.get(0).getOffset());
    assertEquals(32, shuffleDataSegments.get(0).getLength());
    assertEquals(1, shuffleDataSegments.get(0).getBufferSegments().size());

    assertEquals(32, shuffleDataSegments.get(1).getOffset());
    assertEquals(58, shuffleDataSegments.get(1).getLength());
    assertEquals(3,shuffleDataSegments.get(1).getBufferSegments().size());

    assertEquals(90, shuffleDataSegments.get(2).getOffset());
    assertEquals(6, shuffleDataSegments.get(2).getLength());
    assertEquals(1, shuffleDataSegments.get(2).getBufferSegments().size());
  }
",non-flaky,5
76967,Tencent_Firestorm,ExitUtilsTest.test,"  @Test
  public void test() {
    try {
    final int status = -1;
    final String testExitMessage = ""testExitMessage"";
    try {
      ExitUtils.disableSystemExit();
      ExitUtils.terminate(status, testExitMessage, null, null);
      fail();
    } catch (ExitException e) {
      assertEquals(status, e.getStatus());
      assertEquals(testExitMessage, e.getMessage());
    }

    final Thread t = new Thread(null, () -> {
      throw new AssertionError(""TestUncaughtException"");
    }, ""testThread"");
    t.start();
    t.join();
  } catch (Exception e) {
      e.printStackTrace();
      fail();
    }

  }
",non-flaky,5
76968,Tencent_Firestorm,UnitConverterTest.testByteString,"  @Test
  public void testByteString() {

    assertEquals(10 * PB, UnitConverter.byteStringAs(""10PB"", ByteUnit.BYTE));
    assertEquals(10 * PB, UnitConverter.byteStringAs(""10pb"", ByteUnit.BYTE));
    assertEquals(10 * PB, UnitConverter.byteStringAs(""10pB"", ByteUnit.BYTE));
    assertEquals(10 * PB, UnitConverter.byteStringAs(""10p"", ByteUnit.BYTE));
    assertEquals(10 * PB, UnitConverter.byteStringAs(""10P"", ByteUnit.BYTE));

    assertEquals(10 * TB, UnitConverter.byteStringAs(""10TB"", ByteUnit.BYTE));
    assertEquals(10 * TB, UnitConverter.byteStringAs(""10tb"", ByteUnit.BYTE));
    assertEquals(10 * TB, UnitConverter.byteStringAs(""10tB"", ByteUnit.BYTE));
    assertEquals(10 * TB, UnitConverter.byteStringAs(""10T"", ByteUnit.BYTE));
    assertEquals(10 * TB, UnitConverter.byteStringAs(""10t"", ByteUnit.BYTE));

    assertEquals(10 * GB, UnitConverter.byteStringAs(""10GB"", ByteUnit.BYTE));
    assertEquals(10 * GB, UnitConverter.byteStringAs(""10gb"", ByteUnit.BYTE));
    assertEquals(10 * GB, UnitConverter.byteStringAs(""10gB"", ByteUnit.BYTE));

    assertEquals(10 * MB, UnitConverter.byteStringAs(""10MB"", ByteUnit.BYTE));
    assertEquals(10 * MB, UnitConverter.byteStringAs(""10mb"", ByteUnit.BYTE));
    assertEquals(10 * MB, UnitConverter.byteStringAs(""10mB"", ByteUnit.BYTE));
    assertEquals(10 * MB, UnitConverter.byteStringAs(""10M"", ByteUnit.BYTE));
    assertEquals(10 * MB, UnitConverter.byteStringAs(""10m"", ByteUnit.BYTE));

    assertEquals(10 * KB, UnitConverter.byteStringAs(""10KB"", ByteUnit.BYTE));
    assertEquals(10 * KB, UnitConverter.byteStringAs(""10kb"", ByteUnit.BYTE));
    assertEquals(10 * KB, UnitConverter.byteStringAs(""10Kb"", ByteUnit.BYTE));
    assertEquals(10 * KB, UnitConverter.byteStringAs(""10K"", ByteUnit.BYTE));
    assertEquals(10 * KB, UnitConverter.byteStringAs(""10k"", ByteUnit.BYTE));

    assertEquals(1111, UnitConverter.byteStringAs(""1111"", ByteUnit.BYTE));
  }
",non-flaky,5
76969,Tencent_Firestorm,ArgumentsTest.argTest,"  @Test
  public void argTest() {
    String[] args = {""-c"", confFile};
    Arguments arguments = new Arguments();
    CommandLine commandLine = new CommandLine(arguments);
    commandLine.parseArgs(args);
    assertEquals(confFile, arguments.getConfigFile());
  }
",non-flaky,5
76970,Tencent_Firestorm,ArgumentsTest.argEmptyTest,"  @Test
  public void argEmptyTest() {
    String[] args = new String[0];
    Arguments arguments = new Arguments();
    CommandLine commandLine = new CommandLine(arguments);
    commandLine.parseArgs(args);
    assertNull(arguments.getConfigFile());
  }
",non-flaky,5
76971,Tencent_Firestorm,MetricsManagerTest.testMetricsManager,"  @Test
  public void testMetricsManager() {
    MetricsManager metricsManager = new MetricsManager();
    assertEquals(CollectorRegistry.defaultRegistry, metricsManager.getCollectorRegistry());

    CollectorRegistry expectedRegistry = new CollectorRegistry();
    metricsManager = new MetricsManager(expectedRegistry);
    assertEquals(expectedRegistry, metricsManager.getCollectorRegistry());

    String expectedName1 = ""counter"";
    String expectedHelp1 = ""Counter "" + expectedName1;
    metricsManager.addCounter(expectedName1);

    String expectedName2 = ""name2"";
    String expectedHelp2 = ""Gauge "" + expectedName2;
    String label = ""gaugeLabel"";
    Gauge gauge = metricsManager.addGauge(expectedName2, label);
    gauge.labels(""lv1"").inc();
    gauge.labels(""lv2"").inc();

    Map<String, MetricFamilySamples> metricsSamples = new HashMap<>();
    Enumeration<MetricFamilySamples> mfs = expectedRegistry.metricFamilySamples();
    while (mfs.hasMoreElements()) {
      MetricFamilySamples cur = mfs.nextElement();
      metricsSamples.put(cur.name, cur);
    }

    assertEquals(expectedHelp1, metricsSamples.get(expectedName1).help);
    assertEquals(1, metricsSamples.get(expectedName1).samples.size());

    assertEquals(expectedHelp2, metricsSamples.get(expectedName2).help);
    List<MetricFamilySamples.Sample> f = metricsSamples.get(expectedName2).samples;
    assertEquals(2, metricsSamples.get(expectedName2).samples.size());
    String[] actualLabelValues = metricsSamples
        .get(expectedName2).samples
        .stream().map(i -> i.labelValues.get(0))
        .collect(Collectors.toList()).toArray(new String[0]);
    Arrays.sort(actualLabelValues);
    assertArrayEquals(new String[]{""lv1"", ""lv2""}, actualLabelValues);
  }
",non-flaky,5
76972,Tencent_Firestorm,ShufflePartitionedBlockTest.shufflePartitionedBlockTest,"  @Test
  public void shufflePartitionedBlockTest() {
    byte[] buf = new byte[3];
    new Random().nextBytes(buf);

    ShufflePartitionedBlock b1 = new ShufflePartitionedBlock(1, 1, 2, 3, 1, buf);
    assertEquals(1, b1.getLength());
    assertEquals(2, b1.getCrc());
    assertEquals(3, b1.getBlockId());

    ShufflePartitionedBlock b3 = new ShufflePartitionedBlock(1, 1, 2, 3, 3, buf);
    assertArrayEquals(buf, b3.getData());
  }
",non-flaky,5
76973,Tencent_Firestorm,SparkClientWithLocalTest.readTest1,"  @Test
  public void readTest1() {
    String testAppId = ""localReadTest1"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    createTestData(testAppId, expectedData, blockIdBitmap, taskIdBitmap);
    blockIdBitmap.addLong((1 << Constants.TASK_ATTEMPT_ID_MAX_LENGTH));
    ShuffleReadClientImpl readClient;
    readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", blockIdBitmap, taskIdBitmap, shuffleServerInfo, null);
    validateResult(readClient, expectedData);
    try {
      // can't find all expected block id, data loss
      readClient.checkProcessedBlockIds();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Blocks read inconsistent:""));
    } finally {
      readClient.close();
    }
  }
",non-flaky,5
76974,Tencent_Firestorm,SparkClientWithLocalTest.readTest2,"  @Test
  public void readTest2() {
    String testAppId = ""localReadTest2"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 2, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);
    blocks = createShuffleBlockList(
        0, 0, 0, 2, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(),
        testAppId, 0, 0, 100, 1, 10, 1000,
        """", blockIdBitmap, taskIdBitmap, shuffleServerInfo, null);

    validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
",non-flaky,5
76975,Tencent_Firestorm,SparkClientWithLocalTest.readTest3,"  @Test
  public void readTest3() throws Exception {
    String testAppId = ""localReadTest3"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 2, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(),
        testAppId, 0, 0, 100, 1, 10, 1000,
        """", blockIdBitmap, taskIdBitmap, shuffleServerInfo, null);
    FileUtils.deleteDirectory(new File(DATA_DIR1.getAbsolutePath() + ""/"" + testAppId + ""/0/0-0""));
    FileUtils.deleteDirectory(new File(DATA_DIR2.getAbsolutePath() + ""/"" + testAppId + ""/0/0-0""));
    // sleep to wait delete operation
    Thread.sleep(2000);

    try {
      readClient.readShuffleBlockData();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Failed to read shuffle index""));
    }
    readClient.close();
  }
",non-flaky,5
76976,Tencent_Firestorm,SparkClientWithLocalTest.readTest4,"  @Test
  public void readTest4() {
    String testAppId = ""localReadTest4"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 1)));

    Map<Long, byte[]> expectedData1 = Maps.newHashMap();
    Map<Long, byte[]> expectedData2 = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 10, 30, blockIdBitmap1, expectedData1, mockSSI);
    sendTestData(testAppId, blocks);

    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    blocks = createShuffleBlockList(
        0, 1, 0, 10, 30, blockIdBitmap2, expectedData2, mockSSI);
    sendTestData(testAppId, blocks);

    blocks = createShuffleBlockList(
        0, 0, 0, 10, 30, blockIdBitmap1, expectedData1, mockSSI);
    sendTestData(testAppId, blocks);

    ShuffleReadClientImpl readClient1 = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(),
        testAppId, 0, 0, 100, 2, 10, 100,
        """", blockIdBitmap1, taskIdBitmap, shuffleServerInfo, null);
    ShuffleReadClientImpl readClient2 = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(),
        testAppId, 0, 1, 100, 2, 10, 100,
        """", blockIdBitmap2, taskIdBitmap, shuffleServerInfo, null);
    validateResult(readClient1, expectedData1);
    readClient1.checkProcessedBlockIds();
    readClient1.close();

    validateResult(readClient2, expectedData2);
    readClient2.checkProcessedBlockIds();
    readClient2.close();
  }
",non-flaky,5
76977,Tencent_Firestorm,SparkClientWithLocalTest.readTest5,"  @Test
  public void readTest5() {
    String testAppId = ""localReadTest5"";
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(),
        testAppId, 0, 1, 100, 2, 10, 1000,
        """", Roaring64NavigableMap.bitmapOf(), Roaring64NavigableMap.bitmapOf(),
        shuffleServerInfo, null);
    assertNull(readClient.readShuffleBlockData());
    readClient.checkProcessedBlockIds();
  }
",non-flaky,5
76978,Tencent_Firestorm,SparkClientWithLocalTest.readTest6,"  @Test
  public void readTest6() {
    String testAppId = ""localReadTest6"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 5, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);

    Roaring64NavigableMap wrongBlockIdBitmap = Roaring64NavigableMap.bitmapOf();
    LongIterator iter = blockIdBitmap.getLongIterator();
    while (iter.hasNext()) {
      wrongBlockIdBitmap.addLong(iter.next() + (1 << Constants.TASK_ATTEMPT_ID_MAX_LENGTH));
    }

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(),
        testAppId, 0, 0, 100, 1, 10, 100,
        """", wrongBlockIdBitmap, taskIdBitmap, shuffleServerInfo, null);
    assertNull(readClient.readShuffleBlockData());
    try {
      readClient.checkProcessedBlockIds();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Blocks read inconsistent:""));
    }
  }
",non-flaky,5
76979,Tencent_Firestorm,SparkClientWithLocalTest.readTest7,"  @Test
  public void readTest7() {
    String testAppId = ""localReadTest7"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0, 1);

    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 5, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);

    blocks = createShuffleBlockList(
        0, 0, 1, 5, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);

    blocks = createShuffleBlockList(
        0, 0, 2, 5, 30, blockIdBitmap, Maps.newHashMap(), mockSSI);
    sendTestData(testAppId, blocks);

    // unexpected taskAttemptId should be filtered
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", blockIdBitmap, taskIdBitmap, shuffleServerInfo, null);

    validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
",non-flaky,5
76980,Tencent_Firestorm,SparkClientWithLocalTest.readTest8,"  @Test
  public void readTest8() {
    String testAppId = ""localReadTest8"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0, 3);
    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 5, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);

    // test case: data generated by speculation task without report result
    blocks = createShuffleBlockList(
        0, 0, 1, 5, 30, Roaring64NavigableMap.bitmapOf(), Maps.newHashMap(), mockSSI);
    sendTestData(testAppId, blocks);
    // test case: data generated by speculation task with report result
    blocks = createShuffleBlockList(
        0, 0, 2, 5, 30, blockIdBitmap, Maps.newHashMap(), mockSSI);
    sendTestData(testAppId, blocks);

    blocks = createShuffleBlockList(
        0, 0, 3, 5, 30, Roaring64NavigableMap.bitmapOf(), Maps.newHashMap(), mockSSI);
    sendTestData(testAppId, blocks);

    // unexpected taskAttemptId should be filtered
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", blockIdBitmap, taskIdBitmap, shuffleServerInfo, null);

    validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
",non-flaky,5
76981,Tencent_Firestorm,SparkClientWithLocalTest.readTest9,"  @Test
  public void readTest9() throws Exception {
    String testAppId = ""localReadTest9"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);

    List<ShuffleBlockInfo> blocks;
    ShuffleReadClientImpl readClient;

    createTestData(testAppId, expectedData, blockIdBitmap, taskIdBitmap);
    Roaring64NavigableMap beforeAdded = RssUtils.deserializeBitMap(RssUtils.serializeBitMap(blockIdBitmap));
    // write data by another task, read data again, the cache for index file should be updated
    blocks = createShuffleBlockList(
        0, 0, 1, 3, 25, blockIdBitmap, Maps.newHashMap(), mockSSI);
    sendTestData(testAppId, blocks);
    // test with un-changed expected blockId
    readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", beforeAdded, taskIdBitmap,
        shuffleServerInfo, null);
    validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    // test with changed expected blockId
    readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", blockIdBitmap, taskIdBitmap,
        shuffleServerInfo, null);
    validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
",non-flaky,5
76982,Tencent_Firestorm,CombineByKeyTest.combineByKeyTest,"  @Test
  public void combineByKeyTest() throws Exception {
    run();
  }
",non-flaky,5
76983,Tencent_Firestorm,SparkSQLTest.resultCompareTest,"  @Test
  public void resultCompareTest() throws Exception {
    run();
    checkShuffleData();
  }
",non-flaky,5
76984,Tencent_Firestorm,RepartitionTest.resultCompareTest,"  @Test
  public void resultCompareTest() throws Exception {
    run();
  }
",non-flaky,5
76985,Tencent_Firestorm,RepartitionTest.testMemoryRelease,"  @Test
  public void testMemoryRelease() throws Exception {
    String fileName = generateTextFile(10000, 10000);
    SparkConf sparkConf = createSparkConf();
    updateSparkConfWithRss(sparkConf);
    sparkConf.set(""spark.executor.memory"", ""500m"");
    updateRssStorage(sparkConf);

    // oom if there has no memory release
    runSparkApp(sparkConf, fileName);
  }
",non-flaky,5
76986,Tencent_Firestorm,GroupByKeyTest.groupByTest,"  @Test
  public void groupByTest() throws Exception {
    run();
  }
",non-flaky,5
76987,Tencent_Firestorm,SparkFallbackReadTest.resultCompareTest,"  @Test
  public void resultCompareTest() throws Exception {
    run();
    checkShuffleData();
  }
",non-flaky,5
76988,Tencent_Firestorm,ShuffleWithRssClientTest.rpcFailTest,"  @Test
  public void rpcFailTest() throws Exception {
    String testAppId = ""rpcFailTest"";
    shuffleWriteClientImpl.registerShuffle(shuffleServerInfo1,
        testAppId, 0, Lists.newArrayList(new PartitionRange(0, 0)));
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();

    // simulator a failed server
    ShuffleServerInfo fakeShuffleServerInfo =
        new ShuffleServerInfo(""127.0.0.1-20001"", shuffleServers.get(0).getIp(), SHUFFLE_SERVER_PORT + 100);
    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 3, 25, blockIdBitmap,
        expectedData, Lists.newArrayList(shuffleServerInfo1, fakeShuffleServerInfo));
    SendShuffleDataResult result = shuffleWriteClientImpl.sendShuffleData(testAppId, blocks);
    Roaring64NavigableMap failedBlockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap succBlockIdBitmap = Roaring64NavigableMap.bitmapOf();
    for (Long blockId : result.getFailedBlockIds()) {
      failedBlockIdBitmap.addLong(blockId);
    }
    for (Long blockId : result.getSuccessBlockIds()) {
      succBlockIdBitmap.addLong(blockId);
    }
    assertEquals(blockIdBitmap, failedBlockIdBitmap);
    assertEquals(blockIdBitmap, succBlockIdBitmap);

    boolean commitResult = shuffleWriteClientImpl.sendCommit(Sets.newHashSet(
        shuffleServerInfo1, fakeShuffleServerInfo), testAppId, 0, 2);
    assertFalse(commitResult);

    Map<Integer, List<Long>> ptb = Maps.newHashMap();
    ptb.put(1, Lists.newArrayList(1L));
    try {
      Map<Integer, List<ShuffleServerInfo>> partitionToServers = Maps.newHashMap();
      partitionToServers.put(1, Lists.newArrayList(
          shuffleServerInfo1, fakeShuffleServerInfo));
      shuffleWriteClientImpl.reportShuffleResult(partitionToServers, testAppId, 0, 0, ptb, 2);
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Report shuffle result is failed for""));
    }
  }
",non-flaky,5
76989,Tencent_Firestorm,ShuffleWithRssClientTest.reportMultipleServerTest,"  @Test
  public void reportMultipleServerTest() throws Exception {
    String testAppId = ""reportMultipleServerTest"";

    shuffleWriteClientImpl.registerShuffle(shuffleServerInfo1,
        testAppId, 1, Lists.newArrayList(new PartitionRange(1, 1)));

    shuffleWriteClientImpl.registerShuffle(shuffleServerInfo2,
        testAppId, 1, Lists.newArrayList(new PartitionRange(2, 2)));

    Map<Integer, List<ShuffleServerInfo>> partitionToServers = Maps.newHashMap();
    partitionToServers.putIfAbsent(1, Lists.newArrayList(shuffleServerInfo1));
    partitionToServers.putIfAbsent(2, Lists.newArrayList(shuffleServerInfo2));
    Map<Integer, List<Long>> partitionToBlocks = Maps.newHashMap();
    List<Long> blockIds = Lists.newArrayList();
    for (int i = 0; i < 5; i++ ) {
      blockIds.add(ClientUtils.getBlockId(1, 0, i));
    }
    partitionToBlocks.put(1, blockIds);
    blockIds = Lists.newArrayList();
    for (int i = 0; i < 7; i++ ) {
      blockIds.add(ClientUtils.getBlockId(2, 0, i));
    }
    partitionToBlocks.put(2, blockIds);
    shuffleWriteClientImpl
        .reportShuffleResult(partitionToServers, testAppId, 1, 0, partitionToBlocks, 1);

    Roaring64NavigableMap bitmap = shuffleWriteClientImpl
        .getShuffleResult(""GRPC"", Sets.newHashSet(shuffleServerInfo1), testAppId,
        1, 0);
    assertTrue(bitmap.isEmpty());

    bitmap = shuffleWriteClientImpl
        .getShuffleResult(""GRPC"", Sets.newHashSet(shuffleServerInfo1), testAppId,
        1, 1);
    assertEquals(5, bitmap.getLongCardinality());
    for (int i = 0; i < 5; i++) {
      assertTrue(bitmap.contains(partitionToBlocks.get(1).get(i)));
    }

    bitmap = shuffleWriteClientImpl
        .getShuffleResult(""GRPC"", Sets.newHashSet(shuffleServerInfo1), testAppId,
        1, 2);
    assertTrue(bitmap.isEmpty());

    bitmap = shuffleWriteClientImpl
        .getShuffleResult(""GRPC"", Sets.newHashSet(shuffleServerInfo2), testAppId,
        1, 0);
    assertTrue(bitmap.isEmpty());

    bitmap = shuffleWriteClientImpl
        .getShuffleResult(""GRPC"", Sets.newHashSet(shuffleServerInfo2), testAppId,
        1, 1);
    assertTrue(bitmap.isEmpty());

    bitmap = shuffleWriteClientImpl
        .getShuffleResult(""GRPC"", Sets.newHashSet(shuffleServerInfo2), testAppId,
        1, 2);
    assertEquals(7, bitmap.getLongCardinality());
    for (int i = 0; i < 7; i++) {
      assertTrue(bitmap.contains(partitionToBlocks.get(2).get(i)));
    }
  }
",non-flaky,5
76990,Tencent_Firestorm,ShuffleWithRssClientTest.writeReadTest,"  @Test
  public void writeReadTest() throws Exception {
    String testAppId = ""writeReadTest"";
    shuffleWriteClientImpl.registerShuffle(shuffleServerInfo1,
        testAppId, 0, Lists.newArrayList(new PartitionRange(0, 0)));
    shuffleWriteClientImpl.registerShuffle(shuffleServerInfo2,
        testAppId, 0, Lists.newArrayList(new PartitionRange(0, 0)));
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);

    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 3, 25, blockIdBitmap,
        expectedData, Lists.newArrayList(shuffleServerInfo1, shuffleServerInfo2));
    shuffleWriteClientImpl.sendShuffleData(testAppId, blocks);
    // send 1st commit, finish commit won't be sent to Shuffle server and data won't be persisted to disk
    boolean commitResult = shuffleWriteClientImpl
        .sendCommit(Sets.newHashSet(shuffleServerInfo1, shuffleServerInfo2), testAppId, 0, 2);
    assertTrue(commitResult);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", blockIdBitmap, taskIdBitmap,
        Lists.newArrayList(shuffleServerInfo1, shuffleServerInfo2), null);

    try {
      readClient.readShuffleBlockData();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Failed to read shuffle index for""));
    }
    readClient.close();

    // send 2nd commit, data will be persisted to disk
    commitResult = shuffleWriteClientImpl
        .sendCommit(Sets.newHashSet(shuffleServerInfo1, shuffleServerInfo2), testAppId, 0, 2);
    assertTrue(commitResult);
    readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", blockIdBitmap, taskIdBitmap,
        Lists.newArrayList(shuffleServerInfo1, shuffleServerInfo2), null);
    validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    // commit will be failed because of fakeIp
    commitResult = shuffleWriteClientImpl.sendCommit(Sets.newHashSet(new ShuffleServerInfo(
        ""127.0.0.1-20001"", ""fakeIp"", SHUFFLE_SERVER_PORT)), testAppId, 0, 2);
    assertFalse(commitResult);

    // wait resource to be deleted
    Thread.sleep(6000);

    // commit is ok, but finish shuffle rpc will failed because resource was deleted
    commitResult = shuffleWriteClientImpl
        .sendCommit(Sets.newHashSet(shuffleServerInfo1, shuffleServerInfo2), testAppId, 0, 2);
    assertFalse(commitResult);
  }
",non-flaky,5
76991,Tencent_Firestorm,ShuffleWithRssClientTest.emptyTaskTest,"  @Test
  public void emptyTaskTest() {
    String testAppId = ""emptyTaskTest"";
    shuffleWriteClientImpl.registerShuffle(shuffleServerInfo1,
        testAppId, 0, Lists.newArrayList(new PartitionRange(0, 0)));
    boolean commitResult = shuffleWriteClientImpl
        .sendCommit(Sets.newHashSet(shuffleServerInfo1), testAppId, 0, 2);
    assertTrue(commitResult);
    commitResult = shuffleWriteClientImpl
        .sendCommit(Sets.newHashSet(shuffleServerInfo2), testAppId, 0, 2);
    assertFalse(commitResult);
  }
",non-flaky,5
76992,Tencent_Firestorm,CoordinatorGrpcTest.testGetPartitionToServers,"  @Test
  public void testGetPartitionToServers() {
    GetShuffleAssignmentsResponse testResponse = generateShuffleAssignmentsResponse();

    Map<Integer, List<ShuffleServerInfo>> partitionToServers =
        coordinatorClient.getPartitionToServers(testResponse);

    assertEquals(Arrays.asList(new ShuffleServerInfo(""id1"", ""0.0.0.1"", 100),
        new ShuffleServerInfo(""id2"", ""0.0.0.2"", 100)),
        partitionToServers.get(0));
    assertEquals(Arrays.asList(new ShuffleServerInfo(""id1"", ""0.0.0.1"", 100),
        new ShuffleServerInfo(""id2"", ""0.0.0.2"", 100)),
        partitionToServers.get(1));
    assertEquals(Arrays.asList(new ShuffleServerInfo(""id3"", ""0.0.0.3"", 100),
        new ShuffleServerInfo(""id4"", ""0.0.0.4"", 100)),
        partitionToServers.get(2));
    assertEquals(Arrays.asList(new ShuffleServerInfo(""id3"", ""0.0.0.3"", 100),
        new ShuffleServerInfo(""id4"", ""0.0.0.4"", 100)),
        partitionToServers.get(3));
    assertNull(partitionToServers.get(4));
  }
",non-flaky,5
76993,Tencent_Firestorm,CoordinatorGrpcTest.getShuffleRegisterInfoTest,"  @Test
  public void getShuffleRegisterInfoTest() {
    GetShuffleAssignmentsResponse testResponse = generateShuffleAssignmentsResponse();
    Map<ShuffleServerInfo, List<PartitionRange>> serverToPartitionRanges =
        coordinatorClient.getServerToPartitionRanges(testResponse);
    List<ShuffleRegisterInfo> expected = Arrays.asList(
        new ShuffleRegisterInfo(new ShuffleServerInfo(""id1"", ""0.0.0.1"", 100),
            Lists.newArrayList(new PartitionRange(0, 1))),
        new ShuffleRegisterInfo(new ShuffleServerInfo(""id2"", ""0.0.0.2"", 100),
            Lists.newArrayList(new PartitionRange(0, 1))),
        new ShuffleRegisterInfo(new ShuffleServerInfo(""id3"", ""0.0.0.3"", 100),
            Lists.newArrayList(new PartitionRange(2, 3))),
        new ShuffleRegisterInfo(new ShuffleServerInfo(""id4"", ""0.0.0.4"", 100),
            Lists.newArrayList(new PartitionRange(2, 3))));
    assertEquals(4, serverToPartitionRanges.size());
    for (ShuffleRegisterInfo sri : expected) {
      List<PartitionRange> partitionRanges = serverToPartitionRanges.get(sri.getShuffleServerInfo());
      assertEquals(sri.getPartitionRanges(), partitionRanges);
    }
  }
",non-flaky,5
76994,Tencent_Firestorm,CoordinatorGrpcTest.getShuffleAssignmentsTest,"  @Test
  public void getShuffleAssignmentsTest() throws Exception {
    String appId = ""getShuffleAssignmentsTest"";
    CoordinatorTestUtils.waitForRegister(coordinatorClient,2);
    RssGetShuffleAssignmentsRequest request = new RssGetShuffleAssignmentsRequest(
        appId, 1, 10, 4, 1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    RssGetShuffleAssignmentsResponse response = coordinatorClient.getShuffleAssignments(request);
    Set<Integer> expectedStart = Sets.newHashSet(0, 4, 8);

    Map<ShuffleServerInfo, List<PartitionRange>> serverToPartitionRanges = response.getServerToPartitionRanges();
    assertEquals(2, serverToPartitionRanges.size());
    List<PartitionRange> partitionRanges = Lists.newArrayList();
    for (List<PartitionRange> ranges : serverToPartitionRanges.values()) {
      partitionRanges.addAll(ranges);
    }
    for (PartitionRange pr : partitionRanges) {
      switch (pr.getStart()) {
        case 0:
          assertEquals(3, pr.getEnd());
          expectedStart.remove(0);
          break;
        case 4:
          assertEquals(7, pr.getEnd());
          expectedStart.remove(4);
          break;
        case 8:
          assertEquals(11, pr.getEnd());
          expectedStart.remove(8);
          break;
        default:
          fail(""Shouldn't be here"");
      }
    }
    assertTrue(expectedStart.isEmpty());

    request = new RssGetShuffleAssignmentsRequest(
        appId, 1, 10, 4, 2,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    response = coordinatorClient.getShuffleAssignments(request);
    serverToPartitionRanges = response.getServerToPartitionRanges();
    assertEquals(2, serverToPartitionRanges.size());
    partitionRanges = Lists.newArrayList();
    for (List<PartitionRange> ranges : serverToPartitionRanges.values()) {
      partitionRanges.addAll(ranges);
    }
    assertEquals(6, partitionRanges.size());
    int range0To3 = 0;
    int range4To7 = 0;
    int range8To11 = 0;
    for (PartitionRange pr : partitionRanges) {
      switch (pr.getStart()) {
        case 0:
          assertEquals(3, pr.getEnd());
          range0To3++;
          break;
        case 4:
          assertEquals(7, pr.getEnd());
          range4To7++;
          break;
        case 8:
          assertEquals(11, pr.getEnd());
          range8To11++;
          break;
        default:
          fail(""Shouldn't be here"");
      }
    }
    assertEquals(2, range0To3);
    assertEquals(2, range4To7);
    assertEquals(2, range8To11);

    request = new RssGetShuffleAssignmentsRequest(
        appId, 3, 2, 1, 1,
        Sets.newHashSet(""fake_version""));
    try {
      coordinatorClient.getShuffleAssignments(request);
      fail(""Exception should be thrown"");
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Empty assignment""));
    }
  }
",non-flaky,5
76995,Tencent_Firestorm,CoordinatorGrpcTest.appHeartbeatTest,"  @Test
  public void appHeartbeatTest() throws Exception {
    RssAppHeartBeatResponse response =
        coordinatorClient.sendAppHeartBeat(new RssAppHeartBeatRequest(""appHeartbeatTest1"", 1000));
    assertEquals(ResponseStatusCode.SUCCESS, response.getStatusCode());
    assertEquals(Sets.newHashSet(""appHeartbeatTest1""),
        coordinators.get(0).getApplicationManager().getAppIds());
    coordinatorClient.sendAppHeartBeat(new RssAppHeartBeatRequest(""appHeartbeatTest2"", 1000));
    assertEquals(Sets.newHashSet(""appHeartbeatTest1"", ""appHeartbeatTest2""),
        coordinators.get(0).getApplicationManager().getAppIds());
    int retry = 0;
    while (retry < 5) {
      coordinatorClient.sendAppHeartBeat(new RssAppHeartBeatRequest(""appHeartbeatTest1"", 1000));
      retry++;
      Thread.sleep(1000);
    }
    // appHeartbeatTest2 was removed because of expired
    assertEquals(Sets.newHashSet(""appHeartbeatTest1""),
        coordinators.get(0).getApplicationManager().getAppIds());
  }
",non-flaky,5
76996,Tencent_Firestorm,CoordinatorGrpcTest.shuffleServerHeartbeatTest,"  @Test
  public void shuffleServerHeartbeatTest() throws Exception {
    CoordinatorTestUtils.waitForRegister(coordinatorClient, 2);
    shuffleServers.get(0).stopServer();
    Thread.sleep(5000);
    SimpleClusterManager scm = (SimpleClusterManager) coordinators.get(0).getClusterManager();
    List<ServerNode> nodes = scm.getServerList(Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    assertEquals(1, nodes.size());
    ServerNode node = nodes.get(0);
    assertTrue(node.getTags().contains(Constants.SHUFFLE_SERVER_VERSION));
    assertTrue(scm.getTagToNodes().get(Constants.SHUFFLE_SERVER_VERSION).contains(node));
    ShuffleServerConf shuffleServerConf = shuffleServers.get(0).getShuffleServerConf();
    shuffleServerConf.setInteger(""rss.rpc.server.port"", SHUFFLE_SERVER_PORT + 2);
    shuffleServerConf.setInteger(""rss.jetty.http.port"", 18082);
    ShuffleServer ss = new ShuffleServer(shuffleServerConf);
    ss.start();
    shuffleServers.set(0, ss);
    Thread.sleep(3000);
    assertEquals(2, coordinators.get(0).getClusterManager().getNodesNum());
  }
",non-flaky,5
76997,Tencent_Firestorm,CoordinatorGrpcTest.rpcMetricsTest,"  @Test
  public void rpcMetricsTest() throws Exception{
    String appId = ""rpcMetricsTest"";
    double oldValue = coordinators.get(0).getGrpcMetrics().getCounterMap()
        .get(CoordinatorGrpcMetrics.HEARTBEAT_METHOD).get();
    CoordinatorTestUtils.waitForRegister(coordinatorClient,2);
    double newValue = coordinators.get(0).getGrpcMetrics().getCounterMap()
        .get(CoordinatorGrpcMetrics.HEARTBEAT_METHOD).get();
    assertTrue(newValue - oldValue > 1);
    assertEquals(0,
        coordinators.get(0).getGrpcMetrics().getGaugeMap()
            .get(CoordinatorGrpcMetrics.HEARTBEAT_METHOD).get(), 0.5);

    RssGetShuffleAssignmentsRequest request = new RssGetShuffleAssignmentsRequest(
        appId, 1, 10, 4, 1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    oldValue = coordinators.get(0).getGrpcMetrics().getCounterMap()
        .get(CoordinatorGrpcMetrics.GET_SHUFFLE_ASSIGNMENTS_METHOD).get();
    coordinatorClient.getShuffleAssignments(request);
    newValue = coordinators.get(0).getGrpcMetrics().getCounterMap()
        .get(CoordinatorGrpcMetrics.GET_SHUFFLE_ASSIGNMENTS_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        coordinators.get(0).getGrpcMetrics().getGaugeMap()
            .get(CoordinatorGrpcMetrics.GET_SHUFFLE_ASSIGNMENTS_METHOD).get(), 0.5);
  }
",non-flaky,5
76998,Tencent_Firestorm,PartitionBalanceCoordinatorGrpcTest.getShuffleAssignmentsTest,"  @Test
  public void getShuffleAssignmentsTest() throws Exception {
    CoordinatorTestUtils.waitForRegister(coordinatorClient, 3);
    RssGetShuffleAssignmentsRequest request = new RssGetShuffleAssignmentsRequest(
        ""app1"",
        1,
        1,
        1,
        1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    RssGetShuffleAssignmentsResponse response = coordinatorClient.getShuffleAssignments(request);
    assertEquals(1, response.getPartitionToServers().size());
    for (Map.Entry<Integer, List<ShuffleServerInfo>> entry : response.getPartitionToServers().entrySet()) {
      assertEquals(1, entry.getValue().size());
      assertEquals(SHUFFLE_SERVER_PORT + 1, entry.getValue().get(0).getPort());
    }
    request = new RssGetShuffleAssignmentsRequest(
        ""app1"",
        2,
        1,
        1,
        1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    response = coordinatorClient.getShuffleAssignments(request);
    assertEquals(1, response.getPartitionToServers().size());
    for (Map.Entry<Integer, List<ShuffleServerInfo>> entry : response.getPartitionToServers().entrySet()) {
      assertEquals(1, entry.getValue().size());
      assertEquals(SHUFFLE_SERVER_PORT + 1, entry.getValue().get(0).getPort());
    }
    request = new RssGetShuffleAssignmentsRequest(
        ""app1"",
        2,
        1,
        1,
        1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    response = coordinatorClient.getShuffleAssignments(request);
    assertEquals(1, response.getPartitionToServers().size());
    for (Map.Entry<Integer, List<ShuffleServerInfo>> entry : response.getPartitionToServers().entrySet()) {
      assertEquals(1, entry.getValue().size());
      assertEquals(SHUFFLE_SERVER_PORT, entry.getValue().get(0).getPort());
    }
  }
",non-flaky,5
76999,Tencent_Firestorm,ShuffleServerWithHdfsTest.hdfsWriteReadTest,"  @Test
  public void hdfsWriteReadTest() {
    String appId = ""app_hdfs_read_write"";
    String dataBasePath = HDFS_URI + ""rss/test"";
    RssRegisterShuffleRequest rrsr = new RssRegisterShuffleRequest(appId, 0,
        Lists.newArrayList(new PartitionRange(0, 1)));
    shuffleServerClient.registerShuffle(rrsr);
    rrsr = new RssRegisterShuffleRequest(appId, 0, Lists.newArrayList(new PartitionRange(2, 3)));
    shuffleServerClient.registerShuffle(rrsr);

    Roaring64NavigableMap[] bitmaps = new Roaring64NavigableMap[4];
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Map<Integer, List<ShuffleBlockInfo>>  dataBlocks = createTestData(bitmaps, expectedData);
    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = Maps.newHashMap();
    partitionToBlocks.put(0, dataBlocks.get(0));
    partitionToBlocks.put(1, dataBlocks.get(1));

    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);

    RssSendShuffleDataRequest rssdr = new RssSendShuffleDataRequest(appId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    assertEquals(456, shuffleServers.get(0).getShuffleBufferManager().getUsedMemory());
    assertEquals(0, shuffleServers.get(0).getShuffleBufferManager().getPreAllocatedSize());
    RssSendCommitRequest rscr = new RssSendCommitRequest(appId, 0);
    shuffleServerClient.sendCommit(rscr);
    RssFinishShuffleRequest rfsr = new RssFinishShuffleRequest(appId, 0);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        appId, 0, 0, 100, 2, 10, 1000,
        dataBasePath, bitmaps[0], Roaring64NavigableMap.bitmapOf(0), Lists.newArrayList(), new Configuration());
    assertNull(readClient.readShuffleBlockData());
    shuffleServerClient.finishShuffle(rfsr);

    partitionToBlocks.clear();
    partitionToBlocks.put(2, dataBlocks.get(2));
    shuffleToBlocks.clear();
    shuffleToBlocks.put(0, partitionToBlocks);
    rssdr = new RssSendShuffleDataRequest(appId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    assertEquals(0, shuffleServers.get(0).getShuffleBufferManager().getPreAllocatedSize());
    rscr = new RssSendCommitRequest(appId, 0);
    shuffleServerClient.sendCommit(rscr);
    rfsr = new RssFinishShuffleRequest(appId, 0);
    shuffleServerClient.finishShuffle(rfsr);

    partitionToBlocks.clear();
    partitionToBlocks.put(3, dataBlocks.get(3));
    shuffleToBlocks.clear();
    shuffleToBlocks.put(0, partitionToBlocks);
    rssdr = new RssSendShuffleDataRequest(appId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    rscr = new RssSendCommitRequest(appId, 0);
    shuffleServerClient.sendCommit(rscr);
    rfsr = new RssFinishShuffleRequest(appId, 0);
    shuffleServerClient.finishShuffle(rfsr);

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        appId, 0, 0, 100, 2, 10, 1000,
        dataBasePath, bitmaps[0], Roaring64NavigableMap.bitmapOf(0), Lists.newArrayList(), new Configuration());
    validateResult(readClient, expectedData, bitmaps[0]);

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        appId, 0, 1, 100, 2, 10, 1000,
        dataBasePath, bitmaps[1], Roaring64NavigableMap.bitmapOf(1), Lists.newArrayList(), new Configuration());
    validateResult(readClient, expectedData, bitmaps[1]);

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        appId, 0, 2, 100, 2, 10, 1000,
        dataBasePath, bitmaps[2], Roaring64NavigableMap.bitmapOf(2), Lists.newArrayList(), new Configuration());
    validateResult(readClient, expectedData, bitmaps[2]);

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        appId, 0, 3, 100, 2, 10, 1000,
        dataBasePath, bitmaps[3], Roaring64NavigableMap.bitmapOf(3), Lists.newArrayList(), new Configuration());
    validateResult(readClient, expectedData, bitmaps[3]);
  }
",non-flaky,5
77000,Tencent_Firestorm,MultiStorageFaultToleranceTest.hdfsFaultTolerance,"  @Test
  public void hdfsFaultTolerance() {
    try {
      String appId = ""app_hdfs_fault_tolerance_data"";
      Map<Long, byte[]> expectedData = Maps.newHashMap();
      Map<Integer, List<Integer>> map = Maps.newHashMap();
      map.put(2, Lists.newArrayList(0, 3));
      map.put(3, Lists.newArrayList(3));
      registerShuffle(appId, map);

      Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
      Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
      Roaring64NavigableMap blockIdBitmap3 = Roaring64NavigableMap.bitmapOf();

      List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
          2, 0, 1,11, 10 * 1024 * 1024, blockIdBitmap1, expectedData);

      List<ShuffleBlockInfo> blocks2 = createShuffleBlockList(
          3, 3, 2,9, 10 * 1024 * 1024, blockIdBitmap2, expectedData);

      List<ShuffleBlockInfo> blocks3 = createShuffleBlockList(
          2, 3, 2,9, 10 * 1024 * 1024, blockIdBitmap3, expectedData);

      assertEquals(0, ShuffleStorageUtils.getStorageIndex(2, appId, 2, 0));
      assertEquals(0, ShuffleStorageUtils.getStorageIndex(2, appId, 3, 3));
      assertEquals(0, ShuffleStorageUtils.getStorageIndex(2, appId, 2, 3));
      assertEquals(1, cluster.getDataNodes().size());
      cluster.stopDataNode(0);
      assertEquals(0, cluster.getDataNodes().size());

      sendSinglePartitionToShuffleServer(appId, 2, 0, 1, blocks1);
      boolean isException = false;
      try {
        sendSinglePartitionToShuffleServer(appId, 3, 3,2, blocks2);
      } catch (RuntimeException re) {
        isException = true;
        assertTrue(re.getMessage().contains(""Fail to finish""));
      }
      assertTrue(isException);

      cluster.startDataNodes(conf, 1, true, HdfsServerConstants.StartupOption.REGULAR,
          null, null, null, false, true);
      assertEquals(1, cluster.getDataNodes().size());

      sendSinglePartitionToShuffleServer(appId, 2, 3, 2, blocks3);

      validateResult(appId, 2, 0, blockIdBitmap1, Roaring64NavigableMap.bitmapOf(1), expectedData);
      validateResult(appId, 2, 3, blockIdBitmap3, Roaring64NavigableMap.bitmapOf(2), expectedData);
    } catch (Exception e) {
      e.printStackTrace();
      fail();
    }
  }
",non-flaky,5
77001,Tencent_Firestorm,MultiStorageFaultToleranceTest.diskFaultTolerance,"  @Test
  public void diskFaultTolerance() {
    String appId = ""app_disk_fault_tolerance_data"";
    Map<Long, byte[]> expectedData = Maps.newHashMap();

    Map<Integer, List<Integer>> map = Maps.newHashMap();
    map.put(2, Lists.newArrayList(1, 3));
    map.put(3, Lists.newArrayList(1));
    registerShuffle(appId, map);

    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap3 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap4 = Roaring64NavigableMap.bitmapOf();

    List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
        2, 1, 1,11, 10 * 1024 * 1024, blockIdBitmap1, expectedData);

    List<ShuffleBlockInfo> blocks2 = createShuffleBlockList(
        3, 1, 2,9, 10 * 1024 * 1024, blockIdBitmap2, expectedData);

    List<ShuffleBlockInfo> blocks3 = createShuffleBlockList(
        2, 3, 2,9, 10 * 1024 * 1024, blockIdBitmap3, expectedData);

    List<ShuffleBlockInfo> blocks4 = createShuffleBlockList(
        2, 1, 1, 11, 10 * 1024 * 1024, blockIdBitmap4, expectedData);

    assertEquals(1, ShuffleStorageUtils.getStorageIndex(2, appId, 2, 1));
    assertEquals(1, ShuffleStorageUtils.getStorageIndex(2, appId, 3, 1));
    assertEquals(1, ShuffleStorageUtils.getStorageIndex(2, appId, 2, 3));
    assertEquals(1, ShuffleStorageUtils.getStorageIndex(2, appId, 2, 1));
    try {
      sendSinglePartitionToShuffleServer(appId, 2, 1, 1, blocks1);
      sendSinglePartitionToShuffleServer(appId, 3, 1,2, blocks2);
      sendSinglePartitionToShuffleServer(appId, 2, 3, 2, blocks3);
      sendSinglePartitionToShuffleServer(appId, 2, 1, 1, blocks4);
    } catch (Exception e) {
      e.printStackTrace();
      fail();
    }
    validateResult(appId, 2, 1, blockIdBitmap1, Roaring64NavigableMap.bitmapOf(1), expectedData);
    validateResult(appId, 3, 1, blockIdBitmap2, Roaring64NavigableMap.bitmapOf(2), expectedData);
    validateResult(appId, 2, 3, blockIdBitmap3, Roaring64NavigableMap.bitmapOf(2), expectedData);
  }
",non-flaky,5
77002,Tencent_Firestorm,ShuffleServerWithLocalTest.localWriteReadTest,"  @Test
  public void localWriteReadTest() throws Exception {
    String testAppId = ""localWriteReadTest"";
    RssRegisterShuffleRequest rrsr = new RssRegisterShuffleRequest(testAppId, 0,
        Lists.newArrayList(new PartitionRange(0, 1)));
    shuffleServerClient.registerShuffle(rrsr);
    rrsr = new RssRegisterShuffleRequest(testAppId, 0, Lists.newArrayList(new PartitionRange(2, 3)));
    shuffleServerClient.registerShuffle(rrsr);

    Map<Long, byte[]> expectedData = Maps.newHashMap();

    Roaring64NavigableMap[] bitmaps = new Roaring64NavigableMap[4];
    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = createTestData(bitmaps, expectedData);

    Set<Long> expectedBlockIds1 = transBitmapToSet(bitmaps[0]);
    Set<Long> expectedBlockIds2 = transBitmapToSet(bitmaps[1]);
    Set<Long> expectedBlockIds3 = transBitmapToSet(bitmaps[2]);
    Set<Long> expectedBlockIds4 = transBitmapToSet(bitmaps[3]);

    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);

    RssSendShuffleDataRequest rssdr = new RssSendShuffleDataRequest(
        testAppId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    RssSendCommitRequest rscr = new RssSendCommitRequest(testAppId, 0);
    shuffleServerClient.sendCommit(rscr);
    RssFinishShuffleRequest rfsr = new RssFinishShuffleRequest(testAppId, 0);
    shuffleServerClient.finishShuffle(rfsr);

    ShuffleDataResult sdr  = readShuffleData(
        shuffleServerClient, testAppId, 0, 0, 2,
        10, 1000, 0);
    validateResult(sdr, expectedBlockIds1, expectedData, 0);
    sdr  = readShuffleData(
        shuffleServerClient, testAppId, 0, 1, 2,
        10, 1000, 0);
    validateResult(sdr, expectedBlockIds2, expectedData, 1);
    sdr  = readShuffleData(
        shuffleServerClient, testAppId, 0, 2, 2,
        10, 1000, 0);
    validateResult(sdr, expectedBlockIds3, expectedData, 2);
    sdr  = readShuffleData(
        shuffleServerClient, testAppId, 0, 3, 2,
        10, 1000, 0);
    validateResult(sdr, expectedBlockIds4, expectedData, 3);

    assertEquals(4, shuffleServers.get(0).getShuffleTaskManager()
        .getServerReadHandlers().get(testAppId).size());
    assertNotNull(shuffleServers.get(0).getShuffleTaskManager()
        .getPartitionsToBlockIds().get(testAppId));
    Thread.sleep(8000);
    assertNull(shuffleServers.get(0).getShuffleTaskManager().getServerReadHandlers().get(testAppId));
    assertNull(shuffleServers.get(0).getShuffleTaskManager().getPartitionsToBlockIds().get(testAppId));
  }
",non-flaky,5
77003,Tencent_Firestorm,ShuffleServerGrpcTest.clearResourceTest,"  @Test
  public void clearResourceTest() throws Exception {
    final ShuffleWriteClient shuffleWriteClient =
        ShuffleClientFactory.getInstance().createShuffleWriteClient(
            ""GRPC"", 2, 10000L, 4);
    shuffleWriteClient.registerCoordinators(""127.0.0.1:19999"");
    shuffleWriteClient.registerShuffle(
        new ShuffleServerInfo(""127.0.0.1-20001"", ""127.0.0.1"", 20001),
        ""clearResourceTest1"",
        0,
        Lists.newArrayList(new PartitionRange(0, 1)));

    shuffleWriteClient.sendAppHeartbeat(""clearResourceTest1"", 1000L);
    shuffleWriteClient.sendAppHeartbeat(""clearResourceTest2"", 1000L);

    RssRegisterShuffleRequest rrsr = new RssRegisterShuffleRequest(""clearResourceTest1"", 0,
        Lists.newArrayList(new PartitionRange(0, 1)));
    shuffleServerClient.registerShuffle(rrsr);
    rrsr = new RssRegisterShuffleRequest(""clearResourceTest2"", 0,
        Lists.newArrayList(new PartitionRange(0, 1)));
    shuffleServerClient.registerShuffle(rrsr);
    assertEquals(Sets.newHashSet(""clearResourceTest1"", ""clearResourceTest2""),
        shuffleServers.get(0).getShuffleTaskManager().getAppIds().keySet());

    // Thread will keep refresh clearResourceTest1 in coordinator
    Thread t = new Thread(() -> {
      int i = 0;
      while (i < 20) {
        shuffleWriteClient.sendAppHeartbeat(""clearResourceTest1"", 1000L);
        i++;
        try {
          Thread.sleep(1000);
        } catch (InterruptedException e) {
          return;
        }
      }
    });
    t.start();

    // Heartbeat is sent to coordinator too]
    Thread.sleep(3000);
    shuffleServerClient.registerShuffle(new RssRegisterShuffleRequest(""clearResourceTest1"", 0,
        Lists.newArrayList(new PartitionRange(0, 1))));
    assertEquals(Sets.newHashSet(""clearResourceTest1""),
        coordinators.get(0).getApplicationManager().getAppIds());
    // clearResourceTest2 will be removed because of rss.server.app.expired.withoutHeartbeat
    Thread.sleep(2000);
    assertEquals(Sets.newHashSet(""clearResourceTest1""),
        shuffleServers.get(0).getShuffleTaskManager().getAppIds().keySet());

    // clearResourceTest1 will be removed because of rss.server.app.expired.withoutHeartbeat
    t.interrupt();
    Thread.sleep(8000);
    assertEquals(0, shuffleServers.get(0).getShuffleTaskManager().getAppIds().size());

  }
",non-flaky,5
77004,Tencent_Firestorm,ShuffleServerGrpcTest.shuffleResultTest,"  @Test
  public void shuffleResultTest() throws Exception {
    Map<Integer, List<Long>> partitionToBlockIds = Maps.newHashMap();
    List<Long> blockIds1 = getBlockIdList(1, 3);
    List<Long> blockIds2 = getBlockIdList(2, 2);
    List<Long> blockIds3 = getBlockIdList(3, 1);
    partitionToBlockIds.put(1, blockIds1);
    partitionToBlockIds.put(2, blockIds2);
    partitionToBlockIds.put(3, blockIds3);

    RssReportShuffleResultRequest request =
        new RssReportShuffleResultRequest(""shuffleResultTest"", 0, 0L, partitionToBlockIds, 1);
    try {
      shuffleServerClient.reportShuffleResult(request);
      fail(""Exception should be thrown"");
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""error happened when report shuffle result""));
    }

    RssGetShuffleResultRequest req = new RssGetShuffleResultRequest(""shuffleResultTest"", 1, 1);
    try {
      shuffleServerClient.getShuffleResult(req);
      fail(""Exception should be thrown"");
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Can't get shuffle result""));
    }

    RssRegisterShuffleRequest rrsr = new RssRegisterShuffleRequest(""shuffleResultTest"", 100,
        Lists.newArrayList(new PartitionRange(0, 1)));
    shuffleServerClient.registerShuffle(rrsr);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 1);
    RssGetShuffleResultResponse result = shuffleServerClient.getShuffleResult(req);
    Roaring64NavigableMap blockIdBitmap = result.getBlockIdBitmap();
    assertEquals(Roaring64NavigableMap.bitmapOf(), blockIdBitmap);

    request =
        new RssReportShuffleResultRequest(""shuffleResultTest"", 0, 0L, partitionToBlockIds, 1);
    RssReportShuffleResultResponse response = shuffleServerClient.reportShuffleResult(request);
    assertEquals(ResponseStatusCode.SUCCESS, response.getStatusCode());
    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 1);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    Roaring64NavigableMap expectedP1 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP1, blockIds1);
    assertEquals(expectedP1, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 2);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    Roaring64NavigableMap expectedP2 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP2, blockIds2);
    assertEquals(expectedP2, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 3);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    Roaring64NavigableMap expectedP3 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP3, blockIds3);
    assertEquals(expectedP3, blockIdBitmap);

    partitionToBlockIds = Maps.newHashMap();
    blockIds1 = getBlockIdList(1, 3);
    blockIds2 = getBlockIdList(2, 2);
    blockIds3 = getBlockIdList(3, 1);
    partitionToBlockIds.put(1, blockIds1);
    partitionToBlockIds.put(2, blockIds2);
    partitionToBlockIds.put(3, blockIds3);

    request =
        new RssReportShuffleResultRequest(""shuffleResultTest"", 0, 1L, partitionToBlockIds, 1);
    shuffleServerClient.reportShuffleResult(request);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 1);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    addExpectedBlockIds(expectedP1, blockIds1);
    assertEquals(expectedP1, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 2);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    addExpectedBlockIds(expectedP2, blockIds2);
    assertEquals(expectedP2, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 3);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    addExpectedBlockIds(expectedP3, blockIds3);
    assertEquals(expectedP3, blockIdBitmap);

    request =
        new RssReportShuffleResultRequest(""shuffleResultTest"", 1, 1L, Maps.newHashMap(), 1);
    shuffleServerClient.reportShuffleResult(request);
    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 1, 1);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    assertEquals(Roaring64NavigableMap.bitmapOf(), blockIdBitmap);

    // test with bitmapNum > 1
    partitionToBlockIds = Maps.newHashMap();
    blockIds1 = getBlockIdList(1, 3);
    blockIds2 = getBlockIdList(2, 2);
    blockIds3 = getBlockIdList(3, 1);
    partitionToBlockIds.put(1, blockIds1);
    partitionToBlockIds.put(2, blockIds2);
    partitionToBlockIds.put(3, blockIds3);
    request =
        new RssReportShuffleResultRequest(""shuffleResultTest"", 2, 1L, partitionToBlockIds, 3);
    shuffleServerClient.reportShuffleResult(request);
    // validate bitmap in shuffleTaskManager
    Roaring64NavigableMap[] bitmaps = shuffleServers.get(0).getShuffleTaskManager()
        .getPartitionsToBlockIds().get(""shuffleResultTest"").get(2);
    assertEquals(3, bitmaps.length);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 2, 1);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    expectedP1 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP1, blockIds1);
    assertEquals(expectedP1, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 2, 2);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    expectedP2 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP2, blockIds2);
    assertEquals(expectedP2, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 2, 3);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    expectedP3 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP3, blockIds3);
    assertEquals(expectedP3, blockIdBitmap);

    partitionToBlockIds = Maps.newHashMap();
    blockIds1 = getBlockIdList((int) Constants.MAX_PARTITION_ID, 3);
    blockIds2 = getBlockIdList(2, 2);
    blockIds3 = getBlockIdList(3, 1);
    partitionToBlockIds.put((int) Constants.MAX_PARTITION_ID, blockIds1);
    partitionToBlockIds.put(2, blockIds2);
    partitionToBlockIds.put(3, blockIds3);
    // bimapNum = 2
    request =
        new RssReportShuffleResultRequest(""shuffleResultTest"", 4, 1L, partitionToBlockIds, 2);
    shuffleServerClient.reportShuffleResult(request);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 4, (int) Constants.MAX_PARTITION_ID);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    expectedP1 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP1, blockIds1);
    assertEquals(expectedP1, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 4, 2);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    expectedP2 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP2, blockIds2);
    assertEquals(expectedP2, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 4, 3);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    expectedP3 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP3, blockIds3);
    assertEquals(expectedP3, blockIdBitmap);

    // wait resources are deleted
    Thread.sleep(12000);
    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 1, 1);
    try {
      shuffleServerClient.getShuffleResult(req);
      fail(""Exception should be thrown"");
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Can't get shuffle result""));
    }
  }
",non-flaky,5
77005,Tencent_Firestorm,ShuffleServerGrpcTest.registerTest,"  @Test
  public void registerTest() {
    shuffleServerClient.registerShuffle(new RssRegisterShuffleRequest(""registerTest"", 0,
        Lists.newArrayList(new PartitionRange(0, 1))));
    RssGetShuffleResultRequest req = new RssGetShuffleResultRequest(""registerTest"", 0, 0);
    // no exception with getShuffleResult means register successfully
    shuffleServerClient.getShuffleResult(req);
    req = new RssGetShuffleResultRequest(""registerTest"", 0, 1);
    shuffleServerClient.getShuffleResult(req);
    shuffleServerClient.registerShuffle(new RssRegisterShuffleRequest(""registerTest"", 1,
        Lists.newArrayList(new PartitionRange(0, 0), new PartitionRange(1, 1), new PartitionRange(2, 2))));
    req = new RssGetShuffleResultRequest(""registerTest"", 1, 0);
    shuffleServerClient.getShuffleResult(req);
    req = new RssGetShuffleResultRequest(""registerTest"", 1, 1);
    shuffleServerClient.getShuffleResult(req);
    req = new RssGetShuffleResultRequest(""registerTest"", 1, 2);
    shuffleServerClient.getShuffleResult(req);
  }
",non-flaky,5
77006,Tencent_Firestorm,ShuffleServerGrpcTest.sendDataWithoutRegisterTest,"  @Test
  public void sendDataWithoutRegisterTest() throws Exception {
    List<ShuffleBlockInfo> blockInfos = Lists.newArrayList(new ShuffleBlockInfo(0, 0, 0, 100, 0,
        new byte[]{}, Lists.newArrayList(), 0, 100, 0));
    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = Maps.newHashMap();
    partitionToBlocks.put(0, blockInfos);
    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);

    RssSendShuffleDataRequest rssdr = new RssSendShuffleDataRequest(
        ""sendDataWithoutRegisterTest"", 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    assertEquals(132, shuffleServers.get(0).getPreAllocatedMemory());
    Thread.sleep(10000);
    assertEquals(0, shuffleServers.get(0).getPreAllocatedMemory());
  }
",non-flaky,5
77007,Tencent_Firestorm,ShuffleServerGrpcTest.multipleShuffleResultTest,"  @Test
  public void multipleShuffleResultTest() throws Exception {
    Set<Long> expectedBlockIds = Sets.newConcurrentHashSet();
    RssRegisterShuffleRequest rrsr = new RssRegisterShuffleRequest(""multipleShuffleResultTest"", 100,
        Lists.newArrayList(new PartitionRange(0, 1)));
    shuffleServerClient.registerShuffle(rrsr);

    Runnable r1 = () -> {
      for (int i = 0; i < 100; i++) {
        Map<Integer, List<Long>> ptbs = Maps.newHashMap();
        List<Long> blockIds = Lists.newArrayList();
        Long blockId = ClientUtils.getBlockId(1, 0, i);
        expectedBlockIds.add(blockId);
        blockIds.add(blockId);
        ptbs.put(1, blockIds);
        RssReportShuffleResultRequest req1 =
            new RssReportShuffleResultRequest(""multipleShuffleResultTest"", 1, 0, ptbs, 1);
        shuffleServerClient.reportShuffleResult(req1);
      }
    };
    Runnable r2 = () -> {
      for (int i = 100; i < 200; i++) {
        Map<Integer, List<Long>> ptbs = Maps.newHashMap();
        List<Long> blockIds = Lists.newArrayList();
        Long blockId = ClientUtils.getBlockId(1, 1, i);
        expectedBlockIds.add(blockId);
        blockIds.add(blockId);
        ptbs.put(1, blockIds);
        RssReportShuffleResultRequest req1 =
            new RssReportShuffleResultRequest(""multipleShuffleResultTest"", 1, 1, ptbs, 1);
        shuffleServerClient.reportShuffleResult(req1);
      }
    };
    Runnable r3 = () -> {
      for (int i = 200; i < 300; i++) {
        Map<Integer, List<Long>> ptbs = Maps.newHashMap();
        List<Long> blockIds = Lists.newArrayList();
        Long blockId = ClientUtils.getBlockId(1, 2, i);
        expectedBlockIds.add(blockId);
        blockIds.add(blockId);
        ptbs.put(1, blockIds);
        RssReportShuffleResultRequest req1 =
            new RssReportShuffleResultRequest(""multipleShuffleResultTest"", 1, 2, ptbs, 1);
        shuffleServerClient.reportShuffleResult(req1);
      }
    };
    Thread t1 = new Thread(r1);
    Thread t2 = new Thread(r2);
    Thread t3 = new Thread(r3);
    t1.start();
    t2.start();
    t3.start();
    t1.join();
    t2.join();
    t3.join();

    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    for (Long blockId : expectedBlockIds) {
      blockIdBitmap.addLong(blockId);
    }

    RssGetShuffleResultRequest req = new RssGetShuffleResultRequest(
        ""multipleShuffleResultTest"", 1, 1);
    RssGetShuffleResultResponse result = shuffleServerClient.getShuffleResult(req);
    Roaring64NavigableMap actualBlockIdBitmap = result.getBlockIdBitmap();
    assertEquals(blockIdBitmap, actualBlockIdBitmap);
  }
",non-flaky,5
77008,Tencent_Firestorm,ShuffleServerGrpcTest.rpcMetricsTest,"  @Test
  public void rpcMetricsTest() {
    String appId = ""rpcMetricsTest"";
    int shuffleId = 0;
    double oldGrpcTotal = shuffleServers.get(0).getGrpcMetrics().getCounterGrpcTotal().get();
    double oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().
        get(ShuffleServerGrpcMetrics.REGISTER_SHUFFLE_METHOD).get();
    shuffleServerClient.registerShuffle(new RssRegisterShuffleRequest(appId, shuffleId,
        Lists.newArrayList(new PartitionRange(0, 1))));
    double newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap()
        .get(ShuffleServerGrpcMetrics.REGISTER_SHUFFLE_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.REGISTER_SHUFFLE_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.APP_HEARTBEAT_METHOD).get();
    shuffleServerClient.sendHeartBeat(new RssAppHeartBeatRequest(appId, 10000));
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.APP_HEARTBEAT_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.APP_HEARTBEAT_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.REQUIRE_BUFFER_METHOD).get();
    shuffleServerClient.requirePreAllocation(100, 10, 1000);
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.REQUIRE_BUFFER_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.REQUIRE_BUFFER_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.SEND_SHUFFLE_DATA_METHOD).get();
    List<ShuffleBlockInfo> blockInfos = Lists.newArrayList(new ShuffleBlockInfo(shuffleId, 0, 0, 100, 0,
        new byte[]{}, Lists.newArrayList(), 0, 100, 0));
    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = Maps.newHashMap();
    partitionToBlocks.put(0, blockInfos);
    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);
    RssSendShuffleDataRequest rssdr = new RssSendShuffleDataRequest(
        appId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.SEND_SHUFFLE_DATA_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.SEND_SHUFFLE_DATA_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.COMMIT_SHUFFLE_TASK_METHOD).get();
    shuffleServerClient.sendCommit(new RssSendCommitRequest(appId, shuffleId));
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.COMMIT_SHUFFLE_TASK_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.COMMIT_SHUFFLE_TASK_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.FINISH_SHUFFLE_METHOD).get();
    shuffleServerClient.finishShuffle(new RssFinishShuffleRequest(appId, shuffleId));
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.FINISH_SHUFFLE_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.FINISH_SHUFFLE_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.REPORT_SHUFFLE_RESULT_METHOD).get();
    Map<Integer, List<Long>> partitionToBlockIds = Maps.newHashMap();
    List<Long> blockIds1 = getBlockIdList(1, 3);
    List<Long> blockIds2 = getBlockIdList(2, 2);
    List<Long> blockIds3 = getBlockIdList(3, 1);
    partitionToBlockIds.put(1, blockIds1);
    partitionToBlockIds.put(2, blockIds2);
    partitionToBlockIds.put(3, blockIds3);
    RssReportShuffleResultRequest request =
        new RssReportShuffleResultRequest(appId, shuffleId, 0L, partitionToBlockIds, 1);
    shuffleServerClient.reportShuffleResult(request);
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.REPORT_SHUFFLE_RESULT_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.REPORT_SHUFFLE_RESULT_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_RESULT_METHOD).get();
    shuffleServerClient.getShuffleResult(new RssGetShuffleResultRequest(appId, shuffleId, 1));
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_RESULT_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.GET_SHUFFLE_RESULT_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_INDEX_METHOD).get();
    try {
      shuffleServerClient.getShuffleIndex(new RssGetShuffleIndexRequest(
          appId, shuffleId, 1, 1, 3));
    } catch (Exception e) {
      // ignore the exception, just test metrics value
    }
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_INDEX_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.GET_SHUFFLE_INDEX_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_DATA_METHOD).get();
    try {
      shuffleServerClient.getShuffleData(new RssGetShuffleDataRequest(
          appId, shuffleId, 0, 1, 3,
          0, 100));
    } catch (Exception e) {
      // ignore the exception, just test metrics value
    }
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_DATA_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.GET_SHUFFLE_DATA_METHOD).get(), 0.5);

    double newGrpcTotal = shuffleServers.get(0).getGrpcMetrics().getCounterGrpcTotal().get();
    // require buffer will be called one more time when send data
    assertEquals(oldGrpcTotal + 11, newGrpcTotal, 0.5);
    assertEquals(0, shuffleServers.get(0).getGrpcMetrics().getGaugeGrpcOpen().get(), 0.5);
  }
",non-flaky,5
77009,Tencent_Firestorm,MultiStorageTest.readUploadedDataTest,"  @Test
  public void readUploadedDataTest() {
    String appId = ""ap_read_uploaded_data"";
    RssRegisterShuffleRequest rr1 =  new RssRegisterShuffleRequest(appId, 0,
        Lists.newArrayList(new PartitionRange(0, 0)));
    RssRegisterShuffleRequest rr2 =  new RssRegisterShuffleRequest(appId, 0,
        Lists.newArrayList(new PartitionRange(1, 1)));
    RssRegisterShuffleRequest rr3 =  new RssRegisterShuffleRequest(appId, 0,
        Lists.newArrayList(new PartitionRange(2, 2)));
    RssRegisterShuffleRequest rr4 =  new RssRegisterShuffleRequest(appId, 0,
        Lists.newArrayList(new PartitionRange(4, 4)));
    shuffleServerClient.registerShuffle(rr1);
    shuffleServerClient.registerShuffle(rr2);
    shuffleServerClient.registerShuffle(rr3);
    shuffleServerClient.registerShuffle(rr4);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Set<Long> expectedBlock1 = Sets.newHashSet();
    Set<Long> expectedBlock2 = Sets.newHashSet();

    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap3 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap4 = Roaring64NavigableMap.bitmapOf();

    List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
        0, 0, 1,3, 25, blockIdBitmap1, expectedData);
    List<ShuffleBlockInfo> blocks2 = createShuffleBlockList(
        0, 1, 1,5,1024 * 1024, blockIdBitmap2, expectedData);
    List<ShuffleBlockInfo> blocks3 = createShuffleBlockList(
        0, 2, 2,4, 25, blockIdBitmap3, expectedData);
    List<ShuffleBlockInfo> blocks4 = createShuffleBlockList(
        0, 4, 3,1, 1024 * 1024, blockIdBitmap4, expectedData);


    blocks1.forEach(b -> expectedBlock1.add(b.getBlockId()));
    blocks2.forEach(b -> expectedBlock2.add(b.getBlockId()));

    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = Maps.newHashMap();
    partitionToBlocks.put(0, blocks1);
    partitionToBlocks.put(1, blocks2);
    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);
    RssSendShuffleDataRequest rs1 = new RssSendShuffleDataRequest(appId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rs1);

    RssSendCommitRequest rc1 = new RssSendCommitRequest(appId, 0);
    shuffleServerClient.sendCommit(rc1);
    RssFinishShuffleRequest rf1 = new RssFinishShuffleRequest(appId, 0);
    shuffleServerClient.finishShuffle(rf1);
    Map<Integer, List<Long>> partitionToBlockIds = Maps.newHashMap();
    partitionToBlockIds.put(0, new ArrayList<>(expectedBlock1));
    partitionToBlockIds.put(1, new ArrayList<>(expectedBlock2));
    RssReportShuffleResultRequest rrp1 = new RssReportShuffleResultRequest(
        appId, 0, 1L, partitionToBlockIds, 2);
    shuffleServerClient.reportShuffleResult(rrp1);

    DiskItem item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 0);
    assertTrue(item.canWrite());
    assertEquals(3 * 25, item.getNotUploadedSize(appId + ""/"" + 0));
    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 1);
    assertTrue(item.canWrite());
    assertEquals(5 * 1024 * 1024, item.getNotUploadedSize(appId + ""/"" + 0));

    sendSinglePartitionToShuffleServer(appId, 0,2, 2L, blocks3);
    sendSinglePartitionToShuffleServer(appId, 0, 4, 3L, blocks4);

    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 2);
    assertTrue(item.canWrite());
    assertEquals(3 * 25 + 4 * 25, item.getNotUploadedSize(appId + ""/"" + 0));

    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 4);
    assertTrue(item.canWrite());
    assertEquals(5 * 1024 * 1024 + 1024 * 1024, item.getNotUploadedSize(appId + ""/"" + 0));


    RssGetShuffleResultRequest rg1 = new RssGetShuffleResultRequest(appId, 0, 0);
    shuffleServerClient.getShuffleResult(rg1);
    RssGetShuffleResultRequest rg2 = new RssGetShuffleResultRequest(appId, 0, 1);
    shuffleServerClient.getShuffleResult(rg2);
    RssGetShuffleResultRequest rg3 = new RssGetShuffleResultRequest(appId, 0, 2);
    shuffleServerClient.getShuffleResult(rg3);
    RssGetShuffleResultRequest rg4 = new RssGetShuffleResultRequest(appId, 0, 4);
    shuffleServerClient.getShuffleResult(rg4);

    readShuffleData(shuffleServerClient, appId, 0, 0, 1, 10, 100, 0);
    readShuffleData(shuffleServerClient, appId, 0, 1, 1, 10, 100, 0);


    wait(appId);

    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 0);
    assertTrue(item.canWrite());
    assertEquals(0, item.getNotUploadedSize(appId + ""/"" + 0));

    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 1);
    assertTrue(item.canWrite());
    assertEquals(0, item.getNotUploadedSize(appId + ""/"" + 0));

    boolean isException = false;
    try {
      ShuffleDataResult result = readShuffleData(shuffleServerClient, appId, 0, 0,
          1, 10, 1000,  0);
    } catch (RuntimeException re) {
      isException = true;
      assertTrue(re.getMessage().contains(""Can't get shuffle index""));
    }
    assertTrue(isException);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(""LOCALFILE_AND_HDFS"",
        appId, 0, 0, 100, 1, 10, 1000, HDFS_URI + ""rss/multi_storage"",
        blockIdBitmap1, Roaring64NavigableMap.bitmapOf(1), Lists.newArrayList(), conf);
    validateResult(readClient, expectedData, blockIdBitmap1);

    readClient = new ShuffleReadClientImpl(""LOCALFILE_AND_HDFS"",
        appId, 0, 1, 100, 1, 10, 1000, HDFS_URI + ""rss/multi_storage"",
        blockIdBitmap2, Roaring64NavigableMap.bitmapOf(1), Lists.newArrayList(), conf);
    validateResult(readClient, expectedData, blockIdBitmap2);

    readClient = new ShuffleReadClientImpl(""LOCALFILE_AND_HDFS"",
        appId, 0, 2, 100, 1, 10, 1000, HDFS_URI + ""rss/multi_storage"",
        blockIdBitmap3, Roaring64NavigableMap.bitmapOf(2), Lists.newArrayList(), conf);
    validateResult(readClient, expectedData, blockIdBitmap3);

    readClient = new ShuffleReadClientImpl(""LOCALFILE_AND_HDFS"",
        appId, 0, 4, 100, 1, 10, 1000, HDFS_URI + ""rss/multi_storage"",
        blockIdBitmap4, Roaring64NavigableMap.bitmapOf(3), Lists.newArrayList(), conf);
    validateResult(readClient, expectedData, blockIdBitmap4);
  }
",non-flaky,5
77010,Tencent_Firestorm,MultiStorageTest.readLocalDataTest,"  @Test
  public void readLocalDataTest() {
    String appId = ""app_read_not_uploaded_data"";
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    RssRegisterShuffleRequest rr1 =  new RssRegisterShuffleRequest(appId, 1,
        Lists.newArrayList(new PartitionRange(0, 0)));
    RssRegisterShuffleRequest rr2 =  new RssRegisterShuffleRequest(appId, 1,
        Lists.newArrayList(new PartitionRange(1, 1)));
    RssRegisterShuffleRequest rr3 =  new RssRegisterShuffleRequest(appId, 1,
        Lists.newArrayList(new PartitionRange(2, 2)));
    RssRegisterShuffleRequest rr4 =  new RssRegisterShuffleRequest(appId, 1,
        Lists.newArrayList(new PartitionRange(3, 3)));
    shuffleServerClient.registerShuffle(rr1);
    shuffleServerClient.registerShuffle(rr2);
    shuffleServerClient.registerShuffle(rr3);
    shuffleServerClient.registerShuffle(rr4);

    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap3 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap4 = Roaring64NavigableMap.bitmapOf();

    List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
        1, 0, 1,3, 25, blockIdBitmap1, expectedData);
    List<ShuffleBlockInfo> blocks2 = createShuffleBlockList(
        1, 1, 2,5,1024 * 1024, blockIdBitmap2, expectedData);
    List<ShuffleBlockInfo> blocks3 = createShuffleBlockList(
        1, 2, 3,4, 25, blockIdBitmap3, expectedData);
    List<ShuffleBlockInfo> blocks4 = createShuffleBlockList(
        1, 3, 4,1, 1024 * 1024, blockIdBitmap4, expectedData);

    sendSinglePartitionToShuffleServer(appId, 1,0, 1L, blocks1);
    sendSinglePartitionToShuffleServer(appId, 1,1, 2L, blocks2);
    sendSinglePartitionToShuffleServer(appId, 1,2, 3L, blocks3);
    sendSinglePartitionToShuffleServer(appId, 1,3, 4L, blocks4);

    RssGetShuffleResultRequest rg1 = new RssGetShuffleResultRequest(appId, 1, 0);
    shuffleServerClient.getShuffleResult(rg1);
    RssGetShuffleResultRequest rg2 = new RssGetShuffleResultRequest(appId, 1, 1);
    shuffleServerClient.getShuffleResult(rg2);
    RssGetShuffleResultRequest rg3 = new RssGetShuffleResultRequest(appId, 1, 2);
    shuffleServerClient.getShuffleResult(rg3);
    RssGetShuffleResultRequest rg4 = new RssGetShuffleResultRequest(appId, 1, 3);
    shuffleServerClient.getShuffleResult(rg4);

    Uninterruptibles.sleepUninterruptibly(2, TimeUnit.SECONDS);
    validateResult(appId, 1, 0, expectedData, getExpectBlockIds(blocks1));
    Uninterruptibles.sleepUninterruptibly(2, TimeUnit.SECONDS);
    validateResult(appId, 1, 1, expectedData, getExpectBlockIds(blocks2));
    Uninterruptibles.sleepUninterruptibly(2, TimeUnit.SECONDS);
    validateResult(appId, 1, 2, expectedData, getExpectBlockIds(blocks3));
    Uninterruptibles.sleepUninterruptibly(2, TimeUnit.SECONDS);
    validateResult(appId, 1, 3, expectedData, getExpectBlockIds(blocks4));
    Uninterruptibles.sleepUninterruptibly(20, TimeUnit.SECONDS);
    boolean isException = false;
    try {
      readShuffleData(shuffleServerClient, appId, 1, 0,
          1, 10, 1000,  0);
    } catch (RuntimeException re) {
      isException = true;
      assertTrue(re.getMessage().contains(""Can't get shuffle index""));
    }
    assertTrue(isException);
  }
",non-flaky,5
77011,Tencent_Firestorm,MultiStorageTest.readMixedDataTest,"  @Test
  public void readMixedDataTest() {
    String appId = ""app_read_mix_data"";
    RssRegisterShuffleRequest rr1 =  new RssRegisterShuffleRequest(appId, 0,
        Lists.newArrayList(new PartitionRange(0, 0)));
    shuffleServerClient.registerShuffle(rr1);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Set<Long> expectedBlock1 = Sets.newHashSet();

    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();

    List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
        0, 0, 1,15, 1024 * 1024, blockIdBitmap1, expectedData);

    blocks1.forEach(b -> expectedBlock1.add(b.getBlockId()));

    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = Maps.newHashMap();
    partitionToBlocks.put(0, blocks1);
    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);
    RssSendShuffleDataRequest rs1 = new RssSendShuffleDataRequest(appId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rs1);

    RssSendCommitRequest rc1 = new RssSendCommitRequest(appId, 0);
    shuffleServerClient.sendCommit(rc1);
    RssFinishShuffleRequest rf1 = new RssFinishShuffleRequest(appId, 0);
    shuffleServerClient.finishShuffle(rf1);
    Map<Integer, List<Long>> partitionToBlockIds = Maps.newHashMap();
    partitionToBlockIds.put(0, new ArrayList<>(expectedBlock1));
    RssReportShuffleResultRequest rrp1 = new RssReportShuffleResultRequest(
        appId, 0, 1L, partitionToBlockIds, 1);
    shuffleServerClient.reportShuffleResult(rrp1);

    RssGetShuffleResultRequest rg1 = new RssGetShuffleResultRequest(appId, 0, 0);
    shuffleServerClient.getShuffleResult(rg1);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(""LOCALFILE_AND_HDFS"",
        appId, 0, 0, 100, 1, 10, 1000, HDFS_URI + ""rss/multi_storage"",
        blockIdBitmap1, Roaring64NavigableMap.bitmapOf(1), Lists.newArrayList(new ShuffleServerInfo(""test"", LOCALHOST, SHUFFLE_SERVER_PORT)), conf);

    CompressedShuffleBlock csb = readClient.readShuffleBlockData();
    Roaring64NavigableMap matched = Roaring64NavigableMap.bitmapOf();
    assertNotNull(csb);
    assertNotNull(csb.getByteBuffer());
    for (Map.Entry<Long, byte[]> entry : expectedData.entrySet()) {
      if (compareByte(entry.getValue(), csb.getByteBuffer())) {
        matched.addLong(entry.getKey());
      }
    }
    wait(appId);

    csb = readClient.readShuffleBlockData();
    while (csb != null && csb.getByteBuffer() != null) {
      for (Map.Entry<Long, byte[]> entry : expectedData.entrySet()) {
        if (compareByte(entry.getValue(), csb.getByteBuffer())) {
          matched.addLong(entry.getKey());
          break;
        }
      }
      csb = readClient.readShuffleBlockData();
    }
    assertTrue(blockIdBitmap1.equals(matched));

    boolean isException = false;
    try {
      readShuffleData(shuffleServerClient, appId, 0, 0,
          1, 10, 1000, 0);
    } catch (RuntimeException re) {
      isException = true;
      assertTrue(re.getMessage().contains(""Can't get shuffle index""));
    }
    assertTrue(isException);

    List<ShuffleBlockInfo> blocks5 = createShuffleBlockList(
        0, 0, 1,15, 1024 * 1024, blockIdBitmap1, expectedData);
    partitionToBlocks.clear();
    shuffleToBlocks.clear();
    partitionToBlocks.put(0, blocks5);
    shuffleToBlocks.put(0, partitionToBlocks);
    RssSendShuffleDataRequest rs5 = new RssSendShuffleDataRequest(appId, 3, 1000, shuffleToBlocks);
    DiskItem diskItem = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 0);
    String path = ShuffleStorageUtils.getFullShuffleDataFolder(diskItem.getBasePath(),
        ShuffleStorageUtils.getShuffleDataPath(appId, 0, 0, 0));
    File file = new File(path);
    assertFalse(file.exists());
    try {
      shuffleServerClient.sendShuffleData(rs5);
      shuffleServerClient.sendCommit(rc1);
      shuffleServerClient.finishShuffle(rf1);
      shuffleServerClient.reportShuffleResult(rrp1);
    } catch (Exception e) {
      fail();
    }
    assertFalse(file.exists());
  }
",non-flaky,5
77012,Tencent_Firestorm,MultiStorageTest.diskUsageTest,"  @Test
  public void diskUsageTest() {
    String appId = ""app_read_diskusage_data"";
    long originSize = shuffleServers.get(0).getShuffleBufferManager().getCapacity();
    Map<Long, byte[]> expectedData = Maps.newHashMap();

    RssRegisterShuffleRequest rr1 =  new RssRegisterShuffleRequest(appId, 2,
        Lists.newArrayList(new PartitionRange(0, 0)));
    shuffleServerClient.registerShuffle(rr1);

    RssRegisterShuffleRequest rr2 =  new RssRegisterShuffleRequest(appId, 3,
        Lists.newArrayList(new PartitionRange(1, 1)));
    shuffleServerClient.registerShuffle(rr2);

    RssRegisterShuffleRequest rr3 =  new RssRegisterShuffleRequest(appId, 2,
        Lists.newArrayList(new PartitionRange(1, 1)));
    shuffleServerClient.registerShuffle(rr3);

    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap3 = Roaring64NavigableMap.bitmapOf();

    List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
        2, 0, 1,30, 10 * 1024 * 1024, blockIdBitmap1, expectedData);

    List<ShuffleBlockInfo> blocks2 = createShuffleBlockList(
        3, 1, 2,9, 10 * 1024 * 1024, blockIdBitmap2, expectedData);

    List<ShuffleBlockInfo> blocks3 = createShuffleBlockList(
        2, 1, 2,9, 10 * 1024 * 1024, blockIdBitmap3, expectedData);

    DiskItem item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 2, 0);
    item.createMetadataIfNotExist(appId + ""/"" + 2);
    item.getLock(appId + ""/"" + 2).readLock().lock();
    sendSinglePartitionToShuffleServer(appId, 2, 0, 1, blocks1);
    assertFalse(item.canWrite());
    assertEquals(30 * 1024 * 1024 * 10, item.getNotUploadedSize(appId + ""/"" + 2));
    assertEquals(1, item.getNotUploadedPartitions(appId + ""/"" + 2).getCardinality());
    boolean isException = false;
    try {
      sendSinglePartitionToShuffleServer(appId, 2, 1, 2, blocks3);
    } catch (RuntimeException re) {
      isException = true;
      assertTrue(re.getMessage().contains(""Can't finish shuffle process""));
    }
    item.getLock(appId + ""/"" + 2).readLock().unlock();
    Uninterruptibles.sleepUninterruptibly(6, TimeUnit.SECONDS);
    assertEquals(originSize, shuffleServers.get(0).getShuffleBufferManager().getCapacity());
    assertTrue(isException);
    RssGetShuffleResultRequest rg1 = new RssGetShuffleResultRequest(appId, 2, 0);
    shuffleServerClient.getShuffleResult(rg1);
    validateResult(appId, 2, 0, expectedData, Sets.newHashSet());
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(""LOCALFILE_AND_HDFS"",
        appId, 2, 0, 100, 1, 10, 1000, HDFS_URI + ""rss/multi_storage"",
        blockIdBitmap1, Roaring64NavigableMap.bitmapOf(1), Lists.newArrayList(new ShuffleServerInfo(""test"", LOCALHOST, SHUFFLE_SERVER_PORT)), conf);
    validateResult(readClient, expectedData, blockIdBitmap1);
    try {
      sendSinglePartitionToShuffleServer(appId, 3, 1,2, blocks2);
    } catch (RuntimeException re) {
      fail();
    }
    RssGetShuffleResultRequest rg2 = new RssGetShuffleResultRequest(appId, 3, 1);
    shuffleServerClient.getShuffleResult(rg2);
    validateResult(appId, 3, 1, expectedData,
        getExpectBlockIds(blocks2));

    Uninterruptibles.sleepUninterruptibly(5, TimeUnit.SECONDS);
  }
",non-flaky,5
77013,Tencent_Firestorm,MultiStorageTest.removeMetaTest,"  @Test
  public void removeMetaTest() {
    String appId = ""app_read_diskusage_data_without_report"";
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    RssRegisterShuffleRequest rr1 =  new RssRegisterShuffleRequest(appId, 2,
        Lists.newArrayList(new PartitionRange(0, 0)));
    shuffleServerClient.registerShuffle(rr1);
    RssRegisterShuffleRequest rr2 =  new RssRegisterShuffleRequest(appId, 3,
        Lists.newArrayList(new PartitionRange(1, 1)));
    shuffleServerClient.registerShuffle(rr2);

    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();

    List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
        2, 0, 1,30, 10 * 1024 * 1024, blockIdBitmap1, expectedData);
    List<ShuffleBlockInfo> blocks2 = createShuffleBlockList(
        3, 1, 2,9, 10 * 1024 * 1024, blockIdBitmap2, expectedData);

    sendSinglePartitionToShuffleServerWithoutReport(appId, 2, 2, 2, blocks1);
    sendSinglePartitionToShuffleServerWithoutReport(appId, 3, 1,2, blocks2);
    shuffleServers.get(0).getShuffleTaskManager().removeResources(appId);
    DiskItem item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 2, 0);
    Uninterruptibles.sleepUninterruptibly(1500, TimeUnit.MILLISECONDS);
    Set<String> keys = item.getShuffleMetaSet();
    assertTrue(keys.isEmpty());
    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 3, 1);
    keys = item.getShuffleMetaSet();
    assertTrue(keys.isEmpty());

    appId = ""app_read_diskusage_data_with_report"";
    rr1 =  new RssRegisterShuffleRequest(appId, 0, Lists.newArrayList(new PartitionRange(0, 0)));
    shuffleServerClient.registerShuffle(rr1);
    blocks1 = createShuffleBlockList(
        0, 0, 1,30, 10 * 1024, blockIdBitmap1, expectedData);
    sendSinglePartitionToShuffleServer(appId, 0, 0, 2, blocks1);
    shuffleServers.get(0).getShuffleTaskManager().removeResources(appId);
    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 0);
    Uninterruptibles.sleepUninterruptibly(1500, TimeUnit.MILLISECONDS);
    keys = item.getShuffleMetaSet();
    assertTrue(keys.isEmpty());
  }
",non-flaky,5
77014,Tencent_Firestorm,AQESkewedJoinTest.resultCompareTest,"  @Test
  public void resultCompareTest() throws Exception {
    run();
  }
",non-flaky,5
77015,Tencent_Firestorm,AQERepartitionTest.resultCompareTest,"  @Test
  public void resultCompareTest() throws Exception {
    run();
  }
",non-flaky,5
77016,Tencent_Firestorm,ShuffleHdfsStorageUtilsTest.testUploadFile,"  @Test
  public void testUploadFile() {
    FileOutputStream fileOut = null;
    DataOutputStream dataOut = null;
    try {
      TemporaryFolder tmpDir = new TemporaryFolder();
      tmpDir.create();
      File file = tmpDir.newFile(""test"");
      fileOut = new FileOutputStream(file);
      dataOut = new DataOutputStream(fileOut);
      byte[] buf = new byte[2096];
      new Random().nextBytes(buf);
      dataOut.write(buf);
      dataOut.close();
      fileOut.close();
      String path = HDFS_URI + ""test"";
      HdfsFileWriter writer = new HdfsFileWriter(new Path(path), conf);
      long size = ShuffleStorageUtils.uploadFile(file, writer, 1024);
      assertEquals(2096, size);
      size = ShuffleStorageUtils.uploadFile(file, writer, 100);
      assertEquals(2096, size);
      writer.close();
      tmpDir.delete();
    } catch (Exception e) {
      e.printStackTrace();
      fail();
    }
  }
",non-flaky,5
77017,Tencent_Firestorm,ShuffleStorageUtilsTest.mergeSegmentsTest,"  @Test
  public void mergeSegmentsTest() {
    List<FileBasedShuffleSegment> segments = Lists.newArrayList(
        new FileBasedShuffleSegment(1, 0, 40, 0, 0, 0));
    List<DataFileSegment> fileSegments = ShuffleStorageUtils.mergeSegments(""path"", segments, 100);
    assertEquals(1, fileSegments.size());
    for (DataFileSegment seg : fileSegments) {
      assertEquals(0, seg.getOffset());
      assertEquals(40, seg.getLength());
      assertEquals(""path"", seg.getPath());
      List<BufferSegment> bufferSegments = seg.getBufferSegments();
      assertEquals(1, bufferSegments.size());
      assertEquals(new BufferSegment(1, 0, 40, 0, 0, 0), bufferSegments.get(0));
    }

    segments = Lists.newArrayList(
        new FileBasedShuffleSegment(1, 0, 40, 0, 0, 0),
        new FileBasedShuffleSegment(2, 40, 40, 0, 0, 0),
        new FileBasedShuffleSegment(3, 80, 20, 0, 0, 0));
    fileSegments = ShuffleStorageUtils.mergeSegments(""path"", segments, 100);
    assertEquals(1, fileSegments.size());
    for (DataFileSegment seg : fileSegments) {
      assertEquals(0, seg.getOffset());
      assertEquals(100, seg.getLength());
      assertEquals(""path"", seg.getPath());
      List<BufferSegment> bufferSegments = seg.getBufferSegments();
      assertEquals(3, bufferSegments.size());
      Set<Long> testedBlockIds = Sets.newHashSet();
      for (BufferSegment segment : bufferSegments) {
        if (segment.getBlockId() == 1) {
          assertTrue(segment.equals(new BufferSegment(1, 0, 40, 0, 0, 0)));
          testedBlockIds.add(1L);
        } else if (segment.getBlockId() == 2) {
          assertTrue(segment.equals(new BufferSegment(2, 40, 40, 0, 0, 0)));
          testedBlockIds.add(2L);
        } else if (segment.getBlockId() == 3) {
          assertTrue(segment.equals(new BufferSegment(3, 80, 20, 0, 0, 0)));
          testedBlockIds.add(3L);
        }
      }
      assertEquals(3, testedBlockIds.size());
    }

    segments = Lists.newArrayList(
        new FileBasedShuffleSegment(1, 0, 40, 0, 0, 0),
        new FileBasedShuffleSegment(2, 40, 40, 0, 0, 0),
        new FileBasedShuffleSegment(3, 80, 20, 0, 0, 0),
        new FileBasedShuffleSegment(4, 100, 20, 0, 0, 0));
    fileSegments = ShuffleStorageUtils.mergeSegments(""path"", segments, 100);
    assertEquals(2, fileSegments.size());
    boolean tested = false;
    for (DataFileSegment seg : fileSegments) {
      if (seg.getOffset() == 100) {
        tested = true;
        assertEquals(20, seg.getLength());
        assertEquals(""path"", seg.getPath());
        List<BufferSegment> bufferSegments = seg.getBufferSegments();
        assertEquals(1, bufferSegments.size());
        assertTrue(bufferSegments.get(0).equals(new BufferSegment(4, 0, 20, 0, 0, 0)));
      }
    }
    assertTrue(tested);

    segments = Lists.newArrayList(
        new FileBasedShuffleSegment(1, 0, 40, 0, 0, 0),
        new FileBasedShuffleSegment(2, 40, 40, 0, 0, 0),
        new FileBasedShuffleSegment(3, 80, 20, 0, 0, 0),
        new FileBasedShuffleSegment(4, 100, 20, 0, 0, 0),
        new FileBasedShuffleSegment(5, 120, 100, 0, 0, 0));
    fileSegments = ShuffleStorageUtils.mergeSegments(""path"", segments, 100);
    assertEquals(2, fileSegments.size());
    tested = false;
    for (DataFileSegment seg : fileSegments) {
      if (seg.getOffset() == 100) {
        tested = true;
        assertEquals(120, seg.getLength());
        assertEquals(""path"", seg.getPath());
        List<BufferSegment> bufferSegments = seg.getBufferSegments();
        assertEquals(2, bufferSegments.size());
        Set<Long> testedBlockIds = Sets.newHashSet();
        for (BufferSegment segment : bufferSegments) {
          if (segment.getBlockId() == 4) {
            assertTrue(segment.equals(new BufferSegment(4, 0, 20, 0, 0, 0)));
            testedBlockIds.add(4L);
          } else if (segment.getBlockId() == 5) {
            assertTrue(segment.equals(new BufferSegment(5, 20, 100, 0, 0, 0)));
            testedBlockIds.add(5L);
          }
        }
        assertEquals(2, testedBlockIds.size());
      }
    }
    assertTrue(tested);

    segments = Lists.newArrayList(
        new FileBasedShuffleSegment(1, 10, 40, 0, 0, 0),
        new FileBasedShuffleSegment(2, 80, 20, 0, 0, 0),
        new FileBasedShuffleSegment(3, 500, 120, 0, 0, 0),
        new FileBasedShuffleSegment(4, 700, 20, 0, 0, 0));
    fileSegments = ShuffleStorageUtils.mergeSegments(""path"", segments, 100);
    assertEquals(3, fileSegments.size());
    Set<Long> expectedOffset = Sets.newHashSet(10L, 500L, 700L);
    for (DataFileSegment seg : fileSegments) {
      if (seg.getOffset() == 10) {
        validResult(seg, 90, 1, 40, 2, 70);
        expectedOffset.remove(10L);
      }
      if (seg.getOffset() == 500) {
        assertEquals(120, seg.getLength());
        List<BufferSegment> bufferSegments = seg.getBufferSegments();
        assertEquals(1, bufferSegments.size());
        assertTrue(bufferSegments.get(0).equals(new BufferSegment(3, 0, 120, 0, 0, 0)));
        expectedOffset.remove(500L);
      }
      if (seg.getOffset() == 700) {
        assertEquals(20, seg.getLength());
        List<BufferSegment> bufferSegments = seg.getBufferSegments();
        assertEquals(1, bufferSegments.size());
        assertTrue(bufferSegments.get(0).equals(new BufferSegment(4, 0, 20, 0, 0, 0)));
        expectedOffset.remove(700L);
      }
    }
    assertTrue(expectedOffset.isEmpty());

    segments = Lists.newArrayList(
        new FileBasedShuffleSegment(5, 500, 120, 0, 0, 0),
        new FileBasedShuffleSegment(3, 630, 10, 0, 0, 0),
        new FileBasedShuffleSegment(2, 80, 20, 0, 0, 0),
        new FileBasedShuffleSegment(1, 10, 40, 0, 0, 0),
        new FileBasedShuffleSegment(6, 769, 20, 0, 0, 0),
        new FileBasedShuffleSegment(4, 700, 20, 0, 0, 0));
    fileSegments = ShuffleStorageUtils.mergeSegments(""path"", segments, 100);
    assertEquals(4, fileSegments.size());
    expectedOffset = Sets.newHashSet(10L, 500L, 630L, 700L);
    for (DataFileSegment seg : fileSegments) {
      if (seg.getOffset() == 10) {
        validResult(seg, 90, 1, 40, 2, 70);
        expectedOffset.remove(10L);
      }
      if (seg.getOffset() == 500) {
        assertEquals(120, seg.getLength());
        List<BufferSegment> bufferSegments = seg.getBufferSegments();
        assertEquals(1, bufferSegments.size());
        assertTrue(bufferSegments.get(0).equals(new BufferSegment(5, 0, 120, 0, 0, 0)));
        expectedOffset.remove(500L);
      }
      if (seg.getOffset() == 630) {
        assertEquals(10, seg.getLength());
        List<BufferSegment> bufferSegments = seg.getBufferSegments();
        assertEquals(1, bufferSegments.size());
        assertTrue(bufferSegments.get(0).equals(new BufferSegment(3, 0, 10, 0, 0, 0)));
        expectedOffset.remove(630L);
      }
      if (seg.getOffset() == 700) {
        validResult(seg, 89, 4, 20, 6, 69);
        expectedOffset.remove(700L);
      }
    }
    assertTrue(expectedOffset.isEmpty());
  }
",non-flaky,5
77018,Tencent_Firestorm,ShuffleStorageUtilsTest.getShuffleDataPathWithRangeTest,"  @Test
  public void getShuffleDataPathWithRangeTest() {
    String result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 1, 3, 6);
    assertEquals(""appId/0/0-2"", result);
    result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 2, 3, 6);
    assertEquals(""appId/0/0-2"", result);
    result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 3, 3, 6);
    assertEquals(""appId/0/3-5"", result);
    result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 5, 3, 6);
    assertEquals(""appId/0/3-5"", result);
    try {
      ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 6, 3, 6);
      fail(""shouldn't be here"");
    } catch (Exception e) {
      assertTrue(e.getMessage().startsWith(""Can't generate ShuffleData Path""));
    }
    result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 6, 3, 7);
    assertEquals(""appId/0/6-8"", result);
  }
",non-flaky,5
77019,Tencent_Firestorm,ShuffleStorageUtilsTest.getStorageIndexTest,"  @Test
  public void getStorageIndexTest() {
    int index = ShuffleStorageUtils.getStorageIndex(3, ""abcde"", 3, 1);
    assertEquals(2, index);
    index = ShuffleStorageUtils.getStorageIndex(3, ""abcde"", 3, 4);
    assertEquals(1, index);
  }
",non-flaky,5
77484,dropwizard_dropwizard,TaskServletTest.execute,"    @Test
            public void execute(Map<String, List<String>> parameters, PrintWriter output) {
                output.println(""Vacuum cleaning"");
            }
",non-flaky,5
77485,dropwizard_dropwizard,TaskServletTest.execute,"    @Test
            public void execute(Map<String, List<String>> parameters, PrintWriter output) throws Exception {
                output.println(""Vacuum cleaning"");
            }
",non-flaky,5
77486,dropwizard_dropwizard,TaskServletTest.execute,"    @Test
            public void execute(Map<String, List<String>> parameters, PrintWriter output) {
                throw new RuntimeException(""The engine has died"");
            }
",non-flaky,5
77487,dropwizard_dropwizard,TaskServletTest.isFinished,"    @Test
        public boolean isFinished() {
            return false;
        }
",non-flaky,5
77488,dropwizard_dropwizard,FileAppenderFactoryTest.buildAppender,"    @Test
            public FileAppender<ILoggingEvent> buildAppender(LoggerContext context) {
                return super.buildAppender(context);
            }
",non-flaky,5
77489,dropwizard_dropwizard,SubstitutingSourceProviderTest.open,"    @Test
        public InputStream open(String s) throws IOException {
            // used to test that the stream is properly closed
            lastStream = new BufferedInputStream(new ByteArrayInputStream(s.getBytes(StandardCharsets.UTF_8)));
            return lastStream;
        }
",non-flaky,5
77490,dropwizard_dropwizard,ConfigurationMetadataTest.shouldDiscoverAllFields,"    @ParameterizedTest
    public void shouldDiscoverAllFields(String name, boolean isPrimitive,
                                        boolean isCollectionOrArrayType,
",non-flaky,5
77491,dropwizard_dropwizard,ConfigurationMetadataTest.isCollectionOfStringsShouldWork,"    @ParameterizedTest
    public void isCollectionOfStringsShouldWork(String name, boolean isCollectionOfStrings) {
        final ConfigurationMetadata metadata = new ConfigurationMetadata(
                Jackson.newObjectMapper(), ExampleConfiguration.class);

        assertThat(metadata.isCollectionOfStrings(name)).isEqualTo(isCollectionOfStrings);
    }
",non-flaky,5
77492,dropwizard_dropwizard,Issue3796Test.deserialize,"    @Test
        public CustomProperty deserialize(JsonParser parser, DeserializationContext context) throws IOException {
            assertThat(parser.getCodec()).isNotNull();

            TreeNode treeNode = parser.readValueAsTree();
            final TextNode custom = (TextNode) treeNode.path(""custom"");
            return new CustomProperty(custom.asText());
        }
",non-flaky,5
77493,dropwizard_dropwizard,JsonConfigurationFactoryTest.throwsAnExceptionOnMalformedFiles,"    @BeforeEach
    public void throwsAnExceptionOnMalformedFiles() {
        assertThatThrownBy(super::throwsAnExceptionOnMalformedFiles)
                .hasMessageContaining(""* Malformed JSON at line:"");
    }
",non-flaky,5
77494,dropwizard_dropwizard,SelfValidatingValidatorTest.validateCorrect,"    @Test
        public void validateCorrect(ViolationCollector col) {
        }
",non-flaky,5
77495,dropwizard_dropwizard,SelfValidationTest.clearAllLoggers,"    @BeforeEach
    public void clearAllLoggers() {
        //this must be a clear all because the validation runs in other threads
        TestLoggerFactory.clearAll();
    }
",non-flaky,5
77496,dropwizard_dropwizard,AuthBaseTest.setUp,"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();
    }
",non-flaky,5
77497,dropwizard_dropwizard,AuthBaseTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();
    }
",non-flaky,5
77498,dropwizard_dropwizard,PolymorphicPrincipalEntityTest.setUp,"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();
    }
",non-flaky,5
77499,dropwizard_dropwizard,PolymorphicPrincipalEntityTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();
    }
",non-flaky,5
77500,dropwizard_dropwizard,NoAuthPrincipalEntityTest.setUp,"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();
    }
",non-flaky,5
77501,dropwizard_dropwizard,NoAuthPrincipalEntityTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();
    }
",non-flaky,5
77502,dropwizard_dropwizard,NoAuthPolymorphicPrincipalEntityTest.setUp,"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();
    }
",non-flaky,5
77503,dropwizard_dropwizard,NoAuthPolymorphicPrincipalEntityTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();
    }
",non-flaky,5
77504,dropwizard_dropwizard,OptionalAuthFilterOrderingTest.setUp,"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();
    }
",non-flaky,5
77505,dropwizard_dropwizard,OptionalAuthFilterOrderingTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();
    }
",non-flaky,5
77506,dropwizard_dropwizard,OptionalAuthFilterOrderingTest.getUserPrincipal,"    @Test
        public void filter(ContainerRequestContext requestContext) throws IOException {
            requestContext.setSecurityContext(new SecurityContext() {
                @Override
                public Principal getUserPrincipal() {
                    return new NullPrincipal();
                }
",non-flaky,5
77507,dropwizard_dropwizard,AuthFilterTest.filter,"    @Test
        public void filter(ContainerRequestContext requestContext) throws IOException {
            authenticate(requestContext, ""some-password"", ""SOME_SCHEME"");
        }
",non-flaky,5
77508,dropwizard_dropwizard,BasicCredentialsTest.hasAWorkingEqualsMethod,"    @Test
    public void hasAWorkingEqualsMethod() {
        assertThat(credentials)
            .isEqualTo(credentials)
            .isEqualTo(new BasicCredentials(""u"", ""p""))
            .isNotEqualTo(null)
            .isNotEqualTo(""string"")
            .isNotEqualTo(new BasicCredentials(""u1"", ""p""))
            .isNotEqualTo(new BasicCredentials(""u"", ""p1""));
    }
",non-flaky,5
77509,dropwizard_dropwizard,DropwizardAppRuleWithoutConfigTest.runWithoutConfigFile,"    @Test
    public void runWithoutConfigFile() {
        Map<String, String> response = RULE.client().target(""http://localhost:"" + RULE.getLocalPort() + ""/test"")
            .request()
            .get(new GenericType<Map<String, String>>() {
            });
        assertThat(response).containsOnly(entry(""color"", ""orange""));
    }
",non-flaky,5
77510,dropwizard_dropwizard,DropwizardAppRuleWithExplicitTest.runWithExplicitConfig,"    @Test
    public void runWithExplicitConfig() {
        Map<String, String> response = RULE.client().target(""http://localhost:"" + RULE.getLocalPort() + ""/test"")
            .request()
            .get(new GenericType<Map<String, String>>() {
            });
        assertThat(response).containsOnly(entry(""message"", ""stuff!""));
    }
",non-flaky,5
77511,dropwizard_dropwizard,DAOTestRuleWithoutLoggingBootstrapTest.ruleCreatedSessionFactory,"    @Test
    public void ruleCreatedSessionFactory() {
        final SessionFactory sessionFactory = daoTestRule.getSessionFactory();

        assertThat(sessionFactory).isNotNull();
    }
",non-flaky,5
77512,dropwizard_dropwizard,DropwizardAppRuleResetConfigOverrideTest.test2,"    @Test
    public void test2() throws Exception {
        dropwizardAppRule.before();
        assertThat(System.getProperty(""app-rule-reset.message"")).isEqualTo(""A new way to say Hooray!"");
        assertThat(System.getProperty(""app-rule-reset.extra"")).isNull();
        dropwizardAppRule.after();

        System.setProperty(""app-rule-reset.extra"", ""Some extra system property"");
        dropwizardAppRule.before();
        assertThat(System.getProperty(""app-rule-reset.message"")).isEqualTo(""A new way to say Hooray!"");
        assertThat(System.getProperty(""app-rule-reset.extra"")).isEqualTo(""Some extra system property"");
        dropwizardAppRule.after();

        assertThat(System.getProperty(""app-rule-reset.message"")).isNull();
        assertThat(System.getProperty(""app-rule-reset.extra"")).isEqualTo(""Some extra system property"");
        System.clearProperty(""app-rule-reset.extra"");
    }
",non-flaky,5
77513,dropwizard_dropwizard,DAOTestRuleTest.ruleCreatedSessionFactory,"    @Test
    public void ruleCreatedSessionFactory() {
        final SessionFactory sessionFactory = daoTestRule.getSessionFactory();

        assertThat(sessionFactory).isNotNull();
    }
",non-flaky,5
77514,dropwizard_dropwizard,DAOTestRuleTest.ruleCanOpenTransaction,"    @Test
    public void ruleCanOpenTransaction() {
        final Long id = daoTestRule.inTransaction(() -> persist(new TestEntity(""description"")).getId());

        assertThat(id).isNotNull();
    }
",non-flaky,5
77515,dropwizard_dropwizard,DAOTestRuleTest.ruleCanRoundtrip,"    @Test
    public void ruleCanRoundtrip() {
        final Long id = daoTestRule.inTransaction(() -> persist(new TestEntity(""description"")).getId());

        final TestEntity testEntity = get(id);

        assertThat(testEntity).isNotNull();
        assertThat(testEntity.getDescription()).isEqualTo(""description"");
    }
",non-flaky,5
77516,dropwizard_dropwizard,DAOTestRuleTest.transactionThrowsExceptionAsExpected,"    @Test
    public void transactionThrowsExceptionAsExpected() {
        assertThatExceptionOfType(ConstraintViolationException.class).isThrownBy(()->
            daoTestRule.inTransaction(() -> persist(new TestEntity(null))));
    }
",non-flaky,5
77517,dropwizard_dropwizard,DAOTestRuleTest.rollsBackTransaction,"    @Test
    public void rollsBackTransaction() {
        // given a successfully persisted entity
        final TestEntity testEntity = new TestEntity(""description"");
        daoTestRule.inTransaction(() -> persist(testEntity));

        // when we prepare an update of that entity
        testEntity.setDescription(""newDescription"");
        // ... but cause a constraint violation during the actual update
        assertThatExceptionOfType(ConstraintViolationException.class)
            .isThrownBy(() -> daoTestRule.inTransaction(() -> {
                persist(testEntity);
                persist(new TestEntity(null));
            }));
        // ... the entity has the original value
        assertThat(get(testEntity.getId()).getDescription()).isEqualTo(""description"");
    }
",non-flaky,5
77518,dropwizard_dropwizard,DropwizardAppRuleTest.canGetExpectedResourceOverHttp,"    @Test
    public void canGetExpectedResourceOverHttp() {
        final String content = ClientBuilder.newClient().target(
            ""http://localhost:"" + RULE.getLocalPort() + ""/test"").request().get(String.class);

        assertThat(content).isEqualTo(""Yes, it's here"");
    }
",non-flaky,5
77519,dropwizard_dropwizard,DropwizardAppRuleTest.returnsConfiguration,"    @Test
    public void returnsConfiguration() {
        final TestConfiguration config = RULE.getConfiguration();
        assertThat(config.getMessage()).isEqualTo(""Yes, it's here"");
    }
",non-flaky,5
77520,dropwizard_dropwizard,DropwizardAppRuleTest.returnsApplication,"    @Test
    public void returnsApplication() {
        final DropwizardTestApplication application = RULE.getApplication();
        assertThat(application).isNotNull();
    }
",non-flaky,5
77521,dropwizard_dropwizard,DropwizardAppRuleTest.returnsEnvironment,"    @Test
    public void returnsEnvironment() {
        final Environment environment = RULE.getEnvironment();
        assertThat(environment.getName()).isEqualTo(""DropwizardTestApplication"");
    }
",non-flaky,5
77522,dropwizard_dropwizard,DropwizardAppRuleTest.canPerformAdminTask,"    @Test
    public void canPerformAdminTask() {
        final String response
            = RULE.client().target(""http://localhost:""
            + RULE.getAdminPort() + ""/tasks/hello?name=test_user"")
            .request()
            .post(Entity.entity("""", MediaType.TEXT_PLAIN), String.class);

        assertThat(response).isEqualTo(""Hello has been said to test_user"");
    }
",non-flaky,5
77523,dropwizard_dropwizard,DropwizardAppRuleTest.canPerformAdminTaskWithPostBody,"    @Test
    public void canPerformAdminTaskWithPostBody() {
        final String response
            = RULE.client().target(""http://localhost:""
            + RULE.getAdminPort() + ""/tasks/echo"")
            .request()
            .post(Entity.entity(""Custom message"", MediaType.TEXT_PLAIN), String.class);

        assertThat(response).isEqualTo(""Custom message"");
    }
",non-flaky,5
77524,dropwizard_dropwizard,DropwizardAppRuleTest.clientUsesJacksonMapperFromEnvironment,"    @Test
    public void clientUsesJacksonMapperFromEnvironment() {
        assertThat(RULE.client().target(""http://localhost:"" + RULE.getLocalPort() + ""/message"")
            .request()
            .get(DropwizardTestApplication.MessageView.class).getMessage())
            .contains(""Yes, it's here"");
    }
",non-flaky,5
77525,dropwizard_dropwizard,DropwizardAppRuleTest.clientSupportsPatchMethod,"    @Test
    public void clientSupportsPatchMethod() {
        assertThat(RULE.client().target(""http://localhost:"" + RULE.getLocalPort() + ""/echoPatch"")
            .request()
            .method(""PATCH"", Entity.text(""Patch is working""), String.class))
            .contains(""Patch is working"");
    }
",non-flaky,5
77526,dropwizard_dropwizard,DAOTestRuleConfigTest.explicitConfigCreatesSessionFactory,"    @Test
    public void explicitConfigCreatesSessionFactory() {
        // it yields a valid SessionFactory instance
        final SessionFactory sessionFactory = database.getSessionFactory();
        assertThat(sessionFactory).isNotNull();
        assertThat(sessionFactory.getProperties())
                .containsEntry(AvailableSettings.FORMAT_SQL, ""true"")
                .containsEntry(""foobar"", ""baz"");

        final Session currentSession = sessionFactory.getCurrentSession();

        // an instance of an entity contained in the package can be saved
        currentSession.saveOrUpdate(new TestEntity(""foo""));
    }
",non-flaky,5
77527,dropwizard_dropwizard,DropwizardClientRuleTest.shouldGetStringBodyFromDropWizard,"    @Test
    public void shouldGetStringBodyFromDropWizard() throws IOException {
        final URL url = new URL(RULE_WITH_INSTANCE.baseUri() + ""/test"");
        assertThat(""foo"").isEqualTo(Resources.toString(url, StandardCharsets.UTF_8));
    }
",non-flaky,5
77528,dropwizard_dropwizard,DropwizardClientRuleTest.shouldGetDefaultStringBodyFromDropWizard,"    @Test
    public void shouldGetDefaultStringBodyFromDropWizard() throws IOException {
        final URL url = new URL(RULE_WITH_CLASS.baseUri() + ""/test"");
        assertThat(Resources.toString(url, StandardCharsets.UTF_8)).isEqualTo(TestResource.DEFAULT_MESSAGE);
    }
",non-flaky,5
77529,dropwizard_dropwizard,DropwizardAppRuleConfigOverrideTest.supportsConfigAttributeOverrides,"    @Test
    public void supportsConfigAttributeOverrides() {
        final String content = RULE.client().target(""http://localhost:"" + RULE.getLocalPort() + ""/test"")
            .request().get(String.class);

        assertThat(content).isEqualTo(""A new way to say Hooray!"");
    }
",non-flaky,5
77530,dropwizard_dropwizard,DropwizardAppRuleConfigOverrideTest.supportsSuppliedConfigAttributeOverrides,"    @Test
    public void supportsSuppliedConfigAttributeOverrides() throws Exception {
        assertThat(System.getProperty(""app-rule.extra"")).isEqualTo(""supplied"");
        assertThat(System.getProperty(""dw.extra"")).isEqualTo(""supplied again"");
    }
",non-flaky,5
77531,dropwizard_dropwizard,DropwizardAppRuleReentrantTest.testReentrantRuleStartsApplicationOnlyOnce,"    @Test
    public void testReentrantRuleStartsApplicationOnlyOnce() throws Throwable {
        @SuppressWarnings(""deprecation"")
        DropwizardAppRule<TestConfiguration> dropwizardAppRule = new DropwizardAppRule<>(testSupport);

        RuleChain.outerRule(dropwizardAppRule)
            .around(dropwizardAppRule) // recursive
            .apply(statement, description)
            .evaluate();

        InOrder inOrder = inOrder(testSupport, statement, description);
        inOrder.verify(testSupport, times(1)).before();
        inOrder.verify(statement).evaluate();
        inOrder.verify(testSupport, times(1)).after();
        inOrder.verifyNoMoreInteractions();
    }
",non-flaky,5
77532,dropwizard_dropwizard,DropwizardTestSupportTest.initialize,"    @Test
        public void initialize(Bootstrap<TestConfiguration> bootstrap) {
            bootstrap.setConfigurationFactoryFactory(FailingConfigurationFactory::new);
        }
",non-flaky,5
77533,dropwizard_dropwizard,ResourceTestRuleWithoutLoggingBootstrapTest.testResource,"    @Test
    public void testResource() {
        assertThat(resourceTestRule.target(""test"").request()
                .get(String.class))
                .isEqualTo(""Default message"");
    }
",non-flaky,5
77534,dropwizard_dropwizard,ResourceTestRuleWithGrizzlyTest.testResource,"    @Test
    public void testResource() {
        assertThat(resourceTestRule.target(""test"").request()
                .get(String.class))
                .isEqualTo(""test"");
    }
",non-flaky,5
77535,dropwizard_dropwizard,ResourceTestRuleWithGrizzlyTest.testExceptionMapper,"    @Test
    public void testExceptionMapper() {
        final Response resp = resourceTestRule.target(""test"").request()
                .post(Entity.json(""""));
        assertThat(resp.getStatus()).isEqualTo(500);
        assertThat(resp.readEntity(String.class)).isEqualTo(""Can't touch this"");
    }
",non-flaky,5
77536,dropwizard_dropwizard,ResourceTestRuleWithGrizzlyTest.testClientSupportsPatchMethod,"    @Test
    public void testClientSupportsPatchMethod() {
        final String resp = resourceTestRule.target(""test"")
            .request()
            .method(""PATCH"", Entity.text(""Patch is working""), String.class);
        assertThat(resp).isEqualTo(""Patch is working"");
    }
",non-flaky,5
77537,dropwizard_dropwizard,PersonResourceExceptionMapperTest.testDefaultConstraintViolation,"    @Test
    public void testDefaultConstraintViolation() {
        assertThat(RESOURCES.target(""/person/blah/index"")
            .queryParam(""ind"", -1).request()
            .get().readEntity(String.class))
            .isEqualTo(""Invalid data"");
    }
",non-flaky,5
77538,dropwizard_dropwizard,PersonResourceExceptionMapperTest.testDefaultJsonProcessingMapper,"    @Test
    public void testDefaultJsonProcessingMapper() {
        assertThat(RESOURCES.target(""/person/blah/runtime-exception"")
            .request()
            .post(Entity.json(""{ \""he: \""ho\""}""))
            .readEntity(String.class))
            .startsWith(""Something went wrong: Unexpected character"");
    }
",non-flaky,5
77539,dropwizard_dropwizard,PersonResourceExceptionMapperTest.testDefaultExceptionMapper,"    @Test
    public void testDefaultExceptionMapper() {
        assertThat(RESOURCES.target(""/person/blah/runtime-exception"")
            .request()
            .post(Entity.json(""{}""))
            .readEntity(String.class))
            .isEqualTo(""Something went wrong: I'm an exception!"");
    }
",non-flaky,5
77540,dropwizard_dropwizard,PersonResourceExceptionMapperTest.testDefaultEofExceptionMapper,"    @Test
    public void testDefaultEofExceptionMapper() {
        assertThat(RESOURCES.target(""/person/blah/eof-exception"")
            .request()
            .get().readEntity(String.class))
            .isEqualTo(""Something went wrong: I'm an eof exception!"");
    }
",non-flaky,5
77541,dropwizard_dropwizard,ResourceTestRuleTest.testGetPerson,"    @Test
    public void testGetPerson() {
        assertThat(resourceTestRule.target(""/person/blah"").request()
                .get(Person.class))
                .isEqualTo(person);
        verify(peopleStore).fetchPerson(""blah"");
    }
",non-flaky,5
77542,dropwizard_dropwizard,ResourceTestRuleTest.testGetImmutableListOfPersons,"    @Test
    public void testGetImmutableListOfPersons() {
        assertThat(resourceTestRule.target(""/person/blah/list"").request()
                .get(new GenericType<List<Person>>() {
                })).isEqualTo(Collections.singletonList(person));
    }
",non-flaky,5
77543,dropwizard_dropwizard,ResourceTestRuleTest.testGetPersonWithQueryParam,"    @Test
    public void testGetPersonWithQueryParam() {
        // Test to ensure that the dropwizard validator is registered so that
        // it can validate the ""ind"" IntParam.
        assertThat(resourceTestRule.target(""/person/blah/index"")
                .queryParam(""ind"", 0).request()
                .get(Person.class))
                .isEqualTo(person);
        verify(peopleStore).fetchPerson(""blah"");
    }
",non-flaky,5
77544,dropwizard_dropwizard,ResourceTestRuleTest.testDefaultConstraintViolation,"    @Test
    public void testDefaultConstraintViolation() {
        assertThat(resourceTestRule.target(""/person/blah/index"")
                .queryParam(""ind"", -1).request()
                .get().readEntity(String.class))
                .isEqualTo(""{\""errors\"":[\""query param ind must be greater than or equal to 0\""]}"");
    }
",non-flaky,5
77545,dropwizard_dropwizard,ResourceTestRuleTest.testDefaultJsonProcessingMapper,"    @Test
    public void testDefaultJsonProcessingMapper() {
        assertThat(resourceTestRule.target(""/person/blah/runtime-exception"")
                .request()
                .post(Entity.json(""{ \""he: \""ho\""}""))
                .readEntity(String.class))
                .isEqualTo(""{\""code\"":400,\""message\"":\""Unable to process JSON\""}"");
    }
",non-flaky,5
77546,dropwizard_dropwizard,ResourceTestRuleTest.testDefaultEofExceptionMapper,"    @Test
    public void testDefaultEofExceptionMapper() {
        assertThat(resourceTestRule.target(""/person/blah/eof-exception"")
                .request()
                .get().getStatus())
                .isEqualTo(Response.Status.BAD_REQUEST.getStatusCode());
    }
",non-flaky,5
77547,dropwizard_dropwizard,ResourceTestRuleTest.testValidationGroupsException,"    @Test
    public void testValidationGroupsException() {
        final Response resp = resourceTestRule.target(""/person/blah/validation-groups-exception"")
                .request()
                .post(Entity.json(""{}""));
        assertThat(resp.getStatus()).isEqualTo(Response.Status.INTERNAL_SERVER_ERROR.getStatusCode());
        assertThat(resp.readEntity(String.class))
                .isEqualTo(""{\""code\"":500,\""message\"":\""Parameters must have the same"" +
                        "" validation groups in validationGroupsException\""}"");
    }
",non-flaky,5
77548,dropwizard_dropwizard,ResourceTestRuleTest.testCustomClientConfiguration,"    @Test
    public void testCustomClientConfiguration() {
        assertThat(resourceTestRule.client().getConfiguration().isRegistered(DummyExceptionMapper.class)).isTrue();
    }
",non-flaky,5
77549,dropwizard_dropwizard,GzipDefaultVaryBehaviourTest.testDefaultVaryHeader,"    @Test
    public void testDefaultVaryHeader() {
        final Response clientResponse = RULE.client().target(
            ""http://localhost:"" + RULE.getLocalPort() + ""/test"").request().header(ACCEPT_ENCODING, ""gzip"").get();

        assertThat(clientResponse.getHeaders().get(VARY)).isEqualTo(Collections.singletonList((Object) ACCEPT_ENCODING));
        assertThat(clientResponse.getHeaders().get(CONTENT_ENCODING)).isEqualTo(Collections.singletonList((Object) ""gzip""));
    }
",non-flaky,5
77550,dropwizard_dropwizard,LogbackExcludedTest.testBuildConfigurationMetadata,"    @Test
    public void testBuildConfigurationMetadata(CheckedConsumer<String> classFilter) throws Exception {
        try (ByteArrayOutputStream byteStream = captureStderr();
                CustomClassLoader loader = new CustomClassLoader(classFilter)) {
            // create class objects from custom loader
            Class<ConfigurationMetadata> cmType = loader.reloadClass(ConfigurationMetadata.class);
            Class<ObjectMapper> omType = loader.reloadClass(ObjectMapper.class);
            Class<Configuration> confType = loader.reloadClass(Configuration.class);
            // construct ConfigurationMetadata object using class object associated with custom loader so that we can
            // simulate Logback not being in the classpath
            cmType.getConstructor(omType, Class.class).newInstance(omType.newInstance(), confType);

            // make sure nothing is emitted to stderr; previously the absence of Logback in the classpath would cause
            // ""class io.dropwizard.configuration.ConfigurationMetadata$1: Type ch.qos.logback.access.spi.IAccessEvent
            // not present"" to be emitted to stderr
            String err = byteStream.toString();
            assertThat(err).isEmpty();
        }
    }
",non-flaky,5
77551,dropwizard_dropwizard,DropwizardAppExtensionWithoutConfigTest.run,"    @Test
        public void run(Configuration configuration, Environment environment) throws Exception {
            environment.jersey().register(new TestResource());
        }
",non-flaky,5
77552,dropwizard_dropwizard,ResourceExtensionMocksTest.getPersonName,"    @Test
        public String getPersonName() {
            return person.getName();
        }
",non-flaky,5
77553,dropwizard_dropwizard,ResourceExtensionWithJettyTest.toResponse,"    @Test
        public Response toResponse(WebApplicationException e) {
            throw new UnsupportedOperationException();
        }
",non-flaky,5
77554,dropwizard_dropwizard,DropwizardAppExtensionWithExplicitTest.run,"    @Test
        public void run(TestConfiguration configuration, Environment environment) throws Exception {
            environment.jersey().register(new TestResource(configuration.getMessage()));
        }
",non-flaky,5
77555,dropwizard_dropwizard,PersonResourceExceptionMapperTest.toResponse,"    @Test
        public Response toResponse(JerseyViolationException exception) {
            return Response.status(Response.Status.BAD_REQUEST)
                .type(MediaType.TEXT_PLAIN)
                .entity(""Invalid data"")
                .build();
        }
",non-flaky,5
77556,dropwizard_dropwizard,ResourceExtensionRandomPortsTest.eachTestShouldUseANewPort,"    @Test
    public void eachTestShouldUseANewPort() throws Throwable {
        final ResourceExtension resources = ResourceExtension.builder()
                .setTestContainerFactory(new GrizzlyTestContainerFactory())
                .build();
        Set<Integer> usedPorts = new HashSet<>();

        for (int i = 0; i < 10; i++) {
            resources.before();
            final int port = resources.target(""/"").getUri().getPort();
            usedPorts.add(port);
        }
        assertThat(usedPorts).hasSizeGreaterThanOrEqualTo(2);
    }
",non-flaky,5
77557,dropwizard_dropwizard,ResourceExtensionWithGrizzlyTest.toResponse,"    @Test
        public Response toResponse(WebApplicationException e) {
            throw new UnsupportedOperationException();
        }
",non-flaky,5
77558,dropwizard_dropwizard,DropwizardTestSupportWithResourceConfigProviderTest.open,"    @Test
        public InputStream open(String path) throws IOException {
            openCalled = true;
            return super.open(path);
        }
",non-flaky,5
77559,dropwizard_dropwizard,OptionalIntMessageBodyWriterTest.showWithQueryParam,"    @Test
        public OptionalInt showWithQueryParam(@QueryParam(""id"") OptionalInt id) {
            return id;
        }
",non-flaky,5
77560,dropwizard_dropwizard,OptionalDoubleMessageBodyWriterTest.showWithQueryParam,"    @Test
        public OptionalDouble showWithQueryParam(@QueryParam(""id"") OptionalDouble id) {
            return id;
        }
",non-flaky,5
77561,dropwizard_dropwizard,OptionalMessageBodyWriterTest.showWithQueryParam,"    @Test
        public Optional<String> showWithQueryParam(@QueryParam(""id"") String id) {
            return Optional.ofNullable(id);
        }
",non-flaky,5
77562,dropwizard_dropwizard,OptionalQueryParamResourceTest.getMessage,"    @Test
        public String getMessage(@QueryParam(""message"") Optional<String> message) {
            return message.orElse(""Default Message"");
        }
",non-flaky,5
77563,dropwizard_dropwizard,OptionalHeaderParamResourceTest.getMessage,"    @Test
        public String getMessage(@HeaderParam(""message"") Optional<String> message) {
            return message.orElse(""Default Message"");
        }
",non-flaky,5
77564,dropwizard_dropwizard,OptionalLongMessageBodyWriterTest.showWithQueryParam,"    @Test
        public OptionalLong showWithQueryParam(@QueryParam(""id"") OptionalLong id) {
            return id;
        }
",non-flaky,5
77565,dropwizard_dropwizard,OptionalCookieParamResourceTest.getMessage,"    @Test
        public String getMessage(@CookieParam(""message"") Optional<String> message) {
            return message.orElse(""Default Message"");
        }
",non-flaky,5
77566,dropwizard_dropwizard,OptionalFormParamResourceTest.getMessage,"    @Test
        public String getMessage(@FormParam(""message"") Optional<String> message) {
            return message.orElse(""Default Message"");
        }
",non-flaky,5
77567,dropwizard_dropwizard,DropwizardResourceConfigTest.foo,"    @Test
        public String foo() {
            return ""bar"";
        }
",non-flaky,5
77568,dropwizard_dropwizard,NonEmptyStringParamProviderTest.getMessage,"    @Test
        public String getMessage(@QueryParam(""message"") NonEmptyStringParam message) {
            return message.get().orElse(""Hello"");
        }
",non-flaky,5
77569,dropwizard_dropwizard,ConstraintViolationExceptionMapperTest.setUp,"    @BeforeEach
    public void setUp() throws Exception {
        assumeThat(Locale.getDefault().getLanguage()).isEqualTo(""en"");
        super.setUp();
    }
",non-flaky,5
77570,dropwizard_dropwizard,OptionalMessageBodyWriterTest.showWithQueryParam,"    @Test
        public Optional<String> showWithQueryParam(@QueryParam(""id"") String id) {
            return Optional.fromNullable(id);
        }
",non-flaky,5
77571,dropwizard_dropwizard,OptionalQueryParamResourceTest.getMessage,"    @Test
        public String getMessage(@QueryParam(""message"") Optional<String> message) {
            return message.or(""Default Message"");
        }
",non-flaky,5
77572,dropwizard_dropwizard,OptionalHeaderParamResourceTest.getMessage,"    @Test
        public String getMessage(@HeaderParam(""message"") Optional<String> message) {
            return message.or(""Default Message"");
        }
",non-flaky,5
77573,dropwizard_dropwizard,OptionalCookieParamResourceTest.getMessage,"    @Test
        public String getMessage(@CookieParam(""message"") Optional<String> message) {
            return message.or(""Default Message"");
        }
",non-flaky,5
77574,dropwizard_dropwizard,OptionalFormParamResourceTest.getMessage,"    @Test
        public String getMessage(@FormParam(""message"") Optional<String> message) {
            return message.or(""Default Message"");
        }
",non-flaky,5
77575,dropwizard_dropwizard,ConfiguredGZipEncoderTest.write,"    @Test
            public void write(int i) throws IOException {
                //void
            }
",non-flaky,5
77576,dropwizard_dropwizard,EofExceptionWriterInterceptorJerseyTest.streamForever,"    @Test
        public Response streamForever() {
            final StreamingOutput output = os -> {
                //noinspection InfiniteLoopStatement
                while (true) {
                    os.write('a');
                    os.flush();
                }
            };

            return Response.ok(output).build();
        }
",non-flaky,5
77577,dropwizard_dropwizard,JerseyIgnoreRequestUserAgentHeaderFilterTest.getReturnUserAgentHeader,"    @Test
        public String getReturnUserAgentHeader(@HeaderParam(""User-Agent"") String userAgentHeader) {
            return userAgentHeader;
        }
",non-flaky,5
77578,dropwizard_dropwizard,HttpClientBuilderTest.select,"    @Test
            public List<Proxy> select(URI uri) {
                return Collections.singletonList(new Proxy(Proxy.Type.HTTP, new InetSocketAddress(""192.168.52.1"", 8080)));
            }
",non-flaky,5
77579,dropwizard_dropwizard,HttpClientBuilderTest.setCredentials,"    @Test
            public void setCredentials(AuthScope authscope, Credentials credentials) {
            }
",non-flaky,5
77580,dropwizard_dropwizard,HttpClientBuilderTest.isRedirected,"    @Test
            public boolean isRedirected(HttpRequest httpRequest,
                                        HttpResponse httpResponse,
",non-flaky,5
77581,dropwizard_dropwizard,JerseyClientBuilderTest.usesAnExecutorServiceFromTheEnvironment,"    @Test
    public void usesAnExecutorServiceFromTheEnvironment() {
        final JerseyClientConfiguration configuration = new JerseyClientConfiguration();
        configuration.setMinThreads(7);
        configuration.setMaxThreads(532);
        configuration.setWorkQueueSize(16);

        final ExecutorServiceBuilder executorServiceBuilderMock = mock(ExecutorServiceBuilder.class);
        when(lifecycleEnvironment.executorService(""jersey-client-test-%d"")).thenReturn(executorServiceBuilderMock);

        when(executorServiceBuilderMock.minThreads(7)).thenReturn(executorServiceBuilderMock);
        when(executorServiceBuilderMock.maxThreads(532)).thenReturn(executorServiceBuilderMock);

        final ArgumentCaptor<ArrayBlockingQueue> arrayBlockingQueueCaptor =
                ArgumentCaptor.forClass(ArrayBlockingQueue.class);
        when(executorServiceBuilderMock.workQueue(arrayBlockingQueueCaptor.capture()))
                .thenReturn(executorServiceBuilderMock);
        when(executorServiceBuilderMock.build()).thenReturn(mock(ExecutorService.class));

        builder.using(configuration).using(environment).build(""test"");

        assertThat(arrayBlockingQueueCaptor.getValue().remainingCapacity()).isEqualTo(16);
    }
",non-flaky,5
77582,dropwizard_dropwizard,JerseyClientBuilderTest.checkClientTrusted,"    @Test
                public void checkClientTrusted(X509Certificate[] xcs, String string) {
                }
",non-flaky,5
77583,dropwizard_dropwizard,JerseyClientBuilderTest.select,"    @Test
            public List<Proxy> select(URI uri) {
                return Collections.singletonList(new Proxy(Proxy.Type.HTTP, new InetSocketAddress(""192.168.53.12"", 8080)));
            }
",non-flaky,5
84559,apache_zookeeper,DistributedQueueTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();
    }
",non-flaky,5
84560,apache_zookeeper,DistributedQueueTest.testOffer1,"    @Test
    public void testOffer1() throws Exception {
        String dir = ""/testOffer1"";
        String testString = ""Hello World"";
        final int numClients = 1;
        ZooKeeper[] clients = new ZooKeeper[numClients];
        DistributedQueue[] queueHandles = new DistributedQueue[numClients];
        for (int i = 0; i < clients.length; i++) {
            clients[i] = createClient();
            queueHandles[i] = new DistributedQueue(clients[i], dir, null);
        }

        queueHandles[0].offer(testString.getBytes());

        byte[] dequeuedBytes = queueHandles[0].remove();
        assertEquals(new String(dequeuedBytes), testString);
    }
",non-flaky,5
84561,apache_zookeeper,DistributedQueueTest.testOffer2,"    @Test
    public void testOffer2() throws Exception {
        String dir = ""/testOffer2"";
        String testString = ""Hello World"";
        final int numClients = 2;
        ZooKeeper[] clients = new ZooKeeper[numClients];
        DistributedQueue[] queueHandles = new DistributedQueue[numClients];
        for (int i = 0; i < clients.length; i++) {
            clients[i] = createClient();
            queueHandles[i] = new DistributedQueue(clients[i], dir, null);
        }

        queueHandles[0].offer(testString.getBytes());

        byte[] dequeuedBytes = queueHandles[1].remove();
        assertEquals(new String(dequeuedBytes), testString);
    }
",non-flaky,5
84562,apache_zookeeper,DistributedQueueTest.testTake1,"    @Test
    public void testTake1() throws Exception {
        String dir = ""/testTake1"";
        String testString = ""Hello World"";
        final int numClients = 1;
        ZooKeeper[] clients = new ZooKeeper[numClients];
        DistributedQueue[] queueHandles = new DistributedQueue[numClients];
        for (int i = 0; i < clients.length; i++) {
            clients[i] = createClient();
            queueHandles[i] = new DistributedQueue(clients[i], dir, null);
        }

        queueHandles[0].offer(testString.getBytes());

        byte[] dequeuedBytes = queueHandles[0].take();
        assertEquals(new String(dequeuedBytes), testString);
    }
",non-flaky,5
84563,apache_zookeeper,DistributedQueueTest.testRemove1,"    @Test
    public void testRemove1() throws Exception {
        String dir = ""/testRemove1"";
        final int numClients = 1;
        ZooKeeper[] clients = new ZooKeeper[numClients];
        DistributedQueue[] queueHandles = new DistributedQueue[numClients];
        for (int i = 0; i < clients.length; i++) {
            clients[i] = createClient();
            queueHandles[i] = new DistributedQueue(clients[i], dir, null);
        }

        try {
            queueHandles[0].remove();
        } catch (NoSuchElementException e) {
            return;
        }

        fail();
    }
",non-flaky,5
84564,apache_zookeeper,DistributedQueueTest.testRemove2,"    @Test
    public void testRemove2() throws Exception {
        createNremoveMtest(""/testRemove2"", 10, 2);
    }
",non-flaky,5
84565,apache_zookeeper,DistributedQueueTest.testRemove3,"    @Test
    public void testRemove3() throws Exception {
        createNremoveMtest(""/testRemove3"", 1000, 1000);
    }
",non-flaky,5
84566,apache_zookeeper,DistributedQueueTest.testElement1,"    @Test
    public void testElement1() throws Exception {
        createNremoveMelementTest(""/testElement1"", 1, 0);
    }
",non-flaky,5
84567,apache_zookeeper,DistributedQueueTest.testElement2,"    @Test
    public void testElement2() throws Exception {
        createNremoveMelementTest(""/testElement2"", 10, 2);
    }
",non-flaky,5
84568,apache_zookeeper,DistributedQueueTest.testElement3,"    @Test
    public void testElement3() throws Exception {
        createNremoveMelementTest(""/testElement3"", 1000, 500);
    }
",non-flaky,5
84569,apache_zookeeper,DistributedQueueTest.testElement4,"    @Test
    public void testElement4() throws Exception {
        createNremoveMelementTest(""/testElement4"", 1000, 1000 - 1);
    }
",non-flaky,5
84570,apache_zookeeper,DistributedQueueTest.testTakeWait1,"    @Test
    public void testTakeWait1() throws Exception {
        String dir = ""/testTakeWait1"";
        final String testString = ""Hello World"";
        final int numClients = 1;
        final ZooKeeper[] clients = new ZooKeeper[numClients];
        final DistributedQueue[] queueHandles = new DistributedQueue[numClients];
        for (int i = 0; i < clients.length; i++) {
            clients[i] = createClient();
            queueHandles[i] = new DistributedQueue(clients[i], dir, null);
        }

        final byte[][] takeResult = new byte[1][];
        Thread takeThread = new Thread(() -> {
            try {
                takeResult[0] = queueHandles[0].take();
            } catch (KeeperException | InterruptedException ignore) {
                // no op
            }
        });
        takeThread.start();

        Thread.sleep(1000);
        Thread offerThread = new Thread(() -> {
            try {
                queueHandles[0].offer(testString.getBytes());
            } catch (KeeperException | InterruptedException ignore) {
                // no op
            }
        });
        offerThread.start();
        offerThread.join();

        takeThread.join();

        assertNotNull(takeResult[0]);
        assertEquals(new String(takeResult[0]), testString);
    }
",non-flaky,5
84571,apache_zookeeper,DistributedQueueTest.testTakeWait2,"    @Test
    public void testTakeWait2() throws Exception {
        String dir = ""/testTakeWait2"";
        final String testString = ""Hello World"";
        final int numClients = 1;
        final ZooKeeper[] clients = new ZooKeeper[numClients];
        final DistributedQueue[] queueHandles = new DistributedQueue[numClients];
        for (int i = 0; i < clients.length; i++) {
            clients[i] = createClient();
            queueHandles[i] = new DistributedQueue(clients[i], dir, null);
        }
        int numAttempts = 2;
        for (int i = 0; i < numAttempts; i++) {
            final byte[][] takeResult = new byte[1][];
            final String threadTestString = testString + i;
            Thread takeThread = new Thread(() -> {
                try {
                    takeResult[0] = queueHandles[0].take();
                } catch (KeeperException | InterruptedException ignore) {
                    // no op
                }
            });
            takeThread.start();

            Thread.sleep(1000);
            Thread offerThread = new Thread(() -> {
                try {
                    queueHandles[0].offer(threadTestString.getBytes());
                } catch (KeeperException | InterruptedException ignore) {
                    // no op
                }
            });
            offerThread.start();
            offerThread.join();

            takeThread.join();

            assertNotNull(takeResult[0]);
            assertEquals(new String(takeResult[0]), threadTestString);
        }
    }
",non-flaky,5
84572,apache_zookeeper,LeaderElectionSupportTest.setUp,"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();

        zooKeeper = createClient();

        zooKeeper.create(
            TEST_ROOT_NODE + Thread.currentThread().getId(),
            new byte[0],
            ZooDefs.Ids.OPEN_ACL_UNSAFE,
            CreateMode.PERSISTENT);
    }
",non-flaky,5
84573,apache_zookeeper,LeaderElectionSupportTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        if (zooKeeper != null) {
            zooKeeper.delete(TEST_ROOT_NODE + Thread.currentThread().getId(), -1);
        }

        super.tearDown();
    }
",non-flaky,5
84574,apache_zookeeper,LeaderElectionSupportTest.testNode,"    @Test
    public void testNode() throws Exception {
        LeaderElectionSupport electionSupport = createLeaderElectionSupport();

        electionSupport.start();
        Thread.sleep(3000);
        electionSupport.stop();
    }
",non-flaky,5
84575,apache_zookeeper,LeaderElectionSupportTest.testNodes3,"    @Test
    public void testNodes3() throws Exception {
        int testIterations = 3;
        final CountDownLatch latch = new CountDownLatch(testIterations);
        final AtomicInteger failureCounter = new AtomicInteger();

        for (int i = 0; i < testIterations; i++) {
            runElectionSupportThread(latch, failureCounter);
        }

        assertEquals(0, failureCounter.get());

        if (!latch.await(10, TimeUnit.SECONDS)) {
            LOGGER.info(""Waited for all threads to start, but timed out. We had {} failures."", failureCounter);
        }
    }
",non-flaky,5
84576,apache_zookeeper,LeaderElectionSupportTest.testNodes9,"    @Test
    public void testNodes9() throws Exception {
        int testIterations = 9;
        final CountDownLatch latch = new CountDownLatch(testIterations);
        final AtomicInteger failureCounter = new AtomicInteger();

        for (int i = 0; i < testIterations; i++) {
            runElectionSupportThread(latch, failureCounter);
        }

        assertEquals(0, failureCounter.get());

        if (!latch.await(10, TimeUnit.SECONDS)) {
            LOGGER.info(""Waited for all threads to start, but timed out. We had {} failures."", failureCounter);
        }
    }
",non-flaky,5
84577,apache_zookeeper,LeaderElectionSupportTest.testNodes20,"    @Test
    public void testNodes20() throws Exception {
        int testIterations = 20;
        final CountDownLatch latch = new CountDownLatch(testIterations);
        final AtomicInteger failureCounter = new AtomicInteger();

        for (int i = 0; i < testIterations; i++) {
            runElectionSupportThread(latch, failureCounter);
        }

        assertEquals(0, failureCounter.get());

        if (!latch.await(10, TimeUnit.SECONDS)) {
            LOGGER.info(""Waited for all threads to start, but timed out. We had {} failures."", failureCounter);
        }
    }
",non-flaky,5
84578,apache_zookeeper,LeaderElectionSupportTest.testNodes100,"    @Test
    public void testNodes100() throws Exception {
        int testIterations = 100;
        final CountDownLatch latch = new CountDownLatch(testIterations);
        final AtomicInteger failureCounter = new AtomicInteger();

        for (int i = 0; i < testIterations; i++) {
            runElectionSupportThread(latch, failureCounter);
        }

        assertEquals(0, failureCounter.get());

        if (!latch.await(20, TimeUnit.SECONDS)) {
            LOGGER.info(""Waited for all threads to start, but timed out. We had {} failures."", failureCounter);
        }
    }
",non-flaky,5
84579,apache_zookeeper,LeaderElectionSupportTest.testOfferShuffle,"    @Test
    public void testOfferShuffle() throws InterruptedException {
        int testIterations = 10;
        final CountDownLatch latch = new CountDownLatch(testIterations);
        final AtomicInteger failureCounter = new AtomicInteger();
        List<Thread> threads = new ArrayList<>(testIterations);

        for (int i = 1; i <= testIterations; i++) {
            threads.add(runElectionSupportThread(latch, failureCounter, Math.min(i * 1200, 10000)));
        }

        if (!latch.await(60, TimeUnit.SECONDS)) {
            LOGGER.info(""Waited for all threads to start, but timed out. We had {} failures."", failureCounter);
        }
    }
",non-flaky,5
84580,apache_zookeeper,LeaderElectionSupportTest.testGetLeaderHostName,"    @Test
    public void testGetLeaderHostName() throws Exception {
        LeaderElectionSupport electionSupport = createLeaderElectionSupport();

        electionSupport.start();

        // Sketchy: We assume there will be a leader (probably us) in 3 seconds.
        Thread.sleep(3000);

        String leaderHostName = electionSupport.getLeaderHostName();

        assertNotNull(leaderHostName);
        assertEquals(""foohost"", leaderHostName);

        electionSupport.stop();
    }
",non-flaky,5
84581,apache_zookeeper,LeaderElectionSupportTest.onElectionEvent,"    @Test
    public void testReadyOffer() throws Exception {
        final ArrayList<EventType> events = new ArrayList<>();
        final CountDownLatch electedComplete = new CountDownLatch(1);

        final LeaderElectionSupport electionSupport1 = createLeaderElectionSupport();
        electionSupport1.start();
        LeaderElectionSupport electionSupport2 = createLeaderElectionSupport();
        LeaderElectionAware listener = new LeaderElectionAware() {
            boolean stoppedElectedNode = false;
            @Override
            public void onElectionEvent(EventType eventType) {
                events.add(eventType);
                if (!stoppedElectedNode
                    && eventType == EventType.DETERMINE_COMPLETE) {
                    stoppedElectedNode = true;
                    try {
                        // stopping the ELECTED node, so re-election will happen.
                        electionSupport1.stop();
                    } catch (Exception e) {
                        LOGGER.error(""Unexpected exception"", e);
                    }
                }
                if (eventType == EventType.ELECTED_COMPLETE) {
                    electedComplete.countDown();
                }
            }
",non-flaky,5
84582,apache_zookeeper,WriteLockTest.testRun,"    @Test
    public void testRun() throws Exception {
        runTest(3);
    }
",non-flaky,5
84583,apache_zookeeper,WriteLockTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        if (nodes != null) {
            for (int i = 0; i < nodes.length; i++) {
                WriteLock node = nodes[i];
                if (node != null) {
                    System.out.println(""Closing node: "" + i);
                    node.close();
                    if (workAroundClosingLastZNodeFails && i == nodes.length - 1) {
                        System.out.println(""Not closing zookeeper: "" + i + "" due to bug!"");
                    } else {
                        System.out.println(""Closing zookeeper: "" + i);
                        node.getZookeeper().close();
                        System.out.println(""Closed zookeeper: "" + i);
                    }
                }
            }
        }
        System.out.println(""Now lets stop the server"");
        super.tearDown();

    }
",non-flaky,5
84584,apache_zookeeper,ZNodeNameTest.testOrderWithSamePrefix,"    @Test
    public void testOrderWithSamePrefix() throws Exception {
        final String[] names = {""x-3"", ""x-5"", ""x-11"", ""x-1""};
        ZNodeName zname;

        final Collection<ZNodeName> nodeNames = Arrays.asList(names).stream()
            .map(name -> new ZNodeName(name)).sorted().collect(Collectors.toList());

        final Iterator<ZNodeName> it = nodeNames.iterator();

        zname = it.next();
        assertEquals(""x-1"", zname.getName());
        assertEquals(""x"", zname.getPrefix());
        assertEquals(Integer.valueOf(1), zname.getSequence().get());

        zname = it.next();
        assertEquals(""x-3"", zname.getName());
        assertEquals(""x"", zname.getPrefix());
        assertEquals(Integer.valueOf(3), zname.getSequence().get());

        zname = it.next();
        assertEquals(""x-5"", zname.getName());
        assertEquals(""x"", zname.getPrefix());
        assertEquals(Integer.valueOf(5), zname.getSequence().get());

        zname = it.next();
        assertEquals(""x-11"", zname.getName());
        assertEquals(""x"", zname.getPrefix());
        assertEquals(Integer.valueOf(11), zname.getSequence().get());
    }
",non-flaky,5
84585,apache_zookeeper,ZNodeNameTest.testOrderWithDifferentPrefixes,"    @Test
    public void testOrderWithDifferentPrefixes() throws Exception {
        final String[] names = {""r-3"", ""r-2"", ""r-1"", ""w-2"", ""w-1""};
        ZNodeName zname;

        final Collection<ZNodeName> nodeNames = Arrays.asList(names).stream()
            .map(name -> new ZNodeName(name)).sorted().collect(Collectors.toList());

        final Iterator<ZNodeName> it = nodeNames.iterator();

        zname = it.next();
        assertEquals(""r-1"", zname.getName());
        assertEquals(""r"", zname.getPrefix());
        assertEquals(Integer.valueOf(1), zname.getSequence().get());

        zname = it.next();
        assertEquals(""w-1"", zname.getName());
        assertEquals(""w"", zname.getPrefix());
        assertEquals(Integer.valueOf(1), zname.getSequence().get());

        zname = it.next();
        assertEquals(""r-2"", zname.getName());
        assertEquals(""r"", zname.getPrefix());
        assertEquals(Integer.valueOf(2), zname.getSequence().get());

        zname = it.next();
        assertEquals(""w-2"", zname.getName());
        assertEquals(""w"", zname.getPrefix());
        assertEquals(Integer.valueOf(2), zname.getSequence().get());

        zname = it.next();
        assertEquals(""r-3"", zname.getName());
        assertEquals(""r"", zname.getPrefix());
        assertEquals(Integer.valueOf(3), zname.getSequence().get());
    }
",non-flaky,5
84586,apache_zookeeper,ZNodeNameTest.testOrderWithDifferentPrefixIncludingSessionId,"    @Test
    public void testOrderWithDifferentPrefixIncludingSessionId() throws Exception {
        String[] names = {
            ""x-242681582799028564-0000000002"",
            ""x-170623981976748329-0000000003"",
            ""x-98566387950223723-0000000001""
        };
        ZNodeName zname;

        final Collection<ZNodeName> nodeNames = Arrays.asList(names).stream()
            .map(name -> new ZNodeName(name)).sorted().collect(Collectors.toList());

        final Iterator<ZNodeName> it = nodeNames.iterator();

        zname = it.next();
        assertEquals(""x-98566387950223723-0000000001"", zname.getName());
        assertEquals(""x-98566387950223723"", zname.getPrefix());
        assertEquals(Integer.valueOf(1), zname.getSequence().get());

        zname = it.next();
        assertEquals(""x-242681582799028564-0000000002"", zname.getName());
        assertEquals(""x-242681582799028564"", zname.getPrefix());
        assertEquals(Integer.valueOf(2), zname.getSequence().get());

        zname = it.next();
        assertEquals(""x-170623981976748329-0000000003"", zname.getName());
        assertEquals(""x-170623981976748329"", zname.getPrefix());
        assertEquals(Integer.valueOf(3), zname.getSequence().get());
    }
",non-flaky,5
84587,apache_zookeeper,ZNodeNameTest.testOrderWithExtraPrefixes,"    @Test
    public void testOrderWithExtraPrefixes() throws Exception {
        String[] names = {""r-1-3-2"", ""r-2-2-1"", ""r-3-1-3""};
        ZNodeName zname;

        final Collection<ZNodeName> nodeNames = Arrays.asList(names).stream()
            .map(name -> new ZNodeName(name)).sorted().collect(Collectors.toList());

        final Iterator<ZNodeName> it = nodeNames.iterator();

        zname = it.next();
        assertEquals(""r-2-2-1"", zname.getName());
        assertEquals(""r-2-2"", zname.getPrefix());
        assertEquals(Integer.valueOf(1), zname.getSequence().get());

        zname = it.next();
        assertEquals(""r-1-3-2"", zname.getName());
        assertEquals(""r-1-3"", zname.getPrefix());
        assertEquals(Integer.valueOf(2), zname.getSequence().get());

        zname = it.next();
        assertEquals(""r-3-1-3"", zname.getName());
        assertEquals(""r-3-1"", zname.getPrefix());
        assertEquals(Integer.valueOf(3), zname.getSequence().get());
    }
",non-flaky,5
84588,apache_zookeeper,ZNodeNameTest.testMissingSequenceNumber,"    @Test
    public void testMissingSequenceNumber() throws Exception {
        String[] names = {""c"", ""b-1"", ""a""};
        ZNodeName zname;

        final Collection<ZNodeName> nodeNames = Arrays.asList(names).stream()
            .map(name -> new ZNodeName(name)).sorted().collect(Collectors.toList());

        final Iterator<ZNodeName> it = nodeNames.iterator();

        zname = it.next();
        assertEquals(""b-1"", zname.getName());
        assertEquals(""b"", zname.getPrefix());
        assertEquals(Integer.valueOf(1), zname.getSequence().get());

        zname = it.next();
        assertEquals(""a"", zname.getName());
        assertEquals(""a"", zname.getPrefix());
        assertFalse(zname.getSequence().isPresent());

        zname = it.next();
        assertEquals(""c"", zname.getName());
        assertEquals(""c"", zname.getPrefix());
        assertFalse(zname.getSequence().isPresent());
    }
",non-flaky,5
84589,apache_zookeeper,ZNodeNameTest.testNullName,"    @Test
    public void testNullName() {
        assertThrows(NullPointerException.class, () -> {
            new ZNodeName(null);
        });
    }
",non-flaky,5
84590,apache_zookeeper,TestApacheCuratorCompatibility.testBasicUsageOfApisAndRecipes,"    @Test
    public void testBasicUsageOfApisAndRecipes() throws Exception {
        try (TestingServer server = new TestingServer()) {
            doTest(server.getConnectString());
        }
    }
",non-flaky,5
84591,apache_zookeeper,TestApacheCuratorCompatibility.testBasicUsageOfApisAndRecipesInCluster,"    @Test
    public void testBasicUsageOfApisAndRecipesInCluster() throws Exception {
        try (TestingCluster cluster = new TestingCluster(3)) {
            cluster.start();
            doTest(cluster.getConnectString());
        }
    }
",non-flaky,5
84592,apache_zookeeper,BinaryInputArchiveTest.testReadStringCheckLength,"    @Test
    public void testReadStringCheckLength() {
        byte[] buf = new byte[]{
                Byte.MAX_VALUE, Byte.MAX_VALUE, Byte.MAX_VALUE, Byte.MAX_VALUE};
        ByteArrayInputStream is = new ByteArrayInputStream(buf);
        BinaryInputArchive ia = BinaryInputArchive.getArchive(is);
        try {
            ia.readString("""");
            fail(""Should have thrown an IOException"");
        } catch (IOException e) {
            assertTrue(e.getMessage().startsWith(BinaryInputArchive.UNREASONBLE_LENGTH),
                    () -> ""Not 'Unreasonable length' exception: "" + e);
        }
    }
",non-flaky,5
84593,apache_zookeeper,BinaryInputArchiveTest.testInt,"    @Test
    public void testInt() {
        final int expected = 4;
        final String tag = ""tag1"";
        checkWriterAndReader(
                (oa) -> oa.writeInt(expected, tag),
                (ia) -> {
                    int actual = ia.readInt(tag);
                    assertEquals(expected, actual);
                }
        );
    }
",non-flaky,5
84594,apache_zookeeper,BinaryInputArchiveTest.testBool,"    @Test
    public void testBool() {
        final boolean expected = false;
        final String tag = ""tag1"";
        checkWriterAndReader(
                (oa) -> oa.writeBool(expected, tag),
                (ia) -> {
                    boolean actual = ia.readBool(tag);
                    assertEquals(expected, actual);
                }
        );
    }
",non-flaky,5
84595,apache_zookeeper,BinaryInputArchiveTest.testString,"    @Test
    public void testString() {
        final String expected = ""hello"";
        final String tag = ""tag1"";
        checkWriterAndReader(
                (oa) -> oa.writeString(expected, tag),
                (ia) -> {
                    String actual = ia.readString(tag);
                    assertEquals(expected, actual);
                }
        );
    }
",non-flaky,5
84596,apache_zookeeper,BinaryInputArchiveTest.testFloat,"    @Test
    public void testFloat() {
        final float expected = 3.14159f;
        final String tag = ""tag1"";
        final float delta = 1e-10f;
        checkWriterAndReader(
                (oa) -> oa.writeFloat(expected, tag),
                (ia) -> {
                    float actual = ia.readFloat(tag);
                    assertEquals(expected, actual, delta);
                }
        );
    }
",non-flaky,5
84597,apache_zookeeper,BinaryInputArchiveTest.testDouble,"    @Test
    public void testDouble() {
        final double expected = 3.14159f;
        final String tag = ""tag1"";
        final float delta = 1e-20f;
        checkWriterAndReader(
                (oa) -> oa.writeDouble(expected, tag),
                (ia) -> {
                    double actual = ia.readDouble(tag);
                    assertEquals(expected, actual, delta);
                }
        );
    }
",non-flaky,5
84598,apache_zookeeper,BinaryInputArchiveTest.testBuffer,"    @Test
    public void testBuffer() {
        final byte[] expected = ""hello-world"".getBytes(StandardCharsets.UTF_8);
        final String tag = ""tag1"";
        checkWriterAndReader(
                (oa) -> oa.writeBuffer(expected, tag),
                (ia) -> {
                    byte[] actual = ia.readBuffer(tag);
                    assertArrayEquals(expected, actual);
                }
        );
    }
",non-flaky,5
84599,apache_zookeeper,BinaryInputArchiveTest.testReadStringForRecordsHavingLengthMoreThanMaxAllowedSize,"  @Test
  public void testReadStringForRecordsHavingLengthMoreThanMaxAllowedSize() {
    int maxBufferSize = 2000;
    int extraMaxBufferSize = 1025;
    //this record size is more than the max allowed size
    int recordSize = maxBufferSize + extraMaxBufferSize + 100;
    BinaryInputArchive ia =
        getBinaryInputArchive(recordSize, maxBufferSize, extraMaxBufferSize);
    try {
      ia.readString("""");
      fail(""Should have thrown an IOException"");
    } catch (IOException e) {
      assertTrue(e.getMessage().startsWith(BinaryInputArchive.UNREASONBLE_LENGTH),
              () -> ""Not 'Unreasonable length' exception: "" + e);
    }
  }
",non-flaky,5
84600,apache_zookeeper,BinaryInputArchiveTest.testReadStringForRecordsHavingLengthLessThanMaxAllowedSize,"  @Test
  public void testReadStringForRecordsHavingLengthLessThanMaxAllowedSize()
      throws IOException {
    int maxBufferSize = 2000;
    int extraMaxBufferSize = 1025;
    int recordSize = maxBufferSize + extraMaxBufferSize - 100;
    //Exception is not expected as record size is less than the allowed size
    BinaryInputArchive ia =
        getBinaryInputArchive(recordSize, maxBufferSize, extraMaxBufferSize);
    String s = ia.readString("""");
    assertNotNull(s);
    assertEquals(recordSize, s.getBytes().length);
  }
",non-flaky,5
84601,apache_zookeeper,SimpleSysTest.testSimpleCase,"    @Test
    public void testSimpleCase() throws Exception {
        configureServers(serverCount);
        configureClients(clientCount, SimpleClient.class, getHostPort());
        Stat stat = new Stat();
        startServers();
        LOG.debug(""Connecting to "" + getHostPort());
        ZooKeeper zk = new ZooKeeper(getHostPort(), 15000, this);
        waitForConnect(zk, 10000);
        zk.create(""/simpleCase"", ""orig"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        startClients();

        // Check that all clients connect properly
        for(int i = 0; i < getClientCount(); i++) {
            for(int j = 0; j < maxTries; j++) {
                try {
                    byte b[] = zk.getData(""/simpleCase/"" + i, false, stat);
                    Assert.assertEquals(""orig"", new String(b));
                } catch(NoNodeException e) {
                    if (j+1 == maxTries) {
                        Assert.fail(""Max tries exceeded on client "" + i);
                    }
                    Thread.sleep(1000);
                }
            }
        }

        // Kill half the servers, make a change, restart the dead
        // servers, and then bounce the other servers one by one
        for(int i = 0; i < getServerCount(); i++) {
            stopServer(i);
            if (i+1 > getServerCount()/2) {
                startServer(i);
            } else if (i+1 == getServerCount()/2) {
                Assert.assertTrue(""Connection didn't recover"", waitForConnect(zk, 10000));
                try {
                    zk.setData(""/simpleCase"", ""new"".getBytes(), -1);
                } catch(ConnectionLossException e) {
                    Assert.assertTrue(""Connection didn't recover"", waitForConnect(zk, 10000));
                    zk.setData(""/simpleCase"", ""new"".getBytes(), -1);
                }
                for(int j = 0; j < i; j++) {
                    LOG.info(""Starting server "" + j);
                    startServer(i);
                }
            }
        }
        Thread.sleep(100); // wait for things to stabilize
        Assert.assertTrue(""Servers didn't bounce"", waitForConnect(zk, 15000));
        try {
            zk.getData(""/simpleCase"", false, stat);
        } catch(ConnectionLossException e) {
            Assert.assertTrue(""Servers didn't bounce"", waitForConnect(zk, 15000));
        }

        // check that the change has propagated to everyone
        for(int i = 0; i < getClientCount(); i++) {
            for(int j = 0; j < maxTries; j++) {
                byte[] data = zk.getData(""/simpleCase/"" + i, false, stat);
                if (new String(data).equals(""new"")) {
                    break;
                }
                if (j+1 == maxTries) {
                    Assert.fail(""max tries exceeded for "" + i);
                }
                Thread.sleep(1000);
            }
        }

        // send out the kill signal
        zk.setData(""/simpleCase"", ""die"".getBytes(), -1);

        // watch for everyone to die
        for(int i = 0; i < getClientCount(); i++) {
            try {
                for(int j = 0; j < maxTries; j++) {
                    zk.getData(""/simpleCase/"" + i, false, stat);
                    if (j+1 == maxTries) {
                        Assert.fail(""max tries exceeded waiting for child "" + i + "" to die"");
                    }
                    Thread.sleep(200);
                }
            } catch(NoNodeException e) {
                // Great this is what we were hoping for!
            }
        }

        stopClients();
        stopServers();
    }
",non-flaky,5
84602,apache_zookeeper,PrometheusMetricsProviderTest.setup,"    @BeforeEach
    public void setup() throws Exception {
        CollectorRegistry.defaultRegistry.clear();
        provider = new PrometheusMetricsProvider();
        Properties configuration = new Properties();
        configuration.setProperty(""httpPort"", ""0""); // ephemeral port
        configuration.setProperty(""exportJvmInfo"", ""false"");
        provider.configure(configuration);
        provider.start();
    }
",non-flaky,5
84603,apache_zookeeper,PrometheusMetricsProviderTest.tearDown,"    @AfterEach
    public void tearDown() {
        if (provider != null) {
            provider.stop();
        }
        CollectorRegistry.defaultRegistry.clear();
    }
",non-flaky,5
84604,apache_zookeeper,PrometheusMetricsProviderTest.testCounters,"    @Test
    public void testCounters() throws Exception {
        Counter counter = provider.getRootContext().getCounter(""cc"");
        counter.add(10);
        int[] count = {0};
        provider.dump((k, v) -> {
            assertEquals(""cc"", k);
            assertEquals(10, ((Number) v).intValue());
            count[0]++;
        }
        );
        assertEquals(1, count[0]);
        count[0] = 0;

        // this is not allowed but it must not throw errors
        counter.add(-1);

        provider.dump((k, v) -> {
            assertEquals(""cc"", k);
            assertEquals(10, ((Number) v).intValue());
            count[0]++;
        }
        );
        assertEquals(1, count[0]);

        // we always must get the same object
        assertSame(counter, provider.getRootContext().getCounter(""cc""));

        String res = callServlet();
        assertThat(res, CoreMatchers.containsString(""# TYPE cc counter""));
        assertThat(res, CoreMatchers.containsString(""cc 10.0""));
    }
",non-flaky,5
84605,apache_zookeeper,PrometheusMetricsProviderTest.testGauge,"    @Test
    public void testGauge() throws Exception {
        int[] values = {78, -89};
        int[] callCounts = {0, 0};
        Gauge gauge0 = () -> {
            callCounts[0]++;
            return values[0];
        };
        Gauge gauge1 = () -> {
            callCounts[1]++;
            return values[1];
        };
        provider.getRootContext().registerGauge(""gg"", gauge0);

        int[] count = {0};
        provider.dump((k, v) -> {
            assertEquals(""gg"", k);
            assertEquals(values[0], ((Number) v).intValue());
            count[0]++;
        }
        );
        assertEquals(1, callCounts[0]);
        assertEquals(0, callCounts[1]);
        assertEquals(1, count[0]);
        count[0] = 0;
        String res2 = callServlet();
        assertThat(res2, CoreMatchers.containsString(""# TYPE gg gauge""));
        assertThat(res2, CoreMatchers.containsString(""gg 78.0""));

        provider.getRootContext().unregisterGauge(""gg"");
        provider.dump((k, v) -> {
            count[0]++;
        }
        );
        assertEquals(2, callCounts[0]);
        assertEquals(0, callCounts[1]);
        assertEquals(0, count[0]);
        String res3 = callServlet();
        assertTrue(res3.isEmpty());

        provider.getRootContext().registerGauge(""gg"", gauge1);

        provider.dump((k, v) -> {
            assertEquals(""gg"", k);
            assertEquals(values[1], ((Number) v).intValue());
            count[0]++;
        }
        );
        assertEquals(2, callCounts[0]);
        assertEquals(1, callCounts[1]);
        assertEquals(1, count[0]);
        count[0] = 0;

        String res4 = callServlet();
        assertThat(res4, CoreMatchers.containsString(""# TYPE gg gauge""));
        assertThat(res4, CoreMatchers.containsString(""gg -89.0""));
        assertEquals(2, callCounts[0]);
        // the servlet must sample the value again (from gauge1)
        assertEquals(2, callCounts[1]);

        // override gauge, without unregister
        provider.getRootContext().registerGauge(""gg"", gauge0);

        provider.dump((k, v) -> {
            count[0]++;
        }
        );
        assertEquals(1, count[0]);
        assertEquals(3, callCounts[0]);
        assertEquals(2, callCounts[1]);
    }
",non-flaky,5
84606,apache_zookeeper,PrometheusMetricsProviderTest.testBasicSummary,"    @Test
    public void testBasicSummary() throws Exception {
        Summary summary = provider.getRootContext()
                .getSummary(""cc"", MetricsContext.DetailLevel.BASIC);
        summary.add(10);
        summary.add(10);
        int[] count = {0};
        provider.dump((k, v) -> {
            count[0]++;
            int value = ((Number) v).intValue();

            switch (k) {
                case ""cc{quantile=\""0.5\""}"":
                    assertEquals(10, value);
                    break;
                case ""cc_count"":
                    assertEquals(2, value);
                    break;
                case ""cc_sum"":
                    assertEquals(20, value);
                    break;
                default:
                    fail(""unespected key "" + k);
                    break;
            }
        }
        );
        assertEquals(3, count[0]);
        count[0] = 0;

        // we always must get the same object
        assertSame(summary, provider.getRootContext()
                .getSummary(""cc"", MetricsContext.DetailLevel.BASIC));

        try {
            provider.getRootContext()
                    .getSummary(""cc"", MetricsContext.DetailLevel.ADVANCED);
            fail(""Can't get the same summary with a different DetailLevel"");
        } catch (IllegalArgumentException err) {
            assertThat(err.getMessage(), containsString(""Already registered""));
        }

        String res = callServlet();
        assertThat(res, containsString(""# TYPE cc summary""));
        assertThat(res, CoreMatchers.containsString(""cc_sum 20.0""));
        assertThat(res, CoreMatchers.containsString(""cc_count 2.0""));
        assertThat(res, CoreMatchers.containsString(""cc{quantile=\""0.5\"",} 10.0""));
    }
",non-flaky,5
84607,apache_zookeeper,PrometheusMetricsProviderTest.testAdvancedSummary,"    @Test
    public void testAdvancedSummary() throws Exception {
        Summary summary = provider.getRootContext()
                .getSummary(""cc"", MetricsContext.DetailLevel.ADVANCED);
        summary.add(10);
        summary.add(10);
        int[] count = {0};
        provider.dump((k, v) -> {
            count[0]++;
            int value = ((Number) v).intValue();

            switch (k) {
                case ""cc{quantile=\""0.5\""}"":
                    assertEquals(10, value);
                    break;
                case ""cc{quantile=\""0.9\""}"":
                    assertEquals(10, value);
                    break;
                case ""cc{quantile=\""0.99\""}"":
                    assertEquals(10, value);
                    break;
                case ""cc_count"":
                    assertEquals(2, value);
                    break;
                case ""cc_sum"":
                    assertEquals(20, value);
                    break;
                default:
                    fail(""unespected key "" + k);
                    break;
            }
        }
        );
        assertEquals(5, count[0]);
        count[0] = 0;

        // we always must get the same object
        assertSame(summary, provider.getRootContext()
                .getSummary(""cc"", MetricsContext.DetailLevel.ADVANCED));

        try {
            provider.getRootContext()
                    .getSummary(""cc"", MetricsContext.DetailLevel.BASIC);
            fail(""Can't get the same summary with a different DetailLevel"");
        } catch (IllegalArgumentException err) {
            assertThat(err.getMessage(), containsString(""Already registered""));
        }

        String res = callServlet();
        assertThat(res, containsString(""# TYPE cc summary""));
        assertThat(res, CoreMatchers.containsString(""cc_sum 20.0""));
        assertThat(res, CoreMatchers.containsString(""cc_count 2.0""));
        assertThat(res, CoreMatchers.containsString(""cc{quantile=\""0.5\"",} 10.0""));
        assertThat(res, CoreMatchers.containsString(""cc{quantile=\""0.9\"",} 10.0""));
        assertThat(res, CoreMatchers.containsString(""cc{quantile=\""0.99\"",} 10.0""));
    }
",non-flaky,5
84608,apache_zookeeper,ExportJvmInfoTest.exportInfo,"    @Test
    public void exportInfo() throws Exception {
        runTest(true);
    }
",non-flaky,5
84609,apache_zookeeper,ExportJvmInfoTest.doNotExportInfo,"    @Test
    public void doNotExportInfo() throws Exception {
        runTest(false);
    }
",non-flaky,5
84610,apache_zookeeper,CustomHostProviderTest.testZooKeeperWithCustomHostProvider,"    @Test
    public void testZooKeeperWithCustomHostProvider() throws IOException, InterruptedException {
        final int CLIENT_PORT = PortAssignment.unique();
        final HostProvider specialHostProvider = new SpecialHostProvider();
        int expectedCounter = 3;
        counter.set(expectedCounter);

        ZooKeeper zkDefaults = new ZooKeeper(
            ""127.0.0.1:"" + CLIENT_PORT,
            ClientBase.CONNECTION_TIMEOUT,
            DummyWatcher.INSTANCE,
            false);

        ZooKeeper zkSpecial = new ZooKeeper(
                ""127.0.0.1:"" + CLIENT_PORT,
                ClientBase.CONNECTION_TIMEOUT,
                DummyWatcher.INSTANCE,
                false,
                specialHostProvider);

        assertTrue(counter.get() == expectedCounter);
        zkDefaults.updateServerList(""127.0.0.1:"" + PortAssignment.unique());
        assertTrue(counter.get() == expectedCounter);

        zkSpecial.updateServerList(""127.0.0.1:"" + PortAssignment.unique());
        expectedCounter--;
        assertTrue(counter.get() == expectedCounter);
    }
",non-flaky,5
84611,apache_zookeeper,GetEphemeralsTest.setUp,"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();

        zk = createClient();
        expected = generatePaths(PERSISTENT_CNT, EPHEMERAL_CNT);
    }
",non-flaky,5
84612,apache_zookeeper,GetEphemeralsTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();

        zk.close();
    }
",non-flaky,5
84613,apache_zookeeper,GetEphemeralsTest.testGetEphemeralsSync,"    @Test
    public void testGetEphemeralsSync() throws KeeperException, InterruptedException {
        List<String> actual = zk.getEphemerals();
        assertEquals(actual.size(), expected.length, ""Expected ephemeral count for allPaths"");
        for (int i = 0; i < expected.length; i++) {
            String path = expected[i];
            assertTrue(actual.contains(path), String.format(""Path=%s exists in get All Ephemerals list "", path));
        }
    }
",non-flaky,5
84614,apache_zookeeper,GetEphemeralsTest.testGetEphemeralsSyncByPath,"    @Test
    public void testGetEphemeralsSyncByPath() throws KeeperException, InterruptedException {
        final String prefixPath = BASE + 0;
        List<String> actual = zk.getEphemerals(prefixPath);
        assertEquals(actual.size(), EPHEMERAL_CNT, ""Expected ephemeral count for allPaths"");
        for (int i = 0; i < EPHEMERAL_CNT; i++) {
            String path = expected[i];
            assertTrue(actual.contains(path), String.format(""Path=%s exists in getEphemerals(%s) list "", path, prefixPath));
        }
    }
",non-flaky,5
84615,apache_zookeeper,GetEphemeralsTest.testGetEphemerals,"    @Test
    public void testGetEphemerals() throws IOException, KeeperException, InterruptedException {

        final CountDownLatch doneProcessing = new CountDownLatch(1);
        final List<String> unexpectedBehavior = new ArrayList<String>();
        zk.getEphemerals((rc, ctx, paths) -> {
            if (paths == null) {
                unexpectedBehavior.add(String.format(""Expected ephemeral count for""
                                                             + "" allPaths to be %d but was null"", expected.length));
            } else if (paths.size() != expected.length) {
                unexpectedBehavior.add(String.format(""Expected ephemeral count for allPaths to be %d but was %d"", expected.length, paths.size()));
            }
            for (int i = 0; i < expected.length; i++) {
                String path = expected[i];
                if (!paths.contains(path)) {
                    unexpectedBehavior.add(String.format(""Path=%s exists in getEphemerals list "", path));
                }
            }
            doneProcessing.countDown();
        }, null);
        long waitForCallbackSecs = 2L;
        if (!doneProcessing.await(waitForCallbackSecs, TimeUnit.SECONDS)) {
            fail(String.format(""getEphemerals didn't callback within %d seconds"", waitForCallbackSecs));
        }
        checkForUnexpectedBehavior(unexpectedBehavior);

    }
",non-flaky,5
84616,apache_zookeeper,GetEphemeralsTest.testGetEphemeralsByPath,"    @Test
    public void testGetEphemeralsByPath() throws IOException, KeeperException, InterruptedException {

        final CountDownLatch doneProcessing = new CountDownLatch(1);
        final String checkPath = BASE + ""0"";
        final List<String> unexpectedBehavior = new ArrayList<String>();
        zk.getEphemerals(checkPath, (rc, ctx, paths) -> {
            if (paths == null) {
                unexpectedBehavior.add(String.format(""Expected ephemeral count for %s to be %d but was null"", checkPath, expected.length));
            } else if (paths.size() != EPHEMERAL_CNT) {
                unexpectedBehavior.add(String.format(""Expected ephemeral count for %s to be %d but was %d"", checkPath, EPHEMERAL_CNT, paths.size()));
            }
            for (int i = 0; i < EPHEMERAL_CNT; i++) {
                String path = expected[i];
                if (!paths.contains(path)) {
                    unexpectedBehavior.add(String.format(""Expected path=%s didn't exist ""
                                                                 + ""in getEphemerals list."", path));
                }
            }
            doneProcessing.countDown();
        }, null);
        long waitForCallbackSecs = 2L;
        if (!doneProcessing.await(waitForCallbackSecs, TimeUnit.SECONDS)) {
            fail(String.format(""getEphemerals(%s) didn't callback within %d seconds"", checkPath, waitForCallbackSecs));
        }
        checkForUnexpectedBehavior(unexpectedBehavior);
    }
",non-flaky,5
84617,apache_zookeeper,GetEphemeralsTest.testGetEphemeralsEmpty,"    @Test
    public void testGetEphemeralsEmpty() throws IOException, KeeperException, InterruptedException {

        final CountDownLatch doneProcessing = new CountDownLatch(1);
        final String checkPath = ""/unknownPath"";
        final int expectedSize = 0;
        final List<String> unexpectedBehavior = new ArrayList<String>();
        zk.getEphemerals(checkPath, (rc, ctx, paths) -> {
            if (paths == null) {
                unexpectedBehavior.add(String.format(""Expected ephemeral count for %s to be %d but was null"", checkPath, expectedSize));
            } else if (paths.size() != expectedSize) {
                unexpectedBehavior.add(String.format(""Expected ephemeral count for %s to be %d but was %d"", checkPath, expectedSize, paths.size()));
            }
            doneProcessing.countDown();
        }, null);
        long waitForCallbackSecs = 2L;
        if (!doneProcessing.await(waitForCallbackSecs, TimeUnit.SECONDS)) {
            fail(String.format(""getEphemerals(%s) didn't callback within %d seconds"", checkPath, waitForCallbackSecs));
        }
        checkForUnexpectedBehavior(unexpectedBehavior);
    }
",non-flaky,5
84618,apache_zookeeper,GetEphemeralsTest.testGetEphemeralsErrors,"    @Test
    public void testGetEphemeralsErrors() throws KeeperException {
        try {
            zk.getEphemerals(null, null, null);
            fail(""Should have thrown a IllegalArgumentException for a null prefixPath"");
        } catch (IllegalArgumentException e) {
            //pass
        }

        try {
            zk.getEphemerals(""no leading slash"", null, null);
            fail(""Should have thrown a IllegalArgumentException "" + ""for a prefix with no leading slash"");
        } catch (IllegalArgumentException e) {
            //pass
        }
    }
",non-flaky,5
84619,apache_zookeeper,ServerConfigTest.setUp,"    @BeforeEach
    public void setUp() {
        serverConfig = new ServerConfig();
    }
",non-flaky,5
84620,apache_zookeeper,ServerConfigTest.testFewArguments,"    @Test
    public void testFewArguments() {
        assertThrows(IllegalArgumentException.class, () -> {
            String[] args = {""2181""};
            serverConfig.parse(args);
        });
    }
",non-flaky,5
84621,apache_zookeeper,ServerConfigTest.testValidArguments,"    @Test
    public void testValidArguments() {
        String[] args = {""2181"", ""/data/dir"", ""60000"", ""10000""};
        serverConfig.parse(args);

        assertEquals(2181, serverConfig.getClientPortAddress().getPort());
        assertTrue(checkEquality(""/data/dir"", serverConfig.getDataDir()));
        assertEquals(60000, serverConfig.getTickTime());
        assertEquals(10000, serverConfig.getMaxClientCnxns());
    }
",non-flaky,5
84622,apache_zookeeper,ServerConfigTest.testTooManyArguments,"    @Test
    public void testTooManyArguments() {
        assertThrows(IllegalArgumentException.class, () -> {
            String[] args = {""2181"", ""/data/dir"", ""60000"", ""10000"", ""9999""};
            serverConfig.parse(args);
        });
    }
",non-flaky,5
84623,apache_zookeeper,ServerConfigTest.testJvmPauseMonitorConfigured,"    @Test
    public void testJvmPauseMonitorConfigured() {
        final Long sleepTime = 444L;
        final Long warnTH = 5555L;
        final Long infoTH = 555L;

        QuorumPeerConfig qpConfig = mock(QuorumPeerConfig.class);
        when(qpConfig.isJvmPauseMonitorToRun()).thenReturn(true);
        when(qpConfig.getJvmPauseSleepTimeMs()).thenReturn(sleepTime);
        when(qpConfig.getJvmPauseWarnThresholdMs()).thenReturn(warnTH);
        when(qpConfig.getJvmPauseInfoThresholdMs()).thenReturn(infoTH);

        serverConfig.readFrom(qpConfig);

        assertEquals(sleepTime, Long.valueOf(serverConfig.getJvmPauseSleepTimeMs()));
        assertEquals(warnTH, Long.valueOf(serverConfig.getJvmPauseWarnThresholdMs()));
        assertEquals(infoTH, Long.valueOf(serverConfig.getJvmPauseInfoThresholdMs()));
        assertTrue(serverConfig.isJvmPauseMonitorToRun());
    }
",non-flaky,5
84624,apache_zookeeper,ClientCnxnSocketTest.setUp,"    @BeforeEach
    public void setUp() {
        ClientCnxnSocketNetty.setTestAllocator(TestByteBufAllocator.getInstance());
    }
",non-flaky,5
84625,apache_zookeeper,ClientCnxnSocketTest.tearDown,"    @AfterEach
    public void tearDown() {
        ClientCnxnSocketNetty.clearTestAllocator();
        TestByteBufAllocator.checkForLeaks();
    }
",non-flaky,5
84626,apache_zookeeper,ClientCnxnSocketTest.testWhenInvalidJuteMaxBufferIsConfiguredIOExceptionIsThrown,"    @Test
    public void testWhenInvalidJuteMaxBufferIsConfiguredIOExceptionIsThrown() {
        ZKClientConfig clientConfig = new ZKClientConfig();
        String value = ""SomeInvalidInt"";
        clientConfig.setProperty(ZKConfig.JUTE_MAXBUFFER, value);
        // verify ClientCnxnSocketNIO creation
        try {
            new ClientCnxnSocketNIO(clientConfig);
            fail(""IOException is expected."");
        } catch (IOException e) {
            assertTrue(e.getMessage().contains(value));
        }
        // verify ClientCnxnSocketNetty creation
        try {
            new ClientCnxnSocketNetty(clientConfig);
            fail(""IOException is expected."");
        } catch (IOException e) {
            assertTrue(e.getMessage().contains(value));
        }

    }
",non-flaky,5
84627,apache_zookeeper,ClientCnxnSocketFragilityTest.testClientCnxnSocketFragility,"    @Test
    public void testClientCnxnSocketFragility() throws Exception {
        System.setProperty(ZKClientConfig.ZOOKEEPER_CLIENT_CNXN_SOCKET,
                FragileClientCnxnSocketNIO.class.getName());
        System.setProperty(ZKClientConfig.ZOOKEEPER_REQUEST_TIMEOUT, ""1000"");
        final int[] clientPorts = new int[SERVER_COUNT];
        StringBuilder sb = new StringBuilder();
        String server;

        for (int i = 0; i < SERVER_COUNT; i++) {
            clientPorts[i] = PortAssignment.unique();
            server = ""server."" + i + ""=127.0.0.1:"" + PortAssignment.unique() + "":""
                    + PortAssignment.unique() + "":participant;127.0.0.1:"" + clientPorts[i];
            sb.append(server + ""\n"");
        }
        String currentQuorumCfgSection = sb.toString();
        MainThread[] mt = new MainThread[SERVER_COUNT];

        for (int i = 0; i < SERVER_COUNT; i++) {
            mt[i] = new MainThread(i, clientPorts[i], currentQuorumCfgSection, false);
            mt[i].start();
        }

        // Ensure server started
        for (int i = 0; i < SERVER_COUNT; i++) {
            assertTrue(ClientBase.waitForServerUp(""127.0.0.1:"" + clientPorts[i], CONNECTION_TIMEOUT),
                    ""waiting for server "" + i + "" being up"");
        }
        String path = ""/testClientCnxnSocketFragility"";
        String data = ""balabala"";
        ClientWatcher watcher = new ClientWatcher();
        zk = new CustomZooKeeper(getCxnString(clientPorts), SESSION_TIMEOUT, watcher);
        watcher.watchFor(zk);

        // Let's see some successful operations
        zk.create(path, data.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        assertEquals(new String(zk.getData(path, false, new Stat())), data);
        assertTrue(!watcher.isSessionExpired());

        // Let's make a broken operation
        socket.mute();
        boolean catchKeeperException = false;
        try {
            zk.getData(path, false, new Stat());
        } catch (KeeperException e) {
            catchKeeperException = true;
            assertFalse(e instanceof KeeperException.SessionExpiredException);
        }
        socket.unmute();
        assertTrue(catchKeeperException);
        assertTrue(!watcher.isSessionExpired());

        GetDataRetryForeverBackgroundTask retryForeverGetData =
                new GetDataRetryForeverBackgroundTask(zk, path);
        retryForeverGetData.startTask();
        // Let's make a broken network
        socket.mute();

        // Let's attempt to close ZooKeeper
        cnxn.attemptClose();

        // Wait some time to expect continuous reconnecting.
        // We try to make reconnecting hit the unsafe region.
        cnxn.waitUntilHitUnsafeRegion();

        // close zk with timeout 1000 milli seconds
        closeZookeeper(zk);
        TimeUnit.MILLISECONDS.sleep(3000);

        // Since we already close zookeeper, we expect that the zk should not be alive.
        assertTrue(!zk.isAlive());
        assertTrue(!watcher.isSessionExpired());

        retryForeverGetData.syncCloseTask();
        for (int i = 0; i < SERVER_COUNT; i++) {
            mt[i].shutdown();
        }
    }
",non-flaky,5
84628,apache_zookeeper,ZKClientConfigTest.testDefaultConfiguration,"    @Test
    public void testDefaultConfiguration() {
        Map<String, String> properties = new HashMap<>();
        properties.put(ZK_SASL_CLIENT_USERNAME, ""zookeeper1"");
        properties.put(LOGIN_CONTEXT_NAME_KEY, ""Client1"");
        properties.put(ENABLE_CLIENT_SASL_KEY, ""true"");
        properties.put(ZOOKEEPER_SERVER_REALM, ""zookeeper/hadoop.hadoop.com"");
        properties.put(DISABLE_AUTO_WATCH_RESET, ""true"");
        properties.put(ZOOKEEPER_CLIENT_CNXN_SOCKET, ""ClientCnxnSocketNetty"");
        properties.put(SECURE_CLIENT, ""true"");

        for (Map.Entry<String, String> e : properties.entrySet()) {
            System.setProperty(e.getKey(), e.getValue());
        }
        /**
         * ZKClientConfig should get initialized with system properties
         */
        ZKClientConfig conf = new ZKClientConfig();
        for (Map.Entry<String, String> e : properties.entrySet()) {
            assertEquals(e.getValue(), conf.getProperty(e.getKey()));
        }
        /**
         * clear properties
         */
        for (Map.Entry<String, String> e : properties.entrySet()) {
            System.clearProperty(e.getKey());
        }

        conf = new ZKClientConfig();
        /**
         * test that all the properties are null
         */
        for (Map.Entry<String, String> e : properties.entrySet()) {
            String result = conf.getProperty(e.getKey());
            assertNull(result);
        }
    }
",non-flaky,5
84629,apache_zookeeper,ZKClientConfigTest.testSystemPropertyValue,"    @Test
    public void testSystemPropertyValue() {
        String clientName = ""zookeeper1"";
        System.setProperty(ZK_SASL_CLIENT_USERNAME, clientName);

        ZKClientConfig conf = new ZKClientConfig();
        assertEquals(conf.getProperty(ZK_SASL_CLIENT_USERNAME), clientName);

        String newClientName = ""zookeeper2"";
        conf.setProperty(ZK_SASL_CLIENT_USERNAME, newClientName);

        assertEquals(conf.getProperty(ZK_SASL_CLIENT_USERNAME), newClientName);
    }
",non-flaky,5
84630,apache_zookeeper,ZKClientConfigTest.testReadConfigurationFile,"    @Test
    public void testReadConfigurationFile() throws IOException, ConfigException {
        File file = File.createTempFile(""clientConfig"", "".conf"", testData);
        file.deleteOnExit();
        Properties clientConfProp = new Properties();
        clientConfProp.setProperty(ENABLE_CLIENT_SASL_KEY, ""true"");
        clientConfProp.setProperty(ZK_SASL_CLIENT_USERNAME, ""ZK"");
        clientConfProp.setProperty(LOGIN_CONTEXT_NAME_KEY, ""MyClient"");
        clientConfProp.setProperty(ZOOKEEPER_SERVER_REALM, ""HADOOP.COM"");
        clientConfProp.setProperty(""dummyProperty"", ""dummyValue"");
        OutputStream io = new FileOutputStream(file);
        try {
            clientConfProp.store(io, ""Client Configurations"");
        } finally {
            io.close();
        }

        ZKClientConfig conf = new ZKClientConfig();
        conf.addConfiguration(file.getAbsolutePath());
        assertEquals(conf.getProperty(ENABLE_CLIENT_SASL_KEY), ""true"");
        assertEquals(conf.getProperty(ZK_SASL_CLIENT_USERNAME), ""ZK"");
        assertEquals(conf.getProperty(LOGIN_CONTEXT_NAME_KEY), ""MyClient"");
        assertEquals(conf.getProperty(ZOOKEEPER_SERVER_REALM), ""HADOOP.COM"");
        assertEquals(conf.getProperty(""dummyProperty""), ""dummyValue"");

        // try to delete it now as we have done with the created file, why to
        // wait for deleteOnExit() deletion
        file.delete();
    }
",non-flaky,5
84631,apache_zookeeper,ZKClientConfigTest.testSetConfiguration,"    @Test
    public void testSetConfiguration() {
        ZKClientConfig conf = new ZKClientConfig();
        String defaultValue = conf.getProperty(ZKClientConfig.ENABLE_CLIENT_SASL_KEY, ZKClientConfig.ENABLE_CLIENT_SASL_DEFAULT);
        if (defaultValue.equals(""true"")) {
            conf.setProperty(ENABLE_CLIENT_SASL_KEY, ""false"");
        } else {
            conf.setProperty(ENABLE_CLIENT_SASL_KEY, ""true"");
        }
        assertTrue(conf.getProperty(ENABLE_CLIENT_SASL_KEY) != defaultValue);
    }
",non-flaky,5
84632,apache_zookeeper,ZKClientConfigTest.testIntegerRetrievalFromProperty,"    @Test
    public void testIntegerRetrievalFromProperty() {
        ZKClientConfig conf = new ZKClientConfig();
        String prop = ""UnSetProperty"" + System.currentTimeMillis();
        int defaultValue = 100;
        // property is not set we should get the default value
        int result = conf.getInt(prop, defaultValue);
        assertEquals(defaultValue, result);

        // property is set but can not be parsed to int, we should get the
        // NumberFormatException
        conf.setProperty(ZKConfig.JUTE_MAXBUFFER, ""InvlaidIntValue123"");
        try {
            result = conf.getInt(ZKConfig.JUTE_MAXBUFFER, defaultValue);
            fail(""NumberFormatException is expected"");
        } catch (NumberFormatException exception) {
            // do nothing
        }
        assertEquals(defaultValue, result);

        // property is set to an valid int, we should get the set value
        int value = ZKClientConfig.CLIENT_MAX_PACKET_LENGTH_DEFAULT;
        conf.setProperty(ZKConfig.JUTE_MAXBUFFER, Integer.toString(value));
        result = conf.getInt(ZKConfig.JUTE_MAXBUFFER, defaultValue);
        assertEquals(value, result);

        // property is set but with white spaces
        value = 12345;
        conf.setProperty(ZKConfig.JUTE_MAXBUFFER, "" "" + value + "" "");
        result = conf.getInt(ZKConfig.JUTE_MAXBUFFER, defaultValue);
        assertEquals(value, result);
    }
",non-flaky,5
84633,apache_zookeeper,ZKClientConfigTest.testIntegerRetrievalFromHexadecimalProperty,"    @Test
    public void testIntegerRetrievalFromHexadecimalProperty() {
        int hexaValue = 0x3000000;
        String wrongValue = ""0xwel"";
        int defaultValue = 100;
        // property is set in hexadecimal value
        ZKClientConfig zkClientConfig = new ZKClientConfig();
        zkClientConfig.setProperty(ZKConfig.JUTE_MAXBUFFER,
                Integer.toString(hexaValue));
        int result = zkClientConfig.getInt(ZKConfig.JUTE_MAXBUFFER, defaultValue);
        assertEquals(result, hexaValue);
        zkClientConfig.setProperty(ZKConfig.JUTE_MAXBUFFER,
                wrongValue);
        try {
            result = zkClientConfig.getInt(ZKConfig.JUTE_MAXBUFFER, defaultValue);
            fail(""NumberFormatException is expected"");
        } catch (NumberFormatException exception) {
            // do nothing
        }
        zkClientConfig.setProperty(ZKConfig.JUTE_MAXBUFFER,
                "" "" + hexaValue + "" "");
        result = zkClientConfig.getInt(ZKConfig.JUTE_MAXBUFFER, defaultValue);
        assertEquals(result, hexaValue);
    }
",non-flaky,5
84634,apache_zookeeper,GetAllChildrenNumberTest.setUp,"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();

        zk = createClient();
        generatePaths(PERSISTENT_CNT, EPHEMERAL_CNT);
    }
",non-flaky,5
84635,apache_zookeeper,GetAllChildrenNumberTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();

        zk.close();
    }
",non-flaky,5
84636,apache_zookeeper,GetAllChildrenNumberTest.testGetAllChildrenNumberSync,"    @Test
    public void testGetAllChildrenNumberSync() throws KeeperException, InterruptedException {
        //a bad case
        try {
            zk.getAllChildrenNumber(null);
            fail(""the path for getAllChildrenNumber must not be null."");
        } catch (IllegalArgumentException e) {
            //expected
        }

        assertEquals(EPHEMERAL_CNT, zk.getAllChildrenNumber(BASE + ""/0""));
        assertEquals(0, zk.getAllChildrenNumber(BASE + ""/0/ephem0""));
        assertEquals(0, zk.getAllChildrenNumber(BASE_EXT));
        assertEquals(PERSISTENT_CNT + PERSISTENT_CNT * EPHEMERAL_CNT, zk.getAllChildrenNumber(BASE));
        // 6(EPHEMERAL) + 2(PERSISTENT) + 3(""/zookeeper,/zookeeper/quota,/zookeeper/config"") + 1(BASE_EXT) + 1(BASE) = 13
        assertEquals(13, zk.getAllChildrenNumber(""/""));
    }
",non-flaky,5
84637,apache_zookeeper,GetAllChildrenNumberTest.testGetAllChildrenNumberAsync,"    @Test
    public void testGetAllChildrenNumberAsync() throws IOException, KeeperException, InterruptedException {

        final CountDownLatch doneProcessing = new CountDownLatch(1);

        zk.getAllChildrenNumber(""/"", (rc, path, ctx, number) -> {
            if (path == null) {
                fail((String.format(""the path of getAllChildrenNumber was null."")));
            }
            assertEquals(13, number);
            doneProcessing.countDown();
        }, null);
        long waitForCallbackSecs = 2L;
        if (!doneProcessing.await(waitForCallbackSecs, TimeUnit.SECONDS)) {
            fail(String.format(""getAllChildrenNumber didn't callback within %d seconds"", waitForCallbackSecs));
        }
    }
",non-flaky,5
84638,apache_zookeeper,MultiResponseTest.testEmptyRoundTrip,"    @Test
    public void testEmptyRoundTrip() throws IOException {
        MultiResponse result = new MultiResponse();
        MultiResponse decodedResult = codeDecode(result);

        assertEquals(result, decodedResult);
        assertEquals(result.hashCode(), decodedResult.hashCode());
    }
",non-flaky,5
84639,apache_zookeeper,EnforceAuthenticationTest.testEnforceAuthenticationOldBehaviour,"    @Test
    public void testEnforceAuthenticationOldBehaviour() throws Exception {
        Map<String, String> prop = new HashMap<>();
        startServer(prop);
        testEnforceAuthOldBehaviour(false);
    }
",non-flaky,5
84640,apache_zookeeper,EnforceAuthenticationTest.testEnforceAuthenticationOldBehaviourWithNetty,"    @Test
    public void testEnforceAuthenticationOldBehaviourWithNetty() throws Exception {
        Map<String, String> prop = new HashMap<>();
        //setting property false should give the same behaviour as when property is not set
        prop.put(removeZooKeeper(AuthenticationHelper.ENFORCE_AUTH_ENABLED), ""false"");
        prop.put(""serverCnxnFactory"", ""org.apache.zookeeper.server.NettyServerCnxnFactory"");
        startServer(prop);
        testEnforceAuthOldBehaviour(true);
    }
",non-flaky,5
84641,apache_zookeeper,EnforceAuthenticationTest.testServerStartShouldFailWhenEnforceAuthSchemeIsNotConfigured,"    @Test
    public void testServerStartShouldFailWhenEnforceAuthSchemeIsNotConfigured() throws Exception {
        Map<String, String> prop = new HashMap<>();
        prop.put(removeZooKeeper(AuthenticationHelper.ENFORCE_AUTH_ENABLED), ""true"");
        testServerCannotStart(prop);
    }
",non-flaky,5
84642,apache_zookeeper,EnforceAuthenticationTest.testServerStartShouldFailWhenAuthProviderIsNotConfigured,"    @Test
    public void testServerStartShouldFailWhenAuthProviderIsNotConfigured() throws Exception {
        Map<String, String> prop = new HashMap<>();
        prop.put(removeZooKeeper(AuthenticationHelper.ENFORCE_AUTH_ENABLED), ""true"");
        prop.put(removeZooKeeper(AuthenticationHelper.ENFORCE_AUTH_SCHEMES), ""sasl"");
        testServerCannotStart(prop);
    }
",non-flaky,5
84643,apache_zookeeper,EnforceAuthenticationTest.testEnforceAuthenticationNewBehaviour,"    @Test
    public void testEnforceAuthenticationNewBehaviour() throws Exception {
        Map<String, String> prop = new HashMap<>();
        prop.put(removeZooKeeper(AuthenticationHelper.ENFORCE_AUTH_ENABLED), ""true"");
        prop.put(removeZooKeeper(AuthenticationHelper.ENFORCE_AUTH_SCHEMES), ""digest"");
        //digest auth provider is started by default, so no need to
        //prop.put(""authProvider.1"", DigestAuthenticationProvider.class.getName());
        startServer(prop);
        testEnforceAuthNewBehaviour(false);
    }
",non-flaky,5
84644,apache_zookeeper,EnforceAuthenticationTest.testEnforceAuthenticationNewBehaviourWithNetty,"    @Test
    public void testEnforceAuthenticationNewBehaviourWithNetty() throws Exception {
        Map<String, String> prop = new HashMap<>();
        prop.put(removeZooKeeper(AuthenticationHelper.ENFORCE_AUTH_ENABLED), ""true"");
        prop.put(removeZooKeeper(AuthenticationHelper.ENFORCE_AUTH_SCHEMES), ""digest"");
        prop.put(""serverCnxnFactory"", ""org.apache.zookeeper.server.NettyServerCnxnFactory"");
        startServer(prop);
        testEnforceAuthNewBehaviour(true);
    }
",non-flaky,5
84645,apache_zookeeper,EnforceAuthenticationTest.testEnforceAuthenticationWithMultipleAuthSchemes,"    @Test
    public void testEnforceAuthenticationWithMultipleAuthSchemes() throws Exception {
        Map<String, String> prop = new HashMap<>();
        prop.put(removeZooKeeper(AuthenticationHelper.ENFORCE_AUTH_ENABLED), ""true"");
        prop.put(removeZooKeeper(AuthenticationHelper.ENFORCE_AUTH_SCHEMES), ""digest,ip"");
        startServer(prop);
        ZKClientConfig config = new ZKClientConfig();
        CountDownLatch countDownLatch = new CountDownLatch(1);
        ZooKeeper client =
            new ZooKeeper(""127.0.0.1:"" + clientPort, CONNECTION_TIMEOUT, getWatcher(countDownLatch),
                config);
        countDownLatch.await();
        // try operation without adding auth info, it should be success as ip auth info is
        // added automatically by server
        String path = ""/newAuth"" + System.currentTimeMillis();
        String data = ""someData"";
        client.create(path, data.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        byte[] data1 = client.getData(path, false, null);
        assertEquals(data, new String(data1));
        client.close();
    }
",non-flaky,5
84646,apache_zookeeper,ZooKeeperTest.testDeleteRecursive,"    @Test
    public void testDeleteRecursive() throws IOException, InterruptedException, KeeperException {
        final ZooKeeper zk = createClient();
        setupDataTree(zk);

        assertTrue(ZKUtil.deleteRecursive(zk, ""/a/c"", 1000));
        List<String> children = zk.getChildren(""/a"", false);
        assertEquals(1, children.size(), ""1 children - c should be deleted "");
        assertTrue(children.contains(""b""));

        assertTrue(ZKUtil.deleteRecursive(zk, ""/a"", 1000));
        assertNull(zk.exists(""/a"", null));
    }
",non-flaky,5
84647,apache_zookeeper,ZooKeeperTest.testDeleteRecursiveFail,"    @Test
    public void testDeleteRecursiveFail() throws IOException, InterruptedException, KeeperException {
        final ZooKeeper zk = createClient();
        setupDataTree(zk);

        ACL deleteProtection = new ACL(ZooDefs.Perms.DELETE, new Id(""digest"", ""user:tl+z3z0vO6PfPfEENfLF96E6pM0=""/* password is test */));
        List<ACL> acls = Arrays.asList(new ACL(ZooDefs.Perms.READ, Ids.ANYONE_ID_UNSAFE), deleteProtection);

        // poison the well
        zk.create(""/a/c/0/surprise"", """".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        assertEquals(1, zk.getACL(""/a/c/0"", new Stat()).size());
        zk.setACL(""/a/c/0"", acls, -1);
        assertEquals(2, zk.getACL(""/a/c/0"", new Stat()).size());

        assertFalse(ZKUtil.deleteRecursive(zk, ""/a/c"", 1000));
        List<String> children = zk.getChildren(""/a"", false);
        assertEquals(2, children.size(), ""2 children - c should fail to be deleted "");
        assertTrue(children.contains(""b""));

        assertTrue(ZKUtil.deleteRecursive(zk, ""/a/b"", 1000));
        children = zk.getChildren(""/a"", false);
        assertEquals(1, children.size(), ""1 children - b should be deleted "");

        // acquire immunity to poison
        zk.addAuthInfo(deleteProtection.getId().getScheme(), ""user:test"".getBytes());

        assertTrue(ZKUtil.deleteRecursive(zk, ""/a"", 1000));
        assertNull(zk.exists(""/a"", null));
    }
",non-flaky,5
84648,apache_zookeeper,ZooKeeperTest.testDeleteRecursiveCli,"    @Test
    public void testDeleteRecursiveCli() throws IOException, InterruptedException, CliException, KeeperException {
        final ZooKeeper zk = createClient();
        // making sure setdata works on /
        zk.setData(""/"", ""some"".getBytes(), -1);
        zk.create(""/a"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/b"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/b/v"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/b/v/1"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/c"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/c/v"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        List<String> children = zk.getChildren(""/a"", false);

        assertEquals(children.size(), 2, ""2 children - b & c should be present "");
        assertTrue(children.contains(""b""));
        assertTrue(children.contains(""c""));

        ZooKeeperMain zkMain = new ZooKeeperMain(zk);
        String cmdstring1 = ""deleteall /a"";
        zkMain.cl.parseCommand(cmdstring1);
        assertFalse(zkMain.processZKCmd(zkMain.cl));
        assertNull(zk.exists(""/a"", null));
    }
",non-flaky,5
84649,apache_zookeeper,ZooKeeperTest.processResult,"    @Test
    public void testDeleteRecursiveAsync() throws IOException, InterruptedException, KeeperException {
        final ZooKeeper zk = createClient();
        // making sure setdata works on /
        zk.setData(""/"", ""some"".getBytes(), -1);
        zk.create(""/a"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/b"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/b/v"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/b/v/1"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/c"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/c/v"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        for (int i = 0; i < 50; ++i) {
            zk.create(""/a/c/"" + i, ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        }
        List<String> children = zk.getChildren(""/a"", false);

        assertEquals(children.size(), 2, ""2 children - b & c should be present "");
        assertTrue(children.contains(""b""));
        assertTrue(children.contains(""c""));

        VoidCallback cb = new VoidCallback() {

            @Override
            public void processResult(int rc, String path, Object ctx) {
                synchronized (ctx) {
                    ((AtomicInteger) ctx).set(4);
                    ctx.notify();
                }
            }
",non-flaky,5
84650,apache_zookeeper,ZooKeeperTest.testStatWhenPathDoesNotExist,"    @Test
    public void testStatWhenPathDoesNotExist() throws IOException, InterruptedException, MalformedCommandException {
        final ZooKeeper zk = createClient();
        ZooKeeperMain main = new ZooKeeperMain(zk);
        String cmdstring = ""stat /invalidPath"";
        main.cl.parseCommand(cmdstring);
        try {
            main.processZKCmd(main.cl);
            fail(""As Node does not exist, command should fail by throwing No Node Exception."");
        } catch (CliException e) {
            assertEquals(""Node does not exist: /invalidPath"", e.getMessage());
        }
    }
",non-flaky,5
84651,apache_zookeeper,ZooKeeperTest.testParseWithExtraSpaces,"    @Test
    public void testParseWithExtraSpaces() throws Exception {
        final ZooKeeper zk = createClient();
        ZooKeeperMain zkMain = new ZooKeeperMain(zk);
        String cmdstring = ""      ls       /  "";
        zkMain.cl.parseCommand(cmdstring);
        assertEquals(zkMain.cl.getNumArguments(), 2, ""Spaces also considered as characters"");
        assertEquals(zkMain.cl.getCmdArgument(0), ""ls"", ""ls is not taken as first argument"");
        assertEquals(zkMain.cl.getCmdArgument(1), ""/"", ""/ is not taken as second argument"");
    }
",non-flaky,5
84652,apache_zookeeper,ZooKeeperTest.testParseWithQuotes,"    @Test
    public void testParseWithQuotes() throws Exception {
        final ZooKeeper zk = createClient();
        ZooKeeperMain zkMain = new ZooKeeperMain(zk);
        for (String quoteChar : new String[]{""'"", ""\""""}) {
            String cmdstring = String.format(""create /node %1$squoted data%1$s"", quoteChar);
            zkMain.cl.parseCommand(cmdstring);
            assertEquals(zkMain.cl.getNumArguments(), 3, ""quotes combine arguments"");
            assertEquals(zkMain.cl.getCmdArgument(0), ""create"", ""create is not taken as first argument"");
            assertEquals(zkMain.cl.getCmdArgument(1), ""/node"", ""/node is not taken as second argument"");
            assertEquals(zkMain.cl.getCmdArgument(2), ""quoted data"", ""quoted data is not taken as third argument"");
        }
    }
",non-flaky,5
84653,apache_zookeeper,ZooKeeperTest.testParseWithMixedQuotes,"    @Test
    public void testParseWithMixedQuotes() throws Exception {
        final ZooKeeper zk = createClient();
        ZooKeeperMain zkMain = new ZooKeeperMain(zk);
        for (String[] quoteChars : new String[][]{{""'"", ""\""""}, {""\"""", ""'""}}) {
            String outerQuotes = quoteChars[0];
            String innerQuotes = quoteChars[1];
            String cmdstring = String.format(""create /node %1$s%2$squoted data%2$s%1$s"", outerQuotes, innerQuotes);
            zkMain.cl.parseCommand(cmdstring);
            assertEquals(zkMain.cl.getNumArguments(), 3, ""quotes combine arguments"");
            assertEquals(zkMain.cl.getCmdArgument(0), ""create"", ""create is not taken as first argument"");
            assertEquals(zkMain.cl.getCmdArgument(1), ""/node"", ""/node is not taken as second argument"");
            assertEquals(zkMain.cl.getCmdArgument(2), innerQuotes + ""quoted data"" + innerQuotes,
                    ""quoted data is not taken as third argument"");
        }
    }
",non-flaky,5
84654,apache_zookeeper,ZooKeeperTest.testParseWithEmptyQuotes,"    @Test
    public void testParseWithEmptyQuotes() throws Exception {
        final ZooKeeper zk = createClient();
        ZooKeeperMain zkMain = new ZooKeeperMain(zk);
        String cmdstring = ""create /node ''"";
        zkMain.cl.parseCommand(cmdstring);
        assertEquals(zkMain.cl.getNumArguments(), 3, ""empty quotes should produce arguments"");
        assertEquals(zkMain.cl.getCmdArgument(0), ""create"", ""create is not taken as first argument"");
        assertEquals(zkMain.cl.getCmdArgument(1), ""/node"", ""/node is not taken as second argument"");
        assertEquals(zkMain.cl.getCmdArgument(2), """", ""empty string is not taken as third argument"");
    }
",non-flaky,5
84655,apache_zookeeper,ZooKeeperTest.testParseWithMultipleQuotes,"    @Test
    public void testParseWithMultipleQuotes() throws Exception {
        final ZooKeeper zk = createClient();
        ZooKeeperMain zkMain = new ZooKeeperMain(zk);
        String cmdstring = ""create /node '' ''"";
        zkMain.cl.parseCommand(cmdstring);
        assertEquals(zkMain.cl.getNumArguments(), 4, ""expected 5 arguments"");
        assertEquals(zkMain.cl.getCmdArgument(0), ""create"", ""create is not taken as first argument"");
        assertEquals(zkMain.cl.getCmdArgument(1), ""/node"", ""/node is not taken as second argument"");
        assertEquals(zkMain.cl.getCmdArgument(2), """", ""empty string is not taken as third argument"");
        assertEquals(zkMain.cl.getCmdArgument(3), """", ""empty string is not taken as fourth argument"");
    }
",non-flaky,5
84656,apache_zookeeper,ZooKeeperTest.testNonexistantCommand,"    @Test
    public void testNonexistantCommand() throws Exception {
        testInvalidCommand(""cret -s /node1"", 127);
    }
",non-flaky,5
84657,apache_zookeeper,ZooKeeperTest.testCreateCommandWithoutPath,"    @Test
    public void testCreateCommandWithoutPath() throws Exception {
        testInvalidCommand(""create"", 1);
    }
",non-flaky,5
84658,apache_zookeeper,ZooKeeperTest.testCreateEphemeralCommandWithoutPath,"    @Test
    public void testCreateEphemeralCommandWithoutPath() throws Exception {
        testInvalidCommand(""create -e "", 1);
    }
",non-flaky,5
86038,graylog2_graylog2-server,NotificationResourceHandlerTest.testExecution,"    @Test
    public void testExecution() throws EventNotificationException {
        notificationResourceHandler.test(getHttpNotification(), ""testUser"");

        ArgumentCaptor<EventNotificationContext> captor = ArgumentCaptor.forClass(EventNotificationContext.class);
        verify(eventNotification, times(1)).execute(captor.capture());

        assertThat(captor.getValue()).satisfies(ctx -> {
            assertThat(ctx.event().message()).isEqualTo(""Notification test message triggered from user <testUser>"");
            assertThat(ctx.notificationId()).isEqualTo(NotificationTestData.TEST_NOTIFICATION_ID);
            assertThat(ctx.notificationConfig().type()).isEqualTo(HTTPEventNotificationConfig.TYPE_NAME);
            assertThat(ctx.eventDefinition().get().title()).isEqualTo(""Event Definition Test Title"");
        });
    }
",non-flaky,5
86039,graylog2_graylog2-server,NotificationDtoTest.testValidateWithEmptyTitle,"    @Test
    public void testValidateWithEmptyTitle() {
        final NotificationDto invalidNotification = getHttpNotification().toBuilder().title("""").build();
        final ValidationResult validationResult = invalidNotification.validate();
        assertThat(validationResult.failed()).isTrue();
        assertThat(validationResult.getErrors()).containsOnlyKeys(""title"");
    }
",non-flaky,5
86040,graylog2_graylog2-server,NotificationDtoTest.testValidateWithEmptyConfig,"    @Test
    public void testValidateWithEmptyConfig() {
        final NotificationDto invalidNotification = NotificationDto.builder()
                .title(""Foo"")
                .description("""")
                .config(new EventNotificationConfig.FallbackNotificationConfig())
                .build();
        final ValidationResult validationResult = invalidNotification.validate();
        assertThat(validationResult.failed()).isTrue();
        assertThat(validationResult.getErrors()).containsOnlyKeys(""config"");
    }
",non-flaky,5
86041,graylog2_graylog2-server,NotificationDtoTest.testValidateHttpWithEmptyConfigParameters,"    @Test
    public void testValidateHttpWithEmptyConfigParameters() {
        final HTTPEventNotificationConfig emptyConfig = HTTPEventNotificationConfig.Builder.create()
                .url("""")
                .build();
        final NotificationDto emptyNotification = getHttpNotification().toBuilder().config(emptyConfig).build();
        final ValidationResult validationResult = emptyNotification.validate();
        assertThat(validationResult.failed()).isTrue();
        assertThat(validationResult.getErrors()).containsOnlyKeys(""url"");
    }
",non-flaky,5
86042,graylog2_graylog2-server,NotificationDtoTest.testValidateEmailWithEmptyConfigParameters,"    @Test
    public void testValidateEmailWithEmptyConfigParameters() {
        final EmailEventNotificationConfig emptyConfig = EmailEventNotificationConfig.Builder.create()
                .sender("""")
                .subject("""")
                .bodyTemplate("""")
                .build();
        final NotificationDto emptyNotification = getEmailNotification().toBuilder().config(emptyConfig).build();
        final ValidationResult validationResult = emptyNotification.validate();
        assertThat(validationResult.failed()).isTrue();
        assertThat(validationResult.getErrors().size()).isEqualTo(4);
        assertThat(validationResult.getErrors()).containsOnlyKeys(""subject"", ""sender"", ""body_template"", ""recipients"");
    }
",non-flaky,5
86043,graylog2_graylog2-server,NotificationDtoTest.testValidateLegacyWithEmptyConfigParameters,"    @Test
    public void testValidateLegacyWithEmptyConfigParameters() {
        final LegacyAlarmCallbackEventNotificationConfig emptyConfig = LegacyAlarmCallbackEventNotificationConfig.Builder.create()
                .callbackType("""")
                .configuration(new HashMap<>())
                .build();
        final NotificationDto emptyNotification = getLegacyNotification().toBuilder().config(emptyConfig).build();
        final ValidationResult validationResult = emptyNotification.validate();
        assertThat(validationResult.failed()).isTrue();
        assertThat(validationResult.getErrors()).containsOnlyKeys(""callback_type"");
    }
",non-flaky,5
86044,graylog2_graylog2-server,NotificationDtoTest.testValidHttpNotification,"    @Test
    public void testValidHttpNotification() {
        final NotificationDto validNotification = getHttpNotification();

        final ValidationResult validationResult = validNotification.validate();
        assertThat(validationResult.failed()).isFalse();
        assertThat(validationResult.getErrors().size()).isEqualTo(0);
    }
",non-flaky,5
86045,graylog2_graylog2-server,NotificationDtoTest.testValidEmailNotification,"    @Test
    public void testValidEmailNotification() {
        final NotificationDto validNotification = getEmailNotification();

        final ValidationResult validationResult = validNotification.validate();
        assertThat(validationResult.failed()).isFalse();
        assertThat(validationResult.getErrors().size()).isEqualTo(0);
    }
",non-flaky,5
86046,graylog2_graylog2-server,NotificationDtoTest.testValidLegacyNotification,"    @Test
    public void testValidLegacyNotification() {
        final NotificationDto validNotification = getLegacyNotification();

        final ValidationResult validationResult = validNotification.validate();
        assertThat(validationResult.failed()).isFalse();
        assertThat(validationResult.getErrors().size()).isEqualTo(0);
    }
",non-flaky,5
86047,graylog2_graylog2-server,EventProcessorDependencyCheckTest.canProcessTimerange,"    @Test
    public void canProcessTimerange() {
        final DateTime now = DateTime.now(DateTimeZone.UTC);

        final EventProcessorStateDto stateDto1 = EventProcessorStateDto.builder()
                .eventDefinitionId(""a"")
                .minProcessedTimestamp(now.minusDays(1))
                .maxProcessedTimestamp(now)
                .build();
        final EventProcessorStateDto stateDto2 = EventProcessorStateDto.builder()
                .eventDefinitionId(""b"")
                .minProcessedTimestamp(now.minusDays(1))
                .maxProcessedTimestamp(now.minusHours(1))
                .build();
        final EventProcessorStateDto stateDto3 = EventProcessorStateDto.builder()
                .eventDefinitionId(""c"")
                .minProcessedTimestamp(now.minusDays(1))
                .maxProcessedTimestamp(now.minusHours(2))
                .build();

        // No state objects yet
        assertThat(dependencyCheck.canProcessTimerange(now, ImmutableSet.of(""a""))).isFalse();

        stateService.setState(stateDto1);
        stateService.setState(stateDto2);
        stateService.setState(stateDto3);

        // No state object has processedTimerageEnd >= now + 1h
        assertThat(dependencyCheck.canProcessTimerange(now.plusHours(1), ImmutableSet.of(""a""))).isFalse();

        // Only processor ""a"" has been processed at ""now""
        assertThat(dependencyCheck.canProcessTimerange(now, ImmutableSet.of(""a""))).isTrue();
        assertThat(dependencyCheck.canProcessTimerange(now, ImmutableSet.of(""a"", ""b""))).isFalse();
        assertThat(dependencyCheck.canProcessTimerange(now, ImmutableSet.of(""a"", ""c""))).isFalse();
        assertThat(dependencyCheck.canProcessTimerange(now, ImmutableSet.of(""a"", ""b"", ""c""))).isFalse();
        assertThat(dependencyCheck.canProcessTimerange(now, ImmutableSet.of(""b""))).isFalse();
        assertThat(dependencyCheck.canProcessTimerange(now, ImmutableSet.of(""c""))).isFalse();

        // Only processors ""a"" and ""b"" have been processed at now - 1h
        assertThat(dependencyCheck.canProcessTimerange(now.minusHours(1), ImmutableSet.of(""a"", ""b""))).isTrue();
        assertThat(dependencyCheck.canProcessTimerange(now.minusHours(1), ImmutableSet.of(""a"", ""c""))).isFalse();

        // Processors ""a"", ""b"" and ""c"" have been processed at now - 2h
        assertThat(dependencyCheck.canProcessTimerange(now.minusHours(2), ImmutableSet.of(""a"", ""b"", ""c""))).isTrue();
        assertThat(dependencyCheck.canProcessTimerange(now.minusHours(2), ImmutableSet.of(""a"", ""b""))).isTrue();
        assertThat(dependencyCheck.canProcessTimerange(now.minusHours(2), ImmutableSet.of(""a"", ""c""))).isTrue();
        assertThat(dependencyCheck.canProcessTimerange(now.minusHours(2), ImmutableSet.of(""a""))).isTrue();
        assertThat(dependencyCheck.canProcessTimerange(now.minusHours(2), ImmutableSet.of(""b""))).isTrue();
        assertThat(dependencyCheck.canProcessTimerange(now.minusHours(2), ImmutableSet.of(""c""))).isTrue();
    }
",non-flaky,5
86048,graylog2_graylog2-server,EventProcessorDependencyCheckTest.hasMessagesIndexedUpTo,"    @Test
    public void hasMessagesIndexedUpTo() {
        final DateTime timestamp = DateTime.now(DateTimeZone.UTC);

        when(dbProcessingStatusService.earliestPostIndexingTimestamp()).thenReturn(Optional.of(timestamp));

        assertThat(dependencyCheck.hasMessagesIndexedUpTo(timestamp)).isTrue();
        assertThat(dependencyCheck.hasMessagesIndexedUpTo(timestamp.minusHours(1))).isTrue();
        assertThat(dependencyCheck.hasMessagesIndexedUpTo(timestamp.plusHours(1))).isFalse();

        // The method should always return false if there is no value for the max indexed timestamp available
        when(dbProcessingStatusService.earliestPostIndexingTimestamp()).thenReturn(Optional.empty());

        assertThat(dependencyCheck.hasMessagesIndexedUpTo(timestamp)).isFalse();
        assertThat(dependencyCheck.hasMessagesIndexedUpTo(timestamp.minusHours(1))).isFalse();
        assertThat(dependencyCheck.hasMessagesIndexedUpTo(timestamp.plusHours(1))).isFalse();
    }
",non-flaky,5
86049,graylog2_graylog2-server,NotificationGracePeriodServiceTest.falseWithDisabledGracePeriod,"    @Test
    public void falseWithDisabledGracePeriod() {
        final NotificationGracePeriodService notificationGracePeriodService = new NotificationGracePeriodService();

        when(settings.gracePeriodMs()).thenReturn(0L);
        when(definition.notificationSettings()).thenReturn(settings);
        when(definition.id()).thenReturn(""1234"");

        final Event event = new TestEvent();
        event.setKeyTuple(ImmutableList.of(""testkey""));
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event)).isFalse();
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event)).isFalse();
    }
",non-flaky,5
86050,graylog2_graylog2-server,NotificationGracePeriodServiceTest.withinGracePeriod,"    @Test
    public void withinGracePeriod() {
        final NotificationGracePeriodService notificationGracePeriodService = new NotificationGracePeriodService();

        when(settings.gracePeriodMs()).thenReturn(10L);
        when(definition.notificationSettings()).thenReturn(settings);
        when(definition.id()).thenReturn(""1234"");

        final Event event = new TestEvent();
        event.setKeyTuple(ImmutableList.of(""testkey""));
        final Event event2 = new TestEvent();
        event2.setKeyTuple(ImmutableList.of(""testkey""));
        event2.setEventTimestamp(event.getEventTimestamp().plus(5L));
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event)).isFalse();
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event2)).isTrue();
    }
",non-flaky,5
86051,graylog2_graylog2-server,NotificationGracePeriodServiceTest.outsideGracePeriod,"    @Test
    public void outsideGracePeriod() {
        final NotificationGracePeriodService notificationGracePeriodService = new NotificationGracePeriodService();

        when(settings.gracePeriodMs()).thenReturn(10L);
        when(definition.notificationSettings()).thenReturn(settings);
        when(definition.id()).thenReturn(""1234"");

        final Event event = new TestEvent();
        event.setKeyTuple(ImmutableList.of(""testkey""));
        final Event event2 = new TestEvent();
        event2.setKeyTuple(ImmutableList.of(""testkey""));
        event2.setEventTimestamp(event.getEventTimestamp().plus(11L));
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event)).isFalse();
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event2)).isFalse();
    }
",non-flaky,5
86052,graylog2_graylog2-server,NotificationGracePeriodServiceTest.insideThenInsideGracePeriod,"    @Test
    public void insideThenInsideGracePeriod() {
        final NotificationGracePeriodService notificationGracePeriodService = new NotificationGracePeriodService();

        when(settings.gracePeriodMs()).thenReturn(10L);
        when(definition.notificationSettings()).thenReturn(settings);
        when(definition.id()).thenReturn(""1234"");

        final Event event = new TestEvent(DateTime.now(UTC), ""testkey"");
        final Event event2 = new TestEvent(event.getEventTimestamp().plus(5L), ""testkey"");
        final Event event3 = new TestEvent(event2.getEventTimestamp().plus(4L), ""testkey"");

        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event)).isFalse();
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event2)).isTrue();
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event3)).isTrue();
    }
",non-flaky,5
86053,graylog2_graylog2-server,NotificationGracePeriodServiceTest.insideOutsideInsideGracePeriod,"    @Test
    public void insideOutsideInsideGracePeriod() {
        final NotificationGracePeriodService notificationGracePeriodService = new NotificationGracePeriodService();

        when(settings.gracePeriodMs()).thenReturn(10L);
        when(definition.notificationSettings()).thenReturn(settings);
        when(definition.id()).thenReturn(""1234"");

        final Event event = new TestEvent(DateTime.now(UTC), ""testkey"");
        final Event event2 = new TestEvent(event.getEventTimestamp().plus(5L), ""testkey"");
        final Event event3 = new TestEvent(event2.getEventTimestamp().plus(6L), ""testkey"");
        final Event event4 = new TestEvent(event3.getEventTimestamp().plus(6L), ""testkey"");

        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event)).isFalse();
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event2)).isTrue();
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event3)).isFalse();
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event4)).isTrue();
    }
",non-flaky,5
86054,graylog2_graylog2-server,NotificationGracePeriodServiceTest.differentKey,"    @Test
    public void differentKey() {
        final NotificationGracePeriodService notificationGracePeriodService = new NotificationGracePeriodService();

        when(settings.gracePeriodMs()).thenReturn(10L);
        when(definition.notificationSettings()).thenReturn(settings);
        when(definition.id()).thenReturn(""1234"");

        final Event event = new TestEvent();
        event.setKeyTuple(ImmutableList.of(""testkey""));
        final Event event2 = new TestEvent();
        event2.setKeyTuple(ImmutableList.of(""otherkey""));
        event2.setEventTimestamp(event.getEventTimestamp().plus(1L));
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event)).isFalse();
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event2)).isFalse();
    }
",non-flaky,5
86055,graylog2_graylog2-server,NotificationGracePeriodServiceTest.differentNotification,"    @Test
    public void differentNotification() {
        final NotificationGracePeriodService notificationGracePeriodService = new NotificationGracePeriodService();

        when(settings.gracePeriodMs()).thenReturn(10L);
        when(definition.notificationSettings()).thenReturn(settings);
        when(definition.id()).thenReturn(""1234"");

        final Event event = new TestEvent();
        event.setKeyTuple(ImmutableList.of(""testkey""));
        final Event event2 = new TestEvent();
        event2.setKeyTuple(ImmutableList.of(""testkey""));
        event2.setEventTimestamp(event.getEventTimestamp().plus(1L));
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event)).isFalse();
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""4242"", event2)).isFalse();
    }
",non-flaky,5
86056,graylog2_graylog2-server,NotificationGracePeriodServiceTest.emptyKey,"    @Test
    public void emptyKey() {
        final NotificationGracePeriodService notificationGracePeriodService = new NotificationGracePeriodService();

        when(settings.gracePeriodMs()).thenReturn(10L);
        when(definition.notificationSettings()).thenReturn(settings);
        when(definition.id()).thenReturn(""1234"");

        final Event event = new TestEvent();
        event.setKeyTuple(ImmutableList.of());
        final Event event2 = new TestEvent();
        event.setKeyTuple(ImmutableList.of());
        event2.setEventTimestamp(event.getEventTimestamp().plus(1L));
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event)).isFalse();
        assertThat(notificationGracePeriodService.inGracePeriod(definition, ""5678"", event2)).isTrue();
    }
",non-flaky,5
86057,graylog2_graylog2-server,AggregationFunctionTest.testFunctionMapping,"    @Test
    public void testFunctionMapping() {
        testToSeriesSpec(AggregationFunction.AVG, Average.class);
        testToSeriesSpec(AggregationFunction.CARD, Cardinality.class);
        testToSeriesSpec(AggregationFunction.COUNT, Count.class);
        testToSeriesSpec(AggregationFunction.MAX, Max.class);
        testToSeriesSpec(AggregationFunction.MIN, Min.class);
        testToSeriesSpec(AggregationFunction.STDDEV, StdDev.class);
        testToSeriesSpec(AggregationFunction.SUM, Sum.class);
        testToSeriesSpec(AggregationFunction.SUMOFSQUARES, SumOfSquares.class);
        testToSeriesSpec(AggregationFunction.VARIANCE, Variance.class);
    }
",non-flaky,5
86058,graylog2_graylog2-server,AggregationFunctionTest.fieldRequirements,"    @Test
    public void fieldRequirements() {
        assertThatCode(() -> AggregationFunction.AVG.toSeriesSpec(""a"", null))
                .hasMessageContaining(""<avg>"")
                .isInstanceOf(IllegalArgumentException.class);

        assertThatCode(() -> AggregationFunction.CARD.toSeriesSpec(""a"", null))
                .hasMessageContaining(""<card>"")
                .isInstanceOf(IllegalArgumentException.class);

        assertThatCode(() -> AggregationFunction.COUNT.toSeriesSpec(""a"", null))
                .doesNotThrowAnyException();

        assertThatCode(() -> AggregationFunction.MAX.toSeriesSpec(""a"", null))
                .hasMessageContaining(""<max>"")
                .isInstanceOf(IllegalArgumentException.class);

        assertThatCode(() -> AggregationFunction.MIN.toSeriesSpec(""a"", null))
                .hasMessageContaining(""<min>"")
                .isInstanceOf(IllegalArgumentException.class);

        assertThatCode(() -> AggregationFunction.STDDEV.toSeriesSpec(""a"", null))
                .hasMessageContaining(""<stddev>"")
                .isInstanceOf(IllegalArgumentException.class);

        assertThatCode(() -> AggregationFunction.SUM.toSeriesSpec(""a"", null))
                .hasMessageContaining(""<sum>"")
                .isInstanceOf(IllegalArgumentException.class);

        assertThatCode(() -> AggregationFunction.SUMOFSQUARES.toSeriesSpec(""a"", null))
                .hasMessageContaining(""<sumofsquares>"")
                .isInstanceOf(IllegalArgumentException.class);

        assertThatCode(() -> AggregationFunction.VARIANCE.toSeriesSpec(""a"", null))
                .hasMessageContaining(""<variance>"")
                .isInstanceOf(IllegalArgumentException.class);
    }
",non-flaky,5
86059,graylog2_graylog2-server,AggregationEventProcessorConfigTest.toJobSchedulerConfig,"    @Test
    public void toJobSchedulerConfig() {
        final EventDefinitionDto dto = dbService.get(""54e3deadbeefdeadbeefaffe"").orElse(null);

        assertThat(dto).isNotNull();

        assertThat(dto.config().toJobSchedulerConfig(dto, clock)).isPresent().get().satisfies(schedulerConfig -> {
            assertThat(schedulerConfig.jobDefinitionConfig()).satisfies(jobDefinitionConfig -> {
                assertThat(jobDefinitionConfig).isInstanceOf(EventProcessorExecutionJob.Config.class);

                final EventProcessorExecutionJob.Config config = (EventProcessorExecutionJob.Config) jobDefinitionConfig;

                assertThat(config.eventDefinitionId()).isEqualTo(dto.id());
                assertThat(config.processingWindowSize()).isEqualTo(300000);
                assertThat(config.processingHopSize()).isEqualTo(300000);
                assertThat(config.parameters()).isEqualTo(AggregationEventProcessorParameters.builder()
                        .timerange(AbsoluteRange.create(clock.nowUTC().minus(300000), clock.nowUTC()))
                        .build());
            });

            assertThat(schedulerConfig.schedule()).satisfies(schedule -> {
                assertThat(schedule).isInstanceOf(IntervalJobSchedule.class);

                final IntervalJobSchedule config = (IntervalJobSchedule) schedule;

                assertThat(config.interval()).isEqualTo(300000);
                assertThat(config.unit()).isEqualTo(TimeUnit.MILLISECONDS);
            });
        });
    }
",non-flaky,5
86060,graylog2_graylog2-server,AggregationEventProcessorConfigTest.testValidateWithInvalidTimeRange,"    @Test
    public void testValidateWithInvalidTimeRange() {
        final AggregationEventProcessorConfig invalidConfig1 = getConfig().toBuilder()
            .searchWithinMs(-1)
            .build();

        final ValidationResult validationResult1 = invalidConfig1.validate();
        assertThat(validationResult1.failed()).isTrue();
        assertThat(validationResult1.getErrors()).containsOnlyKeys(""search_within_ms"");

        final AggregationEventProcessorConfig invalidConfig2 = invalidConfig1.toBuilder()
            .searchWithinMs(0)
            .build();

        final ValidationResult validationResult2 = invalidConfig2.validate();
        assertThat(validationResult2.failed()).isTrue();
        assertThat(validationResult2.getErrors()).containsOnlyKeys(""search_within_ms"");
    }
",non-flaky,5
86061,graylog2_graylog2-server,AggregationEventProcessorConfigTest.testValidateWithInvalidExecutionTime,"    @Test
    public void testValidateWithInvalidExecutionTime() {
        final AggregationEventProcessorConfig invalidConfig1 = getConfig().toBuilder()
            .executeEveryMs(-1)
            .build();

        final ValidationResult validationResult1 = invalidConfig1.validate();
        assertThat(validationResult1.failed()).isTrue();
        assertThat(validationResult1.getErrors()).containsOnlyKeys(""execute_every_ms"");

        final AggregationEventProcessorConfig invalidConfig2 = invalidConfig1.toBuilder()
            .executeEveryMs(0)
            .build();

        final ValidationResult validationResult2 = invalidConfig2.validate();
        assertThat(validationResult2.failed()).isTrue();
        assertThat(validationResult2.getErrors()).containsOnlyKeys(""execute_every_ms"");
    }
",non-flaky,5
86062,graylog2_graylog2-server,AggregationEventProcessorConfigTest.testValidateWithIncompleteAggregationOptions,"    @Test
    public void testValidateWithIncompleteAggregationOptions() {
        AggregationEventProcessorConfig invalidConfig = getConfig().toBuilder()
            .groupBy(ImmutableList.of(""foo""))
            .build();

        ValidationResult validationResult = invalidConfig.validate();
        assertThat(validationResult.failed()).isTrue();
        assertThat(validationResult.getErrors()).containsOnlyKeys(""series"", ""conditions"");

        invalidConfig = getConfig().toBuilder()
            .series(ImmutableList.of(this.getSeries()))
            .build();

        validationResult = invalidConfig.validate();
        assertThat(validationResult.failed()).isTrue();
        assertThat(validationResult.getErrors()).containsOnlyKeys(""conditions"");

        invalidConfig = getConfig().toBuilder()
            .conditions(this.getConditions())
            .build();

        validationResult = invalidConfig.validate();
        assertThat(validationResult.failed()).isTrue();
        assertThat(validationResult.getErrors()).containsOnlyKeys(""series"");
    }
",non-flaky,5
86063,graylog2_graylog2-server,AggregationEventProcessorConfigTest.testValidConfiguration,"    @Test
    public void testValidConfiguration() {
        final ValidationResult validationResult = getConfig().validate();
        assertThat(validationResult.failed()).isFalse();
        assertThat(validationResult.getErrors().size()).isEqualTo(0);
    }
",non-flaky,5
86064,graylog2_graylog2-server,AggregationEventProcessorConfigTest.testValidFilterConfiguration,"    @Test
    public void testValidFilterConfiguration() {
        final AggregationEventProcessorConfig config = getConfig().toBuilder()
            .query(""foo"")
            .streams(ImmutableSet.of(""1"", ""2""))
            .build();

        final ValidationResult validationResult = config.validate();
        assertThat(validationResult.failed()).isFalse();
        assertThat(validationResult.getErrors().size()).isEqualTo(0);
    }
",non-flaky,5
86065,graylog2_graylog2-server,AggregationEventProcessorConfigTest.testValidAggregationConfiguration,"    @Test
    public void testValidAggregationConfiguration() {
        final AggregationEventProcessorConfig config = getConfig().toBuilder()
            .groupBy(ImmutableList.of(""bar""))
            .series(ImmutableList.of(this.getSeries()))
            .conditions(this.getConditions())
            .build();

        final ValidationResult validationResult = config.validate();
        assertThat(validationResult.failed()).isFalse();
        assertThat(validationResult.getErrors().size()).isEqualTo(0);
    }
",non-flaky,5
86066,graylog2_graylog2-server,AggregationEventProcessorConfigTest.requiredPermissions,"    @Test
    public void requiredPermissions() {
        assertThat(dbService.get(""54e3deadbeefdeadbeefaffe"")).get().satisfies(definition -> {
            assertThat(definition.config().requiredPermissions()).containsOnly(""streams:read:stream-a"", ""streams:read:stream-b"");
        });
    }
",non-flaky,5
86067,graylog2_graylog2-server,AggregationEventProcessorConfigTest.requiredPermissionsWithEmptyStreams,"    @Test
    public void requiredPermissionsWithEmptyStreams() {
        assertThat(dbService.get(""54e3deadbeefdeadbeefafff"")).get().satisfies(definition -> {
            assertThat(definition.config().requiredPermissions()).containsOnly(""streams:read"");
        });
    }
",non-flaky,5
86068,graylog2_graylog2-server,AggregationEventProcessorTest.testEventsFromAggregationResult,"    @Test
    public void testEventsFromAggregationResult() {
        final DateTime now = DateTime.now(DateTimeZone.UTC);
        final AbsoluteRange timerange = AbsoluteRange.create(now.minusHours(1), now.plusHours(1));

        // We expect to get the end of the aggregation timerange as event time
        final TestEvent event1 = new TestEvent(timerange.to());
        final TestEvent event2 = new TestEvent(timerange.to());
        when(eventFactory.createEvent(any(EventDefinition.class), eq(now), anyString()))
                .thenReturn(event1)  // first invocation return value
                .thenReturn(event2); // second invocation return value

        final EventDefinitionDto eventDefinitionDto = EventDefinitionDto.builder()
                .id(""dto-id-1"")
                .title(""Test Aggregation"")
                .description(""A test aggregation event processors"")
                .priority(1)
                .alert(false)
                .notificationSettings(EventNotificationSettings.withGracePeriod(60000))
                .config(AggregationEventProcessorConfig.builder()
                        .query("""")
                        .streams(ImmutableSet.of(""stream-2""))
                        .groupBy(ImmutableList.of(""group_field_one"", ""group_field_two""))
                        .series(ImmutableList.of())
                        .conditions(null)
                        .searchWithinMs(30000)
                        .executeEveryMs(30000)
                        .build())
                .keySpec(ImmutableList.of())
                .build();
        final AggregationEventProcessorParameters parameters = AggregationEventProcessorParameters.builder()
                .timerange(timerange)
                .build();

        final AggregationEventProcessor eventProcessor = new AggregationEventProcessor(eventDefinitionDto, searchFactory, eventProcessorDependencyCheck, stateService, moreSearch, streamService, messages);

        final AggregationResult result = AggregationResult.builder()
                .effectiveTimerange(timerange)
                .totalAggregatedMessages(1)
                .sourceStreams(ImmutableSet.of(""stream-1"", ""stream-2""))
                .keyResults(ImmutableList.of(
                        AggregationKeyResult.builder()
                                .key(ImmutableList.of(""one"", ""two""))
                                .timestamp(now)
                                .seriesValues(ImmutableList.of(
                                        AggregationSeriesValue.builder()
                                                .key(ImmutableList.of(""a""))
                                                .value(42.0d)
                                                .series(AggregationSeries.builder()
                                                        .id(""abc123"")
                                                        .function(AggregationFunction.COUNT)
                                                        .field(""source"")
                                                        .build())
                                                .build(),
                                        AggregationSeriesValue.builder()
                                                .key(ImmutableList.of(""a""))
                                                .value(23.0d)
                                                .series(AggregationSeries.builder()
                                                        .id(""abc123-no-field"")
                                                        .function(AggregationFunction.COUNT)
                                                        .build())
                                                .build(),
                                        AggregationSeriesValue.builder()
                                                .key(ImmutableList.of(""a""))
                                                .value(1.0d)
                                                .series(AggregationSeries.builder()
                                                        .id(""xyz789"")
                                                        .function(AggregationFunction.CARD)
                                                        .field(""source"")
                                                        .build())
                                                .build()
                                ))
                                .build()
                ))
                .build();

        final ImmutableList<EventWithContext> eventsWithContext = eventProcessor.eventsFromAggregationResult(eventFactory, parameters, result);

        assertThat(eventsWithContext).hasSize(1);

        assertThat(eventsWithContext.get(0)).satisfies(eventWithContext -> {
            final Event event = eventWithContext.event();

            assertThat(event.getId()).isEqualTo(event1.getId());
            assertThat(event.getMessage()).isEqualTo(event1.getMessage());
            assertThat(event.getEventTimestamp()).isEqualTo(timerange.to());
            assertThat(event.getTimerangeStart()).isEqualTo(timerange.from());
            assertThat(event.getTimerangeEnd()).isEqualTo(timerange.to());
            // Should only contain the streams that have been configured in event definition
            assertThat(event.getSourceStreams()).containsOnly(""stream-2"");

            final Message message = eventWithContext.messageContext().orElse(null);

            assertThat(message).isNotNull();
            assertThat(message.getField(""group_field_one"")).isEqualTo(""one"");
            assertThat(message.getField(""group_field_two"")).isEqualTo(""two"");
            assertThat(message.getField(""aggregation_key"")).isEqualTo(""one|two"");
            assertThat(message.getField(""aggregation_value_count_source"")).isEqualTo(42.0d);
            // Make sure that the count with a ""null"" field doesn't include the field in the name
            assertThat(message.getField(""aggregation_value_count"")).isEqualTo(23.0d);
            assertThat(message.getField(""aggregation_value_card_source"")).isEqualTo(1.0d);
        });
    }
",non-flaky,5
86069,graylog2_graylog2-server,AggregationEventProcessorTest.testEventsFromAggregationResultWithConditions,"    @Test
    public void testEventsFromAggregationResultWithConditions() {
        final DateTime now = DateTime.now(DateTimeZone.UTC);
        final AbsoluteRange timerange = AbsoluteRange.create(now.minusHours(1), now.plusHours(1));

        // We expect to get the end of the aggregation timerange as event time
        final TestEvent event1 = new TestEvent(timerange.to());
        final TestEvent event2 = new TestEvent(timerange.to());
        when(eventFactory.createEvent(any(EventDefinition.class), eq(now), anyString()))
                .thenReturn(event1)  // first invocation return value
                .thenReturn(event2); // second invocation return value

        // There should only be one result because the second result's ""abc123"" value is less than 40. (it is 23)
        // See result builder below
        final AggregationConditions conditions = AggregationConditions.builder()
                .expression(Expr.And.create(
                        Expr.Greater.create(Expr.NumberReference.create(""abc123""), Expr.NumberValue.create(40.0d)),
                        Expr.Lesser.create(Expr.NumberReference.create(""xyz789""), Expr.NumberValue.create(2.0d))
                ))
                .build();

        final EventDefinitionDto eventDefinitionDto = EventDefinitionDto.builder()
                .id(""dto-id-1"")
                .title(""Test Aggregation"")
                .description(""A test aggregation event processors"")
                .priority(1)
                .alert(false)
                .notificationSettings(EventNotificationSettings.withGracePeriod(60000))
                .config(AggregationEventProcessorConfig.builder()
                        .query("""")
                        .streams(ImmutableSet.of())
                        .groupBy(ImmutableList.of(""group_field_one"", ""group_field_two""))
                        .series(ImmutableList.of())
                        .conditions(conditions)
                        .searchWithinMs(30000)
                        .executeEveryMs(30000)
                        .build())
                .keySpec(ImmutableList.of())
                .build();
        final AggregationEventProcessorParameters parameters = AggregationEventProcessorParameters.builder()
                .timerange(timerange)
                .build();

        final AggregationEventProcessor eventProcessor = new AggregationEventProcessor(eventDefinitionDto, searchFactory, eventProcessorDependencyCheck, stateService, moreSearch, streamService, messages);

        final AggregationResult result = AggregationResult.builder()
                .effectiveTimerange(timerange)
                .totalAggregatedMessages(1)
                .sourceStreams(ImmutableSet.of(""stream-1"", ""stream-2"", ""stream-3""))
                .keyResults(ImmutableList.of(
                        AggregationKeyResult.builder()
                                .key(ImmutableList.of(""one"", ""two""))
                                .timestamp(now)
                                .seriesValues(ImmutableList.of(
                                        AggregationSeriesValue.builder()
                                                .key(ImmutableList.of(""a""))
                                                .value(42.0d)
                                                .series(AggregationSeries.builder()
                                                        .id(""abc123"")
                                                        .function(AggregationFunction.COUNT)
                                                        .field(""source"")
                                                        .build())
                                                .build(),
                                        AggregationSeriesValue.builder()
                                                .key(ImmutableList.of(""a""))
                                                .value(1.0d)
                                                .series(AggregationSeries.builder()
                                                        .id(""xyz789"")
                                                        .function(AggregationFunction.CARD)
                                                        .field(""source"")
                                                        .build())
                                                .build()
                                ))
                                .build(),
                        AggregationKeyResult.builder()
                                .key(ImmutableList.of(now.toString(), ""one"", ""two""))
                                .seriesValues(ImmutableList.of(
                                        AggregationSeriesValue.builder()
                                                .key(ImmutableList.of(""a""))
                                                .value(23.0d) // Doesn't match condition
                                                .series(AggregationSeries.builder()
                                                        .id(""abc123"")
                                                        .function(AggregationFunction.COUNT)
                                                        .field(""source"")
                                                        .build())
                                                .build(),
                                        AggregationSeriesValue.builder()
                                                .key(ImmutableList.of(""a""))
                                                .value(1.0d)
                                                .series(AggregationSeries.builder()
                                                        .id(""xyz789"")
                                                        .function(AggregationFunction.CARD)
                                                        .field(""source"")
                                                        .build())
                                                .build()
                                ))
                                .build()
                ))
                .build();

        final ImmutableList<EventWithContext> eventsWithContext = eventProcessor.eventsFromAggregationResult(eventFactory, parameters, result);

        assertThat(eventsWithContext).hasSize(1);

        assertThat(eventsWithContext.get(0)).satisfies(eventWithContext -> {
            final Event event = eventWithContext.event();

            assertThat(event.getId()).isEqualTo(event1.getId());
            assertThat(event.getMessage()).isEqualTo(event1.getMessage());
            assertThat(event.getEventTimestamp()).isEqualTo(timerange.to());
            assertThat(event.getTimerangeStart()).isEqualTo(timerange.from());
            assertThat(event.getTimerangeEnd()).isEqualTo(timerange.to());
            // Should contain all streams because when config.streams is empty, we search in all streams
            assertThat(event.getSourceStreams()).containsOnly(""stream-1"", ""stream-2"", ""stream-3"");

            final Message message = eventWithContext.messageContext().orElse(null);

            assertThat(message).isNotNull();
            assertThat(message.getField(""group_field_one"")).isEqualTo(""one"");
            assertThat(message.getField(""group_field_two"")).isEqualTo(""two"");
            assertThat(message.getField(""aggregation_key"")).isEqualTo(""one|two"");
            assertThat(message.getField(""aggregation_value_count_source"")).isEqualTo(42.0d);
            assertThat(message.getField(""aggregation_value_card_source"")).isEqualTo(1.0d);
        });
    }
",non-flaky,5
86070,graylog2_graylog2-server,AggregationEventProcessorTest.createEventsWithFilter,"    @Test
    public void createEventsWithFilter() throws Exception {
        when(eventProcessorDependencyCheck.hasMessagesIndexedUpTo(any(DateTime.class))).thenReturn(true);

        final DateTime now = DateTime.now(DateTimeZone.UTC);
        final AbsoluteRange timerange = AbsoluteRange.create(now.minusHours(1), now.plusHours(1));

        final AggregationEventProcessorConfig config = AggregationEventProcessorConfig.builder()
                .query("""")
                .streams(ImmutableSet.of())
                .groupBy(ImmutableList.of())
                .series(ImmutableList.of())
                .conditions(null)
                .searchWithinMs(30000)
                .executeEveryMs(30000)
                .build();
        final EventDefinitionDto eventDefinitionDto = EventDefinitionDto.builder()
                .id(""dto-id-1"")
                .title(""Test Aggregation"")
                .description(""A test aggregation event processors"")
                .priority(1)
                .alert(false)
                .notificationSettings(EventNotificationSettings.withGracePeriod(60000))
                .config(config)
                .keySpec(ImmutableList.of())
                .build();
        final AggregationEventProcessorParameters parameters = AggregationEventProcessorParameters.builder()
                .timerange(timerange)
                .build();

        final AggregationEventProcessor eventProcessor = new AggregationEventProcessor(eventDefinitionDto, searchFactory, eventProcessorDependencyCheck, stateService, moreSearch, streamService, messages);

        assertThatCode(() -> eventProcessor.createEvents(eventFactory, parameters, (events) -> {})).doesNotThrowAnyException();

        verify(moreSearch, times(1)).scrollQuery(
                eq(config.query()),
                eq(config.streams()),
                eq(config.queryParameters()),
                eq(parameters.timerange()),
                eq(parameters.batchSize()),
                any(MoreSearch.ScrollCallback.class)
        );
        verify(searchFactory, never()).create(eq(config), eq(parameters), any(String.class), eq(eventDefinitionDto));
    }
",non-flaky,5
86071,graylog2_graylog2-server,AggregationEventProcessorTest.createEventsWithoutRequiredMessagesBeingIndexed,"    @Test
    public void createEventsWithoutRequiredMessagesBeingIndexed() throws Exception {
        final DateTime now = DateTime.now(DateTimeZone.UTC);
        final AbsoluteRange timerange = AbsoluteRange.create(now.minusHours(1), now.plusHours(1));

        final AggregationEventProcessorConfig config = AggregationEventProcessorConfig.builder()
                .query("""")
                .streams(ImmutableSet.of())
                .groupBy(ImmutableList.of())
                .series(ImmutableList.of())
                .conditions(null)
                .searchWithinMs(30000)
                .executeEveryMs(30000)
                .build();
        final EventDefinitionDto eventDefinitionDto = EventDefinitionDto.builder()
                .id(""dto-id-1"")
                .title(""Test Aggregation"")
                .description(""A test aggregation event processors"")
                .priority(1)
                .alert(false)
                .notificationSettings(EventNotificationSettings.withGracePeriod(60000))
                .config(config)
                .keySpec(ImmutableList.of())
                .build();
        final AggregationEventProcessorParameters parameters = AggregationEventProcessorParameters.builder()
                .timerange(timerange)
                .build();

        final AggregationEventProcessor eventProcessor = new AggregationEventProcessor(eventDefinitionDto, searchFactory, eventProcessorDependencyCheck, stateService, moreSearch, streamService, messages);

        // If the dependency check returns true, there should be no exception raised and the state service should be called
        when(eventProcessorDependencyCheck.hasMessagesIndexedUpTo(timerange.to())).thenReturn(true);

        assertThatCode(() -> eventProcessor.createEvents(eventFactory, parameters, (events) -> {})).doesNotThrowAnyException();

        verify(stateService, times(1)).setState(""dto-id-1"", timerange.from(), timerange.to());
        verify(moreSearch, times(1)).scrollQuery(
                eq(config.query()),
                eq(config.streams()),
                eq(config.queryParameters()),
                eq(parameters.timerange()),
                eq(parameters.batchSize()),
                any(MoreSearch.ScrollCallback.class)
        );

        reset(stateService, moreSearch, searchFactory); // Rest mocks so we can verify it again

        // If the dependency check returns false, a precondition exception should be raised and the state service not be called
        when(eventProcessorDependencyCheck.hasMessagesIndexedUpTo(timerange.to())).thenReturn(false);

        assertThatCode(() -> eventProcessor.createEvents(eventFactory, parameters, (events) -> {}))
                .hasMessageContaining(eventDefinitionDto.title())
                .hasMessageContaining(eventDefinitionDto.id())
                .hasMessageContaining(timerange.from().toString())
                .hasMessageContaining(timerange.to().toString())
                .isInstanceOf(EventProcessorPreconditionException.class);

        verify(stateService, never()).setState(any(String.class), any(DateTime.class), any(DateTime.class));
        verify(searchFactory, never()).create(any(), any(), any(), any());
        verify(moreSearch, never()).scrollQuery(
                eq(config.query()),
                eq(config.streams()),
                eq(config.queryParameters()),
                eq(parameters.timerange()),
                eq(parameters.batchSize()),
                any(MoreSearch.ScrollCallback.class)
        );
    }
",non-flaky,5
86072,graylog2_graylog2-server,AggregationEventProcessorTest.testEventsFromAggregationResultWithEmptyResultUsesEventDefinitionStreamAsSourceStreams,"    @Test
    public void testEventsFromAggregationResultWithEmptyResultUsesEventDefinitionStreamAsSourceStreams() {
        final DateTime now = DateTime.now(DateTimeZone.UTC);
        final AbsoluteRange timerange = AbsoluteRange.create(now.minusHours(1), now.plusHours(1));

        // We expect to get the end of the aggregation timerange as event time
        final TestEvent event1 = new TestEvent(timerange.to());
        final TestEvent event2 = new TestEvent(timerange.to());
        when(eventFactory.createEvent(any(EventDefinition.class), eq(now), anyString()))
                .thenReturn(event1)  // first invocation return value
                .thenReturn(event2); // second invocation return value

        final EventDefinitionDto eventDefinitionDto = EventDefinitionDto.builder()
                .id(""dto-id-1"")
                .title(""Test Aggregation"")
                .description(""A test aggregation event processors"")
                .priority(1)
                .alert(false)
                .notificationSettings(EventNotificationSettings.withGracePeriod(60000))
                .config(AggregationEventProcessorConfig.builder()
                        .query("""")
                        .streams(ImmutableSet.of(""stream-2""))
                        .groupBy(ImmutableList.of(""group_field_one"", ""group_field_two""))
                        .series(ImmutableList.of())
                        .conditions(null)
                        .searchWithinMs(30000)
                        .executeEveryMs(30000)
                        .build())
                .keySpec(ImmutableList.of())
                .build();
        final AggregationEventProcessorParameters parameters = AggregationEventProcessorParameters.builder()
                .timerange(timerange)
                .build();

        final AggregationEventProcessor eventProcessor = new AggregationEventProcessor(eventDefinitionDto, searchFactory, eventProcessorDependencyCheck, stateService, moreSearch, streamService, messages);

        final AggregationResult result = AggregationResult.builder()
                .effectiveTimerange(timerange)
                .totalAggregatedMessages(0)
                .sourceStreams(ImmutableSet.of()) // No streams in result
                .keyResults(ImmutableList.of(
                        AggregationKeyResult.builder()
                                .key(ImmutableList.of(""one"", ""two""))
                                .timestamp(now)
                                .seriesValues(ImmutableList.of(
                                        AggregationSeriesValue.builder()
                                                .key(ImmutableList.of(""a""))
                                                .value(0.0d)
                                                .series(AggregationSeries.builder()
                                                        .id(""abc123"")
                                                        .function(AggregationFunction.COUNT)
                                                        .build())
                                                .build()
                                ))
                                .build()
                ))
                .build();

        final ImmutableList<EventWithContext> eventsWithContext = eventProcessor.eventsFromAggregationResult(eventFactory, parameters, result);

        assertThat(eventsWithContext).hasSize(1);

        assertThat(eventsWithContext.get(0)).satisfies(eventWithContext -> {
            final Event event = eventWithContext.event();

            assertThat(event.getId()).isEqualTo(event1.getId());
            assertThat(event.getMessage()).isEqualTo(event1.getMessage());
            assertThat(event.getEventTimestamp()).isEqualTo(timerange.to());
            assertThat(event.getTimerangeStart()).isEqualTo(timerange.from());
            assertThat(event.getTimerangeEnd()).isEqualTo(timerange.to());
            // Must contain the stream from the event definition because there is none in the result
            assertThat(event.getSourceStreams()).containsOnly(""stream-2"");

            final Message message = eventWithContext.messageContext().orElse(null);

            assertThat(message).isNotNull();
            assertThat(message.getField(""group_field_one"")).isEqualTo(""one"");
            assertThat(message.getField(""group_field_two"")).isEqualTo(""two"");
            assertThat(message.getField(""aggregation_key"")).isEqualTo(""one|two"");
            assertThat(message.getField(""aggregation_value_count"")).isEqualTo(0.0d);
        });
    }
",non-flaky,5
86073,graylog2_graylog2-server,AggregationEventProcessorTest.testEventsFromAggregationResultWithEmptyResultAndNoConfiguredStreamsUsesAllStreamsAsSourceStreams,"    @Test
    public void testEventsFromAggregationResultWithEmptyResultAndNoConfiguredStreamsUsesAllStreamsAsSourceStreams() {
        final DateTime now = DateTime.now(DateTimeZone.UTC);
        final AbsoluteRange timerange = AbsoluteRange.create(now.minusHours(1), now.plusHours(1));

        // We expect to get the end of the aggregation timerange as event time
        final TestEvent event1 = new TestEvent(timerange.to());
        final TestEvent event2 = new TestEvent(timerange.to());
        when(eventFactory.createEvent(any(EventDefinition.class), eq(now), anyString()))
                .thenReturn(event1)  // first invocation return value
                .thenReturn(event2); // second invocation return value

        when(streamService.loadAll()).thenReturn(ImmutableList.of(
                new StreamMock(Collections.singletonMap(""_id"", ""stream-1""), Collections.emptyList()),
                new StreamMock(Collections.singletonMap(""_id"", ""stream-2""), Collections.emptyList()),
                new StreamMock(Collections.singletonMap(""_id"", ""stream-3""), Collections.emptyList()),
                new StreamMock(Collections.singletonMap(""_id"", StreamImpl.DEFAULT_STREAM_ID), Collections.emptyList()),
                new StreamMock(Collections.singletonMap(""_id"", StreamImpl.DEFAULT_EVENTS_STREAM_ID), Collections.emptyList()),
                new StreamMock(Collections.singletonMap(""_id"", StreamImpl.DEFAULT_SYSTEM_EVENTS_STREAM_ID), Collections.emptyList())
        ));

        final EventDefinitionDto eventDefinitionDto = EventDefinitionDto.builder()
                .id(""dto-id-1"")
                .title(""Test Aggregation"")
                .description(""A test aggregation event processors"")
                .priority(1)
                .alert(false)
                .notificationSettings(EventNotificationSettings.withGracePeriod(60000))
                .config(AggregationEventProcessorConfig.builder()
                        .query("""")
                        .streams(ImmutableSet.of()) // No configured streams!
                        .groupBy(ImmutableList.of(""group_field_one"", ""group_field_two""))
                        .series(ImmutableList.of())
                        .conditions(null)
                        .searchWithinMs(30000)
                        .executeEveryMs(30000)
                        .build())
                .keySpec(ImmutableList.of())
                .build();
        final AggregationEventProcessorParameters parameters = AggregationEventProcessorParameters.builder()
                .timerange(timerange)
                .build();

        final AggregationEventProcessor eventProcessor = new AggregationEventProcessor(eventDefinitionDto, searchFactory, eventProcessorDependencyCheck, stateService, moreSearch, streamService, messages);

        final AggregationResult result = AggregationResult.builder()
                .effectiveTimerange(timerange)
                .totalAggregatedMessages(0)
                .sourceStreams(ImmutableSet.of()) // No streams in result
                .keyResults(ImmutableList.of(
                        AggregationKeyResult.builder()
                                .key(ImmutableList.of(""one"", ""two""))
                                .timestamp(now)
                                .seriesValues(ImmutableList.of(
                                        AggregationSeriesValue.builder()
                                                .key(ImmutableList.of(""a""))
                                                .value(0.0d)
                                                .series(AggregationSeries.builder()
                                                        .id(""abc123"")
                                                        .function(AggregationFunction.COUNT)
                                                        .build())
                                                .build()
                                ))
                                .build()
                ))
                .build();

        final ImmutableList<EventWithContext> eventsWithContext = eventProcessor.eventsFromAggregationResult(eventFactory, parameters, result);

        assertThat(eventsWithContext).hasSize(1);

        assertThat(eventsWithContext.get(0)).satisfies(eventWithContext -> {
            final Event event = eventWithContext.event();

            assertThat(event.getId()).isEqualTo(event1.getId());
            assertThat(event.getMessage()).isEqualTo(event1.getMessage());
            assertThat(event.getEventTimestamp()).isEqualTo(timerange.to());
            assertThat(event.getTimerangeStart()).isEqualTo(timerange.from());
            assertThat(event.getTimerangeEnd()).isEqualTo(timerange.to());
            // Must contain all existing streams but the default event streams!
            assertThat(event.getSourceStreams()).containsOnly(
                    ""stream-1"",
                    ""stream-2"",
                    ""stream-3"",
                    StreamImpl.DEFAULT_STREAM_ID
            );

            final Message message = eventWithContext.messageContext().orElse(null);

            assertThat(message).isNotNull();
            assertThat(message.getField(""group_field_one"")).isEqualTo(""one"");
            assertThat(message.getField(""group_field_two"")).isEqualTo(""two"");
            assertThat(message.getField(""aggregation_key"")).isEqualTo(""one|two"");
            assertThat(message.getField(""aggregation_value_count"")).isEqualTo(0.0d);
        });
    }
",non-flaky,5
86074,graylog2_graylog2-server,PivotAggregationSearchTest.testExtractValuesWithGroupBy,"    @Test
    public void testExtractValuesWithGroupBy() throws Exception {
        final AbsoluteRange timerange = AbsoluteRange.create(DateTime.now(DateTimeZone.UTC).minusSeconds(3600), DateTime.now(DateTimeZone.UTC));
        final AggregationSeries seriesCount = AggregationSeries.create(""abc123"", AggregationFunction.COUNT, ""source"");
        final AggregationSeries seriesCard = AggregationSeries.create(""abc123"", AggregationFunction.CARD, ""source"");
        final AggregationEventProcessorConfig config = AggregationEventProcessorConfig.builder()
                .query("""")
                .streams(Collections.emptySet())
                .groupBy(Collections.emptyList())
                .series(ImmutableList.of(seriesCount, seriesCard))
                .conditions(null)
                .searchWithinMs(30000)
                .executeEveryMs(30000)
                .build();
        final AggregationEventProcessorParameters parameters = AggregationEventProcessorParameters.builder()
                .streams(Collections.emptySet())
                .timerange(timerange)
                .batchSize(500)
                .build();

        final PivotAggregationSearch pivotAggregationSearch = new PivotAggregationSearch(
                config,
                parameters,
                ""test"",
                eventDefinition,
                searchJobService,
                queryEngine,
                EventsConfigurationTestProvider.create(),
                moreSearch,
                permittedStreams);

        final String toString = timerange.getTo().toString();
        final PivotResult pivotResult = PivotResult.builder()
                .id(""test"")
                .effectiveTimerange(timerange)
                .total(1)
                .addRow(PivotResult.Row.builder()
                        .key(ImmutableList.of(toString, ""a"", ""b""))
                        .addValue(PivotResult.Value.create(ImmutableList.of(""metric/count/source/abc123""), 42, true, ""row-leaf""))
                        .addValue(PivotResult.Value.create(ImmutableList.of(""metric/card/source/abc123""), 1, true, ""row-leaf""))
                        .source(""leaf"")
                        .build())
                .addRow(PivotResult.Row.builder()
                        .key(ImmutableList.of(toString, ""a""))
                        .addValue(PivotResult.Value.create(ImmutableList.of(""metric/count/source/abc123""), 84, true, ""row-inner""))
                        .addValue(PivotResult.Value.create(ImmutableList.of(""metric/card/source/abc123""), 1, true, ""row-inner""))
                        .source(""non-leaf"")
                        .build())
                .addRow(PivotResult.Row.builder()
                        .key(ImmutableList.of(toString, ""a"", ""c""))
                        .addValue(PivotResult.Value.create(ImmutableList.of(""metric/count/source/abc123""), 42, true, ""row-leaf""))
                        .addValue(PivotResult.Value.create(ImmutableList.of(""metric/card/source/abc123""), 1, true, ""row-leaf""))
                        .source(""leaf"")
                        .build())
                .build();

        final ImmutableList<AggregationKeyResult> results = pivotAggregationSearch.extractValues(pivotResult);

        assertThat(results.size()).isEqualTo(2);

        assertThat(results.get(0)).isEqualTo(AggregationKeyResult.builder()
                .timestamp(timerange.getTo())
                .key(ImmutableList.of(""a"", ""b""))
                .seriesValues(ImmutableList.of(
                        AggregationSeriesValue.builder()
                                .key(ImmutableList.of(""a"", ""b""))
                                .value(42.0)
                                .series(seriesCount)
                                .build(),
                        AggregationSeriesValue.builder()
                                .key(ImmutableList.of(""a"", ""b""))
                                .value(1.0)
                                .series(seriesCard)
                                .build()
                ))
                .build());

        assertThat(results.get(1)).isEqualTo(AggregationKeyResult.builder()
                .timestamp(timerange.getTo())
                .key(ImmutableList.of(""a"", ""c""))
                .seriesValues(ImmutableList.of(
                        AggregationSeriesValue.builder()
                                .key(ImmutableList.of(""a"", ""c""))
                                .value(42.0)
                                .series(seriesCount)
                                .build(),
                        AggregationSeriesValue.builder()
                                .key(ImmutableList.of(""a"", ""c""))
                                .value(1.0)
                                .series(seriesCard)
                                .build()
                ))
                .build());
    }
",non-flaky,5
86075,graylog2_graylog2-server,PivotAggregationSearchTest.testExtractValuesWithoutGroupBy,"    @Test
    public void testExtractValuesWithoutGroupBy() throws Exception {
        final AbsoluteRange timerange = AbsoluteRange.create(DateTime.now(DateTimeZone.UTC).minusSeconds(3600), DateTime.now(DateTimeZone.UTC));
        final AggregationSeries seriesCount = AggregationSeries.create(""abc123"", AggregationFunction.COUNT, ""source"");
        final AggregationSeries seriesCountNoField = AggregationSeries.create(""abc123"", AggregationFunction.COUNT, """");
        final AggregationSeries seriesCard = AggregationSeries.create(""abc123"", AggregationFunction.CARD, ""source"");
        final AggregationEventProcessorConfig config = AggregationEventProcessorConfig.builder()
                .query("""")
                .streams(Collections.emptySet())
                .groupBy(Collections.emptyList())
                .series(ImmutableList.of(seriesCount, seriesCountNoField, seriesCard))
                .conditions(null)
                .searchWithinMs(30000)
                .executeEveryMs(30000)
                .build();
        final AggregationEventProcessorParameters parameters = AggregationEventProcessorParameters.builder()
                .streams(Collections.emptySet())
                .timerange(timerange)
                .batchSize(500)
                .build();

        final PivotAggregationSearch pivotAggregationSearch = new PivotAggregationSearch(
                config,
                parameters,
                ""test"",
                eventDefinition,
                searchJobService,
                queryEngine,
                EventsConfigurationTestProvider.create(),
                moreSearch,
                permittedStreams);

        final PivotResult pivotResult = PivotResult.builder()
                .id(""test"")
                .effectiveTimerange(timerange)
                .total(1)
                .addRow(PivotResult.Row.builder()
                        .key(ImmutableList.of(timerange.getTo().toString()))
                        .addValue(PivotResult.Value.create(ImmutableList.of(""metric/count/source/abc123""), 42, true, ""row-leaf""))
                        .addValue(PivotResult.Value.create(ImmutableList.of(""metric/count/<no-field>/abc123""), 23, true, ""row-leaf""))
                        .addValue(PivotResult.Value.create(ImmutableList.of(""metric/card/source/abc123""), 1, true, ""row-leaf""))
                        .source(""leaf"")
                        .build())
                .build();

        final ImmutableList<AggregationKeyResult> results = pivotAggregationSearch.extractValues(pivotResult);

        assertThat(results.size()).isEqualTo(1);

        assertThat(results.get(0)).isEqualTo(AggregationKeyResult.builder()
                .key(ImmutableList.of())
                .timestamp(timerange.getTo())
                .seriesValues(ImmutableList.of(
                        AggregationSeriesValue.builder()
                                .key(ImmutableList.of())
                                .value(42.0)
                                .series(seriesCount)
                                .build(),
                        AggregationSeriesValue.builder()
                                .key(ImmutableList.of())
                                .value(23.0)
                                .series(seriesCountNoField)
                                .build(),
                        AggregationSeriesValue.builder()
                                .key(ImmutableList.of())
                                .value(1.0)
                                .series(seriesCard)
                                .build()
                ))
                .build());
    }
",non-flaky,5
86076,graylog2_graylog2-server,PivotAggregationSearchTest.testExtractValuesWithNullValues,"    @Test
    public void testExtractValuesWithNullValues() throws Exception {
        final AbsoluteRange timerange = AbsoluteRange.create(DateTime.now(DateTimeZone.UTC).minusSeconds(3600), DateTime.now(DateTimeZone.UTC));
        final AggregationSeries seriesCount = AggregationSeries.create(""abc123"", AggregationFunction.COUNT, ""source"");
        final AggregationSeries seriesAvg = AggregationSeries.create(""abc123"", AggregationFunction.AVG, ""some_field"");
        final AggregationEventProcessorConfig config = AggregationEventProcessorConfig.builder()
                .query("""")
                .streams(Collections.emptySet())
                .groupBy(Collections.emptyList())
                .series(ImmutableList.of(seriesCount, seriesAvg))
                .conditions(null)
                .searchWithinMs(30000)
                .executeEveryMs(30000)
                .build();
        final AggregationEventProcessorParameters parameters = AggregationEventProcessorParameters.builder()
                .streams(Collections.emptySet())
                .timerange(timerange)
                .batchSize(500)
                .build();

        final PivotAggregationSearch pivotAggregationSearch = new PivotAggregationSearch(
                config,
                parameters,
                ""test"",
                eventDefinition,
                searchJobService,
                queryEngine,
                EventsConfigurationTestProvider.create(),
                moreSearch,
                permittedStreams);

        final PivotResult pivotResult = PivotResult.builder()
                .id(""test"")
                .effectiveTimerange(timerange)
                .total(1)
                .addRow(PivotResult.Row.builder()
                        .key(ImmutableList.of(timerange.getTo().toString()))
                        .addValue(PivotResult.Value.create(ImmutableList.of(""metric/count/source/abc123""), 42, true, ""row-leaf""))
                        // A ""null"" value can happen with some Elasticsearch aggregations (e.g. avg on a non-existent field)
                        .addValue(PivotResult.Value.create(ImmutableList.of(""metric/avg/some_field/abc123""), null, true, ""row-leaf""))
                        .source(""leaf"")
                        .build())
                .build();

        final ImmutableList<AggregationKeyResult> results = pivotAggregationSearch.extractValues(pivotResult);

        assertThat(results.size()).isEqualTo(1);

        assertThat(results.get(0)).isEqualTo(AggregationKeyResult.builder()
                .key(ImmutableList.of())
                .timestamp(timerange.getTo())
                .seriesValues(ImmutableList.of(
                        AggregationSeriesValue.builder()
                                .key(ImmutableList.of())
                                .value(42.0)
                                .series(seriesCount)
                                .build(),
                        AggregationSeriesValue.builder()
                                .key(ImmutableList.of())
                                .value(Double.NaN) // For ""null"" we expect NaN
                                .series(seriesAvg)
                                .build()
                ))
                .build());
    }
",non-flaky,5
86077,graylog2_graylog2-server,PivotAggregationSearchTest.testDateRangeBucketWithOneTumblingWindow,"    @Test
    public void testDateRangeBucketWithOneTumblingWindow() {
        final long processingWindowSize = Duration.standardSeconds(60).getMillis();
        final long processingHopSize = Duration.standardSeconds(60).getMillis();
        final DateTime now = DateTime.now(DateTimeZone.UTC);
        final DateTime from = now;
        final DateTime to = now.plusMillis((int) processingWindowSize);
        TimeRange timeRange = AbsoluteRange.create(from, to);
        final DateRangeBucket rangeBucket = PivotAggregationSearch.buildDateRangeBuckets(timeRange, processingWindowSize, processingHopSize);

        assertThat(rangeBucket.ranges()).containsExactly(DateRange.create(from, to));
    }
",non-flaky,5
86078,graylog2_graylog2-server,PivotAggregationSearchTest.testDateRangeBucketWithCatchUpTumblingWindows,"    @Test
    public void testDateRangeBucketWithCatchUpTumblingWindows() {
        final long processingWindowSize = Duration.standardSeconds(60).getMillis();
        final long processingHopSize = Duration.standardSeconds(60).getMillis();
        final DateTime now = DateTime.now(DateTimeZone.UTC);
        final DateTime from = now;
        // We are 3 full processingWindows behind
        final DateTime to = now.plusMillis((int) processingWindowSize * 3);
        TimeRange timeRange = AbsoluteRange.create(from, to);
        final DateRangeBucket rangeBucket = PivotAggregationSearch.buildDateRangeBuckets(timeRange, processingWindowSize, processingHopSize);

        assertThat(rangeBucket.ranges()).containsExactly(
                DateRange.create(from.plusMillis((int) (processingWindowSize * 0)), from.plusMillis((int) (processingWindowSize * 1))),
                DateRange.create(from.plusMillis((int) (processingWindowSize * 1)), from.plusMillis((int) (processingWindowSize * 2))),
                DateRange.create(from.plusMillis((int) (processingWindowSize * 2)), from.plusMillis((int) (processingWindowSize * 3)))
        );
    }
",non-flaky,5
86079,graylog2_graylog2-server,PivotAggregationSearchTest.testDateRangeBucketWithSlidingWindow,"    @Test
    public void testDateRangeBucketWithSlidingWindow() {
        final long processingWindowSize = Duration.standardSeconds(3600).getMillis();
        final long processingHopSize = Duration.standardSeconds(60).getMillis();
        final DateTime now = DateTime.now(DateTimeZone.UTC);
        final DateTime from = now;
        final DateTime to = now.plusMillis((int) processingWindowSize);
        TimeRange timeRange = AbsoluteRange.create(from, to);
        final DateRangeBucket rangeBucket = PivotAggregationSearch.buildDateRangeBuckets(timeRange, processingWindowSize, processingHopSize);

        assertThat(rangeBucket.ranges()).containsExactly(
                DateRange.create(from, to)
        );
    }
",non-flaky,5
86080,graylog2_graylog2-server,PivotAggregationSearchTest.testDateRangeBucketWithCatchUpSlidingWindows,"    @Test
    public void testDateRangeBucketWithCatchUpSlidingWindows() {
        final int processingWindowSizeSec = 120;
        final int processingHopSizeSec = 60;
        final DateTime now = DateTime.now(DateTimeZone.UTC);
        final DateTime from = now;
        // We are 3 full processingWindows behind
        final DateTime to = now.plusSeconds(processingWindowSizeSec * 3);
        TimeRange timeRange = AbsoluteRange.create(from, to);
        final DateRangeBucket rangeBucket = PivotAggregationSearch.buildDateRangeBuckets(timeRange, processingWindowSizeSec * 1000, processingHopSizeSec * 1000);

        assertThat(rangeBucket.ranges()).containsExactly(
                DateRange.create(from.plusSeconds(processingHopSizeSec * 0), from.plusSeconds(processingWindowSizeSec)),
                DateRange.create(from.plusSeconds(processingHopSizeSec * 1), from.plusSeconds(processingHopSizeSec * 1).plusSeconds(processingWindowSizeSec)),
                DateRange.create(from.plusSeconds(processingHopSizeSec * 2), from.plusSeconds(processingHopSizeSec * 2).plusSeconds(processingWindowSizeSec)),
                DateRange.create(from.plusSeconds(processingHopSizeSec * 3), from.plusSeconds(processingHopSizeSec * 3).plusSeconds(processingWindowSizeSec)),
                DateRange.create(from.plusSeconds(processingHopSizeSec * 4), to)
        );
    }
",non-flaky,5
86081,graylog2_graylog2-server,EventDefinitionHandlerTest.create,"    @Test
    public void create() {
        final EventDefinitionDto newDto = EventDefinitionDto.builder()
                .title(""Test"")
                .description(""A test event definition"")
                .config(TestEventProcessorConfig.builder()
                        .message(""This is a test event processor"")
                        .searchWithinMs(300000)
                        .executeEveryMs(60001)
                        .build())
                .priority(3)
                .alert(false)
                .notificationSettings(EventNotificationSettings.withGracePeriod(60000))
                .keySpec(ImmutableList.of(""a"", ""b""))
                .notifications(ImmutableList.of())
                .build();

        final EventDefinitionDto dto = handler.create(newDto, Optional.empty());

        // Handler should create the event definition
        assertThat(eventDefinitionService.get(dto.id())).isPresent();

        final Optional<JobDefinitionDto> jobDefinition = jobDefinitionService.getByConfigField(""event_definition_id"", dto.id());

        // Handler also should create the job definition for the event definition/processor
        assertThat(jobDefinition).isPresent().get().satisfies(definition -> {
            assertThat(definition.title()).isEqualTo(""Test"");
            assertThat(definition.description()).isEqualTo(""A test event definition"");
            assertThat(definition.config()).isInstanceOf(EventProcessorExecutionJob.Config.class);

            final EventProcessorExecutionJob.Config config = (EventProcessorExecutionJob.Config) definition.config();


            assertThat(config.processingWindowSize()).isEqualTo(300000);
            assertThat(config.processingHopSize()).isEqualTo(60001);
        });

        // And the handler should also create a job trigger for the created job definition
        final Optional<JobTriggerDto> jobTrigger = jobTriggerService.nextRunnableTrigger();

        assertThat(jobTrigger).isPresent().get().satisfies(trigger -> {
            assertThat(trigger.jobDefinitionId()).isEqualTo(jobDefinition.get().id());
            assertThat(trigger.schedule()).isInstanceOf(IntervalJobSchedule.class);

            final IntervalJobSchedule schedule = (IntervalJobSchedule) trigger.schedule();

            assertThat(schedule.interval()).isEqualTo(60001);
            assertThat(schedule.unit()).isEqualTo(TimeUnit.MILLISECONDS);
        });
    }
",non-flaky,5
86082,graylog2_graylog2-server,EventDefinitionHandlerTest.createWithoutSchedule,"    @Test
    public void createWithoutSchedule() {
        final EventDefinitionDto newDto = EventDefinitionDto.builder()
                .title(""Test"")
                .description(""A test event definition"")
                .config(TestEventProcessorConfig.builder()
                        .message(""This is a test event processor"")
                        .searchWithinMs(300000)
                        .executeEveryMs(60001)
                        .build())
                .priority(3)
                .alert(false)
                .notificationSettings(EventNotificationSettings.withGracePeriod(60000))
                .keySpec(ImmutableList.of(""a"", ""b""))
                .notifications(ImmutableList.of())
                .build();

        final EventDefinitionDto dto = handler.createWithoutSchedule(newDto, Optional.empty());

        // Handler should create the event definition
        assertThat(eventDefinitionService.get(dto.id())).isPresent();

        // Handler should NOT create a job definition for the event definition/processor
        assertThat(jobDefinitionService.getByConfigField(""event_definition_id"", dto.id())).isNotPresent();

        // And the handler should also NOT create a job trigger for the created job definition
        assertThat(jobTriggerService.nextRunnableTrigger()).isNotPresent();
    }
",non-flaky,5
86083,graylog2_graylog2-server,EventDefinitionHandlerTest.update,"    @Test
    public void update() {
        final String newTitle = ""A NEW TITLE "" + DateTime.now(DateTimeZone.UTC).toString();
        final String newDescription = ""A NEW DESCRIPTION "" + DateTime.now(DateTimeZone.UTC).toString();

        final EventDefinitionDto existingDto = eventDefinitionService.get(""54e3deadbeefdeadbeef0000"").orElse(null);
        final JobDefinitionDto existingJobDefinition = jobDefinitionService.get(""54e3deadbeefdeadbeef0001"").orElse(null);
        final JobTriggerDto existingTrigger = jobTriggerService.get(""54e3deadbeefdeadbeef0002"").orElse(null);
        final TestEventProcessorConfig existingConfig = (TestEventProcessorConfig) existingDto.config();
        final TestEventProcessorConfig newConfig = existingConfig.toBuilder()
                .executeEveryMs(550000)
                .searchWithinMs(800000)
                .build();
        final EventProcessorExecutionJob.Data existingTriggerData = (EventProcessorExecutionJob.Data) existingTrigger.data().orElseThrow(AssertionError::new);

        assertThat(existingDto).isNotNull();
        assertThat(existingJobDefinition).isNotNull();
        assertThat(existingTrigger).isNotNull();

        final EventDefinitionDto updatedDto = existingDto.toBuilder()
                .title(newTitle)
                .description(newDescription)
                .config(newConfig)
                .build();

        assertThat(handler.update(updatedDto, true)).isNotEqualTo(existingDto);

        assertThat(eventDefinitionService.get(existingDto.id())).isPresent().get().satisfies(dto -> {
            assertThat(dto.id()).isEqualTo(existingDto.id());
            assertThat(dto.title()).isEqualTo(newTitle);
            assertThat(dto.description()).isEqualTo(newDescription);
        });

        // Test that the schedule is updated to the new config
        final JobDefinitionDto newJobDefinition = jobDefinitionService.get(""54e3deadbeefdeadbeef0001"").orElseThrow(AssertionError::new);
        assertThat(newJobDefinition.title()).isEqualTo(newTitle);
        assertThat(newJobDefinition.description()).isEqualTo(newDescription);
        assertThat(((EventProcessorExecutionJob.Config) newJobDefinition.config()).processingHopSize()).isEqualTo(550000);
        assertThat(((EventProcessorExecutionJob.Config) newJobDefinition.config()).processingWindowSize()).isEqualTo(800000);

        // Test if the EventDefinition update removed the old trigger data
        // and reset the job definition timerange to the new parameters
        final EventProcessorExecutionJob.Config newJobConfig = (EventProcessorExecutionJob.Config) newJobDefinition.config();
        final TimeRange newTimeRange = newJobConfig.parameters().timerange();
        assertThat(newTimeRange.getFrom()).isEqualTo(clock.nowUTC().minus(newConfig.searchWithinMs()));
        assertThat(newTimeRange.getTo()).isEqualTo(clock.nowUTC());

        assertThat(jobTriggerService.get(""54e3deadbeefdeadbeef0002"")).isPresent().get().satisfies(trigger -> {
            assertThat(trigger.data()).isEmpty();
            assertThat(trigger.nextTime()).isEqualTo(clock.nowUTC());
        });
    }
",non-flaky,5
86084,graylog2_graylog2-server,EventDefinitionHandlerTest.updateWithSchedulingDisabled,"    @Test
    public void updateWithSchedulingDisabled() {
        final String newTitle = ""A NEW TITLE "" + DateTime.now(DateTimeZone.UTC).toString();
        final String newDescription = ""A NEW DESCRIPTION "" + DateTime.now(DateTimeZone.UTC).toString();

        final EventDefinitionDto existingDto = eventDefinitionService.get(""54e3deadbeefdeadbeef0000"").orElse(null);
        final JobDefinitionDto existingJobDefinition = jobDefinitionService.get(""54e3deadbeefdeadbeef0001"").orElse(null);
        final JobTriggerDto existingTrigger = jobTriggerService.get(""54e3deadbeefdeadbeef0002"").orElse(null);
        final TestEventProcessorConfig existingConfig = (TestEventProcessorConfig) existingDto.config();
        final TestEventProcessorConfig newConfig = existingConfig.toBuilder()
                .executeEveryMs(550000)
                .searchWithinMs(800000)
                .build();

        assertThat(existingDto).isNotNull();
        assertThat(existingJobDefinition).isNotNull();
        assertThat(existingTrigger).isNotNull();

        final EventDefinitionDto updatedDto = existingDto.toBuilder()
                .title(newTitle)
                .description(newDescription)
                .config(newConfig)
                .build();

        assertThat(handler.update(updatedDto, false)).isNotEqualTo(existingDto);

        assertThat(eventDefinitionService.get(existingDto.id())).isPresent().get().satisfies(dto -> {
            assertThat(dto.id()).isEqualTo(existingDto.id());
            assertThat(dto.title()).isEqualTo(newTitle);
            assertThat(dto.description()).isEqualTo(newDescription);
        });

        assertThat(jobDefinitionService.get(""54e3deadbeefdeadbeef0001"")).isNotPresent();
        assertThat(jobTriggerService.get(""54e3deadbeefdeadbeef0002"")).isNotPresent();
    }
",non-flaky,5
86085,graylog2_graylog2-server,EventDefinitionHandlerTest.updateWithSchedulingReEnabled,"    @Test
    public void updateWithSchedulingReEnabled() {
        final String newTitle = ""A NEW TITLE "" + DateTime.now(DateTimeZone.UTC).toString();
        final String newDescription = ""A NEW DESCRIPTION "" + DateTime.now(DateTimeZone.UTC).toString();

        final EventDefinitionDto existingDto = eventDefinitionService.get(""54e3deadbeefdeadbeef0000"").orElse(null);
        final TestEventProcessorConfig existingConfig = (TestEventProcessorConfig) existingDto.config();
        final TestEventProcessorConfig newConfig = existingConfig.toBuilder()
                .executeEveryMs(550000)
                .searchWithinMs(800000)
                .build();

        assertThat(existingDto).isNotNull();

        final EventDefinitionDto updatedDto = existingDto.toBuilder()
                .title(newTitle)
                .description(newDescription)
                .config(newConfig)
                .build();

        assertThat(handler.update(updatedDto, true)).isNotEqualTo(existingDto);

        assertThat(eventDefinitionService.get(existingDto.id())).isPresent().get().satisfies(dto -> {
            assertThat(dto.id()).isEqualTo(existingDto.id());
            assertThat(dto.title()).isEqualTo(newTitle);
            assertThat(dto.description()).isEqualTo(newDescription);
        });

        final JobDefinitionDto newJobDefinition = jobDefinitionService.getByConfigField(""event_definition_id"", existingDto.id())
                .orElseThrow(AssertionError::new);
        assertThat(newJobDefinition.title()).isEqualTo(newTitle);
        assertThat(newJobDefinition.description()).isEqualTo(newDescription);
        assertThat(((EventProcessorExecutionJob.Config) newJobDefinition.config()).processingHopSize()).isEqualTo(550000);

        assertThat(jobTriggerService.getForJob(newJobDefinition.id()).get(0)).satisfies(trigger -> {
            final IntervalJobSchedule schedule = (IntervalJobSchedule) trigger.schedule();
            assertThat(schedule.interval()).isEqualTo(550000);
        });
    }
",non-flaky,5
86086,graylog2_graylog2-server,EventDefinitionHandlerTest.updateWithErrors,"    @Test
    public void updateWithErrors() {
        final String newTitle = ""A NEW TITLE "" + DateTime.now(DateTimeZone.UTC).toString();
        final String newDescription = ""A NEW DESCRIPTION "" + DateTime.now(DateTimeZone.UTC).toString();

        final EventDefinitionDto existingDto = eventDefinitionService.get(""54e3deadbeefdeadbeef0000"").orElse(null);
        final JobDefinitionDto existingJobDefinition = jobDefinitionService.get(""54e3deadbeefdeadbeef0001"").orElse(null);
        final JobTriggerDto existingTrigger = jobTriggerService.get(""54e3deadbeefdeadbeef0002"").orElse(null);

        assertThat(existingDto).isNotNull();
        assertThat(existingJobDefinition).isNotNull();
        assertThat(existingTrigger).isNotNull();

        final EventDefinitionDto updatedDto = existingDto.toBuilder()
                .title(newTitle)
                .description(newDescription)
                .build();

        doThrow(new NullPointerException(""yolo1"")).when(eventDefinitionService).save(any());

        assertThatCode(() -> handler.update(updatedDto, true))
                .isInstanceOf(NullPointerException.class)
                .hasMessageContaining(""yolo1"");

        assertThat(eventDefinitionService.get(existingDto.id())).isPresent().get().satisfies(dto -> {
            assertThat(dto.id()).isEqualTo(existingDto.id());
            assertThat(dto.title()).isEqualTo(existingDto.title());
            assertThat(dto.description()).isEqualTo(existingDto.description());
        });

        assertThat(jobDefinitionService.get(""54e3deadbeefdeadbeef0001"")).isPresent().get().satisfies(definition -> {
            assertThat(definition.title()).isEqualTo(existingJobDefinition.title());
            assertThat(definition.description()).isEqualTo(existingJobDefinition.description());
        });

        // Reset all before doing new stubs
        reset(eventDefinitionService);
        reset(jobDefinitionService);
        reset(jobTriggerService);

        doThrow(new NullPointerException(""yolo2"")).when(jobDefinitionService).save(any());

        assertThatCode(() -> handler.update(updatedDto, true))
                .isInstanceOf(NullPointerException.class)
                .hasMessageContaining(""yolo2"");

        assertThat(eventDefinitionService.get(existingDto.id())).isPresent().get().satisfies(dto -> {
            assertThat(dto.id()).isEqualTo(existingDto.id());
            assertThat(dto.title()).isEqualTo(existingDto.title());
            assertThat(dto.description()).isEqualTo(existingDto.description());
        });

        assertThat(jobDefinitionService.get(""54e3deadbeefdeadbeef0001"")).isPresent().get().satisfies(definition -> {
            assertThat(definition.title()).isEqualTo(existingJobDefinition.title());
            assertThat(definition.description()).isEqualTo(existingJobDefinition.description());
        });

        // Reset all before doing new stubs
        reset(eventDefinitionService);
        reset(jobDefinitionService);
        reset(jobTriggerService);

        doThrow(new NullPointerException(""yolo3"")).when(jobTriggerService).update(any());

        assertThatCode(() -> handler.update(updatedDto, true))
                .isInstanceOf(NullPointerException.class)
                .hasMessageContaining(""yolo3"");

        assertThat(eventDefinitionService.get(existingDto.id())).isPresent().get().satisfies(dto -> {
            assertThat(dto.id()).isEqualTo(existingDto.id());
            assertThat(dto.title()).isEqualTo(existingDto.title());
            assertThat(dto.description()).isEqualTo(existingDto.description());
        });

        assertThat(jobDefinitionService.get(""54e3deadbeefdeadbeef0001"")).isPresent().get().satisfies(definition -> {
            assertThat(definition.title()).isEqualTo(existingJobDefinition.title());
            assertThat(definition.description()).isEqualTo(existingJobDefinition.description());
        });
    }
",non-flaky,5
86087,graylog2_graylog2-server,EventDefinitionHandlerTest.delete,"    @Test
    public void delete() {
        assertThat(eventDefinitionService.get(""54e3deadbeefdeadbeef0000"")).isPresent();
        assertThat(jobDefinitionService.get(""54e3deadbeefdeadbeef0001"")).isPresent();
        assertThat(jobTriggerService.get(""54e3deadbeefdeadbeef0002"")).isPresent();

        assertThat(handler.delete(""54e3deadbeefdeadbeef0000"")).isTrue();

        assertThat(eventDefinitionService.get(""54e3deadbeefdeadbeef0000"")).isNotPresent();
        assertThat(jobDefinitionService.get(""54e3deadbeefdeadbeef0001"")).isNotPresent();
        assertThat(jobTriggerService.get(""54e3deadbeefdeadbeef0002"")).isNotPresent();
    }
",non-flaky,5
86088,graylog2_graylog2-server,EventDefinitionHandlerTest.schedule,"    @Test
    public void schedule() {
        assertThat(eventDefinitionService.get(""54e3deadbeefdeadbeef0000"")).isPresent();
        assertThat(jobDefinitionService.streamAll().count()).isEqualTo(0);
        assertThat(jobTriggerService.all()).isEmpty();

        handler.schedule(""54e3deadbeefdeadbeef0000"");

        assertThat(eventDefinitionService.get(""54e3deadbeefdeadbeef0000"")).isPresent();

        assertThat(jobDefinitionService.getByConfigField(""event_definition_id"", ""54e3deadbeefdeadbeef0000""))
                .get()
                .satisfies(definition -> {
                    assertThat(definition.title()).isEqualTo(""Test"");
                    assertThat(definition.description()).isEqualTo(""A test event definition"");
                    assertThat(definition.config()).isInstanceOf(EventProcessorExecutionJob.Config.class);

                    final EventProcessorExecutionJob.Config config = (EventProcessorExecutionJob.Config) definition.config();


                    assertThat(config.processingWindowSize()).isEqualTo(300000);
                    assertThat(config.processingHopSize()).isEqualTo(60000);

                    assertThat(jobTriggerService.nextRunnableTrigger()).get().satisfies(trigger -> {
                        assertThat(trigger.jobDefinitionId()).isEqualTo(definition.id());
                        assertThat(trigger.schedule()).isInstanceOf(IntervalJobSchedule.class);

                        final IntervalJobSchedule schedule = (IntervalJobSchedule) trigger.schedule();

                        assertThat(schedule.interval()).isEqualTo(60000);
                        assertThat(schedule.unit()).isEqualTo(TimeUnit.MILLISECONDS);
                    });
                });


        assertThat(jobDefinitionService.get(""54e3deadbeefdeadbeef0001"")).isNotPresent();
        assertThat(jobTriggerService.get(""54e3deadbeefdeadbeef0002"")).isNotPresent();
    }
",non-flaky,5
86089,graylog2_graylog2-server,EventDefinitionHandlerTest.scheduleWithMissingEventDefinition,"    @Test
    public void scheduleWithMissingEventDefinition() {
        final String id = ""54e3deadbeefdeadbeef9999"";

        // The event definition should not exist so our test works
        assertThat(eventDefinitionService.get(id)).isNotPresent();

        assertThatThrownBy(() -> handler.schedule(id))
                .hasMessageContaining(""doesn't exist"")
                .isInstanceOf(IllegalArgumentException.class);
    }
",non-flaky,5
86090,graylog2_graylog2-server,EventDefinitionHandlerTest.unschedule,"    @Test
    public void unschedule() {
        assertThat(eventDefinitionService.get(""54e3deadbeefdeadbeef0000"")).isPresent();
        assertThat(jobDefinitionService.get(""54e3deadbeefdeadbeef0001"")).isPresent();
        assertThat(jobTriggerService.get(""54e3deadbeefdeadbeef0002"")).isPresent();

        handler.unschedule(""54e3deadbeefdeadbeef0000"");

        // Unschedule should NOT delete the event definition!
        assertThat(eventDefinitionService.get(""54e3deadbeefdeadbeef0000"")).isPresent();

        // Only the job definition and the trigger
        assertThat(jobDefinitionService.get(""54e3deadbeefdeadbeef0001"")).isNotPresent();
        assertThat(jobTriggerService.get(""54e3deadbeefdeadbeef0002"")).isNotPresent();
    }
",non-flaky,5
86091,graylog2_graylog2-server,EventDefinitionHandlerTest.unscheduleWithMissingEventDefinition,"    @Test
    public void unscheduleWithMissingEventDefinition() {
        final String id = ""54e3deadbeefdeadbeef9999"";

        // The event definition should not exist so our test works
        assertThat(eventDefinitionService.get(id)).isNotPresent();

        assertThatThrownBy(() -> handler.unschedule(id))
                .hasMessageContaining(""doesn't exist"")
                .isInstanceOf(IllegalArgumentException.class);
    }
",non-flaky,5
86092,graylog2_graylog2-server,EventDefinitionDtoTest.testValidateWithEmptyTitle,"    @Test
    public void testValidateWithEmptyTitle() {
        final EventDefinitionDto invalidEventDefinition = testSubject.toBuilder()
            .title("""")
            .build();
        final ValidationResult validationResult = invalidEventDefinition.validate();
        assertThat(validationResult.failed()).isTrue();
        assertThat(validationResult.getErrors()).containsOnlyKeys(""title"");
    }
",non-flaky,5
86093,graylog2_graylog2-server,EventDefinitionDtoTest.testValidateWithEmptyConfigType,"    @Test
    public void testValidateWithEmptyConfigType() {
        final EventDefinitionDto invalidEventDefinition = testSubject.toBuilder()
            .config(new EventProcessorConfig.FallbackConfig())
            .build();
        final ValidationResult validationResult = invalidEventDefinition.validate();
        assertThat(validationResult.failed()).isTrue();
        assertThat(validationResult.getErrors()).containsOnlyKeys(""config"");
    }
",non-flaky,5
86094,graylog2_graylog2-server,EventDefinitionDtoTest.testValidateWithInvalidConfig,"    @Test
    public void testValidateWithInvalidConfig() {
        final AggregationEventProcessorConfig configMock = mock(AggregationEventProcessorConfig.class);
        final ValidationResult mockedValidationResult = new ValidationResult();
        mockedValidationResult.addError(""foo"", ""bar"");
        when(configMock.validate()).thenReturn(mockedValidationResult);

        final EventDefinitionDto invalidEventDefinition = testSubject.toBuilder()
            .config(configMock)
            .build();
        final ValidationResult validationResult = invalidEventDefinition.validate();
        assertThat(validationResult.failed()).isTrue();
        assertThat(validationResult.getErrors()).containsOnlyKeys(""foo"");
    }
",non-flaky,5
86095,graylog2_graylog2-server,EventDefinitionDtoTest.testValidateWithInvalidFieldName,"    @Test
    public void testValidateWithInvalidFieldName() {
        final EventFieldSpec fieldSpecMock = mock(EventFieldSpec.class);
        final EventDefinitionDto invalidEventDefinition = testSubject.toBuilder()
            .fieldSpec(ImmutableMap.of(""foo\\bar"", fieldSpecMock, ""$yo&^a"", fieldSpecMock))
            .build();
        final ValidationResult validationResult = invalidEventDefinition.validate();
        assertThat(validationResult.failed()).isTrue();
        assertThat(validationResult.getErrors()).containsOnlyKeys(""field_spec"");
        final List<String> fieldValidation = (List<String>) validationResult.getErrors().get(""field_spec"");
        assertThat(fieldValidation.size()).isEqualTo(2);
        assertThat(fieldValidation.get(0)).contains(""foo\\bar"");
        assertThat(fieldValidation.get(1)).contains(""$yo&^a"");
    }
",non-flaky,5
86096,graylog2_graylog2-server,EventDefinitionDtoTest.testValidateWithKeySpecNotInFieldSpec,"    @Test
    public void testValidateWithKeySpecNotInFieldSpec() {
        final EventFieldSpec fieldSpecMock = mock(EventFieldSpec.class);
        final EventDefinitionDto invalidEventDefinition = testSubject.toBuilder()
            .fieldSpec(ImmutableMap.of(""bar"", fieldSpecMock, ""baz"", fieldSpecMock))
            .keySpec(ImmutableList.of(""foo""))
            .build();
        final ValidationResult validationResult = invalidEventDefinition.validate();
        assertThat(validationResult.failed()).isTrue();
        assertThat(validationResult.getErrors()).containsOnlyKeys(""key_spec"");
    }
",non-flaky,5
86097,graylog2_graylog2-server,EventDefinitionDtoTest.testValidEventDefinition,"    @Test
    public void testValidEventDefinition() {
        final ValidationResult validationResult = testSubject.validate();
        assertThat(validationResult.failed()).isFalse();
        assertThat(validationResult.getErrors().size()).isEqualTo(0);
    }
",non-flaky,5
86098,graylog2_graylog2-server,EventDefinitionDtoTest.testValidEventDefinitionWithKeySpecInFieldSpec,"    @Test
    public void testValidEventDefinitionWithKeySpecInFieldSpec() {
        final EventFieldSpec fieldSpecMock = mock(EventFieldSpec.class);
        final EventDefinitionDto invalidEventDefinition = testSubject.toBuilder()
            .fieldSpec(ImmutableMap.of(""foo"", fieldSpecMock, ""bar"", fieldSpecMock))
            .keySpec(ImmutableList.of(""foo"", ""bar""))
            .build();
        final ValidationResult validationResult = invalidEventDefinition.validate();
        assertThat(validationResult.failed()).isFalse();
        assertThat(validationResult.getErrors().size()).isEqualTo(0);
    }
",non-flaky,5
86099,graylog2_graylog2-server,EventProcessorDtoTest.type,"    @Test
    public void automaticallyAddsPersistToStreamsStorageHandler() {
        final EventStorageHandler.Config testStorageHandlerConfig = new EventStorageHandler.Config() {
            @Override
            public String type() {
                return ""storage-test"";
            }
",non-flaky,5
86100,graylog2_graylog2-server,DBEventProcessorServiceTest.loadPersisted,"    @Test
    public void loadPersisted() {
        final List<EventDefinitionDto> dtos = dbService.streamAll().collect(Collectors.toList());

        assertThat(dtos).hasSize(1);

        assertThat(dtos.get(0)).satisfies(dto -> {
            assertThat(dto.id()).isNotBlank();
            assertThat(dto.title()).isEqualTo(""Test"");
            assertThat(dto.description()).isEqualTo(""A test event definition"");
            assertThat(dto.priority()).isEqualTo(2);
            assertThat(dto.keySpec()).isEqualTo(ImmutableList.of(""username""));
            assertThat(dto.fieldSpec()).isEmpty();
            assertThat(dto.notifications()).isEmpty();
            assertThat(dto.storage()).hasSize(1);

            assertThat(dto.config()).isInstanceOf(TestEventProcessorConfig.class);
            assertThat(dto.config()).satisfies(abstractConfig -> {
                final TestEventProcessorConfig config = (TestEventProcessorConfig) abstractConfig;

                assertThat(config.type()).isEqualTo(""__test_event_processor_config__"");
                assertThat(config.message()).isEqualTo(""This is a test event processor"");
            });
        });
    }
",non-flaky,5
86101,graylog2_graylog2-server,DBEventProcessorServiceTest.save,"    @Test
    public void save() {
        final EventDefinitionDto newDto = EventDefinitionDto.builder()
                .title(""Test"")
                .description(""A test event definition"")
                .config(TestEventProcessorConfig.builder()
                        .message(""This is a test event processor"")
                        .searchWithinMs(1000)
                        .executeEveryMs(1000)
                        .build())
                .priority(3)
                .alert(false)
                .notificationSettings(EventNotificationSettings.withGracePeriod(60000))
                .keySpec(ImmutableList.of(""a"", ""b""))
                .notifications(ImmutableList.of())
                .build();

        final EventDefinitionDto dto = dbService.save(newDto);

        assertThat(dto.id()).isNotBlank();
        assertThat(dto.title()).isEqualTo(""Test"");
        assertThat(dto.description()).isEqualTo(""A test event definition"");
        assertThat(dto.priority()).isEqualTo(3);
        assertThat(dto.keySpec()).isEqualTo(ImmutableList.of(""a"", ""b""));
        assertThat(dto.fieldSpec()).isEmpty();
        assertThat(dto.notifications()).isEmpty();
        assertThat(dto.storage()).hasSize(1);
        // We will always add a persist-to-streams handler for now
        assertThat(dto.storage()).containsOnly(PersistToStreamsStorageHandler.Config.createWithDefaultEventsStream());
    }
",non-flaky,5
86102,graylog2_graylog2-server,DBEventProcessorStateServiceTest.persistence,"    @Test
    public void persistence() {
        final DateTime now = DateTime.now(DateTimeZone.UTC);
        final DateTime min = now.minusHours(1);
        final DateTime max = now;

        final EventProcessorStateDto stateDto = EventProcessorStateDto.builder()
                .eventDefinitionId(""abc123"")
                .minProcessedTimestamp(min)
                .maxProcessedTimestamp(max)
                .build();

        assertThat(stateService.setState(stateDto)).isPresent().get().satisfies(dto -> {
            assertThat(dto.id()).isNotBlank();
            assertThat(dto.eventDefinitionId()).isEqualTo(""abc123"");
            assertThat(dto.minProcessedTimestamp()).isEqualTo(min);
            assertThat(dto.maxProcessedTimestamp()).isEqualTo(max);
        });

        assertThatThrownBy(() -> stateService.setState("""", min, max))
                .hasMessageContaining(""eventDefinitionId"")
                .isInstanceOf(IllegalArgumentException.class);
        assertThatThrownBy(() -> stateService.setState(null, min, max))
                .hasMessageContaining(""eventDefinitionId"")
                .isInstanceOf(IllegalArgumentException.class);

        assertThatThrownBy(() -> stateService.setState(""a"", null, max))
                .hasMessageContaining(""minProcessedTimestamp"")
                .isInstanceOf(IllegalArgumentException.class);

        assertThatThrownBy(() -> stateService.setState(""a"", min, null))
                .hasMessageContaining(""maxProcessedTimestamp"")
                .isInstanceOf(IllegalArgumentException.class);

        // A max timestamp that is older than the min timestamp is an error! (e.g. mixing up arguments)
        assertThatThrownBy(() -> stateService.setState(""a"", max, min))
                .hasMessageContaining(""minProcessedTimestamp"")
                .hasMessageContaining(""maxProcessedTimestamp"")
                .isInstanceOf(IllegalArgumentException.class);
    }
",non-flaky,5
86103,graylog2_graylog2-server,DBEventProcessorStateServiceTest.loading,"    @Test
    public void loading() {
        final Optional<EventProcessorStateDto> stateDto = stateService.findByEventDefinitionId(""54e3deadbeefdeadbeefaff3"");

        assertThat(stateDto).isPresent().get().satisfies(dto -> {
            assertThat(dto.id()).isEqualTo(""54e3deadbeefdeadbeefaffe"");
            assertThat(dto.eventDefinitionId()).isEqualTo(""54e3deadbeefdeadbeefaff3"");
            assertThat(dto.minProcessedTimestamp()).isEqualTo(DateTime.parse(""2019-01-01T00:00:00.000Z""));
            assertThat(dto.maxProcessedTimestamp()).isEqualTo(DateTime.parse(""2019-01-01T01:00:00.000Z""));
        });
    }
",non-flaky,5
86104,graylog2_graylog2-server,DBEventProcessorStateServiceTest.findByEventProcessorId,"    @Test
    public void findByEventProcessorId() {
        assertThat(stateService.findByEventDefinitionId(""54e3deadbeefdeadbeefaff3"")).isPresent();

        assertThat(stateService.findByEventDefinitionId(""nope"")).isNotPresent();

        assertThatThrownBy(() -> stateService.findByEventDefinitionId(null))
                .hasMessageContaining(""eventDefinitionId"")
                .isInstanceOf(IllegalArgumentException.class);

        assertThatThrownBy(() -> stateService.findByEventDefinitionId(""""))
                .hasMessageContaining(""eventDefinitionId"")
                .isInstanceOf(IllegalArgumentException.class);
    }
",non-flaky,5
86105,graylog2_graylog2-server,DBEventProcessorStateServiceTest.findByEventProcessorsAndMaxTimestamp,"    @Test
    public void findByEventProcessorsAndMaxTimestamp() {
        assertThat(stateService.findByEventDefinitionId(""54e3deadbeefdeadbeefaff3"")).isPresent().get().satisfies(dto -> {
            final DateTime maxTs = dto.maxProcessedTimestamp();
            final String id = dto.eventDefinitionId();

            assertThat(stateService.findByEventDefinitionsAndMaxTimestamp(ImmutableSet.of(id), maxTs))
                    .hasSize(1);
            assertThat(stateService.findByEventDefinitionsAndMaxTimestamp(ImmutableSet.of(id), maxTs.minusHours(1)))
                    .hasSize(1);
            assertThat(stateService.findByEventDefinitionsAndMaxTimestamp(ImmutableSet.of(id), maxTs.plusHours(1)))
                    .hasSize(0);

            assertThatThrownBy(() -> stateService.findByEventDefinitionsAndMaxTimestamp(ImmutableSet.of(), maxTs))
                    .isInstanceOf(IllegalArgumentException.class);
            assertThatThrownBy(() -> stateService.findByEventDefinitionsAndMaxTimestamp(null, maxTs))
                    .isInstanceOf(IllegalArgumentException.class);
            assertThatThrownBy(() -> stateService.findByEventDefinitionsAndMaxTimestamp(ImmutableSet.of(id), null))
                    .isInstanceOf(IllegalArgumentException.class);

            assertThat(stateService.findByEventDefinitionsAndMaxTimestamp(ImmutableSet.of(""nope""), maxTs))
                    .hasSize(0);
            assertThat(stateService.findByEventDefinitionsAndMaxTimestamp(ImmutableSet.of(id, ""nope""), maxTs))
                    .hasSize(1);
        });
    }
",non-flaky,5
86106,graylog2_graylog2-server,DBEventProcessorStateServiceTest.setState,"    @Test
    public void setState() {
        final DateTime now = DateTime.now(DateTimeZone.UTC);

        // Before we set the state, there should be no record
        assertThat(stateService.findByEventDefinitionId(""yolo"")).isNotPresent();

        assertThat(stateService.setState(""yolo"", now.minusHours(1), now))
                .isPresent()
                .get()
                .satisfies(dto1 -> {
                    assertThat(dto1.minProcessedTimestamp()).isEqualTo(now.minusHours(1));
                    assertThat(dto1.maxProcessedTimestamp()).isEqualTo(now);
                    assertThat(dto1.eventDefinitionId()).isEqualTo(""yolo"");

                    assertThat(stateService.setState(""yolo"", now, now.plusHours(1)))
                            .isPresent()
                            .get()
                            .satisfies(dto2 -> {
                                // The second setState call should update the existing one
                                assertThat(dto2.id()).isEqualTo(dto1.id());
                                assertThat(dto2.eventDefinitionId()).isEqualTo(""yolo"");
                                assertThat(dto2.minProcessedTimestamp()).isEqualTo(dto1.minProcessedTimestamp());
                                assertThat(dto2.maxProcessedTimestamp()).isEqualTo(dto1.maxProcessedTimestamp().plusHours(1));
                            });
                });
    }
",non-flaky,5
86107,graylog2_graylog2-server,DBEventProcessorStateServiceTest.setStateKeepsMinMaxTimestamp,"    @Test
    public void setStateKeepsMinMaxTimestamp() {
        final DateTime now = DateTime.now(DateTimeZone.UTC);
        final DateTime min = now.minusHours(1);
        final DateTime max = now;

        // Before we set the state, there should be no record
        assertThat(stateService.findByEventDefinitionId(""yolo"")).isNotPresent();

        // Create state
        stateService.setState(""yolo"", min, now);

        // Check that it has been created
        assertThat(stateService.findByEventDefinitionId(""yolo""))
                .isPresent()
                .get()
                .satisfies(dto -> {
                    assertThat(dto.minProcessedTimestamp()).isEqualTo(min);
                    assertThat(dto.maxProcessedTimestamp()).isEqualTo(now);
                });

        // Overwrite state with an EARLIER max timestamp
        stateService.setState(""yolo"", min, max.minusMinutes(10));

        // Max timestamp should NOT be overwritten by older timestamp
        assertThat(stateService.findByEventDefinitionId(""yolo""))
                .isPresent()
                .get()
                .satisfies(dto -> {
                    assertThat(dto.minProcessedTimestamp()).isEqualTo(min);
                    assertThat(dto.maxProcessedTimestamp()).isEqualTo(max);
                });

        // Overwrite state with a LATER min timestamp
        stateService.setState(""yolo"", min.plusMinutes(5), max);

        // Min timestamp should NOT be overwritten by younger timestamp
        assertThat(stateService.findByEventDefinitionId(""yolo""))
                .isPresent()
                .get()
                .satisfies(dto -> {
                    assertThat(dto.minProcessedTimestamp()).isEqualTo(min);
                    assertThat(dto.maxProcessedTimestamp()).isEqualTo(max);
                });

        // Overwrite state with a NEWER max timestamp
        stateService.setState(""yolo"", min, max.plusDays(10));

        // Max timestamp is now set to the newer one
        assertThat(stateService.findByEventDefinitionId(""yolo""))
                .isPresent()
                .get()
                .satisfies(dto -> {
                    assertThat(dto.minProcessedTimestamp()).isEqualTo(min);
                    assertThat(dto.maxProcessedTimestamp()).isEqualTo(max.plusDays(10));
                });

        // Overwrite state with an OLDER min timestamp
        stateService.setState(""yolo"", min.minusDays(100), max.plusDays(10));

        // Min timestamp is now set to the older one
        assertThat(stateService.findByEventDefinitionId(""yolo""))
                .isPresent()
                .get()
                .satisfies(dto -> {
                    assertThat(dto.minProcessedTimestamp()).isEqualTo(min.minusDays(100));
                    assertThat(dto.maxProcessedTimestamp()).isEqualTo(max.plusDays(10));
                });
    }
",non-flaky,5
86108,graylog2_graylog2-server,DBEventProcessorStateServiceTest.deleteByEventProcessorId,"    @Test
    public void deleteByEventProcessorId() {
        assertThat(stateService.deleteByEventDefinitionId(""54e3deadbeefdeadbeefaff3"")).isEqualTo(1);
        assertThat(stateService.deleteByEventDefinitionId(""nope"")).isEqualTo(0);
    }
",non-flaky,5
86109,graylog2_graylog2-server,NotificationFacadeTest.exportEntity,"    @Test
    public void exportEntity() {
        final ModelId id = ModelId.of(""5d4d33753d27460ad18e0c4d"");
        final EntityDescriptor descriptor = EntityDescriptor.create(id, ModelTypes.NOTIFICATION_V1);
        final EntityDescriptorIds entityDescriptorIds = EntityDescriptorIds.of(descriptor);
        final Optional<Entity> entity = facade.exportEntity(descriptor, entityDescriptorIds);
        assertThat(entity).isPresent();
        final EntityV1 entityV1 = (EntityV1) entity.get();
        final NotificationEntity notificationEntity = objectMapper.convertValue(entityV1.data(),
                NotificationEntity.class);
        assertThat(notificationEntity.title().asString()).isEqualTo(""title"");
        assertThat(notificationEntity.description().asString()).isEqualTo(""description"");
        assertThat(notificationEntity.config().type()).isEqualTo(""email-notification-v1"");
    }
",non-flaky,5
86110,graylog2_graylog2-server,NotificationFacadeTest.createNativeEntity,"    @Test
    public void createNativeEntity() {
        final EntityV1 entityV1 = createTestEntity();
        final JobDefinitionDto jobDefinitionDto = mock(JobDefinitionDto.class);

        when(jobDefinitionService.save(any(JobDefinitionDto.class))).thenReturn(jobDefinitionDto);
        final UserImpl kmerzUser = new UserImpl(mock(PasswordAlgorithmFactory.class), new Permissions(ImmutableSet.of()), ImmutableMap.of(""username"", ""kmerz""));
        when(userService.load(""kmerz"")).thenReturn(kmerzUser);

        final NativeEntity<NotificationDto> nativeEntity = facade.createNativeEntity(
            entityV1,
            ImmutableMap.of(),
            ImmutableMap.of(),
            ""kmerz"");
        assertThat(nativeEntity).isNotNull();

        final NotificationDto notificationDto = nativeEntity.entity();
        assertThat(notificationDto.title()).isEqualTo(""title"");
        assertThat(notificationDto.description()).isEqualTo(""descriptions"");
        assertThat(notificationDto.config().type()).isEqualTo(""http-notification-v1"");
    }
",non-flaky,5
86111,graylog2_graylog2-server,NotificationFacadeTest.loadNativeEntity,"    @Test
    public void loadNativeEntity() {
        final NativeEntityDescriptor nativeEntityDescriptor = NativeEntityDescriptor.create(
                ModelId.of(""content-pack-id""),
                ModelId.of(""5d4d33753d27460ad18e0c4d""),
                ModelTypes.NOTIFICATION_V1,
                ""title"");
        final Optional<NativeEntity<NotificationDto>> optionalNativeEntity = facade.loadNativeEntity(
                nativeEntityDescriptor);
        assertThat(optionalNativeEntity).isPresent();
        final NativeEntity<NotificationDto> nativeEntity = optionalNativeEntity.get();
        assertThat(nativeEntity.entity()).isNotNull();
        final NotificationDto notificationDto = nativeEntity.entity();
        assertThat(notificationDto.id()).isEqualTo(""5d4d33753d27460ad18e0c4d"");
    }
",non-flaky,5
86112,graylog2_graylog2-server,NotificationFacadeTest.createExcerpt,"    @Test
    public void createExcerpt() {
        final Optional<NotificationDto> notificationDto = notificationService.get(
                ""5d4d33753d27460ad18e0c4d"");
        assertThat(notificationDto).isPresent();
        final EntityExcerpt excerpt = facade.createExcerpt(notificationDto.get());
        assertThat(excerpt.title()).isEqualTo(""title"");
        assertThat(excerpt.id()).isEqualTo(ModelId.of(""5d4d33753d27460ad18e0c4d""));
        assertThat(excerpt.type()).isEqualTo(ModelTypes.NOTIFICATION_V1);
    }
",non-flaky,5
86113,graylog2_graylog2-server,NotificationFacadeTest.listExcerpts,"    @Test
    public void listExcerpts() {
        final Set<EntityExcerpt> excerpts = facade.listEntityExcerpts();
        final EntityExcerpt excerpt = excerpts.iterator().next();
        assertThat(excerpt.title()).isEqualTo(""title"");
        assertThat(excerpt.id()).isEqualTo(ModelId.of(""5d4d33753d27460ad18e0c4d""));
        assertThat(excerpt.type()).isEqualTo(ModelTypes.NOTIFICATION_V1);
    }
",non-flaky,5
86114,graylog2_graylog2-server,NotificationFacadeTest.delete,"    @Test
    public void delete() {
        long countBefore = notificationService.streamAll().count();
        assertThat(countBefore).isEqualTo(1);

        final Optional<NotificationDto> notificationDto = notificationService.get(
                ""5d4d33753d27460ad18e0c4d"");
        assertThat(notificationDto).isPresent();
        facade.delete(notificationDto.get());

        long countAfter = notificationService.streamAll().count();
        assertThat(countAfter).isEqualTo(0);
    }
",non-flaky,5
86115,graylog2_graylog2-server,EventDefinitionFacadeTest.exportEntity,"    @Test
    public void exportEntity() {
        final ModelId id = ModelId.of(""5d4032513d2746703d1467f6"");

        when(jobDefinitionService.getByConfigField(eq(""event_definition_id""), eq(id.id())))
                .thenReturn(Optional.of(mock(JobDefinitionDto.class)));

        final EntityDescriptor descriptor = EntityDescriptor.create(id, ModelTypes.EVENT_DEFINITION_V1);
        final EntityDescriptorIds entityDescriptorIds = EntityDescriptorIds.of(descriptor);
        final Optional<Entity> entity = facade.exportEntity(descriptor, entityDescriptorIds);
        assertThat(entity).isPresent();
        final EntityV1 entityV1 = (EntityV1) entity.get();
        final EventDefinitionEntity eventDefinitionEntity = objectMapper.convertValue(entityV1.data(),
                EventDefinitionEntity.class);
        assertThat(eventDefinitionEntity.title().asString()).isEqualTo(""title"");
        assertThat(eventDefinitionEntity.description().asString()).isEqualTo(""description"");
        assertThat(eventDefinitionEntity.config().type()).isEqualTo(AggregationEventProcessorConfigEntity.TYPE_NAME);
        assertThat(eventDefinitionEntity.isScheduled().asBoolean(ImmutableMap.of())).isTrue();
    }
",non-flaky,5
86116,graylog2_graylog2-server,EventDefinitionFacadeTest.exportEntityWithoutScheduling,"    @Test
    public void exportEntityWithoutScheduling() {
        final ModelId id = ModelId.of(""5d4032513d2746703d1467f6"");

        when(jobDefinitionService.getByConfigField(eq(""event_definition_id""), eq(id.id())))
                .thenReturn(Optional.empty());

        final EntityDescriptor descriptor = EntityDescriptor.create(id, ModelTypes.EVENT_DEFINITION_V1);
        final EntityDescriptorIds entityDescriptorIds = EntityDescriptorIds.of(descriptor);
        final Optional<Entity> entity = facade.exportEntity(descriptor, entityDescriptorIds);
        assertThat(entity).isPresent();
        final EntityV1 entityV1 = (EntityV1) entity.get();
        final EventDefinitionEntity eventDefinitionEntity = objectMapper.convertValue(entityV1.data(),
                EventDefinitionEntity.class);
        assertThat(eventDefinitionEntity.title().asString()).isEqualTo(""title"");
        assertThat(eventDefinitionEntity.description().asString()).isEqualTo(""description"");
        assertThat(eventDefinitionEntity.config().type()).isEqualTo(AggregationEventProcessorConfigEntity.TYPE_NAME);
        assertThat(eventDefinitionEntity.isScheduled().asBoolean(ImmutableMap.of())).isFalse();
    }
",non-flaky,5
86117,graylog2_graylog2-server,EventDefinitionFacadeTest.createNativeEntity,"    @Test
    public void createNativeEntity() {
        final EntityV1 entityV1 = createTestEntity();
        final NotificationDto notificationDto = NotificationDto.builder()
                .config(HTTPEventNotificationConfig.builder().url(""https://hulud.net"").build())
                .title(""Notify me Senpai"")
                .description(""A notification for senpai"")
                .id(""dead-beef"")
                .build();
        final EntityDescriptor entityDescriptor = EntityDescriptor.create(""123123"", ModelTypes.NOTIFICATION_V1);
        final ImmutableMap<EntityDescriptor, Object> nativeEntities = ImmutableMap.of(
                entityDescriptor, notificationDto);

        final JobDefinitionDto jobDefinitionDto = mock(JobDefinitionDto.class);
        final JobTriggerDto jobTriggerDto = mock(JobTriggerDto.class);
        when(jobDefinitionDto.id()).thenReturn(""job-123123"");
        when(jobSchedulerClock.nowUTC()).thenReturn(DateTime.now(DateTimeZone.UTC));
        when(jobDefinitionService.save(any(JobDefinitionDto.class))).thenReturn(jobDefinitionDto);
        when(jobTriggerService.create(any(JobTriggerDto.class))).thenReturn(jobTriggerDto);
        final UserImpl kmerzUser = new UserImpl(mock(PasswordAlgorithmFactory.class), new Permissions(ImmutableSet.of()), ImmutableMap.of(""username"", ""kmerz""));
        when(userService.load(""kmerz"")).thenReturn(kmerzUser);


        final NativeEntity<EventDefinitionDto> nativeEntity = facade.createNativeEntity(
                entityV1,
                ImmutableMap.of(),
                nativeEntities,
                ""kmerz"");
        assertThat(nativeEntity).isNotNull();

        final EventDefinitionDto eventDefinitionDto = nativeEntity.entity();
        assertThat(eventDefinitionDto.title()).isEqualTo(""title"");
        assertThat(eventDefinitionDto.description()).isEqualTo(""description"");
        assertThat(eventDefinitionDto.config().type()).isEqualTo(""aggregation-v1"");
        // verify that ownership was registered for this entity
        verify(entityOwnershipService, times(1)).registerNewEventDefinition(nativeEntity.entity().id(), kmerzUser);
    }
",non-flaky,5
86118,graylog2_graylog2-server,EventDefinitionFacadeTest.loadNativeEntity,"    @Test
    public void loadNativeEntity() {
        final NativeEntityDescriptor nativeEntityDescriptor = NativeEntityDescriptor
                .create(ModelId.of(""content-pack-id""),
                        ModelId.of(""5d4032513d2746703d1467f6""),
                        ModelTypes.EVENT_DEFINITION_V1,
                        ""title"");
        final Optional<NativeEntity<EventDefinitionDto>> optionalNativeEntity = facade.loadNativeEntity(nativeEntityDescriptor);
        assertThat(optionalNativeEntity).isPresent();
        final NativeEntity<EventDefinitionDto> nativeEntity = optionalNativeEntity.get();
        assertThat(nativeEntity.entity()).isNotNull();
        final EventDefinitionDto eventDefinition = nativeEntity.entity();
        assertThat(eventDefinition.id()).isEqualTo(""5d4032513d2746703d1467f6"");
    }
",non-flaky,5
86119,graylog2_graylog2-server,EventDefinitionFacadeTest.createExcerpt,"    @Test
    public void createExcerpt() {
        final Optional<EventDefinitionDto> eventDefinitionDto = eventDefinitionService.get(
                ""5d4032513d2746703d1467f6"");
        assertThat(eventDefinitionDto).isPresent();
        final EntityExcerpt excerpt = facade.createExcerpt(eventDefinitionDto.get());
        assertThat(excerpt.title()).isEqualTo(""title"");
        assertThat(excerpt.id()).isEqualTo(ModelId.of(""5d4032513d2746703d1467f6""));
        assertThat(excerpt.type()).isEqualTo(ModelTypes.EVENT_DEFINITION_V1);
    }
",non-flaky,5
86120,graylog2_graylog2-server,EventDefinitionFacadeTest.listExcerpts,"    @Test
    public void listExcerpts() {
        final Set<EntityExcerpt> excerpts = facade.listEntityExcerpts();
        final EntityExcerpt excerpt = excerpts.iterator().next();
        assertThat(excerpt.title()).isEqualTo(""title"");
        assertThat(excerpt.id()).isEqualTo(ModelId.of(""5d4032513d2746703d1467f6""));
        assertThat(excerpt.type()).isEqualTo(ModelTypes.EVENT_DEFINITION_V1);
    }
",non-flaky,5
86121,graylog2_graylog2-server,EventDefinitionFacadeTest.delete,"    @Test
    public void delete() {
        long countBefore = eventDefinitionService.streamAll().count();
        assertThat(countBefore).isEqualTo(1);

        final Optional<EventDefinitionDto> eventDefinitionDto = eventDefinitionService.get(
                ""5d4032513d2746703d1467f6"");
        assertThat(eventDefinitionDto).isPresent();
        facade.delete(eventDefinitionDto.get());

        long countAfter = eventDefinitionService.streamAll().count();
        assertThat(countAfter).isEqualTo(0);
    }
",non-flaky,5
86122,graylog2_graylog2-server,EventDefinitionFacadeTest.resolveNativeEntity,"    @Test
    public void resolveNativeEntity() {
        EntityDescriptor eventDescriptor = EntityDescriptor
                .create(""5d4032513d2746703d1467f6"", ModelTypes.EVENT_DEFINITION_V1);
        EntityDescriptor streamDescriptor = EntityDescriptor
                .create(""5cdab2293d27467fbe9e8a72"", ModelTypes.STREAM_V1);
        Set<EntityDescriptor> expectedNodes = ImmutableSet.of(eventDescriptor, streamDescriptor);
        Graph<EntityDescriptor> graph = facade.resolveNativeEntity(eventDescriptor);
        assertThat(graph).isNotNull();
        Set<EntityDescriptor> nodes = graph.nodes();
        assertThat(nodes).isEqualTo(expectedNodes);
    }
",non-flaky,5
86123,graylog2_graylog2-server,EventDefinitionFacadeTest.resolveForInstallation,"    @Test
    public void resolveForInstallation() {
        EntityV1 eventEntityV1 = createTestEntity();

        final NotificationEntity notificationEntity = NotificationEntity.builder()
                .title(ValueReference.of(""title""))
                .description(ValueReference.of(""description""))
                .config(HttpEventNotificationConfigEntity.builder()
                        .url(ValueReference.of(""http://url"")).build())
                .build();
        final JsonNode data = objectMapper.convertValue(notificationEntity, JsonNode.class);
        final EntityV1 notificationV1 = EntityV1.builder()
                .data(data)
                .id(ModelId.of(""123123""))
                .type(ModelTypes.EVENT_DEFINITION_V1)
                .build();

        final EntityDescriptor entityDescriptor = EntityDescriptor.create(""123123"", ModelTypes.NOTIFICATION_V1);

        Map<String, ValueReference> parameters = ImmutableMap.of();
        Map<EntityDescriptor, Entity> entities = ImmutableMap.of(entityDescriptor, notificationV1);

        Graph<Entity> graph = facade.resolveForInstallation(eventEntityV1, parameters, entities);
        assertThat(graph).isNotNull();
        Set<Entity> expectedNodes = ImmutableSet.of(eventEntityV1, notificationV1);
        assertThat(graph.nodes()).isEqualTo(expectedNodes);
    }
",non-flaky,5
86124,graylog2_graylog2-server,LegacyAlertConditionMigratorTest.run,"    @Test
    public void run() {
        final int migratedConditions = 10;
        final int migratedCallbacks = 4;

        assertThat(migrator.run(Collections.emptySet(), Collections.emptySet())).satisfies(result -> {
            assertThat(result.completedAlertConditions()).containsOnly(
                    ""00000000-0000-0000-0000-000000000001"",
                    ""00000000-0000-0000-0000-000000000002"",
                    ""00000000-0000-0000-0000-000000000003"",
                    ""00000000-0000-0000-0000-000000000004"",
                    ""00000000-0000-0000-0000-000000000005"",
                    ""00000000-0000-0000-0000-000000000006"",
                    ""00000000-0000-0000-0000-000000000007"",
                    ""00000000-0000-0000-0000-000000000008"",
                    ""00000000-0000-0000-0000-000000000009"",
                    ""00000000-0000-0000-0000-000000000010""
            );
            assertThat(result.completedAlarmCallbacks()).containsOnly(
                    ""54e3deadbeefdeadbeef0001"",
                    ""54e3deadbeefdeadbeef0002"",
                    ""54e3deadbeefdeadbeef0003"",
                    ""54e3deadbeefdeadbeef0004""
            );
        });

        // Make sure we use the EventDefinitionHandler to create the event definitions
        verify(eventDefinitionHandler, times(migratedConditions)).create(any(EventDefinitionDto.class), any(Optional.class));

        // Make sure we use the NotificationResourceHandler to create the notifications
        verify(notificationResourceHandler, times(migratedCallbacks)).create(any(NotificationDto.class), any(Optional.class));

        assertThat(eventDefinitionService.streamAll().count()).isEqualTo(migratedConditions);
        assertThat(notificationService.streamAll().count()).isEqualTo(migratedCallbacks);

        final NotificationDto httpNotification = notificationService.streamAll()
                .filter(n -> n.title().equals(""HTTP Callback Test""))
                .findFirst()
                .orElse(null);

        assertThat(httpNotification).isNotNull();
        assertThat(httpNotification.title()).isEqualTo(""HTTP Callback Test"");
        assertThat(httpNotification.description()).isEqualTo(""Migrated legacy alarm callback"");
        assertThat(httpNotification.config()).isInstanceOf(LegacyAlarmCallbackEventNotificationConfig.class);
        assertThat((LegacyAlarmCallbackEventNotificationConfig) httpNotification.config()).satisfies(config -> {
            assertThat(config.callbackType()).isEqualTo(""org.graylog2.alarmcallbacks.HTTPAlarmCallback"");
            assertThat(config.configuration().get(""url"")).isEqualTo(""http://localhost:11000/"");
        });

        final NotificationDto httpNotificationWithoutTitle = notificationService.streamAll()
                .filter(n -> n.title().equals(""Untitled""))
                .findFirst()
                .orElse(null);

        assertThat(httpNotificationWithoutTitle).isNotNull();
        assertThat(httpNotificationWithoutTitle.title()).isEqualTo(""Untitled"");
        assertThat(httpNotificationWithoutTitle.description()).isEqualTo(""Migrated legacy alarm callback"");
        assertThat(httpNotificationWithoutTitle.config()).isInstanceOf(LegacyAlarmCallbackEventNotificationConfig.class);
        assertThat((LegacyAlarmCallbackEventNotificationConfig) httpNotificationWithoutTitle.config()).satisfies(config -> {
            assertThat(config.callbackType()).isEqualTo(""org.graylog2.alarmcallbacks.HTTPAlarmCallback"");
            assertThat(config.configuration().get(""url"")).isEqualTo(""http://localhost:11000/"");
        });

        final NotificationDto emailNotification = notificationService.streamAll()
                .filter(n -> n.title().equals(""Email Callback Test""))
                .findFirst()
                .orElse(null);

        assertThat(emailNotification).isNotNull();
        assertThat(emailNotification.title()).isEqualTo(""Email Callback Test"");
        assertThat(emailNotification.description()).isEqualTo(""Migrated legacy alarm callback"");
        assertThat(emailNotification.config()).isInstanceOf(LegacyAlarmCallbackEventNotificationConfig.class);
        assertThat((LegacyAlarmCallbackEventNotificationConfig) emailNotification.config()).satisfies(config -> {
            assertThat(config.callbackType()).isEqualTo(""org.graylog2.alarmcallbacks.EmailAlarmCallback"");
            assertThat(config.configuration().get(""sender"")).isEqualTo(""graylog@example.org"");
            assertThat(config.configuration().get(""subject"")).isEqualTo(""Graylog alert for stream: ${stream.title}: ${check_result.resultDescription}"");
            assertThat((String) config.configuration().get(""body"")).contains(""Alert Description: ${check_result.resultDescription}\nDate: "");
            assertThat(config.configuration().get(""user_receivers"")).isEqualTo(Collections.emptyList());
            assertThat(config.configuration().get(""email_receivers"")).isEqualTo(Collections.singletonList(""jane@example.org""));
        });

        final NotificationDto slackNotification = notificationService.streamAll()
                .filter(n -> n.title().equals(""Slack Callback Test""))
                .findFirst()
                .orElse(null);

        assertThat(slackNotification).isNotNull();
        assertThat(slackNotification.title()).isEqualTo(""Slack Callback Test"");
        assertThat(slackNotification.description()).isEqualTo(""Migrated legacy alarm callback"");
        assertThat(slackNotification.config()).isInstanceOf(LegacyAlarmCallbackEventNotificationConfig.class);
        assertThat((LegacyAlarmCallbackEventNotificationConfig) slackNotification.config()).satisfies(config -> {
            assertThat(config.callbackType()).isEqualTo(""org.graylog2.plugins.slack.callback.SlackAlarmCallback"");
            assertThat(config.configuration().get(""icon_url"")).isEqualTo("""");
            assertThat(config.configuration().get(""graylog2_url"")).isEqualTo("""");
            assertThat(config.configuration().get(""link_names"")).isEqualTo(true);
            assertThat(config.configuration().get(""webhook_url"")).isEqualTo(""http://example.com/slack-hook"");
            assertThat(config.configuration().get(""color"")).isEqualTo(""#FF0000"");
            assertThat(config.configuration().get(""icon_emoji"")).isEqualTo("""");
            assertThat(config.configuration().get(""user_name"")).isEqualTo(""Graylog"");
            assertThat(config.configuration().get(""backlog_items"")).isEqualTo(5);
            assertThat(config.configuration().get(""custom_fields"")).isEqualTo("""");
            assertThat(config.configuration().get(""proxy_address"")).isEqualTo("""");
            assertThat(config.configuration().get(""channel"")).isEqualTo(""#channel"");
            assertThat(config.configuration().get(""notify_channel"")).isEqualTo(false);
            assertThat(config.configuration().get(""add_attachment"")).isEqualTo(true);
            assertThat(config.configuration().get(""short_mode"")).isEqualTo(false);
        });

        assertThat(eventDefinitionService.streamAll().filter(ed -> ed.title().equals(""Message Count - MORE"")).findFirst())
                .get()
                .satisfies(eventDefinition -> {
                    assertThat(eventDefinition.alert()).isTrue();
                    assertThat(eventDefinition.priority()).isEqualTo(2);
                    assertThat(eventDefinition.keySpec()).isEmpty();
                    assertThat(eventDefinition.notificationSettings().gracePeriodMs()).isEqualTo(120000);
                    assertThat(eventDefinition.notificationSettings().backlogSize()).isEqualTo(10);

                    assertThat(eventDefinition.notifications()).hasSize(2);
                    assertThat(eventDefinition.notifications().stream().map(EventNotificationHandler.Config::notificationId).collect(Collectors.toList()))
                            .containsOnly(httpNotification.id(), httpNotificationWithoutTitle.id());

                    assertThat((AggregationEventProcessorConfig) eventDefinition.config()).satisfies(config -> {
                        assertThat(config.streams()).containsExactly(""54e3deadbeefdeadbeef0001"");
                        assertThat(config.query()).isEqualTo(""hello:world"");
                        assertThat(config.groupBy()).isEmpty();
                        assertThat(config.searchWithinMs()).isEqualTo(10 * 60 * 1000);
                        assertThat(config.executeEveryMs()).isEqualTo(CHECK_INTERVAL * 1000);

                        assertThat(config.series()).hasSize(1);
                        assertThat(config.series().get(0).id()).isNotBlank();
                        assertThat(config.series().get(0).function()).isEqualTo(AggregationFunction.COUNT);
                        assertThat(config.series().get(0).field()).isNotPresent();

                        assertThat(config.conditions()).get().satisfies(conditions -> {
                            assertThat(conditions.expression()).get().satisfies(expression -> {
                                assertThat(expression).isInstanceOf(Expr.Greater.class);

                                final Expr.Greater greater = (Expr.Greater) expression;

                                assertThat(greater.left()).isEqualTo(Expr.NumberReference.create(config.series().get(0).id()));
                                assertThat(greater.right()).isEqualTo(Expr.NumberValue.create(1));
                            });
                        });
                    });
                });

        assertThat(eventDefinitionService.streamAll().filter(ed -> ed.title().equals(""Message Count - LESS"")).findFirst())
                .get()
                .satisfies(eventDefinition -> {
                    assertThat(eventDefinition.alert()).isTrue();
                    assertThat(eventDefinition.priority()).isEqualTo(2);
                    assertThat(eventDefinition.keySpec()).isEmpty();
                    assertThat(eventDefinition.notificationSettings().gracePeriodMs()).isEqualTo(0);
                    assertThat(eventDefinition.notificationSettings().backlogSize()).isEqualTo(0);

                    assertThat(eventDefinition.notifications()).hasSize(2);
                    assertThat(eventDefinition.notifications().stream().map(EventNotificationHandler.Config::notificationId).collect(Collectors.toList()))
                            .containsOnly(httpNotification.id(), httpNotificationWithoutTitle.id());

                    assertThat((AggregationEventProcessorConfig) eventDefinition.config()).satisfies(config -> {
                        assertThat(config.streams()).containsExactly(""54e3deadbeefdeadbeef0001"");
                        assertThat(config.query()).isEmpty();
                        assertThat(config.groupBy()).isEmpty();
                        assertThat(config.searchWithinMs()).isEqualTo(4 * 60 * 1000);
                        assertThat(config.executeEveryMs()).isEqualTo(CHECK_INTERVAL * 1000);

                        assertThat(config.series()).hasSize(1);
                        assertThat(config.series().get(0).id()).isNotBlank();
                        assertThat(config.series().get(0).function()).isEqualTo(AggregationFunction.COUNT);
                        assertThat(config.series().get(0).field()).isNotPresent();

                        assertThat(config.conditions()).get().satisfies(conditions -> {
                            assertThat(conditions.expression()).get().satisfies(expression -> {
                                assertThat(expression).isInstanceOf(Expr.Lesser.class);

                                final Expr.Lesser lesser = (Expr.Lesser) expression;

                                assertThat(lesser.left()).isEqualTo(Expr.NumberReference.create(config.series().get(0).id()));
                                assertThat(lesser.right()).isEqualTo(Expr.NumberValue.create(42));
                            });
                        });
                    });
                });

        assertThat(eventDefinitionService.streamAll().filter(ed -> ed.title().equals(""Field Value - HIGHER - MEAN"")).findFirst())
                .get()
                .satisfies(eventDefinition -> {
                    assertThat(eventDefinition.alert()).isTrue();
                    assertThat(eventDefinition.priority()).isEqualTo(2);
                    assertThat(eventDefinition.keySpec()).isEmpty();
                    assertThat(eventDefinition.notificationSettings().gracePeriodMs()).isEqualTo(60000);
                    assertThat(eventDefinition.notificationSettings().backlogSize()).isEqualTo(15);
                    assertThat(eventDefinition.notifications()).isEmpty();

                    assertThat((AggregationEventProcessorConfig) eventDefinition.config()).satisfies(config -> {
                        assertThat(config.streams()).containsExactly(""54e3deadbeefdeadbeef0002"");
                        assertThat(config.query()).isEqualTo(""*"");
                        assertThat(config.groupBy()).isEmpty();
                        assertThat(config.searchWithinMs()).isEqualTo(5 * 60 * 1000);
                        assertThat(config.executeEveryMs()).isEqualTo(CHECK_INTERVAL * 1000);

                        assertThat(config.series()).hasSize(1);
                        assertThat(config.series().get(0).id()).isNotBlank();
                        assertThat(config.series().get(0).function()).isEqualTo(AggregationFunction.AVG);
                        assertThat(config.series().get(0).field()).get().isEqualTo(""test_field_1"");

                        assertThat(config.conditions()).get().satisfies(conditions -> {
                            assertThat(conditions.expression()).get().satisfies(expression -> {
                                assertThat(expression).isInstanceOf(Expr.Greater.class);

                                final Expr.Greater greater = (Expr.Greater) expression;

                                assertThat(greater.left()).isEqualTo(Expr.NumberReference.create(config.series().get(0).id()));
                                assertThat(greater.right()).isEqualTo(Expr.NumberValue.create(23));
                            });
                        });
                    });
                });

        assertThat(eventDefinitionService.streamAll().filter(ed -> ed.title().equals(""Field Value - LOWER - SUM"")).findFirst())
                .get()
                .satisfies(eventDefinition -> {
                    assertThat(eventDefinition.alert()).isTrue();
                    assertThat(eventDefinition.priority()).isEqualTo(2);
                    assertThat(eventDefinition.keySpec()).isEmpty();
                    assertThat(eventDefinition.notificationSettings().gracePeriodMs()).isEqualTo(60000);
                    assertThat(eventDefinition.notificationSettings().backlogSize()).isEqualTo(15);
                    assertThat(eventDefinition.notifications()).isEmpty();

                    assertThat((AggregationEventProcessorConfig) eventDefinition.config()).satisfies(config -> {
                        assertThat(config.streams()).containsExactly(""54e3deadbeefdeadbeef0002"");
                        assertThat(config.query()).isEqualTo(""*"");
                        assertThat(config.groupBy()).isEmpty();
                        assertThat(config.searchWithinMs()).isEqualTo(5 * 60 * 1000);
                        assertThat(config.executeEveryMs()).isEqualTo(CHECK_INTERVAL * 1000);

                        assertThat(config.series()).hasSize(1);
                        assertThat(config.series().get(0).id()).isNotBlank();
                        assertThat(config.series().get(0).function()).isEqualTo(AggregationFunction.SUM);
                        assertThat(config.series().get(0).field()).get().isEqualTo(""test_field_1"");

                        assertThat(config.conditions()).get().satisfies(conditions -> {
                            assertThat(conditions.expression()).get().satisfies(expression -> {
                                assertThat(expression).isInstanceOf(Expr.Lesser.class);

                                final Expr.Lesser lesser = (Expr.Lesser) expression;

                                assertThat(lesser.left()).isEqualTo(Expr.NumberReference.create(config.series().get(0).id()));
                                assertThat(lesser.right()).isEqualTo(Expr.NumberValue.create(23));
                            });
                        });
                    });
                });

        assertThat(eventDefinitionService.streamAll().filter(ed -> ed.title().equals(""Field Value - LOWER - MIN"")).findFirst())
                .get()
                .satisfies(eventDefinition -> {
                    assertThat(eventDefinition.alert()).isTrue();
                    assertThat(eventDefinition.priority()).isEqualTo(2);
                    assertThat(eventDefinition.keySpec()).isEmpty();
                    assertThat(eventDefinition.notificationSettings().gracePeriodMs()).isEqualTo(60000);
                    assertThat(eventDefinition.notificationSettings().backlogSize()).isEqualTo(15);
                    assertThat(eventDefinition.notifications()).isEmpty();

                    assertThat((AggregationEventProcessorConfig) eventDefinition.config()).satisfies(config -> {
                        assertThat(config.streams()).containsExactly(""54e3deadbeefdeadbeef0002"");
                        assertThat(config.query()).isEqualTo(""*"");
                        assertThat(config.groupBy()).isEmpty();
                        assertThat(config.searchWithinMs()).isEqualTo(5 * 60 * 1000);
                        assertThat(config.executeEveryMs()).isEqualTo(CHECK_INTERVAL * 1000);

                        assertThat(config.series()).hasSize(1);
                        assertThat(config.series().get(0).id()).isNotBlank();
                        assertThat(config.series().get(0).function()).isEqualTo(AggregationFunction.MIN);
                        assertThat(config.series().get(0).field()).get().isEqualTo(""test_field_1"");

                        assertThat(config.conditions()).get().satisfies(conditions -> {
                            assertThat(conditions.expression()).get().satisfies(expression -> {
                                assertThat(expression).isInstanceOf(Expr.Lesser.class);

                                final Expr.Lesser lesser = (Expr.Lesser) expression;

                                assertThat(lesser.left()).isEqualTo(Expr.NumberReference.create(config.series().get(0).id()));
                                assertThat(lesser.right()).isEqualTo(Expr.NumberValue.create(23));
                            });
                        });
                    });
                });

        assertThat(eventDefinitionService.streamAll().filter(ed -> ed.title().equals(""Field Value - LOWER - MAX"")).findFirst())
                .get()
                .satisfies(eventDefinition -> {
                    assertThat(eventDefinition.alert()).isTrue();
                    assertThat(eventDefinition.priority()).isEqualTo(2);
                    assertThat(eventDefinition.keySpec()).isEmpty();
                    assertThat(eventDefinition.notificationSettings().gracePeriodMs()).isEqualTo(60000);
                    assertThat(eventDefinition.notificationSettings().backlogSize()).isEqualTo(15);
                    assertThat(eventDefinition.notifications()).isEmpty();

                    assertThat((AggregationEventProcessorConfig) eventDefinition.config()).satisfies(config -> {
                        assertThat(config.streams()).containsExactly(""54e3deadbeefdeadbeef0002"");
                        assertThat(config.query()).isEqualTo(""*"");
                        assertThat(config.groupBy()).isEmpty();
                        assertThat(config.searchWithinMs()).isEqualTo(5 * 60 * 1000);
                        assertThat(config.executeEveryMs()).isEqualTo(CHECK_INTERVAL * 1000);

                        assertThat(config.series()).hasSize(1);
                        assertThat(config.series().get(0).id()).isNotBlank();
                        assertThat(config.series().get(0).function()).isEqualTo(AggregationFunction.MAX);
                        assertThat(config.series().get(0).field()).get().isEqualTo(""test_field_1"");

                        assertThat(config.conditions()).get().satisfies(conditions -> {
                            assertThat(conditions.expression()).get().satisfies(expression -> {
                                assertThat(expression).isInstanceOf(Expr.Lesser.class);

                                final Expr.Lesser lesser = (Expr.Lesser) expression;

                                assertThat(lesser.left()).isEqualTo(Expr.NumberReference.create(config.series().get(0).id()));
                                assertThat(lesser.right()).isEqualTo(Expr.NumberValue.create(23));
                            });
                        });
                    });
                });

        assertThat(eventDefinitionService.streamAll().filter(ed -> ed.title().equals(""Field Value - LOWER - STDDEV"")).findFirst())
                .get()
                .satisfies(eventDefinition -> {
                    assertThat(eventDefinition.alert()).isTrue();
                    assertThat(eventDefinition.priority()).isEqualTo(2);
                    assertThat(eventDefinition.keySpec()).isEmpty();
                    assertThat(eventDefinition.notificationSettings().gracePeriodMs()).isEqualTo(60000);
                    assertThat(eventDefinition.notificationSettings().backlogSize()).isEqualTo(15);
                    assertThat(eventDefinition.notifications()).isEmpty();

                    assertThat((AggregationEventProcessorConfig) eventDefinition.config()).satisfies(config -> {
                        assertThat(config.streams()).containsExactly(""54e3deadbeefdeadbeef0002"");
                        assertThat(config.query()).isEqualTo(""*"");
                        assertThat(config.groupBy()).isEmpty();
                        assertThat(config.searchWithinMs()).isEqualTo(5 * 60 * 1000);
                        assertThat(config.executeEveryMs()).isEqualTo(CHECK_INTERVAL * 1000);

                        assertThat(config.series()).hasSize(1);
                        assertThat(config.series().get(0).id()).isNotBlank();
                        assertThat(config.series().get(0).function()).isEqualTo(AggregationFunction.STDDEV);
                        assertThat(config.series().get(0).field()).get().isEqualTo(""test_field_1"");

                        assertThat(config.conditions()).get().satisfies(conditions -> {
                            assertThat(conditions.expression()).get().satisfies(expression -> {
                                assertThat(expression).isInstanceOf(Expr.Greater.class);

                                final Expr.Greater greater = (Expr.Greater) expression;

                                assertThat(greater.left()).isEqualTo(Expr.NumberReference.create(config.series().get(0).id()));
                                assertThat(greater.right()).isEqualTo(Expr.NumberValue.create(23));
                            });
                        });
                    });
                });

        assertThat(eventDefinitionService.streamAll().filter(ed -> ed.title().equals(""Field Content - WITHOUT QUERY"")).findFirst())
                .get()
                .satisfies(eventDefinition -> {
                    assertThat(eventDefinition.alert()).isTrue();
                    assertThat(eventDefinition.priority()).isEqualTo(2);
                    assertThat(eventDefinition.keySpec()).isEmpty();
                    assertThat(eventDefinition.notificationSettings().gracePeriodMs()).isEqualTo(120000);
                    assertThat(eventDefinition.notificationSettings().backlogSize()).isEqualTo(100);

                    assertThat(eventDefinition.notifications()).hasSize(2);
                    assertThat(eventDefinition.notifications().stream().map(EventNotificationHandler.Config::notificationId).collect(Collectors.toSet()))
                            .containsOnly(emailNotification.id(), slackNotification.id());

                    assertThat((AggregationEventProcessorConfig) eventDefinition.config()).satisfies(config -> {
                        assertThat(config.streams()).containsExactly(""54e3deadbeefdeadbeef0003"");
                        assertThat(config.query()).isEqualTo(""test_field_2:\""hello\"""");
                        assertThat(config.groupBy()).isEmpty();
                        assertThat(config.searchWithinMs()).isEqualTo(CHECK_INTERVAL * 1000);
                        assertThat(config.executeEveryMs()).isEqualTo(CHECK_INTERVAL * 1000);

                        assertThat(config.series()).hasSize(1);
                        assertThat(config.series().get(0).id()).isNotBlank();
                        assertThat(config.series().get(0).function()).isEqualTo(AggregationFunction.COUNT);
                        assertThat(config.series().get(0).field()).isNotPresent();

                        assertThat(config.conditions()).get().satisfies(conditions -> {
                            assertThat(conditions.expression()).get().satisfies(expression -> {
                                assertThat(expression).isInstanceOf(Expr.Greater.class);

                                final Expr.Greater greater = (Expr.Greater) expression;

                                assertThat(greater.left()).isEqualTo(Expr.NumberReference.create(config.series().get(0).id()));
                                assertThat(greater.right()).isEqualTo(Expr.NumberValue.create(0));
                            });
                        });
                    });
                });

        assertThat(eventDefinitionService.streamAll().filter(ed -> ed.title().equals(""Field Content - WITH QUERY"")).findFirst())
                .get()
                .satisfies(eventDefinition -> {
                    assertThat(eventDefinition.alert()).isTrue();
                    assertThat(eventDefinition.priority()).isEqualTo(2);
                    assertThat(eventDefinition.keySpec()).isEmpty();
                    assertThat(eventDefinition.notificationSettings().gracePeriodMs()).isEqualTo(0);
                    assertThat(eventDefinition.notificationSettings().backlogSize()).isEqualTo(0);

                    assertThat(eventDefinition.notifications()).hasSize(2);
                    assertThat(eventDefinition.notifications().stream().map(EventNotificationHandler.Config::notificationId).collect(Collectors.toSet()))
                            .containsOnly(emailNotification.id(), slackNotification.id());

                    assertThat((AggregationEventProcessorConfig) eventDefinition.config()).satisfies(config -> {
                        assertThat(config.streams()).containsExactly(""54e3deadbeefdeadbeef0003"");
                        assertThat(config.query()).isEqualTo(""test_field_3:\""foo\"" AND foo:bar"");
                        assertThat(config.groupBy()).isEmpty();
                        assertThat(config.searchWithinMs()).isEqualTo(CHECK_INTERVAL * 1000);
                        assertThat(config.executeEveryMs()).isEqualTo(CHECK_INTERVAL * 1000);

                        assertThat(config.series()).hasSize(1);
                        assertThat(config.series().get(0).id()).isNotBlank();
                        assertThat(config.series().get(0).function()).isEqualTo(AggregationFunction.COUNT);
                        assertThat(config.series().get(0).field()).isNotPresent();

                        assertThat(config.conditions()).get().satisfies(conditions -> {
                            assertThat(conditions.expression()).get().satisfies(expression -> {
                                assertThat(expression).isInstanceOf(Expr.Greater.class);

                                final Expr.Greater greater = (Expr.Greater) expression;

                                assertThat(greater.left()).isEqualTo(Expr.NumberReference.create(config.series().get(0).id()));
                                assertThat(greater.right()).isEqualTo(Expr.NumberValue.create(0));
                            });
                        });
                    });
                });

        assertThat(eventDefinitionService.streamAll().filter(ed -> ed.title().equals(""Untitled"")).findFirst())
                .get()
                .satisfies(eventDefinition -> {
                    assertThat(eventDefinition.alert()).isTrue();
                    assertThat(eventDefinition.priority()).isEqualTo(2);
                    assertThat(eventDefinition.keySpec()).isEmpty();
                    assertThat(eventDefinition.notificationSettings().gracePeriodMs()).isEqualTo(0);
                    assertThat(eventDefinition.notificationSettings().backlogSize()).isEqualTo(0);

                    assertThat(eventDefinition.notifications()).hasSize(2);
                    assertThat(eventDefinition.notifications().stream().map(EventNotificationHandler.Config::notificationId).collect(Collectors.toSet()))
                            .containsOnly(emailNotification.id(), slackNotification.id());

                    assertThat((AggregationEventProcessorConfig) eventDefinition.config()).satisfies(config -> {
                        assertThat(config.streams()).containsExactly(""54e3deadbeefdeadbeef0003"");
                        assertThat(config.query()).isEqualTo(""test_field_3:\""foo\"" AND foo:bar"");
                        assertThat(config.groupBy()).isEmpty();
                        assertThat(config.searchWithinMs()).isEqualTo(CHECK_INTERVAL * 1000);
                        assertThat(config.executeEveryMs()).isEqualTo(CHECK_INTERVAL * 1000);

                        assertThat(config.series()).hasSize(1);
                        assertThat(config.series().get(0).id()).isNotBlank();
                        assertThat(config.series().get(0).function()).isEqualTo(AggregationFunction.COUNT);
                        assertThat(config.series().get(0).field()).isNotPresent();

                        assertThat(config.conditions()).get().satisfies(conditions -> {
                            assertThat(conditions.expression()).get().satisfies(expression -> {
                                assertThat(expression).isInstanceOf(Expr.Greater.class);

                                final Expr.Greater greater = (Expr.Greater) expression;

                                assertThat(greater.left()).isEqualTo(Expr.NumberReference.create(config.series().get(0).id()));
                                assertThat(greater.right()).isEqualTo(Expr.NumberValue.create(0));
                            });
                        });
                    });
                });
    }
",non-flaky,5
86125,graylog2_graylog2-server,LegacyAlertConditionMigratorTest.runWithMigrationStatus,"    @Test
    public void runWithMigrationStatus() {
        final int migratedConditions = 9; // Only 8 because we pass one migrated condition in
        final int migratedCallbacks = 3;  // Only 2 because we pass one migrated callback in

        assertThat(migrator.run(Collections.singleton(""00000000-0000-0000-0000-000000000002""), Collections.singleton(""54e3deadbeefdeadbeef0001""))).satisfies(result -> {
            assertThat(result.completedAlertConditions()).containsOnly(
                    ""00000000-0000-0000-0000-000000000001"",
                    ""00000000-0000-0000-0000-000000000002"",
                    ""00000000-0000-0000-0000-000000000003"",
                    ""00000000-0000-0000-0000-000000000004"",
                    ""00000000-0000-0000-0000-000000000005"",
                    ""00000000-0000-0000-0000-000000000006"",
                    ""00000000-0000-0000-0000-000000000007"",
                    ""00000000-0000-0000-0000-000000000008"",
                    ""00000000-0000-0000-0000-000000000009"",
                    ""00000000-0000-0000-0000-000000000010""
            );
            assertThat(result.completedAlarmCallbacks()).containsOnly(
                    ""54e3deadbeefdeadbeef0001"",
                    ""54e3deadbeefdeadbeef0002"",
                    ""54e3deadbeefdeadbeef0003"",
                    ""54e3deadbeefdeadbeef0004""
            );
        });

        // Make sure we use the EventDefinitionHandler to create the event definitions
        verify(eventDefinitionHandler, times(migratedConditions)).create(any(EventDefinitionDto.class), any(Optional.class));

        // Make sure we use the NotificationResourceHandler to create the notifications
        verify(notificationResourceHandler, times(migratedCallbacks)).create(any(NotificationDto.class), any(Optional.class));

        assertThat(eventDefinitionService.streamAll().count()).isEqualTo(migratedConditions);
        assertThat(notificationService.streamAll().count()).isEqualTo(migratedCallbacks);
    }
",non-flaky,5
86126,graylog2_graylog2-server,LookupTableFieldValueProviderTest.testWithMessageContext,"    @Test
    public void testWithMessageContext() {
        final String fieldValueString = ""world"";
        final String expectedLookupValue = ""lookup-world"";

        final TestEvent event = new TestEvent();
        final Message message = newMessage(ImmutableMap.of(""hello"", fieldValueString));
        final EventWithContext eventWithContext = EventWithContext.create(event, message);

        final LookupTableFieldValueProvider.Config config = newConfig(""test"", ""hello"");

        setupMocks(""test"");
        when(lookupTableFunction.lookup(""world"")).thenReturn(LookupResult.single(""lookup-"" + message.getField(""hello"")));

        final FieldValue fieldValue = newProvider(config).doGet(""test"", eventWithContext);

        assertThat(fieldValue.value()).isEqualTo(expectedLookupValue);
    }
",non-flaky,5
86127,graylog2_graylog2-server,LookupTableFieldValueProviderTest.testWithEventContext,"    @Test
    public void testWithEventContext() {
        final String fieldValueString = ""event"";
        final String expectedLookupValue = ""lookup-event"";

        final TestEvent event = new TestEvent();
        final TestEvent eventContext = new TestEvent();

        eventContext.setField(""hello"", FieldValue.string(fieldValueString));

        final EventWithContext eventWithContext = EventWithContext.create(event, eventContext);

        final LookupTableFieldValueProvider.Config config = newConfig(""test"", ""hello"");

        setupMocks(""test"");
        when(lookupTableFunction.lookup(fieldValueString)).thenReturn(LookupResult.single(""lookup-"" + eventContext.getField(""hello"").value()));

        final FieldValue fieldValue = newProvider(config).doGet(""test"", eventWithContext);

        assertThat(fieldValue.value()).isEqualTo(expectedLookupValue);
    }
",non-flaky,5
86128,graylog2_graylog2-server,LookupTableFieldValueProviderTest.testWithMissingLookupTable,"    @Test
    public void testWithMissingLookupTable() {
        final TestEvent event = new TestEvent();
        final EventWithContext eventWithContext = EventWithContext.create(event, newMessage(ImmutableMap.of(""hello"", ""world"")));

        final LookupTableFieldValueProvider.Config config = newConfig(""test-doesntexist"", ""hello"");

        setupMocks(""test"");
        when(lookupTableFunction.lookup(""world"")).thenReturn(LookupResult.single(""lookup-world""));

        assertThatThrownBy(() -> newProvider(config).doGet(""test"", eventWithContext))
                .hasMessageContaining(""test-doesntexist"")
                .isInstanceOf(IllegalArgumentException.class);
    }
",non-flaky,5
86129,graylog2_graylog2-server,TemplateFieldValueProviderTest.templateWithMessageContext,"    @Test
    public void templateWithMessageContext() {
        final TestEvent event = new TestEvent();
        final EventWithContext eventWithContext = EventWithContext.create(event, newMessage(ImmutableMap.of(""hello"", ""world"")));

        final FieldValue fieldValue = newTemplate(""hello: ${source.hello}"").doGet(""test"", eventWithContext);

        assertThat(fieldValue.value()).isEqualTo(""hello: world"");
    }
",non-flaky,5
86130,graylog2_graylog2-server,TemplateFieldValueProviderTest.templateWithEventContext,"    @Test
    public void templateWithEventContext() {
        final TestEvent event = new TestEvent();
        final TestEvent eventContext = new TestEvent();

        eventContext.setField(""hello"", FieldValue.string(""event""));

        final EventWithContext eventWithContext = EventWithContext.create(event, eventContext);

        final FieldValue fieldValue = newTemplate(""hello: ${source.hello}"").doGet(""test"", eventWithContext);

        assertThat(fieldValue.value()).isEqualTo(""hello: event"");
    }
",non-flaky,5
86131,graylog2_graylog2-server,TemplateFieldValueProviderTest.templateWithError,"    @Test
    public void templateWithError() {
        final TestEvent event = new TestEvent();
        final EventWithContext eventWithContext = EventWithContext.create(event, newMessage(ImmutableMap.of(""hello"", ""world"")));

        final FieldValue fieldValue = newTemplate(""hello: ${source.yolo}"", true).doGet(""test"", eventWithContext);

        assertThat(fieldValue.dataType()).isEqualTo(FieldValueType.ERROR);
    }
",non-flaky,5
86132,graylog2_graylog2-server,TemplateFieldValueProviderTest.templateCalculation,"    @Test
    @Ignore(""template engine doesn't support expressions"")
    public void templateCalculation() {
        final TestEvent event = new TestEvent();
        final EventWithContext eventWithContext = EventWithContext.create(event, newMessage(ImmutableMap.of(""bytes"", 1024)));

        final FieldValue fieldValue = newTemplate(""${source.bytes / 1024}"").doGet(""test"", eventWithContext);

        assertThat(fieldValue.value()).isEqualTo(""1"");
    }
",non-flaky,5
86133,graylog2_graylog2-server,TemplateFieldValueProviderTest.templateNumberFormatting,"    @Test
    public void templateNumberFormatting() {
        final TestEvent event = new TestEvent();
        final EventWithContext eventWithContext = EventWithContext.create(event, newMessage(ImmutableMap.of(""count"", 10241234, ""avg"", 1024.42)));

        final FieldValue fieldValue = newTemplate(""count: ${source.count} avg: ${source.avg}"").doGet(""test"", eventWithContext);

        assertThat(fieldValue.value()).isEqualTo(""count: 10241234 avg: 1024.42"");
    }
",non-flaky,5
86134,graylog2_graylog2-server,TemplateFieldValueProviderTest.templateDateFormatting,"    @Test
    public void templateDateFormatting() {
        final TestEvent event = new TestEvent();
        final EventWithContext eventWithContext = EventWithContext.create(event, newMessage(ImmutableMap.of(""timestamp"", DateTime.parse(""2019-07-02T12:21:00.123Z""))));

        final FieldValue fieldValue = newTemplate(""timestamp: ${source.timestamp}"").doGet(""test"", eventWithContext);

        assertThat(fieldValue.value()).isEqualTo(""timestamp: 2019-07-02T12:21:00.123Z"");
    }
",non-flaky,5
86135,graylog2_graylog2-server,TemplateFieldValueProviderTest.templateBooleanFormatting,"    @Test
    public void templateBooleanFormatting() {
        final TestEvent event = new TestEvent();
        final EventWithContext eventWithContext = EventWithContext.create(event, newMessage(ImmutableMap.of(""success"", true)));

        final FieldValue fieldValue = newTemplate(""success: ${source.success}"").doGet(""test"", eventWithContext);

        assertThat(fieldValue.value()).isEqualTo(""success: true"");
    }
",non-flaky,5
86136,graylog2_graylog2-server,ESMongoDateTimeDeserializerTest.deserializeDateTime,"    @Test
    public void deserializeDateTime() throws Exception {
        final String json = ""{\""date_time\"":\""2016-12-13 14:00:00.000\""}"";
        final DTO value = objectMapper.readValue(json, DTO.class);
        assertThat(value.dateTime).isEqualTo(new DateTime(2016, 12, 13, 14, 0, DateTimeZone.UTC));
    }
",non-flaky,5
86137,graylog2_graylog2-server,ESMongoDateTimeDeserializerTest.deserializeIsoDateTime,"    @Test
    public void deserializeIsoDateTime() throws Exception {
        final String json = ""{\""date_time\"":\""2016-12-13T14:00:00.000\""}"";
        final DTO value = objectMapper.readValue(json, DTO.class);
        assertThat(value.dateTime).isEqualTo(new DateTime(2016, 12, 13, 14, 0, DateTimeZone.UTC));
    }
",non-flaky,5
91367,OpenLCB_OpenLCB_Java,StreamDataSendMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        int data[]={0x00,0x00,0x00,0x00};
        StreamDataSendMessage t = new StreamDataSendMessage(id1,id2,data);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91368,OpenLCB_OpenLCB_Java,TractionProxyReplyMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID src = new NodeID(new byte[]{6,5,5,4,4,3});
        NodeID dst = new NodeID(new byte[]{2,2,2,4,4,4});
        byte[] payload = new byte[]{0x40,0x01,0x00}; // Traciton Management Reply message
        TractionProxyReplyMessage t = new TractionProxyReplyMessage(src,dst,payload);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91369,OpenLCB_OpenLCB_Java,TractionProxyRequestMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID src = new NodeID(new byte[]{6,5,5,4,4,3});
        NodeID dst = new NodeID(new byte[]{2,2,2,4,4,4});
        byte[] payload = new byte[]{0x40,0x01,0x00}; // Traciton Management Reply message
        TractionProxyRequestMessage t = new TractionProxyRequestMessage(src,dst,payload);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91370,OpenLCB_OpenLCB_Java,TractionControlReplyMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID src = new NodeID(new byte[]{6,5,5,4,4,3});
        NodeID dst = new NodeID(new byte[]{2,2,2,4,4,4});
        byte[] payload = new byte[]{0x40,0x01,0x00}; // Traciton Management Reply message
        TractionControlReplyMessage t = new TractionControlReplyMessage(src,dst,payload);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91371,OpenLCB_OpenLCB_Java,TractionControlReplyMessageTest.testGetcommand,"    @Test
    public void testGetcommand(){
        NodeID src = new NodeID(new byte[]{6,5,5,4,4,3});
        NodeID dst = new NodeID(new byte[]{2,2,2,4,4,4});
        byte[] payload = new byte[]{0x40,0x01,0x00}; // Traciton Management Reply message
        TractionControlReplyMessage t = new TractionControlReplyMessage(src,dst,payload);
        Assert.assertEquals(""command"",0x40,t.getCmd());
    }
",non-flaky,5
91372,OpenLCB_OpenLCB_Java,StreamDataCompleteMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        StreamDataCompleteMessage t = new StreamDataCompleteMessage(id1,id2,(byte)0x00,(byte)0x00);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91373,OpenLCB_OpenLCB_Java,CommonIdentifiersTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        CommonIdentifiers t = new CommonIdentifiers();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91374,OpenLCB_OpenLCB_Java,StreamDataProceedMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        StreamDataProceedMessage t = new StreamDataProceedMessage(id1,id2,(byte)0x00,(byte)0x00);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91375,OpenLCB_OpenLCB_Java,BlueGoldExtendedEngineTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        ScatterGather sg = new ScatterGather();
        EventID eid = new EventID(new byte[]{1,2,3,4,5,6,7,8});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91376,OpenLCB_OpenLCB_Java,VersionOutOfDateExceptionTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        VersionOutOfDateException t = new VersionOutOfDateException();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91377,OpenLCB_OpenLCB_Java,ThrottleFunctionDatagramTest.testCTor,"    @Test
    public void testCTor() {
        ThrottleFunctionDatagram t = new ThrottleFunctionDatagram(0,0);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91378,OpenLCB_OpenLCB_Java,TractionThrottleTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91379,OpenLCB_OpenLCB_Java,TrainNodeCacheTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91380,OpenLCB_OpenLCB_Java,RemoteDccProxyTest.testCTor,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        RemoteDccProxy t = new RemoteDccProxy(nodeID);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91381,OpenLCB_OpenLCB_Java,FdiParserTest.testCTor,"    @Test
    public void testCTor() {
        Element e = new Element(""root"");
        Element segment = new Element(""segment"");
        segment.setAttribute(""space"",""5"");
        segment.setAttribute(""origin"",""0"");
        e.addContent(segment);
        Element group = new Element(""group"");
        group.setAttribute(""offset"",""0"");
        Element fm = new Element(""function"");
        Element fmn = new Element(""name"");
        fmn.addContent(""F1"");
        fm.addContent(fmn);
        fm.setAttribute(""size"",""1"");
        fm.setAttribute(""kind"",""momentary"");
        group.addContent(fm);
        Element ft = new Element(""function"");
        Element ftn = new Element(""name"");
        ftn.addContent(""F2"");
        ft.addContent(ftn);
        ft.setAttribute(""size"",""1"");
        ft.setAttribute(""kind"",""toggle"");
        group.addContent(ft);
        Element fa = new Element(""function"");
        Element fan = new Element(""name"");
        fan.addContent(""F3"");
        fa.addContent(fan);
        fa.setAttribute(""size"",""1"");
        fa.setAttribute(""kind"",""analog"");
        group.addContent(fa);
        e.addContent(group);
        FdiParser t = new FdiParser(e);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91382,OpenLCB_OpenLCB_Java,FdiParserTest.testReadFromFile,"    @Test
    public void testReadFromFile() throws Exception {
        FileReader r = new FileReader(""test/org/openlcb/implementations/throttle/FdiTestFile.xml"");
        Element e = org.openlcb.cdi.jdom.XmlHelper.parseXmlFromReader(r);
        FdiParser t = new FdiParser(e);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91383,OpenLCB_OpenLCB_Java,FakeMemoryConfigurationServiceTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91384,OpenLCB_OpenLCB_Java,MemoryConfigSpaceRetrieverTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91385,OpenLCB_OpenLCB_Java,SingleConsumerTest.put,"    @Test
    public void testCTor() {
        NodeID nid = new NodeID(new byte[]{1,2,3,4,5,6});
        EventID eid = new EventID(new byte[]{1,2,3,4,5,6,7,8});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91386,OpenLCB_OpenLCB_Java,SingleProducerTest.put,"    @Test
    public void testCTor() {
        NodeID nid = new NodeID(new byte[]{1,2,3,4,5,6});
        EventID eid = new EventID(new byte[]{1,2,3,4,5,6,7,8});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91387,OpenLCB_OpenLCB_Java,OlcbInterfaceTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91388,OpenLCB_OpenLCB_Java,BackupConfigTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        BackupConfig t = new BackupConfig();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91389,OpenLCB_OpenLCB_Java,RestoreConfigTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        RestoreConfig t = new RestoreConfig();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91390,OpenLCB_OpenLCB_Java,UtilTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        Util t = new Util();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91391,OpenLCB_OpenLCB_Java,MemorySpaceCacheTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91392,OpenLCB_OpenLCB_Java,DemoReadWriteAccessTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        DemoReadWriteAccess t = new DemoReadWriteAccess();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91393,OpenLCB_OpenLCB_Java,JdomCdiReaderTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        JdomCdiReader t = new JdomCdiReader();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91394,OpenLCB_OpenLCB_Java,XmlHelperTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        XmlHelper t = new XmlHelper();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91395,OpenLCB_OpenLCB_Java,DatagramRejectedMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        DatagramRejectedMessage t = new DatagramRejectedMessage(id1,id2,1);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91396,OpenLCB_OpenLCB_Java,NodeTreeRepTest.put,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        MimicNodeStore store = null;
        NodeID nid1 = new NodeID(new byte[]{1,3,3,4,5,6});
        NodeID nid2 = new NodeID(new byte[]{2,3,3,4,5,6});
    
        ProducerIdentifiedMessage pim1 = new ProducerIdentifiedMessage(nid1, 
                                         new EventID(new byte[]{1,0,0,0,0,0,1,0}), EventState.Unknown);
        Connection connection = new AbstractConnection() {
            public void put(Message msg, Connection sender) {
            }
",non-flaky,5
91397,OpenLCB_OpenLCB_Java,ConsumerPaneTest.put,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        EventID eventID = new EventID(new byte[]{1,0,0,0,0,0,1,0});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection sender) {
            }
",non-flaky,5
91398,OpenLCB_OpenLCB_Java,NodeIdTextFieldTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        NodeIdTextField t = new NodeIdTextField();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91399,OpenLCB_OpenLCB_Java,ProducerPaneTest.put,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        EventID eventID = new EventID(new byte[]{1,0,0,0,0,0,1,0});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection sender) {
            }
",non-flaky,5
91400,OpenLCB_OpenLCB_Java,GridConnectOutputTest.run,"    @Test
    public void testCTor() {
        GridConnectOutput t = new GridConnectOutput(new java.io.ByteArrayOutputStream(), new Runnable(){
    public void run(){
    }
",non-flaky,5
91401,OpenLCB_OpenLCB_Java,GridConnectInputTest.run,"    @Test
    public void testCTor() {
        java.io.BufferedReader br = new java.io.BufferedReader(new java.io.StringReader(""""));
        GridConnectInput t = new GridConnectInput(br, new CanFrameListenerScaffold(), new Runnable(){
    public void run(){
    }
",non-flaky,5
91402,OpenLCB_OpenLCB_Java,OlcbConnectionTest.onConnect,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        OlcbConnection t = new OlcbConnection(nodeID,""test"",5,new OlcbConnection.ConnectionListener(){
            @Override
            public void onConnect(){
            }
",non-flaky,5
91403,OpenLCB_OpenLCB_Java,CanInterfaceTest.testCTor,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        CanInterface t = new CanInterface(nodeID, new CanFrameListenerScaffold() );
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91404,OpenLCB_OpenLCB_Java,DefaultPropertyListenerSupportTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        DefaultPropertyListenerSupport t = new DefaultPropertyListenerSupport();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91405,OpenLCB_OpenLCB_Java,HubTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        Hub t = new Hub();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91406,OpenLCB_OpenLCB_Java,StreamInitiateReplyMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        StreamInitiateReplyMessage t = new StreamInitiateReplyMessage(id1,id2,0,(byte)0x00,(byte)0x00);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91407,OpenLCB_OpenLCB_Java,DatagramAcknowledgedMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        DatagramAcknowledgedMessage t = new DatagramAcknowledgedMessage(id1,id2);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91408,OpenLCB_OpenLCB_Java,VerifyNodeIdHandlerTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
91409,OpenLCB_OpenLCB_Java,StreamInitiateRequestMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID id1 = new NodeID(new byte[]{1, 1, 0, 0, 0, 4});
        NodeID id2 = new NodeID(new byte[]{1, 1, 0, 0, 4, 4});
        StreamInitiateRequestMessage t = new StreamInitiateRequestMessage(id1,id2,0,(byte)0x00,(byte)0x00);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91410,OpenLCB_OpenLCB_Java,CollapsiblePanelTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        CollapsiblePanel t = new CollapsiblePanel(""test"",new javax.swing.JPanel());
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
91411,OpenLCB_OpenLCB_Java,GridLayout2Test.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        GridLayout2 t = new GridLayout2();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
95643,togglz_togglz,JSFMapTest.testJSFFeatureMap,"    @Test
    public void testJSFFeatureMap() throws IOException, Exception {

        WebClient client = new WebClient();
        HtmlPage page = client.getPage(url + ""index.jsf"");

        // this part of the page is rendered
        assertTrue(page.asText().contains(""Text for ENABLED feature!""));

        // this part is disabled
        assertFalse(page.asText().contains(""Text for DISABLED feature!""));

        // one div can be found the other not
        assertNotNull(page.getElementById(""enabledDiv""));
        assertNull(page.getElementById(""disabledDiv""));

    }
",non-flaky,5
95644,togglz_togglz,DeviceActivationStrategyTest.shouldBeInactiveForEmptyParams,"    @Test
    public void shouldBeInactiveForEmptyParams() throws Exception {
        String[] emptyArguments = new String[]{"""", """", """"};
        assertThat(requestFrom(NORMAL)).isInactiveWithParams(emptyArguments);
        cleanup();
        assertThat(requestFrom(TABLET)).isInactiveWithParams(emptyArguments);
        cleanup();
        assertThat(requestFrom(MOBILE)).isInactiveWithParams(emptyArguments);
        cleanup();
    }
",non-flaky,5
95645,togglz_togglz,DeviceActivationStrategyTest.shouldBeActiveForDesktop,"    @Test
    public void shouldBeActiveForDesktop() throws Exception {
        String[] desktopOn = new String[]{""YES"", ""NO"", ""NO""};
        assertThat(requestFrom(NORMAL)).isActiveWithParams(desktopOn);
        cleanup();
        assertThat(requestFrom(TABLET)).isInactiveWithParams(desktopOn);
        cleanup();
        assertThat(requestFrom(MOBILE)).isInactiveWithParams(desktopOn);
        cleanup();
    }
",non-flaky,5
95646,togglz_togglz,DeviceActivationStrategyTest.shouldBeActiveForTablet,"    @Test
    public void shouldBeActiveForTablet() throws Exception {
        String[] tabletOn = new String[]{""NO"", ""YES"", ""NO""};
        assertThat(requestFrom(NORMAL)).isInactiveWithParams(tabletOn);
        cleanup();
        assertThat(requestFrom(TABLET)).isActiveWithParams(tabletOn);
        cleanup();
        assertThat(requestFrom(MOBILE)).isInactiveWithParams(tabletOn);
        cleanup();
    }
",non-flaky,5
95647,togglz_togglz,DeviceActivationStrategyTest.shouldBeActiveForMobile,"    @Test
    public void shouldBeActiveForMobile() throws Exception {
        String[] mobileOn = new String[]{""NO"", ""NO"", ""YES""};
        assertThat(requestFrom(NORMAL)).isInactiveWithParams(mobileOn);
        cleanup();
        assertThat(requestFrom(TABLET)).isInactiveWithParams(mobileOn);
        cleanup();
        assertThat(requestFrom(MOBILE)).isActiveWithParams(mobileOn);
        cleanup();
    }
",non-flaky,5
95648,togglz_togglz,DeviceActivationStrategyTest.shouldBeAccurateForLowerCaseParams,"    @Test
    public void shouldBeAccurateForLowerCaseParams() throws Exception {
        String[] desktopOn = new String[]{""yes"", ""no"", ""yes""};
        assertThat(requestFrom(NORMAL)).isActiveWithParams(desktopOn);
        cleanup();
        String[] tabletOn = new String[]{""no"", ""yes"", ""NO""};
        assertThat(requestFrom(TABLET)).isActiveWithParams(tabletOn);
        cleanup();
        String[] mobileOn = new String[]{""no"", ""no"", ""yes""};
        assertThat(requestFrom(MOBILE)).isActiveWithParams(mobileOn);
        cleanup();
    }
",non-flaky,5
95649,togglz_togglz,ShiroUsersTest.testShiroAsAnonymousUser,"    @Test
    public void testShiroAsAnonymousUser() throws Exception {

        WebClient client = new WebClient();
        TextPage page = client.getPage(url + ""features"");
        assertTrue(page.getContent().contains(""DISABLED = false""));
        assertTrue(page.getContent().contains(""ENABLED_FOR_ALL = true""));
        assertTrue(page.getContent().contains(""ENABLED_FOR_CK = false""));

        TextPage userPage = client.getPage(url + ""user"");
        assertTrue(userPage.getContent().contains(""USER = null""));
        assertTrue(userPage.getContent().contains(""ADMIN = null""));

    }
",non-flaky,5
95650,togglz_togglz,ShiroUsersTest.testShiroLoginAsFeatureAdmin,"    @Test
    public void testShiroLoginAsFeatureAdmin() throws Exception {

        WebClient client = new WebClient();

        TextPage beforeLogin = client.getPage(url + ""user"");
        assertTrue(beforeLogin.getContent().contains(""USER = null""));
        assertTrue(beforeLogin.getContent().contains(""ADMIN = null""));

        TextPage loginPage = client.getPage(url + ""login?user=ck"");
        assertTrue(loginPage.getContent().contains(""SUCCESS""));

        TextPage afterLogin = client.getPage(url + ""user"");
        assertTrue(afterLogin.getContent().contains(""USER = ck""));
        assertTrue(afterLogin.getContent().contains(""ADMIN = true""));

        TextPage logoutPage = client.getPage(url + ""logout"");
        assertTrue(logoutPage.getContent().contains(""SUCCESS""));

        TextPage afterLogout = client.getPage(url + ""user"");
        assertTrue(afterLogout.getContent().contains(""USER = null""));
        assertTrue(afterLogout.getContent().contains(""ADMIN = null""));

    }
",non-flaky,5
95651,togglz_togglz,ShiroUsersTest.testShiroLoginAsNormalUser,"    @Test
    public void testShiroLoginAsNormalUser() throws Exception {

        WebClient client = new WebClient();

        TextPage beforeLogin = client.getPage(url + ""user"");
        assertTrue(beforeLogin.getContent().contains(""USER = null""));
        assertTrue(beforeLogin.getContent().contains(""ADMIN = null""));

        TextPage loginPage = client.getPage(url + ""login?user=somebody"");
        assertTrue(loginPage.getContent().contains(""SUCCESS""));

        TextPage afterLogin = client.getPage(url + ""user"");
        assertTrue(afterLogin.getContent().contains(""USER = somebody""));
        assertTrue(afterLogin.getContent().contains(""ADMIN = false""));

        TextPage logoutPage = client.getPage(url + ""logout"");
        assertTrue(logoutPage.getContent().contains(""SUCCESS""));

        TextPage afterLogout = client.getPage(url + ""user"");
        assertTrue(afterLogout.getContent().contains(""USER = null""));
        assertTrue(afterLogout.getContent().contains(""ADMIN = null""));

    }
",non-flaky,5
95652,togglz_togglz,ShiroUsersTest.testShiroWithCorrectUser,"    @Test
    public void testShiroWithCorrectUser() throws Exception {

        WebClient client = new WebClient();

        TextPage beforeLogin = client.getPage(url + ""features"");
        assertTrue(beforeLogin.getContent().contains(""DISABLED = false""));
        assertTrue(beforeLogin.getContent().contains(""ENABLED_FOR_ALL = true""));
        assertTrue(beforeLogin.getContent().contains(""ENABLED_FOR_CK = false""));

        TextPage loginPage = client.getPage(url + ""login?user=ck"");
        assertTrue(loginPage.getContent().contains(""SUCCESS""));

        TextPage afterLogin = client.getPage(url + ""features"");
        assertTrue(afterLogin.getContent().contains(""DISABLED = false""));
        assertTrue(afterLogin.getContent().contains(""ENABLED_FOR_ALL = true""));
        assertTrue(afterLogin.getContent().contains(""ENABLED_FOR_CK = true""));

        TextPage logoutPage = client.getPage(url + ""logout"");
        assertTrue(logoutPage.getContent().contains(""SUCCESS""));

        TextPage afterLogout = client.getPage(url + ""features"");
        assertTrue(afterLogout.getContent().contains(""DISABLED = false""));
        assertTrue(afterLogout.getContent().contains(""ENABLED_FOR_ALL = true""));
        assertTrue(afterLogout.getContent().contains(""ENABLED_FOR_CK = false""));

    }
",non-flaky,5
95653,togglz_togglz,ShiroUsersTest.testShiroWithSomeOtherUser,"    @Test
    public void testShiroWithSomeOtherUser() throws Exception {

        WebClient client = new WebClient();

        TextPage beforeLogin = client.getPage(url + ""features"");
        assertTrue(beforeLogin.getContent().contains(""DISABLED = false""));
        assertTrue(beforeLogin.getContent().contains(""ENABLED_FOR_ALL = true""));
        assertTrue(beforeLogin.getContent().contains(""ENABLED_FOR_CK = false""));

        TextPage loginPage = client.getPage(url + ""login?user=somebody"");
        assertTrue(loginPage.getContent().contains(""SUCCESS""));

        TextPage afterLogin = client.getPage(url + ""features"");
        assertTrue(afterLogin.getContent().contains(""DISABLED = false""));
        assertTrue(afterLogin.getContent().contains(""ENABLED_FOR_ALL = true""));
        assertTrue(afterLogin.getContent().contains(""ENABLED_FOR_CK = false""));

        TextPage logoutPage = client.getPage(url + ""logout"");
        assertTrue(logoutPage.getContent().contains(""SUCCESS""));

        TextPage afterLogout = client.getPage(url + ""features"");
        assertTrue(afterLogout.getContent().contains(""DISABLED = false""));
        assertTrue(afterLogout.getContent().contains(""ENABLED_FOR_ALL = true""));
        assertTrue(afterLogout.getContent().contains(""ENABLED_FOR_CK = false""));

    }
",non-flaky,5
95654,togglz_togglz,DefaultFeatureStateTest.testFeaturesActiveByDefault,"    @Test
    public void testFeaturesActiveByDefault() {
        assertTrue(MyFeatures.FEATURE_ONE.isActive());
    }
",non-flaky,5
95655,togglz_togglz,DefaultFeatureStateTest.testFeatureManagerImmutable,"    @Test(expected = UnsupportedOperationException.class)
    public void testFeatureManagerImmutable() {
        FeatureContext.getFeatureManager().setFeatureState(new FeatureState(MyFeatures.FEATURE_ONE, false));
    }
",non-flaky,5
95656,togglz_togglz,TestFeatureManagerTest.featureShouldBeInactiveByDefault,"    @Test
    public void featureShouldBeInactiveByDefault() {
        assertFalse(manager.isActive(MyFeatures.ONE));
    }
",non-flaky,5
95657,togglz_togglz,TestFeatureManagerTest.shouldToggleIndividualFeature,"    @Test
    public void shouldToggleIndividualFeature() {

        // enable
        manager.enable(MyFeatures.ONE);
        assertTrue(manager.isActive(MyFeatures.ONE));

        // disable
        manager.disable(MyFeatures.ONE);
        assertFalse(manager.isActive(MyFeatures.ONE));

    }
",non-flaky,5
95658,togglz_togglz,TestFeatureManagerTest.shouldToggleAllFeatures,"    @Test
    public void shouldToggleAllFeatures() {

        // enable
        manager.enableAll();
        assertTrue(manager.isActive(MyFeatures.ONE));
        assertTrue(manager.isActive(MyFeatures.TWO));

        // disable
        manager.disableAll();
        assertFalse(manager.isActive(MyFeatures.ONE));
        assertFalse(manager.isActive(MyFeatures.TWO));

    }
",non-flaky,5
95659,togglz_togglz,TestFeatureManagerTest.shouldSupportTogglingUntypedFeature,"    @Test
    public void shouldSupportTogglingUntypedFeature() {

        // enable
        manager.enable(new NamedFeature(""ONE""));
        assertTrue(manager.isActive(MyFeatures.ONE));

        // disable
        manager.disable(new NamedFeature(""ONE""));
        assertFalse(manager.isActive(MyFeatures.ONE));

    }
",non-flaky,5
95660,togglz_togglz,TestFeatureManagerTest.shouldSupportReadingWithNamedFeature,"    @Test
    public void shouldSupportReadingWithNamedFeature() {

        // enable
        manager.enable(MyFeatures.ONE);
        assertTrue(manager.isActive(new NamedFeature(""ONE"")));

        // disable
        manager.disable(MyFeatures.ONE);
        assertFalse(manager.isActive(new NamedFeature(""ONE"")));

    }
",non-flaky,5
95661,togglz_togglz,TogglzApplicationContextBinderApplicationListenerTest.contextRefreshed,"    @Test
    public void contextRefreshed() {
        ContextRefreshedEvent contextRefreshedEvent = mock(ContextRefreshedEvent.class);
        when(contextRefreshedEvent.getApplicationContext()).thenReturn(applicationContext);
        // Invoke context refreshed event
        applicationListener.onApplicationEvent(contextRefreshedEvent);
        // Assert application context bound
        assertSame(applicationContext, ContextClassLoaderApplicationContextHolder.get());
    }
",non-flaky,5
95662,togglz_togglz,TogglzApplicationContextBinderApplicationListenerTest.contextRefreshedWhileContextAlreadyBound,"    @Test
    public void contextRefreshedWhileContextAlreadyBound() {
        // Bind application context before context refreshed event invoked
        ContextClassLoaderApplicationContextHolder.bind(mock(ApplicationContext.class));
        applicationContext = mock(ApplicationContext.class);
        ContextRefreshedEvent contextRefreshedEvent = mock(ContextRefreshedEvent.class);
        when(contextRefreshedEvent.getApplicationContext()).thenReturn(applicationContext);
        // Invoke context refreshed application event
        applicationListener.onApplicationEvent(contextRefreshedEvent);
        // Assert application context bound
        assertSame(applicationContext, ContextClassLoaderApplicationContextHolder.get());
    }
",non-flaky,5
95663,togglz_togglz,TogglzApplicationContextBinderApplicationListenerTest.contextClosed,"    @Test
    public void contextClosed() {
        // Bind application context before context closed event invoked
        ContextClassLoaderApplicationContextHolder.bind(applicationContext);
        ContextClosedEvent contextClosedEvent = mock(ContextClosedEvent.class);
        // Invoke context closed event
        applicationListener.onApplicationEvent(contextClosedEvent);
        // Assert application context released
        assertNull(ContextClassLoaderApplicationContextHolder.get());
    }
",non-flaky,5
95664,togglz_togglz,SpringEnvironmentPropertyActivationStrategyTest.testGetId,"    @Test
    public void testGetId() {
        assertEquals(SpringEnvironmentPropertyActivationStrategy.ID, strategy.getId());
    }
",non-flaky,5
95665,togglz_togglz,SpringEnvironmentPropertyActivationStrategyTest.testGetName,"    @Test
    public void testGetName() {
        assertTrue(Strings.isNotBlank(strategy.getName()));
    }
",non-flaky,5
95666,togglz_togglz,SpringEnvironmentPropertyActivationStrategyTest.testIsActiveThrowsWhenNoApplicationContext,"    @Test(expected = IllegalStateException.class)
    public void testIsActiveThrowsWhenNoApplicationContext() {
        FeatureState featureState = new FeatureState(TestFeatures.FEATURE_ONE, true);

        strategy.isActive(featureState, null);
    }
",non-flaky,5
95667,togglz_togglz,SpringEnvironmentPropertyActivationStrategyTest.testGetParameters,"    @Test
    public void testGetParameters() {
        Parameter[] parameters = strategy.getParameters();

        assertEquals(1, parameters.length);

        Parameter parameter = parameters[0];

        assertNotNull(parameter);
        assertEquals(SpringEnvironmentPropertyActivationStrategy.PARAM_NAME, parameter.getName());
        assertTrue(parameter.isOptional());
        assertTrue(Strings.isNotBlank(parameter.getLabel()));
        assertTrue(Strings.isNotBlank(parameter.getDescription()));
    }
",non-flaky,5
95668,togglz_togglz,SpringProfileActivationStrategyTest.testGetId,"    @Test
    public void testGetId() {
        assertEquals(SpringProfileActivationStrategy.ID, strategy.getId());
    }
",non-flaky,5
95669,togglz_togglz,SpringProfileActivationStrategyTest.testGetName,"    @Test
    public void testGetName() {
        assertTrue(Strings.isNotBlank(strategy.getName()));
    }
",non-flaky,5
95670,togglz_togglz,SpringProfileActivationStrategyTest.testIsActiveThrowsWhenNoApplicationContext,"    @Test(expected = IllegalStateException.class)
    public void testIsActiveThrowsWhenNoApplicationContext() {
        FeatureState featureState = new FeatureState(TestFeatures.FEATURE_ONE, true);

        ContextClassLoaderApplicationContextHolder.release();

        strategy.isActive(featureState, null);
    }
",non-flaky,5
95671,togglz_togglz,SpringProfileActivationStrategyTest.testGetParameters,"    @Test
    public void testGetParameters() {
        Parameter[] parameters = strategy.getParameters();

        assertEquals(1, parameters.length);

        Parameter parameter = parameters[0];

        assertNotNull(parameter);
        assertEquals(SpringProfileActivationStrategy.PARAM_PROFILES, parameter.getName());
        assertTrue(Strings.isNotBlank(parameter.getLabel()));
        assertTrue(Strings.isNotBlank(parameter.getDescription()));
    }
",non-flaky,5
95672,togglz_togglz,SpringProfileActivationStrategyTest.testGetTokenParameterName,"    @Test
    public void testGetTokenParameterName() {
        assertEquals(SpringProfileActivationStrategy.PARAM_PROFILES, strategy.getTokenParameterName());
    }
",non-flaky,5
95673,togglz_togglz,SpringProfileActivationStrategyTest.testGetTokenParameterTransformer,"    @Test
    public void testGetTokenParameterTransformer() {
        TokenTransformer transformer = strategy.getTokenParameterTransformer();

        assertNotNull(transformer);
        assertEquals(""foo"", transformer.transform(""FOO""));
    }
",non-flaky,5
95674,togglz_togglz,TogglzRuleAllDisabledTest.testActiveByDefault,"    @Test
    public void testActiveByDefault() {

        // should be true by default
        assertFalse(MyFeatures.FEATURE_ONE.isActive());

        // second result should be the same
        assertFalse(MyFeatures.FEATURE_ONE.isActive());

    }
",non-flaky,5
95675,togglz_togglz,TogglzRuleAllDisabledTest.testToggleFeature,"    @Test
    public void testToggleFeature() {

        // initially false
        assertFalse(MyFeatures.FEATURE_ONE.isActive());

        // enable and check result
        togglzRule.enable(MyFeatures.FEATURE_ONE);
        assertTrue(MyFeatures.FEATURE_ONE.isActive());

        // disable and check result
        togglzRule.disable(MyFeatures.FEATURE_ONE);
        assertFalse(MyFeatures.FEATURE_ONE.isActive());

    }
",non-flaky,5
95676,togglz_togglz,TogglzRuleWithAnnotationTest.featureShouldBeInactiveByDefault,"    @Test
    public void featureShouldBeInactiveByDefault()
    {
        assertFalse(MyFeatures.ONE.isActive());
        assertFalse(MyFeatures.TWO.isActive());
    }
",non-flaky,5
95677,togglz_togglz,TogglzRuleWithAnnotationTest.featureShouldBeActiveWithAnnotation,"    @Test
    public void featureShouldBeActiveWithAnnotation()
    {
        assertTrue(MyFeatures.ONE.isActive());
        assertFalse(MyFeatures.TWO.isActive());
    }
",non-flaky,5
95678,togglz_togglz,TogglzRuleWithAnnotationTest.shouldActivateMultipleFeatures,"    @Test
    public void shouldActivateMultipleFeatures()
    {
        assertTrue(MyFeatures.ONE.isActive());
        assertTrue(MyFeatures.TWO.isActive());
    }
",non-flaky,5
95679,togglz_togglz,TogglzRuleAllEnabledTest.testActiveByDefault,"    @Test
    public void testActiveByDefault() {

        // should be true by default
        assertTrue(MyFeatures.FEATURE_ONE.isActive());

        // second result should be the same
        assertTrue(MyFeatures.FEATURE_ONE.isActive());

    }
",non-flaky,5
95680,togglz_togglz,TogglzRuleAllEnabledTest.testToggleFeature,"    @Test
    public void testToggleFeature() {

        // initially true
        assertTrue(MyFeatures.FEATURE_ONE.isActive());

        // disable and check result
        togglzRule.disable(MyFeatures.FEATURE_ONE);
        assertFalse(MyFeatures.FEATURE_ONE.isActive());

        // enable and check result
        togglzRule.enable(MyFeatures.FEATURE_ONE);
        assertTrue(MyFeatures.FEATURE_ONE.isActive());

    }
",non-flaky,5
95681,togglz_togglz,TogglzRuleWithVariations_HappyCase_Test.test,"    @Test
    public void test() {
        assertTrue(MyFeatures.F1.isActive());
        assertTrue(MyFeatures.F2.isActive() || !MyFeatures.F2.isActive());
        assertTrue(MyFeatures.F3.isActive() || !MyFeatures.F3.isActive());
    }
",non-flaky,5
95682,togglz_togglz,FeatureVariationsTest.test,"    @Test
    public void test() {
        assertTrue(MyFeatures.F1.isActive());
        assertTrue(MyFeatures.F2.isActive() || !MyFeatures.F2.isActive());
        assertTrue(MyFeatures.F3.isActive() || !MyFeatures.F3.isActive());
    }
",non-flaky,5
95683,togglz_togglz,TogglzRuleWithVariations_CalledMultipleTimes_Test.test,"    @Test
    public void test() {

        counter++;

        switch (counter) {
            case 1:
                assertEquals(""C1, F1"", false, MyFeatures.F1.isActive());
                assertEquals(""C1, F2"", false, MyFeatures.F2.isActive());
                assertEquals(""C1, F3"", false, MyFeatures.F3.isActive());
                break;

            case 2:
                assertEquals(""C2, F1"", false, MyFeatures.F1.isActive());
                assertEquals(""C2, F2"", true, MyFeatures.F2.isActive());
                assertEquals(""C2, F3"", false, MyFeatures.F3.isActive());
                break;
            case 3:
                assertEquals(""C3, F1"", false, MyFeatures.F1.isActive());
                assertEquals(""C3, F2"", false, MyFeatures.F2.isActive());
                assertEquals(""C3, F3"", true, MyFeatures.F3.isActive());
                break;

            case 4:
                assertEquals(""C4, F1"", false, MyFeatures.F1.isActive());
                assertEquals(""C4, F2"", true, MyFeatures.F2.isActive());
                assertEquals(""C4, F3"", true, MyFeatures.F3.isActive());
                break;

            default:
                fail(""Incorrect execution cound"");

        }
    }
",non-flaky,5
95684,togglz_togglz,TogglzRuleWithVariations_EnableSadCase_Test.test,"    @Test
    public void test() {
        expectedException.expect(AssertionError.class);

        assertFalse(MyFeatures.F1.isActive());
    }
",non-flaky,5
95685,togglz_togglz,TogglzRuleWithVariations_DisableSadCase_Test.test,"    @Test
    public void test() {
        expectedException.expect(AssertionError.class);

        assertTrue(MyFeatures.F1.isActive());
    }
",non-flaky,5
95686,togglz_togglz,GuiceIntegrationTest.testGuiceIntegration,"    @Test
    public void testGuiceIntegration() throws IOException {

        FeatureManager featureManager = FeatureContext.getFeatureManagerOrNull();

        assertThat(featureManager).isNotNull();
        assertThat(featureManager.getFeatures())
            .containsExactly(GuiceFeatures.FEATURE1, GuiceFeatures.FEATURE2);

    }
",non-flaky,5
95687,togglz_togglz,ArchaiusStateRepositoryTest.shouldReturnNullWhenStateDoesntExist,"    @Test
    public void shouldReturnNullWhenStateDoesntExist() {

        final FeatureState state = repository.getFeatureState(TestFeature.F1);

        assertNull(state);
    }
",non-flaky,5
95688,togglz_togglz,ArchaiusStateRepositoryTest.shouldReadFalseStateWithoutStrategyAndParameters,"    @Test
    public void shouldReadFalseStateWithoutStrategyAndParameters() {

        addState(TestFeature.F1.name(), false);

        FeatureState state = repository.getFeatureState(TestFeature.F1);

        assertNotNull(state);
        assertEquals(TestFeature.F1, state.getFeature());
        assertEquals(false, state.isEnabled());
        assertEquals(null, state.getStrategyId());
        assertEquals(0, state.getParameterNames().size());
    }
",non-flaky,5
95689,togglz_togglz,ArchaiusStateRepositoryTest.shouldReadTrueStateWithoutStrategyAndParameters,"    @Test
    public void shouldReadTrueStateWithoutStrategyAndParameters() {

        addState(TestFeature.F1.name(), true);

        FeatureState state = repository.getFeatureState(TestFeature.F1);

        /*
         * THEN the properties should be set like expected
         */
        assertNotNull(state);
        assertEquals(TestFeature.F1, state.getFeature());
        assertEquals(true, state.isEnabled());
        assertEquals(null, state.getStrategyId());
        assertEquals(0, state.getParameterNames().size());
    }
",non-flaky,5
95690,togglz_togglz,ArchaiusStateRepositoryTest.withStrategyNoParameters,"    @Test
    public void withStrategyNoParameters() {

        addState(TestFeature.F1.name(), true, ""S1"");
        
        FeatureState state = repository.getFeatureState(TestFeature.F1);

        assertNotNull(state);
        assertEquals(""S1"", state.getStrategyId());
        assertEquals(0, state.getParameterNames().size());
    }
",non-flaky,5
95691,togglz_togglz,ArchaiusStateRepositoryTest.withStrategyParameters,"    @Test
    public void withStrategyParameters() {

        addState(TestFeature.F1.name(), true, ""S1"", new Param(""one"", ""A""), new Param(""two"", ""B""));

        FeatureState state = repository.getFeatureState(TestFeature.F1);

        assertEquals(2, state.getParameterNames().size());
        assertEquals(""A"", state.getParameter(""one""));
        assertEquals(""B"", state.getParameter(""two""));
    }
",non-flaky,5
95692,togglz_togglz,ArchaiusStateRepositoryTest.setState,"    @Test(expected=UnsupportedOperationException.class)
    public void setState() {
        
        repository.setFeatureState(new FeatureState(TestFeature.F1, true));
    }
",non-flaky,5
95693,togglz_togglz,SingleUserProviderTest.canProvideNamedUser,"    @Test
    public void canProvideNamedUser() {
        String username = ""named-user"";
        boolean featureAdmin = true;
        UserProvider userProvider = new SingleUserProvider(username, featureAdmin);
        FeatureUser user = userProvider.getCurrentUser();
        assertThat(user.getName(), equalTo(username));
        assertThat(user.isFeatureAdmin(), equalTo(featureAdmin));
    }
",non-flaky,5
95694,togglz_togglz,AnnotationFeatureGroupTest.buildWillReturnNullWhenFeatureGroupAnnotationIsNotPresent,"    @Test
    public void buildWillReturnNullWhenFeatureGroupAnnotationIsNotPresent() throws Exception {
        FeatureGroup result = AnnotationFeatureGroup.build(Label.class);

        assertThat(result, nullValue());
    }
",non-flaky,5
95695,togglz_togglz,AnnotationFeatureGroupTest.buildWillReturnFeatureGroupWhenFeatureGroupAnnotationIsPresentForFieldLevelGroup,"    @Test
    public void buildWillReturnFeatureGroupWhenFeatureGroupAnnotationIsPresentForFieldLevelGroup() throws Exception {
        FeatureGroup result = AnnotationFeatureGroup.build(FieldLevelGroup.class);

        assertThat(result, notNullValue());
        assertThat(result.getLabel(), is(FIELD_LEVEL_GROUP_LABEL));
        assertThat(result.contains(TestFeatures.FEATURE), is(true));
    }
",non-flaky,5
95696,togglz_togglz,AnnotationFeatureGroupTest.buildWillReturnFeatureGroupWhenFeatureGroupAnnotationIsPresentForClassLevelGroup,"    @Test
    public void buildWillReturnFeatureGroupWhenFeatureGroupAnnotationIsPresentForClassLevelGroup() throws Exception {
        FeatureGroup result = AnnotationFeatureGroup.build(ClassLevelGroup.class);

        assertThat(result, notNullValue());
        assertThat(result.getLabel(), is(CLASS_LEVEL_GROUP_LABEL));
        assertThat(result.contains(TestFeatures.FEATURE), is(true));
    }
",non-flaky,5
95697,togglz_togglz,EnumFeatureMetaDataTest.constructorWillPopulateGroupsFromAnnotations,"    @Test
    public void constructorWillPopulateGroupsFromAnnotations() throws Exception {
        // act
        EnumFeatureMetaData metaData = new EnumFeatureMetaData(TestFeatures.FEATURE);

        // assert
        Set<FeatureGroup> groups = metaData.getGroups();

        assertThat(groups, notNullValue());
        assertThat(groups.size(), is(2));

        // verify field level group is there
        FeatureGroup group1 = Iterables.find(groups, createFeatureGroupLabelPredicate(FIELD_LEVEL_GROUP_LABEL));
        assertThat(group1.contains(TestFeatures.FEATURE), is(true));

        // verify class level group is there
        FeatureGroup group2 = Iterables.find(groups, createFeatureGroupLabelPredicate(CLASS_LEVEL_GROUP_LABEL));
        assertThat(group2.contains(TestFeatures.FEATURE), is(true));
    }
",non-flaky,5
95698,togglz_togglz,EnumFeatureMetaDataTest.constructorWillPopulateDefaultActivationStrategyFromAnnotations,"    @Test
    public void constructorWillPopulateDefaultActivationStrategyFromAnnotations() throws Exception {
        // act
        EnumFeatureMetaData metaData = new EnumFeatureMetaData(TestFeatures.FEATURE_WITH_DEFAULT_STATE);

        FeatureState featureState = metaData.getDefaultFeatureState();

        assertThat(featureState, notNullValue());
        assertThat(featureState.isEnabled(), is(true));
        assertThat(featureState.getStrategyId(), is(""SomeActivationId""));
        assertThat(featureState.getParameter(""SomeParameterName""), is(""someValue1,someValue2""));
        assertThat(featureState.getParameter(""SomeParameterName2""), is(""someValue3,someValue4""));
    }
",non-flaky,5
95699,togglz_togglz,CompositeFeatureProviderTest.empty,"	@Test
	public void empty() {
		CompositeFeatureProvider provider = new CompositeFeatureProvider();
		assertThat(provider.getFeatures()).isEmpty();
		assertThat(provider.getMetaData(new NamedFeature(""FOO""))).isNull();
	}
",non-flaky,5
95700,togglz_togglz,CompositeFeatureProviderTest.oneProvider,"	@Test
	public void oneProvider() {
		@SuppressWarnings(""unchecked"")
		CompositeFeatureProvider provider = new CompositeFeatureProvider(new EnumBasedFeatureProvider(TestFeatures.class));
		assertThat(provider.getFeatures()).hasSize(2);
		assertThat(provider.getMetaData(new NamedFeature(""FOO""))).isNotNull();
	}
",non-flaky,5
95701,togglz_togglz,PropertyFeatureProviderTest.shouldSupportDefinitionWithoutLabel,"    @Test
    public void shouldSupportDefinitionWithoutLabel() {

        Properties properties = new Properties();
        properties.setProperty(""F1"", """");

        PropertyFeatureProvider provider = new PropertyFeatureProvider(properties);

        Set<Feature> features = provider.getFeatures();
        assertThat(features)
            .hasSize(1)
            .areExactly(1, featureNamed(""F1""));

        FeatureMetaData metadata = provider.getMetaData(new NamedFeature(""F1""));
        assertThat(metadata).isNotNull();
        assertThat(metadata.getLabel()).isEqualTo(""F1"");
        FeatureState defaultFeatureState = metadata.getDefaultFeatureState();
        assertThat(defaultFeatureState.isEnabled()).isFalse();
        assertThat(metadata.getGroups()).isEmpty();

    }
",non-flaky,5
95702,togglz_togglz,PropertyFeatureProviderTest.shouldSupportDefinitionWithOnlyLabel,"    @Test
    public void shouldSupportDefinitionWithOnlyLabel() {

        Properties properties = new Properties();
        properties.setProperty(""F1"", ""My Feature"");

        PropertyFeatureProvider provider = new PropertyFeatureProvider(properties);

        Set<Feature> features = provider.getFeatures();
        assertThat(features)
            .hasSize(1)
            .areExactly(1, featureNamed(""F1""));

        FeatureMetaData metadata = provider.getMetaData(new NamedFeature(""F1""));
        assertThat(metadata).isNotNull();
        assertThat(metadata.getLabel()).isEqualTo(""My Feature"");
        FeatureState defaultFeatureState = metadata.getDefaultFeatureState();
        assertThat(defaultFeatureState.isEnabled()).isFalse();
        assertThat(metadata.getGroups()).isEmpty();

    }
",non-flaky,5
95703,togglz_togglz,PropertyFeatureProviderTest.shouldSupportDefinitionWithLabelAndDefault,"    @Test
    public void shouldSupportDefinitionWithLabelAndDefault() {

        Properties properties = new Properties();
        properties.setProperty(""F1"", ""My Feature;true"");

        PropertyFeatureProvider provider = new PropertyFeatureProvider(properties);

        Set<Feature> features = provider.getFeatures();
        assertThat(features)
            .hasSize(1)
            .areExactly(1, featureNamed(""F1""));

        FeatureMetaData metadata = provider.getMetaData(new NamedFeature(""F1""));
        assertThat(metadata).isNotNull();
        assertThat(metadata.getLabel()).isEqualTo(""My Feature"");
        FeatureState defaultFeatureState = metadata.getDefaultFeatureState();
        assertThat(defaultFeatureState.isEnabled()).isTrue();
        assertThat(metadata.getGroups()).isEmpty();

    }
",non-flaky,5
95704,togglz_togglz,PropertyFeatureProviderTest.shouldSupportDefinitionWithLabelAndDefaultAndTrailingSemicolon,"    @Test
    public void shouldSupportDefinitionWithLabelAndDefaultAndTrailingSemicolon() {

        Properties properties = new Properties();
        properties.setProperty(""F1"", ""My Feature;true;"");

        PropertyFeatureProvider provider = new PropertyFeatureProvider(properties);

        Set<Feature> features = provider.getFeatures();
        assertThat(features)
            .hasSize(1)
            .areExactly(1, featureNamed(""F1""));

        FeatureMetaData metadata = provider.getMetaData(new NamedFeature(""F1""));
        assertThat(metadata).isNotNull();
        assertThat(metadata.getLabel()).isEqualTo(""My Feature"");
        FeatureState defaultFeatureState = metadata.getDefaultFeatureState();
        assertThat(defaultFeatureState.isEnabled()).isTrue();
        assertThat(metadata.getGroups()).isEmpty();

    }
",non-flaky,5
95705,togglz_togglz,PropertyFeatureProviderTest.shouldSupportDefinitionWithSingleGroup,"    @Test
    public void shouldSupportDefinitionWithSingleGroup() {

        Properties properties = new Properties();
        properties.setProperty(""F1"", ""My Feature;true;Group1"");

        PropertyFeatureProvider provider = new PropertyFeatureProvider(properties);

        Set<Feature> features = provider.getFeatures();
        assertThat(features)
            .hasSize(1)
            .areExactly(1, featureNamed(""F1""));

        FeatureMetaData metadata = provider.getMetaData(new NamedFeature(""F1""));
        assertThat(metadata).isNotNull();
        assertThat(metadata.getLabel()).isEqualTo(""My Feature"");
        FeatureState defaultFeatureState = metadata.getDefaultFeatureState();
        assertThat(defaultFeatureState.isEnabled()).isTrue();
        assertThat(metadata.getGroups())
            .hasSize(1)
            .areExactly(1, groupNamed(""Group1""));

    }
",non-flaky,5
95706,togglz_togglz,PropertyFeatureProviderTest.canInitializeFromProperties,"    @Test
    public void canInitializeFromProperties() {

        Properties properties = new Properties();
        properties.setProperty(""ID_1"", ""ID 1;true;Group 1,Group Other"");
        properties.setProperty(""ID_2"", ""ID 2;false;Group 2"");

        PropertyFeatureProvider provider = new PropertyFeatureProvider(properties);

        Set<Feature> features = provider.getFeatures();

        assertThat(features)
            .hasSize(2)
            .areExactly(1, featureNamed(""ID_1""))
            .areExactly(1, featureNamed(""ID_2""));

        FeatureMetaData metadata1 = provider.getMetaData(new NamedFeature(""ID_1""));
        assertThat(metadata1).isNotNull();
        assertThat(metadata1.getLabel()).isEqualTo(""ID 1"");
        FeatureState defaultFeatureState1 = metadata1.getDefaultFeatureState();
        assertThat(defaultFeatureState1.isEnabled()).isTrue();
        assertThat(metadata1.getGroups())
            .hasSize(2)
            .areExactly(1, groupNamed(""Group 1""))
            .areExactly(1, groupNamed(""Group Other""));

        FeatureMetaData metadata2 = provider.getMetaData(new NamedFeature(""ID_2""));
        assertThat(metadata2).isNotNull();
        assertThat(metadata2.getLabel()).isEqualTo(""ID 2"");
        FeatureState defaultFeatureState2 = metadata2.getDefaultFeatureState();
        assertThat(defaultFeatureState2.isEnabled()).isFalse();
        assertThat(metadata2.getGroups())
            .hasSize(1)
            .areExactly(1, groupNamed(""Group 2""));

    }
",non-flaky,5
95707,togglz_togglz,EnumBasedFeatureProviderTest.shouldFailForNull,"    @Test(expected = IllegalArgumentException.class)
    public void shouldFailForNull() {
        new EnumBasedFeatureProvider(null);
    }
",non-flaky,5
95708,togglz_togglz,EnumBasedFeatureProviderTest.shouldFailForArrayWithNull,"    @Test(expected = IllegalArgumentException.class)
    public void shouldFailForArrayWithNull() {
        new EnumBasedFeatureProvider(ValidFeatureEnum.class, null);
    }
",non-flaky,5
95709,togglz_togglz,EnumBasedFeatureProviderTest.shouldFailForNonEnumType,"    @Test(expected = IllegalArgumentException.class)
    public void shouldFailForNonEnumType() {
        new EnumBasedFeatureProvider(NotAnEnum.class);
    }
",non-flaky,5
95710,togglz_togglz,EnumBasedFeatureProviderTest.shouldFailForDuplicateFeatureName,"    @Test(expected = IllegalStateException.class)
    public void shouldFailForDuplicateFeatureName() {
        
        EnumBasedFeatureProvider provider = new EnumBasedFeatureProvider();
        provider.addFeatureEnum(ValidFeatureEnum.class);
        provider.addFeatureEnum(DuplicateNameFeatureEnum.class); // should throw IllegalStateException
    }
",non-flaky,5
95711,togglz_togglz,EnumBasedFeatureProviderTest.shouldReturnCorrectListOfFeaturesForEnum,"    @Test
    public void shouldReturnCorrectListOfFeaturesForEnum() {

        FeatureProvider provider = new EnumBasedFeatureProvider(ValidFeatureEnum.class);
        assertThat(provider.getFeatures())
            .containsSequence(ValidFeatureEnum.FEATURE1, ValidFeatureEnum.FEATURE2);

    }
",non-flaky,5
95712,togglz_togglz,EnumBasedFeatureProviderTest.shouldReturnMetaDataWithCorrectLabel,"    @Test
    public void shouldReturnMetaDataWithCorrectLabel() {

        FeatureProvider provider = new EnumBasedFeatureProvider(ValidFeatureEnum.class);
        FeatureMetaData metaData = provider.getMetaData(ValidFeatureEnum.FEATURE1);
        assertThat(metaData.getLabel()).isEqualTo(""First feature"");

    }
",non-flaky,5
95713,togglz_togglz,EnumBasedFeatureProviderTest.shouldReturnMetaDataWhenRequestedWithOtherFeatureImplementation,"    @Test
    public void shouldReturnMetaDataWhenRequestedWithOtherFeatureImplementation() {

        FeatureProvider provider = new EnumBasedFeatureProvider(ValidFeatureEnum.class);
        FeatureMetaData metaData =
            provider.getMetaData(new OtherFeatureImpl(ValidFeatureEnum.FEATURE1.name()));
        assertThat(metaData.getLabel()).isEqualTo(""First feature"");

    }
",non-flaky,5
95714,togglz_togglz,EnumBasedFeatureProviderTest.shouldReturnOwnerNameIfAnnotationPresent,"    @Test
    public void shouldReturnOwnerNameIfAnnotationPresent() {
        FeatureProvider provider = new EnumBasedFeatureProvider(ValidFeatureEnum.class);
        FeatureMetaData metaData = provider.getMetaData(ValidFeatureEnum.WITH_OWNER);
        assertThat(metaData.getAttributes())
            .containsValue(""Christian"");
    }
",non-flaky,5
95715,togglz_togglz,EnumBasedFeatureProviderTest.shouldReturnNullForOwnerNameByDefault,"    @Test
    public void shouldReturnNullForOwnerNameByDefault() {
        FeatureProvider provider = new EnumBasedFeatureProvider(ValidFeatureEnum.class);
        FeatureMetaData metaData = provider.getMetaData(ValidFeatureEnum.FEATURE1);
        assertThat(metaData.getAttributes())
            .doesNotContainValue(""Christian"");
    }
",non-flaky,5
95716,togglz_togglz,EnumBasedFeatureProviderTest.shouldReturnInfoLinkIfAnnotationPresent,"    @Test
    public void shouldReturnInfoLinkIfAnnotationPresent() {
        FeatureProvider provider = new EnumBasedFeatureProvider(ValidFeatureEnum.class);
        FeatureMetaData metaData = provider.getMetaData(ValidFeatureEnum.WITH_LINK);
        assertThat(metaData.getAttributes())
            .containsValue(""https://github.com/togglz/togglz/pull/33"");
    }
",non-flaky,5
95717,togglz_togglz,EnumBasedFeatureProviderTest.shouldReturnNullForInfoLinkByDefault,"    @Test
    public void shouldReturnNullForInfoLinkByDefault() {
        FeatureProvider provider = new EnumBasedFeatureProvider(ValidFeatureEnum.class);
        FeatureMetaData metaData = provider.getMetaData(ValidFeatureEnum.FEATURE1);
        assertThat(metaData.getAttributes())
            .doesNotContainValue(""https://github.com/togglz/togglz/pull/33"");
    }
",non-flaky,5
95718,togglz_togglz,EnumBasedFeatureProviderTest.shouldReturnCombinedFeatureListForMultipleEnums,"    @Test
    public void shouldReturnCombinedFeatureListForMultipleEnums() {

        FeatureProvider provider = new EnumBasedFeatureProvider()
            .addFeatureEnum(ValidFeatureEnum.class)
            .addFeatureEnum(OtherFeatureEnum.class);

        // all feature are in the list
        assertThat(provider.getFeatures())
            .hasSize(ValidFeatureEnum.values().length + OtherFeatureEnum.values().length)
            .contains(ValidFeatureEnum.FEATURE1)
            .contains(OtherFeatureEnum.ADDITIONAL_FEATURE);

    }
",non-flaky,5
95719,togglz_togglz,EnumBasedFeatureProviderTest.shouldBuildMetadataForMultipleEnums,"    @Test
    public void shouldBuildMetadataForMultipleEnums() {

        FeatureProvider provider = new EnumBasedFeatureProvider()
            .addFeatureEnum(ValidFeatureEnum.class)
            .addFeatureEnum(OtherFeatureEnum.class);

        assertThat(provider.getMetaData(ValidFeatureEnum.FEATURE1).getLabel())
            .isEqualTo(""First feature"");
        assertThat(provider.getMetaData(OtherFeatureEnum.ADDITIONAL_FEATURE).getLabel())
            .isEqualTo(""Additional Feature"");

    }
",non-flaky,5
95720,togglz_togglz,EnumBasedFeatureProviderTest.shouldReturnCombinedFeatureListForMultipleEnumsViaConstructor,"    @Test
        public void shouldReturnCombinedFeatureListForMultipleEnumsViaConstructor() {

            FeatureProvider provider = new EnumBasedFeatureProvider(ValidFeatureEnum.class, OtherFeatureEnum.class);

            // all feature are in the list
            assertThat(provider.getFeatures())
                .hasSize(ValidFeatureEnum.values().length + OtherFeatureEnum.values().length)
                .contains(ValidFeatureEnum.FEATURE1)
                .contains(OtherFeatureEnum.ADDITIONAL_FEATURE);

        }
",non-flaky,5
95721,togglz_togglz,EnumBasedFeatureProviderTest.shouldBuildMetadataForMultipleEnumsViaConstructor,"        @Test
        public void shouldBuildMetadataForMultipleEnumsViaConstructor() {

            FeatureProvider provider = new EnumBasedFeatureProvider(ValidFeatureEnum.class, OtherFeatureEnum.class);

            assertThat(provider.getMetaData(ValidFeatureEnum.FEATURE1).getLabel())
                .isEqualTo(""First feature"");
            assertThat(provider.getMetaData(OtherFeatureEnum.ADDITIONAL_FEATURE).getLabel())
                .isEqualTo(""Additional Feature"");

        }
",non-flaky,5
95722,togglz_togglz,FeatureManagerBuilderTest.shouldAddStrategyIfUsingDefaultProvider,"    @Test
    public void shouldAddStrategyIfUsingDefaultProvider() {

        DefaultActivationStrategyProvider provider = new DefaultActivationStrategyProvider();

        FeatureManagerBuilder.begin()
            .featureEnum(Features.class)
            .activationStrategyProvider(provider)
            .activationStrategy(new CustomActivationStrategy())
            .build();

        assertThat(provider.getActivationStrategies())
            .extracting(""id"")
            .contains(CustomActivationStrategy.class.getSimpleName());

    }
",non-flaky,5
95723,togglz_togglz,FeatureManagerBuilderTest.shouldFailIfAddingStrategyWithCustomProvider,"    @Test(expected = IllegalStateException.class)
    public void shouldFailIfAddingStrategyWithCustomProvider() {

        CustomStrategyProvider provider = new CustomStrategyProvider();

        FeatureManagerBuilder.begin()
            .featureEnum(Features.class)
            .activationStrategyProvider(provider)
            .activationStrategy(new CustomActivationStrategy())
            .build();

    }
",non-flaky,5
95724,togglz_togglz,DefaultFeatureManagerTest.testGetFeatures,"    @Test
    public void testGetFeatures() {
        assertThat(manager.getFeatures())
            .contains(MyFeatures.DELETE_USERS, MyFeatures.EXPERIMENTAL, MyFeatures.MISSING_STRATEGY);
    }
",non-flaky,5
95725,togglz_togglz,DefaultFeatureManagerTest.testIsActive,"    @Test
    public void testIsActive() {

        // DELETE_USERS disabled for unknown user
        featureUserProvider.setFeatureUser(null);
        assertEquals(false, manager.isActive(MyFeatures.DELETE_USERS));

        // DELETE_USERS enabled for admin user
        featureUserProvider.setFeatureUser(new SimpleFeatureUser(""admin"", false));
        assertEquals(true, manager.isActive(MyFeatures.DELETE_USERS));

        // DELETE_USERS enabled for other user
        featureUserProvider.setFeatureUser(new SimpleFeatureUser(""somebody"", false));
        assertEquals(false, manager.isActive(MyFeatures.DELETE_USERS));

        // EXPERIMENTAL disabled for all
        featureUserProvider.setFeatureUser(null);
        assertEquals(false, manager.isActive(MyFeatures.EXPERIMENTAL));

        // MISSING_STRATEGY disabled for all
        assertEquals(false, manager.isActive(MyFeatures.MISSING_STRATEGY));

        // EMPTY_STRATEGY enabled for all
        assertEquals(true, manager.isActive(MyFeatures.EMPTY_STRATEGY));
    }
",non-flaky,5
95726,togglz_togglz,DefaultFeatureManagerTest.testIsActiveUsingDefaultFeatureState,"    @Test
    public void testIsActiveUsingDefaultFeatureState() {
        FeatureProvider featureProvider = mock(FeatureProvider.class);
        FeatureMetaData featureMetaData = mock(FeatureMetaData.class);
        when(featureMetaData.getDefaultFeatureState()).thenReturn(new FeatureState(MyFeatures.NOT_STORED_FEATURE, true));
        when(featureProvider.getMetaData(MyFeatures.NOT_STORED_FEATURE)).thenReturn(featureMetaData);

        FeatureManager manager = new FeatureManagerBuilder()
            .featureEnum(MyFeatures.class)
            .stateRepository(repository)
            .featureProvider(featureProvider)
            .userProvider(featureUserProvider)
            .build();

        assertEquals(true, manager.isActive(MyFeatures.NOT_STORED_FEATURE));

    }
",non-flaky,5
95727,togglz_togglz,DefaultFeatureManagerTest.testShouldHandleEnabledFlagCorrectlyWithCustomStrategy,"    @Test
    public void testShouldHandleEnabledFlagCorrectlyWithCustomStrategy() {

        // enabled for admin
        featureUserProvider.setFeatureUser(new SimpleFeatureUser(""admin"", false));
        assertEquals(true, manager.isActive(MyFeatures.DELETE_USERS));

        // disable feature, but keep configuration
        FeatureState state = repository.getFeatureState(MyFeatures.DELETE_USERS);
        state.setEnabled(false);
        repository.setFeatureState(state);

        // enabled for admin
        assertEquals(false, manager.isActive(MyFeatures.DELETE_USERS));

    }
",non-flaky,5
95728,togglz_togglz,DefaultFeatureManagerTest.testGetFeatureState,"    @Test
    public void testGetFeatureState() {

        FeatureState state = manager.getFeatureState(MyFeatures.DELETE_USERS);
        assertEquals(MyFeatures.DELETE_USERS, state.getFeature());
        assertEquals(true, state.isEnabled());
        assertEquals(""admin"", state.getParameter(UsernameActivationStrategy.PARAM_USERS));

    }
",non-flaky,5
95729,togglz_togglz,DefaultFeatureManagerTest.testGetFeatureStateUsingDefaultFeatureState,"    @Test
    public void testGetFeatureStateUsingDefaultFeatureState() {
        FeatureProvider featureProvider = mock(FeatureProvider.class);
        FeatureMetaData featureMetaData = mock(FeatureMetaData.class);
        when(featureMetaData.getDefaultFeatureState()).thenReturn(new FeatureState(MyFeatures.NOT_STORED_FEATURE, true));
        when(featureProvider.getMetaData(MyFeatures.NOT_STORED_FEATURE)).thenReturn(featureMetaData);

        FeatureManager manager = new FeatureManagerBuilder()
            .featureEnum(MyFeatures.class)
            .stateRepository(repository)
            .featureProvider(featureProvider)
            .userProvider(featureUserProvider)
            .build();


        FeatureState state = manager.getFeatureState(MyFeatures.NOT_STORED_FEATURE);
        assertEquals(MyFeatures.NOT_STORED_FEATURE, state.getFeature());
        assertEquals(true, state.isEnabled());

    }
",non-flaky,5
95730,togglz_togglz,JDBCStateRepositoryTest.testShouldSaveStateWithoutStrategyOrParameters,"    @Test
    public void testShouldSaveStateWithoutStrategyOrParameters() throws SQLException {

        /*
         * WHEN a feature without strategy is persisted
         */
        FeatureState state = new FeatureState(TestFeature.F1).disable();
        repository.setFeatureState(state);

        /*
         * THEN there should be a corresponding entry in the database
         */
        assertEquals(1l, query(dataSource, ""SELECT COUNT(*) FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));
        assertEquals(0, query(dataSource, ""SELECT FEATURE_ENABLED FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));
        assertEquals(null, query(dataSource, ""SELECT STRATEGY_ID FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));
        assertEquals(null, query(dataSource, ""SELECT STRATEGY_PARAMS FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));

    }
",non-flaky,5
95731,togglz_togglz,JDBCStateRepositoryTest.testShouldSaveStateStrategyAndParameters,"    @Test
    public void testShouldSaveStateStrategyAndParameters() throws SQLException {

        /*
         * WHEN a feature without strategy is persisted
         */
        FeatureState state = new FeatureState(TestFeature.F1)
            .enable()
            .setStrategyId(""someId"")
            .setParameter(""param"", ""foo"");
        repository.setFeatureState(state);

        /*
         * THEN there should be a corresponding entry in the database
         */
        assertEquals(1l, query(dataSource, ""SELECT COUNT(*) FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));
        assertEquals(1, query(dataSource, ""SELECT FEATURE_ENABLED FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));
        assertEquals(""someId"", query(dataSource, ""SELECT STRATEGY_ID FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));
        assertEquals(""param=foo"", query(dataSource, ""SELECT STRATEGY_PARAMS FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));

    }
",non-flaky,5
95732,togglz_togglz,JDBCStateRepositoryTest.testShouldReadStateWithoutStrategyAndParameters,"    @Test
    public void testShouldReadStateWithoutStrategyAndParameters() throws SQLException {

        /*
         * GIVEN a database row containing a simple feature state
         */
        update(dataSource, ""INSERT INTO TOGGLZ VALUES ('F1', 0, NULL, NULL)"");

        /*
         * WHEN the repository reads the state
         */
        FeatureState state = repository.getFeatureState(TestFeature.F1);

        /*
         * THEN the properties should be set like expected
         */
        assertNotNull(state);
        assertEquals(TestFeature.F1, state.getFeature());
        assertEquals(false, state.isEnabled());
        assertEquals(null, state.getStrategyId());
        assertEquals(0, state.getParameterNames().size());

    }
",non-flaky,5
95733,togglz_togglz,JDBCStateRepositoryTest.testShouldReadStateWithStrategyAndParameters,"    @Test
    public void testShouldReadStateWithStrategyAndParameters() throws SQLException {

        /*
         * GIVEN a database row containing a simple feature state
         */
        update(dataSource, ""INSERT INTO TOGGLZ VALUES ('F1', 1, 'myStrategy', 'param23=foobar')"");

        /*
         * WHEN the repository reads the state
         */
        FeatureState state = repository.getFeatureState(TestFeature.F1);

        /*
         * THEN the properties should be set like expected
         */
        assertNotNull(state);
        assertEquals(TestFeature.F1, state.getFeature());
        assertEquals(true, state.isEnabled());
        assertEquals(""myStrategy"", state.getStrategyId());
        assertEquals(1, state.getParameterNames().size());
        assertEquals(""foobar"", state.getParameter(""param23""));

    }
",non-flaky,5
95734,togglz_togglz,JDBCStateRepositoryTest.testShouldUpdateExistingDatabaseEntry,"    @Test
    public void testShouldUpdateExistingDatabaseEntry() throws SQLException {

        /*
         * GIVEN a database row containing a simple feature state
         */
        update(dataSource, ""INSERT INTO TOGGLZ VALUES ('F1', 1, 'myStrategy', 'param23=foobar')"");

        /*
         * AND the database entries are like expected
         */
        assertEquals(1l, query(dataSource, ""SELECT COUNT(*) FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));
        assertEquals(1, query(dataSource, ""SELECT FEATURE_ENABLED FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));
        assertEquals(""myStrategy"", query(dataSource, ""SELECT STRATEGY_ID FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));
        assertEquals(""param23=foobar"", query(dataSource, ""SELECT STRATEGY_PARAMS FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));

        /*
         * WHEN the repository writes new state
         */
        FeatureState state = new FeatureState(TestFeature.F1)
            .disable()
            .setStrategyId(""someId"")
            .setParameter(""param"", ""foo"");
        repository.setFeatureState(state);

        /*
         * THEN the properties should be set like expected
         */
        assertEquals(1l, query(dataSource, ""SELECT COUNT(*) FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));
        assertEquals(0, query(dataSource, ""SELECT FEATURE_ENABLED FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));
        assertEquals(""someId"", query(dataSource, ""SELECT STRATEGY_ID FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));
        assertEquals(""param=foo"", query(dataSource, ""SELECT STRATEGY_PARAMS FROM TOGGLZ WHERE FEATURE_NAME = 'F1'""));

	}
",non-flaky,5
95735,togglz_togglz,JDBCStateRepositoryTest.testShouldPropagateTheExceptionWhenReadFails,"	@Test(expected = IllegalStateException.class)
	public void testShouldPropagateTheExceptionWhenReadFails() throws SQLException {

		/*
		 * GIVEN a database row containing a simple feature state
		 */
		update(dataSource, ""INSERT INTO TOGGLZ VALUES ('F1', 0, NULL, NULL)"");

		/**
		 * AND the datasource throws an exception when we try to get a
		 * connection
		 */
		DataSource spyedDataSource = Mockito.spy(dataSource);
		repository = new JDBCStateRepository(spyedDataSource, ""TOGGLZ"", true, DefaultMapSerializer.multiline());
		Mockito.when(spyedDataSource.getConnection()).thenThrow(new SQLException(""Failed to get a connection""));

		/*
		 * WHEN the repository reads the state
		 */
		repository.getFeatureState(TestFeature.F1);

		/*
		 * THEN an IllegalStateException is thrown
		 */
	}
",non-flaky,5
95736,togglz_togglz,JDBCStateRepositoryTest.testShouldPropagateTheExceptionWhenWriteFails,"	@Test(expected = IllegalStateException.class)
	public void testShouldPropagateTheExceptionWhenWriteFails() throws SQLException {

		/*
		 * GIVEN a feature state to persist
		 */
		FeatureState state = new FeatureState(TestFeature.F1).enable();

		/**
		 * AND the datasource throws an exception when we try to get a
		 * connection
		 */
		DataSource spyedDataSource = Mockito.spy(dataSource);
		repository = new JDBCStateRepository(spyedDataSource, ""TOGGLZ"", true, DefaultMapSerializer.multiline());
		Mockito.when(spyedDataSource.getConnection()).thenThrow(new SQLException(""Failed to get a connection""));

		/*
		 * WHEN the feature state is persisted
		 */
		repository.setFeatureState(state);

		/*
		 * THEN an IllegalStateException is thrown
		 */
    }
",non-flaky,5
95737,togglz_togglz,JDBCRepositoryAutoCommitTest.shouldUpdateWithAutoCommitEnabled,"    @Test
    public void shouldUpdateWithAutoCommitEnabled() {
        givenSomeDataSourceWithAutoCommitSetTo(true);
        whenTheFeatureIsEnabled();
        thenTheDatabaseShouldBeUpdated();
    }
",non-flaky,5
95738,togglz_togglz,JDBCRepositoryAutoCommitTest.shouldUpdateWithAutoCommitDisabled,"    @Test
    public void shouldUpdateWithAutoCommitDisabled() {
        givenSomeDataSourceWithAutoCommitSetTo(false);
        whenTheFeatureIsEnabled();
        thenTheDatabaseShouldBeUpdated();
    }
",non-flaky,5
95739,togglz_togglz,SchemaUpdaterTest.shouldDetectMissingTable,"    @Test
    public void shouldDetectMissingTable() throws SQLException {

        Connection connection = createConnection();
        try {

            SchemaUpdater updater = new SchemaUpdater(connection, ""TOGGLZ"", DefaultMapSerializer.multiline());
            assertFalse(updater.doesTableExist());

        } finally {
            DbUtils.closeQuietly(connection);
        }

    }
",non-flaky,5
95740,togglz_togglz,SchemaUpdaterTest.shouldMigrateToVersion1,"    @Test
    public void shouldMigrateToVersion1() throws SQLException {

        Connection connection = createConnection();
        try {

            SchemaUpdater updater = new SchemaUpdater(connection, ""TOGGLZ"", DefaultMapSerializer.multiline());
            assertFalse(updater.doesTableExist());

            updater.migrateToVersion1();

            assertTrue(updater.doesTableExist());
            assertTrue(querySucceeds(connection, ""SELECT FEATURE_NAME FROM TOGGLZ""));

        } finally {
            DbUtils.closeQuietly(connection);
        }

    }
",non-flaky,5
95741,togglz_togglz,SchemaUpdaterTest.shouldDetectVersion1,"    @Test
    public void shouldDetectVersion1() throws SQLException {

        Connection connection = createConnection();
        try {

            SchemaUpdater updater = new SchemaUpdater(connection, ""TOGGLZ"", DefaultMapSerializer.multiline());
            assertFalse(updater.doesTableExist());

            assertFalse(updater.isSchemaVersion1());

            updater.migrateToVersion1();

            assertTrue(updater.isSchemaVersion1());

        } finally {
            DbUtils.closeQuietly(connection);
        }

    }
",non-flaky,5
95742,togglz_togglz,SchemaUpdaterTest.shouldMigrateToVersion2,"    @Test
    public void shouldMigrateToVersion2() throws SQLException {

        Connection connection = createConnection();
        try {

            // create schema version 1
            SchemaUpdater updater = new SchemaUpdater(connection, ""TOGGLZ"", DefaultMapSerializer.multiline());
            assertFalse(updater.doesTableExist());
            updater.migrateToVersion1();
            assertTrue(updater.isSchemaVersion1());

            // insert two feature states
            update(connection, ""INSERT INTO TOGGLZ VALUES ('F1', 1, 'ck, admin')"");
            update(connection, ""INSERT INTO TOGGLZ VALUES ('F2', 1, '')"");
            update(connection, ""INSERT INTO TOGGLZ VALUES ('F3', 1, NULL)"");

            List<Object[]> dataBefore = query(connection,
                ""SELECT FEATURE_NAME, FEATURE_USERS FROM TOGGLZ ORDER BY FEATURE_NAME"");
            assertEquals(3, dataBefore.size());
            assertEquals(""F1"", dataBefore.get(0)[0]);
            assertEquals(""ck, admin"", dataBefore.get(0)[1]);

            // migrate the schema
            updater.migrateToVersion2();

            // check the new columns are present
            assertTrue(querySucceeds(connection, ""SELECT FEATURE_NAME,STRATEGY_ID,STRATEGY_PARAMS FROM TOGGLZ""));

            // check the old users column is deleted
            assertFalse(querySucceeds(connection, ""SELECT FEATURE_USERS FROM TOGGLZ""));

            // check 3 features are there after the migration
            List<Object[]> dataAfter = query(connection,
                ""SELECT FEATURE_NAME, STRATEGY_ID, STRATEGY_PARAMS FROM TOGGLZ ORDER BY FEATURE_NAME"");
            assertEquals(3, dataBefore.size());

            // first feature is migrated
            assertEquals(""F1"", dataAfter.get(0)[0]);
            assertEquals(UsernameActivationStrategy.ID, dataAfter.get(0)[1]);
            assertEquals(""users=ck, admin"", dataAfter.get(0)[2].toString().trim());

            // second feature didn't change
            assertEquals(""F2"", dataAfter.get(1)[0]);
            assertEquals(null, dataAfter.get(1)[1]);
            assertEquals(null, dataAfter.get(1)[2]);

            // second feature didn't change
            assertEquals(""F3"", dataAfter.get(2)[0]);
            assertEquals(null, dataAfter.get(2)[1]);
            assertEquals(null, dataAfter.get(2)[2]);

        } finally {
            DbUtils.closeQuietly(connection);
        }

    }
",non-flaky,5
98010,vert-x3_vertx-mongo-client,MongoClientWithObjectIdTest.testSavePreexistingLongID,"  @Test
  public void testSavePreexistingLongID() throws Exception {
    //Override this test as it does not make sense for useObjectId = true
    assertTrue(true);
    testComplete();
    await();
  }
",non-flaky,5
98011,vert-x3_vertx-mongo-client,MongoClientWithObjectIdTest.testFindOneReturnsStringId,"  @Test
  public void testFindOneReturnsStringId() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject orig = createDoc();
      JsonObject doc = orig.copy();
      mongoClient.insert(collection, doc, onSuccess(id -> {
        assertNotNull(id);
        mongoClient.findOne(collection, new JsonObject().put(""foo"", ""bar""), null, onSuccess(obj -> {
          assertTrue(obj.containsKey(""_id""));
          assertTrue(obj.getValue(""_id"") instanceof String);
          obj.remove(""_id"");
          assertEquals(orig, obj);
          testComplete();
        }));
      }));
    }));
    await();
  }
",non-flaky,5
98012,vert-x3_vertx-mongo-client,MongoClientWithObjectIdTest.testFindOneReturnsNothing,"  @Test
  public void testFindOneReturnsNothing() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject orig = createDoc();
      JsonObject doc = orig.copy();
      mongoClient.insert(collection, doc, onSuccess(id -> {
        assertNotNull(id);
        mongoClient.findOne(collection, new JsonObject().put(""nothing"", ""xxrandomxx""), null, onSuccess(obj -> {
          assertNull(obj);
          testComplete();
        }));
      }));
    }));
    await();
  }
",non-flaky,5
98013,vert-x3_vertx-mongo-client,MongoClientWithObjectIdTest.testFindReturnsStringId,"  @Test
  public void testFindReturnsStringId() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject orig = createDoc();
      JsonObject doc = orig.copy();
      mongoClient.insert(collection, doc, onSuccess(id -> {
        assertNotNull(id);
        mongoClient.find(collection, new JsonObject().put(""foo"", ""bar""), onSuccess(list -> {
          assertTrue(list.size() == 1);
          JsonObject obj = list.get(0);
          assertTrue(obj.containsKey(""_id""));
          assertTrue(obj.getValue(""_id"") instanceof String);
          obj.remove(""_id"");
          assertEquals(orig, obj);
          testComplete();
        }));
      }));
    }));
    await();
  }
",non-flaky,5
98014,vert-x3_vertx-mongo-client,MongoClientWithObjectIdTest.testInsertPreexistingObjectID,"  @Test
  public void testInsertPreexistingObjectID() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject doc = createDoc();
      //Changed to hex string as a random string will not be valid for useObjectId = true
      doc.put(""_id"", new ObjectId().toHexString());
      mongoClient.insertWithOptions(collection, doc, ACKNOWLEDGED, onSuccess(id -> {
        assertNull(id);
        testComplete();
      }));
    }));
    await();
  }
",non-flaky,5
98015,vert-x3_vertx-mongo-client,MongoClientWithObjectIdTest.testInsertPreexistingID,"  @Test
  public void testInsertPreexistingID() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject doc = createDoc();
      //Changed to hex string as a random string will not be valid for useObjectId = true
      doc.put(""_id"", new ObjectId().toHexString());
      mongoClient.insert(collection, doc, onSuccess(id -> {
        assertNull(id);
        testComplete();
      }));
    }));
    await();
  }
",non-flaky,5
98016,vert-x3_vertx-mongo-client,MongoClientWithObjectIdTest.testInsertRetrieve,"  @Test
  public void testInsertRetrieve() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject doc = createDoc();
      doc.put(""_id"", new ObjectId().toHexString());
      mongoClient.insert(collection, doc, onSuccess(id -> {
        assertNull(id);
        mongoClient.findOne(collection, new JsonObject(), null, onSuccess(retrieved -> {
          assertEquals(doc, retrieved);
          testComplete();
        }));
      }));
    }));
    await();
  }
",non-flaky,5
98017,vert-x3_vertx-mongo-client,MongoClientWithObjectIdTest.testSavePreexistingObjectID,"  @Test
  public void testSavePreexistingObjectID() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject doc = createDoc();
      //Changed to hex string as a random string will not be valid for useObjectId = true
      doc.put(""_id"", new ObjectId().toHexString());
      mongoClient.saveWithOptions(collection, doc, ACKNOWLEDGED, onSuccess(id -> {
        assertNull(id);
        testComplete();
      }));
    }));
    await();
  }
",non-flaky,5
98018,vert-x3_vertx-mongo-client,MongoClientWithObjectIdTest.testInsertAlreadyExists,"  @Test
  public void testInsertAlreadyExists() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject doc = createDoc();
      mongoClient.insert(collection, doc, onSuccess(id -> {
        assertNotNull(id);
        doc.put(""_id"", id);
        mongoClient.insert(collection, doc, response -> {
          assertFalse(response.succeeded());
          testComplete();
        });
      }));
    }));
    await();
  }
",non-flaky,5
98019,vert-x3_vertx-mongo-client,MongoClientWithObjectIdTest.testReplaceUpsert,"  @Test
  public void testReplaceUpsert() {
    String collection = randomCollection();
    JsonObject doc = createDoc();
    mongoClient.insert(collection, doc, onSuccess(id -> {
      assertNotNull(id);
      JsonObject replacement = createDoc();
      replacement.put(""replacement"", true);
      mongoClient.replaceDocumentsWithOptions(collection, new JsonObject().put(""_id"", new ObjectId().toHexString()), replacement, new UpdateOptions(true), onSuccess(v -> {
        mongoClient.find(collection, new JsonObject(), onSuccess(list -> {
          assertNotNull(list);
          assertEquals(2, list.size());
          JsonObject result = null;
          for (JsonObject o : list) {
            if (o.containsKey(""replacement"")) {
              result = o;
            }
          }
          assertNotNull(result);
          testComplete();
        }));
      }));
    }));

    await();
  }
",non-flaky,5
98020,vert-x3_vertx-mongo-client,UpdateOptionsTest.testOptions,"  @Test
  public void testOptions() {
    UpdateOptions options = new UpdateOptions();

    WriteOption writeOption = ACKNOWLEDGED;
    assertEquals(options, options.setWriteOption(writeOption));
    assertEquals(writeOption, options.getWriteOption());

    boolean multi = TestUtils.randomBoolean();
    assertEquals(options, options.setMulti(multi));
    assertEquals(multi, options.isMulti());

    boolean upsert = TestUtils.randomBoolean();
    assertEquals(options, options.setUpsert(upsert));
    assertEquals(upsert, options.isUpsert());

    JsonArray arrayFilters = new JsonArray().add(new JsonObject().put(TestUtils.randomAlphaString(5), TestUtils.randomAlphaString(5)));
    assertEquals(options, options.setArrayFilters(arrayFilters));
    assertEquals(arrayFilters, options.getArrayFilters());
  }
",non-flaky,5
98021,vert-x3_vertx-mongo-client,UpdateOptionsTest.testDefaultOptions,"  @Test
  public void testDefaultOptions() {
    UpdateOptions options = new UpdateOptions();
    assertNull(options.getWriteOption());
    assertFalse(options.isMulti());
    assertFalse(options.isUpsert());
    assertNull(options.getArrayFilters());
  }
",non-flaky,5
98022,vert-x3_vertx-mongo-client,UpdateOptionsTest.testOptionsJson,"  @Test
  public void testOptionsJson() {
    JsonObject json = new JsonObject();

    WriteOption writeOption = JOURNALED;
    json.put(""writeOption"", writeOption.name());

    boolean multi = TestUtils.randomBoolean();
    json.put(""multi"", multi);

    boolean upsert = TestUtils.randomBoolean();
    json.put(""upsert"", upsert);

    JsonArray arrayFilters = new JsonArray().add(new JsonObject().put(TestUtils.randomAlphaString(5), TestUtils.randomAlphaString(5)));
    json.put(""arrayFilters"", arrayFilters);

    UpdateOptions options = new UpdateOptions(json);
    assertEquals(writeOption, options.getWriteOption());
    assertEquals(multi, options.isMulti());
    assertEquals(upsert, options.isUpsert());
    assertEquals(arrayFilters, options.getArrayFilters());
  }
",non-flaky,5
98023,vert-x3_vertx-mongo-client,UpdateOptionsTest.testDefaultOptionsJson,"  @Test
  public void testDefaultOptionsJson() {
    UpdateOptions options = new UpdateOptions(new JsonObject());
    UpdateOptions def = new UpdateOptions();
    assertEquals(def.getWriteOption(), options.getWriteOption());
    assertEquals(def.isMulti(), options.isMulti());
    assertEquals(def.isUpsert(), options.isUpsert());
    assertEquals(def.getArrayFilters(), options.getArrayFilters());
  }
",non-flaky,5
98024,vert-x3_vertx-mongo-client,UpdateOptionsTest.testCopyOptions,"  @Test
  public void testCopyOptions() {
    UpdateOptions options = new UpdateOptions();
    WriteOption writeOption = REPLICA_ACKNOWLEDGED;
    boolean multi = TestUtils.randomBoolean();
    boolean upsert = TestUtils.randomBoolean();
    JsonArray arrayFilters = new JsonArray().add(new JsonObject().put(TestUtils.randomAlphaString(5), TestUtils.randomAlphaString(5)));

    options.setWriteOption(writeOption);
    options.setMulti(multi);
    options.setUpsert(upsert);
    options.setArrayFilters(arrayFilters);

    UpdateOptions copy = new UpdateOptions(options);
    assertEquals(options.getWriteOption(), copy.getWriteOption());
    assertEquals(options.isMulti(), copy.isMulti());
    assertEquals(options.isUpsert(), copy.isUpsert());
    assertEquals(options.getArrayFilters(), copy.getArrayFilters());
  }
",non-flaky,5
98025,vert-x3_vertx-mongo-client,UpdateOptionsTest.testToJson,"  @Test
  public void testToJson() {
    UpdateOptions options = new UpdateOptions();
    WriteOption writeOption = MAJORITY;
    boolean multi = TestUtils.randomBoolean();
    boolean upsert = TestUtils.randomBoolean();
    JsonArray arrayFilters = new JsonArray().add(new JsonObject().put(TestUtils.randomAlphaString(5), TestUtils.randomAlphaString(5)));

    options.setWriteOption(writeOption);
    options.setMulti(multi);
    options.setUpsert(upsert);
    options.setArrayFilters(arrayFilters);

    assertEquals(options, new UpdateOptions(options.toJson()));
  }
",non-flaky,5
98026,vert-x3_vertx-mongo-client,MongoClientUpdateResultTest.testMongoClientUpdateResultStatuses,"  @Test
  public void testMongoClientUpdateResultStatuses() {
    long randomMatched = TestUtils.randomLong();
    JsonObject randomUpsertedId = randomUpsertId();
    long randomModified = TestUtils.randomLong();

    MongoClientUpdateResult mongoClientUpdateResult = new MongoClientUpdateResult(randomMatched, randomUpsertedId, randomModified);

    assertEquals(randomMatched, mongoClientUpdateResult.getDocMatched());
    assertEquals(randomUpsertedId, mongoClientUpdateResult.getDocUpsertedId());
    assertEquals(randomModified, mongoClientUpdateResult.getDocModified());
  }
",non-flaky,5
98027,vert-x3_vertx-mongo-client,MongoClientUpdateResultTest.testDefaultMongoClientUpdateResult,"  @Test
  public void testDefaultMongoClientUpdateResult() {
    MongoClientUpdateResult mongoClientUpdateResult = new MongoClientUpdateResult();

    assertEquals(MongoClientUpdateResult.DEFAULT_DOCMATCHED, mongoClientUpdateResult.getDocMatched());
    assertNull(mongoClientUpdateResult.getDocUpsertedId());
    assertEquals(MongoClientUpdateResult.DEFAULT_DOCMODIFIED, mongoClientUpdateResult.getDocModified());
  }
",non-flaky,5
98028,vert-x3_vertx-mongo-client,MongoClientUpdateResultTest.testCopyMongoClientUpdateResult,"  @Test
  public void testCopyMongoClientUpdateResult() {
    MongoClientUpdateResult mongoClientUpdateResultOrigin = new MongoClientUpdateResult(TestUtils.randomLong(),
      randomUpsertId(), TestUtils.randomLong());
    MongoClientUpdateResult mongoClientUpdateResultCopy = new MongoClientUpdateResult(mongoClientUpdateResultOrigin);

    assertEquals(mongoClientUpdateResultOrigin.getDocMatched(), mongoClientUpdateResultCopy.getDocMatched());
    assertEquals(mongoClientUpdateResultOrigin.getDocUpsertedId(), mongoClientUpdateResultCopy.getDocUpsertedId());
    assertEquals(mongoClientUpdateResultOrigin.getDocModified(), mongoClientUpdateResultCopy.getDocModified());
  }
",non-flaky,5
98029,vert-x3_vertx-mongo-client,MongoClientUpdateResultTest.testJsonMongoClientUpdateResult,"  @Test
  public void testJsonMongoClientUpdateResult() {
    properJson();

    jsonWithoutRequiredFields();
  }
",non-flaky,5
98030,vert-x3_vertx-mongo-client,MongoClientUpdateResultTest.testToJsonMongoClientUpdateResult,"  @Test
  public void testToJsonMongoClientUpdateResult() {
    JsonObject mongoClientUpdateResultJson = randomMongoClientUpdateResultJson();
    MongoClientUpdateResult mongoClientUpdateResult = new MongoClientUpdateResult(mongoClientUpdateResultJson);

    assertEquals(mongoClientUpdateResultJson, mongoClientUpdateResult.toJson());
  }
",non-flaky,5
98031,vert-x3_vertx-mongo-client,MongoClientUpdateResultTest.testMongoUpdateResultEquality,"  @Test
  public void testMongoUpdateResultEquality() {
    logicallyUnequal();

    logicallyEqual();
  }
",non-flaky,5
98032,vert-x3_vertx-mongo-client,MongoClientBulkWriteResultTest.testMongoClientBulkWriteStatuses,"  @Test
  public void testMongoClientBulkWriteStatuses() {
    long randomMatched = TestUtils.randomLong();
    long randomModified = TestUtils.randomLong();
    long randomInserted = TestUtils.randomLong();
    long randomDeleted = TestUtils.randomLong();
    List<JsonObject> upserts = randomUpsertIds();

    MongoClientBulkWriteResult mongoClientBulkWriteResult = new MongoClientBulkWriteResult(randomInserted,
        randomMatched, randomDeleted, randomModified, upserts);

    assertEquals(randomMatched, mongoClientBulkWriteResult.getMatchedCount());
    assertEquals(randomModified, mongoClientBulkWriteResult.getModifiedCount());
    assertEquals(randomInserted, mongoClientBulkWriteResult.getInsertedCount());
    assertEquals(randomDeleted, mongoClientBulkWriteResult.getDeletedCount());
    assertEquals(upserts, mongoClientBulkWriteResult.getUpserts());
  }
",non-flaky,5
98033,vert-x3_vertx-mongo-client,MongoClientBulkWriteResultTest.testDefaultMongoClientBulkWriteResult,"  @Test
  public void testDefaultMongoClientBulkWriteResult() {
    MongoClientBulkWriteResult mongoClientBulkWriteResult = new MongoClientBulkWriteResult();

    assertEquals(MongoClientBulkWriteResult.DEFAULT_MATCHED_COUNT, mongoClientBulkWriteResult.getMatchedCount());
    assertEquals(MongoClientBulkWriteResult.DEFAULT_MODIFIED_COUNT, mongoClientBulkWriteResult.getModifiedCount());
    assertEquals(MongoClientBulkWriteResult.DEFAULT_INSERTED_COUNT, mongoClientBulkWriteResult.getInsertedCount());
    assertEquals(MongoClientBulkWriteResult.DEFAULT_DELETED_COUNT, mongoClientBulkWriteResult.getDeletedCount());
    assertNull(mongoClientBulkWriteResult.getUpserts());
  }
",non-flaky,5
98034,vert-x3_vertx-mongo-client,MongoClientBulkWriteResultTest.testCopyMongoClientBulkWriteResult,"  @Test
  public void testCopyMongoClientBulkWriteResult() {
    MongoClientBulkWriteResult mongoClientBulkWriteResultOrigin = new MongoClientBulkWriteResult(TestUtils.randomLong(),
        TestUtils.randomLong(), TestUtils.randomLong(), TestUtils.randomLong(), randomUpsertIds());

    MongoClientBulkWriteResult mongoClientBulkWriteResultCopy = new MongoClientBulkWriteResult(
        mongoClientBulkWriteResultOrigin);

    assertEquals(mongoClientBulkWriteResultCopy.getMatchedCount(), mongoClientBulkWriteResultOrigin.getMatchedCount());
    assertEquals(mongoClientBulkWriteResultCopy.getModifiedCount(),
        mongoClientBulkWriteResultOrigin.getModifiedCount());
    assertEquals(mongoClientBulkWriteResultCopy.getInsertedCount(),
        mongoClientBulkWriteResultOrigin.getInsertedCount());
    assertEquals(mongoClientBulkWriteResultCopy.getDeletedCount(), mongoClientBulkWriteResultOrigin.getDeletedCount());
    assertEquals(mongoClientBulkWriteResultCopy.getUpserts(), mongoClientBulkWriteResultOrigin.getUpserts());
  }
",non-flaky,5
98035,vert-x3_vertx-mongo-client,MongoClientBulkWriteResultTest.testJsonMongoClientBulkWriteResult,"  @Test
  public void testJsonMongoClientBulkWriteResult() {
    properJson();

    jsonWithoutRequiredFields();
  }
",non-flaky,5
98036,vert-x3_vertx-mongo-client,MongoClientBulkWriteResultTest.testToJsonMongoClientBulkWriteResult,"  @Test
  public void testToJsonMongoClientBulkWriteResult() {
    JsonObject mongoClientBulkWriteResultJson = randomMongoClientBulkWriteResultJson();
    MongoClientBulkWriteResult mongoClientBulkWriteResult = new MongoClientBulkWriteResult(
        mongoClientBulkWriteResultJson);

    assertEquals(mongoClientBulkWriteResultJson, mongoClientBulkWriteResult.toJson());
  }
",non-flaky,5
98037,vert-x3_vertx-mongo-client,MongoClientBulkWriteResultTest.testMongoBulkWriteResultEquality,"  @Test
  public void testMongoBulkWriteResultEquality() {
    logicallyUnequal();

    logicallyEqual();
  }
",non-flaky,5
98038,vert-x3_vertx-mongo-client,AggregateOptionsTest.testOptions,"  @Test
  public void testOptions() {
    AggregateOptions options = new AggregateOptions();

    long maxTime = TestUtils.randomLong();
    assertEquals(options, options.setMaxTime(maxTime));
    assertEquals(maxTime, options.getMaxTime());
  }
",non-flaky,5
98039,vert-x3_vertx-mongo-client,AggregateOptionsTest.testDefaultOptions,"  @Test
  public void testDefaultOptions() {
    AggregateOptions options = new AggregateOptions();
    assertEquals(AggregateOptions.DEFAULT_MAX_TIME, options.getMaxTime());
  }
",non-flaky,5
98040,vert-x3_vertx-mongo-client,AggregateOptionsTest.testOptionsJson,"  @Test
  public void testOptionsJson() {
    JsonObject json = new JsonObject();

    long maxAwaitTime = TestUtils.randomLong();
    json.put(""maxAwaitTime"", maxAwaitTime);

    long maxTime = TestUtils.randomLong();
    json.put(""maxTime"", maxTime);

    AggregateOptions options = new AggregateOptions(json);
    assertEquals(maxTime, options.getMaxTime());
  }
",non-flaky,5
98041,vert-x3_vertx-mongo-client,AggregateOptionsTest.testDefaultOptionsJson,"  @Test
  public void testDefaultOptionsJson() {
    AggregateOptions options = new AggregateOptions(new JsonObject());
    AggregateOptions def = new AggregateOptions();
    assertEquals(def.getMaxTime(), options.getMaxTime());
  }
",non-flaky,5
98042,vert-x3_vertx-mongo-client,AggregateOptionsTest.testCopyOptions,"  @Test
  public void testCopyOptions() {
    AggregateOptions options = new AggregateOptions();
    options.setMaxTime(TestUtils.randomLong());

    AggregateOptions copy = new AggregateOptions(options);
    assertEquals(options.getMaxTime(), copy.getMaxTime());
  }
",non-flaky,5
98043,vert-x3_vertx-mongo-client,AggregateOptionsTest.testToJson,"  @Test
  public void testToJson() {
    AggregateOptions options = new AggregateOptions();
    long maxTime = TestUtils.randomPositiveLong();
    options.setMaxTime(maxTime);

    assertEquals(options, new AggregateOptions(options.toJson()));
  }
",non-flaky,5
98044,vert-x3_vertx-mongo-client,RefCountTest.testNonShared,"  @Test
  public void testNonShared() {
    LocalMap<String, Object> map = getLocalMap();
    JsonObject config = getConfig();
    MongoClient client1 = MongoClient.create(vertx, config);
    assertEquals(1, map.size());
    MongoClient client2 = MongoClient.create(vertx, config);
    assertEquals(2, map.size());
    MongoClient client3 = MongoClient.create(vertx, config);
    assertEquals(3, map.size());
    client1.close();
    assertEquals(2, map.size());
    client2.close();
    assertEquals(1, map.size());
    client3.close();
    assertWaitUntil(() -> map.size() == 0);
    assertWaitUntil(() -> getLocalMap().size() == 0);
    assertWaitUntil(() -> map != getLocalMap()); // Map has been closed
  }
",non-flaky,5
98045,vert-x3_vertx-mongo-client,RefCountTest.testSharedDefault,"  @Test
  public void testSharedDefault() throws Exception {
    LocalMap<String, Object> map = getLocalMap();
    JsonObject config = getConfig();
    MongoClient client1 = MongoClient.createShared(vertx, config);
    assertEquals(1, map.size());
    MongoClient client2 = MongoClient.createShared(vertx, config);
    assertEquals(1, map.size());
    MongoClient client3 = MongoClient.createShared(vertx, config);
    assertEquals(1, map.size());
    client1.close();
    assertEquals(1, map.size());
    client2.close();
    assertEquals(1, map.size());
    client3.close();
    assertEquals(0, map.size());
    assertNotSame(map, getLocalMap());
  }
",non-flaky,5
98046,vert-x3_vertx-mongo-client,RefCountTest.testSharedNamed,"  @Test
  public void testSharedNamed() throws Exception {
    LocalMap<String, Object> map = getLocalMap();
    JsonObject config = getConfig();
    MongoClient client1 = MongoClient.createShared(vertx, config, ""ds1"");
    assertEquals(1, map.size());
    MongoClient client2 = MongoClient.createShared(vertx, config, ""ds1"");
    assertEquals(1, map.size());
    MongoClient client3 = MongoClient.createShared(vertx, config, ""ds1"");
    assertEquals(1, map.size());

    MongoClient client4 = MongoClient.createShared(vertx, config, ""ds2"");
    assertEquals(2, map.size());
    MongoClient client5 = MongoClient.createShared(vertx, config, ""ds2"");
    assertEquals(2, map.size());
    MongoClient client6 = MongoClient.createShared(vertx, config, ""ds2"");
    assertEquals(2, map.size());

    client1.close();
    assertEquals(2, map.size());
    client2.close();
    assertEquals(2, map.size());
    client3.close();
    assertEquals(1, map.size());

    client4.close();
    assertEquals(1, map.size());
    client5.close();
    assertEquals(1, map.size());
    client6.close();
    assertEquals(0, map.size());
    assertNotSame(map, getLocalMap());
  }
",non-flaky,5
98047,vert-x3_vertx-mongo-client,GridFsTest.testDelete,"  @Test
  public void testDelete() {
    String fileName = createTempFileWithContent((1024 * 3) + 70);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> mongoGridFsPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", mongoGridFsPromise);

    mongoGridFsPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<Void> deletePromise = Promise.promise();
      gridFsClient.get().delete(id, deletePromise);
      return deletePromise.future();
    }).onComplete(event -> {
      if (event.succeeded()) {
        testComplete();
      } else {
        fail(event.cause());
      }
    });
    await();
  }
",non-flaky,5
98048,vert-x3_vertx-mongo-client,GridFsTest.testFileUpload,"  @Test
  public void testFileUpload() {

    long fileLength = (1024 * 3) + 70;
    String fileName = createTempFileWithContent(fileLength);
    String downloadFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<Long> downloadPromise = Promise.promise();
      gridFsClient.get().downloadFileAs(fileName, downloadFileName, downloadPromise);
      return downloadPromise.future();
    }).compose(length -> {
      assertEquals((long)length, fileLength);
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      } else {
        testComplete();
      }
    });
    await();
  }
",non-flaky,5
98049,vert-x3_vertx-mongo-client,GridFsTest.testBigFileUpload,"  @Test
  public void testBigFileUpload() {
    String originalFileName = createTempFileWithContent((1024 * 50) + 16);
    long originalLength = new File(originalFileName).length();
    String copiedFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(originalFileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<Long> downloadPromise = Promise.promise();
      gridFsClient.get().downloadFileAs(originalFileName, copiedFileName, downloadPromise);
      return downloadPromise.future();
    }).compose(length -> {
      assertEquals(originalLength, length.longValue());
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      } else {
        testComplete();
      }
    });
    await();
  }
",non-flaky,5
98050,vert-x3_vertx-mongo-client,GridFsTest.testFileUploadWithOptions,"  @Test
  public void testFileUploadWithOptions() {

    String fileName = createTempFileWithContent((1027) + 7000);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    JsonObject meta = new JsonObject();
    meta.put(""nick_name"", ""Puhi the eel"");

    GridFsUploadOptions options = new GridFsUploadOptions();
    options.setMetadata(meta);

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFileWithOptions(fileName, options, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
",non-flaky,5
98051,vert-x3_vertx-mongo-client,GridFsTest.testFindWithMetadata,"  @Test
  public void testFindWithMetadata() {
    String fileName = createTempFileWithContent((1024 * 3) + 70);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    JsonObject meta = new JsonObject();
    meta.put(""nick_name"", ""Puhi the eel"");

    GridFsUploadOptions options = new GridFsUploadOptions();
    options.setMetadata(meta);

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFileWithOptions(fileName, options, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<List<String>> findPromise = Promise.promise();
      JsonObject query = new JsonObject().put(""metadata.nick_name"", ""Puhi the eel"");
      gridFsClient.get().findIds(query, findPromise);
      return findPromise.future();
    }).compose(list -> {
      assertTrue(list.size() > 0);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
",non-flaky,5
98052,vert-x3_vertx-mongo-client,GridFsTest.testFindAllIds,"  @Test
  public void testFindAllIds() {

    String fileName = createTempFileWithContent((1024 * 3) + 70);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<List<String>> findPromise = Promise.promise();
      gridFsClient.get().findAllIds(findPromise);
      return findPromise.future();
    }).compose(list -> {
      assertTrue(list.size() == 1);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
",non-flaky,5
98053,vert-x3_vertx-mongo-client,GridFsTest.testDrop,"  @Test
  public void testDrop() {
    createTempFileWithContent((1024 * 3) + 70);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();

  }
",non-flaky,5
98054,vert-x3_vertx-mongo-client,GridFsTest.testDownloadStream,"  @Test
  public void testDownloadStream() {
    long fileLength = (1024 * 3) + 70;
    String fileName = createTempFileWithContent(fileLength);
    String downloadFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createDefaultGridFsBucketService(gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<AsyncFile> openPromise = Promise.promise();
      vertx.fileSystem().open(downloadFileName, new OpenOptions().setWrite(true), openPromise);
      return openPromise.future();
    }).compose(asyncFile -> {
      Promise<Long> downloadedPromise = Promise.promise();
      gridFsClient.get().downloadByFileName(asyncFile, fileName, downloadedPromise);
      return downloadedPromise.future();
    }).compose(length -> {
      assertTrue(fileLength == length);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();

  }
",non-flaky,5
98055,vert-x3_vertx-mongo-client,GridFsTest.testDownloadStreamById,"  @Test
  public void testDownloadStreamById() {
    long fileLength = (1027) + 7000;
    String fileName = createTempFileWithContent(fileLength);
    String downloadFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();
    AtomicReference<String> idCreated = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createDefaultGridFsBucketService(gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      idCreated.set(id);
      Promise<AsyncFile> openPromise = Promise.promise();
      vertx.fileSystem().open(downloadFileName, new OpenOptions().setWrite(true), openPromise);
      return openPromise.future();
    }).compose(asyncFile -> {
      Promise<Long> downloadedPromise = Promise.promise();
      gridFsClient.get().downloadById(asyncFile, idCreated.get(), downloadedPromise);
      return downloadedPromise.future();
    }).compose(length -> {
      assertTrue(fileLength == length);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
",non-flaky,5
98056,vert-x3_vertx-mongo-client,GridFsTest.testDownloadStreamWithOptions,"  @Test
  public void testDownloadStreamWithOptions() {
    long fileLength = (1024 * 3) + 70;
    String fileName = createTempFileWithContent(fileLength);
    String downloadFileName = createTempFile();
    GridFsDownloadOptions options = new GridFsDownloadOptions();
    options.setRevision(GridFsDownloadOptions.DEFAULT_REVISION);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createDefaultGridFsBucketService(gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<AsyncFile> openPromise = Promise.promise();
      vertx.fileSystem().open(downloadFileName, new OpenOptions().setWrite(true), openPromise);
      return openPromise.future();
    }).compose(asyncFile -> {
      Promise<Long> downloadedPromise = Promise.promise();
      gridFsClient.get().downloadByFileNameWithOptions(asyncFile, fileName, options, downloadedPromise);
      return downloadedPromise.future();
    }).compose(length -> {
      assertTrue(fileLength == length);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
",non-flaky,5
98057,vert-x3_vertx-mongo-client,GridFsTest.testFileDownload,"  @Test
  public void testFileDownload() {
    String fileName = createTempFileWithContent(1024);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(uploaded -> {
      Promise<Long> downloadPromise = Promise.promise();
      gridFsClient.get().downloadFile(fileName, downloadPromise);
      return downloadPromise.future();
    }).compose(length -> {
      assertEquals(1024L, length.longValue());
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();

  }
",non-flaky,5
98058,vert-x3_vertx-mongo-client,GridFsTest.testStreamUpload,"  @Test
  public void testStreamUpload() {
    String fileName = createTempFileWithContent(1024);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<AsyncFile> openPromise = Promise.promise();
      vertx.fileSystem().open(fileName, new OpenOptions(), openPromise);
      return openPromise.future();
    }).compose(asyncFile -> {
      Promise<String> uploadedPromise = Promise.promise();
      gridFsClient.get().uploadByFileName(asyncFile, fileName, uploadedPromise);
      return uploadedPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();

  }
",non-flaky,5
98059,vert-x3_vertx-mongo-client,GridFsTest.testStreamUploadWithOptions,"  @Test
  public void testStreamUploadWithOptions() {
    String fileName = createTempFileWithContent(1024);
    GridFsUploadOptions options = new GridFsUploadOptions();
    options.setChunkSizeBytes(1024);
    options.setMetadata(new JsonObject().put(""meta_test"", ""Kamapua`a""));

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<AsyncFile> openPromise = Promise.promise();
      vertx.fileSystem().open(fileName, new OpenOptions(), openPromise);
      return openPromise.future();
    }).compose(asyncFile -> {
      Promise<String> uploadedPromise = Promise.promise();
      gridFsClient.get().uploadByFileNameWithOptions(asyncFile, fileName, options, uploadedPromise);
      return uploadedPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
",non-flaky,5
98060,vert-x3_vertx-mongo-client,GridFsTest.testFileDownloadAs,"  @Test
  public void testFileDownloadAs() {
    String fileName = createTempFileWithContent(1024);
    String asFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(uploaded -> {
      Promise<Long> downloadPromise = Promise.promise();
      gridFsClient.get().downloadFileAs(fileName, asFileName, downloadPromise);
      return downloadPromise.future();
    }).compose(length -> {
      assertEquals(1024L, length.longValue());
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
",non-flaky,5
98061,vert-x3_vertx-mongo-client,GridFsTest.testFileDownloadById,"  @Test
  public void testFileDownloadById() {
    String fileName = createTempFileWithContent(1024);
    String asFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      Promise<Long> downloadPromise = Promise.promise();
      gridFsClient.get().downloadFileByID(id, asFileName, downloadPromise);
      return downloadPromise.future();
    }).compose(length -> {
      assertEquals(1024L, length.longValue());
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
",non-flaky,5
98062,vert-x3_vertx-mongo-client,MongoClientAggregateUpdateTest.testAggregateUpdateCollection,"  @Test
  public void testAggregateUpdateCollection() {
    String collection = randomCollection();
    mongoClient.insert(collection, new JsonObject().put(""price"", 10).put(""quantity"", 1), onSuccess(id -> {
      mongoClient.insert(collection, new JsonObject().put(""price"", 20).put(""quantity"", 2), onSuccess(id2 -> {
        mongoClient.insert(collection, new JsonObject().put(""price"", 30).put(""quantity"", 10), onSuccess(id3 -> {
          mongoClient.updateCollection(collection,
            // reduce price of low quantity items
            new JsonObject().put(""quantity"", new JsonObject().put(""$lte"", 2)),
            new JsonArray().add(new JsonObject().put(""$set"", new JsonObject().put(""price"", new JsonObject().put(""$subtract"", new JsonArray().add(""$price"").add(2))))),
            onSuccess(res -> {
              assertEquals(2, res.getDocModified());
              assertEquals(2, res.getDocMatched());
              testComplete();
            }));
        }));
      }));
    }));
    await();
  }
",non-flaky,5
98063,vert-x3_vertx-mongo-client,MongoClientAggregateUpdateTest.testAggregateUpdateCollectionWithOptions,"  @Test
  public void testAggregateUpdateCollectionWithOptions() {
    String collection = randomCollection();
    mongoClient.insert(collection, new JsonObject().put(""price"", 10).put(""quantity"", 1), onSuccess(id -> {
      mongoClient.insert(collection, new JsonObject().put(""price"", 20).put(""quantity"", 2), onSuccess(id2 -> {
        mongoClient.insert(collection, new JsonObject().put(""price"", 30).put(""quantity"", 10), onSuccess(id3 -> {
          mongoClient.updateCollectionWithOptions(collection,
            // reduce price of low quantity items
            new JsonObject().put(""quantity"", new JsonObject().put(""$lte"", 2)),
            new JsonArray().add(new JsonObject().put(""$set"", new JsonObject().put(""price"", new JsonObject().put(""$subtract"", new JsonArray().add(""$price"").add(2))))),
            new UpdateOptions(),onSuccess(res -> {
              assertEquals(2, res.getDocModified());
              assertEquals(2, res.getDocMatched());
              testComplete();
            }));
        }));
      }));
    }));
    await();
  }
",non-flaky,5
98064,vert-x3_vertx-mongo-client,BulkWriteOptionsTest.testEquals,"  @Test
  public void testEquals() {
    BulkWriteOptions a = new BulkWriteOptions();
    BulkWriteOptions b = new BulkWriteOptions();
    assertEquals(a, b);

    a.setWriteOption(WriteOption.ACKNOWLEDGED);
    b.setWriteOption(WriteOption.JOURNALED);
    assertNotEquals(a, b);

    a.setWriteOption(WriteOption.MAJORITY);
    b.setWriteOption(WriteOption.MAJORITY);
    assertEquals(a, b);

    a.setOrdered(true);
    b.setOrdered(false);
    assertNotEquals(a, b);

    assertNotEquals(a, null);
  }
",non-flaky,5
98065,vert-x3_vertx-mongo-client,BulkWriteOptionsTest.testHashCode,"  @Test
  public void testHashCode() {
    BulkWriteOptions a = new BulkWriteOptions()
      .setWriteOption(WriteOption.JOURNALED)
      .setOrdered(false);
    int hash = a.hashCode();

    a.setWriteOption(WriteOption.ACKNOWLEDGED);
    assertNotEquals(hash, a.hashCode());

    a.setWriteOption(WriteOption.JOURNALED);
    a.setOrdered(true);
    assertNotEquals(hash, a.hashCode());

    a.setWriteOption(WriteOption.JOURNALED);
    a.setOrdered(false);
    assertEquals(hash, a.hashCode());
  }
",non-flaky,5
98066,vert-x3_vertx-mongo-client,FindOptionsTest.testOptions,"  @Test
  public void testOptions() {
    FindOptions options = new FindOptions();

    JsonObject fields = randomJsonObject();
    assertEquals(options, options.setFields(fields));
    assertEquals(fields, options.getFields());

    JsonObject sort = randomJsonObject();
    assertEquals(options, options.setSort(sort));
    assertEquals(sort, options.getSort());

    int limit = TestUtils.randomInt();
    assertEquals(options, options.setLimit(limit));
    assertEquals(limit, options.getLimit());

    int skip = TestUtils.randomInt();
    assertEquals(options, options.setSkip(skip));
    assertEquals(skip, options.getSkip());
  }
",non-flaky,5
98067,vert-x3_vertx-mongo-client,FindOptionsTest.testDefaultOptions,"  @Test
  public void testDefaultOptions() {
    FindOptions options = new FindOptions();
    assertNotNull(options.getFields());
    assertTrue(options.getFields().isEmpty());
    assertNotNull(options.getSort());
    assertTrue(options.getSort().isEmpty());
    assertEquals(FindOptions.DEFAULT_LIMIT, options.getLimit());
    assertEquals(FindOptions.DEFAULT_SKIP, options.getSkip());
  }
",non-flaky,5
98068,vert-x3_vertx-mongo-client,FindOptionsTest.testOptionsJson,"  @Test
  public void testOptionsJson() {
    JsonObject json = new JsonObject();

    JsonObject fields = randomJsonObject();
    json.put(""fields"", fields);

    JsonObject sort = randomJsonObject();
    json.put(""sort"", sort);

    int limit = TestUtils.randomInt();
    json.put(""limit"", limit);

    int skip = TestUtils.randomInt();
    json.put(""skip"", skip);

    FindOptions options = new FindOptions(json);
    assertEquals(fields, options.getFields());
    assertEquals(sort, options.getSort());
    assertEquals(limit, options.getLimit());
    assertEquals(skip, options.getSkip());
  }
",non-flaky,5
98069,vert-x3_vertx-mongo-client,FindOptionsTest.testDefaultOptionsJson,"  @Test
  public void testDefaultOptionsJson() {
    FindOptions options = new FindOptions(new JsonObject());
    FindOptions def = new FindOptions();
    assertEquals(def.getFields(), options.getFields());
    assertEquals(def.getSort(), options.getSort());
    assertEquals(def.getLimit(), options.getLimit());
    assertEquals(def.getSkip(), options.getSkip());
  }
",non-flaky,5
98070,vert-x3_vertx-mongo-client,FindOptionsTest.testCopyOptions,"  @Test
  public void testCopyOptions() {
    FindOptions options = new FindOptions();
    JsonObject fields = randomJsonObject();
    JsonObject sort = randomJsonObject();
    int limit = TestUtils.randomInt();
    int skip = TestUtils.randomInt();
    options.setFields(fields);
    options.setSort(sort);
    options.setLimit(limit);
    options.setSkip(skip);

    FindOptions copy = new FindOptions(options);
    assertEquals(options.getFields(), copy.getFields());
    assertEquals(options.getSort(), copy.getSort());
    assertEquals(options.getLimit(), copy.getLimit());
    assertEquals(options.getSkip(), copy.getSkip());
  }
",non-flaky,5
98071,vert-x3_vertx-mongo-client,FindOptionsTest.testToJson,"  @Test
  public void testToJson() {
    FindOptions options = new FindOptions();
    JsonObject fields = randomJsonObject();
    JsonObject sort = randomJsonObject();
    int limit = TestUtils.randomPositiveInt();
    int skip = TestUtils.randomPositiveInt();
    options.setFields(fields);
    options.setSort(sort);
    options.setLimit(limit);
    options.setSkip(skip);

    assertEquals(options, new FindOptions(options.toJson()));
  }
",non-flaky,5
98072,vert-x3_vertx-mongo-client,ServerSettingsParserTest.testServerSettings,"  @Test
  public void testServerSettings() {
    long heartbeatFrequencyMS = 1234;
    long minHeartbeatFrequencyMS = heartbeatFrequencyMS / 2;
    JsonObject config = new JsonObject();
    config.put(""heartbeatFrequencyMS"", heartbeatFrequencyMS);
    config.put(""minHeartbeatFrequencyMS"", minHeartbeatFrequencyMS);

    ServerSettings settings = new ServerSettingsParser(config).settings();
    assertEquals(heartbeatFrequencyMS, settings.getHeartbeatFrequency(TimeUnit.MILLISECONDS));
    assertEquals(minHeartbeatFrequencyMS, settings.getMinHeartbeatFrequency(TimeUnit.MILLISECONDS));
  }
",non-flaky,5
98073,vert-x3_vertx-mongo-client,WriteConcernParserTest.testNoWriteConcern,"  @Test
  public void testNoWriteConcern() {
    WriteConcern wc = new WriteConcernParser(null, new JsonObject()).writeConcern();
    assertNull(wc);
  }
",non-flaky,5
98074,vert-x3_vertx-mongo-client,WriteConcernParserTest.testWriteConcern,"  @Test
  public void testWriteConcern() {
    JsonObject config = new JsonObject();
    config.put(""writeConcern"", ""ACKNOWLEDGED"");

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(WriteConcern.ACKNOWLEDGED, wc);
  }
",non-flaky,5
98075,vert-x3_vertx-mongo-client,WriteConcernParserTest.testWriteConcernCaseInsensitive,"  @Test
  public void testWriteConcernCaseInsensitive() {
    JsonObject config = new JsonObject();
    config.put(""writeConcern"", ""acknowledged"");

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(WriteConcern.ACKNOWLEDGED, wc);
  }
",non-flaky,5
98076,vert-x3_vertx-mongo-client,WriteConcernParserTest.testInvalidWriteConcern,"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidWriteConcern() {
    JsonObject config = new JsonObject();
    config.put(""writeConcern"", ""foo"");

    new WriteConcernParser(null, config).writeConcern();
  }
",non-flaky,5
98077,vert-x3_vertx-mongo-client,WriteConcernParserTest.testInvalidTypeWriteConcern,"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidTypeWriteConcern() {
    JsonObject config = new JsonObject();
    config.put(""writeConcern"", 123);

    new WriteConcernParser(null, config);
  }
",non-flaky,5
98078,vert-x3_vertx-mongo-client,WriteConcernParserTest.testAdvancedWriteConcern_w_int,"  @Test
  public void testAdvancedWriteConcern_w_int() {
    WriteConcern expected = new WriteConcern(3).withWTimeout(25, TimeUnit.MILLISECONDS).withJournal(true);
    JsonObject config = new JsonObject();
    config.put(""w"", 3);
    config.put(""wtimeoutMS"", 25);
    config.put(""j"", true);

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
",non-flaky,5
98079,vert-x3_vertx-mongo-client,WriteConcernParserTest.testAdvancedWriteConcern_w_string,"  @Test
  public void testAdvancedWriteConcern_w_string() {
    WriteConcern expected = WriteConcern.MAJORITY.withWTimeout(1, TimeUnit.MILLISECONDS).withJournal(true);
    JsonObject config = new JsonObject();
    config.put(""w"", ""majority"");
    config.put(""wtimeoutMS"", 1);
    config.put(""j"", true);

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
",non-flaky,5
98080,vert-x3_vertx-mongo-client,WriteConcernParserTest.testAdvancedWriteConcern_w_int_only,"  @Test
  public void testAdvancedWriteConcern_w_int_only() {
    WriteConcern expected = new WriteConcern(123);
    JsonObject config = new JsonObject();
    config.put(""w"", 123);

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
",non-flaky,5
98081,vert-x3_vertx-mongo-client,WriteConcernParserTest.testAdvancedWriteConcern_w_string_only,"  @Test
  public void testAdvancedWriteConcern_w_string_only() {
    WriteConcern expected = new WriteConcern(""foo"");
    JsonObject config = new JsonObject();
    config.put(""w"", ""foo"");

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
",non-flaky,5
98082,vert-x3_vertx-mongo-client,WriteConcernParserTest.testSimpleAndAdvancedWriteConcern,"  @Test
  public void testSimpleAndAdvancedWriteConcern() {
    WriteConcern expected = WriteConcern.JOURNALED;
    JsonObject config = new JsonObject();
    config.put(""w"", ""majority"");
    config.put(""wtimeoutMS"", 1);
    config.put(""j"", true);
    // this overwrites the other options
    config.put(""writeConcern"", ""journaled"");

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
",non-flaky,5
98083,vert-x3_vertx-mongo-client,WriteConcernParserTest.testInvalidWriteConcern_w_boolean,"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidWriteConcern_w_boolean() {
    JsonObject config = new JsonObject();
    config.put(""w"", true);

    new WriteConcernParser(null, config).writeConcern();
  }
",non-flaky,5
98084,vert-x3_vertx-mongo-client,WriteConcernParserTest.testConnStringNoWriteConcern,"  @Test
  public void testConnStringNoWriteConcern() {
    final ConnectionString connString = new ConnectionString(""mongodb://localhost:27017/mydb?replicaSet=myapp"");
    WriteConcern rp = new WriteConcernParser(connString, new JsonObject()).writeConcern();
    assertNull(rp);
  }
",non-flaky,5
98085,vert-x3_vertx-mongo-client,WriteConcernParserTest.testConnStringWriteConcern,"  @Test
  public void testConnStringWriteConcern() {
    final ConnectionString connString = new ConnectionString(""mongodb://localhost:27017/mydb?replicaSet=myapp&safe=true"");
    WriteConcern wc = new WriteConcernParser(connString, new JsonObject()).writeConcern();

    assertNotNull(wc);
    assertEquals(WriteConcern.ACKNOWLEDGED, wc);
  }
",non-flaky,5
98086,vert-x3_vertx-mongo-client,WriteConcernParserTest.testConnStringSimpleAndAdvancedWriteConcern,"  @Test
  public void testConnStringSimpleAndAdvancedWriteConcern() {
    final ConnectionString connString = new ConnectionString(""mongodb://localhost:27017/mydb?replicaSet=myapp"" +
      ""&w=majority&wtimeoutms=20&journal=false"");
    WriteConcern expected = new WriteConcern(""majority"").withWTimeout(20, TimeUnit.MILLISECONDS).withJournal(false);
    WriteConcern wc = new WriteConcernParser(connString, new JsonObject()).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
",non-flaky,5
98087,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.ssl_should_be_disabled_by_default,"  @Test
  public void ssl_should_be_disabled_by_default() {
    // given
    final JsonObject configWithoutSSLInfo = new JsonObject().put(
      ""connection_string"", ""mongodb://localhost:27017/mydb?replicaSet=myRs""
    );

    // when
    final MongoClientSettings parsedSettings = new MongoClientOptionsParser(vertx, configWithoutSSLInfo).settings();

    // then
    assertFalse(parsedSettings.getSslSettings().isEnabled());
    assertFalse(parsedSettings.getSslSettings().isInvalidHostNameAllowed());
  }
",non-flaky,5
98088,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.one_should_be_able_to_enable_ssl_support_via_connection_string,"  @Test
  public void one_should_be_able_to_enable_ssl_support_via_connection_string() {
    // given
    final JsonObject withSSLEnabled = new JsonObject().put(
      ""connection_string"", ""mongodb://localhost:27017/mydb?replicaSet=myRs&ssl=true""
    );

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLEnabled).settings().getSslSettings();

    // then
    assertTrue(sslSettings.isEnabled());
  }
",non-flaky,5
98089,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.one_should_be_able_to_enable_ssl_support_via_config_property,"  @Test
  public void one_should_be_able_to_enable_ssl_support_via_config_property() {
    // given
    final JsonObject withSSLEnabled = new JsonObject().put(""ssl"", true);

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLEnabled).settings().getSslSettings();

    // then
    assertTrue(sslSettings.isEnabled());
  }
",non-flaky,5
98090,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.one_should_be_able_to_allow_invalid_host_names_via_connection_string,"  @Test
  public void one_should_be_able_to_allow_invalid_host_names_via_connection_string() {
    // given
    final JsonObject withSSLAndInvalidHostnameEnabled = new JsonObject().put(
      ""connection_string"", ""mongodb://localhost:27017/mydb?replicaSet=myRs&ssl=true&sslInvalidHostNameAllowed=true""
    );

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndInvalidHostnameEnabled)
      .settings()
      .getSslSettings();

    // then
    assertTrue(sslSettings.isInvalidHostNameAllowed());
  }
",non-flaky,5
98091,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.one_should_be_able_to_allow_invalid_host_names_via_config_property,"  @Test
  public void one_should_be_able_to_allow_invalid_host_names_via_config_property() {
    // given
    final JsonObject withSSLAndInvalidHostnameEnabled = new JsonObject()
      .put(""ssl"", true)
      .put(""sslInvalidHostNameAllowed"", true);

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndInvalidHostnameEnabled)
      .settings()
      .getSslSettings();

    // then
    assertTrue(sslSettings.isInvalidHostNameAllowed());
  }
",non-flaky,5
98092,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.testTrustAllProperty,"  @Test
  public void testTrustAllProperty() {
    // given
    final JsonObject withSSLAndTrustAllEnabled = new JsonObject()
      .put(""ssl"", true)
      .put(""trustAll"", true);

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndTrustAllEnabled)
      .settings()
      .getSslSettings();

    // then
    assertNotNull(sslSettings.getContext());
  }
",non-flaky,5
98093,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.testEmptyCaPathProperty,"  @Test
  public void testEmptyCaPathProperty() {
    // given
    final JsonObject withSSLwithoutCaPath = new JsonObject().put(""ssl"", true);

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLwithoutCaPath)
      .settings()
      .getSslSettings();

    // then
    assertNotNull(sslSettings.getContext());
  }
",non-flaky,5
98094,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.testInvalidCaPathProperty,"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidCaPathProperty() {
    // given
    final JsonObject withSSLAndCaPath = new JsonObject()
      .put(""ssl"", true)
      .put(""caPath"", ""notExisting.pem"");

    // then
    new MongoClientOptionsParser(vertx, withSSLAndCaPath);
  }
",non-flaky,5
98095,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.testEmptyCaPemCertificate,"  @Test(expected = IllegalArgumentException.class)
  public void testEmptyCaPemCertificate() throws IOException {
    // given
    final File tmpFile = tmpFolder.newFile(""invalidCa.pem"");
    final JsonObject withSSLAndCaPath = new JsonObject()
      .put(""ssl"", true)
      .put(""caPath"", tmpFile.getAbsolutePath());

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndCaPath)
      .settings()
      .getSslSettings();

    // then
    assertNull(sslSettings.getContext());
  }
",non-flaky,5
98096,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.testValidCaPemCertificate,"  @Test
  public void testValidCaPemCertificate() throws IOException {
    // given
    final File tmpFile = tmpFolder.newFile(""validCa.pem"");
    try (final FileWriter tmpWriter = new FileWriter(tmpFile)) {
      tmpWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICljCCAfigAwIBAgIJAK0oe+f4DaojMAoGCCqGSM49BAMEMFkxCzAJBgNVBAYT\n"" +
        ""AkFUMQ8wDQYDVQQIDAZWaWVubmExDjAMBgNVBAoMBU5vRW52MSkwJwYDVQQLDCBO\n"" +
        ""b0VudiBSb290IENlcnRpZmljYXRlIEF1dGhvcml0eTAeFw0xNjEwMjcxNTAwNTFa\n"" +
        ""Fw00NjEwMjAxNTAwNTFaMFkxCzAJBgNVBAYTAkFUMQ8wDQYDVQQIDAZWaWVubmEx\n"" +
        ""DjAMBgNVBAoMBU5vRW52MSkwJwYDVQQLDCBOb0VudiBSb290IENlcnRpZmljYXRl\n"" +
        ""IEF1dGhvcml0eTCBmzAQBgcqhkjOPQIBBgUrgQQAIwOBhgAEAHpsMQth12N0d+aE\n"" +
        ""FIFRd8in4MTYZNSQEyQ4fuPDNq0Zb+4TXpUmedLZQJKkAQxorak8ESC/tXuQJDUL\n"" +
        ""OoKa+R6NAT4EKR1aaVVd7clC9rfGqVwGYslppycy9zsN6O4XLUiripamQF78FzRF\n"" +
        ""8wRZvkwYhzud+jpV6shgEMw3zmcwDSYKo2YwZDAdBgNVHQ4EFgQUD96n//91CReu\n"" +
        ""Cz1K0qics6aNFV0wHwYDVR0jBBgwFoAUD96n//91CReuCz1K0qics6aNFV0wEgYD\n"" +
        ""VR0TAQH/BAgwBgEB/wIBATAOBgNVHQ8BAf8EBAMCAYYwCgYIKoZIzj0EAwQDgYsA\n"" +
        ""MIGHAkFOxsApSB7fn8ZnYG/EUscn/uAkjxHsvdEkPKCC+XYCKMssW4YP2kR6gZjo\n"" +
        ""J8vaOAJZwNevBe/R9J8zMvsAWRJmWgJCAKLedGLnBuJOK9jjnKBwbVm5OIQfApMA\n"" +
        ""I2mJVnNXvS12w4DTZlP0K1t63WxsykBBTOIVXnYdPkdZvvnoAIcfA7iM\n"" +
        ""-----END CERTIFICATE-----"");
    }
    final JsonObject withSSLAndCaPath = new JsonObject()
      .put(""ssl"", true)
      .put(""caPath"", tmpFile.getAbsolutePath());

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndCaPath)
      .settings()
      .getSslSettings();

    // then
    assertNotNull(sslSettings.getContext());
  }
",non-flaky,5
98097,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.testValidCaPemCertificateChain,"  @Test
  public void testValidCaPemCertificateChain() throws IOException {
    // given
    final File tmpFile = tmpFolder.newFile(""validCa.pem"");
    try (final FileWriter tmpWriter = new FileWriter(tmpFile)) {
      tmpWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICljCCAfigAwIBAgIJAK0oe+f4DaojMAoGCCqGSM49BAMEMFkxCzAJBgNVBAYT\n"" +
        ""AkFUMQ8wDQYDVQQIDAZWaWVubmExDjAMBgNVBAoMBU5vRW52MSkwJwYDVQQLDCBO\n"" +
        ""b0VudiBSb290IENlcnRpZmljYXRlIEF1dGhvcml0eTAeFw0xNjEwMjcxNTAwNTFa\n"" +
        ""Fw00NjEwMjAxNTAwNTFaMFkxCzAJBgNVBAYTAkFUMQ8wDQYDVQQIDAZWaWVubmEx\n"" +
        ""DjAMBgNVBAoMBU5vRW52MSkwJwYDVQQLDCBOb0VudiBSb290IENlcnRpZmljYXRl\n"" +
        ""IEF1dGhvcml0eTCBmzAQBgcqhkjOPQIBBgUrgQQAIwOBhgAEAHpsMQth12N0d+aE\n"" +
        ""FIFRd8in4MTYZNSQEyQ4fuPDNq0Zb+4TXpUmedLZQJKkAQxorak8ESC/tXuQJDUL\n"" +
        ""OoKa+R6NAT4EKR1aaVVd7clC9rfGqVwGYslppycy9zsN6O4XLUiripamQF78FzRF\n"" +
        ""8wRZvkwYhzud+jpV6shgEMw3zmcwDSYKo2YwZDAdBgNVHQ4EFgQUD96n//91CReu\n"" +
        ""Cz1K0qics6aNFV0wHwYDVR0jBBgwFoAUD96n//91CReuCz1K0qics6aNFV0wEgYD\n"" +
        ""VR0TAQH/BAgwBgEB/wIBATAOBgNVHQ8BAf8EBAMCAYYwCgYIKoZIzj0EAwQDgYsA\n"" +
        ""MIGHAkFOxsApSB7fn8ZnYG/EUscn/uAkjxHsvdEkPKCC+XYCKMssW4YP2kR6gZjo\n"" +
        ""J8vaOAJZwNevBe/R9J8zMvsAWRJmWgJCAKLedGLnBuJOK9jjnKBwbVm5OIQfApMA\n"" +
        ""I2mJVnNXvS12w4DTZlP0K1t63WxsykBBTOIVXnYdPkdZvvnoAIcfA7iM\n"" +
        ""-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\n"" +
        ""MIIE0zCCA7ugAwIBAgIQGNrRniZ96LtKIVjNzGs7SjANBgkqhkiG9w0BAQUFADCB\n"" +
        ""yjELMAkGA1UEBhMCVVMxFzAVBgNVBAoTDlZlcmlTaWduLCBJbmMuMR8wHQYDVQQL\n"" +
        ""ExZWZXJpU2lnbiBUcnVzdCBOZXR3b3JrMTowOAYDVQQLEzEoYykgMjAwNiBWZXJp\n"" +
        ""U2lnbiwgSW5jLiAtIEZvciBhdXRob3JpemVkIHVzZSBvbmx5MUUwQwYDVQQDEzxW\n"" +
        ""ZXJpU2lnbiBDbGFzcyAzIFB1YmxpYyBQcmltYXJ5IENlcnRpZmljYXRpb24gQXV0\n"" +
        ""aG9yaXR5IC0gRzUwHhcNMDYxMTA4MDAwMDAwWhcNMzYwNzE2MjM1OTU5WjCByjEL\n"" +
        ""MAkGA1UEBhMCVVMxFzAVBgNVBAoTDlZlcmlTaWduLCBJbmMuMR8wHQYDVQQLExZW\n"" +
        ""ZXJpU2lnbiBUcnVzdCBOZXR3b3JrMTowOAYDVQQLEzEoYykgMjAwNiBWZXJpU2ln\n"" +
        ""biwgSW5jLiAtIEZvciBhdXRob3JpemVkIHVzZSBvbmx5MUUwQwYDVQQDEzxWZXJp\n"" +
        ""U2lnbiBDbGFzcyAzIFB1YmxpYyBQcmltYXJ5IENlcnRpZmljYXRpb24gQXV0aG9y\n"" +
        ""aXR5IC0gRzUwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCvJAgIKXo1\n"" +
        ""nmAMqudLO07cfLw8RRy7K+D+KQL5VwijZIUVJ/XxrcgxiV0i6CqqpkKzj/i5Vbex\n"" +
        ""t0uz/o9+B1fs70PbZmIVYc9gDaTY3vjgw2IIPVQT60nKWVSFJuUrjxuf6/WhkcIz\n"" +
        ""SdhDY2pSS9KP6HBRTdGJaXvHcPaz3BJ023tdS1bTlr8Vd6Gw9KIl8q8ckmcY5fQG\n"" +
        ""BO+QueQA5N06tRn/Arr0PO7gi+s3i+z016zy9vA9r911kTMZHRxAy3QkGSGT2RT+\n"" +
        ""rCpSx4/VBEnkjWNHiDxpg8v+R70rfk/Fla4OndTRQ8Bnc+MUCH7lP59zuDMKz10/\n"" +
        ""NIeWiu5T6CUVAgMBAAGjgbIwga8wDwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8E\n"" +
        ""BAMCAQYwbQYIKwYBBQUHAQwEYTBfoV2gWzBZMFcwVRYJaW1hZ2UvZ2lmMCEwHzAH\n"" +
        ""BgUrDgMCGgQUj+XTGoasjY5rw8+AatRIGCx7GS4wJRYjaHR0cDovL2xvZ28udmVy\n"" +
        ""aXNpZ24uY29tL3ZzbG9nby5naWYwHQYDVR0OBBYEFH/TZafC3ey78DAJ80M5+gKv\n"" +
        ""MzEzMA0GCSqGSIb3DQEBBQUAA4IBAQCTJEowX2LP2BqYLz3q3JktvXf2pXkiOOzE\n"" +
        ""p6B4Eq1iDkVwZMXnl2YtmAl+X6/WzChl8gGqCBpH3vn5fJJaCGkgDdk+bW48DW7Y\n"" +
        ""5gaRQBi5+MHt39tBquCWIMnNZBU4gcmU7qKEKQsTb47bDN0lAtukixlE0kF6BWlK\n"" +
        ""WE9gyn6CagsCqiUXObXbf+eEZSqVir2G3l6BFoMtEMze/aiCKm0oHw0LxOXnGiYZ\n"" +
        ""4fQRbxC1lfznQgUy286dUV4otp6F01vvpX1FQHKOtw5rDgb7MzVIcbidJ4vEZV8N\n"" +
        ""hnacRHr2lVz2XTIIM6RUthg/aFzyQkqFOFSDX9HoLPKsEdao7WNq\n"" +
        ""-----END CERTIFICATE-----\n"");
    }
    final JsonObject withSSLAndCaPath = new JsonObject()
      .put(""ssl"", true)
      .put(""caPath"", tmpFile.getAbsolutePath());

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndCaPath)
      .settings()
      .getSslSettings();

    // then
    assertNotNull(sslSettings.getContext());
  }
",non-flaky,5
98098,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.testInvalidPemCertificate,"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidPemCertificate() throws IOException {
    // given
    final File tmpFile = tmpFolder.newFile(""brokenCa.pem"");
    try (final FileWriter tmpWriter = new FileWriter(tmpFile)) {
      tmpWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICljCCAfigAwIBAgI...BROKEN...xsykBBTOIVXnYdPkdZvvnoAIcfA7iM\n"" +
        ""-----END CERTIFICATE-----"");
    }
    final JsonObject withSSLAndCaPath = new JsonObject()
      .put(""ssl"", true)
      .put(""caPath"", tmpFile.getAbsolutePath());

    // then
    new MongoClientOptionsParser(vertx, withSSLAndCaPath);
  }
",non-flaky,5
98099,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.testValidKeyAndCertificate,"  @Test
  public void testValidKeyAndCertificate() throws IOException {
    // given
    final File tmpKeyFile = tmpFolder.newFile(""validKey.pem"");
    try (final FileWriter tmpKeyWriter = new FileWriter(tmpKeyFile)) {
      tmpKeyWriter.write(""-----BEGIN PRIVATE KEY-----\n"" +
        ""MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDVmCecLdUZU917\n"" +
        ""hweVz4JqvZ9vZEi1rH+BG98HYfRR/h3QaobxPImZu3hzKHZ+MPbm94HunLPAVA9y\n"" +
        ""ZhvZMToNfOuD4TUPBPloBuNzwBfZk2O4CaXeG4ailVWUfm5t/l+RD/55zYKuhw1/\n"" +
        ""Vl9lcOryF2XAmPQ2F1gwEKK7wt1Ak8zw8/yeYgBv1/F+ibCMvR6FVj9ABBEfTM+o\n"" +
        ""Os4oy51otUv0h63GqYgXMJyLX7q+AGWdC3srwwLQROtkzi7y00g/YryXUoIqdXEI\n"" +
        ""7CrNL35rZXcZ5LfGRwFX9evX11PpT3OShYlsJBcFE9KMatRoIWd6xUKlxTk0yLjo\n"" +
        ""OUE2tsMJAgMBAAECggEAdewZAjqzidYpU0eLQoRcBj5GRaNiGRrxEgCnM1Y7IwFe\n"" +
        ""yG/nrEu11DASIdHXCXhS99Tx4SCWhLpkBM6m1VQ+LrAm/ppZRr+CSpJzBLaq9C5R\n"" +
        ""QYviDSu5Ow2jP+ZFZWiorlfcMLbrTRu2sfSnmkOrEpkkTh6jxTFCONcWYP8GU93D\n"" +
        ""YCA3hSH0li7CueS+GYJ1JB2Cd7buu+tOhl36AhBD96miExlgNn0YGpTJJ3I0Hb+O\n"" +
        ""lKIIQy+KK8f9TXrSeZC3OYlTtJaIr9ejspTXxIYN11EIit5MFEwnnkCglcsePjsx\n"" +
        ""qeOFRumJ5Nj5H8qyCNZ5MtzwbLkyktJzlumvnyr+AQKBgQDv/QfGKZJFeoCEWpoj\n"" +
        ""f+078JxSYyPVNXxbbr2NuN/V79hJBol87ukycz2CZkDCubIKfubc50eXDmhWCp4p\n"" +
        ""aJgl6BMhnovftYrIrGWJLwqXnwFwsKJSrJJqHlHDJDRGfUSQEWNclNeaB3Mr8W46\n"" +
        ""Zcaadeikstvka9xKA1LOCG3oIQKBgQDj2FFOxZK27KhY/9Oz1dUsPtAYYbLOor/P\n"" +
        ""Rbne3jICQStH3dnUEmWKIKrdYV1u2saw5djn3ujwB0xEXydRvRgiSF0qxYjbm9CG\n"" +
        ""TJaiHhTsQDjWkYMZaxk3gc7Yfh8DHF0wlvWpu1wMXNsCJ6jxqW2e+jSRioZICPK6\n"" +
        ""McWWmArd6QKBgDWjoHEyKXdOAhuTBJCarzOOe+IONpwY8EqfXc6nW6A9k2H/DAvY\n"" +
        ""elbEWyMiJ6deSeT+qCsHpoCkv707ck5fCmKulFgXT7wYn4Rqw+b9lKh+6Zt+X0mL\n"" +
        ""OM5vKGctWGHI7eIlgMfYnLfYom1X8QMsbE9puy3UrEFJulrwkzlpuOcBAoGAVRNV\n"" +
        ""sNsXIFSXu7uyueizU3UU0LXSRVQB2QxJDg3bkHnzBj+xcX15Cq2N/2G2uIjaPf1l\n"" +
        ""E5dpVQ70jGcXUG8SDuMEXs8pfg7dOvhoGpqu51RHpN7qm9ggr1g5+x6Ex+2UYmtL\n"" +
        ""yZfbFAasBE74x1ujQgRdEqct4sHsmFezVrro+9kCgYEAgl70mKk9yK/f7515OaO0\n"" +
        ""Y39tgVzpAG6RN1NKnY6NR5VNNemZx5jhKfk5byaYxX4XBjygD0sQ5KTpaZmoQIIX\n"" +
        ""FxuwhLRRMn6vtsEf1HexJAtRd82aL5wKS62l0AXG/CVLAygn4aSSqLrgTyFFVUR3\n"" +
        ""cASPpPIdZaKZG6q4Hmcpl58=\n"" +
        ""-----END PRIVATE KEY-----"");
    }
    final File tmpCertFile = tmpFolder.newFile(""validCert.pem"");
    try (final FileWriter tmpCertWriter = new FileWriter(tmpCertFile)) {
      tmpCertWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICwTCCAamgAwIBAgIEBeVm4jANBgkqhkiG9w0BAQsFADARMQ8wDQYDVQQDEwZj\n"" +
        ""bGllbnQwHhcNMTgwNTI2MTEzNjUxWhcNMjEwNTI1MTEzNjUxWjARMQ8wDQYDVQQD\n"" +
        ""EwZjbGllbnQwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDVmCecLdUZ\n"" +
        ""U917hweVz4JqvZ9vZEi1rH+BG98HYfRR/h3QaobxPImZu3hzKHZ+MPbm94HunLPA\n"" +
        ""VA9yZhvZMToNfOuD4TUPBPloBuNzwBfZk2O4CaXeG4ailVWUfm5t/l+RD/55zYKu\n"" +
        ""hw1/Vl9lcOryF2XAmPQ2F1gwEKK7wt1Ak8zw8/yeYgBv1/F+ibCMvR6FVj9ABBEf\n"" +
        ""TM+oOs4oy51otUv0h63GqYgXMJyLX7q+AGWdC3srwwLQROtkzi7y00g/YryXUoIq\n"" +
        ""dXEI7CrNL35rZXcZ5LfGRwFX9evX11PpT3OShYlsJBcFE9KMatRoIWd6xUKlxTk0\n"" +
        ""yLjoOUE2tsMJAgMBAAGjITAfMB0GA1UdDgQWBBQ6xJBQsJCJdj/u0iTLYYD2qQsB\n"" +
        ""DDANBgkqhkiG9w0BAQsFAAOCAQEAfoquV375+eAGmfnlLxB30v9VhsFckrxFVpYs\n"" +
        ""XXC6h2G8MtXLpIEpgJo+4SZ4YjNwf/8m9J5j/duU8RukYanyzJdgkFFqKDBYCX7U\n"" +
        ""SD1nQP7729KnQgxtbR/+i3zkNgo7FATdkLq+HOxklNOEE24Ldenya39bsG779B9n\n"" +
        ""Sskcbq++7rMM+onDYBv6PbUKCm6nfqPspq809CLxSaUJg9+9ykut6hiyke/i7GEP\n"" +
        ""XIZHrM+mEvG00ES/zBIdV6TE0AIBP7q2MN7ylT509Ko9sUBMOZdEzikYp5GaRdiv\n"" +
        ""zG9q6rqK5COK614BwJFOD1DKV1BoDFsgugvfvm/mrc3QfIUPDA==\n"" +
        ""-----END CERTIFICATE-----"");
    }
    final JsonObject withSSLAndCertKeyPath = new JsonObject()
      .put(""ssl"", true)
      .put(""keyPath"", tmpKeyFile.getAbsolutePath())
      .put(""certPath"", tmpCertFile.getAbsolutePath());

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndCertKeyPath)
      .settings()
      .getSslSettings();

    // then
    assertNotNull(sslSettings.getContext());
  }
",non-flaky,5
98100,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.testInvalidKey,"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidKey() throws IOException {
    // given
    final File tmpKeyFile = tmpFolder.newFile(""brokenKey.pem"");
    try (final FileWriter tmpKeyWriter = new FileWriter(tmpKeyFile)) {
      tmpKeyWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICljCCAfigAwIBAgI...BROKEN...xsykBBTOIVXnYdPkdZvvnoAIcfA7iM\n"" +
        ""-----END CERTIFICATE-----"");
    }
    final File tmpCertFile = tmpFolder.newFile(""validCert.pem"");
    try (final FileWriter tmpCertWriter = new FileWriter(tmpCertFile)) {
      tmpCertWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICwTCCAamgAwIBAgIEBeVm4jANBgkqhkiG9w0BAQsFADARMQ8wDQYDVQQDEwZj\n"" +
        ""bGllbnQwHhcNMTgwNTI2MTEzNjUxWhcNMjEwNTI1MTEzNjUxWjARMQ8wDQYDVQQD\n"" +
        ""EwZjbGllbnQwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDVmCecLdUZ\n"" +
        ""U917hweVz4JqvZ9vZEi1rH+BG98HYfRR/h3QaobxPImZu3hzKHZ+MPbm94HunLPA\n"" +
        ""VA9yZhvZMToNfOuD4TUPBPloBuNzwBfZk2O4CaXeG4ailVWUfm5t/l+RD/55zYKu\n"" +
        ""hw1/Vl9lcOryF2XAmPQ2F1gwEKK7wt1Ak8zw8/yeYgBv1/F+ibCMvR6FVj9ABBEf\n"" +
        ""TM+oOs4oy51otUv0h63GqYgXMJyLX7q+AGWdC3srwwLQROtkzi7y00g/YryXUoIq\n"" +
        ""dXEI7CrNL35rZXcZ5LfGRwFX9evX11PpT3OShYlsJBcFE9KMatRoIWd6xUKlxTk0\n"" +
        ""yLjoOUE2tsMJAgMBAAGjITAfMB0GA1UdDgQWBBQ6xJBQsJCJdj/u0iTLYYD2qQsB\n"" +
        ""DDANBgkqhkiG9w0BAQsFAAOCAQEAfoquV375+eAGmfnlLxB30v9VhsFckrxFVpYs\n"" +
        ""XXC6h2G8MtXLpIEpgJo+4SZ4YjNwf/8m9J5j/duU8RukYanyzJdgkFFqKDBYCX7U\n"" +
        ""SD1nQP7729KnQgxtbR/+i3zkNgo7FATdkLq+HOxklNOEE24Ldenya39bsG779B9n\n"" +
        ""Sskcbq++7rMM+onDYBv6PbUKCm6nfqPspq809CLxSaUJg9+9ykut6hiyke/i7GEP\n"" +
        ""XIZHrM+mEvG00ES/zBIdV6TE0AIBP7q2MN7ylT509Ko9sUBMOZdEzikYp5GaRdiv\n"" +
        ""zG9q6rqK5COK614BwJFOD1DKV1BoDFsgugvfvm/mrc3QfIUPDA==\n"" +
        ""-----END CERTIFICATE-----"");
    }
    final JsonObject withSSLAndCertKeyPath = new JsonObject()
      .put(""ssl"", true)
      .put(""keyPath"", tmpKeyFile.getAbsolutePath())
      .put(""certPath"", tmpCertFile.getAbsolutePath());

    // then
    new MongoClientOptionsParser(vertx, withSSLAndCertKeyPath);
  }
",non-flaky,5
98101,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.testInvalidCertificate,"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidCertificate() throws IOException {
    // given
    final File tmpKeyFile = tmpFolder.newFile(""validKey.pem"");
    try (final FileWriter tmpKeyWriter = new FileWriter(tmpKeyFile)) {
      tmpKeyWriter.write(""-----BEGIN PRIVATE KEY-----\n"" +
        ""MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDVmCecLdUZU917\n"" +
        ""hweVz4JqvZ9vZEi1rH+BG98HYfRR/h3QaobxPImZu3hzKHZ+MPbm94HunLPAVA9y\n"" +
        ""ZhvZMToNfOuD4TUPBPloBuNzwBfZk2O4CaXeG4ailVWUfm5t/l+RD/55zYKuhw1/\n"" +
        ""Vl9lcOryF2XAmPQ2F1gwEKK7wt1Ak8zw8/yeYgBv1/F+ibCMvR6FVj9ABBEfTM+o\n"" +
        ""Os4oy51otUv0h63GqYgXMJyLX7q+AGWdC3srwwLQROtkzi7y00g/YryXUoIqdXEI\n"" +
        ""7CrNL35rZXcZ5LfGRwFX9evX11PpT3OShYlsJBcFE9KMatRoIWd6xUKlxTk0yLjo\n"" +
        ""OUE2tsMJAgMBAAECggEAdewZAjqzidYpU0eLQoRcBj5GRaNiGRrxEgCnM1Y7IwFe\n"" +
        ""yG/nrEu11DASIdHXCXhS99Tx4SCWhLpkBM6m1VQ+LrAm/ppZRr+CSpJzBLaq9C5R\n"" +
        ""QYviDSu5Ow2jP+ZFZWiorlfcMLbrTRu2sfSnmkOrEpkkTh6jxTFCONcWYP8GU93D\n"" +
        ""YCA3hSH0li7CueS+GYJ1JB2Cd7buu+tOhl36AhBD96miExlgNn0YGpTJJ3I0Hb+O\n"" +
        ""lKIIQy+KK8f9TXrSeZC3OYlTtJaIr9ejspTXxIYN11EIit5MFEwnnkCglcsePjsx\n"" +
        ""qeOFRumJ5Nj5H8qyCNZ5MtzwbLkyktJzlumvnyr+AQKBgQDv/QfGKZJFeoCEWpoj\n"" +
        ""f+078JxSYyPVNXxbbr2NuN/V79hJBol87ukycz2CZkDCubIKfubc50eXDmhWCp4p\n"" +
        ""aJgl6BMhnovftYrIrGWJLwqXnwFwsKJSrJJqHlHDJDRGfUSQEWNclNeaB3Mr8W46\n"" +
        ""Zcaadeikstvka9xKA1LOCG3oIQKBgQDj2FFOxZK27KhY/9Oz1dUsPtAYYbLOor/P\n"" +
        ""Rbne3jICQStH3dnUEmWKIKrdYV1u2saw5djn3ujwB0xEXydRvRgiSF0qxYjbm9CG\n"" +
        ""TJaiHhTsQDjWkYMZaxk3gc7Yfh8DHF0wlvWpu1wMXNsCJ6jxqW2e+jSRioZICPK6\n"" +
        ""McWWmArd6QKBgDWjoHEyKXdOAhuTBJCarzOOe+IONpwY8EqfXc6nW6A9k2H/DAvY\n"" +
        ""elbEWyMiJ6deSeT+qCsHpoCkv707ck5fCmKulFgXT7wYn4Rqw+b9lKh+6Zt+X0mL\n"" +
        ""OM5vKGctWGHI7eIlgMfYnLfYom1X8QMsbE9puy3UrEFJulrwkzlpuOcBAoGAVRNV\n"" +
        ""sNsXIFSXu7uyueizU3UU0LXSRVQB2QxJDg3bkHnzBj+xcX15Cq2N/2G2uIjaPf1l\n"" +
        ""E5dpVQ70jGcXUG8SDuMEXs8pfg7dOvhoGpqu51RHpN7qm9ggr1g5+x6Ex+2UYmtL\n"" +
        ""yZfbFAasBE74x1ujQgRdEqct4sHsmFezVrro+9kCgYEAgl70mKk9yK/f7515OaO0\n"" +
        ""Y39tgVzpAG6RN1NKnY6NR5VNNemZx5jhKfk5byaYxX4XBjygD0sQ5KTpaZmoQIIX\n"" +
        ""FxuwhLRRMn6vtsEf1HexJAtRd82aL5wKS62l0AXG/CVLAygn4aSSqLrgTyFFVUR3\n"" +
        ""cASPpPIdZaKZG6q4Hmcpl58=\n"" +
        ""-----END PRIVATE KEY-----"");
    }
    final File tmpCertFile = tmpFolder.newFile(""brokenCert.pem"");
    try (final FileWriter tmpCertWriter = new FileWriter(tmpCertFile)) {
      tmpCertWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICwTCCAamgAwIBA...BROKEN...FOD1DKV1BoDFsgugvfvm/mrc3QfIUPDA==\n"" +
        ""-----END CERTIFICATE-----"");
    }
    final JsonObject withSSLAndCertKeyPath = new JsonObject()
      .put(""ssl"", true)
      .put(""keyPath"", tmpKeyFile.getAbsolutePath())
      .put(""certPath"", tmpCertFile.getAbsolutePath());

    // then
    new MongoClientOptionsParser(vertx, withSSLAndCertKeyPath);
  }
",non-flaky,5
98102,vert-x3_vertx-mongo-client,SocketSettingsParserTest.testSocketSettings,"  @Test
  public void testSocketSettings() {
    int connectTimeoutMS = Math.abs(TestUtils.randomInt());
    int socketTimeoutMS = Math.abs(TestUtils.randomInt());
    int receiveBufferSize = Math.abs(TestUtils.randomInt());
    int sendBufferSize = Math.abs(TestUtils.randomInt());

    JsonObject config = new JsonObject();
    config.put(""connectTimeoutMS"", connectTimeoutMS);
    config.put(""socketTimeoutMS"", socketTimeoutMS);
    config.put(""receiveBufferSize"", receiveBufferSize);
    config.put(""sendBufferSize"", sendBufferSize);

    SocketSettings settings = new SocketSettingsParser(null, config).settings();
    assertEquals(connectTimeoutMS, settings.getConnectTimeout(TimeUnit.MILLISECONDS));
    assertEquals(socketTimeoutMS, settings.getReadTimeout(TimeUnit.MILLISECONDS));
    assertEquals(receiveBufferSize, settings.getReceiveBufferSize());
    assertEquals(sendBufferSize, settings.getSendBufferSize());
  }
",non-flaky,5
98103,vert-x3_vertx-mongo-client,ParsingStreamTypeTest.should_not_include_any_stream_type_by_default_for_backwards_compatibility,"  @Test
  public void should_not_include_any_stream_type_by_default_for_backwards_compatibility() {
    // given
    final JsonObject noStreamTypeProvided = new JsonObject().put(
      ""connection_string"", ""mongodb://localhost:27017/mydb?replicaSet=myRs""
    );

    // when
    final MongoClientSettings parsedSettings = new MongoClientOptionsParser(vertx, noStreamTypeProvided).settings();

    // then
    assertNull(parsedSettings.getStreamFactoryFactory());
  }
",non-flaky,5
98104,vert-x3_vertx-mongo-client,ParsingStreamTypeTest.should_parse_stream_type_from_config_property,"  @Test
  public void should_parse_stream_type_from_config_property(String streamTypeString, Class<StreamFactoryFactory> streamType) {
    // given
    final JsonObject cfgWithStreamTypeProvided = new JsonObject().put(""streamType"", streamTypeString);

    // when
    final MongoClientSettings parsedSettings = new MongoClientOptionsParser(vertx, cfgWithStreamTypeProvided).settings();

    // then
    assertThat(parsedSettings.getStreamFactoryFactory(), instanceOf(streamType));
  }
",non-flaky,5
98105,vert-x3_vertx-mongo-client,ParsingStreamTypeTest.only_valid_stream_type_values_allowed_as_config_property,"  @Test(expected = IllegalArgumentException.class)
  public void only_valid_stream_type_values_allowed_as_config_property() {
    // given
    final JsonObject withInvalidStreamType = new JsonObject().put(""streamType"", ""unrecognized"");

    // expect thrown
    new MongoClientOptionsParser(vertx, withInvalidStreamType).settings();
  }
",non-flaky,5
98106,vert-x3_vertx-mongo-client,CredentialListParserTest.testConnectionString,"  @Test
  public void testConnectionString() {
    String username = TestUtils.randomAlphaString(8);
    String password = TestUtils.randomAlphaString(20);

    ConnectionString connectionString = new ConnectionString(
      String.format(
        ""mongodb://%s:%s@%s/%s"",
        username,
        password,
        ""localhost:27017"",
        ""my-datasource""));

    List<MongoCredential> credentials = new CredentialListParser(connectionString, null).credentials();
    assertEquals(1, credentials.size());
    MongoCredential credential = credentials.get(0);
    assertEquals(username, credential.getUserName());
    assertArrayEquals(password.toCharArray(), credential.getPassword());
    assertEquals(""my-datasource"", credential.getSource());
  }
",non-flaky,5
98107,vert-x3_vertx-mongo-client,CredentialListParserTest.testSimpleAuth,"  @Test
  public void testSimpleAuth() {
    JsonObject config = new JsonObject().put(""db_name"", ""my-datasource"");
    String username = TestUtils.randomAlphaString(8);
    String password = TestUtils.randomAlphaString(20);
    config.put(""username"", username);
    config.put(""password"", password);


    List<MongoCredential> credentials = new CredentialListParser(null, config).credentials();
    assertEquals(1, credentials.size());
    MongoCredential credential = credentials.get(0);
    assertEquals(username, credential.getUserName());
    assertArrayEquals(password.toCharArray(), credential.getPassword());
    // default source should be the database name - see https://github.com/vert-x3/vertx-mongo-client/issues/46.
    assertEquals(""my-datasource"", credential.getSource());
  }
",non-flaky,5
98108,vert-x3_vertx-mongo-client,CredentialListParserTest.testSimpleAuthWithSource,"  @Test
  public void testSimpleAuthWithSource() {
    JsonObject config = new JsonObject();
    String username = TestUtils.randomAlphaString(8);
    String password = TestUtils.randomAlphaString(20);
    String authSource = TestUtils.randomAlphaString(10);
    config.put(""username"", username);
    config.put(""password"", password);
    config.put(""authSource"", authSource);

    List<MongoCredential> credentials = new CredentialListParser(null, config).credentials();
    assertEquals(1, credentials.size());
    MongoCredential credential = credentials.get(0);
    assertEquals(username, credential.getUserName());
    assertArrayEquals(password.toCharArray(), credential.getPassword());
    assertEquals(authSource, credential.getSource());
  }
",non-flaky,5
98109,vert-x3_vertx-mongo-client,CredentialListParserTest.testAuth_GSSAPI,"  @Test
  public void testAuth_GSSAPI() {
    JsonObject config = new JsonObject();
    String username = TestUtils.randomAlphaString(8);
    String authSource = TestUtils.randomAlphaString(10);
    config.put(""username"", username);
    config.put(""authSource"", authSource);
    config.put(""authMechanism"", ""GSSAPI"");

    List<MongoCredential> credentials = new CredentialListParser(null, config).credentials();
    assertEquals(1, credentials.size());
    MongoCredential credential = credentials.get(0);
    assertEquals(username, credential.getUserName());
    assertNotEquals(authSource, credential.getSource()); // It should ignore the source we pass in

    assertEquals(AuthenticationMechanism.GSSAPI, credential.getAuthenticationMechanism());
  }
",non-flaky,5
98256,spotify_docker-client,PushPullIT.testPushImageToPrivateAuthedRegistryWithoutAuth,"  @Test
  public void testPushImageToPrivateAuthedRegistryWithoutAuth() throws Exception {
    registryContainerId = startAuthedRegistry(client);

    // Make a DockerClient without RegistryAuth
    final DefaultDockerClient client = DefaultDockerClient.fromEnv().build();

    // Push an image to the private registry and check it fails
    final String dockerDirectory = Resources.getResource(""dockerDirectory"").getPath();
    client.build(Paths.get(dockerDirectory), LOCAL_IMAGE);

    exception.expect(ImagePushFailedException.class);
    client.push(LOCAL_IMAGE);
  }
",non-flaky,5
98257,spotify_docker-client,PushPullIT.testPushImageToPrivateAuthedRegistryWithAuth,"  @Test
  public void testPushImageToPrivateAuthedRegistryWithAuth() throws Exception {
    registryContainerId = startAuthedRegistry(client);

    // Push an image to the private registry and check it succeeds
    final String dockerDirectory = Resources.getResource(""dockerDirectory"").getPath();
    client.build(Paths.get(dockerDirectory), LOCAL_IMAGE);
    client.tag(LOCAL_IMAGE, LOCAL_IMAGE_2);
    client.push(LOCAL_IMAGE);

    // Push the same image again under a different user
    final RegistryAuth registryAuth = RegistryAuth.builder()
        .username(LOCAL_AUTH_USERNAME_2)
        .password(LOCAL_AUTH_PASSWORD_2)
        .build();
    client.push(LOCAL_IMAGE_2, registryAuth);

    // We should be able to pull it again
    client.pull(LOCAL_IMAGE);
    client.pull(LOCAL_IMAGE_2);
  }
",non-flaky,5
98258,spotify_docker-client,PushPullIT.testPushImageToPrivateUnauthedRegistryWithoutAuth,"  @Test
  public void testPushImageToPrivateUnauthedRegistryWithoutAuth() throws Exception {
    registryContainerId = startUnauthedRegistry(client);

    // Make a DockerClient without RegistryAuth
    final DefaultDockerClient client = DefaultDockerClient.fromEnv().build();

    // Push an image to the private registry and check it succeeds
    final String dockerDirectory = Resources.getResource(""dockerDirectory"").getPath();
    client.build(Paths.get(dockerDirectory), LOCAL_IMAGE);
    client.push(LOCAL_IMAGE);
    // We should be able to pull it again
    client.pull(LOCAL_IMAGE);
  }
",non-flaky,5
98259,spotify_docker-client,PushPullIT.testPushImageToPrivateUnauthedRegistryWithAuth,"  @Test
  public void testPushImageToPrivateUnauthedRegistryWithAuth() throws Exception {
    registryContainerId = startUnauthedRegistry(client);

    // Push an image to the private registry and check it succeeds
    final String dockerDirectory = Resources.getResource(""dockerDirectory"").getPath();
    client.build(Paths.get(dockerDirectory), LOCAL_IMAGE);
    client.push(LOCAL_IMAGE);
    // We should be able to pull it again
    client.pull(LOCAL_IMAGE);
  }
",non-flaky,5
98260,spotify_docker-client,PushPullIT.testPushHubPublicImageWithAuth,"  @Test
  public void testPushHubPublicImageWithAuth() throws Exception {
    // Push an image to a public repo on Docker Hub and check it succeeds
    final String dockerDirectory = Resources.getResource(""dockerDirectory"").getPath();
    final DockerClient client = DefaultDockerClient
        .fromEnv()
        .registryAuth(RegistryAuth.builder()
                        .username(HUB_AUTH_USERNAME)
                        .password(HUB_AUTH_PASSWORD)
                        .build())
        .build();

    client.build(Paths.get(dockerDirectory), HUB_PUBLIC_IMAGE);
    client.push(HUB_PUBLIC_IMAGE);
  }
",non-flaky,5
98261,spotify_docker-client,PushPullIT.testPushHubPrivateImageWithAuth,"  @Test
  public void testPushHubPrivateImageWithAuth() throws Exception {
    // Push an image to a private repo on Docker Hub and check it succeeds
    final String dockerDirectory = Resources.getResource(""dockerDirectory"").getPath();
    final DockerClient client = DefaultDockerClient
        .fromEnv()
        .registryAuth(RegistryAuth.builder()
                        .username(HUB_AUTH_USERNAME)
                        .password(HUB_AUTH_PASSWORD)
                        .build())
        .build();

    client.build(Paths.get(dockerDirectory), HUB_PRIVATE_IMAGE);
    client.push(HUB_PRIVATE_IMAGE);
  }
",non-flaky,5
98262,spotify_docker-client,PushPullIT.testPullHubPrivateRepoWithBadAuth,"  @Test
  public void testPullHubPrivateRepoWithBadAuth() throws Exception {
    final RegistryAuth badRegistryAuth = RegistryAuth.builder()
        .username(HUB_AUTH_USERNAME2)
        .password(""foobar"")
        .build();
    exception.expect(DockerException.class);
    exception.expectCause(isA(NotAuthorizedException.class));
    client.pull(CIRROS_PRIVATE_LATEST, badRegistryAuth);
  }
",non-flaky,5
98263,spotify_docker-client,PushPullIT.testBuildHubPrivateRepoWithAuth,"  @Test
  public void testBuildHubPrivateRepoWithAuth() throws Exception {
    final String dockerDirectory = Resources.getResource(""dockerDirectoryNeedsAuth"").getPath();
    final RegistryAuth registryAuth = RegistryAuth.builder()
        .username(HUB_AUTH_USERNAME2)
        .password(HUB_AUTH_PASSWORD2)
        .build();

    final DefaultDockerClient client = DefaultDockerClient.fromEnv()
        .registryAuth(registryAuth)
        .build();

    client.build(Paths.get(dockerDirectory), ""testauth"", BuildParam.pullNewerImage());
  }
",non-flaky,5
98264,spotify_docker-client,PushPullIT.testPullHubPrivateRepoWithAuth,"  @Test
  public void testPullHubPrivateRepoWithAuth() throws Exception {
    final RegistryAuth registryAuth = RegistryAuth.builder()
        .username(HUB_AUTH_USERNAME2)
        .password(HUB_AUTH_PASSWORD2)
        .build();
    client.pull(""dxia2/scratch-private:latest"", registryAuth);
  }
",non-flaky,5
98265,spotify_docker-client,ContainerStatsTest.test1_26,"  @Test
  public void test1_26() throws Exception {
    objectMapper.readValue(fixture(""fixtures/1.26/containerStats.json""), ContainerStats.class);
  }
",non-flaky,5
98266,spotify_docker-client,ContainerStateTest.testLoadFromRandomFixture,"  @Test
  public void testLoadFromRandomFixture() throws Exception {
    final ContainerState containerState = objectMapper
        .readValue(fixture(""fixtures/container-state-random.json""), ContainerState.class);
    assertThat(containerState.paused(), is(false));
    assertThat(containerState.restarting(), is(false));
    assertThat(containerState.running(), is(true));
    assertThat(containerState.exitCode(), is(0));
    assertThat(containerState.pid(), is(27629));
    assertThat(containerState.startedAt(), is(new Date(1412236798929L)));
    assertThat(containerState.finishedAt(), is(new Date(-62135769600000L)));
    assertThat(containerState.error(), is(""this is an error""));
    assertThat(containerState.oomKilled(), is(false));
    assertThat(containerState.status(), is(""running""));
    
    ContainerState.Health health = containerState.health();
    assertThat(health.failingStreak(), is(1));
    assertThat(health.status(), is(""starting""));
    assertThat(health.log().size(), is(1));
    
    ContainerState.HealthLog log = health.log().get(0);
    assertThat(log.start(), is(new Date(1412236801547L)));
    assertThat(log.end(), is(new Date(1412236802697L)));
    assertThat(log.exitCode(), is(1));
    assertThat(log.output(), is(""output""));
  }
",non-flaky,5
98267,spotify_docker-client,ContainerStateTest.testLoadFromRandomFixtureMissingProperty,"  @Test
  public void testLoadFromRandomFixtureMissingProperty() throws Exception {
    objectMapper.readValue(fixture(""fixtures/container-state-missing-property.json""),
                           ContainerState.class);
  }
",non-flaky,5
98268,spotify_docker-client,ContainerStateTest.testLoadInvalidConatainerStateJson,"  @Test
  public void testLoadInvalidConatainerStateJson() throws Exception {
    expectedException.expect(JsonMappingException.class);
    objectMapper.readValue(fixture(""fixtures/container-state-invalid.json""), ContainerState.class);

  }
",non-flaky,5
98269,spotify_docker-client,ContainerStateTest.testLoadInvalidJson,"  @Test
  public void testLoadInvalidJson() throws Exception {
    expectedException.expect(JsonParseException.class);
    objectMapper.readValue(fixture(""fixtures/invalid.json""), ContainerState.class);

  }
",non-flaky,5
98270,spotify_docker-client,ContainerInfoTest.test1_22,"  @Test
  public void test1_22() throws Exception {
    objectMapper.readValue(fixture(""fixtures/1.22/containerInfo.json""), ContainerInfo.class);
  }
",non-flaky,5
98271,spotify_docker-client,ContainerInfoTest.test1_24,"  @Test
  public void test1_24() throws Exception {
    objectMapper.readValue(fixture(""fixtures/1.24/containerInfo.json""), ContainerInfo.class);
  }
",non-flaky,5
98272,spotify_docker-client,HostConfigTest.testJsonAlways,"  @Test
  public void testJsonAlways() throws Exception {
    final HostConfig hostConfig = objectMapper
        .readValue(fixture(""fixtures/hostConfig/restartPolicyAlways.json""),
                   HostConfig.class);
    assertThat(hostConfig.restartPolicy(), is(HostConfig.RestartPolicy.always()));
  }
",non-flaky,5
98273,spotify_docker-client,HostConfigTest.testJsonUnlessStopped,"  @Test
  public void testJsonUnlessStopped() throws Exception {
    final HostConfig hostConfig = objectMapper
        .readValue(fixture(""fixtures/hostConfig/restartPolicyUnlessStopped.json""),
                   HostConfig.class);
    assertThat(hostConfig.restartPolicy(), is(HostConfig.RestartPolicy.unlessStopped()));
  }
",non-flaky,5
98274,spotify_docker-client,HostConfigTest.testJsonOnFailure,"  @Test
  public void testJsonOnFailure() throws Exception {
    final HostConfig hostConfig = objectMapper
        .readValue(fixture(""fixtures/hostConfig/restartPolicyOnFailure.json""),
                   HostConfig.class);
    assertThat(hostConfig.restartPolicy(), is(HostConfig.RestartPolicy.onFailure(5)));
  }
",non-flaky,5
98275,spotify_docker-client,HostConfigTest.testReplaceBinds,"  @Test
  public void testReplaceBinds() {
    final List<String> initialBinds = ImmutableList.of(""/one:/one"", ""/two:/two"");
    final HostConfig hostConfig = HostConfig.builder()
        .binds(initialBinds)
        .binds(initialBinds)
        .build();

    assertThat(""Calling .binds() multiple times should replace the list each time"",
               hostConfig.binds(), is(initialBinds));
  }
",non-flaky,5
98276,spotify_docker-client,HostConfigTest.testAppendBinds,"  @Test
  public void testAppendBinds() {
    final List<String> initialBinds = ImmutableList.of(""/one:/one"", ""/two:/two"");
    final HostConfig hostConfig = HostConfig.builder()
        .binds(initialBinds)
        .appendBinds(""/three:/three"")
        .appendBinds(""/four:/four"")
        .build();

    final List<String> expected = ImmutableList.<String>builder()
        .addAll(initialBinds)
        .add(""/three:/three"")
        .add(""/four:/four"")
        .build();

    assertThat(""Calling .appendBinds should append to the list, not replace"",
               hostConfig.binds(), is(expected));
  }
",non-flaky,5
98277,spotify_docker-client,HostConfigTest.testPreventDuplicateBinds,"  @Test
  public void testPreventDuplicateBinds() {
    final HostConfig hostConfig = HostConfig.builder()
        .appendBinds(""/one:/one"")
        .appendBinds(""/one:/one"")
        .appendBinds(""/one:/one"")
        .build();

    assertThat(hostConfig.binds(), contains(""/one:/one""));
  }
",non-flaky,5
98278,spotify_docker-client,ImageInfoTest.test1_24,"  @Test
  public void test1_24() throws Exception {
    objectMapper.readValue(fixture(""fixtures/1.24/imageInfo.json""), ImageInfo.class);
  }
",non-flaky,5
98279,spotify_docker-client,ProgressMessageTest.testNotADigest,"  @Test
  public void testNotADigest() throws Exception {
    assertNull(readMessage(""not-a-digest"").digest());
  }
",non-flaky,5
98280,spotify_docker-client,ProgressMessageTest.testDigest_Docker16,"  @Test
  public void testDigest_Docker16() throws Exception {
    assertEquals(digest, readMessage(""Digest: "" + digest).digest());
  }
",non-flaky,5
98281,spotify_docker-client,ProgressMessageTest.testDigest_Docker18,"  @Test
  public void testDigest_Docker18() throws Exception {
    final String status = ""some-image-tag: digest: "" + digest + "" size: 1234"";
    assertEquals(digest, readMessage(status).digest());
  }
",non-flaky,5
98282,spotify_docker-client,EventTest.serializationRoundTripTest,"  @Test
  public void serializationRoundTripTest() throws Exception {
    // Test serializing and deserializing the same Event instance works and preserves data
    final Event event = Event.create(""create"", ""foo"", ""nginx"", Event.Type.CONTAINER, ""create"",
        Event.Actor.create(""bar"", ImmutableMap.of(""image"", ""nginx"", ""name"", ""docker-nginx"")),
        new Date(1487356000), 100L);

    final ObjectMapper mapper = ObjectMapperProvider.objectMapper();

    final String json = mapper.writeValueAsString(event);

    final Event event2 = mapper.readValue(json, Event.class);
    assertThat(event, equalTo(event2));
  }
",non-flaky,5
98283,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_FullConfig,"  @Test
  public void testFromDockerConfig_FullConfig() throws Exception {
    final RegistryAuth registryAuth = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/fullConfig.json"")).build();
    assertThat(registryAuth, equalTo(DOCKER_AUTH_CONFIG));
  }
",non-flaky,5
98284,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_FullDockerCfg,"  @Test
  public void testFromDockerConfig_FullDockerCfg() throws Exception {
    final RegistryAuth registryAuth = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/fullDockerCfg"")).build();
    assertThat(registryAuth, equalTo(DOCKER_AUTH_CONFIG));
  }
",non-flaky,5
98285,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_IdentityToken,"  @Test
  public void testFromDockerConfig_IdentityToken() throws Exception {
    final RegistryAuth authConfig = RegistryAuth.fromDockerConfig(getTestFilePath(
            ""dockerConfig/identityTokenConfig.json"")).build();
    assertThat(authConfig, equalTo(IDENTITY_TOKEN_AUTH_CONFIG));
  }
",non-flaky,5
98286,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_IncompleteConfig,"  @Test
  public void testFromDockerConfig_IncompleteConfig() throws Exception {
    final RegistryAuth registryAuth = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/incompleteConfig.json"")).build();
    assertThat(registryAuth, equalTo(EMPTY_AUTH_CONFIG));
  }
",non-flaky,5
98287,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_WrongConfigs,"  @Test
  public void testFromDockerConfig_WrongConfigs() throws Exception {
    final RegistryAuth registryAuth1 = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/wrongConfig1.json"")).build();
    assertThat(registryAuth1, equalTo(EMPTY_AUTH_CONFIG));

    final RegistryAuth registryAuth2 = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/wrongConfig2.json"")).build();
    assertThat(registryAuth2, equalTo(EMPTY_AUTH_CONFIG));
  }
",non-flaky,5
98288,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_MissingConfigFile,"  @Test
  public void testFromDockerConfig_MissingConfigFile() throws Exception {
    final Path randomPath = Paths.get(RandomStringUtils.randomAlphanumeric(16) + "".json"");
    expectedException.expect(FileNotFoundException.class);
    RegistryAuth.fromDockerConfig(randomPath).build();
  }
",non-flaky,5
98289,spotify_docker-client,RegistryAuthTest.testFromDockerConfig_MultiConfig,"  @Test
  public void testFromDockerConfig_MultiConfig() throws Exception {
    final RegistryAuth myDockParsed = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/multiConfig.json""), ""https://narnia.mydock.io/v1/"").build();
    assertThat(myDockParsed, equalTo(MY_AUTH_CONFIG));
    final RegistryAuth dockerIoParsed = RegistryAuth.fromDockerConfig(getTestFilePath(
        ""dockerConfig/multiConfig.json""), ""https://index.docker.io/v1/"").build();
    assertThat(dockerIoParsed, equalTo(DOCKER_AUTH_CONFIG));
  }
",non-flaky,5
98290,spotify_docker-client,ContainerTest.testLoadFromFixture,"  @Test
  public void testLoadFromFixture() throws Exception {
    final Container container = objectMapper
        .readValue(fixture(""fixtures/container-ports-as-string.json""), Container.class);
    assertThat(container.portsAsString(), is(""0.0.0.0:80->88/tcp""));
  }
",non-flaky,5
98291,spotify_docker-client,ContainerTest.testLoadFromFixtureMissingPorts,"  @Test
  public void testLoadFromFixtureMissingPorts() throws Exception {
    final Container container = objectMapper
            .readValue(fixture(""fixtures/container-no-ports-or-names.json""), Container.class);
    assertThat(container.id(), is(""1009""));
  }
",non-flaky,5
98292,spotify_docker-client,DockerDateFormatTest.testHandlesMillisecondPrecision,"  @Test
  public void testHandlesMillisecondPrecision() throws Exception {
    assertThat(dockerDateFormat.parse(millisecondDateString), equalTo(expected));
  }
",non-flaky,5
98293,spotify_docker-client,DockerDateFormatTest.testHandlesNanosecondPrecision,"  @Test
  public void testHandlesNanosecondPrecision() throws Exception {
    assertThat(dockerDateFormat.parse(""2015-09-18T17:44:28.145855389Z""), equalTo(expected));
  }
",non-flaky,5
98294,spotify_docker-client,DockerDateFormatTest.testHandlesNanosecondWithLessThanNineDigits,"  @Test
  public void testHandlesNanosecondWithLessThanNineDigits() throws Exception {
    assertThat(dockerDateFormat.parse(""2015-09-18T17:44:28.1458553Z""), equalTo(expected));
  }
",non-flaky,5
98295,spotify_docker-client,DockerDateFormatTest.otherTimeZones,"  @Test
  public void otherTimeZones() throws Exception {
    final Date expected =
        new DateTime(2016, 6, 3, 6, 57, 17, 478, DateTimeZone.forOffsetHours(-4)).toDate();
    assertThat(dockerDateFormat.parse(""2016-06-03T06:57:17.4782869-04:00""), equalTo(expected));
  }
",non-flaky,5
98296,spotify_docker-client,CompressedDirectoryTest.testFile,"  @Test
  public void testFile() throws Exception {
    // note: Paths.get(someURL.toUri()) is the platform-neutral way to convert a URL to a Path
    final URL dockerDirectory = Resources.getResource(""dockerDirectory"");
    try (CompressedDirectory dir = CompressedDirectory.create(Paths.get(dockerDirectory.toURI()));
         BufferedInputStream fileIn = new BufferedInputStream(Files.newInputStream(dir.file()));
         GzipCompressorInputStream gzipIn = new GzipCompressorInputStream(fileIn);
         TarArchiveInputStream tarIn = new TarArchiveInputStream(gzipIn)) {

      final List<String> names = new ArrayList<>();
      TarArchiveEntry entry;
      while ((entry = tarIn.getNextTarEntry()) != null) {
        final String name = entry.getName();
        names.add(name);
      }
      assertThat(names,
                 containsInAnyOrder(""Dockerfile"", ""bin/"", ""bin/date.sh"",
                                    ""innerDir/"", ""innerDir/innerDockerfile""));
    }
  }
",non-flaky,5
98297,spotify_docker-client,CompressedDirectoryTest.testFileWithIgnore,"  @Test
  public void testFileWithIgnore() throws Exception {
    // note: Paths.get(someURL.toUri()) is the platform-neutral way to convert a URL to a Path
    final URL dockerDirectory = Resources.getResource(""dockerDirectoryWithIgnore"");
    try (CompressedDirectory dir = CompressedDirectory.create(Paths.get(dockerDirectory.toURI()));
         BufferedInputStream fileIn = new BufferedInputStream(Files.newInputStream(dir.file()));
         GzipCompressorInputStream gzipIn = new GzipCompressorInputStream(fileIn);
         TarArchiveInputStream tarIn = new TarArchiveInputStream(gzipIn)) {

      final List<String> names = new ArrayList<>();
      TarArchiveEntry entry;
      while ((entry = tarIn.getNextTarEntry()) != null) {
        final String name = entry.getName();
        names.add(name);
      }
      assertThat(names, containsInAnyOrder(""Dockerfile"", ""bin/"", ""bin/date.sh"", ""subdir2/"",
                                           ""subdir2/keep.me"", ""subdir2/do-not.ignore"",
                                           ""subdir3/do.keep"", "".dockerignore""));
    }
  }
",non-flaky,5
98298,spotify_docker-client,CompressedDirectoryTest.testFileWithEmptyDirectory,"  @Test
  public void testFileWithEmptyDirectory() throws Exception {
    Path tempDir = Files.createTempDirectory(""dockerDirectoryEmptySubdirectory"");
    tempDir.toFile().deleteOnExit();
    assertThat(new File(tempDir.toFile(), ""emptySubDir"").mkdir(), is(true));

    try (CompressedDirectory dir = CompressedDirectory.create(tempDir);
         BufferedInputStream fileIn = new BufferedInputStream(Files.newInputStream(dir.file()));
         GzipCompressorInputStream gzipIn = new GzipCompressorInputStream(fileIn);
         TarArchiveInputStream tarIn = new TarArchiveInputStream(gzipIn)) {

      final List<String> names = new ArrayList<>();
      TarArchiveEntry entry;
      while ((entry = tarIn.getNextTarEntry()) != null) {
        final String name = entry.getName();
        names.add(name);
      }
      assertThat(names, contains(""emptySubDir/""));
    }
  }
",non-flaky,5
98299,spotify_docker-client,UnixTimestampDeserializerTest.testFromString,"  @Test
  public void testFromString() throws Exception {
    final String json = toJson(""{\""date\"": \""%s\""}"");

    final TestClass value = OBJECT_MAPPER.readValue(json, TestClass.class);
    assertThat(value.getDate(), equalTo(referenceDateTime.toDate()));
  }
",non-flaky,5
98300,spotify_docker-client,UnixTimestampDeserializerTest.testFromNumber,"  @Test
  public void testFromNumber() throws Exception {
    final String json = toJson(""{\""date\"": %s}"");

    final TestClass value = OBJECT_MAPPER.readValue(json, TestClass.class);
    assertThat(value.getDate(), equalTo(referenceDateTime.toDate()));
  }
",non-flaky,5
98301,spotify_docker-client,UnixTimestampSerializerTest.testToString,"  @Test
  public void testToString() throws Exception {
    final long timestamp = 1487357474682L;
    final String expectedJson = ""{\""date\"":1487357474}"";
    final TestClass testClass = new TestClass(new Date(timestamp));

    final String json = OBJECT_MAPPER.writeValueAsString(testClass);
    assertThat(json, equalTo(expectedJson));
  }
",non-flaky,5
98302,spotify_docker-client,DefaultLogStreamTest.testAttach,"  @Test
  public void testAttach() throws Exception {
    when(reader.nextMessage()).thenReturn(
        logMessage(LogMessage.Stream.STDOUT, ""hello\n""),
        logMessage(LogMessage.Stream.STDERR, ""oops\n""),
        logMessage(LogMessage.Stream.STDOUT, ""world!\n""),
        // need to return null to signal end of stream
        null
    );

    final ByteArrayOutputStream stdout = new ByteArrayOutputStream();
    final ByteArrayOutputStream stderr = new ByteArrayOutputStream();
    logStream.attach(stdout, stderr);

    assertThat(stdout.toString(), is(""hello\nworld!\n""));
    assertThat(stderr.toString(), is(""oops\n""));
  }
",non-flaky,5
98303,spotify_docker-client,DockerRequestExceptionTest.testExceptionMessageWithResponseBody,"  @Test
  public void testExceptionMessageWithResponseBody() {
    final URI uri = URI.create(""http://example.com"");
    final String responseBody = ""uh oh"";
    final DockerRequestException ex =
        new DockerRequestException(""GET"", uri, 500, responseBody, new RuntimeException());

    assertEquals(ex.getMessage(), ""Request error: GET http://example.com: 500, body: uh oh"");
  }
",non-flaky,5
98304,spotify_docker-client,DockerRequestExceptionTest.testExceptionMessageWhenNoResponseBody,"  @Test
  public void testExceptionMessageWhenNoResponseBody() {
    final URI uri = URI.create(""http://example.com"");
    final String responseBody = null;
    final DockerRequestException ex =
        new DockerRequestException(""GET"", uri, 500, responseBody, new RuntimeException());

    assertEquals(ex.getMessage(), ""Request error: GET http://example.com: 500"");
  }
",non-flaky,5
98305,spotify_docker-client,CompressedDirectoryMatchFilepathTest.testMatchFilepath,"  @Test
  public void testMatchFilepath() {
    if (exception != null) {
      expectedException.expect(exception);
    }

    final Path path = fs.getPath(pathString);
    final boolean result = CompressedDirectory.goPathMatcher(fs, pattern).matches(path);

    final String description;
    if (matched) {
      description = MessageFormat.format(""the pattern {0} to match {1}"", pattern, pathString);
    } else {
      description = MessageFormat.format(""the pattern {0} not to match {1}"", pattern, pathString);
    }

    assertThat(result, describedAs(description, is(matched)));
  }
",non-flaky,5
98306,spotify_docker-client,ImageRefTest.testImageWithoutTag,"  @Test
  public void testImageWithoutTag() {
    final ImageRef sut = new ImageRef(""foobar"");
    assertThat(sut.getImage(), equalTo(""foobar""));
    assertThat(sut.getTag(), is(nullValue()));
  }
",non-flaky,5
98307,spotify_docker-client,ImageRefTest.testImageWithTag,"  @Test
  public void testImageWithTag() {
    final ImageRef sut = new ImageRef(""foobar:12345"");
    assertThat(sut.getImage(), equalTo(""foobar""));
    assertThat(sut.getTag(), is(""12345""));
  }
",non-flaky,5
98308,spotify_docker-client,ImageRefTest.testImageWithTagAndRegistry,"  @Test
  public void testImageWithTagAndRegistry() {
    final ImageRef sut = new ImageRef(""registry:4711/foo/bar:12345"");
    assertThat(sut.getImage(), equalTo(""registry:4711/foo/bar""));
    assertThat(sut.getTag(), is(""12345""));
  }
",non-flaky,5
98309,spotify_docker-client,ImageRefTest.testImageWithDigest,"  @Test
  public void testImageWithDigest() {
    final ImageRef sut = new ImageRef(""bar@sha256:12345"");
    assertThat(sut.getImage(), equalTo(""bar@sha256:12345""));
  }
",non-flaky,5
98310,spotify_docker-client,ImageRefTest.testImageWithDigestAndRegistry,"  @Test
  public void testImageWithDigestAndRegistry() {
    final ImageRef sut = new ImageRef(""registry:4711/foo/bar@sha256:12345"");
    assertThat(sut.getImage(), equalTo(""registry:4711/foo/bar@sha256:12345""));
  }
",non-flaky,5
98311,spotify_docker-client,DefaultDockerClientUnitTest.testHostForUnixSocket,"  @Test
  public void testHostForUnixSocket() {
    final DefaultDockerClient client = DefaultDockerClient.builder()
        .uri(""unix:///var/run/docker.sock"").build();
    assertThat(client.getHost(), equalTo(""localhost""));
  }
",non-flaky,5
98312,spotify_docker-client,DefaultDockerClientUnitTest.testHostForLocalHttps,"  @Test
  public void testHostForLocalHttps() {
    final DefaultDockerClient client = DefaultDockerClient.builder()
        .uri(""https://localhost:2375"").build();
    assertThat(client.getHost(), equalTo(""localhost""));
  }
",non-flaky,5
98313,spotify_docker-client,DefaultDockerClientUnitTest.testHostForFqdnHttps,"  @Test
  public void testHostForFqdnHttps() {
    final DefaultDockerClient client = DefaultDockerClient.builder()
        .uri(""https://perdu.com:2375"").build();
    assertThat(client.getHost(), equalTo(""perdu.com""));
  }
",non-flaky,5
98314,spotify_docker-client,DefaultDockerClientUnitTest.testHostForIpHttps,"  @Test
  public void testHostForIpHttps() {
    final DefaultDockerClient client = DefaultDockerClient.builder()
        .uri(""https://192.168.53.103:2375"").build();
    assertThat(client.getHost(), equalTo(""192.168.53.103""));
  }
",non-flaky,5
98315,spotify_docker-client,DefaultDockerClientUnitTest.testNoHeaders,"  @Test
  public void testNoHeaders() throws Exception {
    final DefaultDockerClient dockerClient = new DefaultDockerClient(
        builder, clientBuilderSupplier);
    dockerClient.info();

    verify(builderMock, never()).header(anyString(), anyString());
  }
",non-flaky,5
98316,spotify_docker-client,DefaultDockerClientUnitTest.testOneHeader,"  @Test
  public void testOneHeader() throws Exception {
    builder.header(""foo"", 1);

    final DefaultDockerClient dockerClient = new DefaultDockerClient(
        builder, clientBuilderSupplier);
    dockerClient.info();

    final ArgumentCaptor<String> keyArgument = ArgumentCaptor.forClass(String.class);
    final ArgumentCaptor<Object> valueArgument = ArgumentCaptor.forClass(Object.class);
    verify(builderMock, times(1)).header(keyArgument.capture(), valueArgument.capture());

    Assert.assertEquals(""foo"", keyArgument.getValue());
    Assert.assertEquals(1, valueArgument.getValue());
  }
",non-flaky,5
98317,spotify_docker-client,DefaultDockerClientUnitTest.testMultipleHeaders,"  @Test
  public void testMultipleHeaders() throws Exception {
    final Map<String, Object> headers = Maps.newHashMap();
    headers.put(""int"", 1);
    headers.put(""string"", ""2"");
    headers.put(""list"", Lists.newArrayList(""a"", ""b"", ""c""));

    for (final Map.Entry<String, Object> entry : headers.entrySet()) {
      builder.header(entry.getKey(), entry.getValue());
    }

    final DefaultDockerClient dockerClient = new DefaultDockerClient(
        builder, clientBuilderSupplier);
    dockerClient.info();

    final ArgumentCaptor<String> nameCaptor = ArgumentCaptor.forClass(String.class);
    final ArgumentCaptor<String> valueCaptor = ArgumentCaptor.forClass(String.class);
    verify(builderMock, times(headers.size())).header(nameCaptor.capture(), valueCaptor.capture());

    int idx = 0;
    for (final Map.Entry<String, Object> entry : headers.entrySet()) {
      Assert.assertEquals(entry.getKey(), nameCaptor.getAllValues().get(idx));
      Assert.assertEquals(entry.getValue(), valueCaptor.getAllValues().get(idx));
      ++idx;
    }
  }
",non-flaky,5
98318,spotify_docker-client,DefaultDockerClientUnitTest.testCapAddAndDrop,"  @Test
  public void testCapAddAndDrop() throws Exception {
    final DefaultDockerClient dockerClient = new DefaultDockerClient(
        builder, clientBuilderSupplier);

    final HostConfig hostConfig = HostConfig.builder()
        .capAdd(ImmutableList.of(""foo"", ""bar""))
        .capAdd(ImmutableList.of(""baz"", ""qux""))
        .build();

    final ContainerConfig containerConfig = ContainerConfig.builder()
        .hostConfig(hostConfig)
        .build();

    //noinspection unchecked
    when(asyncInvoker.method(
        anyString(), any(Entity.class), any(Class.class)))
        .thenReturn(Futures.immediateFuture(ContainerCreation.builder().build()));

    dockerClient.createContainer(containerConfig);

    final ArgumentCaptor<String> methodArg = ArgumentCaptor.forClass(String.class);
    final ArgumentCaptor<Entity> entityArg = ArgumentCaptor.forClass(Entity.class);
    final ArgumentCaptor<Class> classArg = ArgumentCaptor.forClass(Class.class);

    //noinspection unchecked
    verify(asyncInvoker, times(1)).method(
        methodArg.capture(), entityArg.capture(), classArg.capture());

    final Entity expectedEntity = Entity.entity(
        containerConfig, new Variant(MediaType.valueOf(APPLICATION_JSON), (String) null, null));

    // Check that we've called the right method on the underlying AsyncInvoker with the right params
    assertThat(methodArg.getValue(), equalTo(""POST""));
    assertThat(entityArg.getValue(), equalTo(expectedEntity));
    assertThat(classArg.getValue(), instanceOf(Class.class));
  }
",non-flaky,5
98319,spotify_docker-client,DockerHostTest.testDefaultDockerEndpoint,"  @Test
  public void testDefaultDockerEndpoint() throws Exception {
    when(systemDelegate.getProperty(""os.name"")).thenReturn(""linux"", ""mac"", ""other"");
    DockerHost.setSystemDelegate(systemDelegate);

    assertThat(DockerHost.defaultDockerEndpoint(), equalTo(""unix:///var/run/docker.sock""));
    assertThat(DockerHost.defaultDockerEndpoint(), equalTo(""unix:///var/run/docker.sock""));
    assertThat(DockerHost.defaultDockerEndpoint(), equalTo(""localhost:2375""));
  }
",non-flaky,5
98320,spotify_docker-client,DockerHostTest.testEndpointFromEnv,"  @Test
  public void testEndpointFromEnv() throws Exception {
    when(systemDelegate.getenv(""DOCKER_HOST"")).thenReturn(""foo"", (String) null);
    when(systemDelegate.getProperty(""os.name"")).thenReturn(""linux"");
    DockerHost.setSystemDelegate(systemDelegate);

    assertThat(DockerHost.endpointFromEnv(), equalTo(""foo""));
    assertThat(DockerHost.endpointFromEnv(), equalTo(""unix:///var/run/docker.sock""));
  }
",non-flaky,5
98321,spotify_docker-client,DockerHostTest.testDefaultUnixEndpoint,"  @Test
  public void testDefaultUnixEndpoint() throws Exception {
    assertThat(DockerHost.defaultUnixEndpoint(), equalTo(""unix:///var/run/docker.sock""));
  }
",non-flaky,5
98322,spotify_docker-client,DockerHostTest.testDefaultAddress,"  @Test
  public void testDefaultAddress() throws Exception {
    assertThat(DockerHost.defaultAddress(), equalTo(""localhost""));
  }
",non-flaky,5
98323,spotify_docker-client,DockerHostTest.testDefaultPort,"  @Test
  public void testDefaultPort() throws Exception {
    assertThat(DockerHost.defaultPort(), equalTo(2375));
  }
",non-flaky,5
98324,spotify_docker-client,DockerHostTest.testPortFromEnv,"  @Test
  public void testPortFromEnv() throws Exception {
    when(systemDelegate.getenv(""DOCKER_PORT"")).thenReturn(""1234"", (String) null);
    DockerHost.setSystemDelegate(systemDelegate);

    assertThat(DockerHost.portFromEnv(), equalTo(1234));
    assertThat(DockerHost.portFromEnv(), equalTo(2375));
  }
",non-flaky,5
98325,spotify_docker-client,DockerHostTest.testDefaultCertPath,"  @Test
  public void testDefaultCertPath() throws Exception {
    when(systemDelegate.getProperty(""user.home"")).thenReturn(""foobar"");
    DockerHost.setSystemDelegate(systemDelegate);

    assertThat(DockerHost.defaultCertPath(), equalTo(""foobar/.docker""));
  }
",non-flaky,5
98326,spotify_docker-client,DockerHostTest.testCertPathFromEnv,"  @Test
  public void testCertPathFromEnv() throws Exception {
    when(systemDelegate.getenv(""DOCKER_CERT_PATH"")).thenReturn(""foo"", (String) null);
    when(systemDelegate.getProperty(""user.home"")).thenReturn(""bar"");
    DockerHost.setSystemDelegate(systemDelegate);

    assertThat(DockerHost.certPathFromEnv(), equalTo(""foo""));
    assertThat(DockerHost.certPathFromEnv(), nullValue());
  }
",non-flaky,5
98327,spotify_docker-client,DockerHostTest.testFromUnixSocket,"  @Test
  public void testFromUnixSocket() throws Exception {
    final String unixSocket = ""unix:///var/run/docker.sock"";
    final String certPath = ""/path/to/cert"";
    final URI unixSocketUri = new URI(unixSocket);

    final DockerHost dockerHost = DockerHost.from(unixSocket, certPath);
    assertThat(dockerHost.host(), equalTo(unixSocket));
    assertThat(dockerHost.uri(), equalTo(unixSocketUri));
    assertThat(dockerHost.bindUri(), equalTo(unixSocketUri));
    assertThat(dockerHost.port(), equalTo(0));
    assertThat(dockerHost.address(), equalTo(""localhost""));
    assertThat(dockerHost.dockerCertPath(), equalTo(certPath));
  }
",non-flaky,5
98328,spotify_docker-client,DockerHostTest.testFromTcpSocketNoCert,"  @Test
  public void testFromTcpSocketNoCert() throws Exception {
    final String tcpSocket = ""tcp://127.0.0.1:2375"";
    final DockerHost dockerHost = DockerHost.from(tcpSocket, null);

    assertThat(dockerHost.host(), equalTo(""127.0.0.1:2375""));
    assertThat(dockerHost.uri(), equalTo(new URI(""http://127.0.0.1:2375"")));
    assertThat(dockerHost.bindUri(), equalTo(new URI(tcpSocket)));
    assertThat(dockerHost.port(), equalTo(2375));
    assertThat(dockerHost.address(), equalTo(""127.0.0.1""));
    assertThat(dockerHost.dockerCertPath(), nullValue());
  }
",non-flaky,5
98329,spotify_docker-client,DockerHostTest.testFromTcpSocketWithCert,"  @Test
  public void testFromTcpSocketWithCert() throws Exception {
    final String tcpSocket = ""tcp://127.0.0.1:2375"";
    final String certPath = ""/path/to/cert"";

    final DockerHost dockerHost = DockerHost.from(tcpSocket, certPath);
    assertThat(dockerHost.host(), equalTo(""127.0.0.1:2375""));
    assertThat(dockerHost.uri(), equalTo(new URI(""https://127.0.0.1:2375"")));
    assertThat(dockerHost.bindUri(), equalTo(new URI(tcpSocket)));
    assertThat(dockerHost.port(), equalTo(2375));
    assertThat(dockerHost.address(), equalTo(""127.0.0.1""));
    assertThat(dockerHost.dockerCertPath(), equalTo(certPath));
  }
",non-flaky,5
98330,spotify_docker-client,DockerHostTest.testFromEnv,"  @Test
  public void testFromEnv() throws Exception {
    when(systemDelegate.getProperty(""os.name"")).thenReturn(""linux"");
    DockerHost.setSystemDelegate(systemDelegate);

    final String dockerHostEnvVar = DockerHost.defaultDockerEndpoint();
    final boolean isUnixSocket = dockerHostEnvVar.startsWith(""unix://"");
    final URI dockerHostUri = new URI(dockerHostEnvVar);

    final String dockerHostAndPort;
    final URI dockerHostHttpUri;
    final URI dockerTcpUri;
    final int dockerHostPort;
    final String dockerHostHost;
    if (isUnixSocket) {
      dockerHostAndPort = dockerHostEnvVar;
      dockerHostHttpUri = dockerHostUri;
      dockerTcpUri = dockerHostUri;
      dockerHostPort = 0;
      dockerHostHost = ""localhost"";
    } else {
      dockerHostAndPort = dockerHostUri.getHost() + "":"" + dockerHostUri.getPort();
      dockerHostHttpUri = new URI(""http://"" + dockerHostAndPort);
      dockerTcpUri = new URI(""tcp://"" + dockerHostAndPort);
      dockerHostPort = dockerHostUri.getPort();
      dockerHostHost = dockerHostUri.getHost();
    }

    final DockerHost dockerHost = DockerHost.fromEnv();
    assertThat(dockerHost.host(), equalTo(dockerHostAndPort));
    assertThat(dockerHost.uri(), equalTo(dockerHostHttpUri));
    assertThat(dockerHost.bindUri(), equalTo(dockerTcpUri));
    assertThat(dockerHost.port(), equalTo(dockerHostPort));
    assertThat(dockerHost.address(), equalTo(dockerHostHost));
    assertThat(dockerHost.dockerCertPath(), nullValue());
  }
",non-flaky,5
98331,spotify_docker-client,DockerCertificatesTest.testBadDockerCertificates,"  @Test(expected = DockerCertificateException.class)
  public void testBadDockerCertificates() throws Exception {
    // try building a DockerCertificates with specifying a cert path to something that
    // isn't a cert
    DockerCertificates.builder()
        .dockerCertPath(getResourceFile(""dockerInvalidSslDirectory""))
        .build();
  }
",non-flaky,5
98332,spotify_docker-client,DockerCertificatesTest.testNoDockerCertificatesInDir,"  @Test
  public void testNoDockerCertificatesInDir() throws Exception {
    final Path certDir = Paths.get(System.getProperty(""java.io.tmpdir""));
    final Optional<DockerCertificatesStore> result = DockerCertificates.builder()
        .dockerCertPath(certDir)
        .build();
    assertThat(result.isPresent(), is(false));
  }
",non-flaky,5
98333,spotify_docker-client,DockerCertificatesTest.testDefaultDockerCertificates,"  @Test
  public void testDefaultDockerCertificates() throws Exception {
    DockerCertificates.builder()
        .dockerCertPath(getCertPath())
        .sslFactory(factory)
        .build();

    verify(factory).newSslContext(keyStore.capture(), password.capture(), trustStore.capture());

    final KeyStore.PrivateKeyEntry pkEntry = (KeyStore.PrivateKeyEntry) keyStore.getValue()
        .getEntry(""key"", new KeyStore.PasswordProtection(password.getValue()));

    final KeyStore caKeyStore = trustStore.getValue();

    assertNotNull(pkEntry);
    assertNotNull(pkEntry.getCertificate());
    assertNotNull(caKeyStore.getCertificate(""o=boot2docker""));
  }
",non-flaky,5
98334,spotify_docker-client,DockerCertificatesTest.testDockerCertificatesWithMultiCa,"  @Test
  public void testDockerCertificatesWithMultiCa() throws Exception {
    DockerCertificates.builder()
        .dockerCertPath(getCertPath())
        .caCertPath(getVariant(""ca-multi.pem""))
        .sslFactory(factory)
        .build();

    verify(factory).newSslContext(keyStore.capture(), password.capture(), trustStore.capture());

    final KeyStore.PrivateKeyEntry pkEntry = (KeyStore.PrivateKeyEntry) keyStore.getValue()
        .getEntry(""key"", new KeyStore.PasswordProtection(password.getValue()));

    assertNotNull(pkEntry);
    assertNotNull(pkEntry.getCertificate());
    assertNotNull(trustStore.getValue().getCertificate(
        ""cn=ca-test,o=internet widgits pty ltd,st=some-state,c=cr""));
    assertNotNull(trustStore.getValue().getCertificate(
        ""cn=ca-test-2,o=internet widgits pty ltd,st=some-state,c=cr""));
  }
",non-flaky,5
98335,spotify_docker-client,DockerCertificatesTest.testReadPrivateKeyPkcs1,"  @Test
  public void testReadPrivateKeyPkcs1() throws Exception {
    DockerCertificates.builder()
        .dockerCertPath(getCertPath())
        .clientKeyPath(getVariant(""key-pkcs1.pem""))
        .sslFactory(factory)
        .build();

    verify(factory).newSslContext(keyStore.capture(), password.capture(), trustStore.capture());

    final KeyStore.PrivateKeyEntry pkEntry = (KeyStore.PrivateKeyEntry) keyStore.getValue()
        .getEntry(""key"", new KeyStore.PasswordProtection(password.getValue()));

    assertNotNull(pkEntry.getPrivateKey());
  }
",non-flaky,5
98336,spotify_docker-client,DockerCertificatesTest.testReadPrivateKeyPkcs8,"  @Test
  public void testReadPrivateKeyPkcs8() throws Exception {
    DockerCertificates.builder()
        .dockerCertPath(getCertPath())
        .clientKeyPath(getVariant(""key-pkcs8.pem""))
        .sslFactory(factory)
        .build();

    verify(factory).newSslContext(keyStore.capture(), password.capture(), trustStore.capture());

    final KeyStore.PrivateKeyEntry pkEntry = (KeyStore.PrivateKeyEntry) keyStore.getValue()
        .getEntry(""key"", new KeyStore.PasswordProtection(password.getValue()));

    assertNotNull(pkEntry.getPrivateKey());
  }
",non-flaky,5
99702,apache_cassandra,DistributionSequenceTest.simpleSequence,"    @Test
    public void simpleSequence() throws Exception
    {
        Distribution dist = OptionDistribution.get(""seq(1..10)"").get();
        assertTrue(dist instanceof DistributionSequence);

        assertEquals(1, dist.minValue());
        assertEquals(10, dist.maxValue());
        assertEquals(5, dist.average());

        assertEquals(1, dist.inverseCumProb(0d));
        assertEquals(10, dist.inverseCumProb(1d));

        long min = dist.next();
        assertEquals(1,min);

        long last = min;
        for (int i=0; i<9; i++)
        {
            long next = dist.next();
            assertEquals(next, last+1); //increase by one each step
            last = next;
        }

        assertEquals(1, dist.next()); // wrapping
    }
",non-flaky,5
99703,apache_cassandra,DistributionSequenceTest.negValueSequence,"    @Test
    public void negValueSequence() throws Exception
    {
        Distribution dist = OptionDistribution.get(""seq(-1000..-10)"").get();
        assertTrue(dist instanceof DistributionSequence);

        assertEquals(-1000, dist.minValue());
        assertEquals( -10, dist.maxValue());
        assertEquals(-504, dist.average());

        assertEquals(-1000, dist.inverseCumProb(0d));
        assertEquals(-10, dist.inverseCumProb(1d));

        long min = dist.next();
        assertEquals(-1000, min);

        long last = min;
        long next = dist.next();
        while (last<next)
        {
            assertEquals(next, last+1); //increase by one each step
            last = next;
            next = dist.next();
        }

        assertEquals(-10, last); // wrapping
        assertEquals(-1000, next); // wrapping
    }
",non-flaky,5
99704,apache_cassandra,DistributionSequenceTest.bigSequence,"    @Test
    public void bigSequence() throws Exception
    {
        Distribution dist = OptionDistribution.get(String.format(""seq(1..%d)"", Long.MAX_VALUE)).get();
        assertTrue(dist instanceof DistributionSequence);

        assertEquals(1, dist.minValue());
        assertEquals(Long.MAX_VALUE, dist.maxValue());

        assertEquals(1, dist.inverseCumProb(0d));
        assertEquals(Long.MAX_VALUE, dist.inverseCumProb(1d));

    }
",non-flaky,5
99705,apache_cassandra,DistributionSequenceTest.setSeed,"    @Test
    public void setSeed() throws Exception
    {
        Distribution dist = OptionDistribution.get(""seq(1..10)"").get();
        assertTrue(dist instanceof DistributionSequence);

        for (int seed=1; seed<500; seed+=seed)
        {
            dist.setSeed(seed);
            assertEquals(1, dist.minValue());
            assertEquals(10, dist.maxValue());
            assertEquals(5, dist.average());

            assertEquals(1, dist.inverseCumProb(0d));
            assertEquals(10, dist.inverseCumProb(1d));

            long last = dist.next();
            for (int i = 0; i < 9; i++)
            {
                long next = dist.next();
                if (next>1)
                {
                    assertEquals(next, last + 1); //increase by one each step
                }else{
                    assertEquals(last, 10); //wrap after the end
                }
                last = next;
            }
        }
    }
",non-flaky,5
99706,apache_cassandra,DistributionGaussianTest.simpleGaussian,"    @Test
    public void simpleGaussian()
    {
        Distribution dist = OptionDistribution.get(""gaussian(1..10)"").get();
        assertTrue(dist instanceof DistributionBoundApache);

        assertEquals(1, dist.minValue());
        assertEquals(10, dist.maxValue());
        assertEquals(5, dist.average());

        assertEquals(1, dist.inverseCumProb(0d));
        assertEquals(10, dist.inverseCumProb(1d));

        int testCount = 100000;
        int[] results = new int[11];
        for (int i = 0; i < testCount; i++)
        {
            int val = toIntExact(dist.next());
            results[val]++;
        }

        // Increasing for the first half
        for (int i = toIntExact(dist.minValue()); i < dist.average(); i++)
        {
            assertTrue(results[i] < results[i + 1]);
        }

        // Decreasing for the second half
        for (int i = toIntExact(dist.average()) + 1; i < dist.maxValue(); i++)
        {
            assertTrue(results[i] > results[i + 1]);
        }
    }
",non-flaky,5
99707,apache_cassandra,DistributionGaussianTest.negValueGaussian,"    @Test
    public void negValueGaussian()
    {
        Distribution dist = OptionDistribution.get(""gaussian(-1000..-10)"").get();
        assertTrue(dist instanceof DistributionBoundApache);

        assertEquals(-1000, dist.minValue());
        assertEquals( -10, dist.maxValue());
        assertEquals(-504, dist.average());

        assertEquals(-1000, dist.inverseCumProb(0d));
        assertEquals(-10, dist.inverseCumProb(1d));
    }
",non-flaky,5
99708,apache_cassandra,MultiResultLoggerTest.delegatesToInitialPrintStream,"    @Test
    public void delegatesToInitialPrintStream() throws Exception
    {
        ByteArrayOutputStream output = new ByteArrayOutputStream();
        PrintStream printStream = new PrintStream(output, true);
        MultiResultLogger underTest = new MultiResultLogger(printStream);

        underTest.println(""Very important result"");

        assertEquals(""Very important result\n"", output.toString());
    }
",non-flaky,5
99709,apache_cassandra,MultiResultLoggerTest.printingExceptions,"    @Test
    public void printingExceptions() throws Exception
    {
        ByteArrayOutputStream output = new ByteArrayOutputStream();
        PrintStream printStream = new PrintStream(output, true);
        MultiResultLogger underTest = new MultiResultLogger(printStream);

        underTest.printException(new RuntimeException(""Bad things""));

        String stackTrace = output.toString();
        assertTrue(""Expected strack trace to be printed but got: "" + stackTrace, stackTrace.startsWith(""java.lang.RuntimeException: Bad things\n"" +
                                                ""\tat org.apache.cassandra.stress.util.MultiResultLoggerTest.printingExceptions""));
    }
",non-flaky,5
99710,apache_cassandra,MultiResultLoggerTest.delegatesToAdditionalPrintStreams,"    @Test
    public void delegatesToAdditionalPrintStreams() throws Exception
    {
        ByteArrayOutputStream output = new ByteArrayOutputStream();
        PrintStream additionalPrintStream = new PrintStream(output, true);
        MultiResultLogger underTest = new MultiResultLogger(new PrintStream(NOOP));

        underTest.addStream(additionalPrintStream);
        underTest.println(""Very important result"");

        assertEquals(""Very important result\n"", output.toString());
    }
",non-flaky,5
99711,apache_cassandra,MultiResultLoggerTest.delegatesPrintfToAdditionalPrintStreams,"    @Test
    public void delegatesPrintfToAdditionalPrintStreams() throws Exception
    {
        ByteArrayOutputStream output = new ByteArrayOutputStream();
        PrintStream additionalPrintStream = new PrintStream(output, true);
        MultiResultLogger underTest = new MultiResultLogger(new PrintStream(NOOP));

        underTest.addStream(additionalPrintStream);
        underTest.printf(""%s %s %s"", ""one"", ""two"", ""three"");

        assertEquals(""one two three"", output.toString());
    }
",non-flaky,5
99712,apache_cassandra,MultiResultLoggerTest.delegatesPrintlnToAdditionalPrintStreams,"    @Test
    public void delegatesPrintlnToAdditionalPrintStreams() throws Exception
    {
        ByteArrayOutputStream output = new ByteArrayOutputStream();
        PrintStream additionalPrintStream = new PrintStream(output, true);
        MultiResultLogger underTest = new MultiResultLogger(new PrintStream(NOOP));

        underTest.addStream(additionalPrintStream);
        underTest.println();

        assertEquals(""\n"", output.toString());
    }
",non-flaky,5
99713,apache_cassandra,SettingsNodeTest.testDefaults,"    @Test
    public void testDefaults() throws Exception
    {
        SettingsNode settingsNode = new SettingsNode(new SettingsNode.Options());
        assertEquals(null, settingsNode.datacenter);
    }
",non-flaky,5
99714,apache_cassandra,SettingsNodeTest.testOveridingDataCenter,"    @Test
    public void testOveridingDataCenter() throws Exception
    {
        SettingsNode.Options options = new SettingsNode.Options();
        options.accept(""datacenter=dc1"");
        SettingsNode settingsNode = new SettingsNode(options);
        assertEquals(""dc1"", settingsNode.datacenter);
    }
",non-flaky,5
99715,apache_cassandra,SettingsMiscTest.versionTriggersSpecialOption,"    @Test
    public void versionTriggersSpecialOption() throws Exception
    {
        assertTrue(SettingsMisc.maybeDoSpecial(ImmutableMap.of(""version"", new String[] {})));
    }
",non-flaky,5
99716,apache_cassandra,SettingsMiscTest.noSpecialOptions,"    @Test
    public void noSpecialOptions() throws Exception
    {
        assertFalse(SettingsMisc.maybeDoSpecial(Collections.emptyMap()));
    }
",non-flaky,5
99717,apache_cassandra,SettingsMiscTest.parsesVersionMatch,"    @Test
    public void parsesVersionMatch() throws Exception
    {
        String versionString = SettingsMisc.parseVersionFile(""CassandraVersion=TheBestVersion\n"");
        assertEquals(""Version: TheBestVersion"", versionString);
    }
",non-flaky,5
99718,apache_cassandra,SettingsMiscTest.parsesVersionNoMatch,"    @Test
    public void parsesVersionNoMatch() throws Exception
    {
        String versionString = SettingsMisc.parseVersionFile(""VersionFileChangedFormat :("");
        assertEquals(""Unable to find version information"", versionString);
    }
",non-flaky,5
99719,apache_cassandra,OptionReplicationTest.defaultsToReplicationFactorOfOne,"    @Test
    public void defaultsToReplicationFactorOfOne() throws Exception
    {
        OptionReplication defaults = new OptionReplication();
        assertEquals(ImmutableMap.of(""replication_factor"", ""1""), defaults.getOptions());
    }
",non-flaky,5
99720,apache_cassandra,StressSettingsTest.isSerializable,"    @Test
    public void isSerializable() throws Exception
    {
        Map<String, String[]> args = new HashMap<>();
        args.put(""write"", new String[] {});
        StressSettings settings = StressSettings.get(args);
        // Will throw if not all settings are Serializable
        new ObjectOutputStream(new ByteArrayOutputStream()).writeObject(settings);
    }
",non-flaky,5
99721,apache_cassandra,FQLReplayTest.testOrderedReplay,"    @Test
    public void testOrderedReplay() throws IOException
    {
        File f = generateQueries(100, true);
        int queryCount = 0;
        try (ChronicleQueue queue = ChronicleQueueBuilder.single(f).build();
             FQLQueryIterator iter = new FQLQueryIterator(queue.createTailer(), 101))
        {
            long last = -1;
            while (iter.hasNext())
            {
                FQLQuery q = iter.next();
                assertTrue(q.queryStartTime >= last);
                last = q.queryStartTime;
                queryCount++;
            }
        }
        assertEquals(100, queryCount);
    }
",non-flaky,5
99722,apache_cassandra,FQLReplayTest.testQueryIterator,"    @Test
    public void testQueryIterator() throws IOException
    {
        File f = generateQueries(100, false);
        int queryCount = 0;
        try (ChronicleQueue queue = ChronicleQueueBuilder.single(f).build();
             FQLQueryIterator iter = new FQLQueryIterator(queue.createTailer(), 1))
        {
            long last = -1;
            while (iter.hasNext())
            {
                FQLQuery q = iter.next();
                assertTrue(q.queryStartTime >= last);
                last = q.queryStartTime;
                queryCount++;
            }
        }
        assertEquals(100, queryCount);
    }
",non-flaky,5
99723,apache_cassandra,FQLReplayTest.testMergingIterator,"    @Test
    public void testMergingIterator() throws IOException
    {
        File f = generateQueries(100, false);
        File f2 = generateQueries(100, false);
        int queryCount = 0;
        try (ChronicleQueue queue = ChronicleQueueBuilder.single(f).build();
             ChronicleQueue queue2 = ChronicleQueueBuilder.single(f2).build();
             FQLQueryIterator iter = new FQLQueryIterator(queue.createTailer(), 101);
             FQLQueryIterator iter2 = new FQLQueryIterator(queue2.createTailer(), 101);
             MergeIterator<FQLQuery, List<FQLQuery>> merger = MergeIterator.get(Lists.newArrayList(iter, iter2), FQLQuery::compareTo, new Replay.Reducer()))
        {
            long last = -1;

            while (merger.hasNext())
            {
                List<FQLQuery> qs = merger.next();
                assertEquals(2, qs.size());
                assertEquals(0, qs.get(0).compareTo(qs.get(1)));
                assertTrue(qs.get(0).queryStartTime >= last);
                last = qs.get(0).queryStartTime;
                queryCount++;
            }
        }
        assertEquals(100, queryCount);
    }
",non-flaky,5
99724,apache_cassandra,FQLReplayTest.testFQLQueryReader,"    @Test
    public void testFQLQueryReader() throws IOException
    {
        FQLQueryReader reader = new FQLQueryReader();

        try (ChronicleQueue queue = ChronicleQueueBuilder.single(generateQueries(1000, true)).build())
        {
            ExcerptTailer tailer = queue.createTailer();
            int queryCount = 0;
            while (tailer.readDocument(reader))
            {
                assertNotNull(reader.getQuery());
                if (reader.getQuery() instanceof FQLQuery.Single)
                {
                    assertTrue(reader.getQuery().keyspace() == null || reader.getQuery().keyspace().equals(""querykeyspace""));
                }
                else
                {
                    assertEquals(""someks"", reader.getQuery().keyspace());
                }
                queryCount++;
            }
            assertEquals(1000, queryCount);
        }
    }
",non-flaky,5
99725,apache_cassandra,FQLReplayTest.testStoringResults,"    @Test
    public void testStoringResults() throws Throwable
    {
        File tmpDir = Files.createTempDirectory(""results"").toFile();
        File queryDir = Files.createTempDirectory(""queries"").toFile();

        ResultHandler.ComparableResultSet res = createResultSet(10, 10, true);
        ResultStore rs = new ResultStore(Collections.singletonList(tmpDir), queryDir);
        FQLQuery query = new FQLQuery.Single(""abc"", QueryOptions.DEFAULT.getProtocolVersion().asInt(), QueryOptions.DEFAULT, 12345, 11111, 22, ""select * from abc"", Collections.emptyList());
        try
        {
            rs.storeColumnDefinitions(query, Collections.singletonList(res.getColumnDefinitions()));
            Iterator<ResultHandler.ComparableRow> it = res.iterator();
            while (it.hasNext())
            {
                List<ResultHandler.ComparableRow> row = Collections.singletonList(it.next());
                rs.storeRows(row);
            }
            // this marks the end of the result set:
            rs.storeRows(Collections.singletonList(null));
        }
        finally
        {
            rs.close();
        }

        compareResults(Collections.singletonList(Pair.create(query, res)),
                       readResultFile(tmpDir, queryDir));

    }
",non-flaky,5
99726,apache_cassandra,FQLReplayTest.testCompareColumnDefinitions,"    @Test
    public void testCompareColumnDefinitions()
    {
        ResultHandler.ComparableResultSet res = createResultSet(10, 10, false);
        ResultComparator rc = new ResultComparator();

        List<ResultHandler.ComparableColumnDefinitions> colDefs = new ArrayList<>(100);
        List<String> targetHosts = new ArrayList<>(100);
        for (int i = 0; i < 100; i++)
        {
            targetHosts.add(""host""+i);
            colDefs.add(res.getColumnDefinitions());
        }
        assertTrue(rc.compareColumnDefinitions(targetHosts, null, colDefs));
        colDefs.set(50, createResultSet(9, 9, false).getColumnDefinitions());
        assertFalse(rc.compareColumnDefinitions(targetHosts, null, colDefs));
    }
",non-flaky,5
99727,apache_cassandra,FQLReplayTest.testCompareEqualRows,"    @Test
    public void testCompareEqualRows()
    {
        ResultComparator rc = new ResultComparator();

        ResultHandler.ComparableResultSet res = createResultSet(10, 10, false);
        ResultHandler.ComparableResultSet res2 = createResultSet(10, 10, false);
        List<ResultHandler.ComparableResultSet> toCompare = Lists.newArrayList(res, res2);
        List<Iterator<ResultHandler.ComparableRow>> iters = toCompare.stream().map(Iterable::iterator).collect(Collectors.toList());

        while (true)
        {
            List<ResultHandler.ComparableRow> rows = ResultHandler.rows(iters);
            assertTrue(rc.compareRows(Lists.newArrayList(""eq1"", ""eq2""), null, rows));
            if (rows.stream().allMatch(Objects::isNull))
                break;
        }
    }
",non-flaky,5
99728,apache_cassandra,FQLReplayTest.testCompareRowsDifferentCount,"    @Test
    public void testCompareRowsDifferentCount()
    {
        ResultComparator rc = new ResultComparator();
        ResultHandler.ComparableResultSet res = createResultSet(10, 10, false);
        ResultHandler.ComparableResultSet res2 = createResultSet(10, 10, false);
        List<ResultHandler.ComparableResultSet> toCompare = Lists.newArrayList(res, res2, createResultSet(10, 11, false));
        List<Iterator<ResultHandler.ComparableRow>> iters = toCompare.stream().map(Iterable::iterator).collect(Collectors.toList());
        boolean foundMismatch = false;
        while (true)
        {
            List<ResultHandler.ComparableRow> rows = ResultHandler.rows(iters);
            if (rows.stream().allMatch(Objects::isNull))
                break;
            if (!rc.compareRows(Lists.newArrayList(""eq1"", ""eq2"", ""diff""), null, rows))
            {
                foundMismatch = true;
            }
        }
        assertTrue(foundMismatch);
    }
",non-flaky,5
99729,apache_cassandra,FQLReplayTest.testCompareRowsDifferentContent,"    @Test
    public void testCompareRowsDifferentContent()
    {
        ResultComparator rc = new ResultComparator();
        ResultHandler.ComparableResultSet res = createResultSet(10, 10, false);
        ResultHandler.ComparableResultSet res2 = createResultSet(10, 10, false);
        List<ResultHandler.ComparableResultSet> toCompare = Lists.newArrayList(res, res2, createResultSet(10, 10, true));
        List<Iterator<ResultHandler.ComparableRow>> iters = toCompare.stream().map(Iterable::iterator).collect(Collectors.toList());
        while (true)
        {
            List<ResultHandler.ComparableRow> rows = ResultHandler.rows(iters);
            if (rows.stream().allMatch(Objects::isNull))
                break;
            assertFalse(rows.toString(), rc.compareRows(Lists.newArrayList(""eq1"", ""eq2"", ""diff""), null, rows));
        }
    }
",non-flaky,5
99730,apache_cassandra,FQLReplayTest.testCompareRowsDifferentColumnCount,"    @Test
    public void testCompareRowsDifferentColumnCount()
    {
        ResultComparator rc = new ResultComparator();
        ResultHandler.ComparableResultSet res = createResultSet(10, 10, false);
        ResultHandler.ComparableResultSet res2 = createResultSet(10, 10, false);
        List<ResultHandler.ComparableResultSet> toCompare = Lists.newArrayList(res, res2, createResultSet(11, 10, false));
        List<Iterator<ResultHandler.ComparableRow>> iters = toCompare.stream().map(Iterable::iterator).collect(Collectors.toList());
        while (true)
        {
            List<ResultHandler.ComparableRow> rows = ResultHandler.rows(iters);
            if (rows.stream().allMatch(Objects::isNull))
                break;
            assertFalse(rows.toString(), rc.compareRows(Lists.newArrayList(""eq1"", ""eq2"", ""diff""), null, rows));
        }
    }
",non-flaky,5
99731,apache_cassandra,FQLReplayTest.testResultHandler,"    @Test
    public void testResultHandler() throws IOException
    {
        List<String> targetHosts = Lists.newArrayList(""hosta"", ""hostb"", ""hostc"");
        File tmpDir = Files.createTempDirectory(""testresulthandler"").toFile();
        File queryDir = Files.createTempDirectory(""queries"").toFile();
        List<File> resultPaths = new ArrayList<>();
        targetHosts.forEach(host -> { File f = new File(tmpDir, host); f.mkdir(); resultPaths.add(f);});

        ResultHandler.ComparableResultSet res = createResultSet(10, 10, false);
        ResultHandler.ComparableResultSet res2 = createResultSet(10, 10, false);
        ResultHandler.ComparableResultSet res3 = createResultSet(10, 10, false);
        List<ResultHandler.ComparableResultSet> toCompare = Lists.newArrayList(res, res2, res3);
        FQLQuery query = new FQLQuery.Single(""abcabc"", QueryOptions.DEFAULT.getProtocolVersion().asInt(), QueryOptions.DEFAULT, 1111, 2222, 3333, ""select * from xyz"", Collections.emptyList());
        try (ResultHandler rh = new ResultHandler(targetHosts, resultPaths, queryDir))
        {
            rh.handleResults(query, toCompare);
        }
        List<Pair<FQLQuery, ResultHandler.ComparableResultSet>> results1 = readResultFile(resultPaths.get(0), queryDir);
        List<Pair<FQLQuery, ResultHandler.ComparableResultSet>> results2 = readResultFile(resultPaths.get(1), queryDir);
        List<Pair<FQLQuery, ResultHandler.ComparableResultSet>> results3 = readResultFile(resultPaths.get(2), queryDir);
        compareResults(results1, results2);
        compareResults(results1, results3);
        compareResults(results3, Collections.singletonList(Pair.create(query, res)));
    }
",non-flaky,5
99732,apache_cassandra,FQLReplayTest.testResultHandlerWithDifference,"    @Test
    public void testResultHandlerWithDifference() throws IOException
    {
        List<String> targetHosts = Lists.newArrayList(""hosta"", ""hostb"", ""hostc"");
        File tmpDir = Files.createTempDirectory(""testresulthandler"").toFile();
        File queryDir = Files.createTempDirectory(""queries"").toFile();
        List<File> resultPaths = new ArrayList<>();
        targetHosts.forEach(host -> { File f = new File(tmpDir, host); f.mkdir(); resultPaths.add(f);});

        ResultHandler.ComparableResultSet res = createResultSet(10, 10, false);
        ResultHandler.ComparableResultSet res2 = createResultSet(10, 5, false);
        ResultHandler.ComparableResultSet res3 = createResultSet(10, 10, false);
        List<ResultHandler.ComparableResultSet> toCompare = Lists.newArrayList(res, res2, res3);
        FQLQuery query = new FQLQuery.Single(""aaa"", QueryOptions.DEFAULT.getProtocolVersion().asInt(), QueryOptions.DEFAULT, 123123, 11111, 22222, ""select * from abcabc"", Collections.emptyList());
        try (ResultHandler rh = new ResultHandler(targetHosts, resultPaths, queryDir))
        {
            rh.handleResults(query, toCompare);
        }
        List<Pair<FQLQuery, ResultHandler.ComparableResultSet>> results1 = readResultFile(resultPaths.get(0), queryDir);
        List<Pair<FQLQuery, ResultHandler.ComparableResultSet>> results2 = readResultFile(resultPaths.get(1), queryDir);
        List<Pair<FQLQuery, ResultHandler.ComparableResultSet>> results3 = readResultFile(resultPaths.get(2), queryDir);
        compareResults(results1, results3);
        compareResults(results2, Collections.singletonList(Pair.create(query, res2)));
    }
",non-flaky,5
99733,apache_cassandra,FQLReplayTest.testResultHandlerMultipleResultSets,"    @Test
    public void testResultHandlerMultipleResultSets() throws IOException
    {
        List<String> targetHosts = Lists.newArrayList(""hosta"", ""hostb"", ""hostc"");
        File tmpDir = Files.createTempDirectory(""testresulthandler"").toFile();
        File queryDir = Files.createTempDirectory(""queries"").toFile();
        List<File> resultPaths = new ArrayList<>();
        targetHosts.forEach(host -> { File f = new File(tmpDir, host); f.mkdir(); resultPaths.add(f);});
        List<Pair<FQLQuery, List<ResultHandler.ComparableResultSet>>> resultSets = new ArrayList<>();
        Random random = new Random();
        for (int i = 0; i < 10; i++)
        {
            List<ResultHandler.ComparableResultSet> results = new ArrayList<>();
            List<ByteBuffer> values = Collections.singletonList(ByteBufferUtil.bytes(i * 50));
            for (int jj = 0; jj < targetHosts.size(); jj++)
            {
                results.add(createResultSet(5, 1 + random.nextInt(10), true));
            }
            FQLQuery q = i % 2 == 0
                         ? new FQLQuery.Single(""abc""+i,
                                             3,
                                             QueryOptions.forInternalCalls(values),
                                             i * 1000,
                                             12345,
                                             54321,
                                             ""select * from xyz where id = ""+i,
                                             values)
                         : new FQLQuery.Batch(""abc""+i,
                                              3,
                                              QueryOptions.forInternalCalls(values),
                                              i * 1000,
                                              i * 54321,
                                              i * 12345,
                                              com.datastax.driver.core.BatchStatement.Type.UNLOGGED,
                                              Lists.newArrayList(""select * from aaaa""),
                                              Collections.singletonList(values));

            resultSets.add(Pair.create(q, results));
        }
        try (ResultHandler rh = new ResultHandler(targetHosts, resultPaths, queryDir))
        {
            for (int i = 0; i < resultSets.size(); i++)
                rh.handleResults(resultSets.get(i).left, resultSets.get(i).right);
        }

        for (int i = 0; i < targetHosts.size(); i++)
            compareWithFile(resultPaths, queryDir, resultSets, i);
    }
",non-flaky,5
99734,apache_cassandra,FQLReplayTest.testResultHandlerFailedQuery,"    @Test
    public void testResultHandlerFailedQuery() throws IOException
    {
        List<String> targetHosts = Lists.newArrayList(""hosta"", ""hostb"", ""hostc"", ""hostd"");
        File tmpDir = Files.createTempDirectory(""testresulthandler"").toFile();
        File queryDir = Files.createTempDirectory(""queries"").toFile();
        List<File> resultPaths = new ArrayList<>();
        targetHosts.forEach(host -> { File f = new File(tmpDir, host); f.mkdir(); resultPaths.add(f);});

        List<Pair<FQLQuery, List<ResultHandler.ComparableResultSet>>> resultSets = new ArrayList<>();
        Random random = new Random();
        for (int i = 0; i < 10; i++)
        {
            List<ResultHandler.ComparableResultSet> results = new ArrayList<>();
            List<ByteBuffer> values = Collections.singletonList(ByteBufferUtil.bytes(i * 50));
            for (int jj = 0; jj < targetHosts.size(); jj++)
            {
                results.add(createResultSet(5, 1 + random.nextInt(10), true));
            }
            results.set(0, StoredResultSet.failed(""testing abc""));
            results.set(3, StoredResultSet.failed(""testing abc""));
            FQLQuery q = new FQLQuery.Single(""abc""+i,
                                             3,
                                             QueryOptions.forInternalCalls(values),
                                             i * 1000,
                                             i * 12345,
                                             i * 54321,
                                             ""select * from xyz where id = ""+i,
                                             values);
            resultSets.add(Pair.create(q, results));
        }
        try (ResultHandler rh = new ResultHandler(targetHosts, resultPaths, queryDir))
        {
            for (int i = 0; i < resultSets.size(); i++)
                rh.handleResults(resultSets.get(i).left, resultSets.get(i).right);
        }
        for (int i = 0; i < targetHosts.size(); i++)
            compareWithFile(resultPaths, queryDir, resultSets, i);
    }
",non-flaky,5
99735,apache_cassandra,FQLReplayTest.testCompare,"    @Test
    public void testCompare()
    {
        FQLQuery q1 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222, ""aaaa"", Collections.emptyList());
        FQLQuery q2 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222,""aaaa"", Collections.emptyList());

        assertEquals(0, q1.compareTo(q2));
        assertEquals(0, q2.compareTo(q1));

        FQLQuery q3 = new FQLQuery.Batch(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222, com.datastax.driver.core.BatchStatement.Type.UNLOGGED, Collections.emptyList(), Collections.emptyList());
        // single queries before batch queries
        assertTrue(q1.compareTo(q3) < 0);
        assertTrue(q3.compareTo(q1) > 0);

        // check that smaller query time
        FQLQuery q4 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 124, 111, 222, ""aaaa"", Collections.emptyList());
        assertTrue(q1.compareTo(q4) < 0);
        assertTrue(q4.compareTo(q1) > 0);

        FQLQuery q5 = new FQLQuery.Batch(""abc"", 0, QueryOptions.DEFAULT, 124, 111, 222, com.datastax.driver.core.BatchStatement.Type.UNLOGGED, Collections.emptyList(), Collections.emptyList());
        assertTrue(q1.compareTo(q5) < 0);
        assertTrue(q5.compareTo(q1) > 0);

        FQLQuery q6 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222, ""aaaa"", Collections.singletonList(ByteBufferUtil.bytes(10)));
        FQLQuery q7 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222, ""aaaa"", Collections.emptyList());
        assertTrue(q6.compareTo(q7) > 0);
        assertTrue(q7.compareTo(q6) < 0);

        FQLQuery q8 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222, ""aaaa"", Collections.singletonList(ByteBufferUtil.bytes(""a"")));
        FQLQuery q9 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222, ""aaaa"", Collections.singletonList(ByteBufferUtil.bytes(""b"")));
        assertTrue(q8.compareTo(q9) < 0);
        assertTrue(q9.compareTo(q8) > 0);
    }
",non-flaky,5
99736,apache_cassandra,FQLReplayTest.testFQLQuerySingleToStatement,"    @Test
    public void testFQLQuerySingleToStatement()
    {
        List<ByteBuffer> values = new ArrayList<>();
        for (int i = 0; i < 10; i++)
            values.add(ByteBufferUtil.bytes(i));
        FQLQuery.Single single = new FQLQuery.Single(""xyz"",
                                                     QueryOptions.DEFAULT.getProtocolVersion().asInt(),
                                                     QueryOptions.forInternalCalls(values),
                                                     1234,
                                                     12345,
                                                     54321,
                                                     ""select * from aaa"",
                                                     values);
        Statement stmt = single.toStatement();
        assertEquals(stmt.getDefaultTimestamp(), 12345);
        assertTrue(stmt instanceof SimpleStatement);
        SimpleStatement simpleStmt = (SimpleStatement)stmt;
        assertEquals(""select * from aaa"",simpleStmt.getQueryString(CodecRegistry.DEFAULT_INSTANCE));
        assertArrayEquals(values.toArray(), simpleStmt.getValues(com.datastax.driver.core.ProtocolVersion.fromInt(QueryOptions.DEFAULT.getProtocolVersion().asInt()), CodecRegistry.DEFAULT_INSTANCE));
    }
",non-flaky,5
99737,apache_cassandra,FQLReplayTest.testFQLQueryBatchToStatement,"    @Test
    public void testFQLQueryBatchToStatement()
    {
        List<List<ByteBuffer>> values = new ArrayList<>();
        List<String> queries = new ArrayList<>();
        for (int bqCount = 0; bqCount < 10; bqCount++)
        {
            queries.add(""select * from asdf where x = ? and y = "" + bqCount);
            List<ByteBuffer> queryValues = new ArrayList<>();
            for (int i = 0; i < 10; i++)
                queryValues.add(ByteBufferUtil.bytes(i + "":"" + bqCount));
            values.add(queryValues);
        }

        FQLQuery.Batch batch = new FQLQuery.Batch(""xyz"",
                                                   QueryOptions.DEFAULT.getProtocolVersion().asInt(),
                                                   QueryOptions.DEFAULT,
                                                   1234,
                                                   12345,
                                                   54321,
                                                   com.datastax.driver.core.BatchStatement.Type.UNLOGGED,
                                                   queries,
                                                   values);
        Statement stmt = batch.toStatement();
        assertEquals(stmt.getDefaultTimestamp(), 12345);
        assertTrue(stmt instanceof com.datastax.driver.core.BatchStatement);
        com.datastax.driver.core.BatchStatement batchStmt = (com.datastax.driver.core.BatchStatement)stmt;
        List<Statement> statements = Lists.newArrayList(batchStmt.getStatements());
        List<Statement> fromFQLQueries = batch.queries.stream().map(FQLQuery.Single::toStatement).collect(Collectors.toList());
        assertEquals(statements.size(), fromFQLQueries.size());
        assertEquals(12345, batchStmt.getDefaultTimestamp());
        for (int i = 0; i < statements.size(); i++)
            compareStatements(statements.get(i), fromFQLQueries.get(i));
    }
",non-flaky,5
99738,apache_cassandra,FQLReplayTest.testParser,"    @Test
    public void testParser() {
        QueryReplayer.ParsedTargetHost pth;
        pth = fromString(""127.0.0.1"");
        assertEquals(""127.0.0.1"", pth.host);
        assertEquals(9042, pth.port );
        assertNull(pth.user);
        assertNull(pth.password);

        pth = fromString(""127.0.0.1:3333"");
        assertEquals(""127.0.0.1"", pth.host);
        assertEquals(3333, pth.port );
        assertNull(pth.user);
        assertNull(pth.password);

        pth = fromString(""aaa:bbb@127.0.0.1:3333"");
        assertEquals(""127.0.0.1"", pth.host);
        assertEquals(3333, pth.port );
        assertEquals(""aaa"", pth.user);
        assertEquals(""bbb"", pth.password);

        pth = fromString(""aaa:bbb@127.0.0.1"");
        assertEquals(""127.0.0.1"", pth.host);
        assertEquals(9042, pth.port );
        assertEquals(""aaa"", pth.user);
        assertEquals(""bbb"", pth.password);
    }
",non-flaky,5
99739,apache_cassandra,FQLReplayTest.testNoPass,"    @Test(expected = RuntimeException.class)
    public void testNoPass()
    {
        fromString(""blabla@abc.com:1234"");
    }
",non-flaky,5
99740,apache_cassandra,FQLReplayTest.testBadPort,"    @Test(expected = RuntimeException.class)
    public void testBadPort()
    {
        fromString(""aaa:bbb@abc.com:xyz"");
    }
",non-flaky,5
99741,apache_cassandra,FQLReplayTest.writeMarshallablePayload,"    @Test (expected = IORuntimeException.class)
    public void testFutureVersion() throws Exception
    {
        FQLQueryReader reader = new FQLQueryReader();
        File dir = Files.createTempDirectory(""chronicle"").toFile();
        try (ChronicleQueue queue = ChronicleQueueBuilder.single(dir).build())
        {
            ExcerptAppender appender = queue.acquireAppender();
            appender.writeDocument(new BinLog.ReleaseableWriteMarshallable() {
                protected long version()
                {
                    return 999;
                }

                protected String type()
                {
                    return FullQueryLogger.SINGLE_QUERY;
                }

                public void writeMarshallablePayload(WireOut wire)
                {
                    wire.write(""future-field"").text(""future_value"");
                }
",non-flaky,5
99742,apache_cassandra,FQLReplayTest.writeMarshallablePayload,"    @Test (expected = IORuntimeException.class)
    public void testUnknownRecord() throws Exception
    {
        FQLQueryReader reader = new FQLQueryReader();
        File dir = Files.createTempDirectory(""chronicle"").toFile();
        try (ChronicleQueue queue = ChronicleQueueBuilder.single(dir).build())
        {
            ExcerptAppender appender = queue.acquireAppender();
            appender.writeDocument(new BinLog.ReleaseableWriteMarshallable() {
                protected long version()
                {
                    return FullQueryLogger.CURRENT_VERSION;
                }

                protected String type()
                {
                    return ""unknown-type"";
                }

                public void writeMarshallablePayload(WireOut wire)
                {
                    wire.write(""unknown-field"").text(""unknown_value"");
                }
",non-flaky,5
99743,apache_cassandra,FQLCompareTest.endToEnd,"    @Test
    public void endToEnd() throws IOException
    {
        List<String> targetHosts = Lists.newArrayList(""hosta"", ""hostb"");
        File tmpDir = Files.createTempDirectory(""testresulthandler"").toFile();
        File queryDir = Files.createTempDirectory(""queries"").toFile();
        List<File> resultPaths = generateResultSets(targetHosts, tmpDir, queryDir, true, false);
        Compare.compare(queryDir.toString(), resultPaths.stream().map(File::toString).collect(Collectors.toList()));
    }
",non-flaky,5
99744,apache_cassandra,FQLCompareTest.endToEndQueryFailures,"    @Test
    public void endToEndQueryFailures() throws IOException
    {
        List<String> targetHosts = Lists.newArrayList(""hosta"", ""hostb"");
        File tmpDir = Files.createTempDirectory(""testresulthandler"").toFile();
        File queryDir = Files.createTempDirectory(""queries"").toFile();
        List<File> resultPaths = generateResultSets(targetHosts, tmpDir, queryDir, true,true);
        Compare.compare(queryDir.toString(), resultPaths.stream().map(File::toString).collect(Collectors.toList()));
    }
",non-flaky,5
99745,apache_cassandra,FQLCompareTest.compareEqual,"    @Test
    public void compareEqual() throws IOException
    {
        List<String> targetHosts = Lists.newArrayList(""hosta"", ""hostb"");
        File tmpDir = Files.createTempDirectory(""testresulthandler"").toFile();
        File queryDir = Files.createTempDirectory(""queries"").toFile();
        List<File> resultPaths = generateResultSets(targetHosts, tmpDir, queryDir, false,false);

        ResultComparator comparator = new ResultComparator();
        List<ChronicleQueue> readQueues = null;
        try
        {
            readQueues = resultPaths.stream().map(s -> ChronicleQueueBuilder.single(s).readOnly(true).build()).collect(Collectors.toList());
            List<Iterator<ResultHandler.ComparableResultSet>> its = readQueues.stream().map(q -> new Compare.StoredResultSetIterator(q.createTailer())).collect(Collectors.toList());
            List<ResultHandler.ComparableResultSet> resultSets = Compare.resultSets(its);
            while(resultSets.stream().allMatch(Objects::nonNull))
            {
                assertTrue(comparator.compareColumnDefinitions(targetHosts, query(), resultSets.stream().map(ResultHandler.ComparableResultSet::getColumnDefinitions).collect(Collectors.toList())));
                List<Iterator<ResultHandler.ComparableRow>> rows = resultSets.stream().map(Iterable::iterator).collect(Collectors.toList());

                List<ResultHandler.ComparableRow> toCompare = ResultHandler.rows(rows);

                while (toCompare.stream().allMatch(Objects::nonNull))
                {
                    assertTrue(comparator.compareRows(targetHosts, query(), ResultHandler.rows(rows)));
                    toCompare = ResultHandler.rows(rows);
                }
                resultSets = Compare.resultSets(its);
            }
        }
        finally
        {
            if (readQueues != null)
                readQueues.forEach(Closeable::close);
        }
    }
",non-flaky,5
99746,apache_cassandra,AsyncStreamingInputPlusTest.isOpen,"//    @Test
//    public void isOpen()
//    {
//        Assert.assertTrue(inputPlus.isOpen());
//        inputPlus.requestClosure();
//        Assert.assertFalse(inputPlus.isOpen());
//    }
",non-flaky,5
99747,apache_cassandra,AsyncStreamingInputPlusTest.append_closed,"    @Test
    public void append_closed()
    {
        inputPlus = new AsyncStreamingInputPlus(channel);
        inputPlus.requestClosure();
        inputPlus.close();
        buf = channel.alloc().buffer(4);
        assertFalse(inputPlus.append(buf));
    }
",non-flaky,5
99748,apache_cassandra,AsyncStreamingInputPlusTest.append_normal,"    @Test
    public void append_normal()
    {
        inputPlus = new AsyncStreamingInputPlus(channel);
        int size = 4;
        buf = channel.alloc().buffer(size);
        buf.writerIndex(size);
        inputPlus.append(buf);
        Assert.assertEquals(buf.readableBytes(), inputPlus.unsafeAvailable());
    }
",non-flaky,5
99749,apache_cassandra,AsyncStreamingInputPlusTest.read,"    @Test
    public void read() throws IOException
    {
        inputPlus = new AsyncStreamingInputPlus(channel);
        // put two buffers of 8 bytes each into the queue.
        // then read an int, then a long. the latter tests offset into the inputPlus, as well as spanning across queued buffers.
        // the values of those int/long will both be '42', but spread across both queue buffers.
        ByteBuf buf = channel.alloc().buffer(8);
        buf.writeInt(42);
        buf.writerIndex(8);
        inputPlus.append(buf);
        buf = channel.alloc().buffer(8);
        buf.writeInt(42);
        buf.writerIndex(8);
        inputPlus.append(buf);
        Assert.assertEquals(16, inputPlus.unsafeAvailable());

//        ByteBuffer out = ByteBuffer.allocate(4);
//        int readCount = inputPlus.read(out);
//        Assert.assertEquals(4, readCount);
//        out.flip();
//        Assert.assertEquals(42, out.getInt());
//        Assert.assertEquals(12, inputPlus.unsafeAvailable());

//        out = ByteBuffer.allocate(8);
//        readCount = inputPlus.read(out);
//        Assert.assertEquals(8, readCount);
//        out.flip();
//        Assert.assertEquals(42, out.getLong());
//        Assert.assertEquals(4, inputPlus.unsafeAvailable());
    }
",non-flaky,5
99750,apache_cassandra,AsyncStreamingInputPlusTest.read_closed,"//    @Test (expected = EOFException.class)
//    public void read_closed() throws IOException
//    {
//        inputPlus.requestClosure();
//        ByteBuffer buf = ByteBuffer.allocate(1);
//        inputPlus.read(buf);
//    }
",non-flaky,5
99751,apache_cassandra,AsyncStreamingInputPlusTest.available_closed,"    @Test
    public void available_closed()
    {
        inputPlus = new AsyncStreamingInputPlus(channel);
        inputPlus.requestClosure();
        inputPlus.unsafeAvailable();
    }
",non-flaky,5
99752,apache_cassandra,AsyncStreamingInputPlusTest.available_HappyPath,"    @Test
    public void available_HappyPath()
    {
        inputPlus = new AsyncStreamingInputPlus(channel);
        int size = 4;
        buf = channel.alloc().heapBuffer(size);
        buf.writerIndex(size);
        inputPlus.append(buf);
        Assert.assertEquals(size, inputPlus.unsafeAvailable());
    }
",non-flaky,5
99753,apache_cassandra,AsyncStreamingInputPlusTest.available_ClosedButWithBytes,"    @Test
    public void available_ClosedButWithBytes()
    {
        inputPlus = new AsyncStreamingInputPlus(channel);
        int size = 4;
        buf = channel.alloc().heapBuffer(size);
        buf.writerIndex(size);
        inputPlus.append(buf);
        inputPlus.requestClosure();
        Assert.assertEquals(size, inputPlus.unsafeAvailable());
    }
",non-flaky,5
99754,apache_cassandra,AsyncStreamingInputPlusTest.consumeUntil_SingleBuffer_Partial_HappyPath,"    @Test
    public void consumeUntil_SingleBuffer_Partial_HappyPath() throws IOException
    {
        consumeUntilTestCycle(1, 8, 0, 4);
    }
",non-flaky,5
99755,apache_cassandra,AsyncStreamingInputPlusTest.consumeUntil_SingleBuffer_AllBytes_HappyPath,"    @Test
    public void consumeUntil_SingleBuffer_AllBytes_HappyPath() throws IOException
    {
        consumeUntilTestCycle(1, 8, 0, 8);
    }
",non-flaky,5
99756,apache_cassandra,AsyncStreamingInputPlusTest.consumeUntil_MultipleBufferr_Partial_HappyPath,"    @Test
    public void consumeUntil_MultipleBufferr_Partial_HappyPath() throws IOException
    {
        consumeUntilTestCycle(2, 8, 0, 13);
    }
",non-flaky,5
99757,apache_cassandra,AsyncStreamingInputPlusTest.consumeUntil_MultipleBuffer_AllBytes_HappyPath,"    @Test
    public void consumeUntil_MultipleBuffer_AllBytes_HappyPath() throws IOException
    {
        consumeUntilTestCycle(2, 8, 0, 16);
    }
",non-flaky,5
99758,apache_cassandra,AsyncStreamingInputPlusTest.consumeUntil_SingleBuffer_Fails,"    @Test(expected = EOFException.class)
    public void consumeUntil_SingleBuffer_Fails() throws IOException
    {
        consumeUntilTestCycle(1, 8, 0, 9);
    }
",non-flaky,5
99759,apache_cassandra,AsyncStreamingInputPlusTest.consumeUntil_MultipleBuffer_Fails,"    @Test(expected = EOFException.class)
    public void consumeUntil_MultipleBuffer_Fails() throws IOException
    {
        consumeUntilTestCycle(2, 8, 0, 17);
    }
",non-flaky,5
99760,apache_cassandra,AsyncStreamingInputPlusTest.rebufferTimeout,"    @Test
    public void rebufferTimeout() throws IOException
    {
        long timeoutMillis = 1000;
        inputPlus = new AsyncStreamingInputPlus(channel, timeoutMillis, TimeUnit.MILLISECONDS);

        long startNanos = System.nanoTime();
        try
        {
            inputPlus.readInt();
            Assert.fail(""should not have been able to read from the queue"");
        }
        catch (InputTimeoutException e)
        {
            // this is the success case, and is expected. any other exception is a failure.
        }

        long durationNanos = System.nanoTime() - startNanos;
        Assert.assertTrue(TimeUnit.MILLISECONDS.toNanos(timeoutMillis) <= durationNanos);
    }
",non-flaky,5
99761,apache_cassandra,RateBasedBackPressureTest.testAcceptsNoLessThanThreeArguments,"    @Test(expected = IllegalArgumentException.class)
    public void testAcceptsNoLessThanThreeArguments() throws Exception
    {
        new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""1""), new TestTimeSource(), 10);
    }
",non-flaky,5
99762,apache_cassandra,RateBasedBackPressureTest.testHighRatioMustBeBiggerThanZero,"    @Test(expected = IllegalArgumentException.class)
    public void testHighRatioMustBeBiggerThanZero() throws Exception
    {
        new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""0"", FACTOR, ""2"", FLOW, ""FAST""), new TestTimeSource(), 10);
    }
",non-flaky,5
99763,apache_cassandra,RateBasedBackPressureTest.testHighRatioMustBeSmallerEqualThanOne,"    @Test(expected = IllegalArgumentException.class)
    public void testHighRatioMustBeSmallerEqualThanOne() throws Exception
    {
        new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""2"", FACTOR, ""2"", FLOW, ""FAST""), new TestTimeSource(), 10);
    }
",non-flaky,5
99764,apache_cassandra,RateBasedBackPressureTest.testFactorMustBeBiggerEqualThanOne,"    @Test(expected = IllegalArgumentException.class)
    public void testFactorMustBeBiggerEqualThanOne() throws Exception
    {
        new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""0"", FLOW, ""FAST""), new TestTimeSource(), 10);
    }
",non-flaky,5
99765,apache_cassandra,RateBasedBackPressureTest.testWindowSizeMustBeBiggerEqualThanTen,"    @Test(expected = IllegalArgumentException.class)
    public void testWindowSizeMustBeBiggerEqualThanTen() throws Exception
    {
        new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""5"", FLOW, ""FAST""), new TestTimeSource(), 1);
    }
",non-flaky,5
99766,apache_cassandra,RateBasedBackPressureTest.testFlowMustBeEitherFASTorSLOW,"    @Test
    public void testFlowMustBeEitherFASTorSLOW() throws Exception
    {
        new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""1"", FLOW, ""FAST""), new TestTimeSource(), 10);
        new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""1"", FLOW, ""SLOW""), new TestTimeSource(), 10);
        try
        {
            new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""1"", FLOW, ""WRONG""), new TestTimeSource(), 10);
            fail(""Expected to fail with wrong flow type."");
        }
        catch (Exception ex)
        {
        }
    }
",non-flaky,5
99767,apache_cassandra,RateBasedBackPressureTest.testBackPressureStateUpdates,"    @Test
    public void testBackPressureStateUpdates()
    {
        long windowSize = 6000;
        TestTimeSource timeSource = new TestTimeSource();
        RateBasedBackPressure strategy = new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""10"", FLOW, ""FAST""), timeSource, windowSize);

        RateBasedBackPressureState state = strategy.newState(InetAddressAndPort.getLoopbackAddress());
        state.onMessageSent(null);
        assertEquals(0, state.incomingRate.size());
        assertEquals(0, state.outgoingRate.size());

        state = strategy.newState(InetAddressAndPort.getLoopbackAddress());
        state.onResponseReceived();
        assertEquals(1, state.incomingRate.size());
        assertEquals(1, state.outgoingRate.size());

        state = strategy.newState(InetAddressAndPort.getLoopbackAddress());
        state.onResponseTimeout();
        assertEquals(0, state.incomingRate.size());
        assertEquals(1, state.outgoingRate.size());
    }
",non-flaky,5
99768,apache_cassandra,RateBasedBackPressureTest.testBackPressureIsNotUpdatedBeyondInfinity,"    @Test
    public void testBackPressureIsNotUpdatedBeyondInfinity() throws Exception
    {
        long windowSize = 6000;
        TestTimeSource timeSource = new TestTimeSource();
        RateBasedBackPressure strategy = new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""10"", FLOW, ""FAST""), timeSource, windowSize);
        RateBasedBackPressureState state = strategy.newState(InetAddressAndPort.getLoopbackAddress());

        // Get initial rate:
        double initialRate = state.rateLimiter.getRate();
        assertEquals(Double.POSITIVE_INFINITY, initialRate, 0.0);

        // Update incoming and outgoing rate equally:
        state.incomingRate.update(1);
        state.outgoingRate.update(1);

        // Move time ahead:
        timeSource.sleep(windowSize, TimeUnit.MILLISECONDS);

        // Verify the rate doesn't change because already at infinity:
        strategy.apply(Sets.newHashSet(state), 1, TimeUnit.SECONDS);
        assertEquals(initialRate, state.rateLimiter.getRate(), 0.0);
    }
",non-flaky,5
99769,apache_cassandra,RateBasedBackPressureTest.testBackPressureIsUpdatedOncePerWindowSize,"    @Test
    public void testBackPressureIsUpdatedOncePerWindowSize() throws Exception
    {
        long windowSize = 6000;
        TestTimeSource timeSource = new TestTimeSource();
        RateBasedBackPressure strategy = new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""10"", FLOW, ""FAST""), timeSource, windowSize);
        RateBasedBackPressureState state = strategy.newState(InetAddressAndPort.getLoopbackAddress());

        // Get initial time:
        long current = state.getLastIntervalAcquire();
        assertEquals(0, current);

        // Update incoming and outgoing rate:
        state.incomingRate.update(1);
        state.outgoingRate.update(1);

        // Move time ahead by window size:
        timeSource.sleep(windowSize, TimeUnit.MILLISECONDS);

        // Verify the timestamp changed:
        strategy.apply(Sets.newHashSet(state), 1, TimeUnit.SECONDS);
        current = state.getLastIntervalAcquire();
        assertEquals(timeSource.currentTimeMillis(), current);

        // Move time ahead by less than interval:
        long previous = current;
        timeSource.sleep(windowSize / 2, TimeUnit.MILLISECONDS);

        // Verify the last timestamp didn't change because below the window size:
        strategy.apply(Sets.newHashSet(state), 1, TimeUnit.SECONDS);
        current = state.getLastIntervalAcquire();
        assertEquals(previous, current);
    }
",non-flaky,5
99770,apache_cassandra,RateBasedBackPressureTest.testBackPressureWhenBelowHighRatio,"    @Test
    public void testBackPressureWhenBelowHighRatio() throws Exception
    {
        long windowSize = 6000;
        TestTimeSource timeSource = new TestTimeSource();
        RateBasedBackPressure strategy = new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""10"", FLOW, ""FAST""), timeSource, windowSize);
        RateBasedBackPressureState state = strategy.newState(InetAddressAndPort.getLoopbackAddress());

        // Update incoming and outgoing rate so that the ratio is 0.5:
        state.incomingRate.update(50);
        state.outgoingRate.update(100);

        // Move time ahead:
        timeSource.sleep(windowSize, TimeUnit.MILLISECONDS);

        // Verify the rate is decreased by factor:
        strategy.apply(Sets.newHashSet(state), 1, TimeUnit.SECONDS);
        assertEquals(7.4, state.rateLimiter.getRate(), 0.1);
    }
",non-flaky,5
99771,apache_cassandra,RateBasedBackPressureTest.testBackPressureRateLimiterIsIncreasedAfterGoingAgainAboveHighRatio,"    @Test
    public void testBackPressureRateLimiterIsIncreasedAfterGoingAgainAboveHighRatio() throws Exception
    {
        long windowSize = 6000;
        TestTimeSource timeSource = new TestTimeSource();
        RateBasedBackPressure strategy = new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""10"", FLOW, ""FAST""), timeSource, windowSize);
        RateBasedBackPressureState state = strategy.newState(InetAddressAndPort.getLoopbackAddress());

        // Update incoming and outgoing rate so that the ratio is 0.5:
        state.incomingRate.update(50);
        state.outgoingRate.update(100);

        // Move time ahead:
        timeSource.sleep(windowSize, TimeUnit.MILLISECONDS);

        // Verify the rate decreased:
        strategy.apply(Sets.newHashSet(state), 1, TimeUnit.SECONDS);
        assertEquals(7.4, state.rateLimiter.getRate(), 0.1);

        // Update incoming and outgoing rate back above high rate:
        state.incomingRate.update(50);
        state.outgoingRate.update(50);

        // Move time ahead:
        timeSource.sleep(windowSize, TimeUnit.MILLISECONDS);

        // Verify rate limiter is increased by factor:
        strategy.apply(Sets.newHashSet(state), 1, TimeUnit.SECONDS);
        assertEquals(8.25, state.rateLimiter.getRate(), 0.1);

        // Update incoming and outgoing rate to keep it below the limiter rate:
        state.incomingRate.update(1);
        state.outgoingRate.update(1);

        // Move time ahead:
        timeSource.sleep(windowSize, TimeUnit.MILLISECONDS);

        // Verify rate limiter is not increased as already higher than the actual rate:
        strategy.apply(Sets.newHashSet(state), 1, TimeUnit.SECONDS);
        assertEquals(8.25, state.rateLimiter.getRate(), 0.1);
    }
",non-flaky,5
99772,apache_cassandra,RateBasedBackPressureTest.testBackPressureFastFlow,"    @Test
    public void testBackPressureFastFlow() throws Exception
    {
        long windowSize = 6000;
        TestTimeSource timeSource = new TestTimeSource();
        TestableBackPressure strategy = new TestableBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""10"", FLOW, ""FAST""), timeSource, windowSize);
        RateBasedBackPressureState state1 = strategy.newState(InetAddressAndPort.getByName(""127.0.0.1""));
        RateBasedBackPressureState state2 = strategy.newState(InetAddressAndPort.getByName(""127.0.0.2""));
        RateBasedBackPressureState state3 = strategy.newState(InetAddressAndPort.getByName(""127.0.0.3""));

        // Update incoming and outgoing rates:
        state1.incomingRate.update(50);
        state1.outgoingRate.update(100);
        state2.incomingRate.update(80); // fast
        state2.outgoingRate.update(100);
        state3.incomingRate.update(20);
        state3.outgoingRate.update(100);

        // Move time ahead:
        timeSource.sleep(windowSize, TimeUnit.MILLISECONDS);

        // Verify the fast replica rate limiting has been applied:
        Set<RateBasedBackPressureState> replicaGroup = Sets.newHashSet(state1, state2, state3);
        strategy.apply(replicaGroup, 1, TimeUnit.SECONDS);
        assertTrue(strategy.checkAcquired());
        assertTrue(strategy.checkApplied());
        assertEquals(12.0, strategy.getRateLimiterForReplicaGroup(replicaGroup).getRate(), 0.1);
    }
",non-flaky,5
99773,apache_cassandra,RateBasedBackPressureTest.testBackPressureSlowFlow,"    @Test
    public void testBackPressureSlowFlow() throws Exception
    {
        long windowSize = 6000;
        TestTimeSource timeSource = new TestTimeSource();
        TestableBackPressure strategy = new TestableBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""10"", FLOW, ""SLOW""), timeSource, windowSize);
        RateBasedBackPressureState state1 = strategy.newState(InetAddressAndPort.getByName(""127.0.0.1""));
        RateBasedBackPressureState state2 = strategy.newState(InetAddressAndPort.getByName(""127.0.0.2""));
        RateBasedBackPressureState state3 = strategy.newState(InetAddressAndPort.getByName(""127.0.0.3""));

        // Update incoming and outgoing rates:
        state1.incomingRate.update(50);
        state1.outgoingRate.update(100);
        state2.incomingRate.update(100);
        state2.outgoingRate.update(100);
        state3.incomingRate.update(20); // slow
        state3.outgoingRate.update(100);

        // Move time ahead:
        timeSource.sleep(windowSize, TimeUnit.MILLISECONDS);

        // Verify the slow replica rate limiting has been applied:
        Set<RateBasedBackPressureState> replicaGroup = Sets.newHashSet(state1, state2, state3);
        strategy.apply(replicaGroup, 1, TimeUnit.SECONDS);
        assertTrue(strategy.checkAcquired());
        assertTrue(strategy.checkApplied());
        assertEquals(3.0, strategy.getRateLimiterForReplicaGroup(replicaGroup).getRate(), 0.1);
    }
",non-flaky,5
99774,apache_cassandra,RateBasedBackPressureTest.testBackPressureWithDifferentGroups,"    @Test
    public void testBackPressureWithDifferentGroups() throws Exception
    {
        long windowSize = 6000;
        TestTimeSource timeSource = new TestTimeSource();
        TestableBackPressure strategy = new TestableBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""10"", FLOW, ""SLOW""), timeSource, windowSize);
        RateBasedBackPressureState state1 = strategy.newState(InetAddressAndPort.getByName(""127.0.0.1""));
        RateBasedBackPressureState state2 = strategy.newState(InetAddressAndPort.getByName(""127.0.0.2""));
        RateBasedBackPressureState state3 = strategy.newState(InetAddressAndPort.getByName(""127.0.0.3""));
        RateBasedBackPressureState state4 = strategy.newState(InetAddressAndPort.getByName(""127.0.0.4""));

        // Update incoming and outgoing rates:
        state1.incomingRate.update(50); // this
        state1.outgoingRate.update(100);
        state2.incomingRate.update(100);
        state2.outgoingRate.update(100);
        state3.incomingRate.update(20); // this
        state3.outgoingRate.update(100);
        state4.incomingRate.update(80);
        state4.outgoingRate.update(100);

        // Move time ahead:
        timeSource.sleep(windowSize, TimeUnit.MILLISECONDS);

        // Verify the first group:
        Set<RateBasedBackPressureState> replicaGroup = Sets.newHashSet(state1, state2);
        strategy.apply(replicaGroup, 1, TimeUnit.SECONDS);
        assertTrue(strategy.checkAcquired());
        assertTrue(strategy.checkApplied());
        assertEquals(7.4, strategy.getRateLimiterForReplicaGroup(replicaGroup).getRate(), 0.1);

        // Verify the second group:
        replicaGroup = Sets.newHashSet(state3, state4);
        strategy.apply(replicaGroup, 1, TimeUnit.SECONDS);
        assertTrue(strategy.checkAcquired());
        assertTrue(strategy.checkApplied());
        assertEquals(3.0, strategy.getRateLimiterForReplicaGroup(replicaGroup).getRate(), 0.1);
    }
",non-flaky,5
99775,apache_cassandra,RateBasedBackPressureTest.testBackPressurePastTimeout,"    @Test
    public void testBackPressurePastTimeout() throws Exception
    {
        long windowSize = 10000;
        TestTimeSource timeSource = new TestTimeSource();
        TestableBackPressure strategy = new TestableBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""10"", FLOW, ""SLOW""), timeSource, windowSize);
        RateBasedBackPressureState state1 = strategy.newState(InetAddressAndPort.getByName(""127.0.0.1""));
        RateBasedBackPressureState state2 = strategy.newState(InetAddressAndPort.getByName(""127.0.0.2""));
        RateBasedBackPressureState state3 = strategy.newState(InetAddressAndPort.getByName(""127.0.0.3""));

        // Update incoming and outgoing rates:
        state1.incomingRate.update(5); // slow
        state1.outgoingRate.update(100);
        state2.incomingRate.update(100);
        state2.outgoingRate.update(100);
        state3.incomingRate.update(100);
        state3.outgoingRate.update(100);

        // Move time ahead:
        timeSource.sleep(windowSize, TimeUnit.MILLISECONDS);

        // Verify the slow replica rate limiting has been applied:
        Set<RateBasedBackPressureState> replicaGroup = Sets.newHashSet(state1, state2, state3);
        strategy.apply(replicaGroup, 4, TimeUnit.SECONDS);
        assertTrue(strategy.checkAcquired());
        assertTrue(strategy.checkApplied());
        assertEquals(0.5, strategy.getRateLimiterForReplicaGroup(replicaGroup).getRate(), 0.1);

        // Make one more apply call to saturate the rate limit timeout (0.5 requests per second means 2 requests span
        // 4 seconds, but we can only make one as we have to subtract the incoming response time):
        strategy.apply(replicaGroup, 4, TimeUnit.SECONDS);

        // Now verify another call to apply doesn't acquire the rate limit because of the max timeout of 4 seconds minus
        // 2 seconds of response time, so the time source itself sleeps two second:
        long start = timeSource.currentTimeMillis();
        strategy.apply(replicaGroup, 4, TimeUnit.SECONDS);
        assertFalse(strategy.checkAcquired());
        assertTrue(strategy.checkApplied());
        assertEquals(TimeUnit.NANOSECONDS.convert(2, TimeUnit.SECONDS),
                     strategy.timeout);
        assertEquals(strategy.timeout,
                     TimeUnit.NANOSECONDS.convert(timeSource.currentTimeMillis() - start, TimeUnit.MILLISECONDS));
    }
",non-flaky,5
99776,apache_cassandra,MessagingServiceTest.testDroppedMessages,"    @Test
    public void testDroppedMessages()
    {
        Verb verb = Verb.READ_REQ;

        for (int i = 1; i <= 5000; i++)
            messagingService.metrics.recordDroppedMessage(verb, i, MILLISECONDS, i % 2 == 0);

        List<String> logs = new ArrayList<>();
        messagingService.metrics.resetAndConsumeDroppedErrors(logs::add);
        assertEquals(1, logs.size());
        Pattern regexp = Pattern.compile(""READ_REQ messages were dropped in last 5000 ms: (\\d+) internal and (\\d+) cross node. Mean internal dropped latency: (\\d+) ms and Mean cross-node dropped latency: (\\d+) ms"");
        Matcher matcher = regexp.matcher(logs.get(0));
        assertTrue(matcher.find());
        assertEquals(2500, Integer.parseInt(matcher.group(1)));
        assertEquals(2500, Integer.parseInt(matcher.group(2)));
        assertTrue(Integer.parseInt(matcher.group(3)) > 0);
        assertTrue(Integer.parseInt(matcher.group(4)) > 0);
        assertEquals(5000, (int) messagingService.metrics.getDroppedMessages().get(verb.toString()));

        logs.clear();
        messagingService.metrics.resetAndConsumeDroppedErrors(logs::add);
        assertEquals(0, logs.size());

        for (int i = 0; i < 2500; i++)
            messagingService.metrics.recordDroppedMessage(verb, i, MILLISECONDS, i % 2 == 0);

        logs.clear();
        messagingService.metrics.resetAndConsumeDroppedErrors(logs::add);
        assertEquals(1, logs.size());
        matcher = regexp.matcher(logs.get(0));
        assertTrue(matcher.find());
        assertEquals(1250, Integer.parseInt(matcher.group(1)));
        assertEquals(1250, Integer.parseInt(matcher.group(2)));
        assertTrue(Integer.parseInt(matcher.group(3)) > 0);
        assertTrue(Integer.parseInt(matcher.group(4)) > 0);
        assertEquals(7500, (int) messagingService.metrics.getDroppedMessages().get(verb.toString()));
    }
",non-flaky,5
99777,apache_cassandra,MessagingServiceTest.testDCLatency,"    @Test
    public void testDCLatency() throws Exception
    {
        int latency = 100;
        ConcurrentHashMap<String, MessagingMetrics.DCLatencyRecorder> dcLatency = MessagingService.instance().metrics.dcLatency;
        dcLatency.clear();

        long now = System.currentTimeMillis();
        long sentAt = now - latency;
        assertNull(dcLatency.get(""datacenter1""));
        addDCLatency(sentAt, now);
        assertNotNull(dcLatency.get(""datacenter1""));
        assertEquals(1, dcLatency.get(""datacenter1"").dcLatency.getCount());
        long expectedBucket = bucketOffsets[Math.abs(Arrays.binarySearch(bucketOffsets, MILLISECONDS.toNanos(latency))) - 1];
        assertEquals(expectedBucket, dcLatency.get(""datacenter1"").dcLatency.getSnapshot().getMax());
    }
",non-flaky,5
99778,apache_cassandra,MessagingServiceTest.testNegativeDCLatency,"    @Test
    public void testNegativeDCLatency()
    {
        MessagingMetrics.DCLatencyRecorder updater = MessagingService.instance().metrics.internodeLatencyRecorder(InetAddressAndPort.getLocalHost());

        // if clocks are off should just not track anything
        int latency = -100;

        long now = System.currentTimeMillis();
        long sentAt = now - latency;

        long count = updater.dcLatency.getCount();
        updater.accept(now - sentAt, MILLISECONDS);
        // negative value shoudln't be recorded
        assertEquals(count, updater.dcLatency.getCount());
    }
",non-flaky,5
99779,apache_cassandra,MessagingServiceTest.testQueueWaitLatency,"    @Test
    public void testQueueWaitLatency()
    {
        int latency = 100;
        Verb verb = Verb.MUTATION_REQ;

        Map<Verb, Timer> queueWaitLatency = MessagingService.instance().metrics.internalLatency;
        MessagingService.instance().metrics.recordInternalLatency(verb, latency, MILLISECONDS);
        assertEquals(1, queueWaitLatency.get(verb).getCount());
        long expectedBucket = bucketOffsets[Math.abs(Arrays.binarySearch(bucketOffsets, MILLISECONDS.toNanos(latency))) - 1];
        assertEquals(expectedBucket, queueWaitLatency.get(verb).getSnapshot().getMax());
    }
",non-flaky,5
99780,apache_cassandra,MessagingServiceTest.testNegativeQueueWaitLatency,"    @Test
    public void testNegativeQueueWaitLatency() throws Exception
    {
        int latency = -100;
        Verb verb = Verb.MUTATION_REQ;

        Map<Verb, Timer> queueWaitLatency = MessagingService.instance().metrics.internalLatency;
        queueWaitLatency.clear();

        assertNull(queueWaitLatency.get(verb));
        MessagingService.instance().metrics.recordInternalLatency(verb, latency, MILLISECONDS);
        assertNull(queueWaitLatency.get(verb));
    }
",non-flaky,5
99781,apache_cassandra,MessagingServiceTest.testUpdatesBackPressureOnSendWhenEnabledAndWithSupportedCallback,"    @Test
    public void testUpdatesBackPressureOnSendWhenEnabledAndWithSupportedCallback() throws UnknownHostException
    {
        MockBackPressureStrategy.MockBackPressureState backPressureState = (MockBackPressureStrategy.MockBackPressureState) messagingService.getBackPressureState(InetAddressAndPort.getByName(""127.0.0.2""));
        RequestCallback bpCallback = new BackPressureCallback();
        RequestCallback noCallback = new NoBackPressureCallback();
        Message<?> ignored = null;

        DatabaseDescriptor.setBackPressureEnabled(true);
        messagingService.updateBackPressureOnSend(InetAddressAndPort.getByName(""127.0.0.2""), noCallback, ignored);
        assertFalse(backPressureState.onSend);

        DatabaseDescriptor.setBackPressureEnabled(false);
        messagingService.updateBackPressureOnSend(InetAddressAndPort.getByName(""127.0.0.2""), bpCallback, ignored);
        assertFalse(backPressureState.onSend);

        DatabaseDescriptor.setBackPressureEnabled(true);
        messagingService.updateBackPressureOnSend(InetAddressAndPort.getByName(""127.0.0.2""), bpCallback, ignored);
        assertTrue(backPressureState.onSend);
    }
",non-flaky,5
99782,apache_cassandra,MessagingServiceTest.testUpdatesBackPressureOnReceiveWhenEnabledAndWithSupportedCallback,"    @Test
    public void testUpdatesBackPressureOnReceiveWhenEnabledAndWithSupportedCallback() throws UnknownHostException
    {
        MockBackPressureStrategy.MockBackPressureState backPressureState = (MockBackPressureStrategy.MockBackPressureState) messagingService.getBackPressureState(InetAddressAndPort.getByName(""127.0.0.2""));
        RequestCallback bpCallback = new BackPressureCallback();
        RequestCallback noCallback = new NoBackPressureCallback();
        boolean timeout = false;

        DatabaseDescriptor.setBackPressureEnabled(true);
        messagingService.updateBackPressureOnReceive(InetAddressAndPort.getByName(""127.0.0.2""), noCallback, timeout);
        assertFalse(backPressureState.onReceive);
        assertFalse(backPressureState.onTimeout);

        DatabaseDescriptor.setBackPressureEnabled(false);
        messagingService.updateBackPressureOnReceive(InetAddressAndPort.getByName(""127.0.0.2""), bpCallback, timeout);
        assertFalse(backPressureState.onReceive);
        assertFalse(backPressureState.onTimeout);

        DatabaseDescriptor.setBackPressureEnabled(true);
        messagingService.updateBackPressureOnReceive(InetAddressAndPort.getByName(""127.0.0.2""), bpCallback, timeout);
        assertTrue(backPressureState.onReceive);
        assertFalse(backPressureState.onTimeout);
    }
",non-flaky,5
99783,apache_cassandra,MessagingServiceTest.testUpdatesBackPressureOnTimeoutWhenEnabledAndWithSupportedCallback,"    @Test
    public void testUpdatesBackPressureOnTimeoutWhenEnabledAndWithSupportedCallback() throws UnknownHostException
    {
        MockBackPressureStrategy.MockBackPressureState backPressureState = (MockBackPressureStrategy.MockBackPressureState) messagingService.getBackPressureState(InetAddressAndPort.getByName(""127.0.0.2""));
        RequestCallback bpCallback = new BackPressureCallback();
        RequestCallback noCallback = new NoBackPressureCallback();
        boolean timeout = true;

        DatabaseDescriptor.setBackPressureEnabled(true);
        messagingService.updateBackPressureOnReceive(InetAddressAndPort.getByName(""127.0.0.2""), noCallback, timeout);
        assertFalse(backPressureState.onReceive);
        assertFalse(backPressureState.onTimeout);

        DatabaseDescriptor.setBackPressureEnabled(false);
        messagingService.updateBackPressureOnReceive(InetAddressAndPort.getByName(""127.0.0.2""), bpCallback, timeout);
        assertFalse(backPressureState.onReceive);
        assertFalse(backPressureState.onTimeout);

        DatabaseDescriptor.setBackPressureEnabled(true);
        messagingService.updateBackPressureOnReceive(InetAddressAndPort.getByName(""127.0.0.2""), bpCallback, timeout);
        assertFalse(backPressureState.onReceive);
        assertTrue(backPressureState.onTimeout);
    }
",non-flaky,5
99784,apache_cassandra,MessagingServiceTest.testAppliesBackPressureWhenEnabled,"    @Test
    public void testAppliesBackPressureWhenEnabled() throws UnknownHostException
    {
        DatabaseDescriptor.setBackPressureEnabled(false);
        messagingService.applyBackPressure(Arrays.asList(InetAddressAndPort.getByName(""127.0.0.2"")), ONE_SECOND);
        assertFalse(MockBackPressureStrategy.applied);

        DatabaseDescriptor.setBackPressureEnabled(true);
        messagingService.applyBackPressure(Arrays.asList(InetAddressAndPort.getByName(""127.0.0.2"")), ONE_SECOND);
        assertTrue(MockBackPressureStrategy.applied);
    }
",non-flaky,5
99785,apache_cassandra,MessagingServiceTest.testDoesntApplyBackPressureToBroadcastAddress,"    @Test
    public void testDoesntApplyBackPressureToBroadcastAddress() throws UnknownHostException
    {
        DatabaseDescriptor.setBackPressureEnabled(true);
        messagingService.applyBackPressure(Arrays.asList(InetAddressAndPort.getByName(""127.0.0.1"")), ONE_SECOND);
        assertFalse(MockBackPressureStrategy.applied);
    }
",non-flaky,5
99786,apache_cassandra,MessagingServiceTest.testFailedInternodeAuth,"    @Test
    public void testFailedInternodeAuth() throws Exception
    {
        MessagingService ms = MessagingService.instance();
        DatabaseDescriptor.setInternodeAuthenticator(ALLOW_NOTHING_AUTHENTICATOR);
        InetAddressAndPort address = InetAddressAndPort.getByName(""127.0.0.250"");

        //Should return null
        Message messageOut = Message.out(Verb.ECHO_REQ, NoPayload.noPayload);
        assertFalse(ms.isConnected(address, messageOut));

        //Should tolerate null
        ms.closeOutbound(address);
        ms.send(messageOut, address);
    }
",non-flaky,5
99787,apache_cassandra,MessagingServiceTest.reconnectWithNewIp,"//    @Test
//    public void reconnectWithNewIp() throws Exception
//    {
//        InetAddressAndPort publicIp = InetAddressAndPort.getByName(""127.0.0.2"");
//        InetAddressAndPort privateIp = InetAddressAndPort.getByName(""127.0.0.3"");
//
//        // reset the preferred IP value, for good test hygene
//        SystemKeyspace.updatePreferredIP(publicIp, publicIp);
//
//        // create pool/conn with public addr
//        Assert.assertEquals(publicIp, messagingService.getCurrentEndpoint(publicIp));
//        messagingService.maybeReconnectWithNewIp(publicIp, privateIp).await(1L, TimeUnit.SECONDS);
//        Assert.assertEquals(privateIp, messagingService.getCurrentEndpoint(publicIp));
//
//        messagingService.closeOutbound(publicIp);
//
//        // recreate the pool/conn, and make sure the preferred ip addr is used
//        Assert.assertEquals(privateIp, messagingService.getCurrentEndpoint(publicIp));
//    }
",non-flaky,5
99788,apache_cassandra,MessagingServiceTest.listenPlainConnection,"    @Test
    public void listenPlainConnection() throws InterruptedException
    {
        ServerEncryptionOptions serverEncryptionOptions = new ServerEncryptionOptions()
                                                          .withInternodeEncryption(ServerEncryptionOptions.InternodeEncryption.none);
        listen(serverEncryptionOptions, false);
    }
",non-flaky,5
99789,apache_cassandra,MessagingServiceTest.listenPlainConnectionWithBroadcastAddr,"    @Test
    public void listenPlainConnectionWithBroadcastAddr() throws InterruptedException
    {
        ServerEncryptionOptions serverEncryptionOptions = new ServerEncryptionOptions()
                                                          .withInternodeEncryption(ServerEncryptionOptions.InternodeEncryption.none);
        listen(serverEncryptionOptions, true);
    }
",non-flaky,5
99790,apache_cassandra,MessagingServiceTest.listenRequiredSecureConnection,"    @Test
    public void listenRequiredSecureConnection() throws InterruptedException
    {
        ServerEncryptionOptions serverEncryptionOptions = new ServerEncryptionOptions()
                                                          .withOptional(false)
                                                          .withInternodeEncryption(ServerEncryptionOptions.InternodeEncryption.all)
                                                          .withLegacySslStoragePort(false);
        listen(serverEncryptionOptions, false);
    }
",non-flaky,5
99791,apache_cassandra,MessagingServiceTest.listenRequiredSecureConnectionWithBroadcastAddr,"    @Test
    public void listenRequiredSecureConnectionWithBroadcastAddr() throws InterruptedException
    {
        ServerEncryptionOptions serverEncryptionOptions = new ServerEncryptionOptions()
                                                          .withOptional(false)
                                                          .withInternodeEncryption(ServerEncryptionOptions.InternodeEncryption.all)
                                                          .withLegacySslStoragePort(false);
        listen(serverEncryptionOptions, true);
    }
",non-flaky,5
99792,apache_cassandra,MessagingServiceTest.listenRequiredSecureConnectionWithLegacyPort,"    @Test
    public void listenRequiredSecureConnectionWithLegacyPort() throws InterruptedException
    {
        ServerEncryptionOptions serverEncryptionOptions = new ServerEncryptionOptions()
                                                          .withInternodeEncryption(ServerEncryptionOptions.InternodeEncryption.all)
                                                          .withOptional(false)
                                                          .withLegacySslStoragePort(true);
        listen(serverEncryptionOptions, false);
    }
",non-flaky,5
99793,apache_cassandra,MessagingServiceTest.listenRequiredSecureConnectionWithBroadcastAddrAndLegacyPort,"    @Test
    public void listenRequiredSecureConnectionWithBroadcastAddrAndLegacyPort() throws InterruptedException
    {
        ServerEncryptionOptions serverEncryptionOptions = new ServerEncryptionOptions()
                                                          .withInternodeEncryption(ServerEncryptionOptions.InternodeEncryption.all)
                                                          .withOptional(false)
                                                          .withLegacySslStoragePort(true);
        listen(serverEncryptionOptions, true);
    }
",non-flaky,5
99794,apache_cassandra,MessagingServiceTest.listenOptionalSecureConnection,"    @Test
    public void listenOptionalSecureConnection() throws InterruptedException
    {
        ServerEncryptionOptions serverEncryptionOptions = new ServerEncryptionOptions()
                                                          .withOptional(true);
        listen(serverEncryptionOptions, false);
    }
",non-flaky,5
99795,apache_cassandra,MessagingServiceTest.listenOptionalSecureConnectionWithBroadcastAddr,"    @Test
    public void listenOptionalSecureConnectionWithBroadcastAddr() throws InterruptedException
    {
        ServerEncryptionOptions serverEncryptionOptions = new ServerEncryptionOptions()
                                                          .withOptional(true);
        listen(serverEncryptionOptions, true);
    }
",non-flaky,5
99796,apache_cassandra,MessagingServiceTest.getPreferredRemoteAddrUsesPrivateIp,"//    @Test
//    public void getPreferredRemoteAddrUsesPrivateIp() throws UnknownHostException
//    {
//        MessagingService ms = MessagingService.instance();
//        InetAddressAndPort remote = InetAddressAndPort.getByNameOverrideDefaults(""127.0.0.151"", 7000);
//        InetAddressAndPort privateIp = InetAddressAndPort.getByName(""127.0.0.6"");
//
//        OutboundConnectionSettings template = new OutboundConnectionSettings(remote)
//                                              .withConnectTo(privateIp)
//                                              .withAuthenticator(ALLOW_NOTHING_AUTHENTICATOR);
//        OutboundConnections pool = new OutboundConnections(template, new MockBackPressureStrategy(null).newState(remote));
//        ms.channelManagers.put(remote, pool);
//
//        Assert.assertEquals(privateIp, ms.getPreferredRemoteAddr(remote));
//    }
",non-flaky,5
99797,apache_cassandra,MessagingServiceTest.getPreferredRemoteAddrUsesPreferredIp,"//    @Test
//    public void getPreferredRemoteAddrUsesPreferredIp() throws UnknownHostException
//    {
//        MessagingService ms = MessagingService.instance();
//        InetAddressAndPort remote = InetAddressAndPort.getByNameOverrideDefaults(""127.0.0.115"", 7000);
//
//        InetAddressAndPort preferredIp = InetAddressAndPort.getByName(""127.0.0.16"");
//        SystemKeyspace.updatePreferredIP(remote, preferredIp);
//
//        Assert.assertEquals(preferredIp, ms.getPreferredRemoteAddr(remote));
//    }
",non-flaky,5
99798,apache_cassandra,MessagingServiceTest.getPreferredRemoteAddrUsesPrivateIpOverridesPreferredIp,"//    @Test
//    public void getPreferredRemoteAddrUsesPrivateIpOverridesPreferredIp() throws UnknownHostException
//    {
//        MessagingService ms = MessagingService.instance();
//        InetAddressAndPort local = InetAddressAndPort.getByNameOverrideDefaults(""127.0.0.4"", 7000);
//        InetAddressAndPort remote = InetAddressAndPort.getByNameOverrideDefaults(""127.0.0.105"", 7000);
//        InetAddressAndPort privateIp = InetAddressAndPort.getByName(""127.0.0.6"");
//
//        OutboundConnectionSettings template = new OutboundConnectionSettings(remote)
//                                              .withConnectTo(privateIp)
//                                              .withAuthenticator(ALLOW_NOTHING_AUTHENTICATOR);
//
//        OutboundConnections pool = new OutboundConnections(template, new MockBackPressureStrategy(null).newState(remote));
//        ms.channelManagers.put(remote, pool);
//
//        InetAddressAndPort preferredIp = InetAddressAndPort.getByName(""127.0.0.16"");
//        SystemKeyspace.updatePreferredIP(remote, preferredIp);
//
//        Assert.assertEquals(privateIp, ms.getPreferredRemoteAddr(remote));
//    }
",non-flaky,5
99799,apache_cassandra,OutboundConnectionSettingsTest.build_SmallSendSize,"    @Test (expected = IllegalArgumentException.class)
    public void build_SmallSendSize()
    {
        test(settings -> settings.withSocketSendBufferSizeInBytes(999));
    }
",non-flaky,5
99800,apache_cassandra,OutboundConnectionSettingsTest.build_SendSizeLessThanZero,"    @Test (expected = IllegalArgumentException.class)
    public void build_SendSizeLessThanZero()
    {
        test(settings -> settings.withSocketSendBufferSizeInBytes(-1));
    }
",non-flaky,5
99801,apache_cassandra,OutboundConnectionSettingsTest.build_TcpConnectTimeoutLessThanZero,"    @Test (expected = IllegalArgumentException.class)
    public void build_TcpConnectTimeoutLessThanZero()
    {
        test(settings -> settings.withTcpConnectTimeoutInMS(-1));
    }
",non-flaky,5
110830,opensource4you_astraea,ArgumentUtilTest.testParse,"  @Test
  public void testParse() {
    var param =
        ArgumentUtil.parseArgument(new FakeParameter(), new String[] {""--require"", ""require""});
    Assertions.assertEquals(""require"", param.require);
  }
",non-flaky,5
110831,opensource4you_astraea,ArgumentUtilTest.testRequired,"  @Test
  public void testRequired() {
    Assertions.assertThrows(
        ParameterException.class,
        () -> ArgumentUtil.parseArgument(new FakeParameter(), new String[] {}));
  }
",non-flaky,5
110832,opensource4you_astraea,ArgumentUtilTest.testLongPositive,"  @Test
  public void testLongPositive() {
    var param =
        ArgumentUtil.parseArgument(
            new FakeParameter(), new String[] {""--require"", ""require"", ""--longPositive"", ""1000""});

    Assertions.assertEquals(1000, param.longPositive);
    Assertions.assertThrows(
        ParameterException.class,
        () ->
            ArgumentUtil.parseArgument(
                new FakeParameter(), new String[] {""--require"", ""require"", ""--longPositive"", ""0""}));
  }
",non-flaky,5
110833,opensource4you_astraea,ArgumentUtilTest.testNotNegative,"  @Test
  public void testNotNegative() {
    FakeParameter param =
        ArgumentUtil.parseArgument(
            new FakeParameter(),
            new String[] {""--require"", ""require"", ""--longNotNegative"", ""1000""});

    Assertions.assertEquals(1000, param.longNotNegative);
    Assertions.assertThrows(
        ParameterException.class,
        () ->
            ArgumentUtil.parseArgument(
                new FakeParameter(),
                new String[] {""--require"", ""require"", ""--longNotNegative"", ""-1""}));
  }
",non-flaky,5
110834,opensource4you_astraea,ArgumentUtilTest.testDurationConvert,"  @Test
  public void testDurationConvert() {
    FakeParameter param =
        ArgumentUtil.parseArgument(
            new FakeParameter(),
            new String[] {""--require"", ""require"", ""--durationConvert"", ""1000""});

    Assertions.assertEquals(Duration.ofSeconds(1000), param.durationConvert);
  }
",non-flaky,5
110835,opensource4you_astraea,ArgumentUtilTest.testSetConverter,"  @Test
  public void testSetConverter() {
    FakeParameter param =
        ArgumentUtil.parseArgument(
            new FakeParameter(),
            new String[] {""--require"", ""require"", ""--setConverter"", ""1"", ""1"", ""2""});

    Assertions.assertEquals(Set.of(""1"", ""2""), param.setConverter);
  }
",non-flaky,5
112627,tbsalling_aismessages,AISMessageTest.testEquals,"    @Test
    public void testEquals() {
          assertEquals(AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,13AkSB0000PhAmJPoTMoiQFT0D1:,0*5E"")), AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,13AkSB0000PhAmJPoTMoiQFT0D1:,0*5E"")));
          assertNotEquals(AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,13AkSB0000PhAmJPoTMoiQFT0D1:,0*5E"")), AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,13AkSB0000PhAmHPoTNcp1Fp0D17,0*00"")));
    }
",non-flaky,5
112628,tbsalling_aismessages,AISMessageTest.testEqualsWithMetadata,"    @Test
    public void testEqualsWithMetadata() {
        String source = ""test"";
        Instant time = Instant.now();
        NMEAMessage nmea = NMEAMessage.fromString(""!AIVDM,1,1,,A,13aEOK?P00PD2wVMdLDRhgvL289?,0*26"");

        Metadata meta1 = new Metadata(source, time);
        Metadata meta2 = new Metadata(source, time);
        Metadata meta3 = new Metadata(source, time.plusMillis(1000));

        AISMessage ais1 = AISMessage.create(meta1, nmea);
        AISMessage ais2 = AISMessage.create(meta2, nmea);
        AISMessage ais3 = AISMessage.create(meta3, nmea);

        assertEquals(meta1, meta2);
        assertNotEquals(meta1, meta3);

        assertEquals(ais1, ais2);
        assertNotEquals(ais1, ais3);
    }
",non-flaky,5
112629,tbsalling_aismessages,AISMessageTest.canHandleEmptyMessage,"    @Test(expected = InvalidMessage.class)
    public void canHandleEmptyMessage() {
        AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,00,4*21""));
    }
",non-flaky,5
112630,tbsalling_aismessages,AISMessageTest.canHandleUnparsableNMEAMessage,"    @Test(expected = NMEAParseException.class)
    public void canHandleUnparsableNMEAMessage() {
        AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,13K6th002u9@8P0DEVv2M1up02Pl,0*740008,2*09""));
    }
",non-flaky,5
112631,tbsalling_aismessages,AISMessageTest.isSerializable,"    @Test
    public void isSerializable() {
        // Type 1
        assertTrue(isSerializable(AISMessage.create(
            NMEAMessage.fromString(""!BSVDM,1,1,,A,1:02Ih001U0d=V:Op85<2aT>0<0F,0*3B"")
        )));

        // Type 4
        assertTrue(isSerializable(AISMessage.create(
            NMEAMessage.fromString(""!AIVDM,1,1,,B,4h3Ovk1udp6I9o>jPHEdjdW000S:,0*0C"")
        )));

        // Type 5
        assertTrue(isSerializable(AISMessage.create(
            NMEAMessage.fromString(""!BSVDM,2,1,5,A,5:02Ih01WrRsEH57J20H5P8u8N222222222222167H66663k085QBS1H,0*55""),
            NMEAMessage.fromString(""!BSVDM,2,2,5,A,888888888888880,2*38"")
        )));
    }
",non-flaky,5
112632,tbsalling_aismessages,AISMessageTest.canReturnRawNmeaMessages,"    @Test
    public void canReturnRawNmeaMessages() {
        // Test one-liner
        AISMessage aisMessage = AISMessage.create(
            NMEAMessage.fromString(""!BSVDM,1,1,,A,1:02Ih001U0d=V:Op85<2aT>0<0F,0*3B"")
        );

        NMEAMessage[] nmeaMessages = aisMessage.getNmeaMessages();
        assertNotNull(nmeaMessages);
        assertEquals(1, nmeaMessages.length);
        assertEquals(""!BSVDM,1,1,,A,1:02Ih001U0d=V:Op85<2aT>0<0F,0*3B"", nmeaMessages[0].getRawMessage());

        // Test two-liner
        aisMessage =AISMessage.create(
            NMEAMessage.fromString(""!BSVDM,2,1,5,A,5:02Ih01WrRsEH57J20H5P8u8N222222222222167H66663k085QBS1H,0*55""),
            NMEAMessage.fromString(""!BSVDM,2,2,5,A,888888888888880,2*38"")
        );

        nmeaMessages = aisMessage.getNmeaMessages();
        assertNotNull(nmeaMessages);
        assertEquals(2, nmeaMessages.length);
        assertEquals(""!BSVDM,2,1,5,A,5:02Ih01WrRsEH57J20H5P8u8N222222222222167H66663k085QBS1H,0*55"", nmeaMessages[0].getRawMessage());
        assertEquals(""!BSVDM,2,2,5,A,888888888888880,2*38"", nmeaMessages[1].getRawMessage());
    }
",non-flaky,5
112633,tbsalling_aismessages,ShipAndVoyageDataTest.canDecode1,"    @Test
    public void canDecode1() {
        AISMessage aisMessage = AISMessage.create(
            NMEAMessage.fromString(""!AIVDM,2,1,3,A,55MuUD02;EFUL@CO;W@lU=<U=<U10V1HuT4LE:1DC@T>B4kC0DliSp=t,0*14""),
            NMEAMessage.fromString(""!AIVDM,2,2,3,A,888888888888880,2*27"")
        );

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.ShipAndVoyageRelatedData, aisMessage.getMessageType());
        ShipAndVoyageData message = (ShipAndVoyageData) aisMessage;
        assertEquals(Integer.valueOf(0), message.getRepeatIndicator());
        assertEquals(MMSI.valueOf(366962000), message.getSourceMmsi());
        assertEquals(IMO.valueOf(9131369), message.getImo());
        assertEquals(""WDD7294"", message.getCallsign());
        assertEquals(""MISSISSIPPI VOYAGER"", message.getShipName());
        assertEquals(ShipType.TankerHazardousD, message.getShipType());
        assertEquals(Integer.valueOf(154), message.getToBow());
        assertEquals(Integer.valueOf(36), message.getToStern());
        assertEquals(Integer.valueOf(18), message.getToStarboard());
        assertEquals(Integer.valueOf(14), message.getToPort());
        assertEquals(PositionFixingDevice.Gps, message.getPositionFixingDevice());
        assertEquals(Float.valueOf(""8.3""), message.getDraught());
        assertEquals((Integer) 83 , message.getRawDraught());
        assertEquals(""06-03 19:00"", message.getEta());
        assertEquals((Integer) 3, message.getEtaMonth());
        assertEquals((Integer) 6, message.getEtaDay());
        assertEquals((Integer) 19, message.getEtaHour());
        assertEquals((Integer) 0, message.getEtaMinute());
        assertEquals(Optional.empty(), message.getEtaAfterReceived());
        assertEquals(""SFO 70"", message.getDestination());
        assertFalse(message.getDataTerminalReady());
    }
",non-flaky,5
112634,tbsalling_aismessages,ShipAndVoyageDataTest.canDecode2,"    @Test
    public void canDecode2() {
        ZonedDateTime now = ZonedDateTime.of(2010, 12, 31, 23, 59, 59, 0, ZoneOffset.UTC);
        AISMessage aisMessage = AISMessage.create(new Metadata(""Test"", now.toInstant()),
            NMEAMessage.fromString(""!AIVDM,2,1,0,B,539S:k40000000c3G04PPh63<00000000080000o1PVG2uGD:00000000000,0*34""),
            NMEAMessage.fromString(""!AIVDM,2,2,0,B,00000000000,2*27"")
        );

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.ShipAndVoyageRelatedData, aisMessage.getMessageType());
        ShipAndVoyageData message = (ShipAndVoyageData) aisMessage;
        assertEquals(Integer.valueOf(0), message.getRepeatIndicator());
        assertEquals(MMSI.valueOf(211339980), message.getSourceMmsi());
        assertEquals(IMO.valueOf(0), message.getImo());
        assertEquals(""J050A"", message.getCallsign());
        assertEquals(""HHLA 3         B"", message.getShipName());
        assertEquals(ShipType.LawEnforcement, message.getShipType());
        assertEquals(Integer.valueOf(12), message.getToBow());
        assertEquals(Integer.valueOf(38), message.getToStern());
        assertEquals(Integer.valueOf(2), message.getToStarboard());
        assertEquals(Integer.valueOf(23), message.getToPort());
        assertNull(message.getPositionFixingDevice());
        assertEquals(Float.valueOf(""0""), message.getDraught());
        assertEquals(""14-05 20:10"", message.getEta());
        assertEquals((Integer) 5, message.getEtaMonth());
        assertEquals((Integer) 14, message.getEtaDay());
        assertEquals((Integer) 20, message.getEtaHour());
        assertEquals((Integer) 10, message.getEtaMinute());
        assertEquals(Optional.of(ZonedDateTime.of(2011, 5, 14, 20, 10, 0, 0, ZoneOffset.UTC)), message.getEtaAfterReceived());
        assertEquals("""", message.getDestination());
        assertFalse(message.getDataTerminalReady());
    }
",non-flaky,5
112635,tbsalling_aismessages,ShipAndVoyageDataTest.digest,"    @Test
    public void digest() throws NoSuchAlgorithmException {
        String expectedDigest = ""2ca6350a33d7b19f0ef49799aa96dd61da9e081e"";

        AISMessage aisMessage = AISMessage.create(
            NMEAMessage.fromString(""!AIVDM,2,1,0,B,539S:k40000000c3G04PPh63<00000000080000o1PVG2uGD:00000000000,0*34""),
            NMEAMessage.fromString(""!AIVDM,2,2,0,B,00000000000,2*27"")
        );
        byte[] digest = aisMessage.digest();
        String digestAsString = String.format(""%040x"", new java.math.BigInteger(1, digest));
        assertEquals(expectedDigest, digestAsString);

        // Change line 1
        aisMessage = AISMessage.create(
            NMEAMessage.fromString(""!AIVDM,2,1,0,B,539S:k40000000c3G04PPh63<00000000080000o1PVG2uGD:00000000001,0*34""),
            NMEAMessage.fromString(""!AIVDM,2,2,0,B,00000000000,2*27"")
        );
        digest = aisMessage.digest();
        digestAsString = String.format(""%040x"", new java.math.BigInteger(1, digest));
        assertNotEquals(expectedDigest, digestAsString);

        // Change line 2
        aisMessage = AISMessage.create(
            NMEAMessage.fromString(""!AIVDM,2,1,0,B,539S:k40000000c3G04PPh63<00000000080000o1PVG2uGD:00000000000,0*34""),
            NMEAMessage.fromString(""!AIVDM,2,2,0,B,00000000001,2*27"")
        );
        digest = aisMessage.digest();
        digestAsString = String.format(""%040x"", new java.math.BigInteger(1, digest));
        assertNotEquals(expectedDigest, digestAsString);


    }
",non-flaky,5
112636,tbsalling_aismessages,AddressedBinaryMessageTest.canDecode,"    @Test
    public void canDecode() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!ABVDM,1,1,,B,63M@g840SJL`01lSk09w1IMK?00100803Pp03g8p001pTaIK00,4*56""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.AddressedBinaryMessage, aisMessage.getMessageType());
        AddressedBinaryMessage message = (AddressedBinaryMessage) aisMessage;
        assertEquals(Integer.valueOf(0), message.getRepeatIndicator());
        assertEquals(MMSI.valueOf(232009504), message.getSourceMmsi());
        assertEquals((Integer) 0, message.getDesignatedAreaCode());
        assertEquals((Integer) 29, message.getFunctionalId());
        // TODO : check the binary value
        assertEquals(""0010001111001100000000100111111100000101100101110101101100111100000000000000000100000000000000100000000000001110000011100000000000001110111100100011100000000000000000000111100010010010100101100101101100000000"", message.getBinaryData());
    }
",non-flaky,5
112637,tbsalling_aismessages,AddressedBinaryMessageTest.canDecodeAsmNumberOfPersonsOnboard,"    @Test
    public void canDecodeAsmNumberOfPersonsOnboard() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,63bump80OEGr06P060,4*79""));
        System.out.println(aisMessage.toString());

        assertTrue(aisMessage instanceof AddressedBinaryMessage);
        AddressedBinaryMessage addressedBinaryMessage = (AddressedBinaryMessage) aisMessage;
        assertEquals(1, addressedBinaryMessage.getDesignatedAreaCode().intValue());
        assertEquals(40, addressedBinaryMessage.getFunctionalId().intValue());

        ApplicationSpecificMessage asm = addressedBinaryMessage.getApplicationSpecificMessage();
        assertEquals(1, asm.getDesignatedAreaCode());
        assertEquals(40, asm.getFunctionalId());

        assertTrue(asm instanceof NumberOfPersonsOnBoard);
        NumberOfPersonsOnBoard numberOfPersonsOnBoard = (NumberOfPersonsOnBoard) asm;
        assertEquals(""0000000000011000"", numberOfPersonsOnBoard.getBinaryData());
        assertEquals(Integer.valueOf(3), numberOfPersonsOnBoard.getNumberOfPersons());
   }
",non-flaky,5
112638,tbsalling_aismessages,InterrogationTest.canDecodeShortVariant,"    @Test
    public void canDecodeShortVariant() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,?h3Ovk1GOPph000,2*53""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.Interrogation, aisMessage.getMessageType());
        Interrogation message = (Interrogation) aisMessage;
        assertEquals(Integer.valueOf(3), message.getRepeatIndicator());
        assertEquals(MMSI.valueOf(3669708), message.getSourceMmsi());
        assertEquals(MMSI.valueOf(366969740), message.getInterrogatedMmsi1());
        assertEquals((Integer) 0, message.getType1_1());
        assertEquals((Integer) 0, message.getOffset1_1());
        assertNull(message.getType1_2());
        assertNull(message.getOffset1_2());
        assertNull(message.getInterrogatedMmsi2());
        assertNull(message.getType2_1());
        assertNull(message.getOffset2_1());
    }
",non-flaky,5
112639,tbsalling_aismessages,ClassBCSStaticDataReportTest.canDecode,"    @Test
    public void canDecode() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,H5NLOjTUG5CD=1BG46mqhj0P7130,0*78""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.ClassBCSStaticDataReport, aisMessage.getMessageType());
        ClassBCSStaticDataReport message = (ClassBCSStaticDataReport) aisMessage;
        assertEquals(Integer.valueOf(0), message.getRepeatIndicator());
        assertEquals(MMSI.valueOf(367468490), message.getSourceMmsi());
        assertEquals((Integer) 1, message.getPartNumber());
        assertNull(message.getShipName());
        assertEquals(ShipType.PleasureCraft, message.getShipType());
        assertEquals(""WESTMAR"", message.getVendorId());
        assertEquals(""WDF5902"", message.getCallsign());
        assertEquals((Integer) 4, message.getToBow());
        assertEquals((Integer) 7, message.getToStern());
        assertEquals((Integer) 3, message.getToStarboard());
        assertEquals((Integer) 1, message.getToPort());
        assertEquals(MMSI.valueOf(8417347), message.getMothershipMmsi());

    }
",non-flaky,5
112640,tbsalling_aismessages,BinaryBroadcastMessageTest.canDecode,"    @Test
    public void canDecode() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,85MwpKiKf:MPiQa:ofV@v2mQTfB26oEtbEVqh4j1QDQPHjhpkNJ3,0*11""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.BinaryBroadcastMessage, aisMessage.getMessageType());
        BinaryBroadcastMessage message = (BinaryBroadcastMessage) aisMessage;
        assertEquals(Integer.valueOf(0), message.getRepeatIndicator());
        assertEquals(MMSI.valueOf(366999663), message.getSourceMmsi());
        assertEquals((Integer) 366, message.getDesignatedAreaCode());
        assertEquals((Integer) 56, message.getFunctionalId());
        // TODO : check the binary value
        assertEquals(""1010011101100000110001100001101001001010110111101110100110010000111110000010110101100001100100101110010010000010000110110111010101111100101010010101100110111001110000000100110010000001100001010100100001100000011000110010110000111000110011011110011010000011"", message.getBinaryData());
    }
",non-flaky,5
112641,tbsalling_aismessages,BinaryBroadcastMessageTest.canDecodeUnknownApplicationSpecificMessage,"    @Test
    public void canDecodeUnknownApplicationSpecificMessage() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,8@30oni?1j020@00,0*23""));

        System.out.println(aisMessage.toString());

        assertEquals(316, ((BinaryBroadcastMessage) aisMessage).getDesignatedAreaCode().intValue());
        assertEquals(7, ((BinaryBroadcastMessage) aisMessage).getFunctionalId().intValue());
        assertEquals(UnknownApplicationSpecificMessage.class, ((BinaryBroadcastMessage) aisMessage).getApplicationSpecificMessage().getClass());
    }
",non-flaky,5
112642,tbsalling_aismessages,BinaryBroadcastMessageTest.canDecodeMultiSentenceUnknownApplicationSpecificMessage,"    @Test
    public void canDecodeMultiSentenceUnknownApplicationSpecificMessage() {
        AISMessage aisMessage = AISMessage.create(
                NMEAMessage.fromString(""!AIVDM,2,1,8,A,803Iw60F14m1CPH4mDT4RDi@000003RP9iHb@001irBQ0@4gAaI00000261Q,0*04""),
                NMEAMessage.fromString(""!AIVDM,2,2,8,A,pGp07IiTPi@BkU5pSwrrbs8219RW=R19RV=R19RVER19RVKtDb>jq20000>4,0*47"")
        );

        System.out.println(aisMessage.toString());

        assertEquals(88, ((BinaryBroadcastMessage) aisMessage).getDesignatedAreaCode().intValue());
        assertEquals(4, ((BinaryBroadcastMessage) aisMessage).getFunctionalId().intValue());
        assertEquals(UnknownApplicationSpecificMessage.class, ((BinaryBroadcastMessage) aisMessage).getApplicationSpecificMessage().getClass());
    }
",non-flaky,5
112643,tbsalling_aismessages,BinaryBroadcastMessageTest.canDecodeDac200Fi10InlandShipStaticAndVoyageRelatedData1,"    @Test
    public void canDecodeDac200Fi10InlandShipStaticAndVoyageRelatedData1() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,839udkPj2d<dteLMt1T0a?bP01L0,0*79""));
        System.out.println(aisMessage.toString());

        assertTrue(aisMessage instanceof BinaryBroadcastMessage);
        BinaryBroadcastMessage binaryBroadcastMessage = (BinaryBroadcastMessage) aisMessage;
        assertEquals(200, binaryBroadcastMessage.getDesignatedAreaCode().intValue());
        assertEquals(10, binaryBroadcastMessage.getFunctionalId().intValue());

        ApplicationSpecificMessage asm = binaryBroadcastMessage.getApplicationSpecificMessage();
        assertEquals(200, asm.getDesignatedAreaCode());
        assertEquals(10, asm.getFunctionalId());

        assertTrue(asm instanceof InlandShipStaticAndVoyageRelatedData);
        InlandShipStaticAndVoyageRelatedData inlandMessage = (InlandShipStaticAndVoyageRelatedData) asm;

        assertEquals(""02325170"", inlandMessage.getUniqueEuropeanVesselIdentificationNumber());
        assertEquals(Float.valueOf(80.0f), inlandMessage.getLengthOfShip());
        assertEquals(Float.valueOf(8.2f), inlandMessage.getBeamOfShip());
        assertEquals(Integer.valueOf(8020), inlandMessage.getShipOrCombinationType());
        assertEquals(Integer.valueOf(0), inlandMessage.getHazardousCargo());
        assertEquals(Float.valueOf(0.0f), inlandMessage.getDraught());
        assertEquals(Integer.valueOf(2), inlandMessage.getLoaded());
        assertEquals(Integer.valueOf(1), inlandMessage.getQualityOfSpeedInformation());
        assertEquals(Integer.valueOf(1), inlandMessage.getQualityOfCourseInformation());
        assertEquals(Integer.valueOf(1), inlandMessage.getQualityOfHeadingInformation());
    }
",non-flaky,5
112644,tbsalling_aismessages,BinaryBroadcastMessageTest.canDecodeDac200Fi10InlandShipStaticAndVoyageRelatedData2,"    @Test
    public void canDecodeDac200Fi10InlandShipStaticAndVoyageRelatedData2() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,83aDCr@j2P000000029Pt?cm0000,0*5F""));
        System.out.println(aisMessage.toString());

        assertTrue(aisMessage instanceof BinaryBroadcastMessage);
        BinaryBroadcastMessage binaryBroadcastMessage = (BinaryBroadcastMessage) aisMessage;
        assertEquals(200, binaryBroadcastMessage.getDesignatedAreaCode().intValue());
        assertEquals(10, binaryBroadcastMessage.getFunctionalId().intValue());

        ApplicationSpecificMessage asm = binaryBroadcastMessage.getApplicationSpecificMessage();
        assertEquals(200, asm.getDesignatedAreaCode());
        assertEquals(10, asm.getFunctionalId());

        assertTrue(asm instanceof InlandShipStaticAndVoyageRelatedData);
        InlandShipStaticAndVoyageRelatedData inlandMessage = (InlandShipStaticAndVoyageRelatedData) asm;

        assertEquals("""", inlandMessage.getUniqueEuropeanVesselIdentificationNumber());
        assertEquals(Float.valueOf(110.0f), inlandMessage.getLengthOfShip());
        assertEquals(Float.valueOf(12.0f), inlandMessage.getBeamOfShip());
        assertEquals(Integer.valueOf(8030), inlandMessage.getShipOrCombinationType());
        assertEquals(Integer.valueOf(5), inlandMessage.getHazardousCargo());
        assertEquals(Float.valueOf(0.0f), inlandMessage.getDraught());
        assertEquals(Integer.valueOf(0), inlandMessage.getLoaded());
        assertEquals(Integer.valueOf(0), inlandMessage.getQualityOfSpeedInformation());
        assertEquals(Integer.valueOf(0), inlandMessage.getQualityOfCourseInformation());
        assertEquals(Integer.valueOf(0), inlandMessage.getQualityOfHeadingInformation());
    }
",non-flaky,5
112645,tbsalling_aismessages,BinaryBroadcastMessageTest.failsWithInvalidMessageWhenDecodingShortMessage,"    @Test(expected = InvalidMessage.class)
    public void failsWithInvalidMessageWhenDecodingShortMessage() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,83aDCr@,0*5F""));
        BinaryBroadcastMessage binaryBroadcastMessage = (BinaryBroadcastMessage) aisMessage;

        ApplicationSpecificMessage asm = binaryBroadcastMessage.getApplicationSpecificMessage();

        System.out.println(aisMessage);
    }
",non-flaky,5
112646,tbsalling_aismessages,PositionReportClassAResponseToInterrogationTest.canDecode,"    @Test
    public void canDecode() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,34RjBV0028o:pnNEBeU<pJF>0PT@,0*3F""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.PositionReportClassAResponseToInterrogation, aisMessage.getMessageType());
        assertEquals((Integer) 0, aisMessage.getRepeatIndicator());
        PositionReportClassAResponseToInterrogation message = (PositionReportClassAResponseToInterrogation) aisMessage;
        assertEquals(MMSI.valueOf(304911000), message.getSourceMmsi());
        assertEquals(NavigationStatus.UnderwayUsingEngine, message.getNavigationStatus());
        assertEquals((Integer) 0, message.getRateOfTurn());
        assertEquals((Float) 13.6f, message.getSpeedOverGround());
        assertEquals((Integer) 136, message.getRawSpeedOverGround());
        assertTrue(message.getPositionAccuracy());
        assertEquals(Float.valueOf(37.21113f), message.getLatitude());
        assertEquals((Integer)22326676, message.getRawLatitude());
        assertEquals(Float.valueOf(-123.45053f), message.getLongitude());
        assertEquals((Integer)(-74070321), message.getRawLongitude());
        assertEquals(Float.valueOf(329.7f), message.getCourseOverGround());
        assertEquals((Integer) 3297, message.getRawCourseOverGround());
        assertEquals((Integer) 331, message.getTrueHeading());
        assertEquals((Integer) 7, message.getSecond());
        assertEquals(ManeuverIndicator.NotAvailable, message.getSpecialManeuverIndicator());
        assertFalse(message.getRaimFlag());
    }
",non-flaky,5
112647,tbsalling_aismessages,PositionReportClassAResponseToInterrogationTest.digest,"    @Test
    public void digest() throws NoSuchAlgorithmException {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,34RjBV0028o:pnNEBeU<pJF>0PT@,0*3F""));
        byte[] digest = aisMessage.digest();
        String digestAsString = String.format(""%040x"", new java.math.BigInteger(1, digest));
        assertEquals(""673ac3b20886868cafe7376e05092bf625f00b75"", digestAsString);
    }
",non-flaky,5
112648,tbsalling_aismessages,BaseStationReportTest.canDecode,"    @Test
    public void canDecode() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,4h3Ovk1udp6I9o>jPHEdjdW000S:,0*0C""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.BaseStationReport, aisMessage.getMessageType());
        assertEquals((Integer) 3, aisMessage.getRepeatIndicator());
        BaseStationReport message = (BaseStationReport) aisMessage;
        assertEquals(MMSI.valueOf(3669708), message.getSourceMmsi());
        assertEquals((Integer) 2011, message.getYear());
        assertEquals((Integer) 3, message.getMonth());
        assertEquals((Integer) 16, message.getDay());
        assertEquals((Integer) 6, message.getHour());
        assertEquals((Integer) 25, message.getMinute());
        assertEquals((Integer) 9, message.getSecond());
        assertTrue(message.getPositionAccurate());
        assertEquals(Float.valueOf(37.923283f), message.getLatitude());
        assertEquals(Float.valueOf(-122.59837f), message.getLongitude());
        assertEquals(PositionFixingDevice.Surveyed, message.getPositionFixingDevice());
        assertFalse(message.getRaimFlag());
    }
",non-flaky,5
112649,tbsalling_aismessages,BaseStationReportTest.canDecodeCommunicationState,"    @Test
    public void canDecodeCommunicationState() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,400TcdiuiT7VDR>3nIfr6>i00000,0*78""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.BaseStationReport, aisMessage.getMessageType());
        assertEquals((Integer) 0, aisMessage.getRepeatIndicator());
        BaseStationReport message = (BaseStationReport) aisMessage;
        assertEquals(MMSI.valueOf(601011), message.getSourceMmsi());
        assertEquals((Integer) 2012, message.getYear());
        assertEquals((Integer) 6, message.getMonth());
        assertEquals((Integer) 8, message.getDay());
        assertEquals((Integer) 7, message.getHour());
        assertEquals((Integer) 38, message.getMinute());
        assertEquals((Integer) 20, message.getSecond());
        assertTrue(message.getPositionAccurate());
        assertEquals(Float.valueOf(-29.870832f), message.getLatitude());
        assertEquals(Float.valueOf(31.033514f), message.getLongitude());
        assertEquals(PositionFixingDevice.Gps, message.getPositionFixingDevice());
        assertFalse(message.getRaimFlag());

        SOTDMACommunicationState sotdmaCommunicationState = message.getCommunicationState();
        assertEquals(SyncState.UTCDirect, sotdmaCommunicationState.getSyncState());
        assertNull(sotdmaCommunicationState.getNumberOfReceivedStations());
        assertNull(sotdmaCommunicationState.getSlotNumber());
        assertEquals(Integer.valueOf(0), sotdmaCommunicationState.getSlotOffset());
        assertEquals(Integer.valueOf(0), sotdmaCommunicationState.getSlotTimeout());
        assertNull(sotdmaCommunicationState.getUtcHour());
        assertNull(sotdmaCommunicationState.getUtcMinute());
    }
",non-flaky,5
112650,tbsalling_aismessages,StandardClassBCSPositionReportTest.canDecode1,"    @Test
    public void canDecode1() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,B5NJ;PP005l4ot5Isbl03wsUkP06,0*76""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.StandardClassBCSPositionReport, aisMessage.getMessageType());
        StandardClassBCSPositionReport message = (StandardClassBCSPositionReport) aisMessage;
        assertEquals(Integer.valueOf(0), message.getRepeatIndicator());
        assertEquals(MMSI.valueOf(367430530), message.getSourceMmsi());
        assertEquals(""00000000"", message.getRegionalReserved1());
        assertEquals((Float) 0.0f, message.getSpeedOverGround());
        assertEquals((Integer) 0, message.getRawSpeedOverGround());
        assertFalse(message.getPositionAccurate());
        assertEquals(Float.valueOf(37.785034f), message.getLatitude());
        assertEquals((Integer)22671021, message.getRawLatitude());
        assertEquals(Float.valueOf(-122.26732f), message.getLongitude());
        assertEquals((Integer)(-73360392), message.getRawLongitude());
        assertEquals(Float.valueOf(0.0f), message.getCourseOverGround());
        assertEquals((Integer) 0, message.getRawCourseOverGround());
        assertEquals((Integer) 511, message.getTrueHeading());
        assertEquals((Integer) 55, message.getSecond());
        assertEquals(""00"", message.getRegionalReserved2());
        assertTrue(message.getCsUnit());
        assertFalse(message.getDisplay());
        assertTrue(message.getDsc());
        assertTrue(message.getBand());
        assertTrue(message.getMessage22());
        assertFalse(message.getAssigned());
        assertFalse(message.getRaimFlag());
        //assertEquals(""11100000000000000110"", message.getRadioStatus());
    }
",non-flaky,5
112651,tbsalling_aismessages,StandardClassBCSPositionReportTest.canDecode2,"    @Test
    public void canDecode2() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,B>1VUFP00vK`auV0eUulKwv0RJGT,0*09""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.StandardClassBCSPositionReport, aisMessage.getMessageType());
        StandardClassBCSPositionReport message = (StandardClassBCSPositionReport) aisMessage;
        assertEquals(Integer.valueOf(0), message.getRepeatIndicator());
        assertEquals(MMSI.valueOf(941204826), message.getSourceMmsi());
        assertEquals(""00000000"", message.getRegionalReserved1());
        assertEquals((Float) 0.3f, message.getSpeedOverGround());
        assertTrue(message.getPositionAccurate());
        assertEquals(Float.valueOf(42.020855f), message.getLatitude());
        assertEquals(Float.valueOf(-87.70006f), message.getLongitude());
        assertEquals(Float.valueOf(186.2f), message.getCourseOverGround());
        assertEquals((Integer) 511, message.getTrueHeading());
        assertEquals((Integer) 60, message.getSecond());
        assertEquals(""00"", message.getRegionalReserved2());
        assertFalse(message.getCsUnit());
        assertFalse(message.getDisplay());
        assertFalse(message.getDsc());
        assertTrue(message.getBand());
        assertFalse(message.getMessage22());
        assertFalse(message.getAssigned());
        assertFalse(message.getRaimFlag());
    }
",non-flaky,5
112652,tbsalling_aismessages,StandardClassBCSPositionReportTest.canDecodeITDMACommunicationState,"    @Test
    public void canDecodeITDMACommunicationState() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,B6CdCm0t3`tba35f@V9faHi7kP06,0*58""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.StandardClassBCSPositionReport, aisMessage.getMessageType());
        StandardClassBCSPositionReport message = (StandardClassBCSPositionReport) aisMessage;
        assertEquals(Integer.valueOf(0), message.getRepeatIndicator());
        assertEquals(MMSI.valueOf(423302100), message.getSourceMmsi());
        assertEquals(""00001111"", message.getRegionalReserved1());
        assertEquals((Float) 1.4f, message.getSpeedOverGround());
        assertTrue(message.getPositionAccurate());
        assertEquals(Float.valueOf(40.005283f), message.getLatitude());
        assertEquals(Float.valueOf(53.010998f), message.getLongitude());
        assertEquals(Float.valueOf(177f), message.getCourseOverGround());
        assertEquals((Integer) 177, message.getTrueHeading());
        assertEquals((Integer) 34, message.getSecond());
        assertEquals(""00"", message.getRegionalReserved2());
        assertTrue(message.getCsUnit());
        assertTrue(message.getDisplay());
        assertTrue(message.getDsc());
        assertTrue(message.getBand());
        assertTrue(message.getMessage22());
        assertFalse(message.getAssigned());
        assertFalse(message.getRaimFlag());
        assertTrue(message.getCommunicationStateSelectorFlag());

        CommunicationState communicationState = message.getCommunicationState();   // 1100000000000000110b = 3, slot incr = 6
        assertEquals(SyncState.BaseIndirect, communicationState.getSyncState());
        assertTrue(communicationState instanceof ITDMACommunicationState);
        ITDMACommunicationState itdmaCommunicationState = (ITDMACommunicationState) communicationState;
        assertEquals(Integer.valueOf(0), itdmaCommunicationState.getSlotIncrement());
        assertEquals(Integer.valueOf(3), itdmaCommunicationState.getNumberOfSlots());
        assertFalse(itdmaCommunicationState.getKeepFlag());
    }
",non-flaky,5
112653,tbsalling_aismessages,PositionReportClassAAssignedScheduleTest.canDecode,"    @Test
    public void canDecode() {
		/*
		User ID	304911000
		Navigation Status	0	Under way using engine
		Rate of Turn (ROT)	0	Turning right at up to 708 degrees per minute or higher
		Speed Over Ground (SOG)	13.6
		Position Accuracy	1	A DGPS-quality fix with an accuracy of < 10 ms
		Longitude	-123.450533333333	West
		Latitude	37.2111266666667	North
		Course Over Ground (COG)	329.7
		True Heading (HDG)	331
		Time Stamp	7
		Reserved for regional	0	Not available (default)
		RAIM flag	0	RAIM not in use (default)
		Communication State	133392	Sync state: UTC Indirect; Slot Timeout: This was the last transmission in this slot; Slot offset: 2320
		COMMUNICATION_SYNC_STATE	1	Sync state: UTC Indirect
		COMMUNICATION_SLOT_TIMEOUT	0	Slot Timeout: This was the last transmission in this slot
		COMMUNICATION_SUB_MESSAGE	2320
		COMMUNICATION_UTC_HOUR	No value
		COMMUNICATION_UTC_MINUTE	No value
		COMMUNICATION_TIME_STAMP	No value
		COMMUNICATION_SLOT_NUMBER	No value
		COMMUNICATION_RECEIVED_STATIONS	No value
		COMMUNICATION_SLOT_OFFSET	2320
		*/

        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,24RjBV0028o:pnNEBeU<pJF>0PT@,0*3F""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.PositionReportClassAAssignedSchedule, aisMessage.getMessageType());
        assertEquals((Integer) 0, aisMessage.getRepeatIndicator());
        PositionReportClassAAssignedSchedule message = (PositionReportClassAAssignedSchedule) aisMessage;
        assertEquals(MMSI.valueOf(304911000), message.getSourceMmsi());
        assertEquals(NavigationStatus.UnderwayUsingEngine, message.getNavigationStatus());
        assertEquals((Integer) 0, message.getRateOfTurn());
        assertEquals((Float) 13.6f, message.getSpeedOverGround());
        assertTrue(message.getPositionAccuracy());
        assertEquals(Float.valueOf(37.21113f), message.getLatitude());
        assertEquals((Integer) 22326676, message.getRawLatitude());
        assertEquals(Float.valueOf(-123.45053f), message.getLongitude());
        assertEquals((Integer) (-74070321), message.getRawLongitude());
        assertEquals(Float.valueOf(329.7f), message.getCourseOverGround());
        assertEquals((Integer) 3297, message.getRawCourseOverGround());
        assertEquals((Integer) 331, message.getTrueHeading());
        assertEquals((Integer) 7, message.getSecond());
        assertEquals(ManeuverIndicator.NotAvailable, message.getSpecialManeuverIndicator());
        assertFalse(message.getRaimFlag());
    }
",non-flaky,5
112654,tbsalling_aismessages,PositionReportClassAScheduledTest.canDecode,"    @Test
    public void canDecode() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,13@nePh01>PjcO4PGReoJEmL0HJg,0*67""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.PositionReportClassAScheduled, aisMessage.getMessageType());
        assertEquals((Integer) 0, aisMessage.getRepeatIndicator());
        PositionReportClassAScheduled message = (PositionReportClassAScheduled) aisMessage;
        assertEquals(MMSI.valueOf(219000195), message.getSourceMmsi());
        assertEquals(NavigationStatus.UnderwayUsingEngine, message.getNavigationStatus());
        assertEquals((Integer) 0, message.getRateOfTurn());
        assertEquals((Float) 7.8f, message.getSpeedOverGround());
        assertTrue(message.getPositionAccuracy());
        assertEquals(Float.valueOf(56.56692f), message.getLatitude());
        assertEquals((Integer) 33940151, message.getRawLatitude());
        assertEquals(Float.valueOf(11.071096f), message.getLongitude());
        assertEquals((Integer) 6642658, message.getRawLongitude());
        assertEquals(Float.valueOf(189.7f), message.getCourseOverGround());
        assertEquals((Integer) 1897, message.getRawCourseOverGround());
        assertEquals((Integer) 46, message.getSecond());
        assertEquals((Integer) 186, message.getTrueHeading());
        assertEquals(ManeuverIndicator.NotAvailable, message.getSpecialManeuverIndicator());
        assertFalse(message.getRaimFlag());
    }
",non-flaky,5
112655,tbsalling_aismessages,PositionReportClassAScheduledTest.canDecodeCommunicationState,"    @Test
    public void canDecodeCommunicationState() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,17OoHr?P009qtlQd6T<0<?wN041P,0*01""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.PositionReportClassAScheduled, aisMessage.getMessageType());
        assertEquals((Integer) 0, aisMessage.getRepeatIndicator());
        PositionReportClassAScheduled message = (PositionReportClassAScheduled) aisMessage;
        assertEquals(MMSI.valueOf(503175400), message.getSourceMmsi());
        assertEquals(NavigationStatus.Undefined, message.getNavigationStatus());
        assertEquals(Integer.valueOf(-128), message.getRateOfTurn()); // ROT = 1000000b = -128
        assertEquals(Float.valueOf(0.0f), message.getSpeedOverGround());
        assertFalse(message.getPositionAccuracy());
        assertEquals(Float.valueOf(-34.773254f), message.getLatitude());
        assertEquals(Float.valueOf(138.48856f), message.getLongitude());
        assertEquals(Float.valueOf(4.8f), message.getCourseOverGround());
        assertEquals(Integer.valueOf(47), message.getSecond());
        assertEquals(Integer.valueOf(511), message.getTrueHeading());
        assertEquals(ManeuverIndicator.NotAvailable, message.getSpecialManeuverIndicator());
        assertFalse(message.getRaimFlag());

        CommunicationState communicationState = message.getCommunicationState();
        assertEquals(SyncState.UTCDirect, communicationState.getSyncState());

        assertTrue(communicationState instanceof SOTDMACommunicationState);
        SOTDMACommunicationState sotdmaCommunicationState = (SOTDMACommunicationState) communicationState;
        assertNull(sotdmaCommunicationState.getNumberOfReceivedStations());
        assertNull(sotdmaCommunicationState.getSlotNumber());
        assertNull(sotdmaCommunicationState.getSlotOffset());
        assertEquals(Integer.valueOf(1), sotdmaCommunicationState.getSlotTimeout());
        assertEquals(Integer.valueOf(0), sotdmaCommunicationState.getUtcHour());
        assertEquals(Integer.valueOf(24), sotdmaCommunicationState.getUtcMinute());
    }
",non-flaky,5
112656,tbsalling_aismessages,DataLinkManagementTest.canDecodeShortVariant1,"    @Test
    public void canDecodeShortVariant1() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,Dh3Ovk1UAN>4,0*0A""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.DataLinkManagement, aisMessage.getMessageType());
        DataLinkManagement message = (DataLinkManagement) aisMessage;
        assertEquals(Integer.valueOf(3), message.getRepeatIndicator());
        assertEquals(MMSI.valueOf(3669708), message.getSourceMmsi());
        assertEquals((Integer) 1620, message.getOffsetNumber1());
        assertEquals((Integer) 5, message.getReservedSlots1());
        assertEquals((Integer) 7, message.getTimeout1());
        assertEquals((Integer) 225, message.getIncrement1());
        assertNull(message.getOffsetNumber2());
        assertNull(message.getReservedSlots2());
        assertNull(message.getTimeout2());
        assertNull(message.getIncrement2());
        assertNull(message.getOffsetNumber3());
        assertNull(message.getReservedSlots3());
        assertNull(message.getTimeout3());
        assertNull(message.getIncrement3());
    }
",non-flaky,5
112657,tbsalling_aismessages,DataLinkManagementTest.canDecodeShortVariant2,"    @Test
    public void canDecodeShortVariant2() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,Dh3Ovk1cEN>4,0*3B""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.DataLinkManagement, aisMessage.getMessageType());
        DataLinkManagement message = (DataLinkManagement) aisMessage;
        assertEquals(Integer.valueOf(3), message.getRepeatIndicator());
        assertEquals(MMSI.valueOf(3669708), message.getSourceMmsi());
        assertEquals((Integer) 1717, message.getOffsetNumber1());
        assertEquals((Integer) 5, message.getReservedSlots1());
        assertEquals((Integer) 7, message.getTimeout1());
        assertEquals((Integer) 225, message.getIncrement1());
        assertNull(message.getOffsetNumber2());
        assertNull(message.getReservedSlots2());
        assertNull(message.getTimeout2());
        assertNull(message.getIncrement2());
        assertNull(message.getOffsetNumber3());
        assertNull(message.getReservedSlots3());
        assertNull(message.getTimeout3());
        assertNull(message.getIncrement3());
    }
",non-flaky,5
112658,tbsalling_aismessages,InvalidMessageTest.invalid,"    @Test(expected = InvalidMessage.class)
    public void invalid() {
        AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,58LAM242B9POUKWWW<0a>0<4E<58,0*6E""));
    }
",non-flaky,5
112659,tbsalling_aismessages,AidToNavigationReportTest.canDecode1,"    @Test
    public void canDecode1() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDO,1,1,,A,E>lt;Lqaps0h3V:@;4a:@0b7W005J`6Dq9e<000003v010,4*7E""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.AidToNavigationReport, aisMessage.getMessageType());
        assertEquals((Integer) 0, aisMessage.getRepeatIndicator());
        AidToNavigationReport message = (AidToNavigationReport) aisMessage;
        assertEquals(MMSI.valueOf(995036019), message.getSourceMmsi());
        assertEquals(AidType.BeaconSpecialMark, message.getAidType());
        assertEquals(false, message.getAssignedMode());
        assertEquals(""S16A GLT VIRT ATON"", message.getName());
        assertEquals(null, message.getNameExtension());
        assertEquals(false, message.getOffPosition());
        assertEquals(Integer.valueOf(60), message.getSecond());
        assertEquals(Integer.valueOf(0), message.getToBow());
        assertEquals(Integer.valueOf(0), message.getToPort());
        assertEquals(Integer.valueOf(0), message.getToStern());
        assertEquals(Integer.valueOf(0), message.getToStarboard());
        assertEquals(true, message.getVirtualAid());
        assertEquals(false, message.getPositionAccurate());
        assertEquals(Float.valueOf(-23.936693f), message.getLatitude()); // lat = 111001001001101101001100000b = -23,9366933333
        assertEquals(Float.valueOf(151.44344f), message.getLongitude());
        assertEquals(PositionFixingDevice.Surveyed, message.getPositionFixingDevice());
        assertFalse(message.getRaimFlag());
    }
",non-flaky,5
112660,tbsalling_aismessages,AidToNavigationReportTest.canDecode2,"    @Test
    public void canDecode2() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDO,1,1,,A,E>lt;MIas0h3V:@;4a::h0b7W005Jh4nq:3l800003v010,4*08""));
        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.AidToNavigationReport, aisMessage.getMessageType());
        assertEquals((Integer) 0, aisMessage.getRepeatIndicator());
        AidToNavigationReport message = (AidToNavigationReport) aisMessage;
        assertEquals(MMSI.valueOf(995036021), message.getSourceMmsi());
        assertEquals(AidType.BeaconSpecialMark, message.getAidType());
        assertEquals(false, message.getAssignedMode());
        assertEquals(""S6A GLT VIRTU ATON"", message.getName());
        assertEquals(null, message.getNameExtension());
        assertEquals(false, message.getOffPosition());
        assertEquals(Integer.valueOf(60), message.getSecond());
        assertEquals(Integer.valueOf(0), message.getToBow());
        assertEquals(Integer.valueOf(0), message.getToPort());
        assertEquals(Integer.valueOf(0), message.getToStern());
        assertEquals(Integer.valueOf(0), message.getToStarboard());
        assertEquals(true, message.getVirtualAid());
        assertEquals(false, message.getPositionAccurate());
        assertEquals(Float.valueOf(-23.917385f), message.getLatitude());
        assertEquals(Float.valueOf(151.49791f), message.getLongitude());
        assertEquals(PositionFixingDevice.Surveyed, message.getPositionFixingDevice());
        assertFalse(message.getRaimFlag());
    }
",non-flaky,5
112661,tbsalling_aismessages,AidToNavigationReportTest.testDataFields,"    @Test
    public void testDataFields() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDO,1,1,,A,E>lt;MIas0h3V:@;4a::h0b7W005Jh4nq:3l800003v010,4*08""));
        Map<String, Object> dataFields = aisMessage.dataFields();

        assertNotNull(dataFields);
        assertEquals(22, dataFields.size());

        assertEquals(""AidToNavigationReport"", dataFields.get(""messageType""));
        assertEquals(0, dataFields.get(""repeatIndicator""));
        assertEquals(995036021, dataFields.get(""sourceMmsi.MMSI""));
        assertEquals(""BeaconSpecialMark"", dataFields.get(""aidType""));
        assertEquals(""S6A GLT VIRTU ATON"", dataFields.get(""name""));
        assertEquals(false, dataFields.get(""positionAccurate""));
        assertEquals(151.49791f, dataFields.get(""longitude""));
        assertEquals(-23.917385f, dataFields.get(""latitude""));
        assertEquals(0, dataFields.get(""toStern""));
        assertEquals(0, dataFields.get(""toBow""));
        assertEquals(0, dataFields.get(""toPort""));
        assertEquals(0, dataFields.get(""toStarboard""));
        assertEquals(""Surveyed"", dataFields.get(""positionFixingDevice""));
        assertEquals(60, dataFields.get(""second""));
        assertEquals(false, dataFields.get(""offPosition""));
        assertEquals(""00000000"", dataFields.get(""atoNStatus""));
        assertEquals(false, dataFields.get(""raimFlag""));
        assertEquals(true, dataFields.get(""virtualAid""));
        assertEquals(false, dataFields.get(""assignedMode""));
        assertEquals(0, dataFields.get(""spare1""));
        assertEquals(0, dataFields.get(""spare2""));

        assertFalse(dataFields.containsKey(""nameExtension""));
        assertFalse(dataFields.containsKey(""class""));
    }
",non-flaky,5
112662,tbsalling_aismessages,LongRangeBroadcastMessageTest.canDecode1,"    @Test
    public void canDecode1() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,KC5E2b@U19PFdLbMuc5=ROv62<7m,0*16""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.LongRangeBroadcastMessage, aisMessage.getMessageType());
        assertEquals((Integer) 1, aisMessage.getRepeatIndicator());
        assertEquals(MMSI.valueOf(206914217), aisMessage.getSourceMmsi());

        LongRangeBroadcastMessage message = (LongRangeBroadcastMessage) aisMessage;
        assertFalse(message.getPositionAccuracy());
        assertFalse(message.getRaim());
        assertEquals(NavigationStatus.NotUnderCommand, message.getNavigationalStatus());
        assertEquals(Float.valueOf(137.02333f), message.getLongitude());
        assertEquals(Float.valueOf(4.84f), message.getLatitude());
        assertEquals(Float.valueOf(57f), message.getSpeedOverGround(), 1e-5);
        assertEquals((Integer)57, message.getRawSpeedOverGround());
        assertEquals(Float.valueOf(167f), message.getCourseOverGround(), 1e-5);
        assertEquals((Integer)167, message.getRawCourseOverGround());
    }
",non-flaky,5
112663,tbsalling_aismessages,LongRangeBroadcastMessageTest.canDecode2,"    @Test
    public void canDecode2() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,K5DfMB9FLsM?P00d,0*70""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.LongRangeBroadcastMessage, aisMessage.getMessageType());
        assertEquals((Integer) 0, aisMessage.getRepeatIndicator());
        assertEquals(MMSI.valueOf(357277000), aisMessage.getSourceMmsi());

        LongRangeBroadcastMessage message = (LongRangeBroadcastMessage) aisMessage;
        assertTrue(message.getPositionAccuracy());
        assertFalse(message.getRaim());
        assertEquals(NavigationStatus.Moored, message.getNavigationalStatus());
        assertEquals(Float.valueOf(176.18167f), message.getLongitude());
        assertEquals(Float.valueOf(-37.65333f), message.getLatitude());
        assertEquals(Float.valueOf(0f), message.getSpeedOverGround(), 1e-5);
        assertEquals((Integer)0, message.getRawSpeedOverGround());
        assertEquals(Float.valueOf(11f), message.getCourseOverGround(), 1e-5);
        assertEquals((Integer)11, message.getRawCourseOverGround());
    }
",non-flaky,5
112664,tbsalling_aismessages,DecodersTest.canConvertToULong,"    @Test
    public void canConvertToULong() {
        assertEquals(Long.valueOf(566517000), UNSIGNED_LONG_DECODER.apply(""100001110001000101110100001000""));
        assertEquals(Long.valueOf(9577991), UNSIGNED_LONG_DECODER.apply(""000000100100100010011000000111""));
    }
",non-flaky,5
112665,tbsalling_aismessages,DecodersTest.canConvertToUnsignedInteger,"    @Test
    public void canConvertToUnsignedInteger() {
        // 1011100101011100011011001111 -> -123.450533333333

        assertEquals(Float.valueOf(0), FLOAT_DECODER.apply(""0000000000000000000000000000""));
        assertEquals(Float.valueOf(1), FLOAT_DECODER.apply(""0000000000000000000000000001""));
        assertEquals(Float.valueOf(-1), FLOAT_DECODER.apply(""1111111111111111111111111111""));
        assertEquals(-123.450533333333f, FLOAT_DECODER.apply(""1011100101011100011011001111"") / 600000f, 1e-16);// 74070320
        assertEquals(37.21113f,          FLOAT_DECODER.apply(""001010101001010110110010100"") / 600000f, 1e-16);
        // 181 degrees (0x6791AC0 hex)
        // Decoder.convertToUnsignedInteger(bitString)
        // 91 degrees (0x3412140 hex)
        // Course over ground will be 3600 (0xE10)
    }
",non-flaky,5
112666,tbsalling_aismessages,NMEAMessageHandlerTest.canHandleUnfragmentedMessageReceived,"    @Test
    public void canHandleUnfragmentedMessageReceived() {
        NMEAMessage unfragmentedNMEAMessage = NMEAMessage.fromString(""!AIVDM,1,1,,B,15MqdBP000G@qoLEi69PVGaN0D0=,0*3A"");

        final ArgumentCaptor<AISMessage> aisMessage = new ArgumentCaptor<>();

        context.checking(new Expectations() {{
            oneOf(aisMessageHandler).accept(with(aisMessage.getMatcher()));
        }});

        aisMessageReceiver.accept(unfragmentedNMEAMessage);

        assertEquals(AISMessageType.PositionReportClassAScheduled, aisMessage.getCapturedObject().getMessageType());
    }
",non-flaky,5
112667,tbsalling_aismessages,NMEAMessageHandlerTest.canHandleFragmentedMessageReceived,"    @Test
    public void canHandleFragmentedMessageReceived() {
        NMEAMessage fragmentedNMEAMessage1 = NMEAMessage.fromString(""!AIVDM,2,1,3,B,55DA><02=6wpPuID000qTf059@DlU<00000000171lMDD4q20LmDp3hB,0*27"");
        NMEAMessage fragmentedNMEAMessage2 = NMEAMessage.fromString(""!AIVDM,2,2,3,B,p=Mh00000000000,2*4C"");

        final ArgumentCaptor<AISMessage> aisMessage = new ArgumentCaptor<>();

        context.checking(new Expectations() {{
            oneOf(aisMessageHandler).accept(with(aisMessage.getMatcher()));
        }});

        aisMessageReceiver.accept(fragmentedNMEAMessage1);
        aisMessageReceiver.accept(fragmentedNMEAMessage2);

        assertEquals(AISMessageType.ShipAndVoyageRelatedData, aisMessage.getCapturedObject().getMessageType());
    }
",non-flaky,5
112668,tbsalling_aismessages,NMEAMessageHandlerTest.canFlushEmpty,"    @Test
    public void canFlushEmpty() {
        NMEAMessage unfragmentedNMEAMessage = NMEAMessage.fromString(""!AIVDM,1,1,,B,15MqdBP000G@qoLEi69PVGaN0D0=,0*3A"");
        NMEAMessage fragmentedNMEAMessage1 = NMEAMessage.fromString(""!AIVDM,2,1,3,B,55DA><02=6wpPuID000qTf059@DlU<00000000171lMDD4q20LmDp3hB,0*27"");
        NMEAMessage fragmentedNMEAMessage2 = NMEAMessage.fromString(""!AIVDM,2,2,3,B,p=Mh00000000000,2*4C"");

        final ArgumentCaptor<AISMessage> aisMessage = new ArgumentCaptor<>();

        context.checking(new Expectations() {{
            exactly(3).of(aisMessageHandler).accept(with(aisMessage.getMatcher()));
        }});

        aisMessageReceiver.accept(unfragmentedNMEAMessage);
        aisMessageReceiver.accept(fragmentedNMEAMessage1);
        aisMessageReceiver.accept(fragmentedNMEAMessage2);

        ArrayList<NMEAMessage> flush = aisMessageReceiver.flush();

        assertNotNull(flush);
        assertEquals(0, flush.size());
    }
",non-flaky,5
112669,tbsalling_aismessages,NMEAMessageHandlerTest.canFlushUnhandled,"    @Test
    public void canFlushUnhandled() {
        NMEAMessage unfragmentedNMEAMessage = NMEAMessage.fromString(""!AIVDM,1,1,,B,15MqdBP000G@qoLEi69PVGaN0D0=,0*3A"");
        NMEAMessage fragmentedNMEAMessage1 = NMEAMessage.fromString(""!AIVDM,2,1,3,B,55DA><02=6wpPuID000qTf059@DlU<00000000171lMDD4q20LmDp3hB,0*27"");

        final ArgumentCaptor<AISMessage> aisMessage = new ArgumentCaptor<>();

        context.checking(new Expectations() {{
            exactly(2).of(aisMessageHandler).accept(with(aisMessage.getMatcher()));
        }});

        aisMessageReceiver.accept(unfragmentedNMEAMessage);
        aisMessageReceiver.accept(fragmentedNMEAMessage1);

        ArrayList<NMEAMessage> flush = aisMessageReceiver.flush();

        assertNotNull(flush);
        assertEquals(1, flush.size());
        assertEquals(fragmentedNMEAMessage1, flush.get(0));
    }
",non-flaky,5
112670,tbsalling_aismessages,NMEAMessageInputStreamReaderTest.catchesInvalidMessageExceptions,"    @Test
    public void catchesInvalidMessageExceptions() throws IOException {
        String nmeaStream =
            ""!AIVDM,1,1,,B,402=481uaUcf;OQ55JS9ITi025Jp,0*2B\n"" +
            ""!AIVDM,1,1,,B,58LAM242B9POUKWWW<0a>0<4E<58,0*6E\n"" +  // invalid
            ""!AIVDM,1,1,,A,33nr7t001f13KNTOahh2@QpF00vh,0*58\n"";

        InputStream inputStream = new ByteArrayInputStream(nmeaStream.getBytes(StandardCharsets.UTF_8));

        new NMEAMessageInputStreamReader(inputStream, nmeaMessageHandler).run();
    }
",non-flaky,5
112671,hwang-pku_ormlite-core,VersionUtilsTest.testCheckCoreVersusJdbcVersionsGood,"	@Test
	public void testCheckCoreVersusJdbcVersionsGood() {
		VersionUtils.setThrownOnErrors(true);
		VersionUtils.checkCoreVersusJdbcVersions(VersionUtils.getCoreVersion());
	}
",non-flaky,5
112672,hwang-pku_ormlite-core,VersionUtilsTest.testCheckCoreVersusJdbcVersionsBad,"	@Test(expected = IllegalStateException.class)
	public void testCheckCoreVersusJdbcVersionsBad() {
		VersionUtils.setThrownOnErrors(true);
		VersionUtils.checkCoreVersusJdbcVersions(""xxx"");
	}
",non-flaky,5
112673,hwang-pku_ormlite-core,VersionUtilsTest.testCheckCoreVersusAndroidVersionsGood,"	@Test
	public void testCheckCoreVersusAndroidVersionsGood() {
		VersionUtils.setThrownOnErrors(true);
		VersionUtils.checkCoreVersusAndroidVersions(VersionUtils.getCoreVersion());
	}
",non-flaky,5
112674,hwang-pku_ormlite-core,VersionUtilsTest.testCheckCoreVersusAndroidVersionsBad,"	@Test(expected = IllegalStateException.class)
	public void testCheckCoreVersusAndroidVersionsBad() {
		VersionUtils.setThrownOnErrors(true);
		VersionUtils.checkCoreVersusAndroidVersions(""xxx"");
	}
",non-flaky,5
112675,hwang-pku_ormlite-core,JavaxPersistenceTest.testConversions,"	@Test
	public void testConversions() throws Exception {
		Field[] fields = Javax.class.getDeclaredFields();
		for (Field field : fields) {
			DatabaseFieldConfig config = new JavaxPersistenceImpl().createFieldConfig(databaseType, field);
			if (field.getName().equals(""generatedId"")) {
				assertFalse(config.isId());
				assertTrue(config.isGeneratedId());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertEquals(field.getName(), config.getFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""id"")) {
				assertTrue(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertEquals(field.getName(), config.getFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""stuff"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertEquals(field.getName(), config.getFieldName());
				assertEquals(STUFF_FIELD_NAME, config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""unknown"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getDataPersister());
				assertEquals(field.getName(), config.getFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""foreignManyToOne"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertTrue(config.isForeign());
				assertFalse(config.isForeignCollection());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getDataPersister());
				assertEquals(field.getName(), config.getFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""foreignOneToOne"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertTrue(config.isForeign());
				assertFalse(config.isForeignCollection());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getDataPersister());
				assertEquals(field.getName(), config.getFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""foreignOneToMany"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertTrue(config.isForeignCollection());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getDataPersister());
				assertEquals(field.getName(), config.getFieldName());
				assertNull(config.getForeignCollectionForeignFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""mappedByField"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertTrue(config.isForeignCollection());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getDataPersister());
				assertEquals(field.getName(), config.getFieldName());
				assertEquals(MAPPED_BY_FIELD_NAME, config.getForeignCollectionForeignFieldName());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""joinFieldName"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertTrue(config.isForeign());
				assertFalse(config.isForeignCollection());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getDataPersister());
				assertEquals(field.getName(), config.getFieldName());
				assertEquals(JOIN_FIELD_NAME, config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""columnDefinition"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertFalse(config.isVersion());
				assertTrue(config.isCanBeNull());
				assertEquals(COLUMN_DEFINITION, config.getColumnDefinition());
			} else if (field.getName().equals(""uniqueColumn"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertTrue(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""nullableColumn"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertFalse(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""uniqueJoinColumn"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertTrue(config.isForeign());
				assertFalse(config.isForeignCollection());
				assertTrue(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""nullableJoinColumn"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertTrue(config.isForeign());
				assertFalse(config.isForeignCollection());
				assertFalse(config.isUnique());
				assertFalse(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""ourEnumOrdinal"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertFalse(config.isVersion());
				assertTrue(config.isCanBeNull());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
				assertTrue(config.getDataPersister() instanceof EnumIntegerType);
			} else if (field.getName().equals(""ourEnumString"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertFalse(config.isVersion());
				assertTrue(config.isCanBeNull());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
				assertTrue(config.getDataPersister() instanceof EnumStringType);
			} else if (field.getName().equals(""version"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertTrue(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""basic"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertTrue(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else if (field.getName().equals(""basicNotOptional"")) {
				assertFalse(config.isId());
				assertFalse(config.isGeneratedId());
				assertFalse(config.isForeign());
				assertFalse(config.isUnique());
				assertFalse(config.isCanBeNull());
				assertFalse(config.isVersion());
				assertNull(config.getColumnName());
				assertNull(config.getColumnDefinition());
			} else {
				System.err.println(""\n\n\nUnknown field: "" + field.getName());
			}
		}
	}
",non-flaky,5
112676,hwang-pku_ormlite-core,JavaxPersistenceTest.testTableName,"	@Test
	public void testTableName() {
		JavaxPersistenceConfigurer configurer = new JavaxPersistenceImpl();
		assertEquals(JAVAX_ENTITY_NAME, configurer.getEntityName(Javax.class));
		assertNull(configurer.getEntityName(EntityNoName.class));
	}
",non-flaky,5
112677,hwang-pku_ormlite-core,JavaxPersistenceTest.testUpperCaseFieldNames,"	@Test
	public void testUpperCaseFieldNames() throws Exception {
		Field[] fields = Javax.class.getDeclaredFields();
		UpperCaseFieldDatabaseType ucDatabaseType = new UpperCaseFieldDatabaseType();
		for (Field field : fields) {
			DatabaseFieldConfig config = new JavaxPersistenceImpl().createFieldConfig(ucDatabaseType, field);
			if (field.getName().equals(""id"")) {
				assertTrue(config.isId());
				assertFalse(config.isGeneratedId());
				assertEquals(""ID"", config.getFieldName());
			}
		}
	}
",non-flaky,5
112678,hwang-pku_ormlite-core,JavaxPersistenceTest.testSerializableClass,"	@Test
	public void testSerializableClass() throws SQLException {
		@SuppressWarnings(""unused"")
		Dao<SerializableWrapper, Integer> dao = createDao(SerializableWrapper.class, true);
		SerializableStuff stuff = new SerializableStuff();
		stuff.field1 = 12345;
		stuff.field2 = ""oejwepfjw"";
		SerializableWrapper wrapper = new SerializableWrapper();
		wrapper.stuff = stuff;

		assertEquals(1, dao.create(wrapper));

		SerializableWrapper result = dao.queryForId(wrapper.id);
		assertNotNull(result);
		assertEquals(wrapper.id, result.id);
		assertEquals(wrapper.stuff, result.stuff);
	}
",non-flaky,5
112679,hwang-pku_ormlite-core,BaseDaoEnabledTest.testCreate,"	@Test
	public void testCreate() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff = ""fewpfjewfew"";
		one.stuff = stuff;
		one.setDao(dao);
		assertEquals(1, one.create());
	}
",non-flaky,5
112680,hwang-pku_ormlite-core,BaseDaoEnabledTest.testCreateNoDao,"	@Test(expected = SQLException.class)
	public void testCreateNoDao() throws Exception {
		One one = new One();
		String stuff = ""fewpfjewfew"";
		one.stuff = stuff;
		one.create();
	}
",non-flaky,5
112681,hwang-pku_ormlite-core,BaseDaoEnabledTest.testUpdate,"	@Test
	public void testUpdate() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		assertEquals(1, dao.create(one));
		String stuff2 = ""fjpfejpwewpfjewfew"";
		one.stuff = stuff2;
		assertEquals(1, one.update());
		One one2 = dao.queryForId(one.id);
		assertEquals(stuff2, one2.stuff);
	}
",non-flaky,5
112682,hwang-pku_ormlite-core,BaseDaoEnabledTest.testUpdateId,"	@Test
	public void testUpdateId() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		assertEquals(1, dao.create(one));
		int id = one.id;
		assertNotNull(dao.queryForId(id));
		assertEquals(1, one.updateId(id + 1));
		assertNull(dao.queryForId(id));
		assertNotNull(dao.queryForId(id + 1));
	}
",non-flaky,5
112683,hwang-pku_ormlite-core,BaseDaoEnabledTest.testDelete,"	@Test
	public void testDelete() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		assertEquals(1, dao.create(one));
		assertNotNull(dao.queryForId(one.id));
		assertEquals(1, one.delete());
		assertNull(dao.queryForId(one.id));
	}
",non-flaky,5
112684,hwang-pku_ormlite-core,BaseDaoEnabledTest.testToString,"	@Test
	public void testToString() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		assertEquals(1, dao.create(one));
		String str = one.objectToString();
		assertTrue(str.contains(""id="" + one.id));
		assertTrue(str.contains(""stuff="" + stuff1));
	}
",non-flaky,5
112685,hwang-pku_ormlite-core,BaseDaoEnabledTest.testObjectEquals,"	@Test
	public void testObjectEquals() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		assertEquals(1, dao.create(one));
		assertTrue(one.objectsEqual(one));
	}
",non-flaky,5
112686,hwang-pku_ormlite-core,BaseDaoEnabledTest.testObjectEqualsNoDao,"	@Test(expected = IllegalArgumentException.class)
	public void testObjectEqualsNoDao() {
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		one.objectToString();
	}
",non-flaky,5
112687,hwang-pku_ormlite-core,BaseDaoEnabledTest.testExtractId,"	@Test
	public void testExtractId() throws Exception {
		Dao<One, Integer> dao = createDao(One.class, true);
		One one = new One();
		String stuff1 = ""fewpfjewfew"";
		one.stuff = stuff1;
		assertEquals(1, dao.create(one));
		assertEquals(one.id, (int) one.extractId());
	}
",non-flaky,5
112688,hwang-pku_ormlite-core,BaseDaoEnabledTest.testForeign,"	@Test
	public void testForeign() throws Exception {
		Dao<One, Integer> oneDao = createDao(One.class, true);
		Dao<ForeignDaoEnabled, Integer> foreignDao = createDao(ForeignDaoEnabled.class, true);

		One one = new One();
		String stuff = ""fewpfjewfew"";
		one.stuff = stuff;
		one.setDao(oneDao);
		assertEquals(1, one.create());

		ForeignDaoEnabled foreign = new ForeignDaoEnabled();
		foreign.one = one;
		foreign.setDao(foreignDao);
		assertEquals(1, foreign.create());

		ForeignDaoEnabled foreign2 = foreignDao.queryForId(foreign.id);
		assertNotNull(foreign2);
		assertEquals(one.id, foreign2.one.id);
		assertNull(foreign2.one.stuff);
		assertEquals(1, foreign2.one.refresh());
		assertEquals(stuff, foreign2.one.stuff);
	}
",non-flaky,5
112689,hwang-pku_ormlite-core,SqlExceptionUtilTest.testException,"	@Test
	public void testException() {
		Throwable cause = new Throwable();
		String msg = ""hello"";
		SQLException e = SqlExceptionUtil.create(msg, cause);
		assertEquals(msg, e.getMessage());
		assertEquals(cause, e.getCause());
	}
",non-flaky,5
112690,hwang-pku_ormlite-core,SqlExceptionUtilTest.testExceptionWithSQLException,"	@Test
	public void testExceptionWithSQLException() {
		String sqlReason = ""sql exception message"";
		String sqlState = ""sql exception state"";
		Throwable cause = new SQLException(sqlReason, sqlState);
		String msg = ""hello"";
		SQLException e = SqlExceptionUtil.create(msg, cause);
		assertEquals(msg, e.getMessage());
		assertEquals(sqlState, e.getSQLState());
		assertEquals(cause, e.getCause());
	}
",non-flaky,5
112691,hwang-pku_ormlite-core,SqlExceptionUtilTest.testConstructor,"	@Test
	public void testConstructor() throws Exception {
		@SuppressWarnings({ ""rawtypes"" })
		Constructor[] constructors = SqlExceptionUtil.class.getDeclaredConstructors();
		assertEquals(1, constructors.length);
		constructors[0].setAccessible(true);
		constructors[0].newInstance();
	}
",non-flaky,5
112692,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManager() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(false);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint);
		conn.commit(savePoint);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn, savePoint);
		TransactionManager tm = new TransactionManager(connectionSource);
		tm.callInTransaction(new Callable<Void>() {
			@Override
			public Void call() {
				return null;
			}
",non-flaky,5
112693,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerTableName() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(false);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint);
		conn.commit(savePoint);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(FOO_TABLE_NAME)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn, savePoint);
		TransactionManager tm = new TransactionManager(connectionSource);
		tm.callInTransaction(FOO_TABLE_NAME, new Callable<Void>() {
			@Override
			public Void call() {
				return null;
			}
",non-flaky,5
112694,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerSavePointNull() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(false);
		expect(conn.setSavePoint(isA(String.class))).andReturn(null);
		conn.commit(null);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn);
		TransactionManager tm = new TransactionManager(connectionSource);
		tm.callInTransaction(new Callable<Void>() {
			@Override
			public Void call() {
				return null;
			}
",non-flaky,5
112695,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerRollback() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(false);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint);
		conn.rollback(savePoint);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn, savePoint);
		TransactionManager tm = new TransactionManager(connectionSource);
		try {
			tm.callInTransaction(new Callable<Void>() {
				@Override
				public Void call() throws Exception {
					throw new SQLException(""you better roll back!!"");
				}
",non-flaky,5
112696,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerRollbackNullSavePoint() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(false);
		expect(conn.setSavePoint(isA(String.class))).andReturn(null);
		conn.rollback(null);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn);
		TransactionManager tm = new TransactionManager(connectionSource);
		try {
			tm.callInTransaction(new Callable<Void>() {
				@Override
				public Void call() throws Exception {
					throw new SQLException(""you better roll back!!"");
				}
",non-flaky,5
112697,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerRollbackOtherException() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(false);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint);
		conn.rollback(savePoint);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn, savePoint);
		TransactionManager tm = new TransactionManager(connectionSource);
		try {
			tm.callInTransaction(new Callable<Void>() {
				@Override
				public Void call() throws Exception {
					throw new Exception(""you better roll back!!"");
				}
",non-flaky,5
112698,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerAutoCommitSupported() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(true);
		expect(conn.isAutoCommit()).andReturn(false);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint);
		conn.commit(savePoint);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn, savePoint);
		TransactionManager tm = new TransactionManager(connectionSource);
		tm.callInTransaction(new Callable<Void>() {
			@Override
			public Void call() {
				return null;
			}
",non-flaky,5
112699,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionManagerAutoCommitOn() throws Exception {
		ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(true);
		expect(conn.isAutoCommit()).andReturn(true);
		conn.setAutoCommit(false);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint);
		conn.commit(savePoint);
		conn.setAutoCommit(true);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		connectionSource.clearSpecialConnection(conn);
		connectionSource.releaseConnection(conn);
		replay(connectionSource, conn, savePoint);
		TransactionManager tm = new TransactionManager(connectionSource);
		tm.callInTransaction(new Callable<Void>() {
			@Override
			public Void call() {
				return null;
			}
",non-flaky,5
112700,hwang-pku_ormlite-core,TransactionManagerTest.testTransactionManagerSpringWiring,"	@Test
	public void testTransactionManagerSpringWiring() {
		TransactionManager tm = new TransactionManager();
		tm.setConnectionSource(connectionSource);
		tm.initialize();
	}
",non-flaky,5
112701,hwang-pku_ormlite-core,TransactionManagerTest.testTransactionManagerNoSet,"	@Test(expected = IllegalStateException.class)
	public void testTransactionManagerNoSet() {
		TransactionManager tm = new TransactionManager();
		tm.initialize();
	}
",non-flaky,5
112702,hwang-pku_ormlite-core,TransactionManagerTest.testDaoTransactionManagerCommitted,"	@Test
	public void testDaoTransactionManagerCommitted() throws Exception {
		if (connectionSource == null) {
			return;
		}
		TransactionManager mgr = new TransactionManager(connectionSource);
		final Dao<Foo, Integer> fooDao = createDao(Foo.class, true);
		testTransactionManager(mgr, null, fooDao);
	}
",non-flaky,5
112703,hwang-pku_ormlite-core,TransactionManagerTest.testRollBack,"	@Test
	public void testRollBack() throws Exception {
		if (connectionSource == null) {
			return;
		}
		TransactionManager mgr = new TransactionManager(connectionSource);
		final Dao<Foo, Integer> fooDao = createDao(Foo.class, true);
		testTransactionManager(mgr, new RuntimeException(""What!!  I protest!!""), fooDao);
	}
",non-flaky,5
112704,hwang-pku_ormlite-core,TransactionManagerTest.testSpringWiredRollBack,"	@Test
	public void testSpringWiredRollBack() throws Exception {
		if (connectionSource == null) {
			return;
		}
		TransactionManager mgr = new TransactionManager();
		mgr.setConnectionSource(connectionSource);
		mgr.initialize();
		final Dao<Foo, Integer> fooDao = createDao(Foo.class, true);
		testTransactionManager(mgr, new RuntimeException(""What!!  I protest!!""), fooDao);
	}
",non-flaky,5
112705,hwang-pku_ormlite-core,TransactionManagerTest.testNonRuntimeExceptionWiredRollBack,"	@Test
	public void testNonRuntimeExceptionWiredRollBack() throws Exception {
		if (connectionSource == null) {
			return;
		}
		TransactionManager mgr = new TransactionManager();
		mgr.setConnectionSource(connectionSource);
		mgr.initialize();
		final Dao<Foo, Integer> dao = createDao(Foo.class, true);
		testTransactionManager(mgr, new Exception(""What!!  I protest via an Exception!!""), dao);
	}
",non-flaky,5
112706,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionWithinTransaction() throws Exception {
		if (connectionSource == null) {
			return;
		}
		final TransactionManager mgr = new TransactionManager(connectionSource);
		final Dao<Foo, Integer> dao = createDao(Foo.class, true);
		mgr.callInTransaction(new Callable<Void>() {
			@Override
			public Void call() throws Exception {
				testTransactionManager(mgr, null, dao);
				return null;
			}
",non-flaky,5
112707,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testTransactionWithinTransactionFails() throws Exception {
		if (connectionSource == null) {
			return;
		}
		final TransactionManager mgr = new TransactionManager(connectionSource);
		final Dao<Foo, Integer> dao = createDao(Foo.class, true);
		try {
			mgr.callInTransaction(new Callable<Void>() {
				@Override
				public Void call() throws Exception {
					dao.create(new Foo());
					mgr.callInTransaction(new Callable<Void>() {
						@Override
						public Void call() throws Exception {
							dao.create(new Foo());
							throw new SQLException(""Exception ahoy!"");
						}
",non-flaky,5
112708,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testConnectionLeakCreateList() throws Exception {
		final Dao<Foo, Integer> dao = createDao(Foo.class, true);
		final List<Foo> list = new ArrayList<Foo>();
		Foo foo1 = new Foo();
		foo1.val = 1;
		list.add(foo1);
		Foo foo2 = new Foo();
		foo2.val = 2;
		list.add(foo2);
		Foo foo3 = new Foo();
		foo3.val = 3;
		list.add(foo3);
		assertTrue(connectionSource.isOkay());
		assertEquals(0, connectionSource.getConnectionCount());
		TransactionManager.callInTransaction(connectionSource, new Callable<Boolean>() {
			@Override
			public Boolean call() throws Exception {
				return dao.create(list) >= 0;
			}
",non-flaky,5
112709,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testNestedTransactions() throws Exception {
		final Dao<Foo, Integer> dao = createDao(Foo.class, true);
		final Foo foo = new Foo();
		assertEquals(1, dao.create(foo));

		Foo result = dao.queryForId(foo.id);
		assertNotNull(result);

		try {
			TransactionManager.callInTransaction(connectionSource, new Callable<Void>() {
				@Override
				public Void call() throws Exception {
					TransactionManager.callInTransaction(connectionSource, new Callable<Void>() {
						@Override
						public Void call() throws Exception {
							dao.delete(foo);
							return null;
						}
",non-flaky,5
112710,hwang-pku_ormlite-core,TransactionManagerTest.call,"	@Test
	public void testNestedTransactionsReleaseFails() throws Exception {
		final ConnectionSource connectionSource = createMock(ConnectionSource.class);
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		expect(conn.isAutoCommitSupported()).andReturn(true).times(2);
		expect(conn.isAutoCommit()).andReturn(true).times(2);
		conn.setAutoCommit(false);
		expectLastCall().times(2);
		Savepoint savePoint = createMock(Savepoint.class);
		expect(savePoint.getSavepointName()).andReturn(""name"").anyTimes();
		expect(conn.setSavePoint(isA(String.class))).andReturn(savePoint).times(2);
		expect(connectionSource.getDatabaseType()).andReturn(databaseType).times(2);
		expect(connectionSource.getReadWriteConnection(null)).andReturn(conn).times(2);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(true);
		expect(connectionSource.saveSpecialConnection(conn)).andReturn(false);
		// should only get one of these because we only returned save once
		connectionSource.clearSpecialConnection(conn);
		conn.releaseSavePoint(savePoint);
		expectLastCall().andThrow(new SQLException(""testing the release to fail""));
		conn.rollback(savePoint);
		expectLastCall().times(2);
		connectionSource.releaseConnection(conn);
		expectLastCall().times(2);
		conn.setAutoCommit(true);
		expectLastCall().times(2);

		replay(connectionSource, conn, savePoint);
		try {
			TransactionManager.callInTransaction(connectionSource, new Callable<Void>() {
				@Override
				public Void call() throws SQLException {
					TransactionManager.callInTransaction(connectionSource, new Callable<Void>() {
						@Override
						public Void call() {
							return null;
						}
",non-flaky,5
112711,hwang-pku_ormlite-core,BaseConnectionSourceTest.testBasicStuff,"	@Test
	public void testBasicStuff() throws Exception {
		OurConnectionSource cs = new OurConnectionSource();
		assertFalse(cs.isSavedConnection(createMock(DatabaseConnection.class)));
		DatabaseConnection conn = cs.getReadOnlyConnection(null);
		assertNotNull(conn);
		assertNull(cs.getSpecialConnection(null));
		cs.saveSpecialConnection(conn);
		assertSame(conn, cs.getSpecialConnection(null));
		assertTrue(cs.isSavedConnection(conn));
		assertFalse(cs.isSavedConnection(createMock(DatabaseConnection.class)));
		DatabaseConnection conn2 = cs.getReadOnlyConnection(null);
		assertSame(conn, conn2);
		assertNotNull(conn2);
		cs.clearSpecialConnection(conn);
		assertNull(cs.getSpecialConnection(null));
		assertFalse(cs.isSavedConnection(conn));
		assertNull(cs.getSavedConnection());
		cs.close();
	}
",non-flaky,5
112712,hwang-pku_ormlite-core,BaseConnectionSourceTest.testNestedSave,"	@Test
	public void testNestedSave() throws Exception {
		OurConnectionSource cs = new OurConnectionSource();
		DatabaseConnection conn = cs.getReadOnlyConnection(null);
		cs.saveSpecialConnection(conn);
		cs.saveSpecialConnection(conn);
		cs.clearSpecialConnection(conn);
		assertEquals(conn, cs.getSpecialConnection(null));
		cs.close();
	}
",non-flaky,5
112713,hwang-pku_ormlite-core,BaseConnectionSourceTest.testSaveDifferentConnection,"	@Test(expected = SQLException.class)
	public void testSaveDifferentConnection() throws Exception {
		OurConnectionSource cs = new OurConnectionSource();
		DatabaseConnection conn = cs.getReadOnlyConnection(null);
		cs.saveSpecialConnection(conn);
		cs.saveSpecialConnection(createMock(DatabaseConnection.class));
		cs.close();
	}
",non-flaky,5
112714,hwang-pku_ormlite-core,BaseConnectionSourceTest.testClearNone,"	@Test
	public void testClearNone() {
		OurConnectionSource cs = new OurConnectionSource();
		cs.clearSpecialConnection(createMock(DatabaseConnection.class));
		cs.close();
	}
",non-flaky,5
112715,hwang-pku_ormlite-core,BaseConnectionSourceTest.testClearDifferentConnection,"	@Test
	public void testClearDifferentConnection() throws Exception {
		OurConnectionSource cs = new OurConnectionSource();
		DatabaseConnection conn = cs.getReadOnlyConnection(null);
		cs.saveSpecialConnection(conn);
		cs.clearSpecialConnection(createMock(DatabaseConnection.class));
		cs.close();
	}
",non-flaky,5
112716,hwang-pku_ormlite-core,ReflectionDatabaseConnectionProxyFactoryTest.testBasic,"	@Test
	public void testBasic() throws Exception {
		Dao<Foo, Object> dao = createDao(Foo.class, true);
		Foo foo = new Foo();
		foo.val = 1131233;

		assertEquals(0, OurConnectionProxy.insertCount);
		assertEquals(1, dao.create(foo));
		assertEquals(1, OurConnectionProxy.insertCount);

		Foo result = dao.queryForId(foo.id);
		assertEquals(foo.val + VALUE_INCREMENT, result.val);
	}
",non-flaky,5
112717,hwang-pku_ormlite-core,DatabaseConnectionProxyFactoryTest.testBasic,"	@Test
	public void testBasic() throws Exception {
		Dao<Foo, Object> dao = createDao(Foo.class, true);
		Foo foo = new Foo();
		foo.val = 100;

		ConnectionProxy.lastValue = 0;
		assertEquals(1, dao.create(foo));
		/*
		 * After we create an instance of foo, we check to see that our proxy was able to intercept the val argument.
		 */
		assertEquals(foo.val, ConnectionProxy.lastValue);
	}
",non-flaky,5
112718,hwang-pku_ormlite-core,DatabaseConnectionProxyFactoryTest.testChangeInsertValue,"	@Test
	public void testChangeInsertValue() throws Exception {
		Dao<Foo, Object> dao = createDao(Foo.class, true);
		Foo foo = new Foo();
		foo.val = TEST_CHANGE_FROM;

		ConnectionProxy.lastValue = 0;
		assertEquals(1, dao.create(foo));
		/*
		 * After we create an instance of foo, we check to see that our proxy was able to intercept the val argument.
		 */
		assertEquals(foo.val, ConnectionProxy.lastValue);

		Foo result = dao.queryForId(foo.id);
		assertNotNull(result);
		assertEquals(TEST_CHANGE_TO, result.val);
		assertTrue(result.val != TEST_CHANGE_FROM);
	}
",non-flaky,5
112719,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsAutoCommitSupported,"	@Test
	public void testIsAutoCommitSupported() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		boolean supported = true;
		expect(conn.isAutoCommitSupported()).andReturn(supported);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(supported, proxy.isAutoCommitSupported());
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112720,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsAutoCommitSupportedNull,"	@Test
	public void testIsAutoCommitSupportedNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertFalse(proxy.isAutoCommitSupported());
		proxy.close();
	}
",non-flaky,5
112721,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsAutoCommit,"	@Test
	public void testIsAutoCommit() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		boolean autoCommit = false;
		expect(conn.isAutoCommit()).andReturn(autoCommit);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(autoCommit, proxy.isAutoCommit());
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112722,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsAutoCommitNull,"	@Test
	public void testIsAutoCommitNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertFalse(proxy.isAutoCommit());
		proxy.close();
	}
",non-flaky,5
112723,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testSetAutoCommit,"	@Test
	public void testSetAutoCommit() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		boolean autoCommit = false;
		conn.setAutoCommit(autoCommit);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.setAutoCommit(autoCommit);
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112724,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testSetAutoCommitNull,"	@Test
	public void testSetAutoCommitNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		proxy.setAutoCommit(false);
		proxy.close();
	}
",non-flaky,5
112725,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testSetSavePoint,"	@Test
	public void testSetSavePoint() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String name = ""savepoint"";
		expect(conn.setSavePoint(name)).andReturn(null);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.setSavePoint(name);
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112726,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testSetSavePointNull,"	@Test
	public void testSetSavePointNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertNull(proxy.setSavePoint(""name""));
		proxy.close();
	}
",non-flaky,5
112727,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCommit,"	@Test
	public void testCommit() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		conn.commit(null);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.commit(null);
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112728,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCommitNull,"	@Test
	public void testCommitNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		proxy.commit(null);
		proxy.close();
	}
",non-flaky,5
112729,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testRollback,"	@Test
	public void testRollback() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		conn.rollback(null);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.rollback(null);
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112730,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testRollbackNull,"	@Test
	public void testRollbackNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		proxy.rollback(null);
		proxy.close();
	}
",non-flaky,5
112731,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testExecuteStatement,"	@Test
	public void testExecuteStatement() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""select foo from bar"";
		int result = 1312321;
		expect(conn.executeStatement(statement, 0)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.executeStatement(statement, 0));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112732,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testExecuteStatementNull,"	@Test
	public void testExecuteStatementNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertEquals(0, proxy.executeStatement(""statment"", 0));
		proxy.close();
	}
",non-flaky,5
112733,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCompileStatementStringStatementTypeFieldTypeArrayInt,"	@Test
	public void testCompileStatementStringStatementTypeFieldTypeArrayInt() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""select foo from bar"";
		StatementType type = StatementType.DELETE;
		int flags = 11253123;
		expect(conn.compileStatement(statement, type, null, flags, false)).andReturn(null);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.compileStatement(statement, type, null, flags, false);
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112734,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCompileStatementStringStatementTypeFieldTypeArrayIntNull,"	@Test
	public void testCompileStatementStringStatementTypeFieldTypeArrayIntNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertNull(proxy.compileStatement(""statment"", StatementType.DELETE, null, 0, false));
		proxy.close();
	}
",non-flaky,5
112735,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testInsert,"	@Test
	public void testInsert() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""insert bar"";
		int result = 13712321;
		expect(conn.insert(statement, null, null, null)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.insert(statement, null, null, null));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112736,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testInsertNull,"	@Test
	public void testInsertNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertEquals(0, proxy.insert(""statment"", null, null, null));
		proxy.close();
	}
",non-flaky,5
112737,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testUpdate,"	@Test
	public void testUpdate() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""insert bar"";
		int result = 13212321;
		expect(conn.update(statement, null, null)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.update(statement, null, null));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112738,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testUpdateNull,"	@Test
	public void testUpdateNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertEquals(0, proxy.update(""statment"", null, null));
		proxy.close();
	}
",non-flaky,5
112739,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testDelete,"	@Test
	public void testDelete() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""insert bar"";
		int result = 13872321;
		expect(conn.delete(statement, null, null)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.delete(statement, null, null));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112740,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testDeleteNull,"	@Test
	public void testDeleteNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertEquals(0, proxy.delete(""statment"", null, null));
		proxy.close();
	}
",non-flaky,5
112741,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testQueryForOne,"	@Test
	public void testQueryForOne() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""insert bar"";
		Object result = new Object();
		expect(conn.queryForOne(statement, null, null, null, null)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.queryForOne(statement, null, null, null, null));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112742,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testQueryForOneNull,"	@Test
	public void testQueryForOneNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertNull(proxy.queryForOne(""statment"", null, null, null, null));
		proxy.close();
	}
",non-flaky,5
112743,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testQueryForLongString,"	@Test
	public void testQueryForLongString() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""select stuff from foo"";
		long result = 31231231241414L;
		expect(conn.queryForLong(statement)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.queryForLong(statement));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112744,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testQueryForLongStringNull,"	@Test
	public void testQueryForLongStringNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertEquals(0, proxy.queryForLong(""statment""));
		proxy.close();
	}
",non-flaky,5
112745,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testQueryForLongStringObjectArrayFieldTypeArray,"	@Test
	public void testQueryForLongStringObjectArrayFieldTypeArray() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		String statement = ""select stuff from foo"";
		long result = 3123123124141413L;
		expect(conn.queryForLong(statement, null, null)).andReturn(result);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(result, proxy.queryForLong(statement, null, null));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112746,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testQueryForLongStringObjectArrayFieldTypeArrayNull,"	@Test
	public void testQueryForLongStringObjectArrayFieldTypeArrayNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertEquals(0, proxy.queryForLong(""statment"", null, null));
		proxy.close();
	}
",non-flaky,5
112747,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testClose,"	@Test
	public void testClose() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112748,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCloseNull,"	@Test
	public void testCloseNull() throws Exception {
		new DatabaseConnectionProxy(null).close();
	}
",non-flaky,5
112749,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCloseQuietly,"	@Test
	public void testCloseQuietly() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		conn.closeQuietly();
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		proxy.closeQuietly();
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112750,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testCloseQuietlyNull,"	@Test
	public void testCloseQuietlyNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		proxy.closeQuietly();
		proxy.close();
	}
",non-flaky,5
112751,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsClosed,"	@Test
	public void testIsClosed() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		boolean closed = true;
		expect(conn.isClosed()).andReturn(closed);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(closed, proxy.isClosed());
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112752,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsClosedNull,"	@Test
	public void testIsClosedNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertTrue(proxy.isClosed());
		proxy.close();
	}
",non-flaky,5
112753,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsTableExists,"	@Test
	public void testIsTableExists() throws Exception {
		DatabaseConnection conn = createMock(DatabaseConnection.class);
		boolean tableExists = true;
		String tableName = ""fjewfjwef"";
		expect(conn.isTableExists(tableName)).andReturn(tableExists);
		conn.close();
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(conn);
		replay(conn);
		assertEquals(tableExists, proxy.isTableExists(tableName));
		proxy.close();
		verify(conn);
	}
",non-flaky,5
112754,hwang-pku_ormlite-core,DatabaseConnectionProxyTest.testIsTableExistsNull,"	@Test
	public void testIsTableExistsNull() throws Exception {
		DatabaseConnectionProxy proxy = new DatabaseConnectionProxy(null);
		assertFalse(proxy.isTableExists(""foo""));
		proxy.close();
	}
",non-flaky,5
112755,hwang-pku_ormlite-core,ThreadLocalSelectArgTest.testStuff,"	@Test
	public void testStuff() {
		ThreadLocalSelectArg arg = new ThreadLocalSelectArg();
		assertNull(arg.getValue());
		assertFalse(arg.isValueSet());
		arg.setValue(null);
		assertNull(arg.getValue());
		assertTrue(arg.isValueSet());
	}
",non-flaky,5
112756,hwang-pku_ormlite-core,ThreadLocalSelectArgTest.testValueConst,"	@Test
	public void testValueConst() {
		int val = 12;
		ThreadLocalSelectArg arg = new ThreadLocalSelectArg(val);
		assertTrue(arg.isValueSet());
		assertEquals(val, arg.getValue());
	}
",non-flaky,5
112757,hwang-pku_ormlite-core,ThreadLocalSelectArgTest.testSqlTypeValueConst,"	@Test
	public void testSqlTypeValueConst() {
		int val = 12;
		SqlType type = SqlType.INTEGER;
		ThreadLocalSelectArg arg = new ThreadLocalSelectArg(type, val);
		assertTrue(arg.isValueSet());
		assertEquals(val, arg.getValue());
		assertEquals(type, arg.getSqlType());
	}
",non-flaky,5
112758,hwang-pku_ormlite-core,ThreadLocalSelectArgTest.testColumnNameTypeValueConst,"	@Test
	public void testColumnNameTypeValueConst() {
		int val = 12;
		String columnName = ""fewopjfewpfjwe"";
		ThreadLocalSelectArg arg = new ThreadLocalSelectArg(columnName, val);
		assertTrue(arg.isValueSet());
		assertEquals(val, arg.getValue());
		assertEquals(columnName, arg.getColumnName());
	}
",non-flaky,5
112759,hwang-pku_ormlite-core,RawResultsImplTest.testQueryRaw,"	@Test
	public void testQueryRaw() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		Foo foo = new Foo();
		foo.val = 1;
		foo.equal = 10;
		assertEquals(1, dao.create(foo));
		QueryBuilder<Foo, Integer> qb = dao.queryBuilder();
		qb.where().eq(Foo.VAL_COLUMN_NAME, new SelectArg());
		GenericRawResults<String[]> rawResults = dao.queryRaw(qb.prepareStatementString(), Integer.toString(foo.val));
		List<String[]> results = rawResults.getResults();
		assertEquals(1, results.size());
		boolean found = false;
		String[] columnNames = rawResults.getColumnNames();
		for (int i = 0; i < rawResults.getNumberColumns(); i++) {
			if (columnNames[i].equalsIgnoreCase(Foo.ID_COLUMN_NAME)) {
				assertEquals(Integer.toString(foo.id), results.get(0)[0]);
				found = true;
			}
		}
		assertTrue(found);
	}
",non-flaky,5
112760,hwang-pku_ormlite-core,RawResultsImplTest.testQueryRawColumns,"	@Test
	public void testQueryRawColumns() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		Foo foo1 = new Foo();
		foo1.val = 1;
		foo1.equal = 10;
		assertEquals(1, dao.create(foo1));
		Foo foo2 = new Foo();
		foo2.val = 10;
		foo2.equal = 5;
		assertEquals(1, dao.create(foo2));
		QueryBuilder<Foo, Integer> qb = dao.queryBuilder();
		qb.selectRaw(""COUNT(*)"");
		GenericRawResults<String[]> rawResults = dao.queryRaw(qb.prepareStatementString());
		List<String[]> results = rawResults.getResults();
		assertEquals(1, results.size());
		// 2 rows inserted
		assertEquals(""2"", results.get(0)[0]);

		qb = dao.queryBuilder();
		qb.selectRaw(""MIN(val)"", ""MAX(val)"");
		rawResults = dao.queryRaw(qb.prepareStatementString());
		results = rawResults.getResults();
		assertEquals(1, results.size());
		String[] result = results.get(0);
		assertEquals(2, result.length);
		// foo1 has the maximum value
		assertEquals(Integer.toString(foo1.val), result[0]);
		// foo2 has the maximum value
		assertEquals(Integer.toString(foo2.val), result[1]);
	}
",non-flaky,5
112761,hwang-pku_ormlite-core,RawResultsImplTest.testHaving,"	@Test
	public void testHaving() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);

		Foo foo = new Foo();
		int val1 = 243342;
		foo.val = val1;
		assertEquals(1, dao.create(foo));
		foo = new Foo();
		foo.val = val1;
		assertEquals(1, dao.create(foo));
		foo = new Foo();
		// only one of these
		int val2 = 6543;
		foo.val = val2;
		assertEquals(1, dao.create(foo));

		QueryBuilder<Foo, Integer> qb = dao.queryBuilder();
		qb.selectColumns(Foo.VAL_COLUMN_NAME);
		qb.groupBy(Foo.VAL_COLUMN_NAME);
		qb.having(""COUNT(VAL) > 1"");
		GenericRawResults<String[]> results = dao.queryRaw(qb.prepareStatementString());
		List<String[]> list = results.getResults();
		// only val2 has 2 of them
		assertEquals(1, list.size());
		assertEquals(String.valueOf(val1), list.get(0)[0]);

		qb.having(""COUNT(VAL) > 2"");
		results = dao.queryRaw(qb.prepareStatementString());
		list = results.getResults();
		assertEquals(0, list.size());
	}
",non-flaky,5
112762,hwang-pku_ormlite-core,RawResultsImplTest.testGetFirstResult,"	@Test
	public void testGetFirstResult() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		Foo foo1 = new Foo();
		foo1.val = 342;
		assertEquals(1, dao.create(foo1));
		Foo foo2 = new Foo();
		foo2.val = 9045342;
		assertEquals(1, dao.create(foo2));

		QueryBuilder<Foo, Integer> qb = dao.queryBuilder();
		qb.selectRaw(""MAX("" + Foo.VAL_COLUMN_NAME + "")"");
		GenericRawResults<String[]> results = dao.queryRaw(qb.prepareStatementString());
		String[] result = results.getFirstResult();
		int max = Integer.parseInt(result[0]);
		if (foo1.val > foo2.val) {
			assertEquals(foo1.val, max);
		} else {
			assertEquals(foo2.val, max);
		}
	}
",non-flaky,5
112763,hwang-pku_ormlite-core,RawResultsImplTest.mapRow,"	@Test
	public void testCustomColumnNames() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		Foo foo = new Foo();
		foo.val = 1213213;
		assertEquals(1, dao.create(foo));
		final String idName = ""SOME_ID"";
		final String valName = ""SOME_VAL"";
		final AtomicBoolean gotResult = new AtomicBoolean(false);
		GenericRawResults<Object> results =
				dao.queryRaw(""select id as "" + idName + "", val as "" + valName + "" from foo"",
						new RawRowMapper<Object>() {
							@Override
							public Object mapRow(String[] columnNames, String[] resultColumns) {
								assertEquals(idName, columnNames[0]);
								assertEquals(valName, columnNames[1]);
								gotResult.set(true);
								return new Object();
							}
",non-flaky,5
112764,hwang-pku_ormlite-core,DeleteBuilderTest.testDeleteAll,"	@Test
	public void testDeleteAll() throws Exception {
		DeleteBuilder<Foo, Integer> stmtb = new DeleteBuilder<Foo, Integer>(databaseType, baseFooTableInfo, null);
		StringBuilder sb = new StringBuilder();
		sb.append(""DELETE FROM "");
		databaseType.appendEscapedEntityName(sb, baseFooTableInfo.getTableName());
		assertEquals(sb.toString(), stmtb.prepareStatementString());
	}
",non-flaky,5
112765,hwang-pku_ormlite-core,DeleteBuilderTest.testDeleteMethod,"	@Test
	public void testDeleteMethod() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		Foo foo = new Foo();
		foo.val = 123123;
		assertEquals(1, dao.create(foo));

		assertNotNull(dao.queryForId(foo.id));
		DeleteBuilder<Foo, Integer> db = dao.deleteBuilder();
		// no match
		db.where().eq(Foo.VAL_COLUMN_NAME, foo.val + 1);
		assertEquals(0, db.delete());
		assertNotNull(dao.queryForId(foo.id));

		db.where().reset();
		db.where().eq(Foo.VAL_COLUMN_NAME, foo.val);
		assertEquals(1, db.delete());
		assertNull(dao.queryForId(foo.id));
	}
",non-flaky,5
112766,hwang-pku_ormlite-core,DeleteBuilderTest.testUpdateLimit,"	@Test
	public void testUpdateLimit() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		int num = 3;
		for (int i = 0; i < num; i++) {
			dao.create(new Foo());
		}
		long limit = 2;
		assertEquals(limit, dao.deleteBuilder().limit(limit).delete());
		int count = (int) dao.countOf();
		assertEquals(num - limit, count);
		assertNotEquals(num, count);
	}
",non-flaky,5
112767,hwang-pku_ormlite-core,SelectIteratorTest.testIterator,"	@Test
	public void testIterator() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		CloseableIterator<Foo> iterator = dao.iterator();
		assertFalse(iterator.hasNext());

		Foo foo1 = new Foo();
		assertEquals(1, dao.create(foo1));

		Foo foo2 = new Foo();
		assertEquals(1, dao.create(foo2));

		iterator = dao.iterator();
		assertTrue(iterator.hasNext());
		Foo result = iterator.next();
		assertEquals(foo1.id, result.id);
		assertTrue(iterator.hasNext());

		result = iterator.next();
		assertEquals(foo2.id, result.id);

		assertFalse(iterator.hasNext());
		assertNull(iterator.nextThrow());
	}
",non-flaky,5
112768,hwang-pku_ormlite-core,SelectIteratorTest.testIteratorPrepared,"	@Test
	public void testIteratorPrepared() throws Exception {
		Dao<Foo, Integer> dao = createDao(Foo.class, true);
		Foo foo1 = new Foo();
		assertEquals(1, dao.create(foo1));

		Foo foo2 = new Foo();
		assertEquals(1, dao.create(foo2));

		PreparedQuery<Foo> query = dao.queryBuilder().where().eq(Foo.ID_COLUMN_NAME, foo2.id).prepare();
		CloseableIterator<Foo> iterator = dao.iterator(query);
		assertTrue(iterator.hasNext());
		Foo result = iterator.next();
		assertEquals(foo2.id, result.id);
		assertFalse(iterator.hasNext());
		assertNull(iterator.nextThrow());
	}
",non-flaky,5
112769,hwang-pku_ormlite-core,SelectIteratorTest.testIteratorRemoveNoNext,"	@Test(expected = IllegalStateException.class)
	public void testIteratorRemoveNoNext() throws Exception {
		Dao<Foo, Object> dao = createDao(Foo.class, true);
		CloseableIterator<Foo> iterator = dao.iterator();
		try {
			iterator.remove();
		} finally {
			iterator.close();
		}
	}
",non-flaky,5
112770,hwang-pku_ormlite-core,SelectIteratorTest.testIteratorNextRemoveRemoveNoNext,"	@Test(expected = IllegalStateException.class)
	public void testIteratorNextRemoveRemoveNoNext() throws Exception {
		Dao<Foo, Object> dao = createDao(Foo.class, true);
		Foo foo1 = new Foo();
		assertEquals(1, dao.create(foo1));
		Foo foo2 = new Foo();
		assertEquals(1, dao.create(foo2));
		CloseableIterator<Foo> iterator = dao.iterator();
		try {
			iterator.next();
			iterator.remove();
			iterator.remove();
		} finally {
			iterator.close();
		}
	}
",non-flaky,5
113857,finos_symphony-wdk,IntegrationTestConfiguration.workflowResourcesProvider,"@TestConfiguration
  public ResourceProvider workflowResourcesProvider() {
    return new TestResourcesProvider(Paths.get(""dummy"").toString());
  }
",non-flaky,5
113970,apache_struts,DefaultActionProxyTest.testThorwExceptionOnNotAllowedMethod,"    @Test
    public void testThorwExceptionOnNotAllowedMethod() throws Exception {
        final String filename = ""com/opensymphony/xwork2/config/providers/xwork-test-allowed-methods.xml"";
        loadConfigurationProviders(new XmlConfigurationProvider(filename));
        DefaultActionProxy dap = new DefaultActionProxy(new MockActionInvocation(), ""strict"", ""Default"", ""notAllowed"", true, true);
        container.inject(dap);

        try {
            dap.prepare();
            fail(""Must throw exception!"");
        } catch (Exception e) {
            assertEquals(e.getMessage(), ""Method notAllowed for action Default is not allowed!"");
        }
    }
",non-flaky,5
113971,apache_struts,RequiredFieldValidatorTest.testNullObject,"    @Test
    public void testNullObject() throws Exception {
        // given
        RequiredFieldValidator rfv = container.inject(RequiredFieldValidator.class);
        rfv.setValueStack(ActionContext.getContext().getValueStack());
        rfv.setFieldName(""stringValue"");
        rfv.setDefaultMessage(""${fieldName} field is required!"");
        ValidationAction action = new ValidationAction();
        DummyValidatorContext context = new DummyValidatorContext(action, container.getInstance(TextProviderFactory.class));
        rfv.setValidatorContext(context);

        // when
        rfv.validate(action);

        // then
        assertTrue(context.hasFieldErrors());
        assertEquals(1, context.getFieldErrors().size());
        assertNotNull(context.getFieldErrors().get(""stringValue""));
        assertEquals(""stringValue field is required!"", context.getFieldErrors().get(""stringValue"").get(0));
    }
",non-flaky,5
113972,apache_struts,RequiredFieldValidatorTest.testArrayObject,"    @Test
    public void testArrayObject() throws Exception {
        // given
        RequiredFieldValidator rfv = container.inject(RequiredFieldValidator.class);
        rfv.setValueStack(ActionContext.getContext().getValueStack());
        rfv.setFieldName(""ints"");
        rfv.setDefaultMessage(""${fieldName} field is required!"");
        ValidationAction action = new ValidationAction();
        action.setInts(new Integer[]{});
        DummyValidatorContext context = new DummyValidatorContext(action, container.getInstance(TextProviderFactory.class));
        rfv.setValidatorContext(context);

        // when
        rfv.validate(action);

        // then
        assertTrue(context.hasFieldErrors());
        assertEquals(1, context.getFieldErrors().size());
        assertNotNull(context.getFieldErrors().get(""ints""));
        assertEquals(""ints field is required!"", context.getFieldErrors().get(""ints"").get(0));
    }
",non-flaky,5
113973,apache_struts,RequiredFieldValidatorTest.testCollectionObject,"    @Test
    public void testCollectionObject() throws Exception {
        // given
        RequiredFieldValidator rfv = container.inject(RequiredFieldValidator.class);
        rfv.setValueStack(ActionContext.getContext().getValueStack());
        rfv.setFieldName(""shorts"");
        rfv.setDefaultMessage(""${fieldName} field is required!"");
        ValidationAction action = new ValidationAction();
        action.setShorts(new ArrayList<Short>());
        DummyValidatorContext context = new DummyValidatorContext(action, container.getInstance(TextProviderFactory.class));
        rfv.setValidatorContext(context);

        // when
        rfv.validate(action);

        // then
        assertTrue(context.hasFieldErrors());
        assertEquals(1, context.getFieldErrors().size());
        assertNotNull(context.getFieldErrors().get(""shorts""));
        assertEquals(""shorts field is required!"", context.getFieldErrors().get(""shorts"").get(0));
    }
",non-flaky,5
113974,apache_struts,TestNGXWorkTestCaseTest.testRun,"    @Test
        public void testRun() {
            ran = true;
            mgr = this.configurationManager;
        }
",non-flaky,5
113975,apache_struts,NamedVariablePatternMatcherTest.testCompile,"    @Test
    public void testCompile() {
        NamedVariablePatternMatcher matcher = new NamedVariablePatternMatcher();

        assertNull(matcher.compilePattern(null));
        assertNull(matcher.compilePattern(""""));

        CompiledPattern pattern = matcher.compilePattern(""foo"");
        assertEquals(""foo"", pattern.getPattern().pattern());

        pattern = matcher.compilePattern(""foo{jim}"");
        assertEquals(""foo([^/]+)"", pattern.getPattern().pattern());
        assertEquals(""jim"", pattern.getVariableNames().get(0));

        pattern = matcher.compilePattern(""foo{jim}/{bob}"");
        assertEquals(""foo([^/]+)/([^/]+)"", pattern.getPattern().pattern());
        assertEquals(""jim"", pattern.getVariableNames().get(0));
        assertEquals(""bob"", pattern.getVariableNames().get(1));
        assertTrue(pattern.getPattern().matcher(""foostar/jie"").matches());
        assertFalse(pattern.getPattern().matcher(""foo/star/jie"").matches());
    }
",non-flaky,5
113976,apache_struts,NamedVariablePatternMatcherTest.testCompileWithMismatchedBracketsParses,"    @Test(expected = IllegalArgumentException.class)
    public void testCompileWithMismatchedBracketsParses() {
        NamedVariablePatternMatcher matcher = new NamedVariablePatternMatcher();

        matcher.compilePattern(""}"");
",non-flaky,5
113977,apache_struts,NamedVariablePatternMatcherTest.testMatch,"    @Test
    public void testMatch() {
        NamedVariablePatternMatcher matcher = new NamedVariablePatternMatcher();

        Map<String, String> vars = new HashMap<>();
        CompiledPattern pattern = new CompiledPattern(Pattern.compile(""foo([^/]+)""), Arrays.asList(""bar""));

        assertTrue(matcher.match(vars, ""foobaz"", pattern));
        assertEquals(""baz"", vars.get(""bar""));
    }
",non-flaky,5
113978,apache_struts,NamedVariablePatternMatcherTest.testIsLiteral,"    @Test
    public void testIsLiteral() {
        NamedVariablePatternMatcher matcher = new NamedVariablePatternMatcher();

        assertTrue(matcher.isLiteral(""bob""));
        assertFalse(matcher.isLiteral(""bob{jim}""));
    }
",non-flaky,5
113979,apache_struts,ParameterTest.shouldConvertRequestValuesToStringArrays,"    @Test(dataProvider = ""paramValues"")
    public void shouldConvertRequestValuesToStringArrays(Object input, String[] expected) {
        Parameter.Request request = new Parameter.Request(PARAM_NAME, input);

        String[] result = request.getMultipleValues();

        assertEquals(result, expected);
        assertNotSame(result, input);
    }
",non-flaky,5
113980,apache_struts,JakartaStreamMultiPartRequestTest.unknownContentLength,"    @Test
    public void unknownContentLength() throws IOException {
        HttpServletRequest request = Mockito.mock(HttpServletRequest.class);
        Mockito.when(request.getContentType()).thenReturn(""multipart/form-data; charset=utf-8; boundary=__X_BOUNDARY__"");
        Mockito.when(request.getMethod()).thenReturn(""POST"");
        Mockito.when(request.getContentLength()).thenReturn(Integer.valueOf(-1));
        StringBuilder entity = new StringBuilder();
        entity.append(""\r\n--__X_BOUNDARY__\r\n"");
        entity.append(""Content-Disposition: form-data; name=\""upload\""; filename=\""test.csv\""\r\n"");
        entity.append(""Content-Type: text/csv\r\n\r\n1,2\r\n\r\n"");
        entity.append(""--__X_BOUNDARY__\r\n"");
        entity.append(""Content-Disposition: form-data; name=\""upload2\""; filename=\""test2.csv\""\r\n"");
        entity.append(""Content-Type: text/csv\r\n\r\n3,4\r\n\r\n"");
        entity.append(""--__X_BOUNDARY__--\r\n"");
        Mockito.when(request.getInputStream()).thenReturn(new DelegatingServletInputStream(new ByteArrayInputStream(entity.toString().getBytes(StandardCharsets.UTF_8))));
        multiPart.setMaxSize(""4"");
        multiPart.parse(request, tempDir.toString());
        LocalizedMessage next = multiPart.getErrors().iterator().next();
        Assert.assertEquals(next.getTextKey(), ""struts.messages.upload.error.SizeLimitExceededException"");
    }
",non-flaky,5
113981,apache_struts,StrutsJavaConfigurationProviderTest.unknownHandlerStack,"    @Test
    public void testRegister() throws Exception {
        final ConstantConfig constantConfig = new ConstantConfig();
        constantConfig.setDevMode(true);

        final String expectedUnknownHandler = ""expectedUnknownHandler"";

        StrutsJavaConfiguration javaConfig = new StrutsJavaConfiguration() {
            @Override
            public List<String> unknownHandlerStack() {
                return Arrays.asList(expectedUnknownHandler);
            }
",non-flaky,5
113982,apache_struts,ConstantConfigTest.testBeanConfToString,"    @Test
    public void testBeanConfToString() throws Exception {
        ConstantConfig constantConfig = new ConstantConfig();

        String actual = constantConfig.beanConfToString(null);
        Assert.assertEquals(null, actual);

        actual = constantConfig.beanConfToString(new BeanConfig(TestBean.class));
        Assert.assertEquals(Container.DEFAULT_NAME, actual);

        String expectedName = ""expectedTestBeanName"";
        actual = constantConfig.beanConfToString(new BeanConfig(TestBean.class, expectedName));
        Assert.assertEquals(expectedName, actual);
    }
",non-flaky,5
113983,apache_struts,ConstantConfigTest.testGetAllAsStringsMap,"    @Test
    public void testGetAllAsStringsMap() throws Exception {
        ConstantConfig constantConfig = new ConstantConfig();

        boolean expectedDevMode = true;
        constantConfig.setDevMode(expectedDevMode);

        String expectedActionExtensions = "".action,.some,.another"";
        constantConfig.setActionExtension(Arrays.asList(expectedActionExtensions.split("","")));

        String expectedLanguage = ""fr"";
        constantConfig.setLocale(new Locale(expectedLanguage));

        Map<String, String> map = constantConfig.getAllAsStringsMap();

        Assert.assertEquals(String.valueOf(expectedDevMode), map.get(StrutsConstants.STRUTS_DEVMODE));
        Assert.assertEquals(expectedActionExtensions, map.get(StrutsConstants.STRUTS_ACTION_EXTENSION));
        Assert.assertEquals(null, map.get(StrutsConstants.STRUTS_I18N_RELOAD));
        Assert.assertEquals(expectedLanguage, map.get(StrutsConstants.STRUTS_LOCALE));
    }
",non-flaky,5
113984,apache_struts,ConstantConfigTest.testEmptyClassesToString,"    @Test
    public void testEmptyClassesToString() throws Exception {
        ConstantConfig constantConfig = new ConstantConfig();

        constantConfig.setExcludedClasses(new HashSet<Class<?>>());

        Map<String, String> map = constantConfig.getAllAsStringsMap();
        Assert.assertEquals(null, map.get(StrutsConstants.STRUTS_EXCLUDED_CLASSES));
    }
",non-flaky,5
113985,apache_struts,ConstantConfigTest.testClassesToString,"    @Test
    public void testClassesToString() throws Exception {
        ConstantConfig constantConfig = new ConstantConfig();

        Set<Class<?>> excludedClasses = new LinkedHashSet<>();
        excludedClasses.add(Object.class);
        excludedClasses.add(Runtime.class);
        excludedClasses.add(System.class);

        constantConfig.setExcludedClasses(excludedClasses);

        Map<String, String> map = constantConfig.getAllAsStringsMap();
        Assert.assertEquals(""java.lang.Object,java.lang.Runtime,java.lang.System"",
                map.get(StrutsConstants.STRUTS_EXCLUDED_CLASSES));
    }
",non-flaky,5
113986,apache_struts,BeanConfigTest.testConstructor,"    @Test
    public void testConstructor() throws Exception {
        Class<TestBean> expectedClass = TestBean.class;

        BeanConfig beanConfig = new BeanConfig(expectedClass);

        Assert.assertEquals(expectedClass, beanConfig.getClazz());
        Assert.assertEquals(Container.DEFAULT_NAME, beanConfig.getName());
        Assert.assertEquals(Scope.SINGLETON, beanConfig.getScope());
        Assert.assertEquals(expectedClass, beanConfig.getType());
        Assert.assertFalse(beanConfig.isOnlyStatic());
        Assert.assertFalse(beanConfig.isOptional());
    }
",non-flaky,5
113987,apache_struts,BeanConfigTest.testConstructor2,"    @Test
    public void testConstructor2() throws Exception {
        Class<TestBean> expectedClass = TestBean.class;
        String expectedName = ""expectedBeanName"";
        Class<Object> expectedType = Object.class;
        Scope expectedScope = Scope.PROTOTYPE;
        boolean expectedOnlyStatic = true;
        boolean expectedOptional = true;

        BeanConfig beanConfig = new BeanConfig(expectedClass, expectedName, expectedType, expectedScope,
                expectedOnlyStatic, expectedOptional);

        Assert.assertEquals(expectedClass, beanConfig.getClazz());
        Assert.assertEquals(expectedName, beanConfig.getName());
        Assert.assertEquals(expectedScope, beanConfig.getScope());
        Assert.assertEquals(expectedType, beanConfig.getType());
        Assert.assertEquals(expectedOnlyStatic, beanConfig.isOnlyStatic());
        Assert.assertEquals(expectedOptional, beanConfig.isOptional());
    }
",non-flaky,5
113988,apache_struts,URLDecoderUtilTest.testURLDecodeStringInvalid,"    @Test
    public void testURLDecodeStringInvalid() {
        // %n rather than %nn should throw an IAE according to the Javadoc
        Exception exception = null;
        try {
            URLDecoderUtil.decode(""%5xxxxx"", ""ISO-8859-1"");
        } catch (Exception e) {
            exception = e;
        }
        assertTrue(exception instanceof IllegalArgumentException);

        // Edge case trying to trigger ArrayIndexOutOfBoundsException
        exception = null;
        try {
            URLDecoderUtil.decode(""%5"", ""ISO-8859-1"");
        } catch (Exception e) {
            exception = e;
        }
        assertTrue(exception instanceof IllegalArgumentException);
    }
",non-flaky,5
113989,apache_struts,URLDecoderUtilTest.testURLDecodeStringValidIso88591Start,"    @Test
    public void testURLDecodeStringValidIso88591Start() {

        String result = URLDecoderUtil.decode(""%41xxxx"", ""ISO-8859-1"");
        assertEquals(""Axxxx"", result);
    }
",non-flaky,5
113990,apache_struts,URLDecoderUtilTest.testURLDecodeStringValidIso88591Middle,"    @Test
    public void testURLDecodeStringValidIso88591Middle() {

        String result = URLDecoderUtil.decode(""xx%41xx"", ""ISO-8859-1"");
        assertEquals(""xxAxx"", result);
    }
",non-flaky,5
113991,apache_struts,URLDecoderUtilTest.testURLDecodeStringValidIso88591End,"    @Test
    public void testURLDecodeStringValidIso88591End() {

        String result = URLDecoderUtil.decode(""xxxx%41"", ""ISO-8859-1"");
        assertEquals(""xxxxA"", result);
    }
",non-flaky,5
113992,apache_struts,URLDecoderUtilTest.testURLDecodeStringValidUtf8Start,"    @Test
    public void testURLDecodeStringValidUtf8Start() {
        String result = URLDecoderUtil.decode(""%c3%aaxxxx"", ""UTF-8"");
        assertEquals(""\u00eaxxxx"", result);
    }
",non-flaky,5
113993,apache_struts,URLDecoderUtilTest.testURLDecodeStringValidUtf8Middle,"    @Test
    public void testURLDecodeStringValidUtf8Middle() {

        String result = URLDecoderUtil.decode(""xx%c3%aaxx"", ""UTF-8"");
        assertEquals(""xx\u00eaxx"", result);
    }
",non-flaky,5
113994,apache_struts,URLDecoderUtilTest.testURLDecodeStringValidUtf8End,"    @Test
    public void testURLDecodeStringValidUtf8End() {

        String result = URLDecoderUtil.decode(""xxxx%c3%aa"", ""UTF-8"");
        assertEquals(""xxxx\u00ea"", result);
    }
",non-flaky,5
113995,apache_struts,URLDecoderUtilTest.testURLDecodePlusCharAsSpace,"    @Test
    public void testURLDecodePlusCharAsSpace() {

        String result = URLDecoderUtil.decode(""a+b"", ""UTF-8"", true);
        assertEquals(""a b"", result);
    }
",non-flaky,5
113996,apache_struts,UploadedFileConverterTest.convertUploadedFileToFile,"    @Test
    public void convertUploadedFileToFile() throws Exception {
        // given
        UploadedFileConverter ufc = new UploadedFileConverter();
        UploadedFile uploadedFile = new StrutsUploadedFile(tempFile);

        // when
        Object result = ufc.convertValue(context, target, member, propertyName, uploadedFile, File.class);

        // then
        assertThat(result).isInstanceOf(File.class);
        File file = (File) result;
        assertThat(file.length()).isEqualTo(tempFile.length());
        assertThat(file.getAbsolutePath()).isEqualTo(tempFile.getAbsolutePath());
    }
",non-flaky,5
113997,apache_struts,UploadedFileConverterTest.convertUploadedFileArrayToFile,"    @Test
    public void convertUploadedFileArrayToFile() throws Exception {
        // given
        UploadedFileConverter ufc = new UploadedFileConverter();
        UploadedFile[] uploadedFile = new UploadedFile[] { new StrutsUploadedFile(tempFile) };

        // when
        Object result = ufc.convertValue(context, target, member, propertyName, uploadedFile, File.class);

        // then
        assertThat(result).isInstanceOf(File.class);
        File file = (File) result;
        assertThat(file.length()).isEqualTo(tempFile.length());
        assertThat(file.getAbsolutePath()).isEqualTo(tempFile.getAbsolutePath());
    }
",non-flaky,5
113998,apache_struts,StrutsJUnit4ConventionTestCaseTest.testConventionUrl,"    @Test
    public void testConventionUrl() throws Exception {
        // Output is filled out only for FreeMarker and Velocity templates
        // If you wanna use JSP check response.getForwardedUrl()
        String output = executeAction(""/view.action"");

        assertTrue(output.contains(""This is the view Hello World""));

        ViewAction action = this.getAction();
        assertEquals(""Hello World"", action.getMessage());
    }
",non-flaky,5
113999,apache_struts,StrutsJUnit4TestCaseTest.testExecuteActionAgainstCustomStrutsConfigFile,"    @Test
    public void testExecuteActionAgainstCustomStrutsConfigFile() throws Exception {
        String output = executeAction(""/test/testAction-2.action"");
        Assert.assertEquals(""Test-2"", output);
    }
",non-flaky,5
114000,apache_struts,StrutsJUnit4TestCaseTest.testSessionInitialized,"    @Test
    public void testSessionInitialized() throws Exception {
        ActionProxy proxy = getActionProxy(""/test/testAction-2.action"");
        Assert.assertNotNull(""invocation session should being initialized"",
                proxy.getInvocation().getInvocationContext().getSession());
    }
",non-flaky,5
114001,apache_struts,StrutsTestCaseTest.shouldPortletContextBeAvailable,"    @Test
    public void shouldPortletContextBeAvailable() throws Exception {
        // given
        assertNull(ActionContext.getContext().get(StrutsStatics.STRUTS_PORTLET_CONTEXT));

        // when
        String output = executeAction(""/test/testAction.action"");
        assertEquals(""Hello"", output);

        // then
        Object portletContext = ActionContext.getContext().get(StrutsStatics.STRUTS_PORTLET_CONTEXT);
        assertNotNull(portletContext);
        assertTrue(portletContext instanceof PortletContext);
    }
",non-flaky,5
114002,apache_struts,StrutsTestCaseTest.shouldAdditionalContextParamsBeAvailable,"    @Test
    public void shouldAdditionalContextParamsBeAvailable() throws Exception {
        // given
        String key = ""my-param"";
        assertNull(ActionContext.getContext().get(key));

        // when
        String output = executeAction(""/test/testAction.action"");
        assertEquals(""Hello"", output);

        // then
        assertNotNull(ActionContext.getContext().get(key));
    }
",non-flaky,5
114003,apache_struts,StrutsSpringJUnit4TestCaseTest.getActionMapping,"	@Test
    public void getActionMapping() {
        ActionMapping mapping = getActionMapping(""/test/testAction.action"");
        Assert.assertNotNull(mapping);
        Assert.assertEquals(""/test"", mapping.getNamespace());
        Assert.assertEquals(""testAction"", mapping.getName());
    }
",non-flaky,5
114004,apache_struts,StrutsSpringJUnit4TestCaseTest.getActionProxy,"	@Test
    public void getActionProxy() throws Exception {
        //set parameters before calling getActionProxy
        request.setParameter(""name"", ""FD"");
        
        ActionProxy proxy = getActionProxy(""/test/testAction.action"");
        Assert.assertNotNull(proxy);

        JUnitTestAction action = (JUnitTestAction) proxy.getAction();
        Assert.assertNotNull(action);

        String result = proxy.execute();
        Assert.assertEquals(Action.SUCCESS, result);
        Assert.assertEquals(""FD"", action.getName());
    }
",non-flaky,5
114005,apache_struts,StrutsSpringJUnit4TestCaseTest.executeAction,"	@Test
    public void executeAction() throws ServletException, UnsupportedEncodingException {
        String output = executeAction(""/test/testAction.action"");
        Assert.assertEquals(""Hello"", output);
    }
",non-flaky,5
114006,apache_struts,StrutsSpringJUnit4TestCaseTest.getValueFromStack,"	@Test
    public void getValueFromStack() throws ServletException, UnsupportedEncodingException {
        request.setParameter(""name"", ""FD"");
        executeAction(""/test/testAction.action"");
        String name = (String) findValueAfterExecute(""name"");
        Assert.assertEquals(""FD"", name);
    }
",non-flaky,5
114007,apache_struts,StrutsJUnit4SessionTestCaseTest.testPersistingSessionValues,"    @Test
    public void testPersistingSessionValues() throws Exception {
        String output = executeAction(""/sessiontest/sessionSet.action"");
        Assert.assertEquals(""sessionValue"", output);

        this.finishExecution();

        String output2 = executeAction(""/sessiontest/sessionGet.action"");
        Assert.assertEquals(""sessionValue"", output2);
    }
",non-flaky,5
114008,apache_struts,TestNGStrutsTestCaseTest.testRun,"        @Test 
        public void testRun() {
            ran = true;
            mgr = this.configurationManager;
            du = Dispatcher.getInstance();
        }
",non-flaky,5
114009,apache_struts,StrutsTilesAnnotationProcessorTest.findAnnotationSingleAction,"    @Test
    public void findAnnotationSingleAction() {
        StrutsTilesAnnotationProcessor annotationProcessor = new StrutsTilesAnnotationProcessor();
        TilesDefinition tilesDefinition = annotationProcessor.findAnnotation(new TilesTestActionSingleAnnotation(), null);
        Assert.assertNotNull(tilesDefinition);
        Assert.assertEquals(""definition-name"", tilesDefinition.name());
    }
",non-flaky,5
114010,apache_struts,StrutsTilesAnnotationProcessorTest.findAnnotationMultipleActionNameNull,"    @Test
    public void findAnnotationMultipleActionNameNull() {
        StrutsTilesAnnotationProcessor annotationProcessor = new StrutsTilesAnnotationProcessor();
        TilesDefinition tilesDefinition = annotationProcessor.findAnnotation(new TilesTestActionMultipleAnnotations(), null);
        Assert.assertNotNull(tilesDefinition);
        Assert.assertEquals(""def1"", tilesDefinition.name());
    }
",non-flaky,5
114011,apache_struts,StrutsTilesAnnotationProcessorTest.findAnnotationMultipleActionNameGiven,"    @Test
    public void findAnnotationMultipleActionNameGiven() {
        StrutsTilesAnnotationProcessor annotationProcessor = new StrutsTilesAnnotationProcessor();
        TilesDefinition tilesDefinition = annotationProcessor.findAnnotation(new TilesTestActionMultipleAnnotations(), ""def2"");
        Assert.assertNotNull(tilesDefinition);
        Assert.assertEquals(""def2"", tilesDefinition.name());
    }
",non-flaky,5
114012,apache_struts,StrutsTilesAnnotationProcessorTest.findAnnotationMultipleActionNotFound,"    @Test
    public void findAnnotationMultipleActionNotFound() {
        StrutsTilesAnnotationProcessor annotationProcessor = new StrutsTilesAnnotationProcessor();
        TilesDefinition tilesDefinition = annotationProcessor.findAnnotation(new TilesTestActionMultipleAnnotations(), ""def3"");
        Assert.assertNull(tilesDefinition);
    }
",non-flaky,5
114013,apache_struts,StrutsTilesAnnotationProcessorTest.buildDefiniton,"    @Test
    public void buildDefiniton() {
        StrutsTilesAnnotationProcessor annotationProcessor = new StrutsTilesAnnotationProcessor();
        TilesDefinition tilesDefinition = annotationProcessor.findAnnotation(new TilesTestActionSingleAnnotation(), null);

        Definition definition = annotationProcessor.buildTilesDefinition(""tileName"", tilesDefinition);

        Assert.assertNotNull(definition);
        Assert.assertEquals(""tileName"", definition.getName());
        Assert.assertEquals(""preparer"", definition.getPreparer());
        Assert.assertEquals(""base-definition"", definition.getExtends());
        Attribute templateAttribute = definition.getTemplateAttribute();
        Assert.assertEquals(""template"", templateAttribute.getValue());
        Assert.assertEquals(""type"", templateAttribute.getRenderer());
        Assert.assertEquals(""role"", templateAttribute.getRole());
        Expression definitionExpressionObject = templateAttribute.getExpressionObject();
        Assert.assertEquals(""templ*"", definitionExpressionObject.getExpression());
        Assert.assertNull(definitionExpressionObject.getLanguage());

        Attribute putAttribute = definition.getAttribute(""put-attr"");
        Assert.assertNotNull(putAttribute);
        Assert.assertEquals(""attr-val"", putAttribute.getValue());
        Assert.assertEquals(""attr-type"", putAttribute.getRenderer());
        Assert.assertEquals(""attr-role"", putAttribute.getRole());
        Expression putAttrExpressionObject = putAttribute.getExpressionObject();
        Assert.assertEquals(""expr"", putAttrExpressionObject.getExpression());
        Assert.assertEquals(""lang"", putAttrExpressionObject.getLanguage());

        Attribute listAttribute = definition.getAttribute(""list-name"");
        Assert.assertEquals(""list-role"", listAttribute.getRole());
        List<Attribute> listValue = getListValue(listAttribute);
        Assert.assertEquals(2, listValue.size());

        Attribute addAttribute = listValue.get(0);
        Assert.assertEquals(""list-attr-role"", addAttribute.getRole());
        Assert.assertEquals(""list-attr-val"", addAttribute.getValue());
        Assert.assertEquals(""list-attr-type"", addAttribute.getRenderer());
        Expression addAttrExpressionObject = addAttribute.getExpressionObject();
        Assert.assertEquals(""list-attr-expr"", addAttrExpressionObject.getExpression());

        Attribute addListAttribute = listValue.get(1);
        Assert.assertEquals(""list-list-attr-role"", addListAttribute.getRole());
        List<Attribute> addListValue = getListValue(addListAttribute);
        Assert.assertEquals(1, addListValue.size());
        Assert.assertEquals(""list-list-add-attr"", addListValue.get(0).getValue());

        Set<String> cascadedAttributeNames = definition.getCascadedAttributeNames();
        Assert.assertEquals(2, cascadedAttributeNames.size());
        Assert.assertTrue(cascadedAttributeNames.contains(""put-attr""));
        Assert.assertTrue(cascadedAttributeNames.contains(""list-name""));
    }
",non-flaky,5
114014,apache_struts,StrutsTilesAnnotationProcessorTest.buildDefinitonAllEmpty,"    @Test
    public void buildDefinitonAllEmpty() {
        StrutsTilesAnnotationProcessor annotationProcessor = new StrutsTilesAnnotationProcessor();
        TilesDefinition tilesDefinition = annotationProcessor.findAnnotation(new TilesTestActionSingleAnnotationAllEmpty(), null);

        Definition definition = annotationProcessor.buildTilesDefinition(null, tilesDefinition);

        Assert.assertNotNull(definition);
        Assert.assertNull(definition.getName());
        Assert.assertNull(definition.getPreparer());
        Assert.assertNull(definition.getExtends());
        Attribute templateAttribute = definition.getTemplateAttribute();
        Assert.assertNull(templateAttribute.getValue());
        Assert.assertNull(templateAttribute.getRole());
        Assert.assertNull(templateAttribute.getExpressionObject());

        Attribute putAttribute = definition.getAttribute(""put-attr"");
        Assert.assertNotNull(putAttribute);
        Assert.assertNull(putAttribute.getValue());
        Assert.assertNull(putAttribute.getRenderer());
        Assert.assertNull(putAttribute.getRole());
        Assert.assertNull(putAttribute.getExpressionObject());

        Attribute listAttribute = definition.getAttribute(""list-name"");
        Assert.assertNull(listAttribute.getRole());
        List<Attribute> listValue = getListValue(listAttribute);
        Assert.assertEquals(2, listValue.size());

        Attribute addAttribute = listValue.get(0);
        Assert.assertNull(addAttribute.getRole());
        Assert.assertNull(addAttribute.getValue());
        Assert.assertNull(addAttribute.getRenderer());
        Assert.assertNull(addAttribute.getExpressionObject());

        Attribute addListAttribute = listValue.get(1);
        Assert.assertNull(addListAttribute.getRole());
        List<Attribute> addListValue = getListValue(addListAttribute);
        Assert.assertEquals(1, addListValue.size());
        Assert.assertNull(addListValue.get(0).getValue());

        Set<String> cascadedAttributeNames = definition.getCascadedAttributeNames();
        Assert.assertNull(cascadedAttributeNames);
    }
",non-flaky,5
114015,apache_struts,CdiObjectFactoryTest.testFindBeanManager,"    @Test
    public void testFindBeanManager() throws Exception {
        assertNotNull(new CdiObjectFactory().findBeanManager());
    }
",non-flaky,5
114016,apache_struts,CdiObjectFactoryTest.testGetBean,"    @Test
    public void testGetBean() throws Exception {
        final CdiObjectFactory cdiObjectFactory = new CdiObjectFactory();
        FooConsumer fooConsumer = (FooConsumer) cdiObjectFactory.buildBean(FooConsumer.class.getCanonicalName(), null, false);
        assertNotNull(fooConsumer);
        assertNotNull(fooConsumer.fooService);
    }
",non-flaky,5
114017,apache_struts,JSONReaderTest.testExponentialNumber,"    @Test
    public void testExponentialNumber() throws Exception {
        Object ret = reader.read(""5e-5"");
        assertNotNull(ret);
        assertEquals(Double.class, ret.getClass());
        assertEquals(5.0E-5, ret);
    }
",non-flaky,5
114018,apache_struts,JSONReaderTest.testExponentialNumber2,"    @Test
    public void testExponentialNumber2() throws Exception {
        Object ret = reader.read(""123.4e10"");
        assertNotNull(ret);
        assertEquals(Double.class, ret.getClass());
        assertEquals(123.4e10, ret);
    }
",non-flaky,5
114019,apache_struts,JSONReaderTest.testDecimalNumber,"    @Test
    public void testDecimalNumber() throws Exception {
        Object ret = reader.read(""3.2"");
        assertNotNull(ret);
        assertEquals(Double.class, ret.getClass());
        assertEquals(3.2, ret);
    }
",non-flaky,5
114020,apache_struts,JSONReaderTest.testNaturalNumber,"    @Test
    public void testNaturalNumber() throws Exception {
        Object ret = reader.read(""123"");
        assertNotNull(ret);
        assertEquals(Long.class, ret.getClass());
        assertEquals(123L, ret);
    }
",non-flaky,5
114021,apache_struts,DefaultJSONWriterTest.testWrite,"    @Test
    public void testWrite() throws Exception {
        Bean bean1=new Bean();
        bean1.setStringField(""str"");
        bean1.setBooleanField(true);
        bean1.setCharField('s');
        bean1.setDoubleField(10.1);
        bean1.setFloatField(1.5f);
        bean1.setIntField(10);
        bean1.setLongField(100);
        bean1.setEnumField(AnEnum.ValueA);
        bean1.setEnumBean(AnEnumBean.Two);

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);
        String json = jsonWriter.write(bean1);
        TestUtils.assertEquals(DefaultJSONWriter.class.getResource(""jsonwriter-write-bean-01.txt""), json);
    }
",non-flaky,5
114022,apache_struts,DefaultJSONWriterTest.testWriteExcludeNull,"    @Test
    public void testWriteExcludeNull() throws Exception {
        BeanWithMap bean1=new BeanWithMap();
        bean1.setStringField(""str"");
        bean1.setBooleanField(true);
        bean1.setCharField('s');
        bean1.setDoubleField(10.1);
        bean1.setFloatField(1.5f);
        bean1.setIntField(10);
        bean1.setLongField(100);
        bean1.setEnumField(AnEnum.ValueA);
        bean1.setEnumBean(AnEnumBean.Two);

        Map m = new LinkedHashMap();
        m.put(""a"", ""x"");
        m.put(""b"", null);
        m.put(""c"", ""z"");
        bean1.setMap(m);

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);
        jsonWriter.setIgnoreHierarchy(false);
        String json = jsonWriter.write(bean1, null, null, true);
        TestUtils.assertEquals(DefaultJSONWriter.class.getResource(""jsonwriter-write-bean-03.txt""), json);
    }
",non-flaky,5
114023,apache_struts,DefaultJSONWriterTest.testWriteAnnotatedBean,"    @Test
    public void testWriteAnnotatedBean() throws Exception {
        AnnotatedBean bean1=new AnnotatedBean();
        bean1.setStringField(""str"");
        bean1.setBooleanField(true);
        bean1.setCharField('s');
        bean1.setDoubleField(10.1);
        bean1.setFloatField(1.5f);
        bean1.setIntField(10);
        bean1.setLongField(100);
        bean1.setEnumField(AnEnum.ValueA);
        bean1.setEnumBean(AnEnumBean.Two);
        bean1.setUrl(new URL(""http://www.google.com""));

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);
        jsonWriter.setIgnoreHierarchy(false);
        String json = jsonWriter.write(bean1);
        TestUtils.assertEquals(DefaultJSONWriter.class.getResource(""jsonwriter-write-bean-02.txt""), json);
    }
",non-flaky,5
114024,apache_struts,DefaultJSONWriterTest.testWriteBeanWithList,"    @Test
    public void testWriteBeanWithList() throws Exception {
        BeanWithList bean1 = new BeanWithList();
        bean1.setStringField(""str"");
        bean1.setBooleanField(true);
        bean1.setCharField('s');
        bean1.setDoubleField(10.1);
        bean1.setFloatField(1.5f);
        bean1.setIntField(10);
        bean1.setLongField(100);
        bean1.setEnumField(AnEnum.ValueA);
        bean1.setEnumBean(AnEnumBean.Two);
        List<String> errors = new ArrayList<String>();
        errors.add(""Field is required"");
        bean1.setErrors(errors);

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);
        jsonWriter.setIgnoreHierarchy(false);
        String json = jsonWriter.write(bean1);
        TestUtils.assertEquals(DefaultJSONWriter.class.getResource(""jsonwriter-write-bean-04.txt""), json);
    }
",non-flaky,5
114025,apache_struts,DefaultJSONWriterTest.testCanSerializeADate,"    @Test
    public void testCanSerializeADate() throws Exception {
        SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss z"");

        SingleDateBean dateBean = new SingleDateBean();
        dateBean.setDate(sdf.parse(""2012-12-23 10:10:10 GMT""));

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);

        TimeZone.setDefault(TimeZone.getTimeZone(""GMT""));
        String json = jsonWriter.write(dateBean);
        assertEquals(""{\""date\"":\""2012-12-23T10:10:10\""}"", json);
    }
",non-flaky,5
114026,apache_struts,DefaultJSONWriterTest.testCanSetDefaultDateFormat,"    @Test
    public void testCanSetDefaultDateFormat() throws Exception {
        SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss z"");

        SingleDateBean dateBean = new SingleDateBean();
        dateBean.setDate(sdf.parse(""2012-12-23 10:10:10 GMT""));

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);
        jsonWriter.setDateFormatter(""MM-dd-yyyy"");
        String json = jsonWriter.write(dateBean);
        assertEquals(""{\""date\"":\""12-23-2012\""}"", json);
    }
",non-flaky,5
114027,apache_struts,JSONPopulatorTest.testParseBadInput,"            // @Test(expected = JSONException.class)
        }
    }
",non-flaky,5
114028,apache_struts,JSONInterceptorTest.testSMDDisabledSMD,"            // @Test(expected = JSONException.class)
    public void testSMDDisabledSMD() throws Exception {
        // request
        setRequestContent(""smd-3.txt"");
        this.request.addHeader(""Content-Type"", ""application/json-rpc"");

        JSONInterceptor interceptor = new JSONInterceptor();
        JSONUtil jsonUtil = new JSONUtil();
        jsonUtil.setWriter(new DefaultJSONWriter());
        interceptor.setJsonUtil(jsonUtil);
        SMDActionTest1 action = new SMDActionTest1();

        this.invocation.setAction(action);

        // SMD was not enabled so invocation must happen
        try {
            interceptor.intercept(this.invocation);
        } catch (JSONException e) {
            fail(""Should have not thrown an exception"");
        }

    }
",non-flaky,5
114029,apache_struts,FileDownloadActionTest.testSanitizeInputPathShouldAllowSimpleParameter,"	@Test
	public void testSanitizeInputPathShouldAllowSimpleParameter() throws Exception {
		assertEquals(""foo"", fileDownloadAction.sanitizeInputPath(""foo""));
	}
",non-flaky,5
114030,apache_struts,FileDownloadActionTest.testSanitizeInputPathShouldReturnNullForNullInput,"	@Test
	public void testSanitizeInputPathShouldReturnNullForNullInput() throws Exception {
		assertNull(fileDownloadAction.sanitizeInputPath(null));
	}
",non-flaky,5
114031,apache_struts,FileDownloadActionTest.testSanitizeInputPathShouldReturnNullForLeadingWebInf,"	@Test
	public void testSanitizeInputPathShouldReturnNullForLeadingWebInf() throws Exception {
		assertNull(fileDownloadAction.sanitizeInputPath(""WEB-INF/foo""));
	}
",non-flaky,5
114032,apache_struts,FileDownloadActionTest.testSanitizeInputPathShouldReturnNullForNonLeadingWebInf,"	@Test
	public void testSanitizeInputPathShouldReturnNullForNonLeadingWebInf() throws Exception {
		assertNull(fileDownloadAction.sanitizeInputPath(""./WEB-INF/foo""));
	}
",non-flaky,5
114033,apache_struts,FileDownloadActionTest.testSanitizeInputPathShouldReturnNullForNonUppercaseWebInf,"	@Test
	public void testSanitizeInputPathShouldReturnNullForNonUppercaseWebInf() throws Exception {
		assertNull(fileDownloadAction.sanitizeInputPath(""./wEB-Inf/foo""));
	}
",non-flaky,5
133930,CorfuDB_CorfuDB,LayoutHandlerTest.testGetLayout,"    @Test
    public void testGetLayout() throws IOException {
        Layout defaultLayout = getDefaultLayout();

        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getLayoutResponseMsg(defaultLayout)
        );

        layoutHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), defaultLayout);
    }
",non-flaky,5
133931,CorfuDB_CorfuDB,LayoutHandlerTest.testMalformedGetLayout,"    @Test
    public void testMalformedGetLayout() throws IOException {
        Layout defaultLayout = getDefaultLayout();
        defaultLayout.setLayoutServers(new LinkedList<>());

        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getLayoutResponseMsg(defaultLayout)
        );

        layoutHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the request was completed exceptionally with the expected exception type.
        verify(mockClientRouter).completeExceptionally(anyLong(), any(SerializerException.class));
    }
",non-flaky,5
133932,CorfuDB_CorfuDB,LayoutHandlerTest.testBootstrapLayout,"    @Test
    public void testBootstrapLayout() {
        ResponseMsg responseACK = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getBootstrapLayoutResponseMsg(true)
        );

        ResponseMsg responseNACK = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getBootstrapLayoutResponseMsg(false)
        );

        layoutHandler.handleMessage(responseACK, mockChannelHandlerContext);
        layoutHandler.handleMessage(responseNACK, mockChannelHandlerContext);

        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(responseACK.getHeader().getRequestId(), true);
        verify(mockClientRouter).completeRequest(responseNACK.getHeader().getRequestId(), false);
    }
",non-flaky,5
133933,CorfuDB_CorfuDB,LayoutHandlerTest.testPrepare,"    @Test
    public void testPrepare() throws IOException {
        Layout defaultLayout = getDefaultLayout();
        long defaultRank = 5L;
        ResponseMsg responseACK = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getPrepareLayoutResponseMsg(true, defaultRank, defaultLayout)
        );
        ResponseMsg responseREJECT = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getPrepareLayoutResponseMsg(false, defaultRank, defaultLayout)
        );

        // Verify that the correct request was completed (once) with the appropriate value.
        layoutHandler.handleMessage(responseACK, mockChannelHandlerContext);
        ArgumentCaptor<LayoutPrepareResponse> layoutPrepareCaptor = ArgumentCaptor.forClass(LayoutPrepareResponse.class);
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(eq(responseACK.getHeader().getRequestId()), layoutPrepareCaptor.capture());

        LayoutPrepareResponse layoutPrepareCaptorValue = layoutPrepareCaptor.getValue();
        Layout retLayout = layoutPrepareCaptorValue.getLayout();
        assertLayoutMatch(retLayout);

        // Verify that the correct exception was thrown with the appropriate field set.
        layoutHandler.handleMessage(responseREJECT, mockChannelHandlerContext);
        ArgumentCaptor<OutrankedException> exceptionCaptor = ArgumentCaptor.forClass(OutrankedException.class);
        verify(mockClientRouter).completeExceptionally(
                eq(responseREJECT.getHeader().getRequestId()), exceptionCaptor.capture());
        OutrankedException outrankedException = exceptionCaptor.getValue();
        assertThat(outrankedException.getNewRank()).isEqualTo(defaultRank);

        retLayout = outrankedException.getLayout();
        assertLayoutMatch(retLayout);
    }
",non-flaky,5
133934,CorfuDB_CorfuDB,LayoutHandlerTest.testPropose,"    @Test
    public void testPropose() {
        long defaultRank = 5L;
        ResponseMsg responseACK = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getProposeLayoutResponseMsg(true, defaultRank)
        );
        ResponseMsg responseREJECT = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getProposeLayoutResponseMsg(false, defaultRank)
        );

        // Verify that the correct request was completed (once) with the appropriate value.
        layoutHandler.handleMessage(responseACK, mockChannelHandlerContext);
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(responseACK.getHeader().getRequestId(), true);

        // Verify that the correct exception was thrown with the appropriate field set.
        layoutHandler.handleMessage(responseREJECT, mockChannelHandlerContext);
        ArgumentCaptor<OutrankedException> exceptionCaptor = ArgumentCaptor.forClass(OutrankedException.class);
        verify(mockClientRouter).completeExceptionally(
                eq(responseREJECT.getHeader().getRequestId()), exceptionCaptor.capture());
        OutrankedException outrankedException = exceptionCaptor.getValue();
        assertThat(outrankedException.getNewRank()).isEqualTo(defaultRank);
    }
",non-flaky,5
133935,CorfuDB_CorfuDB,LayoutHandlerTest.testCommit,"    @Test
    public void testCommit() {
        ResponseMsg responseACK = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getCommitLayoutResponseMsg(true)
        );

        ResponseMsg responseNACK = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getCommitLayoutResponseMsg(false)
        );

        layoutHandler.handleMessage(responseACK, mockChannelHandlerContext);
        layoutHandler.handleMessage(responseNACK, mockChannelHandlerContext);

        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(responseACK.getHeader().getRequestId(), true);
        verify(mockClientRouter).completeRequest(responseNACK.getHeader().getRequestId(), false);
    }
",non-flaky,5
133936,CorfuDB_CorfuDB,ManagementHandlerTest.testHandleReportFailure0,"    @Test
    public void testHandleReportFailure0() {
        testHandleReportFailure(false);
    }
",non-flaky,5
133937,CorfuDB_CorfuDB,ManagementHandlerTest.testHandleReportFailure1,"    @Test
    public void testHandleReportFailure1() {
        testHandleReportFailure(true);
    }
",non-flaky,5
133938,CorfuDB_CorfuDB,ManagementHandlerTest.testHandleHealFailure0,"    @Test
    public void testHandleHealFailure0() {
        testHandleHealFailure(false);
    }
",non-flaky,5
133939,CorfuDB_CorfuDB,ManagementHandlerTest.testHandleHealFailure1,"    @Test
    public void testHandleHealFailure1() {
        testHandleHealFailure(true);
    }
",non-flaky,5
133940,CorfuDB_CorfuDB,ManagementHandlerTest.testHandleManagementBootstrap0,"    @Test
    public void testHandleManagementBootstrap0() {
        testHandleManagementBootstrap(false);
    }
",non-flaky,5
133941,CorfuDB_CorfuDB,ManagementHandlerTest.testHandleManagementBootstrap1,"    @Test
    public void testHandleManagementBootstrap1() {
        testHandleManagementBootstrap(true);
    }
",non-flaky,5
133942,CorfuDB_CorfuDB,ManagementHandlerTest.testHandleManagementLayout,"    @Test
    public void testHandleManagementLayout() {
        final Layout layout = getBasicLayout(ImmutableList.of(""localhost:9000""));
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getManagementLayoutResponseMsg(layout)
        );

        managementHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), layout);
    }
",non-flaky,5
133943,CorfuDB_CorfuDB,ManagementHandlerTest.testHandleQueryNode,"    @Test
    public void testHandleQueryNode() {
        final NodeState state = NodeState.getNotReadyNodeState(""localhost:9000"");
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getQueryNodeResponseMsg(state)
        );

        managementHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), state);
    }
",non-flaky,5
133944,CorfuDB_CorfuDB,ManagementHandlerTest.testHandleOrchestrator,"    @Test
    public void testHandleOrchestrator() {
        // Test with an ORCHESTRATOR_RESPONSE of type QueryResponse.
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.IGNORE, EpochCheck.IGNORE),
                getQueriedWorkflowResponseMsg(true)
        );

        ArgumentCaptor<QueryResponse> qrCaptor = ArgumentCaptor.forClass(QueryResponse.class);
        managementHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(eq(response.getHeader().getRequestId()), qrCaptor.capture());
        assertTrue(qrCaptor.getValue().isActive());

        // Test with an ORCHESTRATOR_RESPONSE of type CreateWorkflowResponse.
        response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.IGNORE, EpochCheck.IGNORE),
                getCreatedWorkflowResponseMsg(DEFAULT_UUID)
        );

        ArgumentCaptor<CreateWorkflowResponse> cwCaptor = ArgumentCaptor.forClass(CreateWorkflowResponse.class);
        managementHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(eq(response.getHeader().getRequestId()), cwCaptor.capture());
        assertEquals(DEFAULT_UUID, cwCaptor.getValue().workflowId);
    }
",non-flaky,5
133945,CorfuDB_CorfuDB,BaseHandlerTest.testHandlePing,"    @Test
    public void testHandlePing() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getPingResponseMsg()
        );

        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
133946,CorfuDB_CorfuDB,BaseHandlerTest.testHandleRestart,"    @Test
    public void testHandleRestart() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getRestartResponseMsg()
        );

        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
133947,CorfuDB_CorfuDB,BaseHandlerTest.testHandleReset,"    @Test
    public void testHandleReset() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getResetResponseMsg()
        );

        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
133948,CorfuDB_CorfuDB,BaseHandlerTest.testHandleSeal,"    @Test
    public void testHandleSeal() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getSealResponseMsg()
        );

        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
133949,CorfuDB_CorfuDB,BaseHandlerTest.testHandleWrongEpochError,"    @Test
    public void testHandleWrongEpochError() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getWrongEpochErrorMsg(2L)
        );

        ArgumentCaptor<WrongEpochException> exceptionCaptor = ArgumentCaptor.forClass(WrongEpochException.class);
        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed exceptionally (once)
        // with the expected exception
        verify(mockClientRouter, never()).completeRequest(anyLong(), any());
        verify(mockClientRouter).completeExceptionally(
                eq(response.getHeader().getRequestId()), exceptionCaptor.capture());

        assertEquals(2L, exceptionCaptor.getValue().getCorrectEpoch());
    }
",non-flaky,5
133950,CorfuDB_CorfuDB,BaseHandlerTest.testHandleWrongClusterError,"    @Test
    public void testHandleWrongClusterError() {
        final UUID EXPECTED_UUID = UUID.randomUUID();
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getWrongClusterErrorMsg(getUuidMsg(EXPECTED_UUID), getUuidMsg(DEFAULT_UUID))
        );

        ArgumentCaptor<WrongClusterException> exceptionCaptor = ArgumentCaptor.forClass(WrongClusterException.class);
        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed exceptionally (once)
        // with the expected exception
        verify(mockClientRouter, never()).completeRequest(anyLong(), any());
        verify(mockClientRouter).completeExceptionally(
                eq(response.getHeader().getRequestId()), exceptionCaptor.capture());

        assertEquals(EXPECTED_UUID, exceptionCaptor.getValue().getExpectedCluster());
        assertEquals(DEFAULT_UUID, exceptionCaptor.getValue().getActualCluster());
    }
",non-flaky,5
133951,CorfuDB_CorfuDB,BaseHandlerTest.testHandleNotReadyError,"    @Test
    public void testHandleNotReadyError() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getNotReadyErrorMsg()
        );

        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed exceptionally (once)
        // with the expected exception
        verify(mockClientRouter, never()).completeRequest(anyLong(), any());
        verify(mockClientRouter).completeExceptionally(
                eq(response.getHeader().getRequestId()), any(ServerNotReadyException.class));
    }
",non-flaky,5
133952,CorfuDB_CorfuDB,BaseHandlerTest.testHandleBootstrappedError,"    @Test
    public void testHandleBootstrappedError() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getBootstrappedErrorMsg()
        );

        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed exceptionally (once)
        // with the expected exception
        verify(mockClientRouter, never()).completeRequest(anyLong(), any());
        verify(mockClientRouter).completeExceptionally(
                eq(response.getHeader().getRequestId()), any(AlreadyBootstrappedException.class));
    }
",non-flaky,5
133953,CorfuDB_CorfuDB,BaseHandlerTest.testHandleNotBootstrappedError,"    @Test
    public void testHandleNotBootstrappedError() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getNotBootstrappedErrorMsg()
        );

        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed exceptionally (once)
        // with the expected exception
        verify(mockClientRouter, never()).completeRequest(anyLong(), any());
        verify(mockClientRouter).completeExceptionally(
                eq(response.getHeader().getRequestId()), any(NoBootstrapException.class));
    }
",non-flaky,5
133954,CorfuDB_CorfuDB,BaseHandlerTest.testHandleUnknownError,"    @Test
    public void testHandleUnknownError() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getUnknownErrorMsg(new Exception(""Unknown Exception Test""))
        );

        ArgumentCaptor<Exception> exceptionCaptor = ArgumentCaptor.forClass(Exception.class);
        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed exceptionally (once)
        // with the expected exception
        verify(mockClientRouter, never()).completeRequest(anyLong(), any());
        verify(mockClientRouter).completeExceptionally(
                eq(response.getHeader().getRequestId()), exceptionCaptor.capture());

        assertEquals(""Unknown Exception Test"", exceptionCaptor.getValue().getMessage());
    }
",non-flaky,5
133955,CorfuDB_CorfuDB,SequencerHandlerTest.testTokenResponseEmptyMap,"    @Test
    public void testTokenResponseEmptyMap() {
        Token token = new Token(0L, 0L);
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getTokenResponseMsg(
                        TokenType.NORMAL,
                        TokenResponse.NO_CONFLICT_KEY,
                        TokenResponse.NO_CONFLICT_STREAM, token,
                        Collections.emptyMap(),
                        Collections.emptyMap())
        );

        sequencerHandler.handleMessage(response, mockChannelHandlerContext);
        ArgumentCaptor<TokenResponse> captor = ArgumentCaptor.forClass(TokenResponse.class);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(eq(response.getHeader().getRequestId()), captor.capture());

        TokenResponse tokenResponse = captor.getValue();
        assertEquals(token, tokenResponse.getToken());
        assertEquals(TokenType.NORMAL, tokenResponse.getRespType());
        assertEquals(TokenResponse.NO_CONFLICT_STREAM, tokenResponse.getConflictStream());
        assertEquals(0, tokenResponse.getStreamTailsCount());
        assertArrayEquals(tokenResponse.getConflictKey(), TokenResponse.NO_CONFLICT_KEY);
        assertTrue(tokenResponse.getBackpointerMap().isEmpty());
    }
",non-flaky,5
133956,CorfuDB_CorfuDB,SequencerHandlerTest.testTokenResponseDefaultMap,"    @Test
    public void testTokenResponseDefaultMap() {
        Token token = new Token(0L, 0L);
        Map<UUID, Long> backPointerMap = getTokenResponseDefaultMap();
        Map<UUID, Long> streamTails = getTokenResponseDefaultMap();
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getTokenResponseMsg(
                        TokenType.NORMAL,
                        TokenResponse.NO_CONFLICT_KEY,
                        TokenResponse.NO_CONFLICT_STREAM, token,
                        backPointerMap,
                        streamTails)
        );

        sequencerHandler.handleMessage(response, mockChannelHandlerContext);
        ArgumentCaptor<TokenResponse> captor = ArgumentCaptor.forClass(TokenResponse.class);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(eq(response.getHeader().getRequestId()), captor.capture());

        TokenResponse tokenResponse = captor.getValue();
        assertEquals(token, tokenResponse.getToken());
        assertEquals(TokenType.NORMAL, tokenResponse.getRespType());
        assertEquals(TokenResponse.NO_CONFLICT_STREAM, tokenResponse.getConflictStream());
        assertEquals(streamTails.size(), tokenResponse.getStreamTailsCount());
        assertEquals(backPointerMap, tokenResponse.getBackpointerMap());
        assertArrayEquals(tokenResponse.getConflictKey(), TokenResponse.NO_CONFLICT_KEY);
    }
",non-flaky,5
133957,CorfuDB_CorfuDB,SequencerHandlerTest.testBootstrapSequencerResponse,"    @Test
    public void testBootstrapSequencerResponse() {
        ResponseMsg responseAck = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getBootstrapSequencerResponseMsg(true)
        );
        ResponseMsg responseNack = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getBootstrapSequencerResponseMsg(false)
        );

        sequencerHandler.handleMessage(responseAck, mockChannelHandlerContext);
        sequencerHandler.handleMessage(responseNack, mockChannelHandlerContext);
        // Verify that the correct request was completed with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(responseAck.getHeader().getRequestId(), true);
        verify(mockClientRouter).completeRequest(responseNack.getHeader().getRequestId(), false);
    }
",non-flaky,5
133958,CorfuDB_CorfuDB,SequencerHandlerTest.testSequencerTrimResponse,"    @Test
    public void testSequencerTrimResponse() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getSequencerTrimResponseMsg()
        );

        sequencerHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
133959,CorfuDB_CorfuDB,SequencerHandlerTest.testSequencerMetricsResponseNormal,"    @Test
    public void testSequencerMetricsResponseNormal() {
        SequencerMetrics sequencerMetricsReady = SequencerMetrics.READY;
        SequencerMetrics sequencerMetricsNotReady = SequencerMetrics.NOT_READY;
        SequencerMetrics sequencerMetricsUnknown = SequencerMetrics.UNKNOWN;
        ResponseMsg responseReady = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getSequencerMetricsResponseMsg(sequencerMetricsReady)
        );
        ResponseMsg responseNotReady = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getSequencerMetricsResponseMsg(sequencerMetricsNotReady)
        );
        ResponseMsg responseUnkown = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getSequencerMetricsResponseMsg(sequencerMetricsUnknown)
        );

        sequencerHandler.handleMessage(responseReady, mockChannelHandlerContext);
        sequencerHandler.handleMessage(responseNotReady, mockChannelHandlerContext);
        sequencerHandler.handleMessage(responseUnkown, mockChannelHandlerContext);
        // Verify that the correct request was completed with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(responseReady.getHeader().getRequestId(), sequencerMetricsReady);
        verify(mockClientRouter).completeRequest(responseNotReady.getHeader().getRequestId(), sequencerMetricsNotReady);
        verify(mockClientRouter).completeRequest(responseUnkown.getHeader().getRequestId(), sequencerMetricsUnknown);
    }
",non-flaky,5
133960,CorfuDB_CorfuDB,SequencerHandlerTest.testStreamsAddressResponseEmptyAddressMap,"    @Test
    public void testStreamsAddressResponseEmptyAddressMap() {
        long defaultLogTail = 5L;
        long defaultEpoch = 10L;

        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getStreamsAddressResponseMsg(defaultLogTail, defaultEpoch, Collections.emptyMap())
        );

        sequencerHandler.handleMessage(response, mockChannelHandlerContext);
        ArgumentCaptor<StreamsAddressResponse> captor = ArgumentCaptor.forClass(StreamsAddressResponse.class);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(eq(response.getHeader().getRequestId()), captor.capture());

        StreamsAddressResponse streamsAddressResponse = captor.getValue();
        assertTrue(streamsAddressResponse.getAddressMap().isEmpty());
        assertEquals(defaultLogTail, streamsAddressResponse.getLogTail());
        assertEquals(defaultEpoch, streamsAddressResponse.getEpoch());
    }
",non-flaky,5
133961,CorfuDB_CorfuDB,SequencerHandlerTest.testStreamsAddressResponseDefaultAddressMap,"    @Test
    public void testStreamsAddressResponseDefaultAddressMap() {
        long defaultLogTail = 5L;
        long defaultEpoch = 10L;
        Map<UUID, StreamAddressSpace> defaultMap = getDefaultAddressMap();

        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getStreamsAddressResponseMsg(defaultLogTail, defaultEpoch, defaultMap)
        );

        sequencerHandler.handleMessage(response, mockChannelHandlerContext);
        ArgumentCaptor<StreamsAddressResponse> captor = ArgumentCaptor.forClass(StreamsAddressResponse.class);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(eq(response.getHeader().getRequestId()), captor.capture());

        StreamsAddressResponse streamsAddressResponse = captor.getValue();
        assertEquals(defaultLogTail, streamsAddressResponse.getLogTail());
        assertEquals(defaultEpoch, streamsAddressResponse.getEpoch());
        Map<UUID, StreamAddressSpace> retMap = streamsAddressResponse.getAddressMap();
        assertEquals(retMap.size(), defaultMap.size());
        for (UUID id : defaultMap.keySet()) {
            assertEquals(defaultMap.get(id).toString(), retMap.get(id).toString());
        }
    }
",non-flaky,5
133962,CorfuDB_CorfuDB,LogUnitHandlerTest.testWrite,"    @Test
    public void testWrite() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getWriteLogResponseMsg()
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
133963,CorfuDB_CorfuDB,LogUnitHandlerTest.testWriteRange,"    @Test
    public void testWriteRange() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getRangeWriteLogResponseMsg()
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
133964,CorfuDB_CorfuDB,LogUnitHandlerTest.testRead,"    @Test
    public void testRead() {
        ReadResponse rr = new ReadResponse();
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getReadLogResponseMsg(rr.getAddresses())
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), rr);
    }
",non-flaky,5
133965,CorfuDB_CorfuDB,LogUnitHandlerTest.testInspectAddresses,"    @Test
    public void testInspectAddresses() {
        List<Long> emptyAddresses = new ArrayList<>();
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getInspectAddressesResponseMsg(emptyAddresses)
        );

        ArgumentCaptor<InspectAddressesResponse> captor = ArgumentCaptor.forClass(InspectAddressesResponse.class);

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(eq(response.getHeader().getRequestId()), captor.capture());
        assertEquals(emptyAddresses, captor.getValue().getEmptyAddresses());
    }
",non-flaky,5
133966,CorfuDB_CorfuDB,LogUnitHandlerTest.testTailResponse,"    @Test
    public void testTailResponse() {
        TailsResponse sampleTailsResponse = new TailsResponse(0L, 0L, new HashMap<>());
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getTailResponseMsg(sampleTailsResponse.getEpoch(), sampleTailsResponse.getLogTail(),
                        sampleTailsResponse.getStreamTails())
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), sampleTailsResponse);
    }
",non-flaky,5
133967,CorfuDB_CorfuDB,LogUnitHandlerTest.testGetCommittedTail,"    @Test
    public void testGetCommittedTail() {
        long sampleCommittedTail = 5L;
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getCommittedTailResponseMsg(sampleCommittedTail)
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), sampleCommittedTail);
    }
",non-flaky,5
133968,CorfuDB_CorfuDB,LogUnitHandlerTest.testUpdateCommittedTail,"    @Test
    public void testUpdateCommittedTail() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getUpdateCommittedTailResponseMsg()
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
133969,CorfuDB_CorfuDB,LogUnitHandlerTest.testGetLogAddressSpace,"    @Test
    public void testGetLogAddressSpace() {
        StreamsAddressResponse addressResponse = new StreamsAddressResponse(0L, new HashMap<>());
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getLogAddressSpaceResponseMsg(addressResponse.getLogTail(), addressResponse.getEpoch(),
                        addressResponse.getAddressMap())
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), addressResponse);
    }
",non-flaky,5
133970,CorfuDB_CorfuDB,LogUnitHandlerTest.testGetTrimMark,"    @Test
    public void testGetTrimMark() {
        long sampleTrimMark = 5L;
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getTrimMarkResponseMsg(sampleTrimMark)
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), sampleTrimMark);
    }
",non-flaky,5
133971,CorfuDB_CorfuDB,LogUnitHandlerTest.testRequestKnownAddresses,"    @Test
    public void testRequestKnownAddresses() {
        KnownAddressResponse knownAddressResponse = new KnownAddressResponse(new HashSet<>());
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getKnownAddressResponseMsg(knownAddressResponse.getKnownAddresses())
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), knownAddressResponse);
    }
",non-flaky,5
133972,CorfuDB_CorfuDB,LogUnitHandlerTest.testPrefixTrim,"    @Test
    public void testPrefixTrim() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getTrimLogResponseMsg()
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
133973,CorfuDB_CorfuDB,LogUnitHandlerTest.testCompact,"    @Test
    public void testCompact() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getCompactResponseMsg()
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
133974,CorfuDB_CorfuDB,LogUnitHandlerTest.testFlushCache,"    @Test
    public void testFlushCache() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getFlushCacheResponseMsg()
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
133975,CorfuDB_CorfuDB,LogUnitHandlerTest.testResetLogUnit,"    @Test
    public void testResetLogUnit() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getResetLogUnitResponseMsg()
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
133976,CorfuDB_CorfuDB,LogUnitHandlerTest.testTrimmedError,"    @Test
    public void testTrimmedError() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getTrimmedErrorMsg()
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed exceptionally.
        verify(mockClientRouter, never()).completeRequest(anyLong(), any());
        verify(mockClientRouter).completeExceptionally(
                eq(response.getHeader().getRequestId()), any(TrimmedException.class));
    }
",non-flaky,5
133977,CorfuDB_CorfuDB,LogUnitHandlerTest.testOverwriteError,"    @Test
    public void testOverwriteError() {
        int causeIdWrittenByHole = OverwriteCause.SAME_DATA.getId();
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getOverwriteErrorMsg(causeIdWrittenByHole)
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        ArgumentCaptor<OverwriteException> captor = ArgumentCaptor.forClass(OverwriteException.class);
        // Verify that the correct request was completed exceptionally.
        verify(mockClientRouter, never()).completeRequest(anyLong(), any());
        verify(mockClientRouter).completeExceptionally(
                eq(response.getHeader().getRequestId()), captor.capture());
        assertEquals(causeIdWrittenByHole, captor.getValue().getOverWriteCause().getId());
    }
",non-flaky,5
133978,CorfuDB_CorfuDB,LogUnitHandlerTest.testDataCorruptionError,"    @Test
    public void testDataCorruptionError() {
        long sampleAddress = 5L;
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getDataCorruptionErrorMsg(sampleAddress)
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed exceptionally.
        verify(mockClientRouter, never()).completeRequest(anyLong(), any());
        verify(mockClientRouter).completeExceptionally(
                eq(response.getHeader().getRequestId()), any(DataCorruptionException.class));
    }
",non-flaky,5
133979,CorfuDB_CorfuDB,ClientHandshakeHandlerTest.testFireHandshakeSucceeded,"    @Test
    public void testFireHandshakeSucceeded() throws Exception {
        // Get a HandshakeRequestMsg with specified server node id.
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getHandshakeResponseMsg(SERVER_NODEID)
        );

        when(mockChannelContext.pipeline()).thenReturn(mockChannelPipeline);
        when(mockChannelPipeline.remove(""readTimeoutHandler"")).thenReturn(clientHandshakeHandler);

        clientHandshakeHandler.channelRead(mockChannelContext, response);

        verify(mockChannelContext).fireUserEventTriggered(ClientHandshakeEvent.CONNECTED);
    }
",non-flaky,5
133980,CorfuDB_CorfuDB,ClientHandshakeHandlerTest.testVersionMismatchHandshakeSucceeded,"    @Test
    public void testVersionMismatchHandshakeSucceeded() throws Exception {
        // Get a HandshakeResponseMsg whose corfu_source_code_version set in the header is different
        // from that at client side.
        ResponseMsg response = getResponseMsg(
            HeaderMsg.newBuilder()
                .setVersion(
                    ProtocolVersionMsg.newBuilder()
                        .setCorfuSourceCodeVersion(FAKE_SERVER_VERSION)
                        .setCapabilityVector(CompatibilityVectorUtils.getCompatibilityVectors())
                        .build())
                .setRequestId(requestCounter.incrementAndGet())
                .setPriority(PriorityLevel.NORMAL)
                .setEpoch(0L)
                .setClusterId(getUuidMsg(DEFAULT_UUID))
                .setClientId(getUuidMsg(DEFAULT_UUID))
                .setIgnoreClusterId(false)
                .setIgnoreEpoch(true)
                .build(),
            getHandshakeResponseMsg(SERVER_NODEID)
        );

        when(mockChannelContext.pipeline()).thenReturn(mockChannelPipeline);
        when(mockChannelPipeline.remove(""readTimeoutHandler"")).thenReturn(clientHandshakeHandler);

        clientHandshakeHandler.channelRead(mockChannelContext, response);

        // Currently when versions do not match we do nothing but log warning, so the handshake
        // is supposed to succeed.
        verify(mockChannelContext).fireUserEventTriggered(ClientHandshakeEvent.CONNECTED);
    }
",non-flaky,5
133981,CorfuDB_CorfuDB,ClientHandshakeHandlerTest.testResponseDroppedBeforeHandshake,"    @Test
    public void testResponseDroppedBeforeHandshake() {
        // Take out the handshake request message upon channelActive.
        Object out = embeddedChannel.readOutbound();
        assertTrue(out instanceof RequestMsg);
        assertTrue(((RequestMsg) out).getPayload().hasHandshakeRequest());
        // Get a ping ResponseMsg
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getPingResponseMsg()
        );

        embeddedChannel.writeInbound(response);

        // Verify that the response was correctly dropped and there is no inbound nor outbound messages.
        assertNull(embeddedChannel.readInbound());
        assertNull(embeddedChannel.readOutbound());
    }
",non-flaky,5
133982,CorfuDB_CorfuDB,ClientHandshakeHandlerTest.testResponsePassedAfterHandshake,"    @Test
    public void testResponsePassedAfterHandshake() {
        // Take out the handshake request message upon channelActive.
        Object out = embeddedChannel.readOutbound();
        assertTrue(out instanceof RequestMsg);
        assertTrue(((RequestMsg) out).getPayload().hasHandshakeRequest());
        // Get a HandshakeRequestMsg with specified server node id.
        ResponseMsg handshakeResponse = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getHandshakeResponseMsg(SERVER_NODEID)
        );
        // Get a ping ResponseMsg
        ResponseMsg pingResponse = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getPingResponseMsg()
        );

        embeddedChannel.writeInbound(handshakeResponse);
        embeddedChannel.writeInbound(pingResponse);

        // Verify that the ping response is passed to next handler.
        Object in = embeddedChannel.readInbound();
        assertEquals(in, pingResponse);
        // Verify that there is no outbound messages.
        assertNull(embeddedChannel.readOutbound());
    }
",non-flaky,5
133983,CorfuDB_CorfuDB,ManagementViewTest.testGetLayoutForQuorum,"    @Test
    public void testGetLayoutForQuorum() {
        final String server1 = ""server1"";
        final String server2 = ""server2"";
        final String server3 = ""server3"";

        final List<String> servers = Arrays.asList(server1, server2, server3);
        final Layout layout = layoutUtil.getLayout(servers);

        Map<String, Layout> layouts = new HashMap<>();

        servers.forEach(server -> layouts.put(server, layout));

        Optional<Layout> quorumLayout = managementView.getLayoutFromQuorum(layouts, layouts.size() - 1);
        assertThat(quorumLayout).isEqualTo(Optional.of(layout));

        quorumLayout = managementView.getLayoutFromQuorum(layouts, layouts.size());
        assertThat(quorumLayout).isEqualTo(Optional.of(layout));

        quorumLayout = managementView.getLayoutFromQuorum(layouts, layouts.size() + 1);
        assertThat(quorumLayout).isEqualTo(Optional.empty());
    }
",non-flaky,5
133984,CorfuDB_CorfuDB,ManagementViewTest.testNodeStatusMap,"    @Test
    public void testNodeStatusMap() {
        final String server1 = ""server1"";
        final String server2 = ""server2"";
        final String server3 = ""server3"";
        Layout layout = layoutUtil.getLayout(Arrays.asList(server1, server2, server3));
        layout.setUnresponsiveServers(Arrays.asList(server1, server2));

        Map<String, NodeStatus> status = managementView.getNodeStatusMap(layout);
        assertThat(status.get(server1)).isEqualTo(NodeStatus.DOWN);
        assertThat(status.get(server2)).isEqualTo(NodeStatus.DOWN);
        assertThat(status.get(server3)).isEqualTo(NodeStatus.UP);
    }
",non-flaky,5
133985,CorfuDB_CorfuDB,LayoutTest.testLayoutComparator,"    @Test
    public void testLayoutComparator(){
        Layout l1 = mock(Layout.class);
        Layout l2 = mock(Layout.class);

        when(l1.getEpoch()).thenReturn(1L);
        when(l2.getEpoch()).thenReturn(2L);

        TreeSet<Layout> descendingOrder = new TreeSet<>(Layout.LAYOUT_COMPARATOR);
        descendingOrder.add(l1);
        descendingOrder.add(l2);

        assertEquals(l2.getEpoch(), descendingOrder.first().getEpoch());
    }
",non-flaky,5
133986,CorfuDB_CorfuDB,ClusterHealthTest.testLayoutServersHealth,"    @Test
    public void testLayoutServersHealth(){
        Layout layout = layoutUtil.getLayout(servers);
        ClusterStatus status = clusterHealth.getLayoutServersClusterHealth(
                layout, layout.getAllActiveServers()
        );
        assertThat(status).isEqualTo(ClusterStatus.STABLE);

        layout.setUnresponsiveServers(Collections.singletonList(server3));
        status = clusterHealth.getLayoutServersClusterHealth(
                layout, layout.getAllActiveServers()
        );
        assertThat(status).isEqualTo(ClusterStatus.DEGRADED);

        layout.setUnresponsiveServers(Arrays.asList(server2, server3));
        status = clusterHealth.getLayoutServersClusterHealth(
                layout, layout.getAllActiveServers()
        );
        assertThat(status).isEqualTo(ClusterStatus.UNAVAILABLE);
    }
",non-flaky,5
133987,CorfuDB_CorfuDB,ClusterHealthTest.testSequencerServersHealth,"    @Test
    public void testSequencerServersHealth(){
        Layout layout = layoutUtil.getLayout(servers);
        layout.setUnresponsiveServers(Collections.singletonList(server3));

        ClusterStatus status = clusterHealth.getSequencerServersClusterHealth(
                layout, layout.getAllActiveServers()
        );
        assertThat(status).isEqualTo(ClusterStatus.STABLE);

        //Unresponsive sequencer
        layout.setUnresponsiveServers(Collections.singletonList(server1));
        status = clusterHealth.getSequencerServersClusterHealth(
                layout, layout.getAllActiveServers()
        );
        assertThat(status).isEqualTo(ClusterStatus.UNAVAILABLE);
    }
",non-flaky,5
133988,CorfuDB_CorfuDB,ClusterHealthTest.testLogUnitServersClusterHealth,"    @Test
    public void testLogUnitServersClusterHealth(){
        Layout layout = layoutUtil.getLayout(servers);

        ClusterStatus status = clusterHealth.getLogUnitServersClusterHealth(
                layout, layout.getAllActiveServers()
        );
        assertThat(status).isEqualTo(ClusterStatus.STABLE);

        //invalid segment
        layout.setUnresponsiveServers(Collections.singletonList(server3));
        status = clusterHealth.getLogUnitServersClusterHealth(
                layout, layout.getAllActiveServers()
        );
        assertThat(status).isEqualTo(ClusterStatus.UNAVAILABLE);

        //exclude unresponsive server
        layout.getFirstSegment().getFirstStripe().getLogServers().remove(server3);
        status = clusterHealth.getLogUnitServersClusterHealth(
                layout, layout.getAllActiveServers()
        );
        assertThat(status).isEqualTo(ClusterStatus.STABLE);
    }
",non-flaky,5
133989,CorfuDB_CorfuDB,ClusterHealthTest.testClusterHealth,"    @Test
    public void testClusterHealth() {
        Layout layout = layoutUtil.getLayout(servers);
        layout.setUnresponsiveServers(Collections.singletonList(server3));

        //invalid log unit state
        ClusterStatus status = clusterHealth.getClusterHealth(
                layout, layout.getAllActiveServers()
        );
        assertThat(status).isEqualTo(ClusterStatus.UNAVAILABLE);

        //stable state with an unresponsive server
        layout.getFirstSegment().getFirstStripe().getLogServers().remove(server3);
        status = clusterHealth.getClusterHealth(
                layout, layout.getAllActiveServers()
        );
        assertThat(status).isEqualTo(ClusterStatus.DEGRADED);
    }
",non-flaky,5
133990,CorfuDB_CorfuDB,PayloadTest.checkConstructorMap,"    @Test
    public void checkConstructorMap() {
        List<Class<?>> types = Arrays.asList(
                Byte.class, Integer.class, Long.class, Boolean.class, Double.class, Float.class, String.class,
                Layout.class, CheckpointEntryType.class, UUID.class, byte[].class, ByteBuf.class
        );

        assertThat(CorfuProtocolCommon.getConstructorMap().keySet()).containsAll(types);
    }
",non-flaky,5
133991,CorfuDB_CorfuDB,PayloadTest.testBuildPayloadFromBuffer,"    @Test
    public void testBuildPayloadFromBuffer(){
        final int value = 12345;
        ByteBuf payload = Unpooled.buffer().writeInt(value);
        Integer result = CorfuProtocolCommon.fromBuffer(payload, Integer.class);

        assertThat(result).isEqualTo(value);
    }
",non-flaky,5
133992,CorfuDB_CorfuDB,PayloadTest.testSerialize,"    @Test
    public void testSerialize(){
        ByteBuf buf = Unpooled.buffer();

        Set<String> payload = new HashSet<>();
        payload.add(""value1"");
        payload.add(""value2"");

        CorfuProtocolCommon.serialize(buf, payload);
        assertThat(CorfuProtocolCommon.setFromBuffer(buf, String.class)).isEqualTo(payload);
    }
",non-flaky,5
133993,CorfuDB_CorfuDB,NodeConnectivityTest.testConnectedAndFailedNodes,"    @Test
    public void testConnectedAndFailedNodes() {
        NodeConnectivity nodeState = NodeConnectivity.connectivity(
                ""a"",
                ImmutableMap.of(""a"", OK, ""b"", OK, ""c"", FAILED)
        );

        assertThat(nodeState.getConnectedNodes()).isEqualTo(ImmutableSet.of(""a"", ""b""));
        assertThat(nodeState.getFailedNodes()).isEqualTo(ImmutableSet.of(""c""));
    }
",non-flaky,5
133994,CorfuDB_CorfuDB,CorfuClusterParamsTest.testFullNodeName,"    @Test
    public void testFullNodeName() {
        final String clusterName = ""mycluster"";
        final int port = ServerUtil.getRandomOpenPort();

        CorfuServerParams param = CorfuServerParams
                .serverParamsBuilder()
                .port(port)
                .clusterName(clusterName)
                .serverVersion(""1.0.0"")
                .build();

        SortedSet<CorfuServerParams> corfuServers = new TreeSet<>(Collections.singletonList(param));

        CorfuClusterParams clusterParams = CorfuClusterParams.builder()
                .name(clusterName)
                .nodes(corfuServers)
                .serverVersion(""1.0.0"")
                .build();

        String fqdn = clusterParams.getFullNodeName(""node"" + port);

        assertThat(fqdn).isEqualTo(clusterName + ""-corfu-"" + ""node"" + port);
    }
",non-flaky,5
133995,CorfuDB_CorfuDB,CorfuServerParamsTest.testEquals,"    @Test
    public void testEquals() {
        final int port = 9000;

        CorfuServerParams p1 = CorfuServerParams.serverParamsBuilder()
                .clusterName(""test-cluster"")
                .port(port)
                .logLevel(Level.TRACE)
                .mode(CorfuServer.Mode.CLUSTER)
                .persistence(CorfuServer.Persistence.DISK)
                .stopTimeout(Duration.ofSeconds(123))
                .serverVersion(""1.0.0"")
                .build();

        CorfuServerParams p2 = CorfuServerParams.serverParamsBuilder()
                .clusterName(""test-cluster"")
                .port(port)
                .logLevel(Level.WARN)
                .mode(CorfuServer.Mode.CLUSTER)
                .persistence(CorfuServer.Persistence.DISK)
                .stopTimeout(Duration.ofSeconds(555))
                .serverVersion(""1.0.0"")
                .build();

        assertThat(p1).isEqualTo(p2);
    }
",non-flaky,5
133996,CorfuDB_CorfuDB,HandOfGodIT.handOfGodTest,"    @Test(timeout = 300000)
    public void handOfGodTest() {
        workflow(wf -> {
            wf.deploy();

            ClientParams clientFixture = ClientParams.builder().build();
            CorfuCluster corfuCluster = wf.getUniverse()
                    .getGroup(wf.getFixture().data().getGroupParamByIndex(0).getName());

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table = corfuClient.createDefaultCorfuTable(DEFAULT_STREAM_NAME);
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }

            //Should force remove two nodes from cluster
            CorfuServer server0 = corfuCluster.getServerByIndex(0);
            CorfuServer server1 = corfuCluster.getServerByIndex(1);
            CorfuServer server2 = corfuCluster.getServerByIndex(2);

            // Sequentially kill two nodes
            server1.kill();
            server2.kill();

            // Force remove the dead nodes
            corfuClient.getManagementView().forceRemoveNode(
                    server1.getEndpoint(),
                    clientFixture.getNumRetry(),
                    clientFixture.getTimeout(),
                    clientFixture.getPollPeriod()
            );

            corfuClient.getManagementView().forceRemoveNode(
                    server2.getEndpoint(),
                    clientFixture.getNumRetry(),
                    clientFixture.getTimeout(),
                    clientFixture.getPollPeriod()
            );

            // Verify layout contains only the node that is up
            corfuClient.invalidateLayout();
            Layout layout = corfuClient.getLayout();
            assertThat(layout.getAllActiveServers()).containsExactly(server0.getEndpoint());

            // Verify cluster status is STABLE
            ClusterStatusReport clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            ScenarioUtils.waitUninterruptibly(Duration.ofSeconds(30));

            // Verify data path working
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            corfuClient.shutdown();
        });
    }
",non-flaky,5
133997,CorfuDB_CorfuDB,NodeDownAndPartitionedIT.nodeDownAndPartitionTest,"    @Test(timeout = 300000)
    public void nodeDownAndPartitionTest() {
        workflow(wf -> {
            wf.deploy();

            CorfuCluster corfuCluster = wf.getUniverse()
                    .getGroup(wf.getFixture().data().getGroupParamByIndex(0).getName());

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table = corfuClient
                    .createDefaultCorfuTable(DEFAULT_STREAM_NAME);

            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }

            //Should stop one node and partition another one""
            CorfuServer server0 = corfuCluster.getServerByIndex(0);
            CorfuServer server1 = corfuCluster.getServerByIndex(1);
            CorfuServer server2 = corfuCluster.getServerByIndex(2);

            // Stop one node and partition another one
            server1.stop(Duration.ofSeconds(10));
            server2.disconnect(Arrays.asList(server0, server1));

            waitUninterruptibly(Duration.ofSeconds(20));

            // Verify cluster status
            corfuClient.invalidateLayout();
            ClusterStatusReport clusterStatusReport = corfuClient
                    .getManagementView()
                    .getClusterStatus();
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            // Wait for failure detector finds cluster is down before recovering
            waitForClusterDown(table);

            // Recover cluster by restarting the stopped node, removing
            // partition and wait for layout's unresponsive servers to change
            server1.start();
            server2.reconnect(Arrays.asList(server0, server1));
            waitForUnresponsiveServersChange(size -> size == 0, corfuClient);

            // Check that the segments are merged and all the servers are equal to 3
            waitForLayoutChange(layout -> layout.getSegments().size() == 1 &&
                    layout.getAllServers().size() == 3, corfuClient);
            // wait for the cluster to be up
            waitForClusterUp(table, ""0"");

            clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            // Verify data path working fine
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            corfuClient.shutdown();
        });
    }
",non-flaky,5
133998,CorfuDB_CorfuDB,WriteAfterResetIT.writeAfterResetTest,"    @Test(timeout = 300000)
    public void writeAfterResetTest() {
        workflow(wf -> {

                    wf.setupDocker(fixture -> {
                        fixture.getCluster().numNodes(1);
                    });

                    wf.deploy();
                    try {
                        writeAfterReset(wf);
                    } catch (Exception e) {
                        Assertions.fail(""Test failed: "" + e);
                    }

                }
        );
    }
",non-flaky,5
133999,CorfuDB_CorfuDB,ClusterResizeIT.clusterResizeTest,"    @Test(timeout = 300000)
    public void clusterResizeTest() {
        workflow(wf -> {
            wf.deploy();
            UniverseParams params = wf.getFixture().data();

            ClientParams clientFixture = ClientParams.builder().build();

            CorfuCluster corfuCluster = wf.getUniverse()
                    .getGroup(params.getGroupParamByIndex(0).getName());

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table =
                    corfuClient.createDefaultCorfuTable(TestFixtureConst.DEFAULT_STREAM_NAME);

            for (int i = 0; i < TestFixtureConst.DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }

            List<CorfuServer> servers = Arrays.asList(
                    corfuCluster.getServerByIndex(1),
                    corfuCluster.getServerByIndex(2)
            );

            //should remove two nodes from corfu cluster
            {
                CorfuServer server0 = corfuCluster.getFirstServer();

                // Sequentially remove two nodes from cluster
                for (CorfuServer candidate : servers) {
                    corfuClient.getManagementView().removeNode(
                            candidate.getEndpoint(),
                            clientFixture.getNumRetry(),
                            clientFixture.getTimeout(),
                            clientFixture.getPollPeriod()
                    );
                }

                // Reset all nodes so that we do not end up with an OverwriteException.
                for (CorfuServer candidate : servers) {
                    corfuClient.getRuntime().getLayoutView().getRuntimeLayout()
                            .getBaseClient(candidate.getEndpoint()).reset();
                }

                // Verify layout contains only the node that is not removed
                corfuClient.invalidateLayout();
                assertThat(corfuClient.getLayout().getAllServers())
                        .containsExactly(server0.getEndpoint());

                // Verify data path working fine
                for (int x = 0; x < TestFixtureConst.DEFAULT_TABLE_ITER; x++) {
                    assertThat(table.get(String.valueOf(x))).isEqualTo(String.valueOf(x));
                }

                if (wf.getUniverseMode() == UniverseMode.VM) {
                    ScenarioUtils.waitUninterruptibly(Duration.ofSeconds(15));
                }
            }

            //should add two nodes back to corfu cluster
            {

                // Sequentially add two nodes back into cluster
                for (CorfuServer candidate : servers) {
                    corfuClient.getManagementView().addNode(
                            candidate.getEndpoint(),
                            clientFixture.getNumRetry(),
                            clientFixture.getTimeout(),
                            clientFixture.getPollPeriod()
                    );
                }

                // Verify layout should contain all three nodes
                corfuClient.invalidateLayout();
                assertThat(corfuClient.getLayout().getAllServers().size())
                        .isEqualTo(corfuCluster.nodes().size());

                // Verify data path working fine
                for (int x = 0; x < TestFixtureConst.DEFAULT_TABLE_ITER; x++) {
                    assertThat(table.get(String.valueOf(x))).isEqualTo(String.valueOf(x));
                }
            }

            corfuClient.shutdown();
        });
    }
",non-flaky,5
134000,CorfuDB_CorfuDB,OneNodePausedIT.oneNodePausedTest,"    @Test(timeout = 300000)
    public void oneNodePausedTest() {
        workflow(wf -> {
            wf.deploy();

            CorfuCluster corfuCluster = wf.getUniverse()
                    .getGroup(wf.getFixture().data().getGroupParamByIndex(0).getName());

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table = corfuClient
                    .createDefaultCorfuTable(DEFAULT_STREAM_NAME);

            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }

            //Should pause one node and then resume
            CorfuServer server1 = corfuCluster.getServerByIndex(1);

            // Pause one node and wait for layout's unresponsive servers to change
            server1.pause();
            waitForUnresponsiveServersChange(size -> size == 1, corfuClient);

            // Verify layout, unresponsive servers should contain only one node
            Layout layout = corfuClient.getLayout();
            assertThat(layout.getUnresponsiveServers())
                    .containsExactly(server1.getEndpoint());

            // Verify cluster status is DEGRADED with one node down
            ClusterStatusReport clusterStatusReport = corfuClient.getManagementView()
                    .getClusterStatus();
            assertThat(clusterStatusReport.getClusterStatus())
                    .isEqualTo(ClusterStatus.DEGRADED);
            Map<String, NodeStatus> statusMap = clusterStatusReport
                    .getClusterNodeStatusMap();
            assertThat(statusMap.get(server1.getEndpoint())).isEqualTo(NodeStatus.DOWN);

            // Verify data path working fine
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            // Resume the stopped node and wait for layout's unresponsive servers to change
            server1.resume();
            waitForUnresponsiveServersChange(size -> size == 0, corfuClient);

            final Duration sleepDuration = Duration.ofSeconds(1);
            // Verify cluster status is STABLE
            clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
            while (!clusterStatusReport.getClusterStatus().equals(ClusterStatus.STABLE)) {
                clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
                Sleep.sleepUninterruptibly(sleepDuration);
            }
            assertThat(clusterStatusReport.getClusterStatus())
                    .isEqualTo(ClusterStatus.STABLE);

            // Verify data path working fine
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            corfuClient.shutdown();
        });
    }
",non-flaky,5
134001,CorfuDB_CorfuDB,OneNodeDownIT.oneNodeDownTest,"    @Test(timeout = 300000)
    public void oneNodeDownTest() {

        workflow(wf -> {
            wf.deploy();

            try {
                oneNodeDown(wf);
            } catch (InterruptedException e) {
                fail(""Test failed"", e);
            }
        });
    }
",non-flaky,5
134002,CorfuDB_CorfuDB,BaseServerFileDescriptorLeaksIT.fileDescriptorLeaksBaseServerResetTest,"    @Test(timeout = 300_000)
    public void fileDescriptorLeaksBaseServerResetTest() {

        workflow(wf -> {
            wf.setupDocker(fixture -> fixture.getCluster().numNodes(1));
            wf.deploy();

            try {
                resourceLeaks(wf);
            } catch (Exception e) {
                fail(""Test failed"", e);
            }
        });
    }
",non-flaky,5
134003,CorfuDB_CorfuDB,RotateLinkFailureIT.rotateLinkFailureTest,"    @Test(timeout = 600000)
    public void rotateLinkFailureTest() {
        workflow(wf -> {
            wf.deploy();

            CorfuCluster corfuCluster = wf.getUniverse()
                    .getGroup(wf.getFixture().data().getGroupParamByIndex(0).getName());

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table = corfuClient
                    .createDefaultCorfuTable(DEFAULT_STREAM_NAME);

            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }

            //Should rotate link failures among cluster
            CorfuServer server0 = corfuCluster.getServerByIndex(0);
            CorfuServer server1 = corfuCluster.getServerByIndex(1);
            CorfuServer server2 = corfuCluster.getServerByIndex(2);

            log.info(""1st link failure rotation, disconnect between server0 and server1. "" +
                            ""Current layout: {}"", corfuClient.getLayout()
            );

            server0.disconnect(Collections.singletonList(server1));

            waitForLayoutChange(
                    layout -> {
                        List<String> expected = Collections.singletonList(server1.getEndpoint());
                        return layout.getUnresponsiveServers().equals(expected);
                    },
                    corfuClient
            );

            ScenarioUtils.waitForClusterUp(table, ""0"");

            Layout latestLayout = corfuClient.getLayout();

            log.info(""Verify data path working fine"");
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            log.info(""2nd link failure rotation, disconnect between server1 and server2 "" +
                    ""and heal previous link failure between server0 and server1"");
            server1.disconnect(Collections.singletonList(server2));
            server0.reconnect(Collections.singletonList(server1));

            log.info(""Wait for some time to ensure cluster stabilizes Server1 should stay "" +
                    ""in unresponsive set, no layout change"");
            waitUninterruptibly(Duration.ofSeconds(30));
            assertThat(corfuClient.getLayout()).isEqualTo(latestLayout);

            ScenarioUtils.waitForClusterUp(table, ""0"");
            log.info(""Verify data path working fine"");
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            log.info(""3rd link failure rotation, disconnect between server2 and server0 "" +
                    ""and heal previous link failure between server1 and server2"");
            server2.disconnect(Collections.singletonList(server0));
            server1.reconnect(Collections.singletonList(server2));

            log.info(""Server0 and server2 has same number of link failure ie. 1, "" +
                    ""the one with larger endpoint should be marked as unresponsive."");
            waitForLayoutChange(
                    layout -> {
                        List<String> expected = Collections.singletonList(server2.getEndpoint());
                        return layout.getUnresponsiveServers().equals(expected);
                    },
                    corfuClient
            );

            log.info(""Verify data path working fine"");
            waitUninterruptibly(Duration.ofSeconds(20));
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            log.info(""4th link failure rotation, reverse the rotating direction, "" +
                    ""disconnect between server1 and server2 "" +
                    ""and heal previous link failure between server1 and server2"");
            server1.disconnect(Collections.singletonList(server2));
            server2.reconnect(Collections.singletonList(server0));

            log.info(""Wait for some time to ensure cluster stabilizes "" +
                    ""Server1 should stay in unresponsive set, no layout change"");
            waitUninterruptibly(Duration.ofSeconds(30));

            log.info(""Verify data path working fine"");
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            log.info(""Finally stop rotation and heal all link failures."");
            server1.reconnect(Collections.singletonList(server2));
            waitForUnresponsiveServersChange(size -> size == 0, corfuClient);

            final Duration sleepDuration = Duration.ofSeconds(1);
            log.info(""Verify cluster status is STABLE"");
            ClusterStatusReport clusterStatusReport = corfuClient
                    .getManagementView()
                    .getClusterStatus();

            while (!clusterStatusReport.getClusterStatus().equals(ClusterStatus.STABLE)) {
                clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
                Sleep.sleepUninterruptibly(sleepDuration);
            }
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            log.info(""Verify data path working fine"");
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            corfuClient.shutdown();
        });
    }
",non-flaky,5
134004,CorfuDB_CorfuDB,NodePausedAndPartitionedIT.nodesPausedAndPartitionedTest,"    @Test(timeout = 300000)
    public void nodesPausedAndPartitionedTest() {
        workflow(wf -> {
            wf.deploy();

            CorfuCluster corfuCluster = wf.getUniverse()
                    .getGroup(wf.getFixture().data().getGroupParamByIndex(0).getName());

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table = corfuClient
                    .createDefaultCorfuTable(DEFAULT_STREAM_NAME);

            for (int i = 0; i < TestFixtureConst.DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }

            //Should pause one node and partition another
            CorfuServer server0 = corfuCluster.getServerByIndex(0);
            CorfuServer server1 = corfuCluster.getServerByIndex(1);
            CorfuServer server2 = corfuCluster.getServerByIndex(2);

            // Pause one node and partition another one
            server1.pause();
            server2.disconnect(Arrays.asList(server0, server1));

            waitUninterruptibly(Duration.ofSeconds(20));

            // Verify cluster status
            corfuClient.invalidateLayout();
            ClusterStatusReport clusterStatusReport = corfuClient
                    .getManagementView()
                    .getClusterStatus();
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            // Wait for failure detector finds cluster is down before recovering
            waitForClusterDown(table);

            // Recover cluster by resuming the paused node, removing
            // partition and wait for layout's unresponsive servers to change.
            // Also wait for the segment merge.
            server1.resume();
            server2.reconnect(Arrays.asList(server0, server1));
            waitForUnresponsiveServersChange(size -> size == 0, corfuClient);
            waitForLayoutChange(layout -> layout.getSegments().size() == 1, corfuClient);
            // Verify cluster status is STABLE
            corfuClient.invalidateLayout();
            clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            // Verify data path working fine
            for (int i = 0; i < TestFixtureConst.DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            corfuClient.shutdown();
        });
    }
",non-flaky,5
134005,CorfuDB_CorfuDB,ConcurrentClusterResizeIT.concurrentClusterResizeTest,"    @Test(timeout = 600000)
    public void concurrentClusterResizeTest() {
        // Deploy a five nodes cluster
        final int numNodes = 5;

        workflow(wf -> {
            wf.setupDocker(fixture -> fixture.getCluster().numNodes(numNodes));
            wf.setupProcess(fixture -> fixture.getCluster().numNodes(numNodes));
            wf.setupVm(fixture -> fixture.getCluster().numNodes(numNodes));

            wf.deploy();

            ClientParams clientFixture = ClientParams.builder().build();
            CorfuCluster corfuCluster = wf.getUniverse()
                    .getGroup(wf.getFixture().data().getGroupParamByIndex(0).getName());

            assertThat(corfuCluster.nodes().size()).isEqualTo(numNodes);

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table =
                    corfuClient.createDefaultCorfuTable(TestFixtureConst.DEFAULT_STREAM_NAME);
            for (int i = 0; i < TestFixtureConst.DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }

            CorfuServer server0 = corfuCluster.getFirstServer();

            // Get the servers list to be added/removed -all servers in the cluster exclude server0
            List<CorfuServer> servers = IntStream.range(1, numNodes)
                    .mapToObj(corfuCluster::getServerByIndex)
                    .collect(Collectors.toList());

            //should concurrently remove four nodes from cluster

            // Concurrently remove four nodes from cluster
            ExecutorService executor = Executors.newFixedThreadPool(numNodes - 1);

            servers.forEach(node -> {
                Runnable removeNodeAction = () -> corfuClient.getManagementView().removeNode(
                        node.getEndpoint(),
                        clientFixture.getNumRetry(),
                        clientFixture.getTimeout(),
                        clientFixture.getPollPeriod()
                );
                executor.submit(removeNodeAction);
            });

            // Wait for layout servers to change and wait for cluster to be up
            waitForLayoutServersChange(size -> size == 1, corfuClient);
            executor.shutdownNow();

            // Verify layout contains only one node
            corfuClient.invalidateLayout();
            assertThat(corfuClient.getLayout().getAllServers()).containsExactly(server0.getEndpoint());

            waitForClusterUp(table, ""0"");
            // Verify data path working fine
            for (int x = 0; x < TestFixtureConst.DEFAULT_TABLE_ITER; x++) {
                assertThat(table.get(String.valueOf(x))).isEqualTo(String.valueOf(x));
            }

            //should concurrently add four nodes back into cluster""

            // Concurrently add four nodes back into cluster and wait for cluster to stabilize
            ExecutorService executor2 = Executors.newFixedThreadPool(numNodes - 1);
            servers.forEach(node -> executor2.submit(() -> corfuClient.getManagementView().addNode(
                    node.getEndpoint(),
                    clientFixture.getNumRetry(),
                    clientFixture.getTimeout(),
                    clientFixture.getPollPeriod())
            ));


            // Check that the segments are merged and all the servers are equal to numNodes
            waitForLayoutChange(layout -> layout.getAllServers().size() == numNodes, corfuClient);
            waitForLayoutChange(layout -> layout.getSegments().size() == 1, corfuClient);
            // wait for the cluster to be up
            waitForClusterUp(table, ""0"");
            executor2.shutdownNow();

            // Verify data path working fine
            for (int x = 0; x < TestFixtureConst.DEFAULT_TABLE_ITER; x++) {
                assertThat(table.get(String.valueOf(x))).isEqualTo(String.valueOf(x));
            }

            corfuClient.shutdown();
        });
    }
",non-flaky,5
134006,CorfuDB_CorfuDB,OneLinkFailureIT.oneLinkFailureTest,"    @Test(timeout = 300000)
    public void oneLinkFailureTest() {
        workflow(wf -> {
            wf.deploy();

            CorfuCluster corfuCluster = wf.getUniverse()
                    .getGroup(wf.getFixture().data().getGroupParamByIndex(0).getName());

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table = corfuClient.createDefaultCorfuTable(DEFAULT_STREAM_NAME);
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }

            //Should fail one link and then heal""
            CorfuServer server0 = corfuCluster.getServerByIndex(0);
            CorfuServer server2 = corfuCluster.getServerByIndex(2);

            // Create link failure between server0 and server2
            server0.disconnect(Collections.singletonList(server2));
            // Server0 and server2 has same number of link failure ie. 1, the one with
            // larger endpoint should be marked as unresponsive.
            String serverToKick = Collections.max(
                    Arrays.asList(server0.getEndpoint(), server2.getEndpoint())
            );
            waitForUnresponsiveServersChange(size -> size == 1, corfuClient);

            assertThat(corfuClient.getLayout().getUnresponsiveServers())
                    .containsExactly(serverToKick);

            // Cluster status should be DEGRADED after one node is marked unresponsive
            ClusterStatusReport clusterStatusReport = corfuClient
                    .getManagementView()
                    .getClusterStatus();
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.DEGRADED);

            // Verify data path working fine
            ScenarioUtils.waitUninterruptibly(Duration.ofSeconds(10));
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            // Repair the partition between server0 and server2
            server0.reconnect(Collections.singletonList(server2));
            waitForUnresponsiveServersChange(size -> size == 0, corfuClient);

            final Duration sleepDuration = Duration.ofSeconds(1);
            // Verify cluster status is STABLE
            clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
            while (!clusterStatusReport.getClusterStatus().equals(ClusterStatus.STABLE)) {
                clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
                Sleep.sleepUninterruptibly(sleepDuration);
            }
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            // Verify data path working fine
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            corfuClient.shutdown();
        });
    }
",non-flaky,5
134007,CorfuDB_CorfuDB,NodeUpAndPartitionedIT.nodeUpAndPartitionedTest,"    @Test(timeout = 300000)
    public void nodeUpAndPartitionedTest() {
        workflow(wf -> {
            wf.deploy();

            CorfuCluster corfuCluster = wf.getUniverse()
                    .getGroup(wf.getFixture().data().getGroupParamByIndex(0).getName());

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table = corfuClient
                    .createDefaultCorfuTable(DEFAULT_STREAM_NAME);
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }

            //Should fail the node with most link failures to unresponsive set
            // Deploy and bootstrap three nodes
            CorfuServer server0 = corfuCluster.getServerByIndex(0);
            CorfuServer server1 = corfuCluster.getServerByIndex(1);
            CorfuServer server2 = corfuCluster.getServerByIndex(2);

            long currEpoch = corfuClient.getLayout().getEpoch();

            log.info(""Stop server1"");
            server1.stop(Duration.ofSeconds(10));
            waitForNextEpoch(corfuClient, currEpoch + 1);
            assertThat(corfuClient.getLayout().getUnresponsiveServers())
                    .containsExactly(server1.getEndpoint());
            currEpoch++;

            // Partition the responsive server0 from both unresponsive server1
            // and responsive server2 and reconnect server 1. Wait for layout's unresponsive
            // servers to change After this, cluster becomes unavailable.
            // NOTE: cannot use waitForClusterDown() since the partition only happens on server side,
            // client can still connect to two nodes, write to table,
            // so system down handler will not be triggered.
            server0.disconnect(Arrays.asList(server1, server2));
            server1.start();

            waitForLayoutChange(l -> {
                List<String> unresponsive = l.getUnresponsiveServers();
                return unresponsive.size() == 1 && unresponsive.contains(server0.getEndpoint());
            }, corfuClient);

            // Verify server0 is unresponsive
            List<String> unresponsiveServers = corfuClient.getLayout().getUnresponsiveServers();
            assertThat(unresponsiveServers)
                    .as(""Wrong number of unresponsive servers: %s"", unresponsiveServers)
                    .containsExactly(server0.getEndpoint());
            currEpoch += 2;

            waitUninterruptibly(Duration.ofSeconds(20));

            // Verify cluster status. Cluster status should be DEGRADED after one node is
            // marked unresponsive
            ClusterStatusReport clusterStatusReport = corfuClient
                    .getManagementView()
                    .getClusterStatus();
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.DEGRADED);

            // Heal all the link failures
            server0.reconnect(Arrays.asList(server1, server2));
            waitForNextEpoch(corfuClient, currEpoch + 1);
            currEpoch++;

            Duration sleepDuration = Duration.ofSeconds(1);
            // Verify cluster status is STABLE
            clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
            while (!clusterStatusReport.getClusterStatus().equals(ClusterStatus.STABLE)) {
                clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
                Sleep.sleepUninterruptibly(sleepDuration);
            }
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            Sleep.sleepUninterruptibly(Duration.ofSeconds(10));

            // Verify data path is working fine
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            corfuClient.shutdown();
        });
    }
",non-flaky,5
134008,CorfuDB_CorfuDB,TwoNodesDownIT.twoNodesDownTest,"    @Test(timeout = 300000)
    public void twoNodesDownTest() {
        workflow(wf -> {
            wf.deploy();

            CorfuCluster corfuCluster = wf.getUniverse()
                    .getGroup(wf.getFixture().data().getGroupParamByIndex(0).getName());

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table = corfuClient
                    .createDefaultCorfuTable(DEFAULT_STREAM_NAME);

            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }

            //Should stop two nodes and then restart
            CorfuServer server0 = corfuCluster.getServerByIndex(0);
            CorfuServer server1 = corfuCluster.getServerByIndex(1);
            CorfuServer server2 = corfuCluster.getServerByIndex(2);

            // Sequentially stop two nodes
            server1.stop(Duration.ofSeconds(10));
            server2.stop(Duration.ofSeconds(10));

            // Verify cluster status is UNAVAILABLE with two node down and one node up
            corfuClient.invalidateLayout();
            ClusterStatusReport clusterStatusReport = corfuClient
                    .getManagementView()
                    .getClusterStatus();

            Map<String, NodeStatus> nodeStatusMap = clusterStatusReport.getClusterNodeStatusMap();
            Map<String, ConnectivityStatus> connectivityStatusMap = clusterStatusReport
                    .getClientServerConnectivityStatusMap();
            ClusterStatusReliability reliability = clusterStatusReport.getClusterStatusReliability();

            assertThat(connectivityStatusMap.get(server0.getEndpoint()))
                    .isEqualTo(ConnectivityStatus.RESPONSIVE);
            assertThat(connectivityStatusMap.get(server1.getEndpoint()))
                    .isEqualTo(ConnectivityStatus.UNRESPONSIVE);
            assertThat(connectivityStatusMap.get(server2.getEndpoint()))
                    .isEqualTo(ConnectivityStatus.UNRESPONSIVE);

            assertThat(nodeStatusMap.get(server0.getEndpoint())).isEqualTo(NodeStatus.NA);
            assertThat(nodeStatusMap.get(server1.getEndpoint())).isEqualTo(NodeStatus.NA);
            assertThat(nodeStatusMap.get(server2.getEndpoint())).isEqualTo(NodeStatus.NA);

            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.UNAVAILABLE);
            assertThat(reliability).isEqualTo(ClusterStatusReliability.WEAK_NO_QUORUM);

            // Wait for failure detector finds cluster is down before recovering
            waitForClusterDown(table);

            // Sequentially restart two nodes and wait for layout's unresponsive servers to change
            server1.start();
            server2.start();

            Layout initialLayout = clusterStatusReport.getLayout();
            waitForLayoutChange(layout -> layout.getEpoch() > initialLayout.getEpoch()
                    && layout.getUnresponsiveServers().size() == 0, corfuClient);

            final Duration sleepDuration = Duration.ofSeconds(1);

            // Verify cluster status is STABLE
            clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
            while (!clusterStatusReport.getClusterStatus().equals(ClusterStatus.STABLE)) {
                clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
                Sleep.sleepUninterruptibly(sleepDuration);
            }
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            // Verify data path working fine
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            corfuClient.shutdown();
        });
    }
",non-flaky,5
134009,CorfuDB_CorfuDB,AllNodesPartitionedIT.allNodesPartitionedTest,"    @Test(timeout = 300000)
    public void allNodesPartitionedTest() {
        workflow(wf -> {
            wf.deploy();

            UniverseParams params = wf.getFixture().data();

            CorfuCluster<CorfuServer, CorfuClusterParams> corfuCluster = wf.getUniverse()
                    .getGroup(params.getGroupParamByIndex(0).getName());

            CorfuClusterParams corfuClusterParams = corfuCluster.getParams();

            assertThat(corfuCluster.nodes().size()).isEqualTo(3);
            assertThat(corfuCluster.nodes().size()).isEqualTo(corfuClusterParams.size());

            assertThat(corfuCluster.getParams().getNodesParams().size())
                    .as(""Invalid cluster: %s, but expected 3 nodes"",
                            corfuClusterParams.getClusterNodes()
                    )
                    .isEqualTo(3);

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table =
                    corfuClient.createDefaultCorfuTable(TestFixtureConst.DEFAULT_STREAM_NAME);
            for (int i = 0; i < TestFixtureConst.DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }


            // Symmetrically partition all nodes and wait for failure
            // detector to work and cluster to stabilize
            List<CorfuServer> allServers = corfuCluster.<CorfuServer>nodes().values().asList();
            allServers.forEach(server -> {
                List<CorfuServer> otherServers = new ArrayList<>(allServers);
                otherServers.remove(server);
                server.disconnect(otherServers);
            });

            waitUninterruptibly(Duration.ofSeconds(20));

            // Verify cluster and node status
            ClusterStatusReport clusterStatusReport = corfuClient
                    .getManagementView()
                    .getClusterStatus();
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            Map<String, NodeStatus> statusMap = clusterStatusReport.getClusterNodeStatusMap();
            corfuCluster.nodes()
                    .values()
                    .forEach(node ->
                            assertThat(statusMap.get(node.getEndpoint())).isEqualTo(NodeStatus.UP)
                    );

            Map<String, ConnectivityStatus> connectivityMap = clusterStatusReport
                    .getClientServerConnectivityStatusMap();

            corfuCluster.nodes().values().forEach(node -> {
                assertThat(connectivityMap.get(node.getEndpoint()))
                        .isEqualTo(ConnectivityStatus.RESPONSIVE);
            });

            // Remove partitions and wait for layout's unresponsive servers to change
            waitUninterruptibly(Duration.ofSeconds(10));
            corfuCluster.nodes().values().forEach(CorfuServer::reconnect);

            waitForUnresponsiveServersChange(size -> size == 0, corfuClient);

            // Verify cluster status is STABLE
            clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            waitForClusterUp(table, ""0"");

            // Verify data path working fine
            for (int i = 0; i < TestFixtureConst.DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }


            corfuClient.shutdown();

        });
    }
",non-flaky,5
134010,CorfuDB_CorfuDB,TwoLinksFailureIT.twoLinksFailureTest,"    @Test(timeout = 300000)
    public void twoLinksFailureTest() {
        workflow(wf -> {
            wf.deploy();

            CorfuCluster corfuCluster = wf.getUniverse()
                    .getGroup(wf.getFixture().data().getGroupParamByIndex(0).getName());

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table = corfuClient
                    .createDefaultCorfuTable(DEFAULT_STREAM_NAME);
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }

            //Should fail two links and then heal
            CorfuServer server0 = corfuCluster.getServerByIndex(0);
            CorfuServer server1 = corfuCluster.getServerByIndex(1);
            CorfuServer server2 = corfuCluster.getServerByIndex(2);

            // Disconnect server0 with server1 and server2
            server0.disconnect(Arrays.asList(server1, server2));
            waitForLayoutChange(layout -> layout.getUnresponsiveServers()
                    .equals(Collections.singletonList(server0.getEndpoint())), corfuClient);

            // Cluster status should be DEGRADED after one node is marked unresponsive
            ClusterStatusReport clusterStatusReport = corfuClient
                    .getManagementView()
                    .getClusterStatus();
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.DEGRADED);

            // Verify data path working fine
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            // Repair the link failure between server0 and others
            server0.reconnect(Arrays.asList(server1, server2));
            waitForUnresponsiveServersChange(size -> size == 0, corfuClient);

            final Duration sleepDuration = Duration.ofSeconds(1);
            // Verify cluster status is STABLE
            clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
            while (!clusterStatusReport.getClusterStatus().equals(ClusterStatus.STABLE)) {
                clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
                Sleep.sleepUninterruptibly(sleepDuration);
            }
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            // Verify data path working fine
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            corfuClient.shutdown();
        });
    }
",non-flaky,5
134011,CorfuDB_CorfuDB,NodeDownAndLinkFailureIT.nodeDownAndLinkFailureTest,"    @Test(timeout = 300000)
    public void nodeDownAndLinkFailureTest() {
        workflow(wf -> {
            wf.deploy();

            CorfuCluster corfuCluster = wf.getUniverse()
                    .getGroup(wf.getFixture().data().getGroupParamByIndex(0).getName());

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table = corfuClient.createDefaultCorfuTable(DEFAULT_STREAM_NAME);
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }

            //Should fail one link then one node and then heal
            CorfuServer server0 = corfuCluster.getServerByIndex(0);
            CorfuServer server1 = corfuCluster.getServerByIndex(1);
            CorfuServer server2 = corfuCluster.getServerByIndex(2);

            long currEpoch = corfuClient.getLayout().getEpoch();

            log.info(""Stop server2 and wait for layout's unresponsive servers to change"");
            server2.stop(Duration.ofSeconds(10));
            waitForNextEpoch(corfuClient, currEpoch + 1);
            assertThat(corfuClient.getLayout().getUnresponsiveServers()).containsExactly(server2.getEndpoint());
            currEpoch++;

            // Create link failure between server0 and server1
            // After this, cluster becomes unavailable.
            // NOTE: cannot use waitForClusterDown() since the partition only happens on server side, client
            // can still connect to two nodes, write to table so system down handler will not be triggered.
            log.info(""Create link failure between server0 and server1"");
            server0.disconnect(Collections.singletonList(server1));

            // Restart the stopped node, server0 and server1 still partitioned,
            // wait for the one with larger endpoint be marked as unresponsive.
            log.info(""Restart the stopped node, server0 and server1 still partitioned wait for "" +
                    ""the one with larger endpoint be marked as unresponsive."");
            server2.start();

            waitForLayoutChange(layout -> layout.getUnresponsiveServers()
                    .equals(Collections.singletonList(server1.getEndpoint())), corfuClient);

            // Cluster status should be DEGRADED after one node is marked unresponsive
            ClusterStatusReport clusterStatusReport = corfuClient
                    .getManagementView()
                    .getClusterStatus();
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.DEGRADED);

            log.info(""Repair the partition between server0 and server1"");
            server0.reconnect(Collections.singletonList(server1));
            //TODO why we update epoch many times?
            waitForUnresponsiveServersChange(size -> size == 0, corfuClient);

            Duration sleepDuration = Duration.ofSeconds(1);
            // Verify cluster status is STABLE
            clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
            while (!clusterStatusReport.getClusterStatus().equals(ClusterStatus.STABLE)) {
                clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
                Sleep.sleepUninterruptibly(sleepDuration);
            }
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            // Verify data path working fine
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            corfuClient.shutdown();
        });
    }
",non-flaky,5
134012,CorfuDB_CorfuDB,LoggingMeterRegistryTest.testWriteGauge,"    @Test
    public void testWriteGauge() {
        Meter.Id id = new Meter.Id(""metric"", Tags.of(""endpoint"", ""localhost:9000""),
                null, null, Meter.Type.GAUGE);
        LoggingMeterRegistryWithHistogramSupport registry = getInstance();
        Stream<String> stream = registry.writeGauge(id, 20.0);
        String line = stream.findFirst().orElseThrow(IllegalArgumentException::new);
        assertTrue(line.contains(""metric,endpoint=localhost:9000,metric_type=gauge value=20""));
    }
",non-flaky,5
134013,CorfuDB_CorfuDB,LoggingMeterRegistryTest.testWriteCounter,"    @Test
    public void testWriteCounter() {
        Meter.Id id = new Meter.Id(""metric"", Tags.of(""endpoint"", ""localhost:9000""),
                null, null,
                Meter.Type.COUNTER);
        LoggingMeterRegistryWithHistogramSupport registry = getInstance();
        Stream<String> stream = registry.writeCounter(id, 30);
        String line = stream.findFirst().orElseThrow(IllegalArgumentException::new);
        assertTrue(line.contains(""metric,endpoint=localhost:9000,metric_type=counter value=30""));
    }
",non-flaky,5
134014,CorfuDB_CorfuDB,LoggingMeterRegistryTest.testWriteTimer,"    @Test
    public void testWriteTimer() {
        LoggingMeterRegistryWithHistogramSupport registry = getInstance();
        Timer timer = new TestTimer();
        String line = registry.writeTimer(timer).findFirst().orElseThrow(IllegalArgumentException::new);
        assertTrue(line.contains(""metric,endpoint=localhost:9000,metric_type=timer sum=200,count=100,mean=2,upper=300""));
    }
",non-flaky,5
134015,CorfuDB_CorfuDB,LoggingMeterRegistryTest.testWriteSummary,"    @Test
    public void testWriteSummary() {
        LoggingMeterRegistryWithHistogramSupport registry = getInstance();
        TestSummary summary = new TestSummary();
        String line = registry.writeSummary(summary).findFirst().orElseThrow(IllegalArgumentException::new);
        assertTrue(line.contains(""metric,endpoint=localhost:9000,metric_type=summary sum=200,count=100,mean=2,upper=300""));
    }
",non-flaky,5
134016,CorfuDB_CorfuDB,LoggingMeterRegistryTest.testTimerPercentiles,"    @Test
    public void testTimerPercentiles() {
        AggregateSink sink = new AggregateSink();

        LoggingMeterRegistryWithHistogramSupport registry = getInstance(sink);

        Timer timer = Timer.builder(""timer"")
                .publishPercentileHistogram()
                .publishPercentiles(0.99, 0.95, 0.5)
                .tags(""endpoint"", ""localhost:9000"")
                .register(registry);
        for (int i = 0; i < 3; i++) {
            timer.record(() -> {
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException ie) {

                }
            });
        }
        assertTrue(sink.substringIsPresent(""timer_percentile,endpoint=localhost:9000,phi=0.99,metric_type=gauge""));
        assertTrue(sink.substringIsPresent(""timer_percentile,endpoint=localhost:9000,phi=0.95,metric_type=gauge""));
        assertTrue(sink.substringIsPresent(""timer_percentile,endpoint=localhost:9000,phi=0.5,metric_type=gauge""));
    }
",non-flaky,5
134017,CorfuDB_CorfuDB,LoggingMeterRegistryTest.testSummaryPercentiles,"    @Test
    public void testSummaryPercentiles() {
        AggregateSink sink = new AggregateSink();

        LoggingMeterRegistryWithHistogramSupport registry = getInstance(sink);

        DistributionSummary summary = DistributionSummary.builder(""summary"")
                .publishPercentileHistogram()
                .publishPercentiles(0.99, 0.95, 0.5)
                .tags(""endpoint"", ""localhost:9000"")
                .register(registry);

        for (int i = 0; i < 3; i++) {
            summary.record(100);
            try {
                Thread.sleep(1000);
            } catch (InterruptedException ie) {

            }
        }
        assertTrue(sink.substringIsPresent(""summary_percentile,endpoint=localhost:9000,phi=0.99,metric_type=gauge value=100""));
        assertTrue(sink.substringIsPresent(""summary_percentile,endpoint=localhost:9000,phi=0.95,metric_type=gauge value=100""));
        assertTrue(sink.substringIsPresent(""summary_percentile,endpoint=localhost:9000,phi=0.5,metric_type=gauge value=100""));
    }
",non-flaky,5
134018,CorfuDB_CorfuDB,LogReplicationClientTest.testHandleLeadershipLoss,"    @Test
    public void testHandleLeadershipLoss() {
        final LogReplicationLeadershipLossResponseMsg leadershipLoss =  LogReplicationLeadershipLossResponseMsg
                .newBuilder().build();
        final ResponseMsg response = ResponseMsg.newBuilder().setPayload(
                CorfuMessage.ResponsePayloadMsg.newBuilder()
                        .setLrLeadershipLoss(leadershipLoss).build()).build();
        lrClient.receive(response);

        ArgumentCaptor<LogReplicationRuntimeEvent> argument = ArgumentCaptor.forClass(LogReplicationRuntimeEvent.class);
        verify(lrFsm).input(argument.capture());
        Assertions.assertThat(argument.getValue().getType()).isEqualTo(LogReplicationRuntimeEventType.REMOTE_LEADER_LOSS);
    }
",non-flaky,5
134019,CorfuDB_CorfuDB,LogReplicationClientTest.testHandleLeadershipResponse,"    @Test
    public void testHandleLeadershipResponse() {
        final LogReplicationLeadershipResponseMsg leadershipResponse = LogReplicationLeadershipResponseMsg
                .newBuilder().build();
        final ResponseMsg response = ResponseMsg.newBuilder().setPayload(
                CorfuMessage.ResponsePayloadMsg.newBuilder()
                        .setLrLeadershipResponse(leadershipResponse).build()).build();

        ArgumentCaptor<PayloadCase> argument = ArgumentCaptor.forClass(PayloadCase.class);

        lrClient.receive(response);
        verify(handlerMap, atLeast(1)).get(argument.capture());
        Assertions.assertThat(argument.getValue()).isEqualTo(PayloadCase.LR_LEADERSHIP_RESPONSE);
    }
",non-flaky,5
134020,CorfuDB_CorfuDB,LogReplicationClientTest.testHandleEntryAck,"    @Test
    public void testHandleEntryAck() {
        final LogReplicationEntryMsg entry =  LogReplicationEntryMsg
                .newBuilder().build();
        final ResponseMsg response = ResponseMsg.newBuilder().setPayload(
                CorfuMessage.ResponsePayloadMsg.newBuilder()
                        .setLrEntryAck(entry).build()).build();

        ArgumentCaptor<PayloadCase> argument = ArgumentCaptor.forClass(PayloadCase.class);

        lrClient.receive(response);
        verify(handlerMap, atLeast(1)).get(argument.capture());
        Assertions.assertThat(argument.getValue()).isEqualTo(PayloadCase.LR_ENTRY_ACK);
    }
",non-flaky,5
134021,CorfuDB_CorfuDB,LogReplicationClientTest.testHandleMetadataResponse,"    @Test
    public void testHandleMetadataResponse() {
        final LogReplicationMetadataResponseMsg entry =  LogReplicationMetadataResponseMsg
                .newBuilder().build();
        final ResponseMsg response = ResponseMsg.newBuilder().setPayload(
                CorfuMessage.ResponsePayloadMsg.newBuilder()
                        .setLrMetadataResponse(entry).build()).build();

        ArgumentCaptor<PayloadCase> argument = ArgumentCaptor.forClass(PayloadCase.class);

        lrClient.receive(response);
        verify(handlerMap, atLeast(1)).get(argument.capture());
        Assertions.assertThat(argument.getValue()).isEqualTo(PayloadCase.LR_METADATA_RESPONSE);
    }
",non-flaky,5
134022,CorfuDB_CorfuDB,ServerHandshakeHandlerTest.testHandshakeSucceed,"    @Test
    public void testHandshakeSucceed() {
        // Get a HandshakeRequestMsg with specified server node id.
        RequestMsg request = getRequestMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getHandshakeRequestMsg(DEFAULT_UUID, SERVER_NODEID)
        );

        embeddedChannel.writeInbound(request);
        Object out = embeddedChannel.readOutbound();

        // Verify that the handshake is complete and HandshakeResponse is sent back.
        assertTrue(out instanceof ResponseMsg);
        assertEquals(SERVER_NODEID, getUUID(((ResponseMsg) out).getPayload().getHandshakeResponse()
                .getServerId()));
    }
",non-flaky,5
134023,CorfuDB_CorfuDB,ServerHandshakeHandlerTest.testVersionMismatchHandshakeSucceed,"    @Test
    public void testVersionMismatchHandshakeSucceed() {
        // Get a HandshakeRequestMsg whose corfu_source_code_version set in the header is different
        // from that at server side.
        RequestMsg request = getRequestMsg(
            HeaderMsg.newBuilder()
                .setVersion(
                     ProtocolVersionMsg.newBuilder()
                    .setCorfuSourceCodeVersion(FAKE_CLIENT_VERSION)
                    .setCapabilityVector(CompatibilityVectorUtils.getCompatibilityVectors())
                    .build())
                .setRequestId(requestCounter.incrementAndGet())
                .setPriority(PriorityLevel.NORMAL)
                .setEpoch(0L)
                .setClusterId(getUuidMsg(DEFAULT_UUID))
                .setClientId(getUuidMsg(DEFAULT_UUID))
                .setIgnoreClusterId(false)
                .setIgnoreEpoch(true)
                .build(),
            getHandshakeRequestMsg(DEFAULT_UUID, SERVER_NODEID)
        );

        embeddedChannel.writeInbound(request);
        Object out = embeddedChannel.readOutbound();

        // Verify that the handshake could still complete even if the versions of client and server
        // are different.
        assertTrue(out instanceof ResponseMsg);
        assertEquals(SERVER_NODEID, getUUID(((ResponseMsg) out).getPayload().getHandshakeResponse()
                .getServerId()));
    }
",non-flaky,5
134024,CorfuDB_CorfuDB,ServerHandshakeHandlerTest.testRequestDroppedBeforeHandshake,"    @Test
    public void testRequestDroppedBeforeHandshake() {
        // Get a ping RequestMsg
        RequestMsg request = getRequestMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getPingRequestMsg()
        );

        embeddedChannel.writeInbound(request);

        // Verify that the request was correctly dropped and there is no inbound nor outbound messages.
        assertNull(embeddedChannel.readInbound());
        assertNull(embeddedChannel.readOutbound());
    }
",non-flaky,5
134025,CorfuDB_CorfuDB,ServerHandshakeHandlerTest.testRequestPassedAfterHandshake,"    @Test
    public void testRequestPassedAfterHandshake() {
        // Get a HandshakeRequestMsg with specified server node id.
        RequestMsg handshakeRequest = getRequestMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getHandshakeRequestMsg(DEFAULT_UUID, SERVER_NODEID)
        );
        // Get a ping RequestMsg
        RequestMsg pingRequest = getRequestMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getPingRequestMsg()
        );

        embeddedChannel.writeInbound(handshakeRequest);
        embeddedChannel.writeInbound(pingRequest);

        Object in = embeddedChannel.readInbound();
        Object out = embeddedChannel.readOutbound();

        // Verify that the ping request is passed to next handler.
        assertEquals(in, pingRequest);
        // Verify that the handshake is complete and HandshakeResponse is sent back.
        assertTrue(out instanceof ResponseMsg);
        assertEquals(SERVER_NODEID, getUUID(((ResponseMsg) out).getPayload().getHandshakeResponse()
                .getServerId()));
    }
",non-flaky,5
134026,CorfuDB_CorfuDB,OrchestratorTest.testQueryWorkflow,"    @Test
    public void testQueryWorkflow() {
        // First perform a QUERY request for an inactive workflow.
        RequestMsg request = getRequestMsg(getBasicHeader(), getQueryWorkflowRequestMsg(WORKFLOW_ID_2));
        ArgumentCaptor<ResponseMsg> responseCaptor = ArgumentCaptor.forClass(ResponseMsg.class);
        orchestrator.handle(request, mockChannelHandlerContext, mockServerRouter);

        verify(mockServerRouter).sendResponse(responseCaptor.capture(), eq(mockChannelHandlerContext));
        ResponseMsg response = responseCaptor.getValue();

        // Assert that the payload has an ORCHESTRATOR_RESPONSE, that the base
        // header fields have remained the same, and that the queried workflow
        // was inactive.
        assertTrue(compareBaseHeaderFields(request.getHeader(), response.getHeader()));
        assertTrue(response.getPayload().hasOrchestratorResponse());
        assertTrue(response.getPayload().getOrchestratorResponse().hasQueryResult());
        assertFalse(response.getPayload().getOrchestratorResponse().getQueryResult().getActive());

        // Now perform a QUERY request for an active workflow.
        request = getRequestMsg(getBasicHeader(), getQueryWorkflowRequestMsg(WORKFLOW_ID_1));
        orchestrator.handle(request, mockChannelHandlerContext, mockServerRouter);

        verify(mockServerRouter, times(2))
                .sendResponse(responseCaptor.capture(), eq(mockChannelHandlerContext));
        response = responseCaptor.getValue();

        // Assert that the payload has an ORCHESTRATOR_RESPONSE, that the base
        // header fields have remained the same, and that the queried workflow
        // was active.
        assertTrue(compareBaseHeaderFields(request.getHeader(), response.getHeader()));
        assertTrue(response.getPayload().hasOrchestratorResponse());
        assertTrue(response.getPayload().getOrchestratorResponse().hasQueryResult());
        assertTrue(response.getPayload().getOrchestratorResponse().getQueryResult().getActive());
    }
",non-flaky,5
134027,CorfuDB_CorfuDB,OrchestratorTest.testAddNodeRequestWithExisting,"    @Test
    public void testAddNodeRequestWithExisting() {
        sendAndValidateWorkflowDispatch(getAddNodeRequestMsg(ENDPOINT_1), WORKFLOW_ID_1);

        // Verify that no new workflow is run.
        verify(orchestrator, never()).run(any(IWorkflow.class), anyInt());
    }
",non-flaky,5
134028,CorfuDB_CorfuDB,OrchestratorTest.testAddNodeRequestWithoutExisting,"    @Test
    public void testAddNodeRequestWithoutExisting() {
        // We expect a new workflow to be created and prepare the required mocked behaviour.
        ArgumentCaptor<AddNodeRequest> requestArgumentCaptor = ArgumentCaptor.forClass(AddNodeRequest.class);
        AddNodeWorkflow mockWorkflow = mock(AddNodeWorkflow.class);
        doReturn(WORKFLOW_ID_2).when(mockWorkflow).getId();
        doReturn(mockWorkflow).when(workflowFactory).getAddNode(any(AddNodeRequest.class));

        sendAndValidateWorkflowDispatch(getAddNodeRequestMsg(ENDPOINT_2), WORKFLOW_ID_2);

        // Verify that a single AddNodeWorkflow was built for the given endpoint, and
        // that the corresponding workflowId was added to the activeWorkflows map.
        verify(workflowFactory).getAddNode(requestArgumentCaptor.capture());
        assertEquals(ENDPOINT_2, requestArgumentCaptor.getValue().getEndpoint());
        assertTrue(orchestrator.activeWorkflows.containsKey(WORKFLOW_ID_2));

        // Verify that run() was invoked with the newly created workflow.
        verify(orchestrator).run(eq(mockWorkflow), anyInt());
    }
",non-flaky,5
134029,CorfuDB_CorfuDB,OrchestratorTest.testRemoveNodeRequestWithExisting,"    @Test
    public void testRemoveNodeRequestWithExisting() {
        sendAndValidateWorkflowDispatch(getRemoveNodeRequestMsg(ENDPOINT_1), WORKFLOW_ID_1);

        // Verify that no new workflow is run.
        verify(orchestrator, never()).run(any(IWorkflow.class), anyInt());
    }
",non-flaky,5
156045,jReddit_jReddit,SubredditTest.testAllSubredditFields,"    @Test
    public void testAllSubredditFields() {
        
        // Field values
        String submit_text_html = null;
        Boolean user_is_banned = null;
        String id = ""SubredditID"";
        String kind = Kind.SUBREDDIT.value();
        String submit_text = ""submit text for subreddit"";
        String display_name = ""subredditDisplayName"";
        String header_img = ""http://a.thumbs.redditmedia.com/yyL5sveWcgkCPKbr.png"";
        String description_html = ""&lt;div&gt;HTML description for subreddit&lt;/d&gt;"";
        String title = ""SubredditTitle"";
        Boolean over18 = false;
        Boolean user_is_moderator = null;
        String header_title = ""Header title for subreddit"";
        String description = ""Description for subreddit"";
        String submit_link_label = ""Submit link label"";
        String accounts_active = null;
        Boolean public_traffic = true;
        JSONArray header_size = JsonHelpers.jsonArrayOf(160, 64);
        long subscribers = 289252;
        String submit_text_label = ""Submit text label"";
        String name = kind + ""_"" + id;
        double created = 1201242956.0;
        String url = ""/r/"" + display_name;
        double created_utc = 1201242956.0;
        Boolean user_is_contributor = null;
        String public_description = ""Public description of subreddit"";
        long comment_score_hide_mins = 0;
        String subreddit_type = ""public"";
        String submission_type = ""any"";
        Boolean user_is_subscriber = null;
        
        // Create JSON Object
        JSONObject data = new JSONObject();
        data.put(""submit_text_html"", submit_text_html);
        data.put(""user_is_banned"", user_is_banned);
        data.put(""id"", id);
        data.put(""submit_text"", submit_text);
        data.put(""display_name"", display_name);
        data.put(""header_img"", header_img);
        data.put(""description_html"", description_html);
        data.put(""title"", title);
        data.put(""over18"", over18);
        data.put(""user_is_moderator"", user_is_moderator);
        data.put(""header_title"", header_title);
        data.put(""description"", description);
        data.put(""submit_link_label"", submit_link_label);
        data.put(""accounts_active"", accounts_active);
        data.put(""public_traffic"", public_traffic);
        data.put(""header_size"", header_size);
        data.put(""subscribers"", subscribers);
        data.put(""submit_text_label"", submit_text_label);
        data.put(""name"", name);
        data.put(""created"", created);
        data.put(""url"", url);
        data.put(""created_utc"", created_utc);
        data.put(""user_is_contributor"", user_is_contributor);
        data.put(""public_description"", public_description);
        data.put(""comment_score_hide_mins"", comment_score_hide_mins);
        data.put(""subreddit_type"", subreddit_type);
        data.put(""submission_type"", submission_type);
        data.put(""user_is_subscriber"", user_is_subscriber);
        
        // Parse
        Subreddit s = new Subreddit(data);
        
        // Test data fields
        assertEquals(s.getDisplayName(), display_name);
        assertEquals(s.getTitle(), title);
        assertEquals(s.getURL(), url);
        assertEquals(s.getCreated(), created, 0);
        assertEquals(s.getCreatedUTC(), created_utc, 0);
        assertEquals(s.isNSFW(), over18);
        assertEquals(s.getSubscribers(), subscribers);
        assertEquals(s.getDescription(), description);
        assertEquals(s.getSubredditType(), subreddit_type);
        
        // Possible tests to activate:
//        assertEquals(s.getSubmitTextHTML(), submit_text_html);
//        assertEquals(s.isUserBanned(), user_is_banned);
//        assertEquals(s.getSubmitText(), submit_text);
//        assertEquals(s.getHeaderIMG(), header_img);
//        assertEquals(s.getDescriptionHTML(), description_html);
//        assertEquals(s.isUserModerator(), user_is_moderator);
//        assertEquals(s.getHeaderTitle(), header_title);
//        assertEquals(s.getSubmitLinkLabel(), submit_link_label);
//        assertEquals(s.getAccountsActive(), accounts_active);
//        assertEquals(s.getPublicTraffic(), public_traffic);
//        assertEquals(s.getHeaderSize(), header_size);
//        assertEquals(s.getSubmitTextLabel(), submit_text_label);
//        assertEquals(s.isUserContributor(), user_is_contributor);
//        assertEquals(s.getPublicDescription(), public_description);
//        assertEquals(s.getCommentScoreHideMins(), comment_score_hide_mins, 0);
//        assertEquals(s.getSubmissionType(), submission_type);
//        assertEquals(s.isUserSubscriber(), user_is_subscriber);
        
    }
",non-flaky,5
156046,jReddit_jReddit,MoreTest.testConstructor,"    @Test
    public void testConstructor() {
        
        // Variables
        long count = 2894;
        String parent_id = ""djk9fa"";
        String child_id_1 = ""ddafe2"";
        String child_id_2 = ""ddaf22"";
        
        // Create JSON Object
        JSONObject data = new JSONObject();
        data.put(""count"", count);
        data.put(""parent_id"", parent_id);
        JSONArray array = new JSONArray();
        array.add(child_id_1);
        array.add(child_id_2);
        data.put(""children"", array);
        
        // Parse
        More m = new More(data);
        
        Assert.assertEquals((Long) count, m.getCount());
        Assert.assertEquals(parent_id, m.getParentId());
        Assert.assertEquals(2, m.getChildrenSize());
        Assert.assertEquals(child_id_1, m.getChildren().get(0));
        Assert.assertEquals(child_id_2, m.getChildren().get(1));
        
        // Test that the toString does not throw an exception an is not null
       Assert.assertNotNull(m.toString());
        
    }
",non-flaky,5
156047,jReddit_jReddit,CommentTest.testAllCommentFields,"    @Test
    public void testAllCommentFields() {
        
        // Field values
        String subreddit_id = ""SubrID"";
        String banned_by = null;
        String subreddit = ""SubredditName"";
        String likes = null;
        String replies = """";
        boolean saved = false;
        String id = ""CommID"";
        String kind = ""t1"";
        long gilded = 0;
        String author = ""author"";
        String parent_id = ""ParID"";
        long score = 2;
        String approved_by = null;
        long controversiality = 0;
        String body = ""comment body"";
        boolean edited = false;
        String author_flair_css_class = null;
        long downs = 0;
        String body_html = ""&lt;div&gt;"" + body + ""&lt;/div&gt;"";
        String link_id = ""LinkIdentifier"";
        boolean score_hidden = false;
        String name = kind + ""_"" + id;
        double created = 1404969798.0;
        String author_flair_text = null;
        double created_utc = 1404940998.0;
        long ups = 2;
        String num_reports = null;
        String distinguished = null;
        
        // Create JSON Object
        JSONObject data = new JSONObject();
        data.put(""subreddit_id"", subreddit_id);
        data.put(""banned_by"", banned_by);
        data.put(""subreddit"", subreddit);
        data.put(""likes"", likes);
        data.put(""replies"", replies);
        data.put(""saved"", saved);
        data.put(""id"", id);
        data.put(""gilded"", gilded);
        data.put(""author"", author);
        data.put(""parent_id"", parent_id);
        data.put(""score"", score);
        data.put(""approved_by"", approved_by);
        data.put(""controversiality"", controversiality);
        data.put(""body"", body);
        data.put(""edited"", edited);
        data.put(""author_flair_css_class"", author_flair_css_class);
        data.put(""downs"", downs);
        data.put(""body_html"", body_html);
        data.put(""link_id"", link_id);
        data.put(""score_hidden"", score_hidden);
        data.put(""name"", name);
        data.put(""created"", created);
        data.put(""author_flair_text"", author_flair_text);
        data.put(""created_utc"", created_utc);
        data.put(""ups"", ups);
        data.put(""num_reports"", num_reports);
        data.put(""distinguished"", distinguished);
        
        // Parse
        Comment c = new Comment(data);
        
        // Test data fields
        assertEquals(c.getFullName(), name);
        assertEquals(c.getAuthor(), author);
        assertEquals(c.getBody(), body);
        assertEquals(c.getCreated(), created, 0);
        assertEquals(c.getCreatedUTC(), created_utc, 0);
        assertEquals(c.getDownvotes(), downs, 0);
        assertEquals(c.getEdited(), edited);
        assertEquals(c.getGilded(), gilded, 0);
        assertEquals(c.getIdentifier(), id);
       // assertEquals(c.getKind(), kind);
        assertEquals(c.getParentId(), parent_id);
        assertEquals(c.getScore(), score, 0);
        assertEquals(c.getUpvotes(), ups, 0);
        assertEquals(c.getSubreddit(), subreddit);
        assertEquals(c.getSubredditId(), subreddit_id);
        assertEquals(c.getLinkId(), link_id);
        assertEquals(c.getBodyHTML(), body_html);
        assertEquals(c.isScoreHidden(), score_hidden);
        
        // Possible tests to activate:
//        assertEquals(c.getBannedBy(), banned_by);
//        assertEquals(c.getLikes(), likes);
//        assertEquals(c.getApprovedBy(), approved_by);
//        assertEquals(c.getAuthorFlairCSSClass(), author_flair_css_class);
//        assertEquals(c.getAuthorFlairText(), author_flair_text);
//        assertEquals(c.getNumReports(), num_reports);
//        assertEquals(c.getDistinguised(), distinguished);
        
    }
",non-flaky,5
156048,jReddit_jReddit,KindTest.testMatchSuccess,"    @Test
    public void testMatchSuccess() {
        Assert.assertEquals(Kind.COMMENT, Kind.match(Kind.COMMENT.value()));
    }
",non-flaky,5
156049,jReddit_jReddit,KindTest.testMatchFailure,"    @Test
    public void testMatchFailure() {
        // Match a string that most likely will never become a Kind's value
        Assert.assertNull(Kind.match(""djkaskjsf7s98f989389589a9f8a998935""));
    }
",non-flaky,5
156050,jReddit_jReddit,SubmissionTest.testAllSubmissionFields,"    @Test
    public void testAllSubmissionFields() {
        
        // Field values
        String kind = Kind.LINK.value();
        String domain = ""imgur.com"";
        String banned_by = null;
        JSONObject media_embed = JsonHelpers.createMediaEmbedObject();
        String subreddit = ""subredditName"";
        String selftext_html = ""Self text HTML"";
        String selftext = ""Self text"";
        String likes = null;
        Boolean secure_media = null;
        String link_flair_text = null;
        String id = ""SubmID"";
        Long gilded = (long) 0;
        JSONObject secure_media_embed = new JSONObject();
        Boolean clicked = false;
        Boolean stickied = false;
        String author = ""authorName"";
        JSONObject media = JsonHelpers.createMediaObject();
        Long score = (long) 613;
        String approved_by = null;
        Boolean over_18 = true;
        Boolean hidden = false;
        String thumbnail = ""nsfw"";
        String subreddit_id = Kind.SUBREDDIT.value() + ""_"" + ""SubrID"";
        Boolean edited = false;
        String link_flair_css_class = null;
        String author_flair_css_class = null;
        Long downs = (long) 0;
        Boolean saved = false;
        Boolean is_self = false;
        String title = ""submTitle"";
        String permalink = ""/r/"" + subreddit + ""/comments"" + id + ""/"" + title + ""/"";
        String name = kind + ""_"" + id;
        Double created = 1405093719.0;
        String url = ""http://imgur.com/a/dxHTq"";
        String author_flair_text = null;
        Double created_utc = 1405064919.0;
        Long ups = (long) 613;
        Long num_comments = (long) 112;
        Boolean visited = false;
        Long num_reports = null;
        String distinguished = null;
        String from = ""t3_djjksjk"";
        String from_id = ""djjksjk"";
        String from_kind = ""t3"";
        String removal_reason = ""Just because"";
        Double upvote_ratio = 0.89;
             
        // Create JSON Object
        JSONObject data = new JSONObject();
        data.put(""kind"", kind);
        data.put(""domain"", domain);
        data.put(""banned_by"", banned_by);
        data.put(""media_embed"", media_embed);
        data.put(""subreddit"", subreddit);
        data.put(""selftext_html"", selftext_html);
        data.put(""selftext"", selftext);
        data.put(""likes"", likes);
        data.put(""secure_media"", secure_media);
        data.put(""link_flair_text"", link_flair_text);
        data.put(""id"", id);
        data.put(""gilded"", gilded);
        data.put(""secure_media_embed"", secure_media_embed);
        data.put(""clicked"", clicked);
        data.put(""stickied"", stickied);
        data.put(""author"", author);
        data.put(""media"", media);
        data.put(""score"", score);
        data.put(""approved_by"", approved_by);
        data.put(""over_18"", over_18);
        data.put(""hidden"", hidden);
        data.put(""thumbnail"", thumbnail);
        data.put(""subreddit_id"", subreddit_id);
        data.put(""edited"", edited);
        data.put(""link_flair_css_class"", link_flair_css_class);
        data.put(""author_flair_css_class"", author_flair_css_class);
        data.put(""downs"", downs);
        data.put(""saved"", saved);
        data.put(""is_self"", is_self);
        data.put(""title"", title);
        data.put(""permalink"", permalink);
        data.put(""name"", name);
        data.put(""created"", created);
        data.put(""url"", url);
        data.put(""author_flair_text"", author_flair_text);
        data.put(""created_utc"", created_utc);
        data.put(""ups"", ups);
        data.put(""num_comments"", num_comments);
        data.put(""visited"", visited);
        data.put(""num_reports"", num_reports);
        data.put(""distinguished"", distinguished);
        data.put(""from"", from);
        data.put(""from_id"", from_id);
        data.put(""from_kind"", from_kind);
        data.put(""removal_reason"", removal_reason);
        data.put(""upvote_ratio"", upvote_ratio);
        
        // Parse
        Submission s = new Submission(data);
        
        // Test data fields
        assertEquals(s.getKind(), Kind.match(kind));
        assertEquals(s.getDomain(), domain);
        assertEquals(s.getBannedBy(), banned_by);
        //assertEquals(s.getMediaEmbed(), media_embed);
        assertEquals(s.getSubreddit(), subreddit);
        assertEquals(s.getSelftextHTML(), selftext_html);
        assertEquals(s.getSelftext(), selftext);
        assertEquals(s.getLikes(), likes);
        //assertEquals(s.getSecureMedia(), secure_media);
        assertEquals(s.getLinkFlairText(), link_flair_text);
        assertEquals(s.getIdentifier(), id);
        assertEquals(s.getGilded(), gilded);
        //assertEquals(s.getSecureMediaEmbed(), secure_media_embed);
        assertEquals(s.isClicked(), clicked);
        assertEquals(s.isStickied(), stickied);
        assertEquals(s.getAuthor(), author);
        //assertEquals(s.getMedia(), media);
        assertEquals(s.getScore(), score);
        assertEquals(s.getApprovedBy(), approved_by);
        assertEquals(s.isNSFW(), over_18);
        assertEquals(s.isHidden(), hidden);
        assertEquals(s.getThumbnail(), thumbnail);
        assertEquals(s.getSubredditId(), subreddit_id);
        assertEquals(s.isEdited(), edited);
        assertEquals(s.getLinkFlairCSSClass(), link_flair_css_class);
        assertEquals(s.getAuthorFlairCSSClass(), author_flair_css_class);
        assertEquals(s.getDownVotes(), downs);
        assertEquals(s.isSaved(), saved);
        assertEquals(s.isSelf(), is_self);
        assertEquals(s.getTitle(), title);
        assertEquals(s.getPermalink(), permalink);
        assertEquals(s.getFullName(), name);
        assertEquals(s.getCreated(), created, 0);
        assertEquals(s.getURL(), url);
        assertEquals(s.getAuthorFlairText(), author_flair_text);
        assertEquals(s.getCreatedUTC(), created_utc, 0);
        assertEquals(s.getUpVotes(), ups);
        assertEquals(s.getCommentCount(), num_comments);
        assertEquals(s.isVisited(), visited);
        assertEquals(s.getReportCount(), num_reports);
        assertEquals(s.getDistinguished(), distinguished);
        assertEquals(s.getFrom(), from);
        assertEquals(s.getFromId(), from_id);
        assertEquals(s.getFromKind(), from_kind);
        assertEquals(s.getRemovalReason(), removal_reason);
        assertEquals(s.getUpvoteRatio(), upvote_ratio);
        
    }
",non-flaky,5
156051,jReddit_jReddit,JsonUtilsTest.testSafeJsonToString,"    @Test
    public void testSafeJsonToString() {
        Assert.assertNull(JsonUtils.safeJsonToString(null));
        Assert.assertEquals(""123"", JsonUtils.safeJsonToString(123));
        Assert.assertEquals(""abcd"", JsonUtils.safeJsonToString(""abcd""));
        Assert.assertEquals("""", JsonUtils.safeJsonToString(""""));
    }
",non-flaky,5
156052,jReddit_jReddit,JsonUtilsTest.testSafeJsonToDouble,"    @Test
    public void testSafeJsonToDouble() {
        Assert.assertNull(JsonUtils.safeJsonToDouble(null));
        Assert.assertNull(JsonUtils.safeJsonToDouble(""abcd""));
        Assert.assertNull(JsonUtils.safeJsonToDouble(""""));
        Assert.assertEquals((Double) (double) 35141, JsonUtils.safeJsonToDouble(""35141""), 0);
        Assert.assertEquals((Double) (double) 0, JsonUtils.safeJsonToDouble(""0""), 0);
    }
",non-flaky,5
156053,jReddit_jReddit,JsonUtilsTest.testSafeJsonToInteger,"    @Test
    public void testSafeJsonToInteger() {
        Assert.assertNull(JsonUtils.safeJsonToInteger(null));
        Assert.assertNull(JsonUtils.safeJsonToInteger(""abcd""));
        Assert.assertNull(JsonUtils.safeJsonToInteger(""""));
        Assert.assertEquals((Integer) 355, (Integer) JsonUtils.safeJsonToInteger(""355""));
        Assert.assertNull(JsonUtils.safeJsonToInteger(""25275738927589278572891""));
        Assert.assertNull(JsonUtils.safeJsonToInteger(""-25275738927589278572891""));
        Assert.assertEquals((Integer) 0, JsonUtils.safeJsonToInteger(""0""));
    }
",non-flaky,5
156054,jReddit_jReddit,JsonUtilsTest.testSafeJsonToBoolean,"    @Test
    public void testSafeJsonToBoolean() {
        Assert.assertNull(JsonUtils.safeJsonToBoolean(null));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""abcd""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""3522""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""25275738927589278572891""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""-25275738927589278572891""));
        Assert.assertTrue(JsonUtils.safeJsonToBoolean(""true""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""false""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""0""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""1""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""yes""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""no""));
    }
",non-flaky,5
156055,jReddit_jReddit,JsonUtilsTest.testSafeJsonToLong,"    @Test
    public void testSafeJsonToLong() {
        Assert.assertNull(JsonUtils.safeJsonToLong(null));
        Assert.assertNull(JsonUtils.safeJsonToLong(""abcd""));
        Assert.assertNull(JsonUtils.safeJsonToLong(""""));
        Assert.assertEquals((Long) (long) 355, (Long) JsonUtils.safeJsonToLong(""355""));
        Assert.assertNull(JsonUtils.safeJsonToLong(""25275738927589278572891""));
        Assert.assertNull(JsonUtils.safeJsonToLong(""-25275738927589278572891""));
        Assert.assertEquals((Long) Long.MAX_VALUE, (Long) JsonUtils.safeJsonToLong("""" + Long.MAX_VALUE));
        Assert.assertEquals((Long) Long.MIN_VALUE, (Long) JsonUtils.safeJsonToLong("""" + Long.MIN_VALUE));
        Assert.assertEquals((Long) (long) 0, JsonUtils.safeJsonToLong(""0""));
    }
",non-flaky,5
156056,jReddit_jReddit,RedditTokenTest.testGetters,"    @Test
    public void testGetters() {
        
        RedditToken subject = new RedditToken(jsonToken);
        RedditToken subjectUserProvided = new RedditToken(accessToken, tokenType, expiresIn, scope);
        assertEquals(accessToken, subject.getAccessToken());
        assertEquals(refreshToken, subject.getRefreshToken());
        assertEquals(tokenType, subject.getTokenType());
        assertEquals(expiresIn, subject.getExpirationSpan());
        assertTrue(subject.hasScope(RedditScope.EDIT));
        assertTrue(subject.hasScope(RedditScope.FLAIR));
        assertFalse(subject.hasScope(RedditScope.PRIVATEMESSAGE));
        assertTrue(subject.isRefreshable());
        assertFalse(subjectUserProvided.isRefreshable());
        
    }
",non-flaky,5
156057,jReddit_jReddit,RedditTokenTest.testRefresh,"    @Test
    public void testRefresh() {
        
        RedditToken subject = new RedditToken(jsonToken);
        assertEquals(accessToken, subject.getAccessToken());
        assertEquals(refreshToken, subject.getRefreshToken());
        assertEquals(tokenType, subject.getTokenType());
        assertEquals(expiresIn, subject.getExpirationSpan());
        assertTrue(subject.hasScope(RedditScope.EDIT));
        assertTrue(subject.hasScope(RedditScope.FLAIR));
        
        subject.refresh(refreshJsonToken);
        
        assertEquals(accessToken2, subject.getAccessToken());
        assertEquals(refreshToken, subject.getRefreshToken());
        assertEquals(tokenType2, subject.getTokenType());
        assertEquals(expiresIn2, subject.getExpirationSpan());
        assertTrue(subject.hasScope(RedditScope.EDIT));
        assertFalse(subject.hasScope(RedditScope.FLAIR));
        
    }
",non-flaky,5
156058,jReddit_jReddit,RedditTokenTest.testTimeSensitiveExpiration,"    @Test
    public void testTimeSensitiveExpiration() {
        
        RedditToken subject = new RedditToken(jsonToken);
        RedditToken subjectUserProvided = new RedditToken(accessToken, tokenType, expiresIn2, scope);
        
        assertFalse(subjectUserProvided.willExpireIn(expiresIn2 - 60));
        assertTrue(subjectUserProvided.willExpireIn(expiresIn2 + 60));
        assertFalse(subjectUserProvided.isExpired());
        
        try {
            Thread.sleep(2000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        
        assertTrue(subject.isExpired());
        assertTrue(subject.getExpiration() < (System.currentTimeMillis() / 1000));
        
    }
",non-flaky,5
156059,jReddit_jReddit,RedditOAuthAgentTest.testDefaultConstructor,"    @Test
    public void testDefaultConstructor() {
        RedditApp app = new RedditWebApp(clientID, clientSecret, redirectURI);
        new RedditOAuthAgent(userAgent, app);
        app = new RedditScriptApp(clientID, clientSecret, redirectURI);
        new RedditOAuthAgent(userAgent, app);
        app = new RedditInstalledApp(clientID, redirectURI);
        new RedditOAuthAgent(userAgent, app);
    }
",non-flaky,5
156060,jReddit_jReddit,RedditOAuthAgentTest.testGenerateCodeFlowURI,"    @Test
    public void testGenerateCodeFlowURI() {
        RedditScopeBuilder builder = new RedditScopeBuilder();
        builder.addScope(RedditScope.EDIT);
        String url = subject.generateCodeFlowURI(builder, RedditDuration.PERMANENT);
        UrlValidator urlValidator = new UrlValidator();
        assertTrue(urlValidator.isValid(url));
    }
",non-flaky,5
156061,jReddit_jReddit,RedditOAuthAgentTest.testGenerateImplicitFlowURI,"    @Test
    public void testGenerateImplicitFlowURI() {
        RedditScopeBuilder builder = new RedditScopeBuilder();
        builder.addScope(RedditScope.FLAIR);
        String url = subject.generateImplicitFlowURI(builder);
        UrlValidator urlValidator = new UrlValidator();
        assertTrue(urlValidator.isValid(url));
    }
",non-flaky,5
156062,jReddit_jReddit,RedditOAuthAgentTest.testTokenFromInfo,"    @Test
    public void testTokenFromInfo() {
        RedditToken token = subject.tokenFromInfo(accessToken, tokenType, expiresIn, scope);
        assertEquals(accessToken, token.getAccessToken());
        assertEquals(tokenType, token.getTokenType());
        assertEquals(expiresIn, token.getExpirationSpan());
        assertTrue(token.hasScope(RedditScope.EDIT));
        assertTrue(token.hasScope(RedditScope.FLAIR));
        assertFalse(token.hasScope(RedditScope.PRIVATEMESSAGE));
    }
",non-flaky,5
156063,jReddit_jReddit,RedditOAuthAgentTest.testToken,"    @Test
    public void testToken() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        
        // Captor for the request that is executed
        ArgumentCaptor<OAuthClientRequest> clientCaptor = ArgumentCaptor.forClass(OAuthClientRequest.class);
        
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenReturn(jsonToken);
        
        // Run subject
        RedditToken token = subject.token(code);
        
        // Verify and capture
        verify(mockOAuthClient).accessToken(clientCaptor.capture());
        
        OAuthClientRequest request = clientCaptor.getValue();
        
        assertNotNull(request.getHeader(""Authorization"")); // This is Base64 encoded
        assertEquals(request.getHeader(""User-Agent""), userAgent);
        
        assertEquals(accessToken, token.getAccessToken());
        assertEquals(refreshToken, token.getRefreshToken());
        assertEquals(tokenType, token.getTokenType());
        assertEquals(expiresIn, token.getExpirationSpan());
        assertTrue(token.hasScope(RedditScope.EDIT));
        assertTrue(token.hasScope(RedditScope.FLAIR));
        assertFalse(token.hasScope(RedditScope.PRIVATEMESSAGE));

    }
",non-flaky,5
156064,jReddit_jReddit,RedditOAuthAgentTest.testTokenOAuthSystemException,"    @Test(expected=RedditOAuthException.class)
    public void testTokenOAuthSystemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(new OAuthSystemException());
        subject.token(code);
    }
",non-flaky,5
156065,jReddit_jReddit,RedditOAuthAgentTest.testTokenOAuthProblemException,"    @Test(expected=RedditOAuthException.class)
    public void testTokenOAuthProblemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(OAuthProblemException.error(""Error""));
        subject.token(code);
    }
",non-flaky,5
156066,jReddit_jReddit,RedditOAuthAgentTest.testRefreshTokenFailure,"    @Test
    public void testRefreshTokenFailure() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        assertFalse(subject.refreshToken(mockRedditToken));
    }
",non-flaky,5
156067,jReddit_jReddit,RedditOAuthAgentTest.testRefreshTokenSuccess,"    @Test
    public void testRefreshTokenSuccess() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        assertTrue(subject.refreshToken(mockRedditTokenRefreshable));
        verify(mockOAuthClient).accessToken(any(OAuthClientRequest.class));
        verify(mockRedditTokenRefreshable).refresh(null);
    }
",non-flaky,5
156068,jReddit_jReddit,RedditOAuthAgentTest.testRefreshTokenOAuthSystemException,"    @Test(expected=RedditOAuthException.class)
    public void testRefreshTokenOAuthSystemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(new OAuthSystemException());
        subject.refreshToken(mockRedditTokenRefreshable);
    }
",non-flaky,5
156069,jReddit_jReddit,RedditOAuthAgentTest.testRefreshTokenOAuthProblemException,"    @Test(expected=RedditOAuthException.class)
    public void testRefreshTokenOAuthProblemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(OAuthProblemException.error(""Error""));
        subject.refreshToken(mockRedditTokenRefreshable);
    }
",non-flaky,5
156070,jReddit_jReddit,RedditOAuthAgentTest.testTokenAppOnlyConfidential,"    @Test
    public void testTokenAppOnlyConfidential() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        
        // Captor for the request that is executed
        ArgumentCaptor<OAuthClientRequest> clientCaptor = ArgumentCaptor.forClass(OAuthClientRequest.class);
        
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenReturn(jsonTokenNonRefreshable);
        
        // Run subject
        RedditToken token = subject.tokenAppOnly(true);
        
        // Verify and capture
        verify(mockOAuthClient).accessToken(clientCaptor.capture());
        
        OAuthClientRequest request = clientCaptor.getValue();
        
        assertNotNull(request.getHeader(""Authorization"")); // This is Base64 encoded
        assertEquals(request.getHeader(""User-Agent""), userAgent);
        
        assertEquals(accessToken, token.getAccessToken());
        assertNull(token.getRefreshToken());
        assertEquals(tokenType, token.getTokenType());
        assertEquals(expiresIn, token.getExpirationSpan());
        assertTrue(token.hasScope(RedditScope.EDIT));
        assertTrue(token.hasScope(RedditScope.FLAIR));
        assertFalse(token.hasScope(RedditScope.PRIVATEMESSAGE));

    }
",non-flaky,5
156071,jReddit_jReddit,RedditOAuthAgentTest.testTokenAppOnly,"    @Test
    public void testTokenAppOnly() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        
        // Captor for the request that is executed
        ArgumentCaptor<OAuthClientRequest> clientCaptor = ArgumentCaptor.forClass(OAuthClientRequest.class);
        
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenReturn(jsonTokenNonRefreshable);
        
        // Run subject
        RedditToken token = subject.tokenAppOnly(false);
        
        // Verify and capture
        verify(mockOAuthClient).accessToken(clientCaptor.capture());
        
        OAuthClientRequest request = clientCaptor.getValue();
        
        assertNotNull(request.getHeader(""Authorization"")); // This is Base64 encoded
        assertEquals(request.getHeader(""User-Agent""), userAgent);
        
        assertEquals(accessToken, token.getAccessToken());
        assertNull(token.getRefreshToken());
        assertEquals(tokenType, token.getTokenType());
        assertEquals(expiresIn, token.getExpirationSpan());
        assertTrue(token.hasScope(RedditScope.EDIT));
        assertTrue(token.hasScope(RedditScope.FLAIR));
        assertFalse(token.hasScope(RedditScope.PRIVATEMESSAGE));

    }
",non-flaky,5
156072,jReddit_jReddit,RedditOAuthAgentTest.testTokenAppOnlyOAuthSystemException,"    @Test(expected=RedditOAuthException.class)
    public void testTokenAppOnlyOAuthSystemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(new OAuthSystemException());
        subject.tokenAppOnly(false);
    }
",non-flaky,5
156073,jReddit_jReddit,RedditOAuthAgentTest.testTokenAppOnlyOAuthProblemException,"    @Test(expected=RedditOAuthException.class)
    public void testTokenAppOnlyOAuthProblemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(OAuthProblemException.error(""Error""));
        subject.tokenAppOnly(false);
    }
",non-flaky,5
156074,jReddit_jReddit,RedditOAuthAgentTest.testRevoke,"    @Test
    public void testRevoke() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        assertTrue(subject.revoke(null, false));
    }
",non-flaky,5
156075,jReddit_jReddit,RedditScopeBuilderTest.testEmpty,"    @Test
    public void testEmpty() {
        assertEquals("""", builder.build());
    }
",non-flaky,5
156076,jReddit_jReddit,RedditScopeBuilderTest.testAddRemove,"    @Test
    public void testAddRemove() {
        builder.addScope(RedditScope.EDIT);
        builder.removeScope(RedditScope.EDIT);
        assertEquals("""", builder.build());
    }
",non-flaky,5
156077,jReddit_jReddit,RedditScopeBuilderTest.testAddRemoveMultiple,"    @Test
    public void testAddRemoveMultiple() {
        builder.addScopes(RedditScope.EDIT, RedditScope.MODPOSTS);
        builder.removeScopes(RedditScope.EDIT, RedditScope.MODPOSTS, RedditScope.MODCONFIG);
        assertEquals("""", builder.build());
    }
",non-flaky,5
156078,jReddit_jReddit,RedditScopeBuilderTest.testAdd,"    @Test
    public void testAdd() {
        builder.addScope(RedditScope.EDIT);
        assertEquals(RedditScope.EDIT.value(), builder.build());
        builder.removeScope(RedditScope.EDIT);
    }
",non-flaky,5
156079,jReddit_jReddit,RedditScopeBuilderTest.testAddDouble,"    @Test
    public void testAddDouble() {
        builder.addScopes(RedditScope.EDIT, RedditScope.EDIT);
        builder.addScope(RedditScope.EDIT);
        assertEquals(RedditScope.EDIT.value(), builder.build());
        builder.removeScope(RedditScope.EDIT);
        assertEquals("""", builder.build());
    }
",non-flaky,5
156080,jReddit_jReddit,RedditScopeBuilderTest.testAddMultiple,"    @Test
    public void testAddMultiple() {
        builder.addScopes(RedditScope.EDIT, RedditScope.FLAIR);
        assertTrue(
                (RedditScope.EDIT.value() + RedditScope.SEPARATOR + RedditScope.FLAIR.value()).equals(builder.build()) 
                ||
                (RedditScope.FLAIR.value() + RedditScope.SEPARATOR + RedditScope.EDIT.value()).equals(builder.build()) 
                );
        builder.removeScopes(RedditScope.EDIT, RedditScope.FLAIR);
    }
",non-flaky,5
159612,liquibase_liquibase,MavenIntegrationTest.nothing,"    @Test
    public void nothing() {
        //tests fail when not running a maven based build. need to figure out how to determine that
    }
",non-flaky,5
159613,liquibase_liquibase,MavenIntegrationTest.testUpdate,"//    @Test
//    public void testUpdate() throws Exception{
//        Verifier verifier=createVerifier();
//
//        verifier.executeGoal( ""clean"" );
//        verifier.executeGoal( ""install"" );
//
//        //Verify everithing has gone well.
//        verifier.verifyErrorFreeLog();
//
//        //Reset the streams before executing the verifier
//        verifier.resetStreams();
//    }
",non-flaky,5
159614,liquibase_liquibase,MavenIntegrationTest.testRollbackTag,"//    @Test
//    public void testRollbackTag() throws Exception {
//        Verifier verifier= createVerifier();
//
//
//        verifier.executeGoal(""clean"");
//        verifier.executeGoal(""liquibase:tag"");
//        verifier.executeGoal(""package""); //runs update that is bound to test phase
//        verifier.executeGoal(""liquibase:rollback"");
//        //If we can reupdate rollback has succeded
//        verifier.executeGoal(""liquibase:update"");
//
//        //Verify everithing has gone well.
//        verifier.verifyErrorFreeLog();
//
//        //Reset the streams before executing the verifier
//        verifier.resetStreams();
//    }
",non-flaky,5
159615,liquibase_liquibase,IntXMLChangeLogSAXParserTest.sampleChangeLogs,"    @Test
    public void sampleChangeLogs() throws Exception {
        new XMLChangeLogSAXParser().parse(""changelogs/cache/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/db2/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/derby/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/firebird/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/h2/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/hsqldb/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/maxdb/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/mysql/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/oracle/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/pgsql/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/sybase/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/asany/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
        new XMLChangeLogSAXParser().parse(""changelogs/unsupported/complete/root.changelog.xml"", new ChangeLogParameters(), new JUnitResourceAccessor());
    }
",non-flaky,5
159616,liquibase_liquibase,MySQLIntegrationTest.testRunChangeLog,"    @Test
    public void testRunChangeLog() throws Exception {
        super.testRunChangeLog();    //To change body of overridden methods use File | Settings | File Templates.
    }
",non-flaky,5
159617,liquibase_liquibase,MySQLIntegrationTest.snapshot,"    @Test
    public void snapshot() throws Exception {
        if (getDatabase() == null) {
            return;
        }


        runCompleteChangeLog();
        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(getDatabase().getDefaultSchema(), getDatabase(), new SnapshotControl(getDatabase()));
        System.out.println(snapshot);
    }
",non-flaky,5
159618,liquibase_liquibase,MySQLIntegrationTest.dateDefaultValue,"    @Test
    public void dateDefaultValue() throws Exception {
        if (getDatabase() == null) {
            return;
        }
        ExecutorService.getInstance().getExecutor(getDatabase()).execute(new RawSqlStatement(""DROP TABLE IF "" +
                                                                                                     ""EXISTS ad""));
        
        try {
            ExecutorService.getInstance().getExecutor(getDatabase()).execute(new RawSqlStatement(""CREATE TABLE ad (\n"" +
                                                                                                         ""ad_id int(10) unsigned NOT NULL AUTO_INCREMENT,\n"" +
                                                                                                         ""advertiser_id int(10) unsigned NOT NULL,\n"" +
                                                                                                         ""ad_type_id int(10) unsigned NOT NULL,\n"" +
                                                                                                         ""name varchar(155) NOT NULL DEFAULT '',\n"" +
                                                                                                         ""label varchar(155)NOT NULL DEFAULT '',\n"" +
                                                                                                         ""description text NOT NULL,\n"" +
                                                                                                         ""active tinyint(1) NOT NULL DEFAULT '0',\n"" +
                                                                                                         ""created datetime NOT NULL DEFAULT '0000-00-00 00:00:00',\n"" +
                                                                                                         ""updated datetime DEFAULT '0000-00-00 00:00:00',\n"" +
                                                                                                         ""PRIMARY KEY (ad_id),\n"" +
                                                                                                         ""KEY active (active)\n"" +
                                                                                                         "")""));
        } catch (DatabaseException e) {
            if (e.getCause() instanceof SQLSyntaxErrorException) {
                Scope.getCurrentScope().getLog(getClass()).warning(LogType.LOG, ""MySQL returned DatabaseException"", e);
                assumeTrue(""MySQL seems to run in strict mode (no datetime literals with 0000-00-00 allowed). "" + ""Cannot run this test"", false);
                
            } else {
                throw e;
            }
        }
        
        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(CatalogAndSchema.DEFAULT, getDatabase(), new SnapshotControl(getDatabase()));
        Column createdColumn = snapshot.get(new Column().setRelation(new Table().setName(""ad"").setSchema(new Schema())).setName(""created""));
        
        Object defaultValue = createdColumn.getDefaultValue();
        assertNotNull(defaultValue);
        assertEquals(""0000-00-00 00:00:00"", defaultValue);
    }
",non-flaky,5
159619,liquibase_liquibase,MariaDBIntegrationTest.testRunChangeLog,"    @Test
    public void testRunChangeLog() throws Exception {
        super.testRunChangeLog();    //To change body of overridden methods use File | Settings | File Templates.
    }
",non-flaky,5
159620,liquibase_liquibase,MariaDBIntegrationTest.snapshot,"    @Test
    public void snapshot() throws Exception {
        if (getDatabase() == null) {
            return;
        }


        runCompleteChangeLog();
        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(getDatabase().getDefaultSchema(), getDatabase(), new SnapshotControl(getDatabase()));
        System.out.println(snapshot);
    }
",non-flaky,5
159621,liquibase_liquibase,MariaDBIntegrationTest.dateDefaultValue,"    @Test
    public void dateDefaultValue() throws Exception {
        if (getDatabase() == null) {
            return;
        }
        ExecutorService.getInstance().getExecutor(getDatabase()).execute(new RawSqlStatement(""DROP TABLE IF "" +
             ""EXISTS ad""));
    
        try {
            ExecutorService.getInstance().getExecutor(getDatabase()).execute(new RawSqlStatement(""CREATE TABLE ad (\n"" +
                    ""ad_id int(10) unsigned NOT NULL AUTO_INCREMENT,\n"" +
                    ""advertiser_id int(10) unsigned NOT NULL,\n"" +
                    ""ad_type_id int(10) unsigned NOT NULL,\n"" +
                    ""name varchar(155) NOT NULL DEFAULT '',\n"" +
                    ""label varchar(155)NOT NULL DEFAULT '',\n"" +
                    ""description text NOT NULL,\n"" +
                    ""active tinyint(1) NOT NULL DEFAULT '0',\n"" +
                    ""created datetime NOT NULL DEFAULT '0000-00-00 00:00:00',\n"" +
                    ""updated datetime DEFAULT '0000-00-00 00:00:00',\n"" +
                    ""PRIMARY KEY (ad_id),\n"" +
                    ""KEY active (active)\n"" +
                    "")""));
        } catch (DatabaseException e) {
            if (e.getCause() instanceof SQLSyntaxErrorException) {
                Scope.getCurrentScope().getLog(getClass()).warning(LogType.LOG, ""MariaDB returned DatabaseException"", e);
                assumeTrue(""MariaDB seems to run in strict mode (no datetime literals with 0000-00-00 allowed). "" + ""Cannot run this test"", false);
                
            } else {
                throw e;
            }
        }
    
        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(CatalogAndSchema.DEFAULT, getDatabase(), new SnapshotControl(getDatabase()));
        Column createdColumn = snapshot.get(new Column().setRelation(new Table().setName(""ad"").setSchema(new Schema())).setName(""created""));

        Object defaultValue = createdColumn.getDefaultValue();
        assertNotNull(defaultValue);
        assertEquals(""0000-00-00 00:00:00"", defaultValue);
    }
",non-flaky,5
159622,liquibase_liquibase,H2IntegrationTest.diffToPrintStream,"    @Test
    public void diffToPrintStream() throws Exception{
        if (getDatabase() == null) {
            return;
        }

        runCompleteChangeLog();

        DiffResult diffResult = DiffGeneratorFactory.getInstance().compare(getDatabase(), null, new CompareControl());
        new DiffToReport(diffResult, System.out).print();
    }
",non-flaky,5
159623,liquibase_liquibase,H2IntegrationTest.diffToChangeLog,"    @Test
    public void diffToChangeLog() throws Exception{
        if (getDatabase() == null) {
            return;
        }

        runCompleteChangeLog();

        DiffResult diffResult = DiffGeneratorFactory.getInstance().compare(getDatabase(), null, new CompareControl());
        File outputFile = new File(""diffToChangeLog_"" + getDatabase().getShortName() + "".log"");
        if (outputFile.exists())
            outputFile.delete();
        PrintStream writer = new PrintStream(outputFile);

        new DiffToChangeLog(diffResult, new DiffOutputControl(true, true, true, null)).print(writer);
        writer.close();


    }
",non-flaky,5
159624,liquibase_liquibase,H2IntegrationTest.snapshot,"    @Test
    public void snapshot() throws Exception {
        if (getDatabase() == null) {
            return;
        }


        runCompleteChangeLog();
        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(getDatabase().getDefaultSchema(), getDatabase(), new SnapshotControl(getDatabase()));
        System.out.println(snapshot);
    }
",non-flaky,5
159625,liquibase_liquibase,H2IntegrationTest.canSpecifyDbmsForIndividualChanges,"    @Test
    public void canSpecifyDbmsForIndividualChanges() throws Exception {
        runChangeLogFile(changeSpecifyDbmsChangeLog);
    }
",non-flaky,5
159626,liquibase_liquibase,H2IntegrationTest.h2IsExcludedFromRunningChangeset,"    @Test
    public void h2IsExcludedFromRunningChangeset() throws Exception {
        runChangeLogFile(dbmsExcludeChangelog);
    }
",non-flaky,5
159627,liquibase_liquibase,H2IntegrationTest.runYamlChangelog,"    @Test
    public void runYamlChangelog() throws Exception {
        if (getDatabase() == null) {
            return;
        }

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        //run again to test changelog testing logic
        liquibase = createLiquibase(""changelogs/yaml/common.tests.changelog.yaml"");
        liquibase.setChangeLogParameter(""loginuser"", getUsername());

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }


    }
",non-flaky,5
159628,liquibase_liquibase,H2IntegrationTest.runJsonChangelog,"    @Test
    public void runJsonChangelog() throws Exception {
        if (getDatabase() == null) {
            return;
        }

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        //run again to test changelog testing logic
        liquibase = createLiquibase(""changelogs/json/common.tests.changelog.json"");
        liquibase.setChangeLogParameter(""loginuser"", getUsername());

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
    }
",non-flaky,5
159629,liquibase_liquibase,H2IntegrationTest.testGenerateChangeLogWithNoChanges,"    @Test
    public void testGenerateChangeLogWithNoChanges() throws Exception {
        super.testGenerateChangeLogWithNoChanges();    //To change body of overridden methods use File | Settings |
        // File Templates.
    }
",non-flaky,5
159630,liquibase_liquibase,SQLiteIntegrationTest.testRunChangeLog,"    @Test
    public void testRunChangeLog() throws Exception {
        super.testRunChangeLog();    //To change body of overridden methods use File | Settings | File Templates.
    }
",non-flaky,5
159631,liquibase_liquibase,SQLiteIntegrationTest.smartDataLoad,"    @Test
    public void smartDataLoad() throws Exception {
        if (this.getDatabase() == null) {
            return;
        }

        Liquibase liquibase = createLiquibase(""changelogs/common/smartDataLoad.changelog.xml"");
        clearDatabase();

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }

        // check that the automatically rollback now works too
        try {
            liquibase.rollback(new Date(0), this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
    }
",non-flaky,5
159632,liquibase_liquibase,SQLiteIntegrationTest.testDiffExternalForeignKeys,"    @Test
    public void testDiffExternalForeignKeys() throws Exception {
        //cross-schema security for oracle is a bother, ignoring test for now
    }
",non-flaky,5
159633,liquibase_liquibase,OracleIntegrationTest.testRunChangeLog,"    @Test
    public void testRunChangeLog() throws Exception {
        super.testRunChangeLog();    //To change body of overridden methods use File | Settings | File Templates.
    }
",non-flaky,5
159634,liquibase_liquibase,OracleIntegrationTest.indexCreatedOnCorrectSchema,"    @Test
    public void indexCreatedOnCorrectSchema() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(this.indexOnSchemaChangeLog);
        clearDatabase();

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }

        Statement queryIndex = ((JdbcConnection) this.getDatabase().getConnection()).getUnderlyingConnection().createStatement();

        ResultSet indexOwner = queryIndex.executeQuery(""SELECT owner FROM ALL_INDEXES WHERE index_name = 'IDX_BOOK_ID'"");

        assertTrue(indexOwner.next());

        String owner = indexOwner.getString(""owner"");

        assertEquals(""LBCAT2"", owner);

        // check that the automatically rollback now works too
        try {
            liquibase.rollback( new Date(0),this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }




    }
",non-flaky,5
159635,liquibase_liquibase,OracleIntegrationTest.viewCreatedOnCorrectSchema,"    @Test
    public void viewCreatedOnCorrectSchema() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(this.viewOnSchemaChangeLog);
        clearDatabase();

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }

        Statement queryIndex = ((JdbcConnection) this.getDatabase().getConnection()).getUnderlyingConnection().createStatement();

        ResultSet indexOwner = queryIndex.executeQuery(""SELECT owner FROM ALL_VIEWS WHERE view_name = 'V_BOOK2'"");

        assertTrue(indexOwner.next());

        String owner = indexOwner.getString(""owner"");

        assertEquals(""LBCAT2"", owner);

        // check that the automatically rollback now works too
        try {
            liquibase.rollback( new Date(0),this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
    }
",non-flaky,5
159636,liquibase_liquibase,OracleIntegrationTest.smartDataLoad,"    @Test
    public void smartDataLoad() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(""changelogs/common/smartDataLoad.changelog.xml"");
        clearDatabase();

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }

        // check that the automatically rollback now works too
        try {
            liquibase.rollback( new Date(0),this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
    }
",non-flaky,5
159637,liquibase_liquibase,OracleIntegrationTest.testDiffExternalForeignKeys,"    @Test
    public void testDiffExternalForeignKeys() throws Exception {
        //cross-schema security for oracle is a bother, ignoring test for now
    }
",non-flaky,5
159638,liquibase_liquibase,AbstractIntegrationTest.testBatchInsert,"    @Test
    public void testBatchInsert() throws Exception {
        if (this.getDatabase() == null) {
            return;
        }
        clearDatabase();

        createLiquibase(""changelogs/common/batchInsert.changelog.xml"").update(this.contexts);
        // ChangeLog already contains the verification code
    }
",non-flaky,5
159639,liquibase_liquibase,AbstractIntegrationTest.testDatabaseIsReachableIfRequired,"    @Test
    public void testDatabaseIsReachableIfRequired() {
        if (isDatabaseProvidedByTravisCI()) {
            assertNotNull(
                    ""This integration test is expected to pass on Travis CI.\n"" +
                            ""If you are running on a dev machine and do not have the required\n"" +
                            ""database installed, you may choose to ignore this failed test.\n"" +
                            ""To run this test on a dev machine, you will need to install the corresponding\n"" +
                            ""database and configure liquibase.integrationtest.local.properties"",
                    getDatabase());
        } else {
            assumeNotNull(this.getDatabase());
        }
    }
",non-flaky,5
159640,liquibase_liquibase,AbstractIntegrationTest.testRunChangeLog,"    @Test
    public void testRunChangeLog() throws Exception {
        assumeNotNull(this.getDatabase());

        runCompleteChangeLog();
    }
",non-flaky,5
159641,liquibase_liquibase,AbstractIntegrationTest.testRunUpdateOnOldChangelogTableFormat,"    @Test
    public void testRunUpdateOnOldChangelogTableFormat() throws Exception {
        assumeNotNull(this.getDatabase());
        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        String nullableKeyword = database.requiresExplicitNullForColumns() ? "" NULL"" : """";

        String sql = ""CREATE TABLE "" +
                database.escapeTableName(
                        database.getDefaultCatalogName(), database.getDefaultSchemaName(), ""DATABASECHANGELOG""
                ) +
                "" (id varchar(150) NOT NULL, "" +
                ""author VARCHAR(150) NOT NULL, "" +
                ""filename VARCHAR(255) NOT NULL, "" +
                ""dateExecuted "" +
                DataTypeFactory.getInstance().fromDescription(
                        ""datetime"", database
                ).toDatabaseDataType(database) + "" NOT NULL, "" +
                ""md5sum VARCHAR(32)"" + nullableKeyword + "", "" +
                ""description VARCHAR(255)"" + nullableKeyword + "", "" +
                ""comments VARCHAR(255)"" + nullableKeyword + "", "" +
                ""tag VARCHAR(255)"" + nullableKeyword + "", "" +
                ""liquibase VARCHAR(10)"" + nullableKeyword + "", "" +
                ""PRIMARY KEY (id, author, filename))"";
        Scope.getCurrentScope().getLog(getClass()).info(LogType.WRITE_SQL, sql);

        Connection conn = ((JdbcConnection) database.getConnection()).getUnderlyingConnection();
        boolean savedAcSetting = conn.getAutoCommit();
        conn.setAutoCommit(false);
        conn.createStatement().execute(sql);
        conn.commit();
        conn.setAutoCommit(savedAcSetting);

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);

    }
",non-flaky,5
159642,liquibase_liquibase,AbstractIntegrationTest.testOutputChangeLog,"    @Test
    public void testOutputChangeLog() throws Exception {
        assumeNotNull(this.getDatabase());

        StringWriter output = new StringWriter();
        Liquibase liquibase;
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter(""loginuser"", getUsername());
        liquibase.update(this.contexts, output);

        String outputResult = output.getBuffer().toString();
        assertNotNull(""generated output change log must not be empty"", outputResult);
        assertTrue(""generated output change log is at least 100 bytes long"", outputResult.length() > 100);

        // TODO should better written to a file so CI servers can pick it up as test artifacts.
        System.out.println(outputResult);
        assertTrue(""create databasechangelog command not found in: \n"" + outputResult, outputResult.contains(""CREATE TABLE ""+database.escapeTableName(database.getLiquibaseCatalogName(), database.getLiquibaseSchemaName(), database.getDatabaseChangeLogTableName())));
        assertTrue(""create databasechangeloglock command not found in: \n"" + outputResult, outputResult.contains(""CREATE TABLE ""+database.escapeTableName(database.getLiquibaseCatalogName(), database.getLiquibaseSchemaName(), database.getDatabaseChangeLogLockTableName())));

        assertTrue(""generated output contains a correctly encoded Euro sign"", outputResult.contains(""""));

        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));
        assertEquals(""no database objects were actually created during creation of the output changelog"",
                0, snapshot.get(Schema.class).iterator().next().getDatabaseObjects(Table.class).size());
    }
",non-flaky,5
159643,liquibase_liquibase,AbstractIntegrationTest.testUpdateTwice,"    @Test
    public void testUpdateTwice() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);
        liquibase.update(this.contexts);
    }
",non-flaky,5
159644,liquibase_liquibase,AbstractIntegrationTest.testUpdateClearUpdate,"    @Test
    public void testUpdateClearUpdate() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);
    }
",non-flaky,5
159645,liquibase_liquibase,AbstractIntegrationTest.testRollbackableChangeLog,"    @Test
    public void testRollbackableChangeLog() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(rollbackChangeLog);
        clearDatabase();

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(this.contexts);

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.rollback(new Date(0), this.contexts);

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(this.contexts);

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.rollback(new Date(0), this.contexts);
    }
",non-flaky,5
159646,liquibase_liquibase,AbstractIntegrationTest.testRollbackableChangeLogScriptOnExistingDatabase,"    @Test
    public void testRollbackableChangeLogScriptOnExistingDatabase() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(rollbackChangeLog);
        clearDatabase();

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(this.contexts);

        StringWriter writer = new StringWriter();

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.rollback(new Date(0), this.contexts, writer);
    }
",non-flaky,5
159647,liquibase_liquibase,AbstractIntegrationTest.testRollbackableChangeLogScriptOnFutureDatabase,"    @Test
    public void testRollbackableChangeLogScriptOnFutureDatabase() throws Exception {
        assumeNotNull(this.getDatabase());

        StringWriter writer = new StringWriter();

        Liquibase liquibase = createLiquibase(rollbackChangeLog);
        clearDatabase();

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.futureRollbackSQL(new Contexts(this.contexts), new LabelExpression(), writer);
    }
",non-flaky,5
159648,liquibase_liquibase,AbstractIntegrationTest.testTag,"    @Test
    public void testTag() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);

        liquibase.tag(""Test Tag"");
    }
",non-flaky,5
159649,liquibase_liquibase,AbstractIntegrationTest.testDiff,"    @Test
    public void testDiff() throws Exception {
        assumeNotNull(this.getDatabase());

        runCompleteChangeLog();

        CompareControl compareControl = new CompareControl();
        compareControl.addSuppressedField(Column.class, ""defaultValue"");  //database returns different data even if the same
        compareControl.addSuppressedField(Column.class, ""autoIncrementInformation""); //database returns different data even if the same
        DiffResult diffResult = DiffGeneratorFactory.getInstance().compare(database, database, compareControl);

        try {
            assertTrue(""comapring a database with itself should return a result of 'DBs are equal'"",
                    diffResult.areEqual());
        } catch (AssertionError e) {
            new DiffToReport(diffResult, System.err).print();
            throw e;
        }
    }
",non-flaky,5
159650,liquibase_liquibase,AbstractIntegrationTest.testRerunDiffChangeLog,"    @Test
    public void testRerunDiffChangeLog() throws Exception {
        assumeNotNull(this.getDatabase());

        for (int run=0; run < 2; run++) { //run once outputting data as insert, once as csv
            boolean outputCsv = run == 1;
            runCompleteChangeLog();

            SnapshotControl snapshotControl = new SnapshotControl(database);

            DatabaseSnapshot originalSnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, snapshotControl);

            CompareControl compareControl = new CompareControl();
            compareControl.addSuppressedField(Column.class, ""defaultValue"");  //database returns different data even if the same
            compareControl.addSuppressedField(Column.class, ""autoIncrementInformation""); //database returns different data even if the same
            if (database instanceof OracleDatabase) {
                compareControl.addSuppressedField(Column.class, ""type""); //database returns different nvarchar2 info even though they are the same
                compareControl.addSuppressedField(Column.class, ""nullable""); // database returns different nullable on views, e.g. v_person.id
            }
            if (database instanceof PostgresDatabase) {
                compareControl.addSuppressedField(Column.class, ""type""); //database returns different nvarchar2 info even though they are the same
            }

            DiffOutputControl diffOutputControl = new DiffOutputControl();
            File tempFile = tempDirectory.getRoot().createTempFile(""liquibase-test"", "".xml"");

            if (outputCsv) {
                diffOutputControl.setDataDir(new File(tempFile.getParentFile(), ""liquibase-data"").getCanonicalPath().replaceFirst(""\\w:"",""""));
            }

            DiffResult diffResult = DiffGeneratorFactory.getInstance().compare(database, null, compareControl);


            FileOutputStream output = new FileOutputStream(tempFile);
            try {
                new DiffToChangeLog(diffResult, new DiffOutputControl()).print(new PrintStream(output));
                output.flush();
            } finally {
                output.close();
            }

            Liquibase liquibase = createLiquibase(tempFile.getName());
            clearDatabase();

            DatabaseSnapshot emptySnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));

            //run again to test changelog testing logic
            liquibase = createLiquibase(tempFile.getName());
            try {
                liquibase.update(this.contexts);
            } catch (ValidationFailedException e) {
                e.printDescriptiveError(System.out);
                throw e;
            }

            DatabaseSnapshot migratedSnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));

            DiffResult finalDiffResult = DiffGeneratorFactory.getInstance().compare(originalSnapshot, migratedSnapshot, compareControl);
            try {
                assertTrue(""recreating the database from the generated change log should cause both 'before' and "" +
                                ""'after' snapshots to be equal."",
                        finalDiffResult.areEqual());
            } catch (AssertionError e) {
                new DiffToReport(finalDiffResult, System.err).print();
                throw e;
            }

            //diff to empty and drop all
            DiffResult emptyDiffResult = DiffGeneratorFactory.getInstance().compare(emptySnapshot, migratedSnapshot, compareControl);
            output = new FileOutputStream(tempFile);
            try {
                new DiffToChangeLog(emptyDiffResult, new DiffOutputControl(true, true, true, null)).print(new PrintStream(output));
                output.flush();
            } finally {
                output.close();
            }

            liquibase = createLiquibase(tempFile.getName());
            Scope.getCurrentScope().getLog(getClass()).info(LogType.LOG, ""updating from ""+tempFile.getCanonicalPath());
            try {
                liquibase.update(this.contexts);
            } catch (LiquibaseException e) {
                throw e;
            }

            DatabaseSnapshot emptyAgainSnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));
            assertEquals(""a database that was 'updated' to an empty snapshot should only have 2 tables left: "" +
                            ""the database change log table and the lock table."",
                    2, emptyAgainSnapshot.get(Table.class).size());
            assertEquals(""a database that was 'updated' to an empty snapshot should not contain any views."",
                    0, emptyAgainSnapshot.get(View.class).size());
        }
    }
",non-flaky,5
159651,liquibase_liquibase,AbstractIntegrationTest.testRerunDiffChangeLogAltSchema,"    @Test
    public void testRerunDiffChangeLogAltSchema() throws Exception {
        assumeNotNull(this.getDatabase());
        if (database.getShortName().equalsIgnoreCase(""mssql"")) {
            return; // not possible on MSSQL.
        }
        if (!database.supportsSchemas()) {
            return;
        }

        Liquibase liquibase = createLiquibase(includedChangeLog);
        database.setDefaultSchemaName(""lbcat2"");
        clearDatabase();


        LockService lockService = LockServiceFactory.getInstance().getLockService(database);
        lockService.forceReleaseLock();

        liquibase.update(includedChangeLog);

        DatabaseSnapshot originalSnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));

        CompareControl compareControl = new CompareControl(
                new CompareControl.SchemaComparison[]{
                        new CompareControl.SchemaComparison(
                                CatalogAndSchema.DEFAULT,
                                new CatalogAndSchema(null, ""lbcat2"")
                        )
                },
                originalSnapshot.getSnapshotControl().getTypesToInclude()
        );
        DiffResult diffResult = DiffGeneratorFactory.getInstance().compare(database, null, compareControl);

        File tempFile = File.createTempFile(""liquibase-test"", "".xml"");

        FileOutputStream output = new FileOutputStream(tempFile);
        try {
            new DiffToChangeLog(diffResult, new DiffOutputControl()).print(new PrintStream(output));
            output.flush();
        } finally {
            output.close();
        }

        liquibase = createLiquibase(tempFile.getName());
        clearDatabase();

        //run again to test changelog testing logic
        Executor executor = ExecutorService.getInstance().getExecutor(database);
        try {
            executor.execute(new DropTableStatement(""lbcat2"", ""lbcat2"", database.getDatabaseChangeLogTableName(), false));
        } catch (DatabaseException e) {
            //ok
        }
        try {
            executor.execute(new DropTableStatement(""lbcat2"", ""lbcat2"", database.getDatabaseChangeLogLockTableName(), false));
        } catch (DatabaseException e) {
            //ok
        }
        database.commit();

        DatabaseConnection connection = DatabaseTestContext.getInstance().getConnection(getJdbcUrl(), username, password);
        database = DatabaseFactory.getInstance().findCorrectDatabaseImplementation(connection);
        database.setDefaultSchemaName(""lbcat2"");
        liquibase = createLiquibase(tempFile.getName());
        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }

        tempFile.deleteOnExit();

        DatabaseSnapshot finalSnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));

        CompareControl finalCompareControl = new CompareControl();
        finalCompareControl.addSuppressedField(Column.class, ""autoIncrementInformation"");
        DiffResult finalDiffResult = DiffGeneratorFactory.getInstance().compare(originalSnapshot, finalSnapshot, finalCompareControl);
        new DiffToReport(finalDiffResult, System.out).print();
        assertTrue(""running the same change log two times against an alternative schema should produce "" +
                        ""equal snapshots."",
                finalDiffResult.areEqual());
    }
",non-flaky,5
159652,liquibase_liquibase,AbstractIntegrationTest.testClearChecksums,"    @Test
    public void testClearChecksums() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);

        liquibase.clearCheckSums();
    }
",non-flaky,5
159653,liquibase_liquibase,AbstractIntegrationTest.testTagEmptyDatabase,"    @Test
    public void testTagEmptyDatabase() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.checkLiquibaseTables(false, null, new Contexts(), new LabelExpression());
        liquibase.tag(""empty"");

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(new Contexts());

        liquibase.rollback(""empty"", new Contexts());

    }
",non-flaky,5
159654,liquibase_liquibase,AbstractIntegrationTest.testUnrunChangeSetsEmptyDatabase,"    @Test
    public void testUnrunChangeSetsEmptyDatabase() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        List<ChangeSet> list = liquibase.listUnrunChangeSets(new Contexts(this.contexts), new LabelExpression());

        assertTrue(""querying the changelog table on an empty target should return at least 1 un-run change set"", !list.isEmpty());

    }
",non-flaky,5
159655,liquibase_liquibase,AbstractIntegrationTest.testAbsolutePathChangeLog,"    @Test
    public void testAbsolutePathChangeLog() throws Exception {
        assumeNotNull(this.getDatabase());

        String fileUrlToChangeLog = getClass().getResource(""/"" + includedChangeLog).toString();
        assertTrue(fileUrlToChangeLog.startsWith(""file:/""));

        String absolutePathOfChangeLog = fileUrlToChangeLog.replaceFirst(""file:\\/"", """");
        if (System.getProperty(""os.name"").startsWith(""Windows "")) {
            absolutePathOfChangeLog = absolutePathOfChangeLog.replace('/', '\\');
        } else {
            absolutePathOfChangeLog = ""/"" + absolutePathOfChangeLog;
        }
        Liquibase liquibase = createLiquibase(absolutePathOfChangeLog, new FileSystemResourceAccessor());
        clearDatabase();

        liquibase.update(this.contexts);

        liquibase.update(this.contexts); //try again, make sure there are no errors

        clearDatabase();
    }
",non-flaky,5
159656,liquibase_liquibase,AbstractIntegrationTest.testRollbackToChange,"    @Test
    public void testRollbackToChange() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(rollbackChangeLog);
        wipeDatabase();

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(this.contexts);

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.rollback(8, this.contexts);

        liquibase.tag(""testRollbackToChange"");

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(this.contexts);

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.rollback(""testRollbackToChange"", this.contexts);
    }
",non-flaky,5
159657,liquibase_liquibase,AbstractIntegrationTest.testDbDoc,"    @Test
    public void testDbDoc() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase;
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);

        Path outputDir = tempDirectory.newFolder().toPath().normalize();
        logger.fine(LogType.LOG, ""Database documentation will be written to this temporary folder: "" + outputDir);

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.generateDocumentation(outputDir.toAbsolutePath().toString(), this.contexts);
    }
",non-flaky,5
159658,liquibase_liquibase,AbstractIntegrationTest.testEncodingUpdating2SQL,"    @Test
    public void testEncodingUpdating2SQL() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(encodingChangeLog);

        StringWriter writer=new StringWriter();
        liquibase.update(this.contexts,writer);
        assertTrue(""Update to SQL preserves encoding"",
            new RegexMatcher(writer.toString(), new String[] {
                //For the UTF-8 encoded cvs
                ""^.*INSERT.*VALUES.*.*?\\)"",
                """",
                //For the latin1 one
                ""^.*INSERT.*VALUES.*.*?\\)"",
                """"
            }).allMatchedInSequentialOrder());
    }
",non-flaky,5
159659,liquibase_liquibase,AbstractIntegrationTest.testDiffExternalForeignKeys,"   @Test
   public void testDiffExternalForeignKeys() throws Exception {
       assumeNotNull(this.getDatabase());
       clearDatabase();
       Liquibase liquibase = createLiquibase(externalfkInitChangeLog);
       liquibase.update(contexts);

       DiffResult diffResult = liquibase.diff(database, null, new CompareControl());
       DiffResultAssert.assertThat(diffResult).containsMissingForeignKeyWithName(""fk_person_country"");
   }
",non-flaky,5
159660,liquibase_liquibase,AbstractIntegrationTest.testInvalidIncludeDoesntBreakLiquibase,"    @Test
    public void testInvalidIncludeDoesntBreakLiquibase() throws Exception {
        assumeNotNull(this.getDatabase());
        Liquibase liquibase = createLiquibase(invalidReferenceChangeLog);
        try {
            liquibase.update(new Contexts());
            fail(""Did not fail with invalid include"");
        } catch (ChangeLogParseException ignored) {
            //expected
        }

        LockService lockService = LockServiceFactory.getInstance().getLockService(database);
        assertFalse(lockService.hasChangeLogLock());
    }
",non-flaky,5
159661,liquibase_liquibase,AbstractIntegrationTest.testContextsWithHyphensWorkInFormattedSql,"    @Test
    public void testContextsWithHyphensWorkInFormattedSql() throws Exception {
        assumeNotNull(this.getDatabase());
        Liquibase liquibase = createLiquibase(""changelogs/common/sqlstyle/formatted.changelog.sql"");
        liquibase.update(""hyphen-context-using-sql,camelCaseContextUsingSql"");

        SnapshotGeneratorFactory tableSnapshotGenerator = SnapshotGeneratorFactory.getInstance();
        assertNotNull(tableSnapshotGenerator.has(new Table().setName(""hyphen_context""), database));
        assertNotNull(tableSnapshotGenerator.has(new Table().setName(""camel_context""), database));
        assertNotNull(tableSnapshotGenerator.has(new Table().setName(""bar_id""), database));
        assertNotNull(tableSnapshotGenerator.has(new Table().setName(""foo_id""), database));
    }
",non-flaky,5
159662,liquibase_liquibase,AbstractIntegrationTest.testObjectQuotingStrategy,"    @Test
    public void testObjectQuotingStrategy() throws Exception {
        assumeNotNull(this.getDatabase());
        if (!Arrays.asList(""oracle,h2,hsqldb,postgresql,mysql"").contains(database.getShortName())) {
            return;
        }

        Liquibase liquibase = createLiquibase(objectQuotingStrategyChangeLog);
        clearDatabase();
        liquibase.update(contexts);
        clearDatabase();
    }
",non-flaky,5
159663,liquibase_liquibase,AbstractIntegrationTest.testOutputChangeLogIgnoringSchema,"    @Test
    public void testOutputChangeLogIgnoringSchema() throws Exception {
        assumeNotNull(this.getDatabase());

        String schemaName = getDatabase().getDefaultSchemaName();
        if (schemaName == null) {
            return;
        }

        getDatabase().setOutputDefaultSchema(false);
        getDatabase().setOutputDefaultCatalog(false);

        StringWriter output = new StringWriter();
        Liquibase liquibase = createLiquibase(includedChangeLog);
        clearDatabase();

        liquibase = createLiquibase(includedChangeLog);
        liquibase.update(contexts, output);

        String outputResult = output.getBuffer().toString();
        assertNotNull(""generated SQL may not be empty"", outputResult);
        assertTrue(""Expect at least 100 bytes of output in generated SQL"", outputResult.length() > 100);
        CharSequence expected = ""CREATE TABLE ""+getDatabase().escapeTableName(getDatabase().getLiquibaseCatalogName(), getDatabase().getLiquibaseSchemaName(), getDatabase().getDatabaseChangeLogTableName());
        assertTrue(""create databasechangelog command not found in: \n"" + outputResult, outputResult.contains(expected));
        assertTrue(""create databasechangeloglock command not found in: \n"" + outputResult, outputResult.contains(expected));
        assertFalse(""the schema name '"" + schemaName + ""' should be ignored\n\n"" + outputResult, outputResult.contains
                (schemaName+"".""));
    }
",non-flaky,5
159664,liquibase_liquibase,AbstractIntegrationTest.testGenerateChangeLogWithNoChanges,"    @Test
    public void testGenerateChangeLogWithNoChanges() throws Exception {
        assumeNotNull(this.getDatabase());

        runCompleteChangeLog();

        DiffResult diffResult = DiffGeneratorFactory.getInstance().compare(database, database, new CompareControl());

        DiffToChangeLog changeLogWriter = new DiffToChangeLog(diffResult, new DiffOutputControl(false, false, false, null));
        List<ChangeSet> changeSets = changeLogWriter.generateChangeSets();
        assertEquals(""generating two change logs without any changes in between should result in an empty generated "" +
                ""differential change set."", 0, changeSets.size());
    }
",non-flaky,5
159665,liquibase_liquibase,MssqlIntegrationTest.defaultValuesTests,"    @Test
    public void defaultValuesTests() throws Exception {
        clearDatabase();

        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(""changelogs/mssql/issues/default.values.xml"");
        liquibase.update((String) null);

        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(CatalogAndSchema.DEFAULT, this.getDatabase(), new SnapshotControl(getDatabase()));

        for (Table table : snapshot.get(Table.class)) {
            for (Column column : table.getColumns()) {
                if (column.getName().toLowerCase().endsWith(""_default"")) {
                    Object defaultValue = column.getDefaultValue();
                    assertNotNull(""Null default value for "" + table.getName() + ""."" + column.getName(), defaultValue);
                    if (column.getName().toLowerCase().contains(""date"") || column.getName().toLowerCase().contains(""time"")) {
                        if (defaultValue instanceof String) {
                            assertTrue(defaultValue.equals(""2017-12-09 23:52:39.1234567 +01:00""));
                        } else if (defaultValue instanceof DatabaseFunction) {
                            ((DatabaseFunction) defaultValue).getValue().contains(""type datetimeoffset"");
                        } else if (defaultValue instanceof Time) {
                            Calendar calendar = Calendar.getInstance();
                            calendar.setTime(((Date) defaultValue));
                            assertEquals(23, calendar.get(Calendar.HOUR_OF_DAY));
                            assertEquals(52, calendar.get(Calendar.MINUTE));
                            assertEquals(39, calendar.get(Calendar.SECOND));
                        } else {
                            assertTrue(""Unexpected default type ""+defaultValue.getClass().getName()+"" for "" + table.getName() + ""."" + column.getName(), defaultValue instanceof Date);
                            Calendar calendar = Calendar.getInstance();
                            calendar.setTime(((Date) defaultValue));
                            assertEquals(9, calendar.get(Calendar.DAY_OF_MONTH));
                            assertEquals(11, calendar.get(Calendar.MONTH));
                            assertEquals(2017, calendar.get(Calendar.YEAR));
                        }
                    } else if (column.getName().toLowerCase().contains(""char_"")) {
                        assertTrue(""Unexpected default type ""+defaultValue.getClass().getName()+"" for "" + table.getName() + ""."" + column.getName(), defaultValue instanceof String);
                    } else if (column.getName().toLowerCase().contains(""binary_"")) {
                        assertTrue(""Unexpected default type ""+defaultValue.getClass().getName()+"" for "" + table.getName() + ""."" + column.getName(), defaultValue instanceof DatabaseFunction);
                    } else {
                        assertTrue(""Unexpected default type ""+defaultValue.getClass().getName()+"" for "" + table.getName() + ""."" + column.getName(), defaultValue instanceof Number);
                        assertEquals(1, ((Number) defaultValue).intValue());
                    }
                }
            }
        }
    }
",non-flaky,5
159666,liquibase_liquibase,MssqlIntegrationTest.dataTypesTest,"    @Test
    public void dataTypesTest() throws Exception {
        assumeNotNull(this.getDatabase());
        clearDatabase();

        Liquibase liquibase = createLiquibase(""changelogs/mssql/issues/data.types.xml"");
        liquibase.update((String) null);

        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(CatalogAndSchema.DEFAULT, this.getDatabase(), new SnapshotControl(getDatabase()));

        for (Table table : snapshot.get(Table.class)) {
            if (getDatabase().isLiquibaseObject(table)) {
                continue;
            }
            for (Column column : table.getColumns()) {
                String expectedType = column.getName().split(""_"")[0];

                switch(expectedType.toUpperCase()) {
                    // See https://docs.microsoft.com/en-us/sql/t-sql/data-types/ntext-text-and-image-transact-sql
                    // Types text, ntext and image are deprecated and should be translated into
                    // varchar(max), nvarchar(max) and varbinary(max).
                    case ""TEXT"":
                        expectedType=""varchar"";
                        break;
                    case ""NTEXT"":
                        expectedType=""nvarchar"";
                        break;
                    case ""IMAGE"":
                        expectedType=""varbinary"";
                        break;
                    default:
                        // nothing to do
                }

                String foundTypeDefinition = DataTypeFactory.getInstance().from(column.getType(), new MSSQLDatabase()).toDatabaseDataType(getDatabase()).toString();
                // [varbinary] -> varbinary
                foundTypeDefinition = foundTypeDefinition.replaceFirst(""^\\[(.*?)\\]"", ""$1"");
                String foundType = foundTypeDefinition.replaceFirst(""\\(.*"", """").trim();

                assertEquals(""Wrong data type for "" + table.getName() + ""."" + column.getName(),
                    expectedType.toLowerCase(),
                    foundType.toLowerCase()
                );

                if (""varbinary"".equalsIgnoreCase(expectedType)) {
                    if (column.getName().endsWith(""_MAX"")) {
                        assertEquals(""VARBINARY(MAX)"", foundTypeDefinition.toUpperCase());
                    } else {
                        assertEquals(""VARBINARY(1)"", foundTypeDefinition.toUpperCase());
                    }
                }
            }
        }
    }
",non-flaky,5
159667,liquibase_liquibase,MssqlIntegrationTest.dataTypeParamsTest,"    @Test
    public void dataTypeParamsTest() throws Exception {
        assumeNotNull(this.getDatabase());
        clearDatabase();

        Liquibase liquibase = createLiquibase(""changelogs/mssql/issues/data.type.params.xml"");
        liquibase.update((String) null);

        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(CatalogAndSchema.DEFAULT, this.getDatabase(), new SnapshotControl(getDatabase()));

        for (Table table : snapshot.get(Table.class)) {
            if (getDatabase().isLiquibaseObject(table)) {
                continue;
            }
            for (Column column : table.getColumns()) {
                String expectedType = column.getName().split(""_"")[0];

                String foundTypeDefinition = DataTypeFactory.getInstance().from(column.getType(), new MSSQLDatabase()).toDatabaseDataType(getDatabase()).toString();
                assertFalse(""Parameter found in "" + table.getName() + ""."" + column.getName(), foundTypeDefinition.contains(""(""));
            }
        }
    }
",non-flaky,5
159668,liquibase_liquibase,AbstractMssqlIntegrationTest.impossibleDefaultSchema,"    @Test
    public void impossibleDefaultSchema() {
        Exception caughtException = null;
        try {
            getDatabase().setDefaultSchemaName(""lbuser"");
        } catch (Exception ex) {
            caughtException = ex;
        }
        assertNotNull(""Must not allow using a defaultSchemaName that is different from the DB user's login schema."",
            caughtException);

    }
",non-flaky,5
159669,liquibase_liquibase,AbstractMssqlIntegrationTest.smartDataLoad,"    @Test
    public void smartDataLoad() throws Exception {
        assumeNotNull(this.getDatabase());
        Liquibase liquibase = createLiquibase(""changelogs/common/smartDataLoad.changelog.xml"");
        clearDatabase();
        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
        try {
            liquibase.rollback(new Date(0), this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
    }
",non-flaky,5
159670,liquibase_liquibase,UnlockDatabaseChangeLogExecuteTest.generateSql,"    @Test
    public void generateSql() throws Exception {
        this.statementUnderTest = new UnlockDatabaseChangeLogStatement();
        assertCorrect(""update [databasechangeloglock] set [locked] = 0, [lockedby] = null, [lockgranted] = null where [id] = 1"", MSSQLDatabase.class, SybaseDatabase.class);
        assertCorrect(""update [databasechangeloglock] set [locked] = 0, [lockedby] = null, [lockgranted] = null where [id] = 1"", MSSQLDatabase.class, SybaseASADatabase.class);
        assertCorrect(""update [databasechangeloglock] set [locked] = 'f', [lockedby] = null, [lockgranted] = null where [id] = 1"", InformixDatabase.class);
        assertCorrect(""update [databasechangeloglock] set [locked] = false, [lockedby] = null, [lockgranted] = null where [id] = 1"", PostgresDatabase.class, HsqlDatabase.class, H2Database.class);
        assertCorrectOnRest(""update [databasechangeloglock] set [locked] = 0, [lockedby] = null, [lockgranted] = null where [id] = 1"");
    }
",non-flaky,5
159671,liquibase_liquibase,AddColumnExecutorTest.generateSql_autoIncrement,"    @Test
    public void generateSql_autoIncrement() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, ""table_name"", ""column_name"", ""int"", null, new AutoIncrementConstraint(""column_name""));

        assertCorrect(""alter table table_name add column_name serial"", InformixDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int default autoincrement null"", SybaseASADatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] serial"", PostgresDatabase.class);
        assertCorrect(""alter table [dbo].[table_name] add [column_name] int identity"", MSSQLDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int identity null"", SybaseDatabase.class);
        assertCorrect(""not supported. fixme!!"", SQLiteDatabase.class);
        assertCorrect(""alter table table_name add column_name int auto_increment_clause"");
    }
",non-flaky,5
159672,liquibase_liquibase,AddColumnExecutorTest.generateSql_notNull,"    @Test
    public void generateSql_notNull() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, null, ""table_name"", ""column_name"", ""int"", 42, new NotNullConstraint());
        assertCorrect(""alter table [table_name] add [column_name] int default 42 not null"", SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table table_name add column_name int default 42 not null"", PostgresDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] [int] constraint df_table_name_column_name default 42 not null"", MSSQLDatabase.class);
        assertCorrect(""alter table table_name add column_name int default 42 not null"", MySQLDatabase.class);
        assertCorrect(""not supported. fixme!!"", SQLiteDatabase.class);
        assertCorrect(""ALTER TABLE [table_name] ADD [column_name] int DEFAULT 42 NOT NULL"");
    }
",non-flaky,5
159673,liquibase_liquibase,AddColumnExecutorTest.fullNoConstraints,"    @Test
    public void fullNoConstraints() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, null, ""table_name"", ""column_name"", ""int"", 42);


        assertCorrect(""alter table [table_name] add [column_name] int default 42 null"", SybaseDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int constraint df_table_name_column_name default 42"", MSSQLDatabase.class);
//        assertCorrect(""alter table [table_name] add [column_name] integer default 42"", SQLiteDatabase.class);
        assertCorrect(""not supported. fixme!!"", SQLiteDatabase.class);
        assertCorrect(""alter table table_name add column_name int default 42"", PostgresDatabase.class, InformixDatabase.class, OracleDatabase.class, DerbyDatabase.class, HsqlDatabase.class, DB2Database.class, H2Database.class, FirebirdDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int default 42 null"", SybaseASADatabase.class);
        assertCorrect(""alter table table_name add column_name int default 42 null"", MySQLDatabase.class, MariaDBDatabase.class);
        assertCorrectOnRest(""ALTER TABLE [table_name] ADD [column_name] int DEFAULT 42"");
    }
",non-flaky,5
159674,liquibase_liquibase,AddColumnExecutorTest.autoIncrement,"    @Test
    public void autoIncrement() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, TABLE_NAME, ""column_name"", ""int"", null, new AutoIncrementConstraint());

        assertCorrect(""ALTER TABLE [dbo].[table_name] ADD [column_name] int auto_increment_clause"", MSSQLDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int default autoincrement null"", SybaseASADatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int identity null"", SybaseDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] serial"", PostgresDatabase.class, InformixDatabase.class);
        assertCorrect(""not supported. fixme!!"", SQLiteDatabase.class);
        assertCorrectOnRest(""ALTER TABLE [table_name] ADD [column_name] int auto_increment_clause"");
    }
",non-flaky,5
159675,liquibase_liquibase,AddColumnExecutorTest.notNull,"    @Test
    public void notNull() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, null, TABLE_NAME, ""column_name"", ""int"", 42, new NotNullConstraint());

        assertCorrect(""ALTER TABLE [table_name] ADD [column_name] int DEFAULT 42 NOT NULL"", SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table table_name add column_name int default 42 not null"", InformixDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int constraint df_table_name_column_name default 42 not null"", MSSQLDatabase.class);
        assertCorrect(""alter table table_name add column_name int default 42 not null"", OracleDatabase.class, DerbyDatabase.class, HsqlDatabase.class, DB2Database.class, H2Database.class, FirebirdDatabase.class);
        assertCorrect(""not supported. fixme!!"", SQLiteDatabase.class);
        assertCorrectOnRest(""ALTER TABLE [table_name] ADD [column_name] int default 42 not null"");
    }
",non-flaky,5
159676,liquibase_liquibase,AddColumnExecutorTest.generateSql_primaryKey,"    @Test
    public void generateSql_primaryKey() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, ""table_name"", ""column_name"", ""int"", null, new PrimaryKeyConstraint());

        assertCorrect(""alter table [table_name] add [column_name] int not null primary key"", HsqlDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int primary key not null"", SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table [dbo].[table_name] add [column_name] int not null primary key"", MSSQLDatabase.class);
        assertCorrect(""alter table table_name add column_name int not null primary key"", PostgresDatabase.class);
        assertCorrect(""alter table `table_name` add `column_name` int not null primary key"", MySQLDatabase.class);
        assertCorrect(""ALTER TABLE [table_name] ADD [column_name] int PRIMARY KEY NOT NULL"");
    }
",non-flaky,5
159677,liquibase_liquibase,AddColumnExecutorTest.generateSql_foreignKey,"    @Test
    public void generateSql_foreignKey() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, ""table_name"", ""column_name"", ""int"", null, new PrimaryKeyConstraint(), new ForeignKeyConstraint(""fk_test_fk"", ""table_name(column_name)""));

        assertCorrect(new String[] {""alter table [table_name] add [column_name] int not null primary key"", ""alter table [table_name] add constraint [fk_test_fk] foreign key ([column_name]) references [table_name]([column_name])""}, HsqlDatabase.class);
        assertCorrect(new String[] {""alter table [table_name] add [column_name] int primary key not null"", ""alter table [table_name] add constraint [fk_test_fk] foreign key ([column_name]) references [table_name]([column_name])""}, SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(new String[] {""alter table [dbo].[table_name] add [column_name] int not null primary key"", ""alter table [dbo].[table_name] add constraint [fk_test_fk] foreign key ([column_name]) references [dbo].[table_name]([column_name])""}, MSSQLDatabase.class);
        assertCorrect(new String[] {""alter table table_name add column_name int not null primary key"", ""alter table [table_name] add constraint [fk_test_fk] foreign key ([column_name]) references [table_name]([column_name])""}, PostgresDatabase.class);
        assertCorrect(new String[] {""alter table `table_name` add `column_name` int not null primary key"", ""alter table [table_name] add constraint [fk_test_fk] foreign key ([column_name]) references [table_name]([column_name])""}, MySQLDatabase.class);
        assertCorrect(new String[] {""ALTER TABLE [table_name] ADD [column_name] int PRIMARY KEY NOT NULL"", ""alter table [table_name] add constraint  foreign key ([column_name]) references [table_name]([column_name]) constraint [fk_test_fk]""}, InformixDatabase.class);
        assertCorrect(new String[] {""ALTER TABLE [table_name] ADD [column_name] int PRIMARY KEY NOT NULL"", ""alter table [table_name] add constraint [fk_test_fk] foreign key ([column_name]) references [table_name]([column_name])""});
    }
",non-flaky,5
159678,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_noSchema,"    //    @Test
//    public void execute_noSchema() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddUniqueConstraintStatement(null, TABLE_NAME, COLUMN_NAME, ""uq_adduqtest"")) {
//
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertFalse(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        //todo: enable snapshot and assertion when snapshot can check for unique constraints
//                        //snapshot = new DatabaseSnapshotGenerator(snapshot);
//                    	assertTrue(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//                });
//    }
",non-flaky,5
159679,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_withSchema,"//    @Test
//    public void execute_withSchema() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(TestContext.ALT_SCHEMA, new AddUniqueConstraintStatement(TestContext.ALT_SCHEMA, TABLE_NAME, COLUMN_NAME, ""uq_adduqtest"")) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertFalse(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        //todo: enable snapshot and assertion when snapshot can check for unique constraints
//                snapshot = new DatabaseSnapshotGenerator(database, TestContext.ALT_SCHEMA);
//                assertTrue(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//
//                });
//    }
",non-flaky,5
159680,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_withTablespace,"//    @Test
//    public void execute_withTablespace() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddUniqueConstraintStatement(null, TABLE_NAME, COLUMN_NAME, ""uq_adduqtest"").setTablespace(TestContext.ALT_TABLESPACE)) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertFalse(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        //todo: enable snapshot and assertion when snapshot can check for unique constraints
//                        // snapshot = new DatabaseSnapshotGenerator(database);
////                assertTrue(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//                });
//    }
",non-flaky,5
159681,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_noSchema,"    @Test
    public void execute_noSchema() throws Exception {
        this.statementUnderTest = new AddUniqueConstraintStatement(null, null, TABLE_NAME, new ColumnConfig[] { new ColumnConfig().setName(COLUMN_NAME)}, CONSTRAINT_NAME);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", SybaseDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", MSSQLDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", SybaseASADatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", MySQLDatabase.class);
        assertCorrect(""alter table adduqtest add constraint unique (coltomakeuq) constraint uq_test"", InformixDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", OracleDatabase.class);
        assertCorrect(""alter table \""adduqtest\"" add constraint uq_test unique (\""coltomakeuq\"")"", PostgresDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", DerbyDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"");
    }
",non-flaky,5
159682,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_noConstraintName,"    @Test
    public void execute_noConstraintName() throws Exception {
        this.statementUnderTest = new AddUniqueConstraintStatement(null, null, TABLE_NAME, new ColumnConfig[] { new ColumnConfig().setName(COLUMN_NAME)}, null);
        assertCorrect(""alter table adduqtest add unique (coltomakeuq)"", MySQLDatabase.class);
        assertCorrect(""alter table adduqtest add constraint unique (coltomakeuq)"", InformixDatabase.class);
        assertCorrect(""alter table adduqtest add unique (coltomakeuq)"", OracleDatabase.class);
        assertCorrect(""alter table \""adduqtest\"" add unique (\""coltomakeuq\"")"", PostgresDatabase.class);
        assertCorrect(""alter table adduqtest add unique (coltomakeuq)"", DerbyDatabase.class);
        assertCorrect(""alter table [adduqtest] add unique ([coltomakeuq])"", SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table [adduqtest] add unique ([coltomakeuq])"", MSSQLDatabase.class);

        assertCorrect(""alter table [adduqtest] add unique ([coltomakeuq])"");
    }
",non-flaky,5
159683,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_withSchema,"    @Test
    public void execute_withSchema() throws Exception {
        statementUnderTest = new AddUniqueConstraintStatement(
                DatabaseTestContext.ALT_CATALOG,
                DatabaseTestContext.ALT_SCHEMA,
                TABLE_NAME,
                new ColumnConfig[]
                        {new ColumnConfig().setName(COLUMN_NAME)},
                CONSTRAINT_NAME
        );

        assertCorrect(""ALTER TABLE liquibasec.adduqtest ADD CONSTRAINT uq_test UNIQUE (coltomakeuq)"", MySQLDatabase
                .class);
        /*
         * In Informix, this test case is actually impossible. While it is allowed to cross-select data from
          * different databases (using the database:schema.table notation), it is not allowed to send DDL to a
          * different database (even if the database is on the same instance). So, even as the following
          * statement is semantically false, it is syntactically correct.
         */
        assertCorrect(""ALTER TABLE liquibasec:liquibaseb.adduqtest ADD CONSTRAINT UNIQUE (coltomakeuq) CONSTRAINT "" +
                ""uq_test"", InformixDatabase.class);

        assertCorrect(""alter table liquibasec.adduqtest add constraint uq_test unique (coltomakeuq)"", OracleDatabase.class);
        assertCorrect(""alter table liquibaseb.\""adduqtest\"" add constraint uq_test unique (\""coltomakeuq\"")"", PostgresDatabase.class);
        assertCorrect(""alter table liquibasec.adduqtest add constraint uq_test unique (coltomakeuq)"", DerbyDatabase
                .class);
        assertCorrect(""alter table [liquibaseb].[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"",
                SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table [liquibasec].[liquibaseb].[adduqtest] add constraint [uq_test] unique "" +
                ""([coltomakeuq])"", MSSQLDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", FirebirdDatabase.class);

        assertCorrect(""alter table [liquibaseb].[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", HsqlDatabase.class);
        assertCorrect(""alter table \""liquibasec\"".[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", DB2Database.class, Db2zDatabase.class);
        assertCorrect(""alter table [liquibaseb].[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", H2Database.class);
        assertCorrectOnRest(""alter table [liquibasec].[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"");

    }
",non-flaky,5
159684,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_withTablespace,"    @Test
    public void execute_withTablespace() throws Exception {
        statementUnderTest = new AddUniqueConstraintStatement(null, null, TABLE_NAME, new ColumnConfig[] { new ColumnConfig().setName(COLUMN_NAME)}, CONSTRAINT_NAME).setTablespace(TABLESPACE_NAME);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq]) on liquibase2"", MSSQLDatabase.class);
        assertCorrect(""alter table adduqtest add constraint unique (coltomakeuq) constraint uq_test"", InformixDatabase.class);
        assertCorrect(""alter table \""adduqtest\"" add constraint uq_test unique (\""coltomakeuq\"") USING INDEX TABLESPACE "" + TABLESPACE_NAME, PostgresDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", MySQLDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", MariaDBDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", DerbyDatabase.class, HsqlDatabase.class, DB2Database.class, H2Database.class, FirebirdDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", Db2zDatabase.class);
        assertCorrectOnRest(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq]) USING INDEX TABLESPACE "" + TABLESPACE_NAME);
    }
",non-flaky,5
159685,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_withDefferedAndDisabled,"    @Test
    public void execute_withDefferedAndDisabled() throws Exception {
        statementUnderTest = new AddUniqueConstraintStatement(null, null, TABLE_NAME, new ColumnConfig[] { new ColumnConfig().setName(COLUMN_NAME)}, CONSTRAINT_NAME).setDeferrable(true).setInitiallyDeferred(true).setDisabled(true);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", SybaseDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", MSSQLDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", SybaseASADatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", MySQLDatabase.class);
        assertCorrect(""alter table adduqtest add constraint unique (coltomakeuq) constraint uq_test"", InformixDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq) DEFERRABLE INITIALLY "" +
                ""DEFERRED DISABLE"", OracleDatabase.class);
        assertCorrect(""ALTER TABLE \""adduqtest\"" ADD CONSTRAINT uq_test unique (\""coltomakeuq\"") DEFERRABLE INITIALLY"" +
                "" DEFERRED"", PostgresDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", DerbyDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"");
    }
",non-flaky,5
159686,liquibase_liquibase,MarkChangeSetRanExecuteTest.generateSql_insert,"    @Test
    public void generateSql_insert() throws Exception {
        this.statementUnderTest = new MarkChangeSetRanStatement(new ChangeSet(""a"", ""b"", false, false, ""c"", ""e"", ""f"",
                null), ChangeSet.ExecType.EXECUTED);
        String version = LiquibaseUtil.getBuildVersion().replaceAll(""SNAPSHOT"", ""SNP"");
        assertCorrect(""insert into [databasechangelog] ([id], [author], [filename], [dateexecuted], "" +
                        ""[orderexecuted], [md5sum], [description], [comments], [exectype], [contexts], [labels], "" +
                        ""[liquibase], [deployment_id]) values ('a', 'b', 'c', getdate(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                MSSQLDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', systimestamp, 1, '8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', "" +
                        ""'executed', 'e', null, '"" + version + ""', null)"",
                OracleDatabase.class);
        assertCorrect(""insert into [databasechangelog] ([id], [author], [filename], [dateexecuted], "" +
                        ""[orderexecuted], [md5sum], [description], [comments], [exectype], [contexts], [labels], "" +
                        ""[liquibase], [deployment_id]) values ('a', 'b', 'c', getdate(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                SybaseDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', "" +
                        ""current year to fraction(5), 1, '8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', "" +
                        ""'executed', "" +
                        ""'e', null, '"" + version + ""', null)"",
                InformixDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', current timestamp, 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                DB2Database.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', current_timestamp, 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                FirebirdDatabase.class, DerbyDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', now, 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                HsqlDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', now(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                SybaseASADatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, `description`, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', now(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                MySQLDatabase.class, MariaDBDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', now(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                PostgresDatabase.class, H2Database.class);
        assertCorrectOnRest(""insert into databasechangelog (id, author, filename, dateexecuted, "" +
                ""orderexecuted, md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) "" +
                ""values ('a', 'b', 'c', "" +
                ""current timestamp, 1, '8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, "" +
                ""'"" + version + ""', null)"");
    }
",non-flaky,5
159687,liquibase_liquibase,MarkChangeSetRanExecuteTest.generateSql_update,"    @Test
    public void generateSql_update() throws Exception {
        this.statementUnderTest = new MarkChangeSetRanStatement(new ChangeSet(""a"", ""b"", false, false, ""c"", ""e"", ""f"",
                null), ChangeSet.ExecType.RERAN);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = getdate(), [deployment_id] = null, [exectype] "" +
                        ""= 'reran', [md5sum] = '8:d41d8cd98f00b204e9800998ecf8427e', [orderexecuted] = 2 where [id] ="" +
                        "" 'a' and"" +
                        "" [author] = 'b' and [filename] = 'c'"",
                MSSQLDatabase.class);
        assertCorrect(""update databasechangelog set dateexecuted = systimestamp, deployment_id = null, exectype = "" +
                        ""'reran', md5sum = '8:d41d8cd98f00b204e9800998ecf8427e', orderexecuted = 2 where id = 'a' and"" +
                        "" author "" +
                        ""= 'b' and filename = 'c'"",
                OracleDatabase.class);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = getdate(), [deployment_id] = null, [exectype] "" +
                ""= 'reran', [md5sum] = '8:d41d8cd98f00b204e9800998ecf8427e', [orderexecuted] = 2 where [id] = 'a' and"" +
                "" [author] = 'b' and [filename] = 'c'"", SybaseDatabase.class);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = current year to fraction(5), deployment_id = "" +
                ""null, exectype = 'reran', md5sum = '8:d41d8cd98f00b204e9800998ecf8427e', orderexecuted = 2 where id "" +
                ""= 'a' and author = 'b' and filename = 'c'"", InformixDatabase.class);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = current timestamp, deployment_id = null, "" +
                        ""exectype = 'reran', md5sum = '8:d41d8cd98f00b204e9800998ecf8427e', orderexecuted = 2 where "" +
                        ""id = 'a' and author = 'b' and filename = 'c'"",
                DB2Database.class);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = current_timestamp, deployment_id = null, "" +
                        ""exectype = 'reran', md5sum = '8:d41d8cd98f00b204e9800998ecf8427e', orderexecuted = 2 where "" +
                        ""id = 'a' and author = 'b' and filename = 'c'"",
                FirebirdDatabase.class,
                DerbyDatabase.class);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = NOW(), deployment_id = null, exectype = "" +
                        ""'reran', md5sum = '8:d41d8cd98f00b204e9800998ecf8427e', orderexecuted = 2 where id = 'a' and"" +
                        "" author = 'b' and filename = 'c'"",
                SybaseASADatabase.class);
        assertCorrect(""update [databasechangelog] set [dateexecuted] = NOW(), deployment_id = null, exectype = "" +
                        ""'reran', md5sum = '8:d41d8cd98f00b204e9800998ecf8427e', orderexecuted = 2 where id = 'a' and"" +
                        "" author = 'b' and filename = 'c'"",
                MySQLDatabase.class, MariaDBDatabase.class, HsqlDatabase.class, PostgresDatabase.class, H2Database
                        .class);
        assertCorrectOnRest(""update [databasechangelog] set [dateexecuted] = NOW(), [deployment_id] = null, [exectype] = 'reran', [md5sum] = "" +
                ""'8:d41d8cd98f00b204e9800998ecf8427e', [orderexecuted] = 2 where id = 'a' and author = 'b' and filename = 'c'"");
    }
",non-flaky,5
159688,liquibase_liquibase,CreateDatabaseChangeLogLockTableExecuteTest.generate,"    @Test
    public void generate() throws Exception {
        this.statementUnderTest = new CreateDatabaseChangeLogLockTableStatement();

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime, "" +
                ""[lockedby] text, "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""}, SQLiteDatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] bit not null, "" +
                ""[lockgranted] datetime null, "" +
                ""[lockedby] varchar(255) null, "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""}, SybaseDatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] bit not null, "" +
                ""[lockgranted] datetime null, "" +
                ""[lockedby] varchar(255) null, "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""}, SybaseASADatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime, "" +
                ""[lockedby] varchar(255), "" +
                ""primary key (id))""}, InformixDatabase.class);
    
        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] [int] not null, "" +
                ""[locked] [bit] not null, "" +
                ""[lockgranted] [datetime2](3), "" +
                ""[lockedby] [nvarchar](255), "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""}, MSSQLDatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] integer not null, "" +
                ""[locked] smallint not null, "" +
                ""[lockgranted] timestamp, "" +
                ""[lockedby] varchar(255), "" +
                ""constraint [pk_dbchgloglock] primary key ([id]))""}, DB2Database.class);
    
        assertCorrect(new String[]{""create table databasechangeloglock ("" +
                ""id integer not null, "" +
                ""locked number(1) not null, "" +
                ""lockgranted timestamp, "" +
                ""lockedby varchar2(255), "" +
                ""constraint pk_databasechangeloglock primary key (id))""}, OracleDatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime null, "" +
                ""[lockedby] varchar(255) null, "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""}, MySQLDatabase.class);
    
        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime null, "" +
                ""[lockedby] varchar(255) null, "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""}, MariaDBDatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime, "" +
                ""[lockedby] varchar(255), "" +
                ""constraint [databasechangeloglock_pkey] primary key ([id]))""}, PostgresDatabase.class);

        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime, "" +
                ""[lockedby] varchar(255), "" +
                ""constraint [pk_dbchgloglock] primary key ([id]))""}, Db2zDatabase.class);

        // all other RDBMS
        assertCorrect(new String[]{""create table [databasechangeloglock] ("" +
                ""[id] int not null, "" +
                ""[locked] boolean not null, "" +
                ""[lockgranted] datetime, "" +
                ""[lockedby] varchar(255), "" +
                ""constraint [pk_databasechangeloglock] primary key ([id]))""});

    }
",non-flaky,5
159689,liquibase_liquibase,RenameColumnExecuteTest.noSchema,"    @Test
    public void noSchema() throws Exception {
        this.statementUnderTest = new RenameColumnStatement(null, null, TABLE_NAME, COLUMN_NAME, ""new_name"", ""int"");

        assertCorrect(""rename column table_name.column_name to new_name"", DerbyDatabase.class, InformixDatabase.class);
        assertCorrect(""alter table table_name alter column column_name rename to new_name"", H2Database.class, HsqlDatabase.class);
        assertCorrect(""alter table table_name alter column column_name to new_name"", FirebirdDatabase.class);
        assertCorrect(""alter table table_name change column_name new_name int"", MySQLDatabase.class, MariaDBDatabase.class);
        assertCorrect(""exec sp_rename '[table_name].[column_name]', 'new_name'"", MSSQLDatabase.class);
        assertCorrect(""exec sp_rename 'table_name.column_name', 'new_name'"", SybaseDatabase.class);
        assertCorrect(""alter table [table_name] rename column_name to new_name"",SybaseASADatabase.class);
        assertCorrectOnRest(""alter table [table_name] rename column [column_name] to [new_name]"");
    }
",non-flaky,5
159690,liquibase_liquibase,AddAutoIncrementExecuteTest.noSchema,"    @Test
    public void noSchema() throws Exception {
        this.statementUnderTest = new AddAutoIncrementStatement(null, null, TABLE_NAME, COLUMN_NAME, ""int"", null, null, null, null);

        assertCorrect(""alter table [table_name] modify column_name serial"", PostgresDatabase.class);
        assertCorrect(""alter table table_name modify column_name int auto_increment"", MySQLDatabase.class);
        assertCorrect(""ALTER TABLE [table_name] ALTER COLUMN [column_name] SET GENERATED BY DEFAULT AS IDENTITY"", DB2Database.class);
        assertCorrect(""alter table table_name alter column column_name int generated by default as identity"", HsqlDatabase.class);
        assertCorrect(""alter table table_name alter column column_name int auto_increment"", H2Database.class);

        assertCorrect(""ALTER TABLE [table_name] MODIFY [column_name] serial"", InformixDatabase.class);
        assertCorrect(""ALTER TABLE [table_name] ALTER [column_name] SET DEFAULT AUTOINCREMENT"", SybaseASADatabase.class);
        assertCorrect(""ALTER TABLE [table_name] MODIFY [column_name] int identity"", SybaseDatabase.class);
        assertCorrect(""ALTER TABLE [table_name] ALTER column [column_name] SET GENERATED BY DEFAULT AS IDENTITY"", Db2zDatabase.class);

        assertCorrectOnRest(""ALTER TABLE [table_name] MODIFY [column_name] int AUTO_INCREMENT"");
    }
",non-flaky,5
159691,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_stringDefault,"//    @Test
//    public void execute_stringDefault() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddColumnStatement(null, TABLE_NAME, NEW_COLUMN_NAME, ""varchar(50)"", ""new default"")) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                        assertNotNull(columnSnapshot);
//                        assertEquals(NEW_COLUMN_NAME.toUpperCase(), columnSnapshot.getName().toUpperCase());
//                        assertEquals(""varchar"".toUpperCase(), columnSnapshot.getShortName().toUpperCase().replaceAll(""VARCHAR2"", ""VARCHAR""));
//                        assertEquals(50, columnSnapshot.getColumnSize());
//                        assertEquals(""new default"", columnSnapshot.getDefaultValue());
//
//                        assertEquals(true, columnSnapshot.isNullable());
//                    }
//                });
//    }
",non-flaky,5
159692,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_intDefault,"//    @Test
//    public void execute_intDefault() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddColumnStatement(null, TABLE_NAME, NEW_COLUMN_NAME, ""int"", 42)) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                        assertNotNull(columnSnapshot);
//                        assertEquals(NEW_COLUMN_NAME.toUpperCase(), columnSnapshot.getName().toUpperCase());
//                        if (snapshot.getDatabase() instanceof OracleDatabase) {
//                            assertEquals(""NUMBER"", columnSnapshot.getShortName().toUpperCase());
//                        } else {
//                            assertTrue(columnSnapshot.getShortName().toUpperCase().startsWith(""INT""));
//                        }
//                        assertEquals(42, ((Number) columnSnapshot.getDefaultValue()).intValue());
//
//                        assertEquals(true, columnSnapshot.isNullable());
//                    }
//
//                }
//
//        );
//    }
",non-flaky,5
159693,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_floatDefault,"//    @Test
//    public void execute_floatDefault() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddColumnStatement(null, TABLE_NAME, NEW_COLUMN_NAME, ""float"", 42.5)) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                        assertNotNull(columnSnapshot);
//                        assertEquals(NEW_COLUMN_NAME.toUpperCase(), columnSnapshot.getName().toUpperCase());
//                        assertEquals(new Double(42.5), new Double(((Number) columnSnapshot.getDefaultValue()).doubleValue()));
//
//                        assertEquals(true, columnSnapshot.isNullable());
//                    }
//                });
//    }
",non-flaky,5
159694,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_notNull,"//    @Test
//    public void execute_notNull() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddColumnStatement(null, TABLE_NAME, NEW_COLUMN_NAME, ""int"", 42, new NotNullConstraint())) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                        assertNotNull(columnSnapshot);
//                        assertEquals(false, columnSnapshot.isNullable());
//                    }
//                }
//
//        );
//    }
",non-flaky,5
159695,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_primaryKey_nonAutoIncrement,"//    @Test
//    public void execute_primaryKey_nonAutoIncrement() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddColumnStatement(null, TABLE_NAME, NEW_COLUMN_NAME, ""int"", null, new PrimaryKeyConstraint())) {
//
//                    protected boolean expectedException(Database database, DatabaseException exception) {
//                        return (database instanceof DB2Database
//                                || database instanceof DerbyDatabase
//                                || database instanceof H2Database
//                                || database instanceof CacheDatabase);
//                    }
//
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                        assertNotNull(columnSnapshot);
//                        assertEquals(false, columnSnapshot.isNullable());
//                        assertTrue(columnSnapshot.isPrimaryKey());
//                        assertEquals(false, columnSnapshot.isAutoIncrement());
//                    }
//                });
//    }
",non-flaky,5
159696,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_altSchema,"//    @Test
//    public void execute_altSchema() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(TestContext.ALT_SCHEMA, new AddColumnStatement(TestContext.ALT_SCHEMA, TABLE_NAME, NEW_COLUMN_NAME, ""varchar(50)"", ""new default"")) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                        assertNotNull(columnSnapshot);
//                        assertEquals(NEW_COLUMN_NAME.toUpperCase(), columnSnapshot.getName().toUpperCase());
//                        assertEquals(""new default"", columnSnapshot.getDefaultValue());
//
//                        assertEquals(true, columnSnapshot.isNullable());
//                    }
//
//                });
//    }
",non-flaky,5
159697,liquibase_liquibase,AddAutoIncrementExecuteTest.execute_primaryKeyAutoIncrement,"//    @Test
//      public void execute_primaryKeyAutoIncrement() throws Exception {
//          new DatabaseTestTemplate().testOnAvailableDatabases(
//                  new SqlStatementDatabaseTest(null, new AddColumnStatement(null, TABLE_NAME, NEW_COLUMN_NAME, ""int"", null, new PrimaryKeyConstraint(), new AutoIncrementConstraint())) {
//
//                      protected boolean expectedException(Database database, DatabaseException exception) {
//                          return (database instanceof DB2Database
//                                  || database instanceof DerbyDatabase
//                                  || database instanceof H2Database
//                                  || database instanceof CacheDatabase
//                                    || !database.supportsAutoIncrement());
//                      }
//
//                      protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                          assertNull(snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME));
//                      }
//
//                      protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                          Column columnSnapshot = snapshot.getTable(TABLE_NAME).getColumn(NEW_COLUMN_NAME);
//                          assertNotNull(columnSnapshot);
//                          assertEquals(false, columnSnapshot.isNullable());
//                          assertTrue(columnSnapshot.isPrimaryKey());
//                          assertEquals(true, columnSnapshot.isAutoIncrement());
//                      }
//                  });
//      }
",non-flaky,5
159698,liquibase_liquibase,SelectFromDatabaseChangeLogLockExecutorTest.generateSql,"    @Test
    public void generateSql() throws Exception {
        this.statementUnderTest = new SelectFromDatabaseChangeLogLockStatement(""LOCKED"");
        assertCorrect(""select [locked] from [databasechangeloglock] where [id]=1"", MSSQLDatabase.class, SybaseDatabase.class);
        assertCorrect(""select [locked] from [databasechangeloglock] where [id]=1"", SybaseASADatabase.class);
        assertCorrect(""select [locked] from [databasechangeloglock] where [id]=1 for update"", OracleDatabase.class);
        assertCorrectOnRest(""select [locked] from [databasechangeloglock] where [id]=1"");
    }
",non-flaky,5
159699,liquibase_liquibase,SelectFromDatabaseChangeLogLockExecutorTest.generateSql_count,"    @Test
    public void generateSql_count() throws Exception {
        this.statementUnderTest = new SelectFromDatabaseChangeLogLockStatement(new ColumnConfig().setName(""COUNT(*)"", true));
        assertCorrect(""select count(*) from [databasechangeloglock] where [id]=1"", MSSQLDatabase.class, SybaseDatabase.class);
        assertCorrect(""select count(*) from [databasechangeloglock] where [id]=1"", MSSQLDatabase.class, SybaseASADatabase.class);
        assertCorrect(""select count(*) from [databasechangeloglock] where [id]=1 for update"", OracleDatabase.class);
        assertCorrectOnRest(""select count(*) from [databasechangeloglock] where [id]=1"");
    }
",non-flaky,5
159700,liquibase_liquibase,SelectFromDatabaseChangeLogLockExecutorTest.generateSql_multicolumn,"    @Test
    public void generateSql_multicolumn() throws Exception {
        this.statementUnderTest = new SelectFromDatabaseChangeLogLockStatement(""LOCKED"", ""LOCKEDBY"");
        assertCorrect(""select [locked],[lockedby] from [databasechangeloglock] where [id]=1"", MSSQLDatabase.class, SybaseDatabase.class);
        assertCorrect(""select [locked],[lockedby] from [databasechangeloglock] where [id]=1"", MSSQLDatabase.class, SybaseASADatabase.class);
        assertCorrect(""select [locked],[lockedby] from [databasechangeloglock] where [id]=1 for update"", OracleDatabase.class);
        assertCorrectOnRest(""select [locked],[lockedby] from [databasechangeloglock] where [id]=1"");
    }
",non-flaky,5
159701,liquibase_liquibase,LockServiceExecuteTest.nothing,"    @Test
    public void nothing() {

    }
",non-flaky,5
159702,liquibase_liquibase,LockServiceExecuteTest.performTest,"//    @Test
//    public void waitForLock_twoConnections() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(new DatabaseTest() {
//            public void performTest(Database database) throws Exception {
////                if (database instanceof H2Database) {
////                    return;
////                }
//
//                String url = DatabaseTestContext.getInstance().getTestUrl(database);
//                System.out.println(url);
//                DatabaseConnection connection2 = DatabaseTestContext.getInstance().openDatabaseConnection(url);
//                Database database2 = DatabaseFactory.getInstance().findCorrectDatabaseImplementation(connection2);
//
//                assertTrue(LockService.getInstance(database).acquireLock());
//                assertTrue(LockService.getInstance(database).hasChangeLogLock());
//                assertFalse(LockService.getInstance(database2).hasChangeLogLock());
//
//                assertFalse(LockService.getInstance(database2).acquireLock());
//                assertFalse(LockService.getInstance(database2).acquireLock());
//
//                LockService.getInstance(database).releaseLock();
//                assertTrue(LockService.getInstance(database2).acquireLock());
//
//            }
",non-flaky,5
159703,liquibase_liquibase,LockServiceExecuteTest.performTest,"//    @Test
//    public void waitForLock_severalAquireLocksCalled() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(new DatabaseTest() {
//            public void performTest(Database database) throws Exception {
//                assertTrue(LockService.getInstance(database).acquireLock());
//                assertTrue(LockService.getInstance(database).acquireLock());
//                assertTrue(LockService.getInstance(database).acquireLock());
//                assertTrue(LockService.getInstance(database).acquireLock());
//            }
",non-flaky,5
159704,liquibase_liquibase,LockServiceExecuteTest.performTest,"//    @Test
//    public void waitForLock_emptyDatabase() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new DatabaseTest() {
//
//                    public void performTest(Database database) throws Exception {
//                        Executor executor = ExecutorService.getInstance().getExecutor(database);
//                        try {
//                            LockService.getInstance(database).resetAll();
//
//                            executor.execute(new DropTableStatement(null, database.getDatabaseChangeLogTableName(), false), new ArrayList<SqlVisitor>());
//                        } catch (DatabaseException e) {
//                            ; //must not be there
//                        }
//                        try {
//                            executor.execute(new DropTableStatement(null, database.getDatabaseChangeLogLockTableName(), false), new ArrayList<SqlVisitor>());
//                        } catch (DatabaseException e) {
//                            ; //must not be there
//                        }
//
//                        database.commit();
//
//                        LockService lockManager = LockService.getInstance(database);
//                        lockManager.waitForLock();
//                        lockManager.waitForLock();
//                    }
",non-flaky,5
159705,liquibase_liquibase,LockServiceExecuteTest.performTest,"//    @Test
//    public void waitForLock_loggingDatabase() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new DatabaseTest() {
//
//                    public void performTest(Database database) throws Exception {
//
//                        LockService.getInstance(database).resetAll();
//
//                        Executor executor = ExecutorService.getInstance().getExecutor(database);
//                        try {
//                            executor.execute(new DropTableStatement(null, database.getDatabaseChangeLogTableName(), false), new ArrayList<SqlVisitor>());
//                        } catch (DatabaseException e) {
//                            ; //must not be there
//                        }
//                        try {
//                            executor.execute(new DropTableStatement(null, database.getDatabaseChangeLogLockTableName(), false), new ArrayList<SqlVisitor>());
//                        } catch (DatabaseException e) {
//                            ; //must not be there
//                        }
//
//                        database.commit();
//
//                        ExecutorService.getInstance().setExecutor(database, (new LoggingExecutor(ExecutorService.getInstance().getExecutor(database), new StringWriter(), database)));
//
//                        LockService lockManager = LockService.getInstance(database);
//                        lockManager.waitForLock();
//                    }
",non-flaky,5
159706,liquibase_liquibase,LockServiceExecuteTest.performTest,"//    @Test
//    public void waitForLock_loggingThenExecute() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new DatabaseTest() {
//
//                    public void performTest(Database database) throws Exception {
//
//                        LockService.getInstance(database).resetAll();
//
//                        try {
//                            ExecutorService.getInstance().getExecutor(database).execute(new DropTableStatement(null, database.getDatabaseChangeLogTableName(), false), new ArrayList<SqlVisitor>());
//                        } catch (DatabaseException e) {
//                            ; //must not be there
//                        }
//                        try {
//                            ExecutorService.getInstance().getExecutor(database).execute(new DropTableStatement(null, database.getDatabaseChangeLogLockTableName(), false), new ArrayList<SqlVisitor>());
//                        } catch (DatabaseException e) {
//                            ; //must not be there
//                        }
//
//                        database.commit();
//
////                        Database clearDatabase = database.getClass().getConstructor().newInstance();
////                        clearDatabase.setConnection(database.getConnection());
//
//                        Executor originalTemplate = ExecutorService.getInstance().getExecutor(database);
//                        ExecutorService.getInstance().setExecutor(database, new LoggingExecutor(originalTemplate, new StringWriter(), database));
//
//                        LockService lockManager = LockService.getInstance(database);
//                        lockManager.waitForLock();
//
//                        ExecutorService.getInstance().setExecutor(database, originalTemplate);
//                        lockManager.waitForLock();
//
////                        database.getWriteExecutor().execute(database.getSelectChangeLogLockSQL());
//                    }
",non-flaky,5
159707,liquibase_liquibase,CDILiquibaseTest.shouldntRunWhenShouldRunIsFalse,"    @Test
    public void shouldntRunWhenShouldRunIsFalse() {
        System.setProperty(""liquibase.shouldRun"", ""false"");
        validateRunningState(false);
    }
",non-flaky,5
159708,liquibase_liquibase,CDILiquibaseTest.shouldRunWhenShouldRunIsTrue,"    @Test
    public void shouldRunWhenShouldRunIsTrue() {
        System.setProperty(""liquibase.shouldRun"", ""true"");
        validateRunningState(true);
    }
",non-flaky,5
159709,liquibase_liquibase,CDILiquibaseTest.shouldntRunWhenConfigShouldRunIsFalse,"    @Test
    public void shouldntRunWhenConfigShouldRunIsFalse() {
        System.setProperty(""liquibase.config.shouldRun"", ""false"");
        validateRunningState(false);
    }
",non-flaky,5
159710,liquibase_liquibase,CDILiquibaseTest.shouldRunWhenConfigShouldRunIsTrue,"    @Test
    public void shouldRunWhenConfigShouldRunIsTrue() {
        System.setProperty(""liquibase.config.shouldRun"", ""true"");
        validateRunningState(true);
    }
",non-flaky,5
159711,liquibase_liquibase,SchemesCDIConfigBuilderTest.testCreateCDILiquibaseConfig,"//    @Test
//    public void testCreateCDILiquibaseConfig() throws Exception {
//        Set<Bean<?>> beans = new LinkedHashSet<Bean<?>>();
//        beans.add(mockBean(new A1()));
//        beans.add(mockBean(new B2()));
//
//        when(bm.getBeans(eq(Object.class), eq(new SchemesCDIConfigBuilder.AnnotationLiteralDefault()))).thenReturn(beans);
//
//        CDILiquibaseConfig config = schemesCDIConfigBuilder.createCDILiquibaseConfig();
//
//        Assert.assertNotNull(config);
//        Assert.assertEquals(""liquibase.cdi.schema.xml"", config.getChangeLog());
//    }
",non-flaky,5
170452,eclipse_jetty.project,ObjectMBeanTest.before,"    @BeforeEach
    public void before()
    {
        container = new MBeanContainer(ManagementFactory.getPlatformMBeanServer());
    }
",non-flaky,5
170453,eclipse_jetty.project,ObjectMBeanTest.after,"    @AfterEach
    public void after()
    {
        container.destroy();
        container = null;
    }
",non-flaky,5
170454,eclipse_jetty.project,ObjectMBeanTest.testMBeanForNull,"    @Test
    public void testMBeanForNull()
    {
        Object mBean = container.mbeanFor(null);
        assertNull(mBean);
    }
",non-flaky,5
170455,eclipse_jetty.project,ObjectMBeanTest.testMBeanForString,"    @Test
    public void testMBeanForString()
    {
        String obj = ""foo"";
        Object mbean = container.mbeanFor(obj);
        assertNotNull(mbean);
        container.beanAdded(null, obj);
        ObjectName objectName = container.findMBean(obj);
        assertNotNull(objectName);
    }
",non-flaky,5
170456,eclipse_jetty.project,ObjectMBeanTest.testMBeanForStringArray,"    @Test
    public void testMBeanForStringArray()
    {
        String[] obj = {""a"", ""b""};
        Object mbean = container.mbeanFor(obj);
        assertNotNull(mbean);
        container.beanAdded(null, obj);
        ObjectName objectName = container.findMBean(obj);
        assertNotNull(objectName);
    }
",non-flaky,5
170457,eclipse_jetty.project,ObjectMBeanTest.testMBeanForIntArray,"    @Test
    public void testMBeanForIntArray()
    {
        int[] obj = {0, 1, 2};
        Object mbean = container.mbeanFor(obj);
        assertNotNull(mbean);
        container.beanAdded(null, obj);
        ObjectName objectName = container.findMBean(obj);
        assertNotNull(objectName);
    }
",non-flaky,5
170458,eclipse_jetty.project,ObjectMBeanTest.testMetaDataCaching,"    @Test
    public void testMetaDataCaching()
    {
        Derived derived = new Derived();
        ObjectMBean derivedMBean = (ObjectMBean)container.mbeanFor(derived);
        ObjectMBean derivedMBean2 = (ObjectMBean)container.mbeanFor(derived);
        assertNotSame(derivedMBean, derivedMBean2);
        assertSame(derivedMBean.metaData(), derivedMBean2.metaData());
    }
",non-flaky,5
170459,eclipse_jetty.project,ObjectMBeanTest.testDerivedAttributes,"    @Test
    public void testDerivedAttributes() throws Exception
    {
        Derived derived = new Derived();
        Managed managed = derived.getManagedInstance();
        ObjectMBean derivedMBean = (ObjectMBean)container.mbeanFor(derived);
        ObjectMBean managedMBean = (ObjectMBean)container.mbeanFor(managed);

        container.beanAdded(null, derived);
        container.beanAdded(null, managed);

        MBeanInfo derivedInfo = derivedMBean.getMBeanInfo();
        assertNotNull(derivedInfo);
        MBeanInfo managedInfo = managedMBean.getMBeanInfo();
        assertNotNull(managedInfo);

        assertEquals(""com.acme.Derived"", derivedInfo.getClassName(), ""name does not match"");
        assertEquals(""Test the mbean stuff"", derivedInfo.getDescription(), ""description does not match"");
        assertEquals(5, derivedInfo.getAttributes().length, ""attribute count does not match"");
        assertEquals(""Full Name"", derivedMBean.getAttribute(""fname""), ""attribute values does not match"");

        derivedMBean.setAttribute(new Attribute(""fname"", ""Fuller Name""));
        assertEquals(""Fuller Name"", derivedMBean.getAttribute(""fname""), ""set attribute value does not match"");
        assertEquals(""goop"", derivedMBean.getAttribute(""goop""), ""proxy attribute values do not match"");
    }
",non-flaky,5
170460,eclipse_jetty.project,ObjectMBeanTest.testDerivedOperations,"    @Test
    public void testDerivedOperations() throws Exception
    {
        Derived derived = new Derived();
        ObjectMBean mbean = (ObjectMBean)container.mbeanFor(derived);

        container.beanAdded(null, derived);

        MBeanInfo info = mbean.getMBeanInfo();
        assertEquals(5, info.getOperations().length, ""operation count does not match"");

        MBeanOperationInfo[] operationInfos = info.getOperations();
        boolean publish = false;
        boolean doodle = false;
        boolean good = false;
        for (MBeanOperationInfo operationInfo : operationInfos)
        {
            if (""publish"".equals(operationInfo.getName()))
            {
                publish = true;
                assertEquals(""publish something"", operationInfo.getDescription(), ""description doesn't match"");
            }

            if (""doodle"".equals(operationInfo.getName()))
            {
                doodle = true;
                assertEquals(""Doodle something"", operationInfo.getDescription(), ""description doesn't match"");
                MBeanParameterInfo[] parameterInfos = operationInfo.getSignature();
                assertEquals(""A description of the argument"", parameterInfos[0].getDescription(), ""parameter description doesn't match"");
                assertEquals(""doodle"", parameterInfos[0].getName(), ""parameter name doesn't match"");
            }

            // This is a proxied operation on the MBean wrapper.
            if (""good"".equals(operationInfo.getName()))
            {
                good = true;
                assertEquals(""test of proxy operations"", operationInfo.getDescription(), ""description does not match"");
                assertEquals(""not bad"", mbean.invoke(""good"", new Object[]{}, new String[]{}), ""execution contexts wrong"");
            }
        }

        assertTrue(publish, ""publish operation was not not found"");
        assertTrue(doodle, ""doodle operation was not not found"");
        assertTrue(good, ""good operation was not not found"");
    }
",non-flaky,5
170461,eclipse_jetty.project,ObjectMBeanTest.testMethodNameMining,"    @Test
    public void testMethodNameMining()
    {
        assertEquals(""fullName"", MetaData.toAttributeName(""getFullName""));
        assertEquals(""fullName"", MetaData.toAttributeName(""getfullName""));
        assertEquals(""fullName"", MetaData.toAttributeName(""isFullName""));
        assertEquals(""fullName"", MetaData.toAttributeName(""isfullName""));
        assertEquals(""fullName"", MetaData.toAttributeName(""setFullName""));
        assertEquals(""fullName"", MetaData.toAttributeName(""setfullName""));
        assertEquals(""fullName"", MetaData.toAttributeName(""FullName""));
        assertEquals(""fullName"", MetaData.toAttributeName(""fullName""));
    }
",non-flaky,5
170462,eclipse_jetty.project,MBeanContainerLifeCycleTest.prepare,"    @BeforeEach
    public void prepare() throws Exception
    {
        container = new ContainerLifeCycle();
        mbeanServer = ManagementFactory.getPlatformMBeanServer();
        MBeanContainer mbeanContainer = new MBeanContainer(mbeanServer);
        container.addBean(mbeanContainer);
        container.start();
    }
",non-flaky,5
170463,eclipse_jetty.project,MBeanContainerLifeCycleTest.dispose,"    @AfterEach
    public void dispose() throws Exception
    {
        container.stop();
    }
",non-flaky,5
170464,eclipse_jetty.project,MBeanContainerLifeCycleTest.testAddBeanRegistersMBeanRemoveBeanUnregistersMBean,"    @Test
    public void testAddBeanRegistersMBeanRemoveBeanUnregistersMBean() throws Exception
    {
        // Adding a bean to the container should register the MBean.
        QueuedThreadPool bean = new QueuedThreadPool();
        container.addBean(bean);

        String pkg = bean.getClass().getPackage().getName();
        Set<ObjectName> objectNames = mbeanServer.queryNames(ObjectName.getInstance(pkg + "":*""), null);
        assertEquals(1, objectNames.size());

        // Removing the bean should unregister the MBean.
        container.removeBean(bean);
        objectNames = mbeanServer.queryNames(ObjectName.getInstance(pkg + "":*""), null);
        assertEquals(0, objectNames.size());
    }
",non-flaky,5
170465,eclipse_jetty.project,MBeanContainerLifeCycleTest.testStoppingContainerDoesNotUnregistersMBeans,"    @Test
    public void testStoppingContainerDoesNotUnregistersMBeans() throws Exception
    {
        QueuedThreadPool bean = new QueuedThreadPool();
        container.addBean(bean, true);

        String pkg = bean.getClass().getPackage().getName();
        Set<ObjectName> objectNames = mbeanServer.queryNames(ObjectName.getInstance(pkg + "":*""), null);
        // QueuedThreadPool and ThreadPoolBudget.
        assertEquals(2, objectNames.size());

        container.stop();

        objectNames = mbeanServer.queryNames(ObjectName.getInstance(pkg + "":*""), null);
        assertEquals(2, objectNames.size());

        // Remove the MBeans to start clean on the next test.
        objectNames.forEach(objectName ->
        {
            try
            {
                mbeanServer.unregisterMBean(objectName);
            }
            catch (Throwable ignored)
            {
            }
        });
    }
",non-flaky,5
170466,eclipse_jetty.project,MBeanContainerLifeCycleTest.testDestroyingContainerUnregistersMBeans,"    @Test
    public void testDestroyingContainerUnregistersMBeans() throws Exception
    {
        QueuedThreadPool bean = new QueuedThreadPool();
        container.addBean(bean, true);

        String pkg = bean.getClass().getPackage().getName();
        Set<ObjectName> objectNames = mbeanServer.queryNames(ObjectName.getInstance(pkg + "":*""), null);
        // QueuedThreadPool and ThreadPoolBudget.
        assertEquals(2, objectNames.size());

        container.stop();
        container.destroy();

        objectNames = mbeanServer.queryNames(ObjectName.getInstance(pkg + "":*""), null);
        assertEquals(0, objectNames.size());
    }
",non-flaky,5
170467,eclipse_jetty.project,PojoTest.testOpenPojo,"    @Test
    public void testOpenPojo()
    {
        Validator validator = ValidatorBuilder.create().with(new SetterTester()).with(new GetterTester()).build();
        List<Class> classes = Arrays.asList(MBeanContainer.class, ObjectMBean.class);
        for (Class clazz : classes)
        {
            validator.validate(PojoClassFactory.getPojoClass(clazz));
        }
    }
",non-flaky,5
170468,eclipse_jetty.project,ObjectMBeanUtilTest.setUp,"    @BeforeEach
    public void setUp()
    {
        container = new MBeanContainer(ManagementFactory.getPlatformMBeanServer());
        derivedExtended = new DerivedExtended();
        objectMBean = (ObjectMBean)container.mbeanFor(derivedExtended);
        objectMBeanInfo = objectMBean.getMBeanInfo();
    }
",non-flaky,5
170469,eclipse_jetty.project,ObjectMBeanUtilTest.testBasicOperations,"    @Test
    public void testBasicOperations()
    {
        assertEquals(derivedExtended, objectMBean.getManagedObject(), ""Managed objects should be equal"");
        assertNull(objectMBean.getObjectName(), ""This method call always returns null in the actual code"");
        assertNull(objectMBean.getObjectNameBasis(), ""This method call always returns null in the actual code"");
        assertNull(objectMBean.getObjectContextBasis(), ""This method call always returns null in the actual code"");
        assertEquals(container, objectMBean.getMBeanContainer(), ""Mbean container should be equal"");
        assertEquals(""Test the mbean extended stuff"", objectMBeanInfo.getDescription(), ""Mbean description must be equal to : Test the mbean extended stuff"");
    }
",non-flaky,5
170470,eclipse_jetty.project,ObjectMBeanUtilTest.testGetAttributeMBeanException,"    @Test
    public void testGetAttributeMBeanException() throws Exception
    {
        Attribute attribute = new Attribute(""doodle4"", ""charu"");
        objectMBean.setAttribute(attribute);

        MBeanException e = assertThrows(MBeanException.class, () -> objectMBean.getAttribute(""doodle4""));

        assertNotNull(e, ""An InvocationTargetException must have occurred by now as doodle4() internally throwing exception"");
    }
",non-flaky,5
170471,eclipse_jetty.project,ObjectMBeanUtilTest.testGetAttributeAttributeNotFoundException,"    @Test
    public void testGetAttributeAttributeNotFoundException()
    {
        AttributeNotFoundException e = assertThrows(AttributeNotFoundException.class, () -> objectMBean.getAttribute(""ffname""));

        assertNotNull(e, ""An AttributeNotFoundException must have occurred by now as there is no attribute with the name ffname in bean"");
    }
",non-flaky,5
170472,eclipse_jetty.project,ObjectMBeanUtilTest.testSetAttributeWithCorrectAttrName,"    @Test
    public void testSetAttributeWithCorrectAttrName() throws Exception
    {
        Attribute attribute = new Attribute(""fname"", ""charu"");
        objectMBean.setAttribute(attribute);

        String value = (String)objectMBean.getAttribute(""fname"");

        assertEquals(""charu"", value, ""Attribute(fname) value must be equal to charu"");
    }
",non-flaky,5
170473,eclipse_jetty.project,ObjectMBeanUtilTest.testSetAttributeNullCheck,"    @Test
    public void testSetAttributeNullCheck() throws Exception
    {
        objectMBean.setAttribute(null);

        AttributeNotFoundException e = assertThrows(AttributeNotFoundException.class, () -> objectMBean.getAttribute(null));

        assertNotNull(e, ""An AttributeNotFoundException must have occurred by now as there is no attribute with the name null"");
    }
",non-flaky,5
170474,eclipse_jetty.project,ObjectMBeanUtilTest.testSetAttributeAttributeWithWrongAttrName,"    @Test
    public void testSetAttributeAttributeWithWrongAttrName()
    {
        attribute = new Attribute(""fnameee"", ""charu"");

        AttributeNotFoundException e = assertThrows(AttributeNotFoundException.class, () -> objectMBean.setAttribute(attribute));

        assertNotNull(e, ""An AttributeNotFoundException must have occurred by now as there is no attribute "" + ""with the name ffname in bean"");
    }
",non-flaky,5
170475,eclipse_jetty.project,ObjectMBeanUtilTest.testSetAttributesWithCorrectValues,"    @Test
    public void testSetAttributesWithCorrectValues()
    {
        AttributeList attributes = getAttributes(""fname"", ""vijay"");
        objectMBean.setAttributes(attributes);

        attributes = objectMBean.getAttributes(new String[]{""fname""});

        assertEquals(1, attributes.size());
        assertEquals(""vijay"", ((Attribute)(attributes.get(0))).getValue(), ""Fname value must be equal to vijay"");
    }
",non-flaky,5
170476,eclipse_jetty.project,ObjectMBeanUtilTest.testSetAttributesForArrayTypeAttribute,"    @Test
    public void testSetAttributesForArrayTypeAttribute() throws Exception
    {
        Derived[] deriveds = getArrayTypeAttribute();

        derivedManaged.setAddresses(deriveds);
        mBeanDerivedManaged.getMBeanInfo();

        assertNotNull(mBeanDerivedManaged.getAttribute(""addresses""), ""Address object shouldn't be null"");
    }
",non-flaky,5
170477,eclipse_jetty.project,ObjectMBeanUtilTest.testSetAttributesForCollectionTypeAttribute,"    @Test
    public void testSetAttributesForCollectionTypeAttribute() throws Exception
    {
        ArrayList<Derived> aliasNames = new ArrayList<>(Arrays.asList(getArrayTypeAttribute()));

        derivedManaged.setAliasNames(aliasNames);
        mBeanDerivedManaged.getMBeanInfo();

        assertNotNull(mBeanDerivedManaged.getAttribute(""aliasNames""), ""Address object shouldn't be null"");
        assertNull(mBeanDerivedManaged.getAttribute(""derived""), ""Derived object shouldn't registered with container so its value will be null"");
    }
",non-flaky,5
170478,eclipse_jetty.project,ObjectMBeanUtilTest.testSetAttributesException,"    @Test
    public void testSetAttributesException()
    {
        AttributeList attributes = getAttributes(""fnameee"", ""charu"");

        attributes = objectMBean.setAttributes(attributes);

        // Original code eating the exception and returning zero size list
        assertEquals(0, attributes.size(), ""As there is no attribute with the name fnameee, this should return empty"");
    }
",non-flaky,5
170479,eclipse_jetty.project,ObjectMBeanUtilTest.testInvokeMBeanException,"    @Test
    public void testInvokeMBeanException()
    {
        ReflectionException e = assertThrows(ReflectionException.class, () -> objectMBean.invoke(""doodle2"", new Object[0], new String[0]));

        assertNotNull(e, ""An ReflectionException must have occurred by now as doodle2() in Derived bean is private"");
    }
",non-flaky,5
170480,eclipse_jetty.project,ObjectMBeanUtilTest.testInvokeReflectionException,"    @Test
    public void testInvokeReflectionException()
    {
        MBeanException e = assertThrows(MBeanException.class, () -> objectMBean.invoke(""doodle1"", new Object[0], new String[0]));

        assertNotNull(e, ""MBeanException is null"");
    }
",non-flaky,5
170481,eclipse_jetty.project,ObjectMBeanUtilTest.testInvoke,"    @Test
    public void testInvoke() throws Exception
    {
        String value = (String)objectMBean.invoke(""good"", new Object[0], new String[0]);

        assertEquals(""not bad"", value, ""Method(good) invocation on objectMBean must return not bad"");
    }
",non-flaky,5
170482,eclipse_jetty.project,ObjectMBeanUtilTest.testInvokeNoSuchMethodException,"    @Test
    public void testInvokeNoSuchMethodException()
    {
        // DerivedMBean contains a managed method with the name good,
        // we must call this method without any arguments.
        ReflectionException e = assertThrows(ReflectionException.class, () ->
            objectMBean.invoke(""good"", new Object[0], new String[]{
                ""int aone""
            }));

        assertNotNull(e, ""A ReflectionException must have occurred by now as we cannot call a method with wrong signature"");
    }
",non-flaky,5
170483,eclipse_jetty.project,ObjectMBeanUtilTest.testToAttributeName,"    @Test
    public void testToAttributeName()
    {
        assertEquals(""fullName"", MetaData.toAttributeName(""isfullName""));
    }
",non-flaky,5
170484,eclipse_jetty.project,ConnectorServerTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception
    {
        if (connectorServer != null)
            connectorServer.stop();
    }
",non-flaky,5
170485,eclipse_jetty.project,ConnectorServerTest.testAddressAfterStart,"    @Test
    public void testAddressAfterStart() throws Exception
    {
        connectorServer = new ConnectorServer(new JMXServiceURL(""service:jmx:rmi:///jndi/rmi:///jmxrmi""), objectName);
        connectorServer.start();

        JMXServiceURL address = connectorServer.getAddress();
        assertTrue(address.toString().matches(""service:jmx:rmi://[^:]+:\\d+/jndi/rmi://[^:]+:\\d+/jmxrmi""));
    }
",non-flaky,5
170486,eclipse_jetty.project,ConnectorServerTest.testNoRegistryHostBindsToHost,"    @Test
    public void testNoRegistryHostBindsToHost() throws Exception
    {
        connectorServer = new ConnectorServer(new JMXServiceURL(""service:jmx:rmi:///jndi/rmi:///jmxrmi""), objectName);
        connectorServer.start();

        // Verify that I can connect to the RMI registry using a non-loopback address.
        new Socket(InetAddress.getLocalHost(), 1099).close();
        assertThrows(ConnectException.class, () ->
        {
            // Verify that I cannot connect to the RMI registry using the loopback address.
            new Socket(InetAddress.getLoopbackAddress(), 1099).close();
        });
    }
",non-flaky,5
170487,eclipse_jetty.project,ConnectorServerTest.testNoRegistryHostNonDefaultRegistryPort,"    @Test
    public void testNoRegistryHostNonDefaultRegistryPort() throws Exception
    {
        ServerSocket serverSocket = new ServerSocket(0);
        int registryPort = serverSocket.getLocalPort();
        serverSocket.close();
        connectorServer = new ConnectorServer(new JMXServiceURL(""service:jmx:rmi:///jndi/rmi://:"" + registryPort + ""/jmxrmi""), objectName);
        connectorServer.start();

        // Verify that I can connect to the RMI registry using a non-loopback address.
        new Socket(InetAddress.getLocalHost(), registryPort).close();
        assertThrows(ConnectException.class, () ->
        {
            // Verify that I cannot connect to the RMI registry using the loopback address.
            new Socket(InetAddress.getLoopbackAddress(), registryPort).close();
        });
    }
",non-flaky,5
170488,eclipse_jetty.project,ConnectorServerTest.testAnyRegistryHostBindsToAny,"    @Test
    public void testAnyRegistryHostBindsToAny() throws Exception
    {
        ServerSocket serverSocket = new ServerSocket(0);
        int registryPort = serverSocket.getLocalPort();
        serverSocket.close();
        connectorServer = new ConnectorServer(new JMXServiceURL(""service:jmx:rmi:///jndi/rmi://0.0.0.0:"" + registryPort + ""/jmxrmi""), objectName);
        connectorServer.start();

        // Verify that I can connect to the RMI registry using a non-loopback address.
        new Socket(InetAddress.getLocalHost(), registryPort).close();
        // Verify that I can connect to the RMI registry using the loopback address.
        new Socket(InetAddress.getLoopbackAddress(), registryPort).close();
    }
",non-flaky,5
170489,eclipse_jetty.project,ConnectorServerTest.testLocalhostRegistryBindsToLoopback,"    @Test
    public void testLocalhostRegistryBindsToLoopback() throws Exception
    {
        connectorServer = new ConnectorServer(new JMXServiceURL(""service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi""), objectName);
        connectorServer.start();

        InetAddress localHost = InetAddress.getLocalHost();
        if (!localHost.isLoopbackAddress())
        {
            assertThrows(ConnectException.class, () ->
            {
                // Verify that I cannot connect to the RMIRegistry using a non-loopback address.
                new Socket(localHost, 1099);
            });
        }

        InetAddress loopback = InetAddress.getLoopbackAddress();
        new Socket(loopback, 1099).close();
    }
",non-flaky,5
170490,eclipse_jetty.project,ConnectorServerTest.testNoRMIHostBindsToHost,"    @Test
    public void testNoRMIHostBindsToHost() throws Exception
    {
        connectorServer = new ConnectorServer(new JMXServiceURL(""service:jmx:rmi:///jndi/rmi:///jmxrmi""), objectName);
        connectorServer.start();

        // Verify that I can connect to the RMI server using a non-loopback address.
        new Socket(InetAddress.getLocalHost(), connectorServer.getAddress().getPort()).close();
        assertThrows(ConnectException.class, () ->
        {
            // Verify that I cannot connect to the RMI server using the loopback address.
            new Socket(InetAddress.getLoopbackAddress(), connectorServer.getAddress().getPort()).close();
        });
    }
",non-flaky,5
170491,eclipse_jetty.project,ConnectorServerTest.testAnyRMIHostBindsToAny,"    @Test
    public void testAnyRMIHostBindsToAny() throws Exception
    {
        connectorServer = new ConnectorServer(new JMXServiceURL(""service:jmx:rmi://0.0.0.0/jndi/rmi:///jmxrmi""), objectName);
        connectorServer.start();

        // Verify that I can connect to the RMI server using a non-loopback address.
        new Socket(InetAddress.getLocalHost(), connectorServer.getAddress().getPort()).close();
        // Verify that I can connect to the RMI server using the loopback address.
        new Socket(InetAddress.getLoopbackAddress(), connectorServer.getAddress().getPort()).close();
    }
",non-flaky,5
170492,eclipse_jetty.project,ConnectorServerTest.testLocalhostRMIBindsToLoopback,"    @Test
    public void testLocalhostRMIBindsToLoopback() throws Exception
    {
        connectorServer = new ConnectorServer(new JMXServiceURL(""service:jmx:rmi://localhost/jndi/rmi://localhost:1099/jmxrmi""), objectName);
        connectorServer.start();
        JMXServiceURL address = connectorServer.getAddress();

        InetAddress localHost = InetAddress.getLocalHost();
        if (!localHost.isLoopbackAddress())
        {
            assertThrows(ConnectException.class, () ->
            {
                // Verify that I cannot connect to the RMIRegistry using a non-loopback address.
                new Socket(localHost, address.getPort());
            });
        }

        InetAddress loopback = InetAddress.getLoopbackAddress();
        new Socket(loopback, address.getPort()).close();
    }
",non-flaky,5
170493,eclipse_jetty.project,ConnectorServerTest.testRMIServerPort,"    @Test
    public void testRMIServerPort() throws Exception
    {
        ServerSocket server = new ServerSocket(0);
        int port = server.getLocalPort();
        server.close();

        connectorServer = new ConnectorServer(new JMXServiceURL(""service:jmx:rmi://localhost:"" + port + ""/jndi/rmi:///jmxrmi""), objectName);
        connectorServer.start();

        JMXServiceURL address = connectorServer.getAddress();
        assertEquals(port, address.getPort());

        InetAddress loopback = InetAddress.getLoopbackAddress();
        new Socket(loopback, port).close();
    }
",non-flaky,5
170494,eclipse_jetty.project,ConnectorServerTest.testRMIServerAndRMIRegistryOnSameHostAndSamePort,"    @Test
    public void testRMIServerAndRMIRegistryOnSameHostAndSamePort() throws Exception
    {
        // RMI can multiplex connections on the same address and port for different
        // RMI objects, in this case the RMI registry and the RMI server. In this
        // case, the RMIServerSocketFactory will be invoked only once.
        // The case with different address and same port is already covered by TCP,
        // that can listen to 192.168.0.1:1099 and 127.0.0.1:1099 without problems.

        String host = ""localhost"";
        ServerSocket serverSocket = new ServerSocket(0);
        int port = serverSocket.getLocalPort();
        serverSocket.close();

        connectorServer = new ConnectorServer(new JMXServiceURL(""rmi"", host, port, ""/jndi/rmi://"" + host + "":"" + port + ""/jmxrmi""), objectName);
        connectorServer.start();

        JMXServiceURL address = connectorServer.getAddress();
        assertEquals(port, address.getPort());
    }
",non-flaky,5
170495,eclipse_jetty.project,ConnectorServerTest.testJMXOverTLS,"    @Test
    public void testJMXOverTLS() throws Exception
    {
        SslContextFactory.Server sslContextFactory = new SslContextFactory.Server();
        String keyStorePath = MavenTestingUtils.getTestResourcePath(""keystore.p12"").toString();
        String keyStorePassword = ""storepwd"";
        sslContextFactory.setKeyStorePath(keyStorePath);
        sslContextFactory.setKeyStorePassword(keyStorePassword);
        sslContextFactory.start();

        // The RMIClientSocketFactory is stored within the RMI stub.
        // When using TLS, the stub is deserialized in a possibly different
        // JVM that does not have access to the server keystore, and there
        // is no way to provide TLS configuration during the deserialization
        // of the stub. Therefore the client must provide system properties
        // to specify the TLS configuration. For this test it needs the
        // trustStore because the server certificate is self-signed.
        // The server needs to contact the RMI registry and therefore also
        // needs these system properties.
        System.setProperty(""javax.net.ssl.trustStore"", keyStorePath);
        System.setProperty(""javax.net.ssl.trustStorePassword"", keyStorePassword);

        connectorServer = new ConnectorServer(new JMXServiceURL(""rmi"", null, 1100, ""/jndi/rmi://localhost:1100/jmxrmi""), null, objectName, sslContextFactory);
        connectorServer.start();

        // The client needs to talk TLS to the RMI registry to download
        // the RMI server stub, and this is independent from JMX.
        // The RMI server stub then contains the SslRMIClientSocketFactory
        // needed to talk to the RMI server.
        Map<String, Object> clientEnv = new HashMap<>();
        clientEnv.put(ConnectorServer.RMI_REGISTRY_CLIENT_SOCKET_FACTORY_ATTRIBUTE, new SslRMIClientSocketFactory());
        try (JMXConnector client = JMXConnectorFactory.connect(connectorServer.getAddress(), clientEnv))
        {
            client.getMBeanServerConnection().queryNames(null, null);
        }
    }
",non-flaky,5
170496,eclipse_jetty.project,MBeanContainerTest.setUp,"    @BeforeEach
    public void setUp()
    {
        mbeanServer = ManagementFactory.getPlatformMBeanServer();
        mbeanContainer = new MBeanContainer(mbeanServer);
    }
",non-flaky,5
170497,eclipse_jetty.project,MBeanContainerTest.testMakeName,"    @Test
    public void testMakeName()
    {
        beanName = ""mngd:bean"";

        beanName = mbeanContainer.makeName(beanName);

        assertEquals(""mngd_bean"", beanName, ""Bean name should be mngd_bean"");
    }
",non-flaky,5
170498,eclipse_jetty.project,MBeanContainerTest.testFindBean,"    @Test
    public void testFindBean()
    {
        managed = getManaged();

        objectName = mbeanContainer.findMBean(managed);
        assertNotNull(objectName);

        assertEquals(managed, mbeanContainer.findBean(objectName), ""Bean must be added"");
        assertNull(mbeanContainer.findBean(null), ""It must return null as there is no bean with the name null"");
    }
",non-flaky,5
170499,eclipse_jetty.project,MBeanContainerTest.testMBeanContainer,"    @Test
    public void testMBeanContainer()
    {
        assertNotNull(mbeanContainer, ""Container shouldn't be null"");
    }
",non-flaky,5
170500,eclipse_jetty.project,MBeanContainerTest.testGetMBeanServer,"    @Test
    public void testGetMBeanServer()
    {
        assertEquals(mbeanServer, mbeanContainer.getMBeanServer(), ""MBean server Instance must be equal"");
    }
",non-flaky,5
170501,eclipse_jetty.project,MBeanContainerTest.testDomain,"    @Test
    public void testDomain()
    {
        String domain = ""Test"";

        mbeanContainer.setDomain(domain);

        assertEquals(domain, mbeanContainer.getDomain(), ""Domain name must be Test"");
    }
",non-flaky,5
170502,eclipse_jetty.project,MBeanContainerTest.testBeanAdded,"    @Test
    public void testBeanAdded()
    {
        setBeanAdded();

        objectName = mbeanContainer.findMBean(managed);

        assertTrue(mbeanServer.isRegistered(objectName), ""Bean must have been registered"");
    }
",non-flaky,5
170503,eclipse_jetty.project,MBeanContainerTest.testBeanAddedNullCheck,"    @Test
    public void testBeanAddedNullCheck()
    {
        setBeanAdded();
        Integer mbeanCount = mbeanServer.getMBeanCount();

        mbeanContainer.beanAdded(null, null);

        assertEquals(mbeanCount, mbeanServer.getMBeanCount(), ""MBean count must not change after beanAdded(null, null) call"");
    }
",non-flaky,5
170504,eclipse_jetty.project,MBeanContainerTest.testBeanRemoved,"    @Test
    public void testBeanRemoved()
    {
        setUpBeanRemoved();

        mbeanContainer.beanRemoved(null, managed);

        assertNull(mbeanContainer.findMBean(managed), ""Bean shouldn't be registered with container as we removed the bean"");
    }
",non-flaky,5
170505,eclipse_jetty.project,MBeanContainerTest.testBeanRemovedInstanceNotFoundException,"    @Test
    public void testBeanRemovedInstanceNotFoundException() throws Exception
    {
        // given
        setUpBeanRemoved();
        objectName = mbeanContainer.findMBean(managed);

        // when
        mbeanContainer.getMBeanServer().unregisterMBean(objectName);

        // then
        assertFalse(mbeanServer.isRegistered(objectName), ""Bean must not have been registered as we unregistered the bean"");
        // this flow covers InstanceNotFoundException. Actual code just eating
        // the exception. i.e Actual code just printing the stacktrace, whenever
        // an exception of type InstanceNotFoundException occurs.
        mbeanContainer.beanRemoved(null, managed);
    }
",non-flaky,5
170506,eclipse_jetty.project,MBeanContainerTest.testDump,"    @Test
    public void testDump()
    {
        assertNotNull(mbeanContainer.dump(), ""Dump operation shouldn't return null if operation is success"");
    }
",non-flaky,5
170507,eclipse_jetty.project,MBeanContainerTest.testDestroy,"    @Test
    public void testDestroy()
    {
        setUpDestroy();

        objectName = mbeanContainer.findMBean(managed);
        mbeanContainer.destroy();

        assertFalse(mbeanContainer.getMBeanServer().isRegistered(objectName), ""Unregistered bean - managed"");
    }
",non-flaky,5
170508,eclipse_jetty.project,MBeanContainerTest.testDestroyInstanceNotFoundException,"    @Test
    public void testDestroyInstanceNotFoundException() throws Exception
    {
        setUpDestroy();

        objectName = mbeanContainer.findMBean(managed);
        mbeanContainer.getMBeanServer().unregisterMBean(objectName);

        assertFalse(mbeanContainer.getMBeanServer().isRegistered(objectName), ""Unregistered bean - managed"");
        // this flow covers InstanceNotFoundException. Actual code just eating
        // the exception. i.e Actual code just printing the stacktrace, whenever
        // an exception of type InstanceNotFoundException occurs.
        mbeanContainer.destroy();
    }
",non-flaky,5
170509,eclipse_jetty.project,MBeanContainerTest.testNonManagedLifecycleNotUnregistered,"    @Test
    public void testNonManagedLifecycleNotUnregistered() throws Exception
    {
        testNonManagedObjectNotUnregistered(new ContainerLifeCycle());
    }
",non-flaky,5
170510,eclipse_jetty.project,MBeanContainerTest.testNonManagedPojoNotUnregistered,"    @Test
    public void testNonManagedPojoNotUnregistered() throws Exception
    {
        testNonManagedObjectNotUnregistered(new Object());
    }
",non-flaky,5
170511,eclipse_jetty.project,TestAnnotationParser.handle,"    @Test
    public void testSampleAnnotation() throws Exception
    {
        String[] classNames = new String[]{""org.eclipse.jetty.annotations.ClassA""};
        AnnotationParser parser = new AnnotationParser();

        class SampleAnnotationHandler extends AnnotationParser.AbstractHandler
        {
            private List<String> methods = Arrays.asList(""a"", ""b"", ""c"", ""d"", ""l"");

            @Override
            public void handle(ClassInfo info, String annotation)
            {
                if (annotation == null || !""org.eclipse.jetty.annotations.Sample"".equals(annotation))
                    return;

                assertEquals(""org.eclipse.jetty.annotations.ClassA"", info.getClassName());
            }
",non-flaky,5
170512,eclipse_jetty.project,TestAnnotationParser.handle,"    @Test
    public void testMultiAnnotation() throws Exception
    {
        String[] classNames = new String[]{""org.eclipse.jetty.annotations.ClassB""};
        AnnotationParser parser = new AnnotationParser();

        class MultiAnnotationHandler extends AnnotationParser.AbstractHandler
        {
            @Override
            public void handle(ClassInfo info, String annotation)
            {
                if (annotation == null || !""org.eclipse.jetty.annotations.Multi"".equals(annotation))
                    return;
                assertTrue(""org.eclipse.jetty.annotations.ClassB"".equals(info.getClassName()));
            }
",non-flaky,5
170513,eclipse_jetty.project,TestAnnotationParser.testHiddenFilesInJar,"    @Test
    public void testHiddenFilesInJar() throws Exception
    {
        File badClassesJar = MavenTestingUtils.getTestResourceFile(""bad-classes.jar"");
        AnnotationParser parser = new AnnotationParser();
        Set<Handler> emptySet = Collections.emptySet();
        parser.parse(emptySet, badClassesJar.toURI());
        // only the valid classes inside bad-classes.jar should be parsed. If any invalid classes are parsed and exception would be thrown here
    }
",non-flaky,5
170514,eclipse_jetty.project,TestAnnotationParser.testModuleInfoClassInJar,"    @Test
    public void testModuleInfoClassInJar() throws Exception
    {
        File badClassesJar = MavenTestingUtils.getTestResourceFile(""jdk9/slf4j-api-1.8.0-alpha2.jar"");
        AnnotationParser parser = new AnnotationParser();
        Set<Handler> emptySet = Collections.emptySet();
        parser.parse(emptySet, badClassesJar.toURI());
        // Should throw no exceptions, and happily skip the module-info.class files
    }
",non-flaky,5
170515,eclipse_jetty.project,TestAnnotationParser.testJep238MultiReleaseInJar,"    @Test
    public void testJep238MultiReleaseInJar() throws Exception
    {
        File badClassesJar = MavenTestingUtils.getTestResourceFile(""jdk9/log4j-api-2.9.0.jar"");
        AnnotationParser parser = new AnnotationParser();
        Set<Handler> emptySet = Collections.emptySet();
        parser.parse(emptySet, badClassesJar.toURI());
        // Should throw no exceptions, and skip the META-INF/versions/9/* files
    }
",non-flaky,5
170516,eclipse_jetty.project,TestAnnotationParser.testJep238MultiReleaseInJarJDK10,"    @Test
    public void testJep238MultiReleaseInJarJDK10() throws Exception
    {
        File jdk10Jar = MavenTestingUtils.getTestResourceFile(""jdk10/multirelease-10.jar"");
        AnnotationParser parser = new AnnotationParser();
        DuplicateClassScanHandler handler = new DuplicateClassScanHandler();
        Set<Handler> handlers = Collections.singleton(handler);
        parser.parse(handlers, new PathResource(jdk10Jar));
        // Should throw no exceptions
    }
",non-flaky,5
170517,eclipse_jetty.project,TestAnnotationParser.testBasedirExclusion,"    @Test
    public void testBasedirExclusion() throws Exception
    {
        // Build up basedir, which itself has a path segment that violates java package and classnaming.
        // The basedir should have no effect on annotation scanning.
        // Intentionally using a base director name that starts with a "".""
        // This mimics what you see in jenkins, hudson, hadoop, solr, camel, and selenium for their 
        // installed and/or managed webapps
        File basedir = testdir.getPathFile("".base/workspace/classes"").toFile();
        FS.ensureEmpty(basedir);

        // Copy in class that is known to have annotations.
        copyClass(ClassA.class, basedir);

        // Setup Tracker
        TrackingAnnotationHandler tracker = new TrackingAnnotationHandler(Sample.class.getName());

        // Setup annotation scanning
        AnnotationParser parser = new AnnotationParser();

        // Parse
        parser.parse(Collections.singleton(tracker), basedir.toURI());

        // Validate
        assertThat(""Found Class"", tracker.foundClasses, contains(ClassA.class.getName()));
    }
",non-flaky,5
170518,eclipse_jetty.project,TestAnnotationParser.testScanDuplicateClassesInJars,"    @Test
    public void testScanDuplicateClassesInJars() throws Exception
    {
        Resource testJar = Resource.newResource(MavenTestingUtils.getTestResourceFile(""tinytest.jar""));
        Resource testJar2 = Resource.newResource(MavenTestingUtils.getTestResourceFile(""tinytest_copy.jar""));
        AnnotationParser parser = new AnnotationParser();
        DuplicateClassScanHandler handler = new DuplicateClassScanHandler();
        Set<Handler> handlers = Collections.singleton(handler);
        parser.parse(handlers, testJar);
        parser.parse(handlers, testJar2);
        List<String> locations = handler.getParsedList(""org.acme.ClassOne"");
        assertNotNull(locations);
        assertEquals(2, locations.size());
        assertTrue(!(locations.get(0).equals(locations.get(1))));
    }
",non-flaky,5
170519,eclipse_jetty.project,TestAnnotationParser.testScanDuplicateClasses,"    @Test
    public void testScanDuplicateClasses() throws Exception
    {
        Resource testJar = Resource.newResource(MavenTestingUtils.getTestResourceFile(""tinytest.jar""));
        File testClasses = new File(MavenTestingUtils.getTargetDir(), ""test-classes"");
        AnnotationParser parser = new AnnotationParser();
        DuplicateClassScanHandler handler = new DuplicateClassScanHandler();
        Set<Handler> handlers = Collections.singleton(handler);
        parser.parse(handlers, testJar);
        parser.parse(handlers, Resource.newResource(testClasses));
        List<String> locations = handler.getParsedList(""org.acme.ClassOne"");
        assertNotNull(locations);
        assertEquals(2, locations.size());
        assertTrue(!(locations.get(0).equals(locations.get(1))));
    }
",non-flaky,5
170520,eclipse_jetty.project,TestAnnotationConfiguration.setup,"    @BeforeEach
    public void setup() throws Exception
    {
        web25 = MavenTestingUtils.getTestResourceFile(""web25.xml"");
        web31false = MavenTestingUtils.getTestResourceFile(""web31false.xml"");
        web31true = MavenTestingUtils.getTestResourceFile(""web31true.xml"");

        // prepare an sci that will be on the webapp's classpath
        jarDir = new File(MavenTestingUtils.getTestResourcesDir().getParentFile(), ""jar"");
        testSciJar = new File(jarDir, ""test-sci.jar"");
        assertTrue(testSciJar.exists());

        testContainerSciJar = new File(jarDir, ""test-sci-for-container-path.jar"");
        testWebInfClassesJar = new File(jarDir, ""test-sci-for-webinf.jar"");

        // unpack some classes to pretend that are in WEB-INF/classes
        unpacked = new File(MavenTestingUtils.getTargetTestingDir(), ""test-sci-for-webinf"");
        unpacked.mkdirs();
        FS.cleanDirectory(unpacked);
        JAR.unpack(testWebInfClassesJar, unpacked);
        webInfClasses = Resource.newResource(unpacked);

        containerLoader = new URLClassLoader(new URL[]{
            testContainerSciJar.toURI().toURL()
        }, Thread.currentThread().getContextClassLoader());

        targetClasses = Resource.newResource(MavenTestingUtils.getTargetDir().toURI()).addPath(""/test-classes"");

        classes = Arrays.asList(new Resource[]{webInfClasses, targetClasses});

        webAppLoader = new URLClassLoader(new URL[]{
            testSciJar.toURI().toURL(), targetClasses.getURI().toURL(), webInfClasses.getURI().toURL()
        },
            containerLoader);
    }
",non-flaky,5
170521,eclipse_jetty.project,TestAnnotationConfiguration.testAnnotationScanControl,"    @Test
    public void testAnnotationScanControl() throws Exception
    {
        //check that a 2.5 webapp with configurationDiscovered will discover annotations
        TestableAnnotationConfiguration config25 = new TestableAnnotationConfiguration();
        WebAppContext context25 = new WebAppContext();
        context25.setClassLoader(Thread.currentThread().getContextClassLoader());
        context25.setAttribute(AnnotationConfiguration.MULTI_THREADED, Boolean.FALSE);
        context25.setAttribute(AnnotationConfiguration.MAX_SCAN_WAIT, 0);
        context25.setConfigurationDiscovered(false);
        context25.getMetaData().setWebDescriptor(new WebDescriptor(Resource.newResource(web25)));
        context25.getServletContext().setEffectiveMajorVersion(2);
        context25.getServletContext().setEffectiveMinorVersion(5);
        config25.configure(context25);
        config25.assertAnnotationDiscovery(false);

        //check that a 2.5 webapp discover annotations
        TestableAnnotationConfiguration config25b = new TestableAnnotationConfiguration();
        WebAppContext context25b = new WebAppContext();
        context25b.setClassLoader(Thread.currentThread().getContextClassLoader());
        context25b.setAttribute(AnnotationConfiguration.MULTI_THREADED, Boolean.FALSE);
        context25b.setAttribute(AnnotationConfiguration.MAX_SCAN_WAIT, 0);
        context25b.getMetaData().setWebDescriptor(new WebDescriptor(Resource.newResource(web25)));
        context25b.getServletContext().setEffectiveMajorVersion(2);
        context25b.getServletContext().setEffectiveMinorVersion(5);
        config25b.configure(context25b);
        config25b.assertAnnotationDiscovery(true);

        //check that a 3.x webapp with metadata true won't discover annotations
        TestableAnnotationConfiguration config31 = new TestableAnnotationConfiguration();
        WebAppContext context31 = new WebAppContext();
        context31.setClassLoader(Thread.currentThread().getContextClassLoader());
        context31.setAttribute(AnnotationConfiguration.MULTI_THREADED, Boolean.FALSE);
        context31.setAttribute(AnnotationConfiguration.MAX_SCAN_WAIT, 0);
        context31.getMetaData().setWebDescriptor(new WebDescriptor(Resource.newResource(web31true)));
        context31.getServletContext().setEffectiveMajorVersion(3);
        context31.getServletContext().setEffectiveMinorVersion(1);
        config31.configure(context31);
        config31.assertAnnotationDiscovery(false);

        //check that a 3.x webapp with metadata false will discover annotations
        TestableAnnotationConfiguration config31b = new TestableAnnotationConfiguration();
        WebAppContext context31b = new WebAppContext();
        context31b.setClassLoader(Thread.currentThread().getContextClassLoader());
        context31b.setAttribute(AnnotationConfiguration.MULTI_THREADED, Boolean.FALSE);
        context31b.setAttribute(AnnotationConfiguration.MAX_SCAN_WAIT, 0);
        context31b.getMetaData().setWebDescriptor(new WebDescriptor(Resource.newResource(web31false)));
        context31b.getServletContext().setEffectiveMajorVersion(3);
        context31b.getServletContext().setEffectiveMinorVersion(1);
        config31b.configure(context31b);
        config31b.assertAnnotationDiscovery(true);
    }
",non-flaky,5
170522,eclipse_jetty.project,TestAnnotationConfiguration.testServerAndWebappSCIs,"    @Test
    public void testServerAndWebappSCIs() throws Exception
    {
        ClassLoader old = Thread.currentThread().getContextClassLoader();
        Thread.currentThread().setContextClassLoader(webAppLoader);

        try
        {
            AnnotationConfiguration config = new AnnotationConfiguration();
            WebAppContext context = new WebAppContext();
            List<ServletContainerInitializer> scis;

            //test 3.1 webapp loads both server and app scis
            context.setClassLoader(webAppLoader);
            context.getMetaData().addWebInfResource(Resource.newResource(testSciJar.toURI().toURL()));
            context.getMetaData().setWebDescriptor(new WebDescriptor(Resource.newResource(web31true)));
            context.getMetaData().setWebInfClassesResources(classes);
            context.getServletContext().setEffectiveMajorVersion(3);
            context.getServletContext().setEffectiveMinorVersion(1);
            scis = config.getNonExcludedInitializers(context);
            assertNotNull(scis);
            assertEquals(3, scis.size());
            assertEquals(""com.acme.ServerServletContainerInitializer"", scis.get(0).getClass().getName()); //container path
            assertEquals(""com.acme.webinf.WebInfClassServletContainerInitializer"", scis.get(1).getClass().getName()); // web-inf
            assertEquals(""com.acme.initializer.FooInitializer"", scis.get(2).getClass().getName()); //web-inf jar no web-fragment
        }
        finally
        {
            Thread.currentThread().setContextClassLoader(old);
        }
    }
",non-flaky,5
170523,eclipse_jetty.project,TestAnnotationConfiguration.createServletContainerInitializerAnnotationHandlers,"    @Test
    public void testClassScanHandlersForSCIs() throws Exception
    {
        //test that SCIs with a @HandlesTypes that is an annotation registers
        //handlers for the scanning phase that will capture the class hierarchy,
        //and also capture all classes that contain the annotation
        ClassLoader old = Thread.currentThread().getContextClassLoader();
        Thread.currentThread().setContextClassLoader(webAppLoader);

        try
        {
            class MyAnnotationConfiguration extends AnnotationConfiguration
            {

                @Override
                public void createServletContainerInitializerAnnotationHandlers(WebAppContext context, List<ServletContainerInitializer> scis) throws Exception
                {
                    super.createServletContainerInitializerAnnotationHandlers(context, scis);
                    //check class hierarchy scanner handler is registered
                    assertNotNull(_classInheritanceHandler);
                    //check 
                    assertEquals(1, _containerInitializerAnnotationHandlers.size());
                    ContainerInitializerAnnotationHandler handler = _containerInitializerAnnotationHandlers.get(0);
                    assertThat(handler._holder.toString(), containsString(""com.acme.initializer.FooInitializer""));
                    assertEquals(""com.acme.initializer.Foo"", handler._annotation.getName());
                }
",non-flaky,5
170524,eclipse_jetty.project,TestAnnotationConfiguration.testMetaDataCompleteSCIs,"    @Test
    public void testMetaDataCompleteSCIs() throws Exception
    {
        ClassLoader old = Thread.currentThread().getContextClassLoader();
        Thread.currentThread().setContextClassLoader(webAppLoader);

        try
        {
            AnnotationConfiguration config = new AnnotationConfiguration();
            WebAppContext context = new WebAppContext();
            List<ServletContainerInitializer> scis;
            // test a 3.1 webapp with metadata-complete=false loads both server
            // and webapp scis
            context.setClassLoader(webAppLoader);
            context.getMetaData().setWebDescriptor(new WebDescriptor(Resource.newResource(web31false)));
            context.getMetaData().setWebInfClassesResources(classes);
            context.getMetaData().addWebInfResource(Resource.newResource(testSciJar.toURI().toURL()));
            context.getServletContext().setEffectiveMajorVersion(3);
            context.getServletContext().setEffectiveMinorVersion(1);
            scis = config.getNonExcludedInitializers(context);
            assertNotNull(scis);
            assertEquals(3, scis.size());
            assertEquals(""com.acme.ServerServletContainerInitializer"", scis.get(0).getClass().getName()); // container
            // path
            assertEquals(""com.acme.webinf.WebInfClassServletContainerInitializer"", scis.get(1).getClass().getName()); // web-inf
            assertEquals(""com.acme.initializer.FooInitializer"", scis.get(2).getClass().getName()); // web-inf
            // jar
            // no
            // web-fragment
        }
        finally
        {
            Thread.currentThread().setContextClassLoader(old);
        }
    }
",non-flaky,5
170525,eclipse_jetty.project,TestAnnotationConfiguration.testRelativeOrderingWithSCIs,"    @Test
    public void testRelativeOrderingWithSCIs() throws Exception
    {
        // test a 3.1 webapp with RELATIVE ORDERING loads sci from
        // equivalent of WEB-INF/classes first as well as container path

        ClassLoader old = Thread.currentThread().getContextClassLoader();

        File orderedFragmentJar = new File(jarDir, ""test-sci-with-ordering.jar"");
        assertTrue(orderedFragmentJar.exists());
        URLClassLoader orderedLoader = new URLClassLoader(new URL[]{
            orderedFragmentJar.toURI().toURL(), testSciJar.toURI().toURL(),
            targetClasses.getURI().toURL(), webInfClasses.getURI().toURL()
        },
            containerLoader);
        Thread.currentThread().setContextClassLoader(orderedLoader);

        try
        {
            AnnotationConfiguration config = new AnnotationConfiguration();
            WebAppContext context = new WebAppContext();
            List<ServletContainerInitializer> scis;
            context.setClassLoader(orderedLoader);
            context.getMetaData().setWebDescriptor(new WebDescriptor(Resource.newResource(web31true)));
            RelativeOrdering ordering = new RelativeOrdering(context.getMetaData());
            context.getMetaData().setOrdering(ordering);
            context.getMetaData().addWebInfResource(Resource.newResource(orderedFragmentJar.toURI().toURL()));
            context.getMetaData().addWebInfResource(Resource.newResource(testSciJar.toURI().toURL()));
            context.getMetaData().setWebInfClassesResources(classes);
            context.getMetaData().orderFragments();
            context.getServletContext().setEffectiveMajorVersion(3);
            context.getServletContext().setEffectiveMinorVersion(1);
            scis = config.getNonExcludedInitializers(context);
            assertNotNull(scis);
            assertEquals(4, scis.size());
            assertEquals(""com.acme.ServerServletContainerInitializer"", scis.get(0).getClass().getName()); //container path
            assertEquals(""com.acme.webinf.WebInfClassServletContainerInitializer"", scis.get(1).getClass().getName()); // web-inf
            assertEquals(""com.acme.ordering.AcmeServletContainerInitializer"", scis.get(2).getClass().getName()); // first
            assertEquals(""com.acme.initializer.FooInitializer"", scis.get(3).getClass().getName()); //other in ordering
        }
        finally
        {
            Thread.currentThread().setContextClassLoader(old);
        }
    }
",non-flaky,5
170526,eclipse_jetty.project,TestAnnotationConfiguration.testDiscoveredFalseWithSCIs,"    @Test
    public void testDiscoveredFalseWithSCIs() throws Exception
    {
        ClassLoader old = Thread.currentThread().getContextClassLoader();
        Thread.currentThread().setContextClassLoader(webAppLoader);
        try
        {
            //test 2.5 webapp with configurationDiscovered=false loads only server scis
            AnnotationConfiguration config = new AnnotationConfiguration();
            WebAppContext context = new WebAppContext();
            List<ServletContainerInitializer> scis;
            context.setConfigurationDiscovered(false);
            context.setClassLoader(webAppLoader);
            context.getMetaData().setWebDescriptor(new WebDescriptor(Resource.newResource(web25)));
            context.getMetaData().setWebInfClassesResources(classes);
            context.getMetaData().addWebInfResource(Resource.newResource(testSciJar.toURI().toURL()));
            context.getServletContext().setEffectiveMajorVersion(2);
            context.getServletContext().setEffectiveMinorVersion(5);
            scis = config.getNonExcludedInitializers(context);
            assertNotNull(scis);
            for (ServletContainerInitializer s : scis)
            {
                //should not have any of the web-inf lib scis in here
                assertFalse(s.getClass().getName().equals(""com.acme.ordering.AcmeServletContainerInitializer""));
                assertFalse(s.getClass().getName().equals(""com.acme.initializer.FooInitializer""));
                //NOTE: should also not have the web-inf classes scis in here either, but due to the
                //way the test is set up, the sci we're pretending is in web-inf classes will actually
                //NOT be loaded by the webapp's classloader, but rather by the junit classloader, so
                //it looks as if it is a container class.
            }
        }
        finally
        {
            Thread.currentThread().setContextClassLoader(old);
        }
    }
",non-flaky,5
170527,eclipse_jetty.project,TestAnnotationConfiguration.testDiscoveredTrueWithSCIs,"    @Test
    public void testDiscoveredTrueWithSCIs() throws Exception
    {
        ClassLoader old = Thread.currentThread().getContextClassLoader();
        Thread.currentThread().setContextClassLoader(webAppLoader);
        try
        {
            //test 2.5 webapp with configurationDiscovered=true loads both server and webapp scis
            AnnotationConfiguration config = new AnnotationConfiguration();
            WebAppContext context = new WebAppContext();
            List<ServletContainerInitializer> scis;
            context.setConfigurationDiscovered(true);
            context.setClassLoader(webAppLoader);
            context.getMetaData().setWebDescriptor(new WebDescriptor(Resource.newResource(web25)));
            context.getMetaData().setWebInfClassesResources(classes);
            context.getMetaData().addWebInfResource(Resource.newResource(testSciJar.toURI().toURL()));
            context.getServletContext().setEffectiveMajorVersion(2);
            context.getServletContext().setEffectiveMinorVersion(5);
            scis = config.getNonExcludedInitializers(context);
            assertNotNull(scis);
            assertEquals(3, scis.size());
            assertEquals(""com.acme.ServerServletContainerInitializer"", scis.get(0).getClass().getName()); //container path
            assertEquals(""com.acme.webinf.WebInfClassServletContainerInitializer"", scis.get(1).getClass().getName()); // web-inf
            assertEquals(""com.acme.initializer.FooInitializer"", scis.get(2).getClass().getName()); //web-inf jar no web-fragment
        }
        finally
        {
            Thread.currentThread().setContextClassLoader(old);
        }
    }
",non-flaky,5
170528,eclipse_jetty.project,TestSecurityAnnotationConversions.testDenyAllOnClass,"    @Test
    public void testDenyAllOnClass() throws Exception
    {

        WebAppContext wac = makeWebAppContext(DenyServlet.class.getCanonicalName(), ""denyServlet"", new String[]{
            ""/foo/*"", ""*.foo""
        });

        //Assume we found 1 servlet with a @HttpConstraint with value=EmptyRoleSemantic.DENY security annotation
        ServletSecurityAnnotationHandler annotationHandler = new ServletSecurityAnnotationHandler(wac);
        AnnotationIntrospector introspector = new AnnotationIntrospector(wac);
        introspector.registerHandler(annotationHandler);

        //set up the expected outcomes:
        //1 ConstraintMapping per ServletMapping pathSpec
        Constraint expectedConstraint = new Constraint();
        expectedConstraint.setAuthenticate(true);
        expectedConstraint.setDataConstraint(Constraint.DC_NONE);

        ConstraintMapping[] expectedMappings = new ConstraintMapping[2];

        expectedMappings[0] = new ConstraintMapping();
        expectedMappings[0].setConstraint(expectedConstraint);
        expectedMappings[0].setPathSpec(""/foo/*"");

        expectedMappings[1] = new ConstraintMapping();
        expectedMappings[1].setConstraint(expectedConstraint);
        expectedMappings[1].setPathSpec(""*.foo"");

        introspector.introspect(new DenyServlet(), null);

        compareResults(expectedMappings, ((ConstraintAware)wac.getSecurityHandler()).getConstraintMappings());
    }
",non-flaky,5
170529,eclipse_jetty.project,TestSecurityAnnotationConversions.testPermitAll,"    @Test
    public void testPermitAll() throws Exception
    {
        //Assume we found 1 servlet with a @ServletSecurity security annotation
        WebAppContext wac = makeWebAppContext(PermitServlet.class.getCanonicalName(), ""permitServlet"", new String[]{
            ""/foo/*"", ""*.foo""
        });

        ServletSecurityAnnotationHandler annotationHandler = new ServletSecurityAnnotationHandler(wac);
        AnnotationIntrospector introspector = new AnnotationIntrospector(wac);
        introspector.registerHandler(annotationHandler);

        //set up the expected outcomes - no constraints at all as per Servlet Spec 3.1 pg 129
        //1 ConstraintMapping per ServletMapping pathSpec

        ConstraintMapping[] expectedMappings = new ConstraintMapping[]{};
        PermitServlet permit = new PermitServlet();
        introspector.introspect(permit, null);

        compareResults(expectedMappings, ((ConstraintAware)wac.getSecurityHandler()).getConstraintMappings());
    }
",non-flaky,5
170530,eclipse_jetty.project,TestSecurityAnnotationConversions.testRolesAllowedWithTransportGuarantee,"    @Test
    public void testRolesAllowedWithTransportGuarantee() throws Exception
    {
        //Assume we found 1 servlet with annotation with roles defined and
        //and a TransportGuarantee

        WebAppContext wac = makeWebAppContext(RolesServlet.class.getCanonicalName(), ""rolesServlet"", new String[]{
            ""/foo/*"", ""*.foo""
        });

        ServletSecurityAnnotationHandler annotationHandler = new ServletSecurityAnnotationHandler(wac);
        AnnotationIntrospector introspector = new AnnotationIntrospector(wac);
        introspector.registerHandler(annotationHandler);

        //set up the expected outcomes:compareResults
        //1 ConstraintMapping per ServletMapping
        Constraint expectedConstraint = new Constraint();
        expectedConstraint.setAuthenticate(true);
        expectedConstraint.setRoles(new String[]{""tom"", ""dick"", ""harry""});
        expectedConstraint.setDataConstraint(Constraint.DC_CONFIDENTIAL);

        ConstraintMapping[] expectedMappings = new ConstraintMapping[2];
        expectedMappings[0] = new ConstraintMapping();
        expectedMappings[0].setConstraint(expectedConstraint);
        expectedMappings[0].setPathSpec(""/foo/*"");

        expectedMappings[1] = new ConstraintMapping();
        expectedMappings[1].setConstraint(expectedConstraint);
        expectedMappings[1].setPathSpec(""*.foo"");
        introspector.introspect(new RolesServlet(), null);
        compareResults(expectedMappings, ((ConstraintAware)wac.getSecurityHandler()).getConstraintMappings());
    }
",non-flaky,5
170531,eclipse_jetty.project,TestSecurityAnnotationConversions.testMethodAnnotation,"    @Test
    public void testMethodAnnotation() throws Exception
    {
        //ServletSecurity annotation with HttpConstraint of TransportGuarantee.CONFIDENTIAL, and a list of rolesAllowed, and
        //an HttpMethodConstraint for GET method that permits all and has TransportGuarantee.NONE (ie is default)

        WebAppContext wac = makeWebAppContext(Method1Servlet.class.getCanonicalName(), ""method1Servlet"", new String[]{
            ""/foo/*"", ""*.foo""
        });

        //set up the expected outcomes: - a Constraint for the RolesAllowed on the class
        //with userdata constraint of DC_CONFIDENTIAL
        //and mappings for each of the pathSpecs
        Constraint expectedConstraint1 = new Constraint();
        expectedConstraint1.setAuthenticate(true);
        expectedConstraint1.setRoles(new String[]{""tom"", ""dick"", ""harry""});
        expectedConstraint1.setDataConstraint(Constraint.DC_CONFIDENTIAL);

        //a Constraint for the PermitAll on the doGet method with a userdata
        //constraint of DC_CONFIDENTIAL inherited from the class
        Constraint expectedConstraint2 = new Constraint();
        expectedConstraint2.setDataConstraint(Constraint.DC_NONE);

        ConstraintMapping[] expectedMappings = new ConstraintMapping[4];
        expectedMappings[0] = new ConstraintMapping();
        expectedMappings[0].setConstraint(expectedConstraint1);
        expectedMappings[0].setPathSpec(""/foo/*"");
        expectedMappings[0].setMethodOmissions(new String[]{""GET""});
        expectedMappings[1] = new ConstraintMapping();
        expectedMappings[1].setConstraint(expectedConstraint1);
        expectedMappings[1].setPathSpec(""*.foo"");
        expectedMappings[1].setMethodOmissions(new String[]{""GET""});

        expectedMappings[2] = new ConstraintMapping();
        expectedMappings[2].setConstraint(expectedConstraint2);
        expectedMappings[2].setPathSpec(""/foo/*"");
        expectedMappings[2].setMethod(""GET"");
        expectedMappings[3] = new ConstraintMapping();
        expectedMappings[3].setConstraint(expectedConstraint2);
        expectedMappings[3].setPathSpec(""*.foo"");
        expectedMappings[3].setMethod(""GET"");

        AnnotationIntrospector introspector = new AnnotationIntrospector(wac);
        ServletSecurityAnnotationHandler annotationHandler = new ServletSecurityAnnotationHandler(wac);
        introspector.registerHandler(annotationHandler);
        introspector.introspect(new Method1Servlet(), null);
        compareResults(expectedMappings, ((ConstraintAware)wac.getSecurityHandler()).getConstraintMappings());
    }
",non-flaky,5
170532,eclipse_jetty.project,TestSecurityAnnotationConversions.testMethodAnnotation2,"    @Test
    public void testMethodAnnotation2() throws Exception
    {
        //A ServletSecurity annotation that has HttpConstraint of CONFIDENTIAL with defined roles, but a
        //HttpMethodConstraint for GET that permits all, but also requires CONFIDENTIAL
        WebAppContext wac = makeWebAppContext(Method2Servlet.class.getCanonicalName(), ""method2Servlet"", new String[]{
            ""/foo/*"", ""*.foo""
        });

        AnnotationIntrospector introspector = new AnnotationIntrospector(wac);
        ServletSecurityAnnotationHandler annotationHandler = new ServletSecurityAnnotationHandler(wac);
        introspector.registerHandler(annotationHandler);

        //set up the expected outcomes: - a Constraint for the RolesAllowed on the class
        //with userdata constraint of DC_CONFIDENTIAL
        //and mappings for each of the pathSpecs
        Constraint expectedConstraint1 = new Constraint();
        expectedConstraint1.setAuthenticate(true);
        expectedConstraint1.setRoles(new String[]{""tom"", ""dick"", ""harry""});
        expectedConstraint1.setDataConstraint(Constraint.DC_CONFIDENTIAL);

        //a Constraint for the Permit on the GET method with a userdata
        //constraint of DC_CONFIDENTIAL
        Constraint expectedConstraint2 = new Constraint();
        expectedConstraint2.setDataConstraint(Constraint.DC_CONFIDENTIAL);

        ConstraintMapping[] expectedMappings = new ConstraintMapping[4];
        expectedMappings[0] = new ConstraintMapping();
        expectedMappings[0].setConstraint(expectedConstraint1);
        expectedMappings[0].setPathSpec(""/foo/*"");
        expectedMappings[0].setMethodOmissions(new String[]{""GET""});
        expectedMappings[1] = new ConstraintMapping();
        expectedMappings[1].setConstraint(expectedConstraint1);
        expectedMappings[1].setPathSpec(""*.foo"");
        expectedMappings[1].setMethodOmissions(new String[]{""GET""});

        expectedMappings[2] = new ConstraintMapping();
        expectedMappings[2].setConstraint(expectedConstraint2);
        expectedMappings[2].setPathSpec(""/foo/*"");
        expectedMappings[2].setMethod(""GET"");
        expectedMappings[3] = new ConstraintMapping();
        expectedMappings[3].setConstraint(expectedConstraint2);
        expectedMappings[3].setPathSpec(""*.foo"");
        expectedMappings[3].setMethod(""GET"");

        introspector.introspect(new Method2Servlet(), null);
        compareResults(expectedMappings, ((ConstraintAware)wac.getSecurityHandler()).getConstraintMappings());
    }
",non-flaky,5
170533,eclipse_jetty.project,TestAnnotationDecorator.testAnnotationDecorator,"    @Test
    public void testAnnotationDecorator() throws Exception
    {
        assertThrows(NullPointerException.class, () ->
        {
            new AnnotationDecorator(null);
        });

        WebAppContext context = new WebAppContext();
        AnnotationDecorator decorator = new AnnotationDecorator(context);
        ServletE servlet = new ServletE();
        //test without BaseHolder metadata
        decorator.decorate(servlet);
        LifeCycleCallbackCollection callbacks = (LifeCycleCallbackCollection)context.getAttribute(LifeCycleCallbackCollection.LIFECYCLE_CALLBACK_COLLECTION);
        assertNotNull(callbacks);
        assertFalse(callbacks.getPreDestroyCallbacks().isEmpty());

        //reset
        context.removeAttribute(LifeCycleCallbackCollection.LIFECYCLE_CALLBACK_COLLECTION);

        //test with BaseHolder metadata, should not introspect with metdata-complete==true
        context.getMetaData().setWebDescriptor(new TestWebDescriptor(MetaData.Complete.True));
        assertTrue(context.getMetaData().isMetaDataComplete());
        ServletHolder holder = new ServletHolder(new Source(Source.Origin.DESCRIPTOR, """"));
        holder.setHeldClass(ServletE.class);
        context.getServletHandler().addServlet(holder);
        DecoratedObjectFactory.associateInfo(holder);
        decorator = new AnnotationDecorator(context);
        decorator.decorate(servlet);
        DecoratedObjectFactory.disassociateInfo();
        callbacks = (LifeCycleCallbackCollection)context.getAttribute(LifeCycleCallbackCollection.LIFECYCLE_CALLBACK_COLLECTION);
        assertNull(callbacks);

        //reset
        context.removeAttribute(LifeCycleCallbackCollection.LIFECYCLE_CALLBACK_COLLECTION);

        //test with BaseHolder metadata, should introspect with metadata-complete==false
        context.getMetaData().setWebDescriptor(new TestWebDescriptor(MetaData.Complete.False));
        DecoratedObjectFactory.associateInfo(holder);
        decorator = new AnnotationDecorator(context);
        decorator.decorate(servlet);
        DecoratedObjectFactory.disassociateInfo();
        callbacks = (LifeCycleCallbackCollection)context.getAttribute(LifeCycleCallbackCollection.LIFECYCLE_CALLBACK_COLLECTION);
        assertNotNull(callbacks);
        assertFalse(callbacks.getPreDestroyCallbacks().isEmpty());
    }
",non-flaky,5
170534,eclipse_jetty.project,TestAnnotationInheritance.destroy,"    @AfterEach
    public void destroy() throws Exception
    {
        classNames.clear();
        InitialContext ic = new InitialContext();
        Context comp = (Context)ic.lookup(""java:comp"");
        comp.destroySubcontext(""env"");
    }
",non-flaky,5
170535,eclipse_jetty.project,TestAnnotationInheritance.testParseClassNames,"    @Test
    public void testParseClassNames() throws Exception
    {
        classNames.add(ClassA.class.getName());
        classNames.add(ClassB.class.getName());

        SampleHandler handler = new SampleHandler();
        AnnotationParser parser = new AnnotationParser();
        parser.parse(Collections.singleton(handler), classNames);

        //check we got  2 class annotations
        assertEquals(2, handler.annotatedClassNames.size());

        //check we got all annotated methods on each class
        assertEquals(7, handler.annotatedMethods.size());
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.a""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.b""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.c""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.d""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.l""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassB.a""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassB.c""));

        //check we got all annotated fields on each class
        assertEquals(1, handler.annotatedFields.size());
        assertEquals(""org.eclipse.jetty.annotations.ClassA.m"", handler.annotatedFields.get(0));
    }
",non-flaky,5
170536,eclipse_jetty.project,TestAnnotationInheritance.testParseClass,"    @Test
    public void testParseClass() throws Exception
    {
        SampleHandler handler = new SampleHandler();
        AnnotationParser parser = new AnnotationParser();
        parser.parse(Collections.singleton(handler), ClassB.class, true);

        //check we got  2 class annotations
        assertEquals(2, handler.annotatedClassNames.size());

        //check we got all annotated methods on each class
        assertEquals(7, handler.annotatedMethods.size());
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.a""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.b""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.c""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.d""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.l""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassB.a""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassB.c""));

        //check we got all annotated fields on each class
        assertEquals(1, handler.annotatedFields.size());
        assertEquals(""org.eclipse.jetty.annotations.ClassA.m"", handler.annotatedFields.get(0));
    }
",non-flaky,5
170537,eclipse_jetty.project,TestAnnotationInheritance.testTypeInheritanceHandling,"    @Test
    public void testTypeInheritanceHandling() throws Exception
    {
        Map<String, Set<String>> map = new ConcurrentHashMap<>();

        AnnotationParser parser = new AnnotationParser();
        ClassInheritanceHandler handler = new ClassInheritanceHandler(map);

        class Foo implements InterfaceD
        {
        }

        classNames.clear();
        classNames.add(ClassA.class.getName());
        classNames.add(ClassB.class.getName());
        classNames.add(InterfaceD.class.getName());
        classNames.add(Foo.class.getName());

        parser.parse(Collections.singleton(handler), classNames);

        assertNotNull(map);
        assertFalse(map.isEmpty());
        assertEquals(2, map.size());

        assertThat(map, hasKey(""org.eclipse.jetty.annotations.ClassA""));
        assertThat(map, hasKey(""org.eclipse.jetty.annotations.InterfaceD""));
        Set<String> classes = map.get(""org.eclipse.jetty.annotations.ClassA"");
        assertThat(classes, contains(""org.eclipse.jetty.annotations.ClassB""));

        classes = map.get(""org.eclipse.jetty.annotations.InterfaceD"");
        assertThat(classes, containsInAnyOrder(""org.eclipse.jetty.annotations.ClassB"",
            Foo.class.getName()));
    }
",non-flaky,5
170538,eclipse_jetty.project,TestAnnotationIntrospector.testIsIntrospectable,"    @Test
    public void testIsIntrospectable() throws Exception
    {
        try (StacklessLogging ignore = new StacklessLogging(AnnotationIntrospector.class))
        {
            WebAppContext wac = new WebAppContext();
            AnnotationIntrospector introspector = new AnnotationIntrospector(wac);
            //can't introspect nothing
            assertFalse(introspector.isIntrospectable(null, null));

            //can introspect if no metadata to say otherwise
            assertTrue(introspector.isIntrospectable(new Object(), null));

            //can introspect if metdata isn't a BaseHolder
            assertTrue(introspector.isIntrospectable(new Object(), new Object()));

            //an EMBEDDED sourced servlet can be introspected
            ServletHolder holder = new ServletHolder();
            holder.setHeldClass(ServletE.class);
            assertTrue(introspector.isIntrospectable(new ServletE(), holder));

            //a JAVAX API sourced servlet can be introspected
            holder = new ServletHolder(Source.JAVAX_API);
            holder.setHeldClass(ServletE.class);
            assertTrue(introspector.isIntrospectable(new ServletE(), holder));

            //an ANNOTATION sourced servlet can be introspected
            holder = new ServletHolder(new Source(Source.Origin.ANNOTATION, ServletE.class.getName()));
            holder.setHeldClass(ServletE.class);
            assertTrue(introspector.isIntrospectable(new ServletE(), holder));

            //a DESCRIPTOR sourced servlet can be introspected if web.xml metdata-complete==false
            File file = MavenTestingUtils.getTestResourceFile(""web31false.xml"");
            Resource resource = Resource.newResource(file);
            wac.getMetaData().setWebDescriptor(new WebDescriptor(resource));
            holder = new ServletHolder(new Source(Source.Origin.DESCRIPTOR, resource.toString()));
            assertTrue(introspector.isIntrospectable(new ServletE(), holder));

            //a DESCRIPTOR sourced servlet can be introspected if web-fragment.xml medata-complete==false && web.xml metadata-complete==false
            file = MavenTestingUtils.getTestResourceFile(""web-fragment4false.xml"");
            resource = Resource.newResource(file);
            wac.getMetaData().addFragmentDescriptor(Resource.newResource(file.getParentFile()), new FragmentDescriptor(resource));
            holder = new ServletHolder(new Source(Source.Origin.DESCRIPTOR, resource.toString()));
            assertTrue(introspector.isIntrospectable(new ServletE(), holder));

            //a DESCRIPTOR sourced servlet cannot be introspected if web-fragment.xml medata-complete==true (&& web.xml metadata-complete==false)
            file = MavenTestingUtils.getTestResourceFile(""web-fragment4true.xml"");
            resource = Resource.newResource(file);
            wac.getMetaData().addFragmentDescriptor(Resource.newResource(file.getParentFile()), new FragmentDescriptor(resource));
            holder = new ServletHolder(new Source(Source.Origin.DESCRIPTOR, resource.toString()));
            assertFalse(introspector.isIntrospectable(new ServletE(), holder));

            //a DESCRIPTOR sourced servlet cannot be introspected if web.xml medata-complete==true
            file = MavenTestingUtils.getTestResourceFile(""web31true.xml"");
            resource = Resource.newResource(file);
            wac.getMetaData().setWebDescriptor(new WebDescriptor(resource));
            holder = new ServletHolder(new Source(Source.Origin.DESCRIPTOR, resource.toString()));
            assertFalse(introspector.isIntrospectable(new ServletE(), holder));
        }
    }
",non-flaky,5
170539,eclipse_jetty.project,TestDiscoveredServletContainerInitializerHolder.test,"    @Test
    public void test() throws Exception
    {
        //SCI with @HandlesTypes[Ordinary, Sample]
        SampleServletContainerInitializer sci = new SampleServletContainerInitializer();
        
        DiscoveredServletContainerInitializerHolder holder = 
            new DiscoveredServletContainerInitializerHolder(new Source(Source.Origin.ANNOTATION, sci.getClass().getName()),
            sci);

        //add the @HandlesTypes to the holder
        holder.addStartupClasses(Ordinary.class, Sample.class);
        
        //pretend scanned and discovered that ASample has the Sample annotation
        holder.addStartupClasses(ASample.class.getName());
        
        //pretend we scanned the entire class hierarchy and found:
        //   com.acme.tom and com.acme.dick both extend Ordinary
        //   ASample has subclass BSample
        Map<String, Set<String>> classMap = new HashMap<>();
        classMap.put(Ordinary.class.getName(), new HashSet(Arrays.asList(""com.acme.tom"", ""com.acme.dick"")));
        classMap.put(ASample.class.getName(), new HashSet(Arrays.asList(BSample.class.getName())));
        holder.resolveClasses(classMap);
        
        //we should now have the following classes that will be passed to the SampleServletContainerInitializer.onStartup
        String toString = holder.toString();
        assertThat(toString, containsString(""com.acme.tom""));
        assertThat(toString, containsString(""com.acme.dick""));
        assertThat(toString, containsString(ASample.class.getName()));
        assertThat(toString, containsString(BSample.class.getName()));
        assertThat(toString, containsString(""applicable=[],annotated=[]""));
    }
",non-flaky,5
170540,eclipse_jetty.project,TestServletAnnotations.testServletAnnotation,"    @Test
    public void testServletAnnotation() throws Exception
    {
        List<String> classes = new ArrayList<String>();
        classes.add(""org.eclipse.jetty.annotations.ServletC"");
        AnnotationParser parser = new AnnotationParser();

        WebAppContext wac = new WebAppContext();
        List<DiscoveredAnnotation> results = new ArrayList<DiscoveredAnnotation>();

        TestWebServletAnnotationHandler handler = new TestWebServletAnnotationHandler(wac, results);

        parser.parse(Collections.singleton(handler), classes);

        assertEquals(1, results.size());
        assertTrue(results.get(0) instanceof WebServletAnnotation);

        results.get(0).apply();

        ServletHolder[] holders = wac.getServletHandler().getServlets();
        assertNotNull(holders);
        assertEquals(1, holders.length);

        // Verify servlet annotations
        ServletHolder cholder = holders[0];
        assertThat(""Servlet Name"", cholder.getName(), is(""CServlet""));
        assertThat(""InitParameter[x]"", cholder.getInitParameter(""x""), is(""y""));
        assertThat(""Init Order"", cholder.getInitOrder(), is(2));
        assertThat(""Async Supported"", cholder.isAsyncSupported(), is(false));

        // Verify mappings
        ServletMapping[] mappings = wac.getServletHandler().getServletMappings();
        assertNotNull(mappings);
        assertEquals(1, mappings.length);
        String[] paths = mappings[0].getPathSpecs();
        assertNotNull(paths);
        assertEquals(2, paths.length);
    }
",non-flaky,5
170541,eclipse_jetty.project,TestServletAnnotations.testWebServletAnnotationOverrideDefault,"    @Test
    public void testWebServletAnnotationOverrideDefault() throws Exception
    {
        //if the existing servlet mapping TO A DIFFERENT SERVLET IS from a default descriptor we
        //DO allow the annotation to replace the mapping.

        WebAppContext wac = new WebAppContext();
        ServletHolder defaultServlet = new ServletHolder();
        defaultServlet.setClassName(""org.eclipse.jetty.servlet.DefaultServlet"");
        defaultServlet.setName(""default"");
        wac.getServletHandler().addServlet(defaultServlet);

        ServletMapping m = new ServletMapping();
        m.setPathSpec(""/"");
        m.setServletName(""default"");
        m.setFromDefaultDescriptor(true);  //this mapping will be from a default descriptor
        wac.getServletHandler().addServletMapping(m);

        WebServletAnnotation annotation = new WebServletAnnotation(wac, ""org.eclipse.jetty.annotations.ServletD"", null);
        annotation.apply();

        //test that as the original servlet mapping had only 1 pathspec, then the whole
        //servlet mapping should be deleted as that pathspec will be remapped to the DServlet
        ServletMapping[] resultMappings = wac.getServletHandler().getServletMappings();
        assertNotNull(resultMappings);
        assertEquals(1, resultMappings.length);
        assertEquals(2, resultMappings[0].getPathSpecs().length);
        resultMappings[0].getServletName().equals(""DServlet"");
        for (String s : resultMappings[0].getPathSpecs())
        {
            assertThat(s, anyOf(is(""/""), is(""/bah/*"")));
        }
    }
",non-flaky,5
170542,eclipse_jetty.project,TestServletAnnotations.testWebServletAnnotationReplaceDefault,"    @Test
    public void testWebServletAnnotationReplaceDefault() throws Exception
    {
        //if the existing servlet mapping TO A DIFFERENT SERVLET IS from a default descriptor we
        //DO allow the annotation to replace the mapping.
        WebAppContext wac = new WebAppContext();
        ServletHolder defaultServlet = new ServletHolder();
        defaultServlet.setClassName(""org.eclipse.jetty.servlet.DefaultServlet"");
        defaultServlet.setName(""default"");
        wac.getServletHandler().addServlet(defaultServlet);

        ServletMapping m = new ServletMapping();
        m.setPathSpec(""/"");
        m.setServletName(""default"");
        m.setFromDefaultDescriptor(true);  //this mapping will be from a default descriptor
        wac.getServletHandler().addServletMapping(m);

        ServletMapping m2 = new ServletMapping();
        m2.setPathSpec(""/other"");
        m2.setServletName(""default"");
        m2.setFromDefaultDescriptor(true);  //this mapping will be from a default descriptor
        wac.getServletHandler().addServletMapping(m2);

        WebServletAnnotation annotation = new WebServletAnnotation(wac, ""org.eclipse.jetty.annotations.ServletD"", null);
        annotation.apply();

        //test that only the mapping for ""/"" was removed from the mappings to the default servlet
        ServletMapping[] resultMappings = wac.getServletHandler().getServletMappings();
        assertNotNull(resultMappings);
        assertEquals(2, resultMappings.length);
        for (ServletMapping r : resultMappings)
        {
            if (r.getServletName().equals(""default""))
            {
                assertEquals(1, r.getPathSpecs().length);
                assertEquals(""/other"", r.getPathSpecs()[0]);
            }
            else if (r.getServletName().equals(""DServlet""))
            {
                assertEquals(2, r.getPathSpecs().length);
                for (String p : r.getPathSpecs())
                {
                    if (!p.equals(""/"") && !p.equals(""/bah/*""))
                        fail(""Unexpected path"");
                }
            }
            else
                fail(""Unexpected servlet mapping: "" + r);
        }
    }
",non-flaky,5
170543,eclipse_jetty.project,TestServletAnnotations.testWebServletAnnotationNotOverride,"    @Test
    public void testWebServletAnnotationNotOverride() throws Exception
    {
        //if the existing servlet mapping TO A DIFFERENT SERVLET IS NOT from a default descriptor we
        //DO NOT allow the annotation to replace the mapping
        WebAppContext wac = new WebAppContext();
        ServletHolder servlet = new ServletHolder();
        servlet.setClassName(""org.eclipse.jetty.servlet.FooServlet"");
        servlet.setName(""foo"");
        wac.getServletHandler().addServlet(servlet);
        ServletMapping m = new ServletMapping();
        m.setPathSpec(""/"");
        m.setServletName(""foo"");
        wac.getServletHandler().addServletMapping(m);

        WebServletAnnotation annotation = new WebServletAnnotation(wac, ""org.eclipse.jetty.annotations.ServletD"", null);
        annotation.apply();

        ServletMapping[] resultMappings = wac.getServletHandler().getServletMappings();
        assertEquals(2, resultMappings.length);
        for (ServletMapping r : resultMappings)
        {
            if (r.getServletName().equals(""DServlet""))
            {
                assertEquals(2, r.getPathSpecs().length);
            }
            else if (r.getServletName().equals(""foo""))
            {
                assertEquals(1, r.getPathSpecs().length);
            }
            else
                fail(""Unexpected servlet name: "" + r);
        }
    }
",non-flaky,5
170544,eclipse_jetty.project,TestServletAnnotations.testWebServletAnnotationIgnore,"    @Test
    public void testWebServletAnnotationIgnore() throws Exception
    {
        //an existing servlet OF THE SAME NAME has even 1 non-default mapping we can't use
        //any of the url mappings in the annotation
        WebAppContext wac = new WebAppContext();
        ServletHolder servlet = new ServletHolder();
        servlet.setClassName(""org.eclipse.jetty.servlet.OtherDServlet"");
        servlet.setName(""DServlet"");
        wac.getServletHandler().addServlet(servlet);

        ServletMapping m = new ServletMapping();
        m.setPathSpec(""/default"");
        m.setFromDefaultDescriptor(true);
        m.setServletName(""DServlet"");
        wac.getServletHandler().addServletMapping(m);

        ServletMapping m2 = new ServletMapping();
        m2.setPathSpec(""/other"");
        m2.setServletName(""DServlet"");
        wac.getServletHandler().addServletMapping(m2);

        WebServletAnnotation annotation = new WebServletAnnotation(wac, ""org.eclipse.jetty.annotations.ServletD"", null);
        annotation.apply();

        ServletMapping[] resultMappings = wac.getServletHandler().getServletMappings();
        assertEquals(2, resultMappings.length);

        for (ServletMapping r : resultMappings)
        {
            assertEquals(1, r.getPathSpecs().length);
            if (!r.getPathSpecs()[0].equals(""/default"") && !r.getPathSpecs()[0].equals(""/other""))
                fail(""Unexpected path in mapping: "" + r);
        }
    }
",non-flaky,5
170545,eclipse_jetty.project,TestServletAnnotations.testWebServletAnnotationNoMappings,"    @Test
    public void testWebServletAnnotationNoMappings() throws Exception
    {
        //an existing servlet OF THE SAME NAME has no mappings, therefore all mappings in the annotation
        //should be accepted
        WebAppContext wac = new WebAppContext();
        ServletHolder servlet = new ServletHolder();
        servlet.setName(""foo"");
        wac.getServletHandler().addServlet(servlet);

        WebServletAnnotation annotation = new WebServletAnnotation(wac, ""org.eclipse.jetty.annotations.ServletD"", null);
        annotation.apply();

        ServletMapping[] resultMappings = wac.getServletHandler().getServletMappings();
        assertEquals(1, resultMappings.length);
        assertEquals(2, resultMappings[0].getPathSpecs().length);
        for (String s : resultMappings[0].getPathSpecs())
        {
            assertThat(s, anyOf(is(""/""), is(""/bah/*"")));
        }
    }
",non-flaky,5
170546,eclipse_jetty.project,TestServletAnnotations.testDeclareRoles,"    @Test
    public void testDeclareRoles()
        throws Exception
",non-flaky,5
170547,eclipse_jetty.project,TestResourceAnnotations.init,"    @BeforeEach
    public void init() throws Exception
    {
        server = new Server();
        wac = new WebAppContext();
        wac.setServer(server);
        injections = new InjectionCollection();
        wac.setAttribute(InjectionCollection.INJECTION_COLLECTION, injections);
        InitialContext ic = new InitialContext();
        comp = (Context)ic.lookup(""java:comp"");
        env = comp.createSubcontext(""env"");
    }
",non-flaky,5
170548,eclipse_jetty.project,TestResourceAnnotations.destroy,"    @AfterEach
    public void destroy() throws Exception
    {
        comp.destroySubcontext(""env"");
    }
",non-flaky,5
170549,eclipse_jetty.project,TestResourceAnnotations.testResourceAnnotations,"    @Test
    public void testResourceAnnotations()
        throws Exception
",non-flaky,5
170550,eclipse_jetty.project,TestResourceAnnotations.testResourcesAnnotation,"    @Test
    public void testResourcesAnnotation()
        throws Exception
",non-flaky,5
170551,eclipse_jetty.project,TestRunAsAnnotation.testRunAsAnnotation,"    @Test
    public void testRunAsAnnotation() throws Exception
    {
        WebAppContext wac = new WebAppContext();
        
        //pre-add a servlet but not by descriptor
        ServletHolder holder = new ServletHolder();
        holder.setName(""foo1"");
        holder.setHeldClass(ServletC.class);
        holder.setInitOrder(1); //load on startup
        wac.getServletHandler().addServletWithMapping(holder, ""/foo/*"");
        
        //add another servlet of the same class, but as if by descriptor
        ServletHolder holder2 = new ServletHolder();
        holder2.setName(""foo2"");
        holder2.setHeldClass(ServletC.class);
        holder2.setInitOrder(1);
        wac.getServletHandler().addServletWithMapping(holder2, ""/foo2/*"");
        Resource fakeXml = Resource.newResource(new File(MavenTestingUtils.getTargetTestingDir(""run-as""), ""fake.xml""));
        wac.getMetaData().setOrigin(holder2.getName() + "".servlet.run-as"", new WebDescriptor(fakeXml));
        
        AnnotationIntrospector parser = new AnnotationIntrospector(wac);
        RunAsAnnotationHandler handler = new RunAsAnnotationHandler(wac);
        parser.registerHandler(handler);
        parser.introspect(new ServletC(), null);
        
        assertEquals(""admin"", holder.getRunAsRole());
        assertEquals(null, holder2.getRunAsRole());
    }
",non-flaky,5
175737,GoogleCloudPlatform_google-cloud-eclipse,MultipleConnectionsTest.testDefaultSettings,"	@Test
	public void testDefaultSettings() throws CoreException {
		connector = new SocketListenMultiConnector();
		Map<String, Connector.Argument> defaults = connector.getDefaultArguments();
		assertTrue(defaults.containsKey(""connectionLimit""));
		assertEquals(1, ((Connector.IntegerArgument) defaults.get(""connectionLimit"")).intValue());
	}
",non-flaky,5
175738,GoogleCloudPlatform_google-cloud-eclipse,MultipleConnectionsTest.testDefaultBehaviour,"	@Test
	public void testDefaultBehaviour() throws CoreException, InterruptedException {
		connector = new SocketListenMultiConnector();
		Map<String, String> arguments = new HashMap<>();
		arguments.put(""port"", Integer.toString(port));
		connector.connect(arguments, new NullProgressMonitor(), launch);
		Thread.sleep(200);

		assertTrue(""first connect should succeed"", connect());
		assertFalse(""second connect should fail"", connect());
	}
",non-flaky,5
175739,GoogleCloudPlatform_google-cloud-eclipse,MultipleConnectionsTest.testSingleConnectionBehaviour,"	@Test
	public void testSingleConnectionBehaviour() throws CoreException, InterruptedException {
		connector = new SocketListenMultiConnector();
		Map<String, String> arguments = new HashMap<>();
		arguments.put(""port"", Integer.toString(port));
		arguments.put(""connectionLimit"", ""1"");
		connector.connect(arguments, new NullProgressMonitor(), launch);
		Thread.sleep(200);

		assertTrue(""first connect should succeed"", connect());
		assertFalse(""second connect should fail"", connect());
	}
",non-flaky,5
175740,GoogleCloudPlatform_google-cloud-eclipse,MultipleConnectionsTest.testTwoConnectionsBehaviour,"	@Test
	public void testTwoConnectionsBehaviour() throws CoreException, InterruptedException {
		connector = new SocketListenMultiConnector();
		Map<String, String> arguments = new HashMap<>();
		arguments.put(""port"", Integer.toString(port));
		arguments.put(""connectionLimit"", ""2"");
		connector.connect(arguments, new NullProgressMonitor(), launch);
		Thread.sleep(200);

		assertTrue(""first connect should succeed"", connect());
		assertTrue(""second connect should succeed"", connect());
	}
",non-flaky,5
175741,GoogleCloudPlatform_google-cloud-eclipse,MultipleConnectionsTest.testUnlimitedConnectionsBehaviour,"	@Test
	public void testUnlimitedConnectionsBehaviour() throws CoreException, InterruptedException {
		connector = new SocketListenMultiConnector();
		Map<String, String> arguments = new HashMap<>();
		arguments.put(""port"", Integer.toString(port));
		arguments.put(""connectionLimit"", ""0"");
		connector.connect(arguments, new NullProgressMonitor(), launch);
		Thread.sleep(200);

		for (int i = 0; i < 10; i++) {
			assertTrue(""connection "" + i + "" should succeed"", connect());
		}
	}
",non-flaky,5
175742,GoogleCloudPlatform_google-cloud-eclipse,MessagesTest.testCloudSdkNotConfigured,"  @Test
  public void testCloudSdkNotConfigured() {
    Assert.assertEquals(""Deploy failed."", Messages.getString(""deploy.failed.error.message""));
  }
",non-flaky,5
175743,GoogleCloudPlatform_google-cloud-eclipse,MessagesTest.testSpecifyVersionTooltip,"  @Test
  public void testSpecifyVersionTooltip() {
    Assert.assertEquals(
        ""If checked, stops the previously running version when ""
        + ""deploying a new version that receives all traffic."",
        Messages.getString(""tooltip.stop.previous.version""));
  }
",non-flaky,5
175744,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testAutoSelectSingleAccount,"  @Test
  public void testAutoSelectSingleAccount() {
    when(loginService.getAccounts()).thenReturn(oneAccountSet);
    deployPanel = createPanel(true /* requireValues */);
    assertThat(deployPanel.getSelectedCredential(), is(credential));

    // verify not in error
    IStatus status = getAccountSelectorValidationStatus();
    assertTrue(""account selector is in error: "" + status.getMessage(), status.isOK());

    assertThat(""auto-selected value should be propagated back to model"",
        deployPanel.model.getAccountEmail(), is(account1.getEmail()));
  }
",non-flaky,5
175745,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testAutoSelectSingleAccount_loadGcpProjects,"  @Test
  public void testAutoSelectSingleAccount_loadGcpProjects()
      throws ProjectRepositoryException, InterruptedException {
    when(loginService.getAccounts()).thenReturn(oneAccountSet);
    initializeProjectRepository();
    deployPanel = createPanel(true /* requireValues */);
    assertNotNull(deployPanel.latestGcpProjectQueryJob);
    deployPanel.latestGcpProjectQueryJob.join();

    Table projectTable = getProjectSelector().getViewer().getTable();
    assertThat(projectTable.getItemCount(), is(2));
  }
",non-flaky,5
175746,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testValidationMessageWhenNotSignedIn,"  @Test
  public void testValidationMessageWhenNotSignedIn() {
    deployPanel = createPanel(true /* requireValues */);
    IStatus status = getAccountSelectorValidationStatus();
    assertThat(status.getMessage(), is(""Sign in to Google.""));
  }
",non-flaky,5
175747,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testValidationMessageWhenSignedIn,"  @Test
  public void testValidationMessageWhenSignedIn() {
    // Return two accounts because the account selector will auto-select if there exists only one.
    when(loginService.getAccounts()).thenReturn(twoAccountSet);

    deployPanel = createPanel(true /* requireValues */);
    IStatus status = getAccountSelectorValidationStatus();
    assertThat(status.getMessage(), is(""Select an account.""));
  }
",non-flaky,5
175748,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testUncheckStopPreviousVersionButtonWhenDisabled,"  @Test
  public void testUncheckStopPreviousVersionButtonWhenDisabled() {
    deployPanel = createPanel(true /* requireValues */);

    Button promoteButton = getButtonWithText(""Promote the deployed version to receive all traffic"");
    Button stopButton = getButtonWithText(""Stop previous version"");
    SWTBotCheckBox promote = new SWTBotCheckBox(promoteButton);
    SWTBotCheckBox stop = new SWTBotCheckBox(stopButton);

    // Initially, everything is checked and enabled.
    assertTrue(promoteButton.getSelection());
    assertTrue(stopButton.getSelection());
    assertTrue(stopButton.getEnabled());

    promote.click();
    assertFalse(promoteButton.getSelection());
    assertFalse(stopButton.getSelection());
    assertFalse(stopButton.getEnabled());

    promote.click();
    assertTrue(promoteButton.getSelection());
    assertTrue(stopButton.getSelection());
    assertTrue(stopButton.getEnabled());

    stop.click();
    assertTrue(promoteButton.getSelection());
    assertFalse(stopButton.getSelection());
    assertTrue(stopButton.getEnabled());

    promote.click();
    assertFalse(promoteButton.getSelection());
    assertFalse(stopButton.getSelection());
    assertFalse(stopButton.getEnabled());

    promote.click();
    assertTrue(promoteButton.getSelection());
    assertFalse(stopButton.getSelection());
    assertTrue(stopButton.getEnabled());
  }
",non-flaky,5
175749,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testProjectSavedInPreferencesSelected,"  @Test
  public void testProjectSavedInPreferencesSelected()
      throws ProjectRepositoryException, InterruptedException, BackingStoreException {
    IEclipsePreferences node =
        new ProjectScope(project).getNode(DeployPreferences.PREFERENCE_STORE_QUALIFIER);
    try {
      node.put(""project.id"", ""projectId1"");
      node.put(""account.email"", EMAIL_1);
      initializeProjectRepository();
      when(loginService.getAccounts()).thenReturn(twoAccountSet);
      deployPanel = createPanel(true /* requireValues */);
      deployPanel.latestGcpProjectQueryJob.join();

      ProjectSelector projectSelector = getProjectSelector();
      IStructuredSelection selection = projectSelector.getViewer().getStructuredSelection();
      assertThat(selection.size(), is(1));
      assertThat(((GcpProject) selection.getFirstElement()).getId(), is(""projectId1""));
    } finally {
      node.clear();
    }
  }
",non-flaky,5
175750,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testProjectNotSelectedIsAnErrorWhenRequireValuesIsTrue,"  @Test
  public void testProjectNotSelectedIsAnErrorWhenRequireValuesIsTrue() {
    deployPanel = createPanel(true /* requireValues */);
    assertThat(getProjectSelectionValidator().getSeverity(), is(IStatus.ERROR));
  }
",non-flaky,5
175751,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testProjectNotSelectedIsNotAnErrorWhenRequireValuesIsFalse,"  @Test
  public void testProjectNotSelectedIsNotAnErrorWhenRequireValuesIsFalse() {
    deployPanel = createPanel(false /* requireValues */);
    assertThat(getProjectSelectionValidator().getSeverity(), is(IStatus.INFO));
  }
",non-flaky,5
175752,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testProjectsExistThenNoProjectNotFoundError,"  @Test
  public void testProjectsExistThenNoProjectNotFoundError()
      throws ProjectRepositoryException, InterruptedException {
    when(loginService.getAccounts()).thenReturn(oneAccountSet);
    initializeProjectRepository();
    deployPanel = createPanel(false /* requireValues */);
    selectAccount(account1);
    deployPanel.latestGcpProjectQueryJob.join();
    assertThat(getProjectSelectionValidator().getSeverity(), is(IStatus.OK));
  }
",non-flaky,5
175753,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testRefreshProjectsForSelectedCredential,"  @Test
  public void testRefreshProjectsForSelectedCredential()
      throws ProjectRepositoryException, InterruptedException {
    when(loginService.getAccounts()).thenReturn(twoAccountSet);
    initializeProjectRepository();

    deployPanel = createPanel(false /* requireValues */);
    Table projectTable = getProjectSelector().getViewer().getTable();
    assertNull(deployPanel.latestGcpProjectQueryJob);
    assertThat(projectTable.getItemCount(), is(0));

    selectAccount(account1);
    assertNotNull(deployPanel.latestGcpProjectQueryJob);
    deployPanel.latestGcpProjectQueryJob.join();
    assertThat(projectTable.getItemCount(), is(2));
    assertThat(((GcpProject) projectTable.getItem(0).getData()).getId(), is(""projectId1""));
    assertThat(((GcpProject) projectTable.getItem(1).getData()).getId(), is(""projectId2""));
  }
",non-flaky,5
175754,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testRefreshProjectsForSelectedCredential_switchAccounts,"  @Test
  public void testRefreshProjectsForSelectedCredential_switchAccounts()
      throws ProjectRepositoryException, InterruptedException {
    when(loginService.getAccounts()).thenReturn(twoAccountSet);
    initializeProjectRepository();

    deployPanel = createPanel(false /* requireValues */);
    Table projectTable = getProjectSelector().getViewer().getTable();
    assertNull(deployPanel.latestGcpProjectQueryJob);
    assertThat(projectTable.getItemCount(), is(0));

    selectAccount(account1);
    Job jobForAccount1 = deployPanel.latestGcpProjectQueryJob;
    jobForAccount1.join();
    assertThat(projectTable.getItemCount(), is(2));

    selectAccount(account2);
    assertNotEquals(jobForAccount1, deployPanel.latestGcpProjectQueryJob);
    deployPanel.latestGcpProjectQueryJob.join();
    assertThat(projectTable.getItemCount(), is(1));
    assertThat(((GcpProject) projectTable.getItem(0).getData()).getId(), is(""projectId2""));
  }
",non-flaky,5
175755,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testNoProjectSelectedWhenSwitchingAccounts,"  @Test
  public void testNoProjectSelectedWhenSwitchingAccounts()
      throws ProjectRepositoryException, InterruptedException {
    when(loginService.getAccounts()).thenReturn(twoAccountSet);
    initializeProjectRepository();

    deployPanel = createPanel(false /* requireValues */);
    selectAccount(account1);
    deployPanel.latestGcpProjectQueryJob.join();

    Table projectTable = getProjectSelector().getViewer().getTable();
    assertThat(projectTable.getItemCount(), is(2));
    projectTable.setSelection(0);
    assertThat(projectTable.getSelectionCount(), is(1));

    selectAccount(account2);
    deployPanel.latestGcpProjectQueryJob.join();

    assertThat(projectTable.getItemCount(), is(1));
    assertThat(projectTable.getSelectionCount(), is(0));
  }
",non-flaky,5
175756,GoogleCloudPlatform_google-cloud-eclipse,PluginXmlTest.testLimitedVisibility,"  @Test
  public void testLimitedVisibility() {
    NodeList pages = getDocument().getElementsByTagName(""page"");
    Assert.assertEquals(2, pages.getLength());
    NodeList enabledWhen = getDocument().getElementsByTagName(""enabledWhen"");
    Assert.assertEquals(4, enabledWhen.getLength());
    NodeList tests = getDocument().getElementsByTagName(""test"");
    Assert.assertEquals(4, tests.getLength());
    NodeList adapts = getDocument().getElementsByTagName(""adapt"");
    Assert.assertEquals(4, adapts.getLength());

    for (int i = 0; i < enabledWhen.getLength(); i++) {
      Element element = (Element) enabledWhen.item(i);
      Node parent = element.getParentNode();
      assertThat(parent.getNodeName(), either(is(""page"")).or(is(""handler"")));
    }

    Element standardAdapt = (Element) adapts.item(0);
    verifyAdapt(standardAdapt, AppEngineStandardFacet.ID);
    Element flexAdapt = (Element) adapts.item(1);
    verifyAdapt(flexAdapt, AppEngineFlexFacet.ID);
  }
",non-flaky,5
175757,GoogleCloudPlatform_google-cloud-eclipse,GcpProjectQueryJobTest.testNullCredential,"  @Test(expected = NullPointerException.class)
  public void testNullCredential() {
    new GcpProjectQueryJob(null /* credential */, projectRepository, projectSelector,
        dataBindingContext, isLatestQueryJob);
  }
",non-flaky,5
175758,GoogleCloudPlatform_google-cloud-eclipse,GcpProjectQueryJobTest.testRun_setsProjects,"  @Test
  public void testRun_setsProjects() throws InterruptedException, ProjectRepositoryException {
    queryJob.schedule();
    queryJob.join();

    verify(projectRepository).getProjects(credential);
    verify(isLatestQueryJob).apply(queryJob);
    verify(projectSelector).isDisposed();
    verify(projectSelector).setProjects(projects);
  }
",non-flaky,5
175759,GoogleCloudPlatform_google-cloud-eclipse,GcpProjectQueryJobTest.testRun_abandonIfDisposed,"  @Test
  public void testRun_abandonIfDisposed() throws InterruptedException, ProjectRepositoryException {
    when(projectSelector.isDisposed()).thenReturn(true);

    queryJob.schedule();
    queryJob.join();

    verify(projectRepository).getProjects(credential);
    verify(projectSelector, never()).setProjects(projects);
  }
",non-flaky,5
175760,GoogleCloudPlatform_google-cloud-eclipse,GcpProjectQueryJobTest.testRun_abandonIfNotLatestJob,"  @Test
  public void testRun_abandonIfNotLatestJob()
      throws InterruptedException, ProjectRepositoryException {
    when(isLatestQueryJob.apply(queryJob)).thenReturn(false);

    queryJob.schedule();
    queryJob.join();

    verify(projectRepository).getProjects(credential);
    verify(projectSelector, never()).setProjects(projects);
  }
",non-flaky,5
175761,GoogleCloudPlatform_google-cloud-eclipse,GcpProjectQueryJobTest.testRun_abandonStaleJob,"  @Test
  public void testRun_abandonStaleJob() throws InterruptedException, ProjectRepositoryException {
    // Prepare another concurrent query job.
    Credential staleCredential = mock(Credential.class);

    List<GcpProject> anotherProjectList = mock(List.class);
    ProjectRepository projectRepository2 = mock(ProjectRepository.class);
    when(projectRepository2.getProjects(staleCredential)).thenReturn(anotherProjectList);

    Predicate<Job> notLatest = mock(Predicate.class);
    Job staleJob = new GcpProjectQueryJob(staleCredential, projectRepository2,
        projectSelector, dataBindingContext, notLatest);

    // This second job is stale, i.e., it was fired, but user has selected another credential.
    when(notLatest.apply(staleJob)).thenReturn(false);

    queryJob.schedule();
    queryJob.join();
    // Make the stale job complete even after ""queryJob"" finishes.
    staleJob.schedule();
    staleJob.join();

    verify(projectRepository).getProjects(credential);
    verify(projectRepository2).getProjects(staleCredential);

    verify(projectSelector).setProjects(projects);
    verify(projectSelector, never()).setProjects(anotherProjectList);
  }
",non-flaky,5
175762,GoogleCloudPlatform_google-cloud-eclipse,BlankDeployPreferencesPanelTest.testGetHelpContextId,"  @Test
  public void testGetHelpContextId() {
    assertNull(new BlankDeployPreferencesPanel(shellTestResource.getShell()).getHelpContextId());
  }
",non-flaky,5
175763,GoogleCloudPlatform_google-cloud-eclipse,DeployPropertyPageTest.testCorrectPanelIsShownForFacetedProject,"  @Test
  public void testCorrectPanelIsShownForFacetedProject() {
    DeployPropertyPage page = new DeployPropertyPage(loginService, googleApiFactory);
    Shell parent = shellTestResource.getShell();
    page.setElement(getProject());
    page.createControl(parent);
    page.setVisible(true);
    Composite preferencePageComposite = (Composite) parent.getChildren()[0];
    for (Control control : preferencePageComposite.getChildren()) {
      if (control instanceof Composite) {
        Composite maybeDeployPageComposite = (Composite) control;
        Layout layout = maybeDeployPageComposite.getLayout();
        if (layout instanceof StackLayout) {
          StackLayout stackLayout = (StackLayout) layout;
          assertThat(stackLayout.topControl, instanceOf(getPanelClass()));
          return;
        }
      }
    }
    fail(""Did not find the deploy preferences panel"");
  }
",non-flaky,5
175764,GoogleCloudPlatform_google-cloud-eclipse,StandardDeployPreferencesPanelTest.testGetHelpContextId,"  @Test
  public void testGetHelpContextId() {
    IProject project = mock(IProject.class);
    when(project.getName()).thenReturn("""");
    StandardDeployPreferencesPanel panel = new StandardDeployPreferencesPanel(
        shellResource.getShell(), project, mock(IGoogleLoginService.class), mock(Runnable.class),
        false, mock(ProjectRepository.class));

    assertEquals(
        ""com.google.cloud.tools.eclipse.appengine.deploy.ui.DeployAppEngineStandardProjectContext"",
        panel.getHelpContextId());
  }
",non-flaky,5
175765,GoogleCloudPlatform_google-cloud-eclipse,FlexDeployPreferencesPanelTest.testGetHelpContextId,"  @Test
  public void testGetHelpContextId() {
    FlexDeployPreferencesPanel panel = createPanel(true /* requireValues */);

    assertEquals(
        ""com.google.cloud.tools.eclipse.appengine.deploy.ui.DeployAppEngineFlexProjectContext"",
        panel.getHelpContextId());
  }
",non-flaky,5
175766,GoogleCloudPlatform_google-cloud-eclipse,FlexDeployPreferencesPanelTest.testDefaultAppYamlPathSet,"  @Test
  public void testDefaultAppYamlPathSet() {
    FlexDeployPreferencesPanel panel = createPanel(true /* requireValues */);

    Text appYamlField = findAppYamlField(panel);
    assertEquals(""src/main/appengine/app.yaml"", appYamlField.getText());
    assertTrue(getAppYamlPathValidationStatus(panel).isOK());
  }
",non-flaky,5
175767,GoogleCloudPlatform_google-cloud-eclipse,FlexDeployPreferencesPanelTest.testAppYamlPathValidation_nonExistingAppYaml,"  @Test
  public void testAppYamlPathValidation_nonExistingAppYaml() {
    FlexDeployPreferencesPanel panel = createPanel(true /* requireValues */);

    Text appYamlField = findAppYamlField(panel);
    appYamlField.setText(""non/existing/app.yaml"");
    assertFalse(getAppYamlPathValidationStatus(panel).isOK());
  }
",non-flaky,5
175768,GoogleCloudPlatform_google-cloud-eclipse,FlexDeployPreferencesPanelTest.testAppYamlPathValidation_noValidationIfRequireValuesIsFalse,"  @Test
  public void testAppYamlPathValidation_noValidationIfRequireValuesIsFalse() {
    FlexDeployPreferencesPanel panel = createPanel(false /* requireValues */);

    Text appYamlField = findAppYamlField(panel);
    appYamlField.setText(""non/existing/app.yaml"");
    assertNull(getAppYamlPathValidationStatus(panel));
  }
",non-flaky,5
175769,GoogleCloudPlatform_google-cloud-eclipse,FlexDeployPreferencesPanelTest.testAppYamlPathValidation_absolutePathWorks,"  @Test
  public void testAppYamlPathValidation_absolutePathWorks() {
    FlexDeployPreferencesPanel panel = createPanel(true /* requireValues */);
    Text appYamlField = findAppYamlField(panel);

    IPath absolutePath = project.getLocation().append(""src/main/appengine/app.yaml"");
    assertTrue(absolutePath.isAbsolute());

    appYamlField.setText(absolutePath.toString());
    assertTrue(getAppYamlPathValidationStatus(panel).isOK());
  }
",non-flaky,5
175770,GoogleCloudPlatform_google-cloud-eclipse,FlexDeployPreferencesDialogTest.testFlexPricingLabel,"  @Test
  public void testFlexPricingLabel() {
    dialog.setBlockOnOpen(false);
    dialog.open();
    Composite dialogArea = (Composite) dialog.createDialogArea(shellResource.getShell());

    assertNotNull(findGcpPricingLink(dialogArea));
  }
",non-flaky,5
175771,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testContructor_nonAbsoluteBasePath,"  @Test
  public void testContructor_nonAbsoluteBasePath() {
    try {
      when(appYamlPath.getValue()).thenReturn(""app.yaml"");
      new AppYamlValidator(new Path(""non/absolute/base/path""), appYamlPath);
      fail();
    } catch (IllegalArgumentException ex) {
      assertEquals(""basePath is not absolute."", ex.getMessage());
    }
  }
",non-flaky,5
175772,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidate_relativePathAndNoAppYaml,"  @Test
  public void testValidate_relativePathAndNoAppYaml() {
    when(appYamlPath.getValue()).thenReturn(""relative/path/app.yaml"");

    IStatus result = pathValidator.validate();
    assertEquals(IStatus.ERROR, result.getSeverity());
    assertEquals(""app.yaml does not exist."", result.getMessage());
  }
",non-flaky,5
175773,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidate_absolutePathAndNoAppYaml,"  @Test
  public void testValidate_absolutePathAndNoAppYaml() {
    String absolutePath = basePath + ""/sub/directory/app.yaml"";
    when(appYamlPath.getValue()).thenReturn(absolutePath);

    IStatus result = pathValidator.validate();
    assertEquals(IStatus.ERROR, result.getSeverity());
    assertEquals(""app.yaml does not exist."", result.getMessage());
  }
",non-flaky,5
175774,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidate_relativePathAndInvalidFileName,"  @Test
  public void testValidate_relativePathAndInvalidFileName() {
    when(appYamlPath.getValue()).thenReturn(""relative/path/my-app.yaml"");

    IStatus result = pathValidator.validate();
    assertEquals(IStatus.ERROR, result.getSeverity());
    assertEquals(""File name is not app.yaml: ""
        + new Path(basePath + ""/relative/path/my-app.yaml"").toOSString(),
        result.getMessage());
  }
",non-flaky,5
175775,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidate_absolutePathInvalidFileName,"  @Test
  public void testValidate_absolutePathInvalidFileName() {
    String absolutePath = basePath + ""/sub/directory/my-app.yaml"";
    when(appYamlPath.getValue()).thenReturn(absolutePath);

    IStatus result = pathValidator.validate();
    assertEquals(IStatus.ERROR, result.getSeverity());
    assertEquals(""File name is not app.yaml: ""
        + new Path(basePath + ""/sub/directory/my-app.yaml"").toOSString(),
        result.getMessage());
  }
",non-flaky,5
175776,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidate_relativePathNotFile,"  @Test
  public void testValidate_relativePathNotFile() {
    createAppYamlAsDirectory(basePath);
    when(appYamlPath.getValue()).thenReturn(""app.yaml"");

    IStatus result = pathValidator.validate();
    assertEquals(IStatus.ERROR, result.getSeverity());
    assertEquals(""Not a file: "" + new Path(basePath + ""/app.yaml"").toOSString(),
        result.getMessage());
  }
",non-flaky,5
175777,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidate_absolutePathNotFile,"  @Test
  public void testValidate_absolutePathNotFile() {
    createAppYamlAsDirectory(basePath);

    String absolutePath = basePath + ""/app.yaml"";
    when(appYamlPath.getValue()).thenReturn(absolutePath);

    IStatus result = pathValidator.validate();
    assertEquals(IStatus.ERROR, result.getSeverity());
    assertEquals(""Not a file: "" + new Path(basePath + ""/app.yaml"").toOSString(),
        result.getMessage());
  }
",non-flaky,5
175778,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidate_relativePathWithAppYaml,"  @Test
  public void testValidate_relativePathWithAppYaml() throws IOException {
    createAppYamlFile(basePath + ""/some/directory"", ""runtime: java"");

    when(appYamlPath.getValue()).thenReturn(""some/directory/app.yaml"");
    IStatus result = pathValidator.validate();
    assertTrue(result.isOK());
  }
",non-flaky,5
175779,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidate_absolutePathWithAppYaml,"  @Test
  public void testValidate_absolutePathWithAppYaml() throws IOException {
    File absolutePath = tempFolder.newFolder(""another"", ""folder"");
    File appYaml = createAppYamlFile(absolutePath.toString(), ""runtime: java"");

    when(appYamlPath.getValue()).thenReturn(appYaml.toString());
    IStatus result = pathValidator.validate();
    assertTrue(result.isOK());
  }
",non-flaky,5
175780,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidateRuntime_javaRuntime,"  @Test
  public void testValidateRuntime_javaRuntime() throws IOException {
    File appYaml = createAppYamlFile(tempFolder.getRoot().toString(), ""runtime: java"");
    IStatus result = AppYamlValidator.validateRuntime(appYaml);
    assertTrue(result.isOK());
  }
",non-flaky,5
175781,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidateRuntime_malformedAppYaml,"  @Test
  public void testValidateRuntime_malformedAppYaml() throws IOException {
    File appYaml = createAppYamlFile(tempFolder.getRoot().toString(), "": m a l f o r m e d !"");
    IStatus result = AppYamlValidator.validateRuntime(appYaml);
    assertEquals(IStatus.ERROR, result.getSeverity());
    assertEquals(""Malformed app.yaml."", result.getMessage());
  }
",non-flaky,5
175782,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidateRuntime_noRuntime,"  @Test
  public void testValidateRuntime_noRuntime() throws IOException {
    File appYaml = createAppYamlFile(tempFolder.getRoot().toString(), ""env: flex"");
    IStatus result = AppYamlValidator.validateRuntime(appYaml);
    assertEquals(IStatus.ERROR, result.getSeverity());
    assertEquals(""\""runtime: null\"" in app.yaml is not \""java\""."", result.getMessage());
  }
",non-flaky,5
175783,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidateRuntime_nullRuntime,"  @Test
  public void testValidateRuntime_nullRuntime() throws IOException {
    File appYaml = createAppYamlFile(tempFolder.getRoot().toString(), ""runtime:"");
    IStatus result = AppYamlValidator.validateRuntime(appYaml);
    assertEquals(IStatus.ERROR, result.getSeverity());
    assertEquals(""\""runtime: null\"" in app.yaml is not \""java\""."", result.getMessage());
  }
",non-flaky,5
175784,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidateRuntime_notJavaRuntime,"  @Test
  public void testValidateRuntime_notJavaRuntime() throws IOException {
    File appYaml = createAppYamlFile(tempFolder.getRoot().toString(), ""runtime: python"");
    IStatus result = AppYamlValidator.validateRuntime(appYaml);
    assertEquals(IStatus.ERROR, result.getSeverity());
    assertEquals(""\""runtime: python\"" in app.yaml is not \""java\""."", result.getMessage());
  }
",non-flaky,5
175785,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidateRuntime_customRuntime,"  @Test
  public void testValidateRuntime_customRuntime() throws IOException {
    File appYaml = createAppYamlFile(tempFolder.getRoot().toString(), ""runtime: custom"");
    IStatus result = AppYamlValidator.validateRuntime(appYaml);
    assertEquals(IStatus.ERROR, result.getSeverity());
    assertEquals(""\""runtime: custom\"" is not yet supported by Cloud Tools for Eclipse."",
        result.getMessage());
  }
",non-flaky,5
175786,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidateRuntime_ioException,"  @Test
  public void testValidateRuntime_ioException() {
    File nonExisting = new File(""/non/existing/file"");
    IStatus result = AppYamlValidator.validateRuntime(nonExisting);
    assertEquals(IStatus.ERROR, result.getSeverity());
    assertTrue(result.getMessage().startsWith(""Cannot read app.yaml:""));
  }
",non-flaky,5
175787,GoogleCloudPlatform_google-cloud-eclipse,AppEngineApplicationQueryJobTest.testRun_projectHasNoApplication,"  @Test
  public void testRun_projectHasNoApplication()
      throws ProjectRepositoryException, InterruptedException {
    when(projectRepository.getAppEngineApplication(credential, ""projectId""))
        .thenReturn(AppEngine.NO_APPENGINE_APPLICATION);
    assertNull(project.getAppEngine());

    queryJob.schedule();
    queryJob.join();

    verify(projectRepository).getAppEngineApplication(credential, ""projectId"");
    verify(isLatestQueryJob).apply(queryJob);
    verify(projectSelector).isDisposed();
    verify(projectSelection).isEmpty();
    verify(projectSelector).setStatusLink(EXPECTED_MESSAGE_WHEN_NO_APPLICATION, EXPECTED_LINK);

    assertEquals(AppEngine.NO_APPENGINE_APPLICATION, project.getAppEngine());
  }
",non-flaky,5
175788,GoogleCloudPlatform_google-cloud-eclipse,AppEngineApplicationQueryJobTest.testRun_projectHasApplication,"  @Test
  public void testRun_projectHasApplication()
      throws ProjectRepositoryException, InterruptedException {
    AppEngine appEngine = AppEngine.withId(""unique-id"");
    when(projectRepository.getAppEngineApplication(credential, ""projectId"")).thenReturn(appEngine);

    queryJob.schedule();
    queryJob.join();

    verify(isLatestQueryJob, never()).apply(queryJob);
    verify(projectSelector, never()).isDisposed();
    verify(projectSelector, never()).setStatusLink(anyString(), anyString());

    assertTrue(appEngine == project.getAppEngine());
  }
",non-flaky,5
175789,GoogleCloudPlatform_google-cloud-eclipse,AppEngineApplicationQueryJobTest.testRun_queryError,"  @Test
  public void testRun_queryError() throws ProjectRepositoryException, InterruptedException {
    when(projectRepository.getAppEngineApplication(credential, ""projectId""))
        .thenThrow(new ProjectRepositoryException(""testException""));

    queryJob.schedule();
    queryJob.join();

    verify(isLatestQueryJob).apply(queryJob);
    verify(projectSelector).isDisposed();
    verify(projectSelector).setStatusLink(EXPECTED_MESSAGE_WHEN_EXCEPTION, null);

    assertNull(project.getAppEngine());
  }
",non-flaky,5
175790,GoogleCloudPlatform_google-cloud-eclipse,AppEngineApplicationQueryJobTest.testRun_abandonIfDisposed,"  @Test
  public void testRun_abandonIfDisposed() throws InterruptedException, ProjectRepositoryException {
    when(projectSelector.isDisposed()).thenReturn(true);
    when(projectRepository.getAppEngineApplication(credential, ""projectId""))
        .thenReturn(AppEngine.NO_APPENGINE_APPLICATION);

    queryJob.schedule();
    queryJob.join();

    verify(projectSelector).isDisposed();
    verify(projectSelector, never()).setStatusLink(anyString(), anyString());
  }
",non-flaky,5
175791,GoogleCloudPlatform_google-cloud-eclipse,AppEngineApplicationQueryJobTest.testRun_abandonIfNotLatestJob,"  @Test
  public void testRun_abandonIfNotLatestJob()
      throws InterruptedException, ProjectRepositoryException {
    when(isLatestQueryJob.apply(queryJob)).thenReturn(false);
    when(projectRepository.getAppEngineApplication(credential, ""projectId""))
        .thenReturn(AppEngine.NO_APPENGINE_APPLICATION);

    queryJob.schedule();
    queryJob.join();

    verify(isLatestQueryJob).apply(queryJob);
    verify(projectSelector, never()).setStatusLink(anyString(), anyString());
  }
",non-flaky,5
175792,GoogleCloudPlatform_google-cloud-eclipse,AppEngineApplicationQueryJobTest.testRun_abandonIfProjectSelectorHasNoSelection,"  @Test
  public void testRun_abandonIfProjectSelectorHasNoSelection()
      throws ProjectRepositoryException, InterruptedException {
    when(projectRepository.getAppEngineApplication(credential, ""projectId""))
        .thenReturn(AppEngine.NO_APPENGINE_APPLICATION);
    when(projectSelection.isEmpty()).thenReturn(true);

    queryJob.schedule();
    queryJob.join();

    verify(isLatestQueryJob).apply(queryJob);
    verify(projectSelector, never()).setStatusLink(anyString(), anyString());
  }
",non-flaky,5
175793,GoogleCloudPlatform_google-cloud-eclipse,AppEngineApplicationQueryJobTest.testRun_abandonStaleJob,"  @Test
  public void testRun_abandonStaleJob() throws InterruptedException, ProjectRepositoryException {
    when(projectRepository.getAppEngineApplication(credential, ""projectId""))
        .thenReturn(AppEngine.NO_APPENGINE_APPLICATION);

    // Prepare another concurrent query job.
    Credential staleCredential = mock(Credential.class);

    GcpProject staleProject = new GcpProject(""name"", ""staleProjectId"");
    ProjectRepository projectRepository2 = mock(ProjectRepository.class);
    when(projectRepository2.getAppEngineApplication(staleCredential, ""staleProjectId""))
        .thenThrow(new ProjectRepositoryException(""testException""));

    Predicate<Job> notLatest = mock(Predicate.class);
    Job staleJob = new AppEngineApplicationQueryJob(staleProject, staleCredential,
        projectRepository2, projectSelector, EXPECTED_LINK, notLatest);

    // This second job is stale, i.e., it was fired, but user has selected another credential.
    when(notLatest.apply(staleJob)).thenReturn(false);

    queryJob.schedule();
    queryJob.join();
    // Make the stale job complete even after ""queryJob"" finishes.
    staleJob.schedule();
    staleJob.join();

    verify(projectRepository).getAppEngineApplication(credential, ""projectId"");
    verify(projectRepository2).getAppEngineApplication(staleCredential, ""staleProjectId"");

    verify(projectSelector).setStatusLink(EXPECTED_MESSAGE_WHEN_NO_APPLICATION, EXPECTED_LINK);
    verify(projectSelector, never()).setStatusLink(EXPECTED_MESSAGE_WHEN_EXCEPTION, null);
  }
",non-flaky,5
175794,GoogleCloudPlatform_google-cloud-eclipse,RelativeFileFieldSetterTest.testConstructor_nonAbsoluteBasePath,"  @Test
  public void testConstructor_nonAbsoluteBasePath() {
    try {
      new RelativeFileFieldSetter(field, new Path(""non/absolute/base/path""), dialog);
      fail();
    } catch (IllegalArgumentException ex) {}
  }
",non-flaky,5
175795,GoogleCloudPlatform_google-cloud-eclipse,RelativeFileFieldSetterTest.testFileDialogCanceled,"  @Test
  public void testFileDialogCanceled() {
    when(field.getText()).thenReturn("""");
    when(dialog.open()).thenReturn(null /* means canceled */);

    new RelativeFileFieldSetter(field, basePath, dialog).widgetSelected(event);
    verify(field, never()).setText(anyString());
  }
",non-flaky,5
175796,GoogleCloudPlatform_google-cloud-eclipse,RelativeFileFieldSetterTest.testSetField,"  @Test
  public void testSetField() {
    when(field.getText()).thenReturn("""");
    when(dialog.open()).thenReturn(basePath + ""/sub/directory/app.yaml"");

    new RelativeFileFieldSetter(field, basePath, dialog).widgetSelected(event);
    verify(field).setText(""sub/directory/app.yaml"");
  }
",non-flaky,5
175797,GoogleCloudPlatform_google-cloud-eclipse,RelativeFileFieldSetterTest.testSetField_userSuppliesPathOutsideBase,"  @Test
  public void testSetField_userSuppliesPathOutsideBase() {
    when(field.getText()).thenReturn("""");
    when(dialog.open()).thenReturn(""/path/outside/base/app.yaml"");

    new RelativeFileFieldSetter(field, new Path(""/base/path""), dialog).widgetSelected(event);
    verify(field).setText(""../../path/outside/base/app.yaml"");
  }
",non-flaky,5
175798,GoogleCloudPlatform_google-cloud-eclipse,RelativeFileFieldSetterTest.testFileDialogFilterSet_relativePathInField,"  @Test
  public void testFileDialogFilterSet_relativePathInField() {
    when(field.getText()).thenReturn(""src/main/appengine/app.yaml"");
    when(dialog.open()).thenReturn(null);

    new RelativeFileFieldSetter(field, basePath, dialog).widgetSelected(event);
    // ""basePath"" is the first physically existing directory.
    verify(dialog).setFilterPath(basePath.toString());

    basePath.append(""src"").toFile().mkdir();
    new RelativeFileFieldSetter(field, basePath, dialog).widgetSelected(event);
    verify(dialog).setFilterPath(basePath + ""/src"");
  }
",non-flaky,5
175799,GoogleCloudPlatform_google-cloud-eclipse,RelativeFileFieldSetterTest.testFileDialogFilterSet_absolutePathInField,"  @Test
  public void testFileDialogFilterSet_absolutePathInField() {
    when(field.getText()).thenReturn(basePath + ""/deploy/temp/app.yaml"");
    when(dialog.open()).thenReturn(null);

    new RelativeFileFieldSetter(field, basePath, dialog).widgetSelected(event);
    // ""basePath"" is the first physically existing directory.
    verify(dialog).setFilterPath(basePath.toString());

    basePath.append(""deploy"").toFile().mkdir();
    new RelativeFileFieldSetter(field, basePath, dialog).widgetSelected(event);
    verify(dialog).setFilterPath(basePath + ""/deploy"");
  }
",non-flaky,5
175800,GoogleCloudPlatform_google-cloud-eclipse,ProjectSelectorSelectionChangedListenerTest.testSelectionChanged_emptySelection,"  @Test
  public void testSelectionChanged_emptySelection() {
    when(event.getSelection()).thenReturn(new StructuredSelection());
    listener.selectionChanged(event);
    verify(projectSelector).clearStatusLink();
  }
",non-flaky,5
175801,GoogleCloudPlatform_google-cloud-eclipse,ProjectSelectorSelectionChangedListenerTest.testSelectionChanged_repositoryException,"  @Test
  public void testSelectionChanged_repositoryException()
      throws ProjectRepositoryException, InterruptedException {
    initSelectionAndAccountSelector();
    when(projectRepository.getAppEngineApplication(any(Credential.class), anyString()))
        .thenThrow(new ProjectRepositoryException(""testException""));

    listener.selectionChanged(event);
    listener.latestQueryJob.join();
    verify(projectSelector).clearStatusLink();  // Should clear initially.
    verify(projectSelector).setStatusLink(EXPECTED_MESSAGE_WHEN_EXCEPTION, null /* tooltip */);
  }
",non-flaky,5
175802,GoogleCloudPlatform_google-cloud-eclipse,ProjectSelectorSelectionChangedListenerTest.testSelectionChanged_noAppEngineApplication,"  @Test
  public void testSelectionChanged_noAppEngineApplication()
      throws ProjectRepositoryException, InterruptedException {
    initSelectionAndAccountSelector();
    when(projectRepository.getAppEngineApplication(any(Credential.class), anyString()))
        .thenReturn(AppEngine.NO_APPENGINE_APPLICATION);

    listener.selectionChanged(event);
    listener.latestQueryJob.join();
    verify(projectSelector).clearStatusLink();  // Should clear initially.
    verify(projectSelector).setStatusLink(EXPECTED_MESSAGE_WHEN_NO_APPLICATION, EXPECTED_LINK);
  }
",non-flaky,5
175803,GoogleCloudPlatform_google-cloud-eclipse,ProjectSelectorSelectionChangedListenerTest.testSelectionChanged_hasAppEngineApplication,"  @Test
  public void testSelectionChanged_hasAppEngineApplication()
      throws ProjectRepositoryException, InterruptedException {
    initSelectionAndAccountSelector();
    when(projectRepository.getAppEngineApplication(any(Credential.class), anyString()))
        .thenReturn(AppEngine.withId(""id""));

    listener.selectionChanged(event);
    listener.latestQueryJob.join();
    verify(projectSelector).clearStatusLink();
  }
",non-flaky,5
175804,GoogleCloudPlatform_google-cloud-eclipse,ProjectSelectorSelectionChangedListenerTest.testSelectionChanged_doNotRunQueryJobIfCached,"  @Test
  public void testSelectionChanged_doNotRunQueryJobIfCached() throws ProjectRepositoryException {
    GcpProject gcpProject = new GcpProject(""projectName"", ""projectId"");
    initSelectionAndAccountSelector(gcpProject);
    gcpProject.setAppEngine(AppEngine.withId(""id""));

    listener.selectionChanged(event);
    assertNull(listener.latestQueryJob);
    verify(projectRepository, never()).getAppEngineApplication(any(Credential.class), anyString());
    verify(projectSelector).clearStatusLink();
  }
",non-flaky,5
175805,GoogleCloudPlatform_google-cloud-eclipse,ProjectSelectorSelectionChangedListenerTest.testSelectionChanged_whenCachedResultIsNoAppEngineApplication,"  @Test
  public void testSelectionChanged_whenCachedResultIsNoAppEngineApplication()
      throws ProjectRepositoryException {
    GcpProject gcpProject = new GcpProject(""projectName"", ""projectId"");
    initSelectionAndAccountSelector(gcpProject);
    gcpProject.setAppEngine(AppEngine.NO_APPENGINE_APPLICATION);

    listener.selectionChanged(event);
    assertNull(listener.latestQueryJob);
    verify(projectRepository, never()).getAppEngineApplication(any(Credential.class), anyString());
    verify(projectSelector).setStatusLink(EXPECTED_MESSAGE_WHEN_NO_APPLICATION, EXPECTED_LINK);
  }
",non-flaky,5
175806,GoogleCloudPlatform_google-cloud-eclipse,ProjectSelectorSelectionChangedListenerTest.testSelectionChanged_changeSelectedProject,"  @Test
  public void testSelectionChanged_changeSelectedProject()
      throws ProjectRepositoryException, InterruptedException {
    when(projectRepository.getAppEngineApplication(any(Credential.class), eq(""oldProjectId"")))
        .thenThrow(new ProjectRepositoryException(""testException""));
    when(projectRepository.getAppEngineApplication(any(Credential.class), eq(""projectId"")))
        .thenReturn(AppEngine.NO_APPENGINE_APPLICATION);

    initSelectionAndAccountSelector(new GcpProject(""oldProjectName"", ""oldProjectId""));
    listener.selectionChanged(event);

    Job oldJob = listener.latestQueryJob;
    assertNotNull(oldJob);
    oldJob.join();

    initSelectionAndAccountSelector();
    listener.selectionChanged(event);

    Job newJob = listener.latestQueryJob;
    assertNotNull(newJob);
    assertNotEquals(oldJob, newJob);
    newJob.join();

    verify(projectRepository).getAppEngineApplication(any(Credential.class), eq(""oldProjectId""));
    verify(projectRepository).getAppEngineApplication(any(Credential.class), eq(""projectId""));
    verify(projectSelector).setStatusLink(EXPECTED_MESSAGE_WHEN_NO_APPLICATION, EXPECTED_LINK);
  }
",non-flaky,5
175807,GoogleCloudPlatform_google-cloud-eclipse,MessagesTest.testUrlOpenErrorDialogTitle,"  @Test
  public void testUrlOpenErrorDialogTitle() {
    assertEquals(""Error"", Messages.getString(""openurllistener.error.title""));
  }
",non-flaky,5
175808,GoogleCloudPlatform_google-cloud-eclipse,MessagesTest.testUrlOpenErrorDialogMessage,"  @Test
  public void testUrlOpenErrorDialogMessage() {
    assertEquals(""Could not open URL"", Messages.getString(""openurllistener.error.message""));
  }
",non-flaky,5
175809,GoogleCloudPlatform_google-cloud-eclipse,MessagesTest.testInvalidUrlErrorMessage,"  @Test
  public void testInvalidUrlErrorMessage() {
    assertEquals(""Invalid URL: http://www.example.com"", 
        Messages.getString(""invalid.url"", ""http://www.example.com""));
  }
",non-flaky,5
175810,GoogleCloudPlatform_google-cloud-eclipse,SharedImagesTest.testCreateRefreshIcon,"  @Test
  public void testCreateRefreshIcon() {
    assertNotNull(SharedImages.REFRESH_IMAGE_DESCRIPTOR.createImage(shell.getDisplay()));
  }
",non-flaky,5
175811,GoogleCloudPlatform_google-cloud-eclipse,PluginXmlTest.testExtensionPoint,"  @Test
  public void testExtensionPoint() {
    NodeList extensions = getDocument().getElementsByTagName(""extension"");
    assertEquals(1, extensions.getLength());
    Element extension = (Element) extensions.item(0);
    assertEquals(""org.eclipse.ui.commands"", extension.getAttribute(""point""));

    NodeList commandDefinitions = extension.getElementsByTagName(""command"");
    assertEquals(1, commandDefinitions.getLength());
    Element configExtension = (Element) commandDefinitions.item(0);
    assertEquals(OpenDropDownMenuHandler.class.getName(),
        configExtension.getAttribute(""defaultHandler""));
    assertEquals(""com.google.cloud.tools.eclipse.ui.util.showPopup"",
        configExtension.getAttribute(""id""));
  }
",non-flaky,5
175812,GoogleCloudPlatform_google-cloud-eclipse,FontUtilTest.testConvertFontToBold,"  @Test
  public void testConvertFontToBold() {
    Label label = new Label(shellTestResource.getShell(), SWT.NONE);
    for (FontData fontData : label.getFont().getFontData()) {
      assertThat(fontData.getStyle(), is(not(SWT.BOLD)));
    }
    FontUtil.convertFontToBold(label);
    for (FontData fontData : label.getFont().getFontData()) {
      assertThat(fontData.getStyle(), is(SWT.BOLD));
    }
  }
",non-flaky,5
175813,GoogleCloudPlatform_google-cloud-eclipse,FontUtilTest.testConvertFontToItalic,"  @Test
  public void testConvertFontToItalic() {
    Label label = new Label(shellTestResource.getShell(), SWT.NONE);
    for (FontData fontData : label.getFont().getFontData()) {
      assertThat(fontData.getStyle(), is(not(SWT.ITALIC)));
    }
    FontUtil.convertFontToItalic(label);
    for (FontData fontData : label.getFont().getFontData()) {
      assertThat(fontData.getStyle(), is(SWT.ITALIC));
    }
  }
",non-flaky,5
175814,GoogleCloudPlatform_google-cloud-eclipse,OpenUriSelectionListenerTest.testWidgetSelected_InvalidURI,"  @Test
  public void testWidgetSelected_InvalidURI() {
    SelectionEvent selectionEvent = getEvent(INVALID_URI);

    new OpenUriSelectionListener(queryParameterProvider, errorHandler, browserSupport).widgetSelected(selectionEvent);
    verify(errorHandler).handle(captor.capture(), any(URI.class));
    assertThat(captor.getValue(), instanceOf(URISyntaxException.class));
  }
",non-flaky,5
175815,GoogleCloudPlatform_google-cloud-eclipse,OpenUriSelectionListenerTest.testWidgetDefaultSelected_InvalidURI,"  @Test
  public void testWidgetDefaultSelected_InvalidURI() {
    SelectionEvent selectionEvent = getEvent(INVALID_URI);

    new OpenUriSelectionListener(queryParameterProvider, errorHandler, browserSupport).widgetDefaultSelected(selectionEvent);
    verify(errorHandler).handle(captor.capture(), any(URI.class));
    assertThat(captor.getValue(), instanceOf(URISyntaxException.class));
  }
",non-flaky,5
175816,GoogleCloudPlatform_google-cloud-eclipse,OpenUriSelectionListenerTest.testWidgetSelected_MalformedURL,"  @Test
  public void testWidgetSelected_MalformedURL() {
    SelectionEvent selectionEvent = getEvent(MALFORMED_URL);

    new OpenUriSelectionListener(queryParameterProvider, errorHandler, browserSupport).widgetSelected(selectionEvent);
    verify(errorHandler).handle(captor.capture(), any(URI.class));
    assertThat(captor.getValue(), instanceOf(MalformedURLException.class));
  }
",non-flaky,5
175817,GoogleCloudPlatform_google-cloud-eclipse,OpenUriSelectionListenerTest.testWidgetDefaultSelected_MalformedURL,"  @Test
  public void testWidgetDefaultSelected_MalformedURL() {
    SelectionEvent selectionEvent = getEvent(MALFORMED_URL);

    new OpenUriSelectionListener(queryParameterProvider, errorHandler, browserSupport).widgetDefaultSelected(selectionEvent);
    verify(errorHandler).handle(captor.capture(), any(URI.class));
    assertThat(captor.getValue(), instanceOf(MalformedURLException.class));
  }
",non-flaky,5
175818,GoogleCloudPlatform_google-cloud-eclipse,OpenUriSelectionListenerTest.testWidgetSelected_errorInvokingBrowser,"  @Test
  public void testWidgetSelected_errorInvokingBrowser() throws PartInitException {
    SelectionEvent selectionEvent = getEvent(VALID_URI);
    doThrow(new PartInitException(""fake exception"")).when(browser).openURL(any(URL.class));

    new OpenUriSelectionListener(queryParameterProvider, errorHandler, browserSupport).widgetSelected(selectionEvent);
    verify(errorHandler).handle(captor.capture(), any(URI.class));
    assertThat(captor.getValue(), instanceOf(PartInitException.class));
  }
",non-flaky,5
175819,GoogleCloudPlatform_google-cloud-eclipse,OpenUriSelectionListenerTest.testWidgetDefaultSelected_errorInvokingBrowser,"  @Test
  public void testWidgetDefaultSelected_errorInvokingBrowser() throws PartInitException {
    SelectionEvent selectionEvent = getEvent(VALID_URI);
    doThrow(new PartInitException(""fake exception"")).when(browser).openURL(any(URL.class));

    new OpenUriSelectionListener(queryParameterProvider, errorHandler, browserSupport)
      .widgetDefaultSelected(selectionEvent);
    verify(errorHandler).handle(captor.capture(), any(URI.class));
    assertThat(captor.getValue(), instanceOf(PartInitException.class));
  }
",non-flaky,5
175820,GoogleCloudPlatform_google-cloud-eclipse,OpenUriSelectionListenerTest.testWidgetSelected_successful,"  @Test
  public void testWidgetSelected_successful() throws PartInitException, MalformedURLException {
    SelectionEvent selectionEvent = getEvent(VALID_URI);
    when(queryParameterProvider.getParameters()).thenReturn(Collections.singletonMap(URL_PARAM_PROJECT, PROJECT_ID));

    new OpenUriSelectionListener(queryParameterProvider, errorHandler, browserSupport).widgetSelected(selectionEvent);
    verify(errorHandler, never()).handle(any(Exception.class), any(URI.class));
    verify(browser).openURL(new URL(VALID_URI + ""?project="" + PROJECT_ID));
  }
",non-flaky,5
175821,GoogleCloudPlatform_google-cloud-eclipse,OpenUriSelectionListenerTest.testWidgetDefaultSelected_successful,"  @Test
  public void testWidgetDefaultSelected_successful() throws PartInitException, MalformedURLException {
    SelectionEvent selectionEvent = getEvent(VALID_URI);
    when(queryParameterProvider.getParameters()).thenReturn(Collections.singletonMap(URL_PARAM_PROJECT, PROJECT_ID));

    new OpenUriSelectionListener(queryParameterProvider, errorHandler, browserSupport)
      .widgetDefaultSelected(selectionEvent);
    verify(errorHandler, never()).handle(any(Exception.class), any(URI.class));
    verify(browser).openURL(new URL(VALID_URI + ""?project="" + PROJECT_ID));
  }
",non-flaky,5
175822,GoogleCloudPlatform_google-cloud-eclipse,BooleanConverterTest.testNegate,"  @Test
  public void testNegate() {
    assertTrue((Boolean) BooleanConverter.negate().convert(Boolean.FALSE));
    assertFalse((Boolean) BooleanConverter.negate().convert(Boolean.TRUE));
  }
",non-flaky,5
175823,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_nonStringInput,"  @Test
  public void testValidation_nonStringInput() {
    IStatus status = validator.validate(new Object());
    assertThat(status.getSeverity(), is(IStatus.ERROR));
    assertThat(status.getMessage(), is(""Invalid bucket name""));
  }
",non-flaky,5
175824,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_emptyString,"  @Test
  public void testValidation_emptyString() {
    assertThat(validator.validate("""").getSeverity(), is(IStatus.OK));
  }
",non-flaky,5
175825,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_upperCaseLetter,"  @Test
  public void testValidation_upperCaseLetter() {
    IStatus status = validator.validate(""THISWOULDBEVALIDIFLOWERCASE"");
    assertThat(status.getSeverity(), is(IStatus.ERROR));
    assertThat(status.getMessage(), is(""Invalid bucket name: THISWOULDBEVALIDIFLOWERCASE""));
  }
",non-flaky,5
175826,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_startWithDot,"  @Test
  public void testValidation_startWithDot() {
    assertThat(validator.validate("".bucket"").getSeverity(), is(IStatus.ERROR));
  }
",non-flaky,5
175827,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_endWithDot,"  @Test
  public void testValidation_endWithDot() {
    assertThat(validator.validate(""bucket."").getSeverity(), is(IStatus.ERROR));
  }
",non-flaky,5
175828,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_startWithHyphen,"  @Test
  public void testValidation_startWithHyphen() {
    assertThat(validator.validate(""-bucket"").getSeverity(), is(IStatus.ERROR));
  }
",non-flaky,5
175829,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_endWithHyphen,"  @Test
  public void testValidation_endWithHyphen() {
    assertThat(validator.validate(""bucket-"").getSeverity(), is(IStatus.ERROR));
  }
",non-flaky,5
175830,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_startWithUnderscore,"  @Test
  public void testValidation_startWithUnderscore() {
    assertThat(validator.validate(""_bucket"").getSeverity(), is(IStatus.ERROR));
  }
",non-flaky,5
175831,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_endWithUnderscore,"  @Test
  public void testValidation_endWithUnderscore() {
    assertThat(validator.validate(""bucket_"").getSeverity(), is(IStatus.ERROR));
  }
",non-flaky,5
175832,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_maxLengthWithoutDot,"  @Test
  public void testValidation_maxLengthWithoutDot() {
    assertThat(validator.validate(LENGTH_63).getSeverity(), is(IStatus.OK));
  }
",non-flaky,5
175833,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_tooLongNameWithoutDot,"  @Test
  public void testValidation_tooLongNameWithoutDot() {
    assertThat(validator.validate(LENGTH_63 + ""4"").getSeverity(), is(IStatus.ERROR));
  }
",non-flaky,5
175834,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_validNameWithDot,"  @Test
  public void testValidation_validNameWithDot() {
    assertThat(validator.validate(LENGTH_64_WITH_DOT).getSeverity(), is(IStatus.OK));
  }
",non-flaky,5
175835,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_tooLongNameWithDot,"  @Test
  public void testValidation_tooLongNameWithDot() {
    assertThat(validator.validate(LENGTH_222 + ""9"").getSeverity(), is(IStatus.ERROR));
  }
",non-flaky,5
175836,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_maxLengthWithDot,"  @Test
  public void testValidation_maxLengthWithDot() {
    assertThat(validator.validate(LENGTH_222).getSeverity(), is(IStatus.OK));
  }
",non-flaky,5
177156,line_armeria,TokenBucketThrottlingStrategyTest.serve1,"    @Test
    public void serve1() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response = client.get(""/http-serve"").aggregate().get();
        assertThat(response.status()).isEqualTo(HttpStatus.OK);

        assertThat(response.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response.headers().contains(""RateLimit-Reset"")).isFalse();
        assertThat(response.headers().contains(""X-RateLimit-Reset"")).isFalse();
        assertThat(response.headers().contains(""X-Rate-Limit-Reset"")).isFalse();
        assertThat(response.headers().contains(""RateLimit-Limit"")).isFalse();
        assertThat(response.headers().contains(""X-RateLimit-Limit"")).isFalse();
        assertThat(response.headers().contains(""X-Rate-Limit-Limit"")).isFalse();
    }
",non-flaky,5
177157,line_armeria,TokenBucketThrottlingStrategyTest.throttle1,"    @Test
    public void throttle1() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle1"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isTrue();
        final long reset1 = Long.parseLong(response1.headers().get(""X-RateLimit-Reset""));
        assertThat(reset1).isBetween(0L, 10L);
        assertThat(response1.headers().contains(""X-RateLimit-Limit"")).isFalse();

        final AggregatedHttpResponse response2 = client.get(""/http-throttle1"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.TOO_MANY_REQUESTS);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER)).isTrue();
        final long retryAfter2 = Long.parseLong(response2.headers().get(HttpHeaderNames.RETRY_AFTER));
        assertThat(retryAfter2).isBetween(0L, 10L);
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"")).isTrue();
        final long reset = Long.parseLong(response2.headers().get(""X-RateLimit-Reset""));
        assertThat(reset).isEqualTo(retryAfter2);
        assertThat(response2.headers().contains(""X-RateLimit-Limit"")).isFalse();
    }
",non-flaky,5
177158,line_armeria,TokenBucketThrottlingStrategyTest.throttle2,"    @Test
    public void throttle2() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle2"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isTrue();
        final long reset1 = Long.parseLong(response1.headers().get(""X-RateLimit-Reset""));
        assertThat(reset1).isBetween(0L, 10L);
        assertThat(response1.headers().get(""X-RateLimit-Limit"")).isEqualTo(""1, 1;window=10"");

        final AggregatedHttpResponse response2 = client.get(""/http-throttle2"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.TOO_MANY_REQUESTS);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER, ""15"")).isTrue();
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"", ""15"")).isTrue();
        assertThat(response1.headers().get(""X-RateLimit-Limit"")).isEqualTo(""1, 1;window=10"");
    }
",non-flaky,5
177159,line_armeria,TokenBucketThrottlingStrategyTest.throttle3,"    @Test
    public void throttle3() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle3"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isFalse();

        final AggregatedHttpResponse response2 = client.get(""/http-throttle3"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.TOO_MANY_REQUESTS);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER)).isTrue();
        final long retryAfter2 = Long.parseLong(response2.headers().get(HttpHeaderNames.RETRY_AFTER));
        assertThat(retryAfter2).isBetween(0L, 10L);
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"")).isFalse();
    }
",non-flaky,5
177160,line_armeria,TokenBucketThrottlingStrategyTest.throttle4,"    @Test
    public void throttle4() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle4"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isFalse();

        final AggregatedHttpResponse response2 = client.get(""/http-throttle4"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.SERVICE_UNAVAILABLE);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER)).isTrue();
        final long retryAfter2 = Long.parseLong(response2.headers().get(HttpHeaderNames.RETRY_AFTER));
        assertThat(retryAfter2).isBetween(5L, 10L);
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"")).isFalse();
    }
",non-flaky,5
177161,line_armeria,SamlRequestIdManagerTest.shouldBeDifferentToEachOther,"    @Test
    public void shouldBeDifferentToEachOther() throws UnsupportedEncodingException {
        final SamlRequestIdManager manager =
                SamlRequestIdManager.ofJwt(""me"", ""test"", 60, 5);

        final String id1 = manager.newId();
        final String id2 = manager.newId();
        final String id3 = manager.newId();

        assertThat(id1).isNotEqualTo(id2).isNotEqualTo(id3);
        assertThat(id2).isNotEqualTo(id3);
    }
",non-flaky,5
177162,line_armeria,SamlRequestIdManagerTest.shouldMatchJWTPattern,"    @Test
    public void shouldMatchJWTPattern() throws UnsupportedEncodingException {
        final Pattern p = Pattern.compile(""[a-zA-Z0-9-_]+\\.[a-zA-Z0-9-_]+\\.[a-zA-Z0-9-_]+"");
        final SamlRequestIdManager manager =
                SamlRequestIdManager.ofJwt(""me"", ""test"", 60, 5);
        final String id = manager.newId();
        assertThat(p.matcher(id).matches()).isTrue();
        assertThat(manager.validateId(id)).isTrue();
    }
",non-flaky,5
177163,line_armeria,SamlRequestIdManagerTest.shouldBeExpired,"    @Test
    public void shouldBeExpired() throws InterruptedException, UnsupportedEncodingException {
        final SamlRequestIdManager manager =
                SamlRequestIdManager.ofJwt(""me"", ""test"", 1, 0);

        final Instant started = Instant.now();
        final String id = manager.newId();
        assertThat(manager.validateId(id)).isTrue();

        await().pollDelay(Durations.TWO_HUNDRED_MILLISECONDS)
               .atMost(Durations.FIVE_SECONDS)
               .untilAsserted(() -> assertThat(manager.validateId(id)).isFalse());

        assertThat(java.time.Duration.between(started, Instant.now()).toMillis())
                .isGreaterThan(TimeUnit.SECONDS.toMillis(1));
    }
",non-flaky,5
177164,line_armeria,SamlRequestIdManagerTest.shouldBeAcceptedBecauseOfLeeway,"    @Test
    public void shouldBeAcceptedBecauseOfLeeway() throws InterruptedException, UnsupportedEncodingException {
        final SamlRequestIdManager manager =
                SamlRequestIdManager.ofJwt(""me"", ""test"", 1, 1);

        final Instant started = Instant.now();
        final String id = manager.newId();
        assertThat(manager.validateId(id)).isTrue();

        await().pollDelay(Durations.TWO_HUNDRED_MILLISECONDS)
               .atMost(Durations.FIVE_SECONDS)
               .untilAsserted(() -> assertThat(manager.validateId(id)).isFalse());

        assertThat(java.time.Duration.between(started, Instant.now()).toMillis())
                .isGreaterThan(TimeUnit.SECONDS.toMillis(2));
    }
",non-flaky,5
177165,line_armeria,SamlRequestIdManagerTest.shouldFail,"    @Test
    public void shouldFail() {
        assertThatThrownBy(() -> SamlRequestIdManager.ofJwt(""me"", ""test"", 0, 0))
                .isInstanceOf(IllegalArgumentException.class);
        assertThatThrownBy(() -> SamlRequestIdManager.ofJwt(""me"", ""test"", -1, 0))
                .isInstanceOf(IllegalArgumentException.class);
        assertThatThrownBy(() -> SamlRequestIdManager.ofJwt(""me"", ""test"", 1, -1))
                .isInstanceOf(IllegalArgumentException.class);
    }
",non-flaky,5
177166,line_armeria,SamlServiceProviderTest.shouldRespondAuthnRequest_HttpRedirect,"    @Test
    public void shouldRespondAuthnRequest_HttpRedirect() throws Exception {
        final AggregatedHttpResponse resp = client.get(""/redirect"").aggregate().join();
        assertThat(resp.status()).isEqualTo(HttpStatus.FOUND);

        // Check the order of the parameters in the quest string.
        final String location = resp.headers().get(HttpHeaderNames.LOCATION);
        final Pattern p = Pattern.compile(
                ""http://idp\\.example\\.com/saml/sso/redirect\\?"" +
                ""SAMLRequest=([^&]+)&RelayState=([^&]+)&SigAlg=([^&]+)&Signature=(.+)$"");
        assertThat(location).isNotNull();
        assertThat(p.matcher(location).matches()).isTrue();

        assertThat(QueryParams.fromQueryString(location)
                              .get(SIGNATURE_ALGORITHM)).isEqualTo(signatureAlgorithm);
    }
",non-flaky,5
177167,line_armeria,SamlServiceProviderTest.shouldRespondAuthnRequest_HttpPost,"    @Test
    public void shouldRespondAuthnRequest_HttpPost() throws Exception {
        final AggregatedHttpResponse resp = client.get(""/post"").aggregate().join();
        assertThat(resp.status()).isEqualTo(HttpStatus.OK);
        assertThat(resp.contentType()).isEqualTo(MediaType.HTML_UTF_8);

        final Document doc = Jsoup.parse(resp.contentUtf8());
        assertThat(doc.body().attr(""onLoad"")).isEqualTo(""document.forms[0].submit()"");

        // SAMLRequest will be posted to the IdP's SSO URL.
        final Element form = doc.body().child(0);
        assertThat(form.attr(""method"")).isEqualTo(""post"");
        assertThat(form.attr(""action"")).isEqualTo(""http://idp.example.com/saml/sso/post"");
        assertThat(form.child(0).attr(""name"")).isEqualTo(SAML_REQUEST);
        assertThat(form.child(1).attr(""name"")).isEqualTo(RELAY_STATE);
    }
",non-flaky,5
177168,line_armeria,SamlServiceProviderTest.shouldBeAlreadyAuthenticated,"    @Test
    public void shouldBeAlreadyAuthenticated() throws Exception {
        final RequestHeaders req = RequestHeaders.of(HttpMethod.GET, ""/redirect"",
                                                     HttpHeaderNames.COOKIE, ""test=test"");
        final AggregatedHttpResponse resp = client.execute(req).aggregate().join();
        assertThat(resp.status()).isEqualTo(HttpStatus.OK);
        assertThat(resp.contentUtf8()).isEqualTo(""authenticated"");
    }
",non-flaky,5
177169,line_armeria,SamlServiceProviderTest.shouldRespondMetadataWithoutAuthentication,"    @Test
    public void shouldRespondMetadataWithoutAuthentication() throws Exception {
        final AggregatedHttpResponse resp = client.get(""/saml/metadata"").aggregate().join();
        assertThat(resp.status()).isEqualTo(HttpStatus.OK);
        assertThat(resp.contentType()).isEqualTo(CONTENT_TYPE_SAML_METADATA);

        final EntityDescriptor metadata =
                (EntityDescriptor) deserialize(resp.contentUtf8().getBytes());
        assertThat(metadata).isNotNull();

        final SPSSODescriptor sp = metadata.getSPSSODescriptor(SAMLConstants.SAML20P_NS);
        assertThat(sp.isAuthnRequestsSigned()).isTrue();
        assertThat(sp.getWantAssertionsSigned()).isTrue();

        final List<KeyDescriptor> kd = sp.getKeyDescriptors();
        assertThat(kd.get(0).getUse().name()).isEqualToIgnoringCase(""signing"");
        assertThat(kd.get(1).getUse().name()).isEqualToIgnoringCase(""encryption"");

        final List<SingleLogoutService> slo = sp.getSingleLogoutServices();
        assertThat(slo.get(0).getLocation())
                .isEqualTo(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/slo/post"");
        assertThat(slo.get(0).getBinding()).isEqualTo(SAMLConstants.SAML2_POST_BINDING_URI);
        assertThat(slo.get(1).getLocation())
                .isEqualTo(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/slo/redirect"");
        assertThat(slo.get(1).getBinding()).isEqualTo(SAMLConstants.SAML2_REDIRECT_BINDING_URI);

        final List<AssertionConsumerService> acs = sp.getAssertionConsumerServices();
        // index 0 (default)
        assertThat(acs.get(0).getIndex()).isEqualTo(0);
        assertThat(acs.get(0).isDefault()).isTrue();
        assertThat(acs.get(0).getLocation())
                .isEqualTo(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/acs/post"");
        assertThat(acs.get(0).getBinding()).isEqualTo(SAMLConstants.SAML2_POST_BINDING_URI);
        // index 1
        assertThat(acs.get(1).getIndex()).isEqualTo(1);
        assertThat(acs.get(1).isDefault()).isFalse();
        assertThat(acs.get(1).getLocation())
                .isEqualTo(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/acs/redirect"");
        assertThat(acs.get(1).getBinding()).isEqualTo(SAMLConstants.SAML2_REDIRECT_BINDING_URI);
    }
",non-flaky,5
177170,line_armeria,SamlServiceProviderTest.shouldConsumeAssertion_HttpPost,"    @Test
    public void shouldConsumeAssertion_HttpPost() throws Exception {
        final Response response =
                getAuthResponse(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/acs/post"");
        final AggregatedHttpResponse res = sendViaHttpPostBindingProtocol(""/saml/acs/post"",
                                                                          SAML_RESPONSE, response);

        assertThat(res.status()).isEqualTo(HttpStatus.FOUND);
        assertThat(res.headers().get(HttpHeaderNames.LOCATION)).isEqualTo(""/"");
    }
",non-flaky,5
177171,line_armeria,SamlServiceProviderTest.shouldConsumeAssertion_HttpRedirect,"    @Test
    public void shouldConsumeAssertion_HttpRedirect() throws Exception {
        final Response response =
                getAuthResponse(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/acs/redirect"");
        final AggregatedHttpResponse res = sendViaHttpRedirectBindingProtocol(""/saml/acs/redirect"",
                                                                              SAML_RESPONSE, response);

        assertThat(res.status()).isEqualTo(HttpStatus.FOUND);
        assertThat(res.headers().get(HttpHeaderNames.LOCATION)).isEqualTo(""/"");
    }
",non-flaky,5
177172,line_armeria,SamlServiceProviderTest.shouldConsumeLogoutRequest_HttpPost,"    @Test
    public void shouldConsumeLogoutRequest_HttpPost() throws Exception {
        final LogoutRequest logoutRequest =
                getLogoutRequest(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/slo/post"",
                                 ""http://idp.example.com/post"");

        final AggregatedHttpResponse res = sendViaHttpPostBindingProtocol(""/saml/slo/post"",
                                                                          SAML_REQUEST, logoutRequest);

        assertThat(res.status()).isEqualTo(HttpStatus.OK);
        assertThat(res.contentType()).isEqualTo(MediaType.HTML_UTF_8);

        final Document doc = Jsoup.parse(res.contentUtf8());
        assertThat(doc.body().attr(""onLoad"")).isEqualTo(""document.forms[0].submit()"");

        // SAMLResponse will be posted to the IdP's logout response URL.
        final Element form = doc.body().child(0);
        assertThat(form.attr(""method"")).isEqualTo(""post"");
        assertThat(form.attr(""action"")).isEqualTo(""http://idp.example.com/saml/slo/post"");
        assertThat(form.child(0).attr(""name"")).isEqualTo(SAML_RESPONSE);
    }
",non-flaky,5
177173,line_armeria,SamlServiceProviderTest.shouldConsumeLogoutRequest_HttpRedirect,"    @Test
    public void shouldConsumeLogoutRequest_HttpRedirect() throws Exception {
        final LogoutRequest logoutRequest =
                getLogoutRequest(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/slo/redirect"",
                                 ""http://idp.example.com/redirect"");

        final AggregatedHttpResponse res =
                sendViaHttpRedirectBindingProtocol(""/saml/slo/redirect"", SAML_REQUEST, logoutRequest);

        assertThat(res.status()).isEqualTo(HttpStatus.FOUND);

        // Check the order of the parameters in the quest string.
        final String location = res.headers().get(HttpHeaderNames.LOCATION);
        final Pattern p = Pattern.compile(
                ""http://idp\\.example\\.com/saml/slo/redirect\\?"" +
                ""SAMLResponse=([^&]+)&SigAlg=([^&]+)&Signature=(.+)$"");
        assertThat(location).isNotNull();
        assertThat(p.matcher(location).matches()).isTrue();
    }
",non-flaky,5
177174,line_armeria,KeyStoreCredentialResolverBuilderTest.expectSuccessWithFile,"    @Test
    public void expectSuccessWithFile() throws Exception {
        final File file = folder.newFile();

        assertThat(file.length()).isZero();

        final KeyStore keyStore = KeyStore.getInstance(""JKS"");
        keyStore.load(null, null);
        keyStore.store(new FileOutputStream(file), """".toCharArray());

        assertThat(file.length()).isGreaterThan(0);
        assertThat(file.canRead()).isTrue();
        assertThat(file.exists()).isTrue();

        new KeyStoreCredentialResolverBuilder(file).build();
    }
",non-flaky,5
177175,line_armeria,KeyStoreCredentialResolverBuilderTest.expectSuccessWithResource,"    @Test
    public void expectSuccessWithResource() throws Exception {
        new KeyStoreCredentialResolverBuilder(getClass().getClassLoader(), ""keystore/test.jks"").build();
    }
",non-flaky,5
177176,line_armeria,KeyStoreCredentialResolverBuilderTest.expectNotFound,"    @Test
    public void expectNotFound() throws Exception {
        assertThatThrownBy(
                () -> new KeyStoreCredentialResolverBuilder(new File(""/not_exist"")).build())
                .isInstanceOf(FileNotFoundException.class);
        assertThatThrownBy(
                () -> new KeyStoreCredentialResolverBuilder(getClass().getClassLoader(), ""not_exist"").build())
                .isInstanceOf(FileNotFoundException.class)
                .hasMessageContaining(""Resource not found"");
    }
",non-flaky,5
177177,line_armeria,BraveIntegrationTest.onComplete,"    @Test
        public void onComplete(String response) {
            resultHandler.onComplete(response);
        }
",non-flaky,5
177178,line_armeria,BraveClientIntegrationTest.callbackContextIsFromInvocationTime_root,"    @Test
    public void callbackContextIsFromInvocationTime_root() {
        try (SafeCloseable ignored = serverContext().push()) {
            super.callbackContextIsFromInvocationTime_root();
        }
    }
",non-flaky,5
177179,line_armeria,BraveClientIntegrationTest.addsStatusCodeWhenNotOk_async,"    @Test
    public void addsStatusCodeWhenNotOk_async() {
        try (SafeCloseable ignored = serverContext().push()) {
            super.addsStatusCodeWhenNotOk_async();
        }
    }
",non-flaky,5
177180,line_armeria,BraveClientIntegrationTest.usesParentFromInvocationTime,"    @Test
    public void usesParentFromInvocationTime() {
        try (SafeCloseable ignored = serverContext().push()) {
            super.usesParentFromInvocationTime();
        }
    }
",non-flaky,5
177181,line_armeria,BraveClientIntegrationTest.clientTimestampAndDurationEnclosedByParent,"    @Test
    public void clientTimestampAndDurationEnclosedByParent() {
    }
",non-flaky,5
177182,line_armeria,BraveClientIntegrationTest.callbackContextIsFromInvocationTime,"    @Test
    public void callbackContextIsFromInvocationTime() {
        // TODO(trustin): Can't make this pass because span is updated *after* we invoke the callback
        //                ITHttpAsyncClient gave us.
    }
",non-flaky,5
177183,line_armeria,BraveClientIntegrationTest.redirect,"    @Test
    public void redirect() {
        throw new AssumptionViolatedException(""Armeria does not support client redirect."");
    }
",non-flaky,5
177184,line_armeria,RequestContextCurrentTraceContextTest.get_returnsNullWhenNoCurrentRequestContext,"    @Test
    public void get_returnsNullWhenNoCurrentRequestContext() {
        assertThat(currentTraceContext.get()).isNull();
    }
",non-flaky,5
177185,line_armeria,RequestContextCurrentTraceContextTest.get_returnsNullWhenCurrentRequestContext_hasNoTraceAttribute,"    @Test
    public void get_returnsNullWhenCurrentRequestContext_hasNoTraceAttribute() {
        try (SafeCloseable requestContextScope = ctx.push()) {
            assertThat(currentTraceContext.get()).isNull();
        }
    }
",non-flaky,5
177186,line_armeria,RequestContextCurrentTraceContextTest.newScope_appliesWhenNoCurrentRequestContext,"    @Test
    public void newScope_appliesWhenNoCurrentRequestContext() {
        try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
            assertThat(traceContextScope).hasToString(""ThreadLocalScope"");
            assertThat(currentTraceContext.get()).isEqualTo(traceContext);
        }
    }
",non-flaky,5
177187,line_armeria,RequestContextCurrentTraceContextTest.newScope_appliesWhenCurrentRequestContext,"    @Test
    public void newScope_appliesWhenCurrentRequestContext() {
        try (SafeCloseable requestContextScope = ctx.push()) {
            try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
                assertThat(traceContextScope).hasToString(""InitialRequestScope"");
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);
            }
        }
    }
",non-flaky,5
177188,line_armeria,RequestContextCurrentTraceContextTest.newScope_closeDoesntClearFirstScope,"    @Test
    public void newScope_closeDoesntClearFirstScope() {
        final TraceContext traceContext2 = TraceContext.newBuilder().traceId(1).spanId(2).build();

        try (SafeCloseable requestContextScope = ctx.push()) {
            try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
                assertThat(traceContextScope).hasToString(""InitialRequestScope"");
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);

                try (Scope traceContextScope2 = currentTraceContext.newScope(traceContext2)) {
                    assertThat(traceContextScope2).hasToString(""RequestContextTraceContextScope"");
                    assertThat(currentTraceContext.get()).isEqualTo(traceContext2);
                }
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);
            }
            // the first scope is attached to the request context and cleared when that's destroyed
            assertThat(currentTraceContext.get()).isEqualTo(traceContext);
        }
    }
",non-flaky,5
177189,line_armeria,RequestContextCurrentTraceContextTest.newScope_notOnEventLoop,"    @Test
    public void newScope_notOnEventLoop() {
        final TraceContext traceContext2 = TraceContext.newBuilder().traceId(1).spanId(2).build();

        try (SafeCloseable requestContextScope = ctx.push()) {
            try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
                assertThat(traceContextScope).hasToString(""InitialRequestScope"");
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);

                when(eventLoop.inEventLoop()).thenReturn(false);
                try (Scope traceContextScope2 = currentTraceContext.newScope(traceContext2)) {
                    assertThat(traceContextScope2).hasToString(""ThreadLocalScope"");
                    assertThat(currentTraceContext.get()).isEqualTo(traceContext2);
                }
                when(eventLoop.inEventLoop()).thenReturn(true);
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);
            }
            // the first scope is attached to the request context and cleared when that's destroyed
            assertThat(currentTraceContext.get()).isEqualTo(traceContext);
        }
    }
",non-flaky,5
177190,line_armeria,RequestContextCurrentTraceContextTest.newScope_canClearScope,"    @Test
    public void newScope_canClearScope() {
        try (SafeCloseable requestContextScope = ctx.push()) {
            try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
                try (Scope traceContextScope2 = currentTraceContext.newScope(null)) {
                    assertThat(currentTraceContext.get()).isNull();
                }
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);
            }
        }
    }
",non-flaky,5
177191,line_armeria,RequestContextCurrentTraceContextTest.newScope_respondsToPing,"    @Test
    public void newScope_respondsToPing() {
        final PingPongExtra extra = new PingPongExtra();
        final TraceContext extraContext = TraceContext.newBuilder().traceId(1).spanId(1)
                                                      .addExtra(extra).build();

        try (Scope traceContextScope = currentTraceContext.newScope(extraContext)) {
            assertThat(traceContextScope).hasToString(""NoopScope"");
            assertThat(extra.isPong()).isTrue();
        }
    }
",non-flaky,5
177192,line_armeria,RequestContextCurrentTraceContextTest.shouldSetPongIfOnlyExtra,"    @Test
    public void shouldSetPongIfOnlyExtra() {
        final PingPongExtra extra = new PingPongExtra();

        final TraceContext context = TraceContext.newBuilder().traceId(1).spanId(1)
                                                 .addExtra(extra).build();

        TraceContextUtil.PingPongExtra.maybeSetPong(context);

        assertThat(extra.isPong()).isTrue();
    }
",non-flaky,5
177193,line_armeria,BraveServiceIntegrationTest.notFound,"    @Test
    public void notFound() {
        throw new AssumptionViolatedException(
                ""Armeria yields 'get /*' as a span name for a non-existent mapping."");
    }
",non-flaky,5
177194,line_armeria,BraveServiceIntegrationTest.httpStatusCodeSettable_onUncaughtException,"    @Test
    public void httpStatusCodeSettable_onUncaughtException() {
        throw new AssumptionViolatedException(
            ""Can't currently control the HTTP status code on uncaught exception. #2656"");
    }
",non-flaky,5
177195,line_armeria,BraveServiceIntegrationTest.httpStatusCodeSettable_onUncaughtException_async,"    @Test
    public void httpStatusCodeSettable_onUncaughtException_async() {
        throw new AssumptionViolatedException(
            ""Can't currently control the HTTP status code on uncaught exception. #2656"");
    }
",non-flaky,5
177196,line_armeria,BraveServiceTest.tearDown,"    @AfterEach
    public void tearDown() {
        Tracing.current().close();
    }
",non-flaky,5
177197,line_armeria,BraveServiceTest.serve,"    @Test
            public HttpResponse serve(ServiceRequestContext ctx, HttpRequest req) throws Exception {
                return HttpResponse.of(HttpStatus.OK);
            }
",non-flaky,5
177198,line_armeria,RequestContextStorageCustomizingTest.pop,"    @Test
            public void pop(RequestContext current, @Nullable RequestContext toRestore) {
                popped.set(true);
                super.pop(current, toRestore);
            }
",non-flaky,5
177199,line_armeria,SpringTomcatApplicationItTest.contextLoads,"    @Test
    public void contextLoads() {
        assertThat(greetingController).isNotNull();
    }
",non-flaky,5
177200,line_armeria,SpringTomcatApplicationItTest.verifyTomcatVersion,"    @Test
    public void verifyTomcatVersion() {
        assertThat(TomcatVersion.major()).isEqualTo(tomcatMajorVersion);
        assertThat(TomcatVersion.minor()).isEqualTo(tomcatMinorVersion);
    }
",non-flaky,5
177201,line_armeria,SpringTomcatApplicationItTest.verifySingleConnector,"    @Test
    public void verifySingleConnector() {
        // Relevant to Tomcat 9.0
        assertThat(applicationContext).isInstanceOf(WebServerApplicationContext.class);
        final WebServer webServer = ((WebServerApplicationContext) applicationContext).getWebServer();
        assertThat(webServer).isInstanceOf(TomcatWebServer.class);
        assertThat(((TomcatWebServer) webServer).getTomcat()
                                                .getEngine()
                                                .getService()
                                                .findConnectors()).hasSize(1);
    }
",non-flaky,5
177202,line_armeria,SpringTomcatApplicationItTest.greetingShouldReturnDefaultMessage,"    @Test
    public void greetingShouldReturnDefaultMessage() throws Exception {
        assertThat(restTemplate.getForObject(""http://localhost:"" +
                                             httpPort +
                                             ""/tomcat/api/rest/v1/greeting"",
                                             String.class))
                .contains(""Hello, World!"");
    }
",non-flaky,5
177203,line_armeria,SpringTomcatApplicationItTest.greetingShouldReturnUsersMessage,"    @Test
    public void greetingShouldReturnUsersMessage() throws Exception {
        assertThat(restTemplate.getForObject(""http://localhost:"" +
                                             httpPort +
                                             ""/tomcat/api/rest/v1/greeting?name=Armeria"",
                                             String.class))
                .contains(""Hello, Armeria!"");
    }
",non-flaky,5
177204,line_armeria,SpringTomcatApplicationItTest.greetingShouldReturn404,"    @Test
    public void greetingShouldReturn404() throws Exception {
        assertThat(restTemplate.getForEntity(""http://localhost:"" +
                                             httpPort +
                                             ""/tomcat/api/rest/v1/greet"",
                                             Void.class)
                               .getStatusCode()).isEqualByComparingTo(HttpStatus.NOT_FOUND);
    }
",non-flaky,5
177205,line_armeria,SpringTomcatApplicationItTest.contextLoads,"    @Test
    public void contextLoads() {
        assertThat(applicationContext.getBean(ArmeriaAutoConfiguration.class)).isNotNull();
        assertThatThrownBy(() -> {
            applicationContext.getBean(ArmeriaReactiveWebServerFactory.class);
        }).isInstanceOf(BeansException.class);
    }
",non-flaky,5
177206,line_armeria,SpringApplicationItTest.contextLoads,"    @Test
    public void contextLoads() {
        assertThat(applicationContext.getBean(ArmeriaReactiveWebServerFactory.class)).isNotNull();
        assertThatThrownBy(() -> {
            applicationContext.getBean(ArmeriaAutoConfiguration.class);
        }).isInstanceOf(BeansException.class);
    }
",non-flaky,5
177207,line_armeria,HBaseClientCompatibilityTest.testGuavaConflict,"    @Test(expected = NotAllMetaRegionsOnlineException.class)
    public void testGuavaConflict() throws Exception {
        // Make sure Armeria is available in the class path.
        assertThat(Version.getAll(Server.class.getClassLoader())).isNotNull();
        // Make sure newer Guava is available in the class path.
        assertThat(Stopwatch.class.getDeclaredConstructor().getModifiers()).is(new Condition<>(
                value -> !Modifier.isPublic(value),
                ""Recent Guava Stopwatch should have non-public default constructor.""));

        final MetaTableLocator locator = new MetaTableLocator();
        final ZooKeeperWatcher zkw = mock(ZooKeeperWatcher.class);
        final RecoverableZooKeeper zk = mock(RecoverableZooKeeper.class);
        when(zkw.getRecoverableZooKeeper()).thenReturn(zk);
        when(zk.exists(any(), any())).thenReturn(new Stat(0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0));

        locator.waitMetaRegionLocation(zkw, 100);
    }
",non-flaky,5
177208,line_armeria,ClientAuthIntegrationTest.normal,"    @Test
    public void normal() {
        try (ClientFactory clientFactory =
                     ClientFactory.builder()
                                  .tlsCustomizer(ctx -> ctx.keyManager(clientCert.certificateFile(),
                                                                       clientCert.privateKeyFile()))
                                  .tlsNoVerify()
                                  .build()) {
            final WebClient client = WebClient.builder(rule.httpsUri())
                                              .factory(clientFactory)
                                              .decorator(LoggingClient.builder().newDecorator())
                                              .build();
            assertThat(client.get(""/"").aggregate().join().status()).isEqualTo(HttpStatus.OK);
        }
    }
",non-flaky,5
177209,line_armeria,HttpProxyIntegrationTest.onSubscribe,"    @Test
    public void proxyWithTrailers() throws Throwable {
        final WebClient client = WebClient.of(frontendServer.httpUri());

        final AtomicBoolean headersReceived = new AtomicBoolean();
        final AtomicBoolean complete = new AtomicBoolean();
        final AtomicReference<Throwable> error = new AtomicReference<>();

        client.get(""/trailers"").subscribe(new Subscriber<HttpObject>() {
            @Override
            public void onSubscribe(Subscription s) {
                s.request(Long.MAX_VALUE);
            }
",non-flaky,5
177210,line_armeria,HttpProxyIntegrationTest.onSubscribe,"    @Test
    public void proxyWithTrailersOnly() throws Throwable {
        final WebClient client = WebClient.of(frontendServer.httpUri());

        final AtomicBoolean complete = new AtomicBoolean();
        final AtomicReference<Throwable> error = new AtomicReference<>();

        client.get(""/trailers-only"").subscribe(new Subscriber<HttpObject>() {
            @Override
            public void onSubscribe(Subscription s) {
                s.request(Long.MAX_VALUE);
            }
",non-flaky,5
177211,line_armeria,Http2ClientWithPushPromiseTest.onSettingsRead,"    @Test
        public void onSettingsRead(ChannelHandlerContext ctx, Http2Settings settings) {
            assertThat(settings.pushEnabled()).isFalse();
        }
",non-flaky,5
177212,line_armeria,HttpClientDelegateTest.testExtractHost,"    @Test
    public void testExtractHost() {
        // additionalRequestHeaders has the highest precedence.
        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, ""foo"")),
                               HttpRequest.of(RequestHeaders.of(HttpMethod.GET, ""/"",
                                                                HttpHeaderNames.AUTHORITY, ""bar:8080"")),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""foo"");

        // Request header
        assertThat(extractHost(context(HttpHeaders.of()),
                               HttpRequest.of(RequestHeaders.of(HttpMethod.GET, ""/"",
                                                                HttpHeaderNames.AUTHORITY, ""bar:8080"")),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""bar"");

        // Endpoint.host() has the lowest precedence.
        assertThat(extractHost(context(HttpHeaders.of()),
                               HttpRequest.of(HttpMethod.GET, ""/""),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""baz"");

        // IPv6 address authority
        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, ""[::1]:8443"")),
                               HttpRequest.of(HttpMethod.GET, ""/""),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""::1"");

        // An invalid authority should be ignored.
        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, ""[::1"")),
                               HttpRequest.of(HttpMethod.GET, ""/""),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""baz"");

        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, "":8080"")),
                               HttpRequest.of(HttpMethod.GET, ""/""),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""baz"");

        // If additionalRequestHeader's authority is invalid but req.authority() is valid,
        // use the authority from 'req'.
        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, ""[::1"")),
                               HttpRequest.of(RequestHeaders.of(HttpMethod.GET, ""/"",
                                                                HttpHeaderNames.AUTHORITY, ""bar"")),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""bar"");

        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, "":8080"")),
                               HttpRequest.of(RequestHeaders.of(HttpMethod.GET, ""/"",
                                                                HttpHeaderNames.AUTHORITY, ""bar"")),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""bar"");
    }
",non-flaky,5
177213,line_armeria,HttpClientMaxConcurrentStreamTest.connectionOpen,"    @Test
            public void connectionOpen(SessionProtocol protocol, InetSocketAddress remoteAddr,
                                       InetSocketAddress localAddr, AttributeMap attrs) throws Exception {
                openRunnable.run();
            }
",non-flaky,5
177214,line_armeria,ClientOptionsBuilderTest.execute,"    @Test
        public HttpResponse execute(ClientRequestContext ctx, HttpRequest req) throws Exception {
            // Will never reach here.
            throw new Error();
        }
",non-flaky,5
177215,line_armeria,HttpDecodedResponseTest.onSubscribe,"    @Test
            public void onSubscribe(Subscription s) {
                s.request(Long.MAX_VALUE);
            }
",non-flaky,5
177216,line_armeria,AbstractStreamDecoderTest.notEmpty,"    @Test
    public void notEmpty() {
        final StreamDecoder decoder = newDecoder();
        final ByteBuf buf = ByteBufAllocator.DEFAULT.buffer();
        buf.writeBytes(PAYLOAD);
        final HttpData data = decoder.decode(HttpData.wrap(buf));
        assertThat(buf.refCnt()).isZero();
        assertThat(data.byteBuf().refCnt()).isOne();
        data.close();
    }
",non-flaky,5
177217,line_armeria,AbstractStreamDecoderTest.empty_unpooled,"    @Test
    public void empty_unpooled() {
        final StreamDecoder decoder = newDecoder();
        final HttpData data = decoder.decode(HttpData.empty());
        assertThat(data.isPooled()).isFalse();
    }
",non-flaky,5
177218,line_armeria,AbstractStreamDecoderTest.empty_pooled,"    @Test
    public void empty_pooled() {
        final StreamDecoder decoder = newDecoder();
        final ByteBuf buf = ByteBufAllocator.DEFAULT.buffer();
        final HttpData data = decoder.decode(HttpData.wrap(buf));
        assertThat(buf.refCnt()).isZero();

        // Even for a pooled empty input, the result is unpooled since there's no point in pooling empty
        // buffers.
        assertThat(data.isPooled()).isFalse();
    }
",non-flaky,5
177219,line_armeria,FileWatcherRunnableTest.testPropertyFileWatcherRunnableExitsOnInterrupt,"    @Test
    public void testPropertyFileWatcherRunnableExitsOnInterrupt() throws InterruptedException {
        final WatchService watchService = mock(WatchService.class);
        final FileWatcherRunnable fileWatcherRunnable = new FileWatcherRunnable(watchService, mock(
                FileSystemWatchContext.class));
        when(watchService.take()).then(invocation -> {
            while (!Thread.currentThread().isInterrupted()) {
                Thread.yield();
            }
            return null;
        });
        final Thread thread = new Thread(fileWatcherRunnable);
        thread.start();
        thread.interrupt();
        await().untilAsserted(() -> assertThat(thread.isAlive()).isFalse());
    }
",non-flaky,5
177220,line_armeria,AbstractEndpointSelectorTest.selectNow,"    @Test
            public Endpoint selectNow(ClientRequestContext ctx) {
                final List<Endpoint> endpoints = endpointGroup.endpoints();
                return endpoints.isEmpty() ? null : endpoints.get(0);
            }
",non-flaky,5
177221,line_armeria,EndpointGroupUtilTest.testGetEndpointGroupName,"    @Test
    public void testGetEndpointGroupName() throws Exception {
        assertNull(getEndpointGroupName(""http://myGroupName/""));
        assertNull(getEndpointGroupName(""http://myGroupName:8080/xxx""));
        assertNull(getEndpointGroupName(""http://group1:myGroupName:8080/""));
        assertNull(getEndpointGroupName(""http://username:password@myGroupName:8080/""));

        assertEquals(""myGroupName"", getEndpointGroupName(""http://"" + endpointGroupMark + ""myGroupName/""));
        assertEquals(""myGroupName"", getEndpointGroupName(""http://"" + endpointGroupMark + ""myGroupName:8080/""));
        assertEquals(""myGroupName"", getEndpointGroupName(""http://"" + endpointGroupMark + ""myGroupName:8080/""));
        assertEquals(""myGroupName"", getEndpointGroupName(""http://username:password@"" + endpointGroupMark +
                                                         ""myGroupName:8080/""));
    }
",non-flaky,5
177222,line_armeria,EndpointGroupUtilTest.testReplace,"    @Test
    public void testReplace() throws Exception {
        final String replacement = ""127.0.0.1:1234"";
        assertEquals(""http://myGroupName/"",
                     replaceEndpointGroup(""http://myGroupName/"", replacement));
        assertEquals(""http://myGroupName:8080/xxx"",
                     replaceEndpointGroup(""http://myGroupName:8080/xxx"", replacement));
        assertEquals(""http://group1:myGroupName:8080/"",
                     replaceEndpointGroup(""http://group1:myGroupName:8080/"", replacement));
        assertEquals(""http://username:password@myGroupName:8080/"",
                     replaceEndpointGroup(""http://username:password@myGroupName:8080/"", replacement));

        assertEquals(""http://127.0.0.1:1234/"",
                     replaceEndpointGroup(""http://"" + endpointGroupMark + ""myGroupName/"", replacement));
        assertEquals(""http://127.0.0.1:1234/"",
                     replaceEndpointGroup(""http://"" + endpointGroupMark + ""myGroupName:8080/"", replacement));
        assertEquals(""http://127.0.0.1:1234/xxx"",
                     replaceEndpointGroup(""http://"" + endpointGroupMark + ""myGroupName:8080/xxx"", replacement));
        assertEquals(""http://username:password@127.0.0.1:1234/xxx"",
                     replaceEndpointGroup(""http://username:password@"" + endpointGroupMark +
                                          ""myGroupName:8080/xxx"", replacement));
    }
",non-flaky,5
177223,line_armeria,WeightRampingUpStrategyTest.compare,"    @Test
        public int compare(Endpoint o1, Endpoint o2) {
            if (o1.equals(o2) && o1.weight() == o2.weight()) {
                return 0;
            }
            return -1;
        }
",non-flaky,5
177224,line_armeria,RestartableThreadTest.testRestartableThreadRestartBehavior,"    @Test
    public void testRestartableThreadRestartBehavior() {
        final RestartableThread restartableThread =
                new RestartableThread(testName.getMethodName(), () -> () -> {
                    while (!Thread.currentThread().isInterrupted()) {
                        Thread.yield();
                    }
                });

        restartableThread.start();
        assertThat(restartableThread.isRunning()).isTrue();
        restartableThread.stop();
        assertThat(restartableThread.isRunning()).isFalse();
        restartableThread.start();
        assertThat(restartableThread.isRunning()).isTrue();
        restartableThread.stop();
        assertThat(restartableThread.isRunning()).isFalse();
    }
",non-flaky,5
177225,line_armeria,FileWatcherRegistryTest.emptyGroupStopsBackgroundThread,"    @Test
    public void emptyGroupStopsBackgroundThread() throws Exception {

        final File file = folder.newFile(""temp-file.properties"");
        final File file2 = folder.newFile(""temp-file2.properties"");

        final FileWatcherRegistry fileWatcherRegistry =
                new FileWatcherRegistry();
        final FileWatchRegisterKey key1 = fileWatcherRegistry.register(file.toPath(), () -> {});
        final FileWatchRegisterKey key2 = fileWatcherRegistry.register(file2.toPath(), () -> {});

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key1);

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key2);

        assertThat(fileWatcherRegistry.isRunning()).isFalse();
    }
",non-flaky,5
177226,line_armeria,FileWatcherRegistryTest.closeEndpointGroupStopsRegistry,"    @Test
    public void closeEndpointGroupStopsRegistry() throws Exception {

        final File file = folder.newFile(""temp-file.properties"");

        final FileWatcherRegistry fileWatcherRegistry = new FileWatcherRegistry();
        fileWatcherRegistry.register(file.toPath(), () -> {});

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.close();

        assertThat(fileWatcherRegistry.isRunning()).isFalse();
    }
",non-flaky,5
177227,line_armeria,FileWatcherRegistryTest.runnableWithExceptionContinuesRun,"    @Test
    public void runnableWithExceptionContinuesRun() throws Exception {

        final File file = folder.newFile(""temp-file.properties"");
        final FileWatcherRegistry fileWatcherRegistry = new FileWatcherRegistry();

        final AtomicInteger val = new AtomicInteger(0);
        final FileWatchRegisterKey key = fileWatcherRegistry.register(file.toPath(), () -> {
            try {
                final BufferedReader bufferedReader = new BufferedReader(new FileReader(file));
                val.set(Integer.valueOf(bufferedReader.readLine()));
            } catch (IOException e) {
                // do nothing
            }
            throw new RuntimeException();
        });

        PrintWriter printWriter = new PrintWriter(file);
        printWriter.print(1);
        printWriter.close();

        await().untilAsserted(() -> assertThat(val.get()).isEqualTo(1));

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        printWriter = new PrintWriter(file);
        printWriter.print(2);
        printWriter.close();

        await().untilAsserted(() -> assertThat(val.get()).isEqualTo(2));

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key);

        assertThat(fileWatcherRegistry.isRunning()).isFalse();

        fileWatcherRegistry.close();
    }
",non-flaky,5
177228,line_armeria,FileWatcherRegistryTest.testMultipleFileSystems,"    @Test
    public void testMultipleFileSystems() throws Exception {

        final FileWatcherRegistry fileWatcherRegistry = new FileWatcherRegistry();

        final Path path1 = createMockedPath();
        final Path path2 = createMockedPath();

        final FileWatchRegisterKey key1 = fileWatcherRegistry.register(path1, () -> {});
        final FileWatchRegisterKey key2 = fileWatcherRegistry.register(path2, () -> {});
        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key1);
        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key2);
        assertThat(fileWatcherRegistry.isRunning()).isFalse();
    }
",non-flaky,5
177229,line_armeria,HealthCheckedEndpointGroupTest.updateCandidates,"    @Test
        public void updateCandidates(List<Endpoint> candidates) {
            this.candidates = candidates;
            selectedCandidates = ImmutableList.copyOf(candidates);
        }
",non-flaky,5
177230,line_armeria,PropertiesEndpointGroupTest.propertiesWithoutDefaultPort,"    @Test
    public void propertiesWithoutDefaultPort() {
        final PropertiesEndpointGroup endpointGroup = PropertiesEndpointGroup.of(PROPS, ""serverA.hosts"");

        assertThat(endpointGroup.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                        Endpoint.parse(""127.0.0.1:8081""),
                                                                        Endpoint.parse(""127.0.0.1""));
    }
",non-flaky,5
177231,line_armeria,PropertiesEndpointGroupTest.propertiesWithDefaultPort,"    @Test
    public void propertiesWithDefaultPort() {
        final PropertiesEndpointGroup endpointGroupA = PropertiesEndpointGroup.builder(PROPS, ""serverA.hosts"")
                                                                              .defaultPort(80)
                                                                              .build();
        final PropertiesEndpointGroup endpointGroupB = PropertiesEndpointGroup.builder(PROPS, ""serverB.hosts"")
                                                                              .defaultPort(8080)
                                                                              .build();

        assertThat(endpointGroupA.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                         Endpoint.parse(""127.0.0.1:8081""),
                                                                         Endpoint.parse(""127.0.0.1:80""));
        assertThat(endpointGroupB.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8082""),
                                                                         Endpoint.parse(""127.0.0.1:8083""));
    }
",non-flaky,5
177232,line_armeria,PropertiesEndpointGroupTest.resourceWithoutDefaultPort,"    @Test
    public void resourceWithoutDefaultPort() {
        final PropertiesEndpointGroup endpointGroup = PropertiesEndpointGroup.of(
                getClass().getClassLoader(), ""server-list.properties"", ""serverA.hosts"");

        assertThat(endpointGroup.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                        Endpoint.parse(""127.0.0.1:8081""),
                                                                        Endpoint.parse(""127.0.0.1""));
    }
",non-flaky,5
177233,line_armeria,PropertiesEndpointGroupTest.resourceWithDefaultPort,"    @Test
    public void resourceWithDefaultPort() {
        final PropertiesEndpointGroup endpointGroupA =
                PropertiesEndpointGroup.builder(getClass().getClassLoader(),
                                                ""server-list.properties"",
                                                ""serverA.hosts"")
                                       .defaultPort(80)
                                       .build();

        final PropertiesEndpointGroup endpointGroupB =
                PropertiesEndpointGroup.builder(getClass().getClassLoader(),
                                                ""server-list.properties"",
                                                ""serverB.hosts"")
                                       .defaultPort(8080)
                                       .build();

        assertThat(endpointGroupA.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                         Endpoint.parse(""127.0.0.1:8081""),
                                                                         Endpoint.parse(""127.0.0.1:80""));
        assertThat(endpointGroupB.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8082""),
                                                                         Endpoint.parse(""127.0.0.1:8083""));
    }
",non-flaky,5
177234,line_armeria,PropertiesEndpointGroupTest.pathWithDefaultPort,"    @Test
    public void pathWithDefaultPort() throws Exception {
        final URL resourceUrl = getClass().getClassLoader().getResource(""server-list.properties"");
        assert resourceUrl != null;
        final Path resourcePath = new File(resourceUrl.getFile()).toPath();
        final PropertiesEndpointGroup endpointGroupA = PropertiesEndpointGroup.builder(
                resourcePath, ""serverA.hosts"").defaultPort(80).build();
        assertThat(endpointGroupA.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                         Endpoint.parse(""127.0.0.1:8081""),
                                                                         Endpoint.parse(""127.0.0.1:80""));
        endpointGroupA.close();
    }
",non-flaky,5
177235,line_armeria,PropertiesEndpointGroupTest.pathWithoutDefaultPort,"    @Test
    public void pathWithoutDefaultPort() {
        final URL resourceUrl = getClass().getClassLoader().getResource(""server-list.properties"");
        assert resourceUrl != null;
        final Path resourcePath = new File(resourceUrl.getFile()).toPath();
        final PropertiesEndpointGroup endpointGroup = PropertiesEndpointGroup.of(
                resourcePath, ""serverA.hosts"");
        assertThat(endpointGroup.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                        Endpoint.parse(""127.0.0.1:8081""),
                                                                        Endpoint.parse(""127.0.0.1""));
        endpointGroup.close();
    }
",non-flaky,5
177236,line_armeria,PropertiesEndpointGroupTest.testWithPrefixThatEndsWithDot,"    @Test
    public void testWithPrefixThatEndsWithDot() {
        final PropertiesEndpointGroup endpointGroup = PropertiesEndpointGroup.of(
                getClass().getClassLoader(), ""server-list.properties"", ""serverA.hosts."");

        assertThat(endpointGroup.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                        Endpoint.parse(""127.0.0.1:8081""),
                                                                        Endpoint.parse(""127.0.0.1""));
    }
",non-flaky,5
177237,line_armeria,PropertiesEndpointGroupTest.containsNoHosts,"    @Test
    public void containsNoHosts() {
        assertThat(PropertiesEndpointGroup.builder(getClass().getClassLoader(),
                                                   ""server-list.properties"", ""serverC.hosts"")
                                          .defaultPort(8080)
                                          .build()
                                          .endpoints()).isEmpty();
    }
",non-flaky,5
177238,line_armeria,PropertiesEndpointGroupTest.illegalDefaultPort,"    @Test
    public void illegalDefaultPort() {
        assertThatThrownBy(() -> PropertiesEndpointGroup.builder(getClass().getClassLoader(),
                                                                 ""server-list.properties"", ""serverA.hosts"")
                                                        .defaultPort(0))
                .isInstanceOf(IllegalArgumentException.class)
                .hasMessageContaining(""defaultPort"");
    }
",non-flaky,5
177239,line_armeria,PropertiesEndpointGroupTest.propertiesFileUpdatesCorrectly,"    @Test
    public void propertiesFileUpdatesCorrectly() throws Exception {
        final File file = folder.newFile(""temp-file.properties"");

        PrintWriter printWriter = new PrintWriter(file);
        Properties props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.store(printWriter, """");
        printWriter.close();

        final PropertiesEndpointGroup endpointGroupA = PropertiesEndpointGroup.of(
                file.toPath(), ""serverA.hosts"");

        await().untilAsserted(() -> assertThat(endpointGroupA.endpoints()).hasSize(1));

        // Update resource
        printWriter = new PrintWriter(file);
        props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.setProperty(""serverA.hosts.1"", ""127.0.0.1:8081"");
        props.store(printWriter, """");
        printWriter.close();

        await().untilAsserted(() -> assertThat(endpointGroupA.endpoints()).hasSize(2));

        endpointGroupA.close();
    }
",non-flaky,5
177240,line_armeria,PropertiesEndpointGroupTest.duplicateResourceUrl,"    @Test
    public void duplicateResourceUrl() throws IOException {
        final File file = folder.newFile(""temp-file.properties"");
        final PropertiesEndpointGroup propertiesEndpointGroupA =
                PropertiesEndpointGroup.of(file.toPath(), ""serverA.hosts"");
        final PropertiesEndpointGroup propertiesEndpointGroupB =
                PropertiesEndpointGroup.of(file.toPath(), ""serverA.hosts"");
        propertiesEndpointGroupA.close();
        propertiesEndpointGroupB.close();
    }
",non-flaky,5
177241,line_armeria,PropertiesEndpointGroupTest.propertiesFileRestart,"    @Test
    public void propertiesFileRestart() throws Exception {
        final File file = folder.newFile(""temp-file.properties"");

        PrintWriter printWriter = new PrintWriter(file);
        Properties props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.store(printWriter, """");
        printWriter.close();

        final PropertiesEndpointGroup endpointGroupA = PropertiesEndpointGroup.of(
                file.toPath(), ""serverA.hosts"");
        await().untilAsserted(() -> assertThat(endpointGroupA.endpoints()).hasSize(1));
        endpointGroupA.close();

        final PropertiesEndpointGroup endpointGroupB = PropertiesEndpointGroup.of(
                file.toPath(), ""serverB.hosts"");
        await().untilAsserted(() -> assertThat(endpointGroupB.endpoints()).isEmpty());

        printWriter = new PrintWriter(file);
        props = new Properties();
        props.setProperty(""serverB.hosts.0"", ""127.0.0.1:8080"");
        props.setProperty(""serverB.hosts.1"", ""127.0.0.1:8081"");
        props.store(printWriter, """");
        printWriter.close();

        await().untilAsserted(() -> assertThat(endpointGroupB.endpoints()).hasSize(2));
        endpointGroupB.close();
    }
",non-flaky,5
177242,line_armeria,PropertiesEndpointGroupTest.endpointChangePropagatesToListeners,"    @Test
    public void endpointChangePropagatesToListeners() throws Exception {
        final File file = folder.newFile(""temp-file.properties"");

        PrintWriter printWriter = new PrintWriter(file);
        Properties props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.setProperty(""serverA.hosts.1"", ""127.0.0.1:8081"");
        props.store(printWriter, """");
        printWriter.close();

        final PropertiesEndpointGroup propertiesEndpointGroup = PropertiesEndpointGroup.of(
                file.toPath(), ""serverA.hosts"");
        final EndpointGroup fallbackEndpointGroup = Endpoint.of(""127.0.0.1"", 8081);
        final EndpointGroup endpointGroup = propertiesEndpointGroup.orElse(fallbackEndpointGroup);

        await().untilAsserted(() -> assertThat(endpointGroup.endpoints()).hasSize(2));

        printWriter = new PrintWriter(file);
        props = new Properties();
        props.store(printWriter, """");
        printWriter.close();

        await().untilAsserted(() -> assertThat(endpointGroup.endpoints()).hasSize(1));

        printWriter = new PrintWriter(file);
        props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.setProperty(""serverA.hosts.1"", ""127.0.0.1:8081"");
        props.setProperty(""serverA.hosts.2"", ""127.0.0.1:8082"");
        props.store(printWriter, """");
        printWriter.close();

        await().untilAsserted(() -> assertThat(endpointGroup.endpoints()).hasSize(3));
        propertiesEndpointGroup.close();
    }
",non-flaky,5
177243,line_armeria,DnsAddressEndpointGroupTest.ipV4Only,"    @Test
    public void ipV4Only() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""foo.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""foo.com."", ""1.1.1.1""))
                                         .addRecord(ANSWER, newAddressRecord(""unrelated.com"", ""1.2.3.4"")),
                new DefaultDnsQuestion(""foo.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""foo.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""foo.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_ONLY)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""foo.com"", 8080).withIpAddr(""1.1.1.1""));
            }
        }
    }
",non-flaky,5
177244,line_armeria,DnsAddressEndpointGroupTest.ipV6Only,"    @Test
    public void ipV6Only() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""bar.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""bar.com."", ""1.1.1.1"")),
                new DefaultDnsQuestion(""bar.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""bar.com."", ""::1""))
                                         .addRecord(ANSWER, newAddressRecord(""bar.com."", ""::1234:5678:90ab""))
                                         .addRecord(ANSWER, newAddressRecord(""bar.com."",
                                                                             ""2404:6800:4004:806::2013""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""bar.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV6_ONLY)
                                                .build()) {

                assertThat(group.whenReady().get(10, TimeUnit.SECONDS)).containsExactly(
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""2404:6800:4004:806::2013""),
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""::1""),
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""::1234:5678:90ab""));
            }
        }
    }
",non-flaky,5
177245,line_armeria,DnsAddressEndpointGroupTest.ipV4AndIpV6,"    @Test
    public void ipV4AndIpV6() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""baz.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""baz.com."", ""1.1.1.1"")),
                new DefaultDnsQuestion(""baz.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""baz.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""baz.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""baz.com"", 8080).withIpAddr(""1.1.1.1""),
                        Endpoint.of(""baz.com"", 8080).withIpAddr(""::1""));
            }
        }
    }
",non-flaky,5
177246,line_armeria,DnsAddressEndpointGroupTest.platformDefault,"    @Test
    public void platformDefault() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""baz.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""baz.com."", ""1.1.1.1"")),
                new DefaultDnsQuestion(""baz.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""baz.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""baz.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .build()) {

                assertThat(group.whenReady().get()).contains(
                        Endpoint.of(""baz.com"", 8080).withIpAddr(""1.1.1.1""));
            }
        }
    }
",non-flaky,5
177247,line_armeria,DnsAddressEndpointGroupTest.cname,"    @Test
    public void cname() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""a.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newBadAddressRecord(""a.com."", true))
                                         .addRecord(ANSWER, newCnameRecord(""a.com."", ""b.com.""))
                                         .addRecord(ANSWER, newAddressRecord(""b.com."", ""1.1.1.1"")),
                new DefaultDnsQuestion(""a.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newBadAddressRecord(""a.com."", false))
                                         .addRecord(ANSWER, newCnameRecord(""a.com."", ""b.com.""))
                                         .addRecord(ANSWER, newAddressRecord(""b.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""a.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""a.com"", 8080).withIpAddr(""1.1.1.1""),
                        Endpoint.of(""a.com"", 8080).withIpAddr(""::1""));
            }
        }
    }
",non-flaky,5
177248,line_armeria,DnsAddressEndpointGroupTest.mixedLoopbackAddresses,"    @Test
    public void mixedLoopbackAddresses() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""foo.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""foo.com."", ""127.0.0.1"")),
                new DefaultDnsQuestion(""foo.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""foo.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""foo.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""foo.com"", 8080).withIpAddr(""127.0.0.1""));
            }
        }
    }
",non-flaky,5
177249,line_armeria,DnsAddressEndpointGroupTest.ipV4MappedOrCompatibleAddresses,"    @Test
    public void ipV4MappedOrCompatibleAddresses() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""bar.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newCompatibleAddressRecord(""bar.com."", ""1.1.1.1""))
                                         .addRecord(ANSWER, newCompatibleAddressRecord(""bar.com."", ""1.1.1.2""))
                                         .addRecord(ANSWER, newMappedAddressRecord(""bar.com."", ""1.1.1.1""))
                                         .addRecord(ANSWER, newMappedAddressRecord(""bar.com."", ""1.1.1.3""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""bar.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV6_ONLY)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""1.1.1.1""),
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""1.1.1.2""),
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""1.1.1.3""));
            }
        }
    }
",non-flaky,5
177250,line_armeria,DnsAddressEndpointGroupTest.noPort,"    @Test
    public void noPort() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""no-port.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""no-port.com"", ""1.1.1.1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""no-port.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_ONLY)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""no-port.com"").withIpAddr(""1.1.1.1""));
            }
        }
    }
",non-flaky,5
177251,line_armeria,DnsAddressEndpointGroupTest.backoff,"    @Test
    public void backoff() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of())) { // Respond nothing.
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""backoff.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .backoff(Backoff.fixed(500))
                                                .build()) {

                await().untilAsserted(() -> assertThat(group.attemptsSoFar).isGreaterThan(2));
                assertThat(group.endpoints()).isEmpty();

                // Start to respond correctly.
                server.setResponses(ImmutableMap.of(
                        new DefaultDnsQuestion(""backoff.com."", A),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""backoff.com"", ""1.1.1.1"", 1)),
                        new DefaultDnsQuestion(""backoff.com."", AAAA),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""backoff.com"", ""::1"", 1))));

                await().untilAsserted(() -> assertThat(group.endpoints()).containsExactly(
                        Endpoint.of(""backoff.com"").withIpAddr(""1.1.1.1""),
                        Endpoint.of(""backoff.com"").withIpAddr(""::1"")));
            }
        }
    }
",non-flaky,5
177252,line_armeria,DnsAddressEndpointGroupTest.backoffOnEmptyResponse,"    @Test
    public void backoffOnEmptyResponse() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                // Respond with empty records.
                new DefaultDnsQuestion(""empty.com."", A), new DefaultDnsResponse(0),
                new DefaultDnsQuestion(""empty.com."", AAAA), new DefaultDnsResponse(0)
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""empty.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .backoff(Backoff.fixed(500))
                                                .build()) {

                await().untilAsserted(() -> assertThat(group.attemptsSoFar).isGreaterThan(2));
                assertThat(group.endpoints()).isEmpty();

                // Start to respond correctly.
                server.setResponses(ImmutableMap.of(
                        new DefaultDnsQuestion(""empty.com."", A),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""empty.com"", ""1.1.1.1"", 1)),
                        new DefaultDnsQuestion(""empty.com."", AAAA),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""empty.com"", ""::1"", 1))));

                await().untilAsserted(() -> assertThat(group.endpoints()).containsExactly(
                        Endpoint.of(""empty.com"").withIpAddr(""1.1.1.1""),
                        Endpoint.of(""empty.com"").withIpAddr(""::1"")));
            }
        }
    }
",non-flaky,5
177253,line_armeria,DnsAddressEndpointGroupTest.partialIpV4Response,"    @ParameterizedTest
    public void partialIpV4Response(ResolvedAddressTypes resolvedAddressTypes) throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                // Respond A record only.
                // Respond with NXDOMAIN for AAAA.
                new DefaultDnsQuestion(""partial.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""partial.com"", ""1.1.1.1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""partial.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(resolvedAddressTypes)
                                                .backoff(Backoff.fixed(500))
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""partial.com"").withIpAddr(""1.1.1.1""));
            }
        }
    }
",non-flaky,5
177254,line_armeria,DnsAddressEndpointGroupTest.partialIpV6Response,"    @ParameterizedTest
    public void partialIpV6Response(ResolvedAddressTypes resolvedAddressTypes) throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                // Respond AAAA record only.
                // Respond with NXDOMAIN for A.
                new DefaultDnsQuestion(""partial.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""partial.com"", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""partial.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(resolvedAddressTypes)
                                                .backoff(Backoff.fixed(500))
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""partial.com"").withIpAddr(""::1""));
            }
        }
    }
",non-flaky,5
177255,line_armeria,DnsServiceEndpointGroupTest.srv,"    @Test
    public void srv() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""foo.com."", SRV),
                new DefaultDnsResponse(0).addRecord(ANSWER, newSrvRecord(""foo.com."", 1, 2, ""a.foo.com.""))
                                         .addRecord(ANSWER, newSrvRecord(""foo.com."", 3, 4, ""b.foo.com.""))
                                         .addRecord(ANSWER, newSrvRecord(""unrelated.com."", 0, 0, ""asdf.com.""))
                                         .addRecord(ANSWER, newTooShortSrvRecord(""foo.com.""))
                                         .addRecord(ANSWER, newBadNameSrvRecord(""foo.com.""))
        ))) {
            try (DnsServiceEndpointGroup group =
                         DnsServiceEndpointGroup.builder(""foo.com"")
                                                .serverAddresses(server.addr())
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""a.foo.com"", 2).withWeight(1),
                        Endpoint.of(""b.foo.com"", 4).withWeight(3));
            }
        }
    }
",non-flaky,5
