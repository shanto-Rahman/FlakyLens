id,project,test_name,full_code,label,category
1,apache_hadoop,TestDelegationTokenRenewer.testAddRemoveRenewAction,"@Test
public void testAddRemoveRenewAction() throws IOException, InterruptedException {
    TestFileSystem tfs = new TestFileSystem();
    renewer.addRenewAction(tfs);
    for (int i = 0; i < 60; i++) {
        Thread.sleep(RENEW_CYCLE);
        if (tfs.testToken.renewCount > 0) {
            renewer.removeRenewAction(tfs);
            break;
        }
    }
    assertTrue(""Token not renewed even after 1 minute"", tfs.testToken.renewCount > 0);
    assertTrue(""Token not removed"", tfs.testToken.renewCount < MAX_RENEWALS);
    assertTrue(""Token not cancelled"", tfs.testToken.cancelled);
}",async wait,0
4,NationalSecurityAgency_timely,MetricAdapterTest.testToMetricResponse,"@Test
public void testToMetricResponse() throws Exception {
    String subscriptionId = ""12345"";
    long ts = 1000L;
    List<Tag> tags = new ArrayList<>();
    tags.add(new Tag(""tag1"", ""value1""));
    Metric m = Metric.newBuilder().name(""sys.cpu.user"").value(ts, 2.0).tags(tags).tag(VISIBILITY_TAG, ""(a&b)|(c&d)"").build();
    String json = JsonUtil.getObjectMapper().writeValueAsString(MetricResponse.fromMetric(m, subscriptionId));
    String expected = ""{\""metric\"":\""sys.cpu.user\"",\""timestamp\"":1000,\""value\"":2.0,\""tags\"":[{\""tag1\"":\""value1\""},{\""viz\"":\""(a&b)|(c&d)\""}],\""subscriptionId\"":\""12345\"",\""complete\"":false}"";
    Assert.assertEquals(expected, json);
}",unordered collections,3
5,apache_hadoop,TestPathData.testToFile,"@Test
public void testToFile() throws Exception {
    item = new PathData(""."", conf);
    assertEquals(new File(testDir.toString()), item.toFile());
    item = new PathData(""d1/f1"", conf);
    assertEquals(new File(testDir + ""/d1/f1""), item.toFile());
    item = new PathData(testDir + ""/d1/f1"", conf);
    assertEquals(new File(testDir + ""/d1/f1""), item.toFile());
}",test order dependency,4
6,swankjesse_dex,test_parseLString,"@Test
public void test_parseLString() throws Exception {
    DateFormat format = DateFormat.getDateTimeInstance(DateFormat.FULL, DateFormat.FULL, Locale.US);
    try {
        Date date = format.parse(format.format(current).toString());
        assertEquals(current.getDate(), date.getDate());
        assertEquals(current.getDay(), date.getDay());
        assertEquals(current.getMonth(), date.getMonth());
        assertEquals(current.getYear(), date.getYear());
        assertEquals(current.getHours(), date.getHours());
        assertEquals(current.getMinutes(), date.getMinutes());
    } catch(ParseException pe) {
    fail(""ParseException was thrown for current Date.""); }
    try {
        format.parse(""January 16, 1970 8:03:52 PM CET"");
        fail(""ParseException was not thrown."");
    } catch(ParseException pe) { }
}",time,2
8,apache_hadoop,TestLocalDirAllocator.testRemoveContext,"@Test
public void testRemoveContext() throws IOException {
    String dir = buildBufferDir(ROOT, 0);
    String contextCfgItemName = ""application_1340842292563_0004.app.cache.dirs"";
    conf.set(contextCfgItemName, dir);
    LocalDirAllocator localDirAllocator = new LocalDirAllocator(contextCfgItemName);
    localDirAllocator.getLocalPathForWrite(""p1/x"", SMALL_FILE_SIZE, conf);
    assertTrue(LocalDirAllocator.isContextValid(contextCfgItemName));
    LocalDirAllocator.removeContext(contextCfgItemName);
    assertFalse(LocalDirAllocator.isContextValid(contextCfgItemName));
}",test order dependency,4
9,apache_hadoop,TestRMContainerAllocator.testSimple,"@Test
public void testSimple() throws Exception {
    Configuration conf = new Configuration();
    MyResourceManager rm = new MyResourceManager(conf);
    rm.start();
    DrainDispatcher dispatcher = ((DrainDispatcher) (rm.getRMContext().getDispatcher()));
    RMApp app = rm.submitApp(1024);
    dispatcher.await();
    MockNM amNodeManager = rm.registerNode(""amNM:1234"", 2048);
    amNodeManager.nodeHeartbeat(true);
    dispatcher.await();
    ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt().getAppAttemptId();
    rm.sendAMLaunched(appAttemptId);
    dispatcher.await();
    JobId jobId = MRBuilderUtils.newJobId(appAttemptId.getApplicationId(), 0);
    Job mockJob = mock(Job.class);
    when(mockJob.getReport()).thenReturn(MRBuilderUtils.newJobReport(jobId, ""job"", ""user"", RUNNING, 0, 0, 0, 0, 0, 0, ""jobfile""));
    MyContainerAllocator allocator = new MyContainerAllocator(rm, conf, appAttemptId, mockJob);
    MockNM nodeManager1 = rm.registerNode(""h1:1234"", 10240);
    MockNM nodeManager2 = rm.registerNode(""h2:1234"", 10240);
    MockNM nodeManager3 = rm.registerNode(""h3:1234"", 10240);
    dispatcher.await();
    ContainerRequestEvent event1 = createReq(jobId, 1, 1024, new String[]{ ""h1"" });
    allocator.sendRequest(event1);
    ContainerRequestEvent event2 = createReq(jobId, 2, 1024, new String[]{ ""h2"" });
    allocator.sendRequest(event2);
    List<TaskAttemptContainerAssignedEvent> assigned = allocator.schedule();
    dispatcher.await();
    Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size());
    ContainerRequestEvent event3 = createReq(jobId, 3, 1024, new String[]{ ""h3"" });
    allocator.sendRequest(event3);
    assigned = allocator.schedule();
    dispatcher.await();
    Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size());
    nodeManager1.nodeHeartbeat(true);
    nodeManager2.nodeHeartbeat(true);
    nodeManager3.nodeHeartbeat(true);
    dispatcher.await();
    assigned = allocator.schedule();
    dispatcher.await();
    checkAssignments(new ContainerRequestEvent[]{ event1, event2, event3 }, assigned, false);
}",async wait,0
11,androidx_androidx,getNanoTime,"@Test
public void getNanoTime() {
    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP) {
        long time = mRecyclerView.getNanoTime();
        assertNotEquals(0, time);
        assertNotEquals(time, mRecyclerView.getNanoTime());
    } else {
        assertEquals(0, mRecyclerView.getNanoTime());
    }
}",time,2
13,androidx_androidx,testTimer_withListenerAndCleanUp,"@Test
@LargeTest
public void testTimer_withListenerAndCleanUp() throws InterruptedException {
    TestTimeLimitExceededListener listenerSpy = spy(mListener);
    mWorkTimer.startTimer(WORKSPEC_ID_1, 0, listenerSpy);
    Thread.sleep(10);
    verify(listenerSpy, times(1)).onTimeLimitExceeded(WORKSPEC_ID_1);
    assertThat(mWorkTimer.getTimerMap().size(), is(0));
    assertThat(mWorkTimer.getListeners().size(), is(0));
}",async wait,0
15,MundaneImmortal_pair-distribution-app,testGenerateNewDayPairs,"@Test
public void testGenerateNewDayPairs() {
    PairCombinations pairs = getPairsList();
    List<Developer> devs = getStandardDevs();
    List<String> tracks = Arrays.asList(""track1"", ""track2"", ""track3"");
    Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);
    subject.buildDevelopersPairingDays(pairs, devs);
    DayPairs dayPairs = subject.generateNewDayPairs(tracks, devs, pairs, pairsWeight, getStandardCompanies());
    assertThat(dayPairs.getTracks().size(), is(2));
    assertThat(dayPairs.getTracks(), contains(""track1"", ""track2""));
    assertThat(dayPairs.getPairByTrack(""track1""),
    is(not(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2""))))));
    assertThat(dayPairs.getPairByTrack(""track2""),
    is(not(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4""))))));
    boolean trackOneHasContext = dayPairs.getPairByTrack(""track1"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track1"").getSecondDev().hasContext();
    boolean trackTwoHasContext = dayPairs.getPairByTrack(""track2"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track2"").getSecondDev().hasContext();
    assertThat(trackOneHasContext, is(true));
    assertThat(trackTwoHasContext, is(true));
}",unordered collections,3
16,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireObjectEvent,"@Test
public void testFireObjectEvent() throws Exception {
    final NamingEventCoordinator coordinator = new NamingEventCoordinator();
    final CollectingListener objectListener = new CollectingListener(1);
    coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
    final CollectingListener subtreeListener = new CollectingListener(0);
    coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
    final CollectingListener oneLevelListener = new CollectingListener(0);
    coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);
    coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE);
    objectListener.latch.await(1, TimeUnit.SECONDS);
    assertEquals(1, objectListener.capturedEvents.size());
    assertTrue(oneLevelListener.capturedEvents.isEmpty());
    assertTrue(subtreeListener.capturedEvents.isEmpty());
}",test order dependency,4
19,apache_camel,KafkaConsumerTopicIsPatternIT.kafkaTopicIsPattern,"@Test
public void kafkaTopicIsPattern() throws Exception {
    to.expectedMessageCount(5);
    to.expectedBodiesReceivedInAnyOrder(""message-0"", ""message-1"", ""message-2"", ""message-3"", ""message-4"");
    to.allMessages().header(TOPIC).isEqualTo(""test"");
    to.expectedHeaderValuesReceivedInAnyOrder(LAST_RECORD_BEFORE_COMMIT, null, null, null, null, null);
    for (int k = 0; k < 5; k++) {
        String msg = ""message-"" + k;
        ProducerRecord<String, String> data = new ProducerRecord<>(TOPIC, ""1"", msg);
        producer.send(data);
    }
    to.assertIsSatisfied(3000);
    assertEquals(5, StreamSupport.stream(recordsCaptured.get(0).records(TOPIC).spliterator(), false).count());
}",test order dependency,4
24,trinodb_trino,TestExchangeClient.testAddLocation,"@Test
public void testAddLocation() throws Exception {
    DataSize maxResponseSize = DataSize.of(10, MEGABYTE);
    MockExchangeRequestProcessor processor = new MockExchangeRequestProcessor(maxResponseSize);
    TaskId task1 = new TaskId(new StageId(""query"", 1), 0, 0);
    TaskId task2 = new TaskId(new StageId(""query"", 1), 1, 0);
    TaskId task3 = new TaskId(new StageId(""query"", 1), 2, 0);
    URI location1 = URI.create(""http:www.example1.com"");
    URI location2 = URI.create(""http:www.example2.com"");
    URI location3 = URI.create(""http:www.example3.com"");
    processor.addPage(location1, createSerializedPage(1));
    processor.addPage(location1, createSerializedPage(2));
    TestingExchangeClientBuffer buffer = new TestingExchangeClientBuffer(DataSize.of(1, MEGABYTE));
    @SuppressWarnings(""resource"")
    ExchangeClient exchangeClient = new ExchangeClient(""localhost"", DataIntegrityVerification.ABORT, buffer, maxResponseSize, 1, new Duration(1, TimeUnit.MINUTES), true, new TestingHttpClient(processor, scheduler), scheduler, new SimpleLocalMemoryContext(newSimpleAggregatedMemoryContext(), ""test""), pageBufferClientCallbackExecutor, ( taskId, failure) -> {
    });
    assertThat(buffer.getAllTasks()).isEmpty();
    assertThat(buffer.getPages().asMap()).isEmpty();
    assertThat(buffer.getFinishedTasks()).isEmpty();
    assertThat(buffer.getFailedTasks().asMap()).isEmpty();
    assertFalse(buffer.isNoMoreTasks());
    exchangeClient.addLocation(task1, location1);
    assertThat(buffer.getAllTasks()).containsExactly(task1);
    assertTaskIsNotFinished(buffer, task1);
    processor.setComplete(location1);
    buffer.whenTaskFinished(task1).get(10, SECONDS);
    assertThat(buffer.getPages().get(task1)).hasSize(2);
    assertThat(buffer.getFinishedTasks()).containsExactly(task1);
    exchangeClient.addLocation(task2, location2);
    assertThat(buffer.getAllTasks()).containsExactlyInAnyOrder(task1, task2);
    assertTaskIsNotFinished(buffer, task2);
    processor.setComplete(location2);
    buffer.whenTaskFinished(task2).get(10, SECONDS);
    assertThat(buffer.getFinishedTasks()).containsExactlyInAnyOrder(task1, task2);
    assertThat(buffer.getPages().get(task2)).hasSize(0);
    exchangeClient.addLocation(task3, location3);
    assertThat(buffer.getAllTasks()).containsExactlyInAnyOrder(task1, task2, task3);
    assertTaskIsNotFinished(buffer, task3);
    exchangeClient.noMoreLocations();
    assertTrue(buffer.isNoMoreTasks());
    assertThat(buffer.getAllTasks()).containsExactlyInAnyOrder(task1, task2, task3);
    assertTaskIsNotFinished(buffer, task3);
    exchangeClient.close();
    assertEventually(() -> assertEquals(exchangeClient.getStatus().getPageBufferClientStatuses().get(0).getHttpRequestState(), ""not scheduled"", ""httpRequestState""));
    assertEventually(() -> assertEquals(exchangeClient.getStatus().getPageBufferClientStatuses().get(1).getHttpRequestState(), ""not scheduled"", ""httpRequestState""));
    assertEventually(() -> assertEquals(exchangeClient.getStatus().getPageBufferClientStatuses().get(2).getHttpRequestState(), ""not scheduled"", ""httpRequestState""));
    assertThat(buffer.getFinishedTasks()).containsExactlyInAnyOrder(task1, task2, task3);
    assertThat(buffer.getFailedTasks().asMap()).isEmpty();
    assertTrue(exchangeClient.isFinished());
}",async wait,0
25,apache_hadoop,TestDelegationToken.testDelegationTokenSecretManager,"@Test
public void testDelegationTokenSecretManager() throws Exception {
    DelegationTokenSecretManager dtSecretManager = cluster.getNameNode().getNamesystem().getDelegationTokenSecretManager();
    Token<DelegationTokenIdentifier> token = generateDelegationToken(""SomeUser"", ""JobTracker"");
    try {
        dtSecretManager.renewToken(token, ""FakeRenewer"");
        Assert.fail(""should have failed"");
    } catch (AccessControlException ace) {
    }
    dtSecretManager.renewToken(token, ""JobTracker"");
    DelegationTokenIdentifier identifier = new DelegationTokenIdentifier();
    byte[] tokenId = token.getIdentifier();
    identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId)));
    Assert.assertTrue(null != dtSecretManager.retrievePassword(identifier));
    LOG.info(""Sleep to expire the token"");
    Thread.sleep(6000);
    try {
        dtSecretManager.retrievePassword(identifier);
        Assert.fail(""Token should have expired"");
    } catch (InvalidToken e) {
    }
    dtSecretManager.renewToken(token, ""JobTracker"");
    LOG.info(""Sleep beyond the max lifetime"");
    Thread.sleep(5000);
    try {
        dtSecretManager.renewToken(token, ""JobTracker"");
        Assert.fail(""should have been expired"");
    } catch (InvalidToken it) {
    }
}",concurrency,1
28,apache_hadoop,TestDFSIO.testReadSkip,"@Test
public void testReadSkip() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.getConf().setLong(""test.io.skip.size"", 1);
    bench.randomReadTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_READ_SKIP, execTime);
}",test order dependency,4
29,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testCreateSubcontext,"@Test
public void testCreateSubcontext() throws Exception {
    assertTrue(namingContext.createSubcontext(new CompositeName(""test"")) instanceof NamingContext);
    assertTrue(testActionPermission(JndiPermission.ACTION_CREATE_SUBCONTEXT, namingContext, ""securitytest"") instanceof NamingContext);
}",test order dependency,4
31,looly_hutool,EnumUtilTest.getFieldNamesTest,"@Test
public void getFieldNamesTest() {
    List<String> names = EnumUtil.getFieldNames(TestEnum.class);
    Assert.assertEquals(CollUtil.newArrayList(""type"", ""name""), names);
}",unordered collections,3
35,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupContextLink,"@Test
public void testLookupContextLink() throws Exception {
    final Name name = new CompositeName(""test/value"");
    namingStore.bind(name, ""testValue"");
    final Name linkName = new CompositeName(""link"");
    namingStore.bind(linkName, new LinkRef(""./test""));
    Object result = namingContext.lookup(""link/value"");
    assertEquals(""testValue"", result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup""),
    new JndiPermission(""test/value"", ""lookup"")), namingContext, ""link/value"");
    assertEquals(""testValue"", result);
}",test order dependency,4
38,apache_hadoop,TestDFSIO.testReadBackward,"@Test
public void testReadBackward() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.getConf().setLong(""test.io.skip.size"", -DEFAULT_BUFFER_SIZE);
    bench.randomReadTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_READ_BACKWARD, execTime);
}",test order dependency,4
39,quarkusio_quarkus,testTimedMethod,"@Test
void testTimedMethod() throws InterruptedException {
    assertTrue(Jobs.latch01.await(5, TimeUnit.SECONDS));
    assertTrue(Jobs.latch02.await(5, TimeUnit.SECONDS));
    Timer timer1 = registry.get(""scheduled.methods"")
    .tag(""method"", ""everySecond"")
    .tag(""class"", ""io.quarkus.scheduler.test.metrics.MicrometerTimedTest$Jobs"")
    .tag(""exception"", ""none"")
    .timer();
    assertNotNull(timer1);
    assertTrue(timer1.count() > 0);
    Timer timer2 = registry.get(""foo"")
    .tag(""method"", ""anotherEverySecond"")
    .tag(""class"", ""io.quarkus.scheduler.test.metrics.MicrometerTimedTest$Jobs"")
    .tag(""exception"", ""none"")
    .timer();
    assertNotNull(timer2);
    assertTrue(timer2.count() > 0);
}",time,2
40,apache_hadoop,TestDFSIO.testReadRandom,"@Test
public void testReadRandom() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.getConf().setLong(""test.io.skip.size"", 0);
    bench.randomReadTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_READ_RANDOM, execTime);
}",test order dependency,4
44,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupEmptyName,"@Test
public void testLookupEmptyName() throws Exception {
    Object result = namingContext.lookup(new CompositeName());
    assertTrue(result instanceof NamingContext);
    result = namingContext.lookup(new CompositeName(""""));
    assertTrue(result instanceof NamingContext);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, null);
    assertTrue(result instanceof NamingContext);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, """");
    assertTrue(result instanceof NamingContext);
}",test order dependency,4
47,apache_hadoop,TestPeerCache.testEviction,"@Test
public void testEviction() throws Exception {
    final int CAPACITY = 3;
    PeerCache cache = PeerCache.getInstance(CAPACITY, 100000);
    DatanodeID dnIds[] = new DatanodeID[CAPACITY + 1];
    FakePeer peers[] = new FakePeer[CAPACITY + 1];
    for (int i = 0; i < dnIds.length; ++i) {
        dnIds[i] = new DatanodeID(""192.168.0.1"",
        ""fakehostname_"" + i, ""fake_storage_id_"" + i,
        100, 101, 102);
        peers[i] = new FakePeer(dnIds[i], false);
    }
    for (int i = 0; i < CAPACITY; ++i) {
        cache.put(dnIds[i], peers[i]);
    }
    assertEquals(CAPACITY, cache.size());
    cache.put(dnIds[CAPACITY], peers[CAPACITY]);
    assertEquals(CAPACITY, cache.size());
    assertSame(null, cache.get(dnIds[0], false));
    for (int i = 1; i < CAPACITY; ++i) {
        Peer peer = cache.get(dnIds[i], false);
        assertSame(peers[i], peer);
        assertTrue(!peer.isClosed());
        peer.close();
    }
    assertEquals(1, cache.size());
    cache.close();
}",test order dependency,4
50,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testCompositeBindingOps,"@Test
public void testCompositeBindingOps() throws Exception {
    final KernelServices services = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build();
    final ModelNode addr = Operations.createAddress(ModelDescriptionConstants.SUBSYSTEM, NamingExtension.SUBSYSTEM_NAME, NamingSubsystemModel.BINDING, ""java:global/alookup"");
    final ModelNode addOp = Operations.createAddOperation(addr);
    addOp.get(NamingSubsystemModel.BINDING_TYPE).set(NamingSubsystemModel.LOOKUP);
    final ModelNode compositeOp = Operations.CompositeOperationBuilder.create().addStep(addOp).addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.LOOKUP, ""java:global/a"")).build().getOperation();
    ModelTestUtils.checkOutcome(services.executeOperation(compositeOp));
}",test order dependency,4
51,apache_hadoop,TestHftpFileSystem.testHftpDefaultPorts,"@Test
public void testHftpDefaultPorts() throws IOException {
    resetFileSystem();
    Configuration conf = new Configuration();
    URI uri = URI.create();
    HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf)));
    assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, fs.getDefaultPort());
    assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getDefaultSecurePort());
    assertEquals(uri, fs.getUri());
    assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getCanonicalServiceName());
}",test order dependency,4
54,androidx_androidx,testGenerateCleanupCallback_deletesOldFinishedWork,"@Test
public void testGenerateCleanupCallback_deletesOldFinishedWork() {
    Work work1 = new Work.Builder(TestWorker.class)
    .withInitialState(SUCCEEDED)
    .withPeriodStartTime(0L)
    .build();
    Work work2 = new Work.Builder(TestWorker.class).withPeriodStartTime(Long.MAX_VALUE).build();
    insertWorkSpecAndTags(work1);
    insertWorkSpecAndTags(work2);
    SupportSQLiteOpenHelper openHelper = mDatabase.getOpenHelper();
    SupportSQLiteDatabase db = openHelper.getWritableDatabase();
    WorkDatabase.generateCleanupCallback().onOpen(db);
    WorkSpecDao workSpecDao = mDatabase.workSpecDao();
    assertThat(workSpecDao.getWorkSpec(work1.getId()), is(nullValue()));
    assertThat(workSpecDao.getWorkSpec(work2.getId()), is(not(nullValue())));
}",time,2
57,androidx_androidx,testMenuInvalidationAfterDestroy,"@Test
public void testMenuInvalidationAfterDestroy() throws Throwable {
    final A activity = getActivity();
    getInstrumentation().runOnMainSync(new Runnable() {
        @Override
        public void run() {
            activity.reset();
            assertNull(activity.getMenu());
            activity.supportInvalidateOptionsMenu();
            getInstrumentation().callActivityOnDestroy(activity);
        }
    });
    Thread.sleep(100);
    assertNull(activity.getMenu());
}",async wait,0
58,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBindAndRetrieveObjectFactoryFromNamingContext,"@Test
public void testBindAndRetrieveObjectFactoryFromNamingContext() throws Exception {
    final Reference reference = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null);
    namingStore.bind(new CompositeName(""test""), reference);
    final Object result = namingContext.lookup(""test"");
    assertTrue(result instanceof String);
    assertEquals(""Test ParsedResult"", result);
}",test order dependency,4
59,apache_beam,testBacklogLimiter,"@Test
public void testBacklogLimiter() {
    long duration = runWithRate(2 * RateLimiting.DEFAULT_MAX_PARALLELISM,-1.0 , new DelayFn<Integer>());
    Assert.assertThat(duration,greaterThan(2 * DelayFn.DELAY_MS));
}",time,2
62,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testJavaContext,"@Test
public void testJavaContext() throws Exception {
    System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
    System.setProperty(Context.URL_PKG_PREFIXES, ""org.jboss.as.naming.interfaces"");
    InitialContext initialContext = new InitialContext();
    Context context = (Context) initialContext.lookup(""java:"");
    assertTrue(context instanceof NamingContext);
}",test order dependency,4
63,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupWithContinuation,"@Test
public void testLookupWithContinuation() throws Exception {
    namingStore.bind(new CompositeName(""comp/nested""), ""test"");
    final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""nns"", ""comp""), TestObjectFactoryWithNameResolution.class.getName(), null);
    namingStore.bind(new CompositeName(""test""), reference);
    Object result = namingContext.lookup(new CompositeName(""test/nested""));
    assertEquals(""test"", result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""comp/nested"", ""lookup"")), namingContext, ""test/nested"");
    assertEquals(""test"", result);
}",test order dependency,4
65,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testInitialFactory,"@Test
public void testInitialFactory() throws Exception {
    System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
    InitialContext initialContext = new InitialContext();
    Context context = (Context) initialContext.lookup("""");
    assertTrue(context instanceof NamingContext);
    if (!NamingManager.hasInitialContextFactoryBuilder()) {
        NamingManager.setInitialContextFactoryBuilder(new InitialContextFactoryBuilder());
    }
    initialContext = new InitialContext();
    context = (Context) initialContext.lookup("""");
    assertTrue(context instanceof NamingContext);
}",test order dependency,4
68,androidx_androidx,testUnsubscribeWithSubscriptionCallbackForMultipleSubscriptions,"@Test
public void testUnsubscribeWithSubscriptionCallbackForMultipleSubscriptions() throws Exception {
    connectMediaBrowserService();
    final List<StubSubscriptionCallback> subscriptionCallbacks = new ArrayList<>();
    final int pageSize = 1;
    for (int page = 0; page < 4; page++) {
        final StubSubscriptionCallback callback = new StubSubscriptionCallback();
        subscriptionCallbacks.add(callback);
        Bundle options = new Bundle();
        options.putInt(MediaBrowserCompat.EXTRA_PAGE, page);
        options.putInt(MediaBrowserCompat.EXTRA_PAGE_SIZE, pageSize);
        callback.reset(1);
        mMediaBrowser.subscribe(MEDIA_ID_ROOT, options, callback);
        callback.await(TIME_OUT_MS);
        assertEquals(1, callback.mChildrenLoadedWithOptionCount);
    }
    final int[] orderOfRemovingCallbacks = {2, 0, 3, 1};
    for (int i = 0; i < orderOfRemovingCallbacks.length; i++) {
        for (StubSubscriptionCallback callback : subscriptionCallbacks) {
            callback.reset(1);
        }
        mMediaBrowser.unsubscribe(MEDIA_ID_ROOT,
        subscriptionCallbacks.get(orderOfRemovingCallbacks[i]));
        callMediaBrowserServiceMethod(NOTIFY_CHILDREN_CHANGED, MEDIA_ID_ROOT,
        getApplicationContext());
        try {
            Thread.sleep(SLEEP_MS);
        } catch (InterruptedException e) {
            fail(""Unexpected InterruptedException occurred."");
        }
        for (int j = 0; j < 4; j++) {
            int childrenLoadedWithOptionsCount = subscriptionCallbacks
            .get(orderOfRemovingCallbacks[j]).mChildrenLoadedWithOptionCount;
            if (j <= i) {
                assertEquals(0, childrenLoadedWithOptionsCount);
            } else {
                assertEquals(1, childrenLoadedWithOptionsCount);
            }
        }
    }
}",async wait,0
71,androidx_androidx,testOneTimeWorkRequest_backedOff,"@Test
public void testOneTimeWorkRequest_backedOff() {
    val now = System.currentTimeMillis() ;
    when(mTaskConverter.now()).thenReturn(now) ;
    val request = OneTimeWorkRequestBuilder<TestWorker>().setInitialRunAttemptCount(1).build() ;
    val workSpec = request.workSpec ;
    val expected = workSpec.calculateNextRunTime();
    val offset = offset(expected, now) ,
    val delta = task.windowEnd - (offset + EXECUTION_WINDOW_SIZE_IN_SECONDS);
    val task = mTaskConverter.convert(request.workSpec);
    assertEquals(task.serviceName, WorkManagerGcmService::class.java.name);
    assertEquals(task.isPersisted, false);
    assertEquals(task.isUpdateCurrent, true);
    assertEquals(task.requiredNetwork, Task.NETWORK_STATE_ANY);
    assertEquals(task.requiresCharging, false);
    assertEquals(task.windowStart, offset);
    assertEquals(task.windowEnd, offset + EXECUTION_WINDOW_SIZE_IN_SECONDS);
}",time,2
72,strapdata_elassandra,testTokenExpiry,"@Test
public void testTokenExpiry() throws Exception {
    ClockMock clock = ClockMock.frozen();
    TokenService tokenService = createTokenService(tokenServiceEnabledSettings, clock);
    Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null);
    PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>();
    tokenService.createUserToken(authentication, authentication, tokenFuture, Collections.emptyMap(), true);
    final UserToken token = tokenFuture.get().v1();
    mockGetTokenFromId(token);
    mockCheckTokenInvalidationFromId(token);
    authentication = token.getAuthentication();
    ThreadContext requestContext = new ThreadContext(Settings.EMPTY);
    storeTokenHeader(requestContext, tokenService.getUserTokenString(token));
    try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
        PlainActionFuture<UserToken> future = new PlainActionFuture<>();
        tokenService.getAndValidateToken(requestContext, future);
        assertAuthenticationEquals(authentication, future.get().getAuthentication());
    }
    final TimeValue defaultExpiration = TokenService.TOKEN_EXPIRATION.get(Settings.EMPTY);
    final int fastForwardAmount = randomIntBetween(1, Math.toIntExact(defaultExpiration.getSeconds()) - 5);
    try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) {
        clock.fastForwardSeconds(Math.toIntExact(defaultExpiration.getSeconds()) - fastForwardAmount);
        clock.rewind(TimeValue.timeValueNanos(clock.instant().getNano()));
        PlainActionFuture<UserToken> future = new PlainActionFuture<>();
        tokenService.getAndValidateToken(requestContext, future);
        assertAuthenticationEquals(authentication, future.get().getAuthentication());
    }
    assertSettingDeprecationsAndWarnings(new Setting[] { TokenService.BWC_ENABLED });
}",time,2
74,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBind.2,"@Test
public void testBind() throws Exception {
    final Name name = new CompositeName(""test"");
    final Object value = new Object();
    WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
    try {
        store.bind(name, value);
    } finally {
        WritableServiceBasedNamingStore.popOwner();
    }
    assertEquals(value, store.lookup(name));
}",test order dependency,4
75,apache_hadoop,TestPathData.testUnqualifiedUriContents,"@Test
public void testUnqualifiedUriContents() throws Exception {
    dirString = ""d1"";
    item = new PathData(dirString, conf);
    PathData[] items = item.getDirectoryContents();
    assertEquals(sortedString(""d1/f1"", ""d1/f1.1"", ""d1/f2""), sortedString(items));
}",test order dependency,4
76,swankjesse_dex,assertDurationIsInRange,"@Test
public void assertDurationIsInRange(long expectedMillis) {
    long minimum = (long) ((double) expectedMillis * 0.90);
    long maximum =
    Math.max((long) ((double) expectedMillis * 1.10), 10);
    long waitMillis = Math.max(expectedMillis * 10, 10);
    long duration = getDurationMillis(waitMillis);
    if (duration < minimum) {
        Assert.fail(""expected duration: "" + expectedMillis +
        "" minimum duration: "" + minimum +
        "" actual duration too short: "" + duration);
    } else if (duration > maximum) {
        Assert.fail(""expected duration: "" + expectedMillis +
        "" maximum duration: "" + maximum +
        "" actual duration too long: "" + duration);
    }
}",time,2
79,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRejectionEAP6,"@Test
public void testRejectionsEAP6() throws Exception {
    testTransformer(""subsystem.xml"", ModelTestControllerVersion.EAP_6_4_0, ModelVersion.create(1, 3),""jboss-as-naming"");
}",test order dependency,4
80,FasterXML_jackson-databind,TestGenerateJsonSchema.testUnwrapping,"@Test
public void testUnwrapping() throws Exception {
    JsonSchema jsonSchema = MAPPER.generateJsonSchema(UnwrappingRoot.class);
    String json = jsonSchema.toString().replaceAll(""\"""", ""'"");
    String EXP = ""{'type':'object',"" + (""'properties':{'age':{'type':'integer'},"" + ""'name.first':{'type':'string'},'name.last':{'type':'string'}}}"");
    assertEquals(EXP, json);
}",unordered collections,3
82,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupLink,"@Test
public void testLookupLink() throws Exception {
    final Name name = new CompositeName(""test"");
    namingStore.bind(name, ""testValue"", String.class);
    final Name linkName = new CompositeName(""link"");
    namingStore.bind(linkName, new LinkRef(""./test""));
    Object result = namingContext.lookup(linkName);
    assertEquals(""testValue"", result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link"");
    assertEquals(""testValue"", result);
    System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
    namingStore.rebind(linkName, new LinkRef(name));
    result = namingContext.lookup(linkName);
    assertEquals(""testValue"", result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link"");
    assertEquals(""testValue"", result);
}",test order dependency,4
83,square_okhttp,CallTest.legalToExecuteTwiceCloning_Async,"@Test
public void legalToExecuteTwiceCloning_Async() throws Exception {
    server.enqueue(new MockResponse().setBody(""abc""));
    server.enqueue(new MockResponse().setBody(""def""));
    Request request = new Request.Builder().url(server.url(""/"")).build();
    Call call = client.newCall(request);
    call.enqueue(callback);
    Call cloned = call.clone();
    cloned.enqueue(callback);
    callback.await(request.url()).assertBody(""abc"");
    callback.await(request.url()).assertBody(""def"");
}",async wait,0
89,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupReference,"@Test
public void testLookupReference() throws Exception {
    final Name name = new CompositeName(""test"");
    final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""blah"", ""test""), TestObjectFactory.class.getName(), null);
    namingStore.bind(name, reference);
    Object result = namingContext.lookup(name);
    assertEquals(""test"", result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
    assertEquals(""test"", result);
}",test order dependency,4
96,apache_hadoop,TestBlockFixer.testGeneratedBlock,"@Test
public void testGeneratedBlock() throws Exception {
    LOG.info(""Test testGeneratedBlock started."");
    long blockSize = 8192L;
    int stripeLength = 3;
    mySetup(stripeLength, -1);
    Path file1 = new Path(""/user/dhruba/raidtest/file1"");
    Path destPath = new Path(""/destraid/user/dhruba/raidtest"");
    long crc1 = TestRaidDfs.createTestFile(fileSys, file1, 1, 7, blockSize);
    long file1Len = fileSys.getFileStatus(file1).getLen();
    LOG.info(""Test testGeneratedBlock created test files"");
    Configuration localConf = new Configuration(conf);
    localConf.set(RAID_LOCATION_KEY, ""/destraid"");
    localConf.setInt(""raid.blockfix.interval"", 1000);
    localConf.setLong(""raid.blockfix.filespertask"", 2L);
    try {
        cnode = RaidNode.createRaidNode(null, localConf);
        TestRaidDfs.waitForFileRaided(LOG, fileSys, file1, destPath);
        cnode.stop();
        cnode.join();
        FileStatus srcStat = fileSys.getFileStatus(file1);
        DistributedFileSystem dfs = ((DistributedFileSystem) (fileSys));
        LocatedBlocks locs = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, srcStat.getLen());
        String[] corruptFiles = RaidDFSUtil.getCorruptFiles(conf);
        assertEquals(corruptFiles.length, 0);
        assertEquals(0, cnode.blockFixer.filesFixed());
        corruptBlock(locs.get(0).getBlock().getBlockName());
        reportCorruptBlocks(dfs, file1, new int[]{ 0 }, blockSize);
        corruptFiles = RaidDFSUtil.getCorruptFiles(conf);
        assertEquals(corruptFiles.length, 1);
        assertEquals(corruptFiles[0], file1.toUri().getPath());
        cnode = RaidNode.createRaidNode(null, localConf);
        long start = System.currentTimeMillis();
        while ((cnode.blockFixer.filesFixed() < 1) && ((System.currentTimeMillis() - start) < 120000)) {
            LOG.info(""Test testGeneratedBlock waiting for files to be fixed."");
            Thread.sleep(1000);
        }
        assertEquals(1, cnode.blockFixer.filesFixed());
        cnode.stop();
        cnode.join();
        cnode = null;
        dfs = getDFS(conf, dfs);
        assertTrue(TestRaidDfs.validateFile(dfs, file1, file1Len, crc1));
        locs = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, srcStat.getLen());
        corruptBlock(locs.get(0).getBlock().getBlockName());
        reportCorruptBlocks(dfs, file1, new int[]{ 0 }, blockSize);
        try {
            Thread.sleep(5 * 1000);
        } catch (InterruptedException ignore) {
        }
        try {
            TestRaidDfs.validateFile(dfs, file1, file1Len, crc1);
            fail(""Expected exception not thrown"");
        } catch (ChecksumException ce) {
        } catch (BlockMissingException bme) {
        }
    } catch (Exception e) {
        LOG.info((""Test testGeneratedBlock Exception "" + e) + StringUtils.stringifyException(e));
        throw e;
    } finally {
        myTearDown();
    }
    LOG.info(""Test testGeneratedBlock completed."");
}",concurrency,1
97,trinodb_trino,testQueryTimeout,"@Test
public void testQueryTimeout()
throws Exception
{
    try (Connection connection = createConnection(""blackhole"", ""blackhole"");
    Statement statement = connection.createStatement()) {
        statement.executeUpdate(""CREATE TABLE test_query_timeout (key BIGINT) "" +
        ""WITH ("" +
        ""   split_count = 1, "" +
        ""   pages_per_split = 1, "" +
        ""   rows_per_page = 1, "" +
        ""   page_processing_delay = '1m'"" +
        "")"");
    }
    CountDownLatch queryFinished = new CountDownLatch(1);
    AtomicReference<Throwable> queryFailure = new AtomicReference<>();
    executorService.submit(() -> {
        try (Connection connection = createConnection(""blackhole"", ""default"");
        Statement statement = connection.createStatement()) {
            statement.setQueryTimeout(1);
            try (ResultSet resultSet = statement.executeQuery(""SELECT * FROM test_query_timeout"")) {
                try {
                    resultSet.next();
                }
                catch (SQLException t) {
                    queryFailure.set(t);
                }
                finally {
                    queryFinished.countDown();
                }
            }
        }
        return null;
    });
    assertTrue(queryFinished.await(2, SECONDS));
    assertNotNull(queryFailure.get());
    assertContains(queryFailure.get().getMessage(), ""Query exceeded maximum time limit of 1.00s"");
    try (Connection connection = createConnection(""blackhole"", ""blackhole"");
    Statement statement = connection.createStatement()) {
        statement.executeUpdate(""DROP TABLE test_query_timeout"");
    }
}",async wait,0
100,androidx_androidx,playbackRate,"@Test
public void playbackRate() throws Exception {
    final int toleranceMs = 1000;
    Future<PlayerResult> setSurfaceFuture = mPlayer.setSurface(
    mActivity.getSurfaceHolder().getSurface());
    Future<PlayerResult> prepareFuture = mPlayer.prepare();
    assertFutureSuccess(setSurfaceFuture);
    assertFutureSuccess(prepareFuture);
    float[] rates = {0.25f, 0.5f, 1.0f, 2.0f};
    for (float playbackRate : rates) {
        Future<PlayerResult> seekFuture = mPlayer.seekTo(0, MediaPlayer.SEEK_PREVIOUS_SYNC);
        Thread.sleep(1000);
        int playTime = 4000;
        int privState = mPlayer.getPlayerState();
        Future<PlayerResult> setParamsFuture = mPlayer.setPlaybackParams(
        new PlaybackParams.Builder().setSpeed(playbackRate).build());
        assertFutureSuccess(seekFuture);
        assertFutureSuccess(setParamsFuture);
        assertEquals(""setPlaybackParams() should not change player state. ""
        + mPlayer.getPlayerState(), privState, mPlayer.getPlayerState());
        Future<PlayerResult> playFuture = mPlayer.play();
        Thread.sleep(playTime);
        PlaybackParams pbp = mPlayer.getPlaybackParams();
        assertEquals(playbackRate, pbp.getSpeed(), FLOAT_TOLERANCE);
        assertEquals(""The player should still be playing"",
        MediaPlayer.PLAYER_STATE_PLAYING, mPlayer.getPlayerState());
        long playedMediaDurationMs = mPlayer.getCurrentPosition();
        long expectedPosition = (long) (playTime * playbackRate);
        int diff = (int) Math.abs(playedMediaDurationMs - expectedPosition);
        if (diff > toleranceMs) {
            fail(""Media player had error in playback rate "" + playbackRate
            + "". expected position after playing "" + playTime
            + "" was "" + expectedPosition + "", but actually "" + playedMediaDurationMs);
        }
        assertFutureSuccess(playFuture);
        assertFutureSuccess(mPlayer.pause());
        pbp = mPlayer.getPlaybackParams();
        assertEquals(""pause() should not change the playback rate property."",
        playbackRate, pbp.getSpeed(), FLOAT_TOLERANCE);
    }
    mPlayer.reset();
}",async wait,0
104,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListNameNotFound,"@Test
public void testListNameNotFound() throws Exception {
    try {
        namingContext.list(new CompositeName(""test""));
        fail(""Should have thrown and NameNotFoundException"");
    } catch (NameNotFoundException expected) {
    }
    try {
        testActionPermission(JndiPermission.ACTION_LIST, namingContext, ""test"");
        fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
    } catch (NameNotFoundException expected) {
    }
}",test order dependency,4
105,apache_hadoop,TestRPCCompatibility.testVersion2ClientVersion2Server,"@Test
public void testVersion2ClientVersion2Server() throws Exception {
    ProtocolSignature.resetCache();
    TestImpl2 impl = new TestImpl2();
    server = new RPC.Builder(conf).setProtocol(TestProtocol2.class).setInstance(impl).setBindAddress(ADDRESS).setPort(0).setNumHandlers(2).setVerbose(false).build();
    server.addProtocol(RPC_WRITABLE, TestProtocol0.class, impl);
    server.start();
    addr = NetUtils.getConnectAddress(server);
    Version2Client client = new Version2Client();
    client.ping();
    assertEquals(""hello"", client.echo(""hello""));
    assertEquals(-3, client.echo(3));
}",test order dependency,4
107,apache_hadoop,TestDelegationTokenForProxyUser.testDelegationTokenWithRealUser,"@Test
public void testDelegationTokenWithRealUser() throws IOException {
    UserGroupInformation ugi = UserGroupInformation.createRemoteUser(REAL_USER);
    final UserGroupInformation proxyUgi = UserGroupInformation.createProxyUserForTesting(PROXY_USER, ugi, GROUP_NAMES);
    try {
        Token<?>[] tokens = proxyUgi.doAs(new PrivilegedExceptionAction<Token<?>[]>() {
            @Override
            public Token<?>[] run() throws IOException {
                return cluster.getFileSystem().addDelegationTokens(""RenewerUser"", null);
            }
        });
        DelegationTokenIdentifier identifier = new DelegationTokenIdentifier();
        byte[] tokenId = tokens[0].getIdentifier();
        identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId)));
        Assert.assertEquals(identifier.getUser().getUserName(), PROXY_USER);
        Assert.assertEquals(identifier.getUser().getRealUser().getUserName(), REAL_USER);
    } catch (InterruptedException e) {
    }
}",test order dependency,4
111,apache_hadoop,TestPathData.testWithStringAndConfForBuggyPath,"@Test
public void testWithStringAndConfForBuggyPath() throws Exception {
    dirString = ""file"" ;
    testDir = new Path(dirString);
    item = new PathData(dirString, conf);
    assertEquals(""file:/tmp"", testDir.toString());
    checkPathData();
}",test order dependency,4
120,apache_hadoop,TestModTime.testModTime,"@Test
public void testModTime() throws IOException {
    Configuration conf = new Configuration();
    MiniDFSCluster cluster = new MiniDFSCluster(conf, numDatanodes, true, null);
    cluster.waitActive();
    InetSocketAddress addr = new InetSocketAddress(""localhost"", cluster.getNameNodePort());
    DFSClient client = new DFSClient(addr, conf);
    DatanodeInfo[] info = client.datanodeReport(LIVE);
    assertEquals(""Number of Datanodes "", numDatanodes, info.length);
    FileSystem fileSys = cluster.getFileSystem();
    int replicas = numDatanodes - 1;
    assertTrue(fileSys instanceof DistributedFileSystem);
    try {
        System.out.println(""Creating testdir1 and testdir1/test1.dat."");
        Path dir1 = new Path(""testdir1"");
        Path file1 = new Path(dir1, ""test1.dat"");
        writeFile(fileSys, file1, replicas);
        FileStatus stat = fileSys.getFileStatus(file1);
        long mtime1 = stat.getModificationTime();
        assertTrue(mtime1 != 0);
        stat = fileSys.getFileStatus(dir1);
        long mdir1 = stat.getModificationTime();
        System.out.println(""Creating testdir1/test2.dat."");
        Path file2 = new Path(dir1, ""test2.dat"");
        writeFile(fileSys, file2, replicas);
        stat = fileSys.getFileStatus(file2);
        stat = fileSys.getFileStatus(dir1);
        assertTrue(stat.getModificationTime() >= mdir1);
        mdir1 = stat.getModificationTime();
        Path dir2 = new Path(""testdir2/"").makeQualified(fileSys);
        System.out.println(""Creating testdir2 "" + dir2);
        assertTrue(fileSys.mkdirs(dir2));
        stat = fileSys.getFileStatus(dir2);
        long mdir2 = stat.getModificationTime();
        Path newfile = new Path(dir2, ""testnew.dat"");
        System.out.println(((""Moving "" + file1) + "" to "") + newfile);
        fileSys.rename(file1, newfile);
        stat = fileSys.getFileStatus(newfile);
        assertTrue(stat.getModificationTime() == mtime1);
        stat = fileSys.getFileStatus(dir1);
        assertTrue(stat.getModificationTime() != mdir1);
        mdir1 = stat.getModificationTime();
        stat = fileSys.getFileStatus(dir2);
        assertTrue(stat.getModificationTime() != mdir2);
        mdir2 = stat.getModificationTime();
        System.out.println(""Deleting testdir2/testnew.dat."");
        assertTrue(fileSys.delete(newfile, true));
        stat = fileSys.getFileStatus(dir1);
        assertTrue(stat.getModificationTime() == mdir1);
        stat = fileSys.getFileStatus(dir2);
        assertTrue(stat.getModificationTime() != mdir2);
        mdir2 = stat.getModificationTime();
        cleanupFile(fileSys, file2);
        cleanupFile(fileSys, dir1);
        cleanupFile(fileSys, dir2);
    } catch (IOException e) {
        info = client.datanodeReport(ALL);
        printDatanodeReport(info);
        throw e;
    } finally {
        fileSys.close();
        cluster.shutdown();
    }
}",time,2
129,apache_hadoop,TestPathData.testWithDirStringAndConf,"@Test
public void testWithDirStringAndConf() throws Exception {
    dirString = ""d1"";
    item = new PathData(dirString, conf);
    checkPathData();
    dirString = ""d1/"";
    item = new PathData(dirString, conf);
    checkPathData();
}",test order dependency,4
130,Kong_unirest-java,DefectTest.nullAndObjectValuesInMap,"@Test
void nullAndObjectValuesInMap() {
    Map<String, Object> queryParams = new HashMap<>();
    queryParams.put(""foo"", null);
    queryParams.put(""baz"", ""qux"");
    Unirest.get(GET).queryString(queryParams).asObject(RequestCapture.class).getBody().assertParam(""foo"", """").assertParam(""baz"", ""qux"").assertQueryString(""foo&baz=qux"");
}",unordered collections,3
131,apache_beam,testClientConnecting,"@Test
public void testClientConnecting() throws Exception {
    PipelineOptions options = PipelineOptionsFactory.create();
    Endpoints.ApiServiceDescriptor descriptor = findOpenPort();
    BeamFnControlService service =
    new BeamFnControlService(
    descriptor,
    ServerStreamObserverFactory.fromOptions(options)::from,
    GrpcContextHeaderAccessorProvider.getHeaderAccessor());
    Server server =
    ServerFactory.fromOptions(options).create(descriptor, ImmutableList.of(service));
    String url = service.getApiServiceDescriptor().getUrl();
    BeamFnControlGrpc.BeamFnControlStub clientStub =
    BeamFnControlGrpc.newStub(ManagedChannelBuilder.forTarget(url).usePlaintext(true).build());
    clientStub.control(requestObserver);
    try (FnApiControlClient client = service.get()) {
        assertNotNull(client);
    }
    server.shutdown();
    server.awaitTermination(1, TimeUnit.SECONDS);
    server.shutdownNow();
    verify(requestObserver).onCompleted();
    verifyNoMoreInteractions(requestObserver);
}",async wait,0
132,androidx_androidx,testInterruption,"@Test
public void testInterruption() throws InterruptedException {
    OneTimeWorkRequest work = new OneTimeWorkRequest.Builder(TestWorker.class).build();
    insertWork(work);
    WorkerWrapper workerWrapper =
    createBuilder(work.getStringId())
    .withSchedulers(Collections.singletonList(mMockScheduler))
    .build();
    FutureListener listener = createAndAddFutureListener(workerWrapper);
    Executors.newSingleThreadExecutor().submit(workerWrapper);
    workerWrapper.interrupt();
    Thread.sleep(6000L);
    assertThat(listener.mResult, is(true));
}",async wait,0
135,apache_hadoop,testPendingAndInvalidate,"@Test
public class Test {
    public void testPendingAndInvalidate() throws Exception {
        final Configuration CONF = new HdfsConfiguration();
        MiniDFSCluster cluster = new MiniDFSCluster.Builder(CONF).numDataNodes(DATANODE_COUNT).build();
        cluster.waitActive();
        FSNamesystem namesystem = cluster.getNamesystem();
        BlockManager bm = namesystem.getBlockManager();
        DistributedFileSystem fs = cluster.getFileSystem();
        try {
            Path filePath = new Path(""/tmp.txt"");
            DFSTestUtil.createFile(fs, filePath, 1024, (short) 3, 0L);
            for (DataNode dn : cluster.getDataNodes()) {
                DataNodeTestUtils.setHeartbeatsDisabledForTests(dn, true);
            }
            LocatedBlock block = NameNodeAdapter.getBlockLocations(
            cluster.getNameNode(), filePath.toString(), 0, 1).get(0);
            cluster.getNamesystem().writeLock();
            try {
                bm.findAndMarkBlockAsCorrupt(block.getBlock(), block.getLocations()[0],
                ""STORAGE_ID"", ""TEST"");
            } finally {
                cluster.getNamesystem().writeUnlock();
            }
            BlockManagerTestUtil.computeAllPendingWork(bm);
            BlockManagerTestUtil.updateState(bm);
            assertEquals(bm.getPendingReconstructionBlocksCount(), 1L);
            BlockInfo storedBlock = bm.getStoredBlock(block.getBlock().getLocalBlock());
            assertEquals(bm.pendingReconstruction.getNumReplicas(storedBlock), 2);
            fs.delete(filePath, true);
            int retries = 10;
            long pendingNum = bm.getPendingReconstructionBlocksCount();
            while (pendingNum != 0 && retries-- > 0) {
                Thread.sleep(1000);
                BlockManagerTestUtil.updateState(bm);
                pendingNum = bm.getPendingReconstructionBlocksCount();
            }
            assertEquals(pendingNum, 0L);
        } finally {
            cluster.shutdown();
        }
    }
}",concurrency,1
145,apache_pinot,SegmentGenerationWithTimeColumnTest.testMinAllowedValue,"@Test
public void testMinAllowedValue() {
    long millis = _validMinTime;
    DateTime dateTime = new DateTime(millis, DateTimeZone.UTC);
    LocalDateTime localDateTime = dateTime.toLocalDateTime();
    int year = localDateTime.getYear();
    int month = localDateTime.getMonthOfYear();
    int day = localDateTime.getDayOfMonth();
    Assert.assertEquals(year, 1971);
    Assert.assertEquals(month, 1);
    Assert.assertEquals(day, 1);
}",time,2
149,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testCompositeBindingUpdate,"@Test
public void testCompositeBindingUpdate() throws Exception {
    final KernelServices services = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build();
    final ModelNode addr = Operations.createAddress(ModelDescriptionConstants.SUBSYSTEM, NamingExtension.SUBSYSTEM_NAME, NamingSubsystemModel.BINDING, ""java:global/a"");
    final ModelNode compositeOp = Operations.CompositeOperationBuilder.create()
    .addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.BINDING_TYPE, NamingSubsystemModel.LOOKUP))
    .addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.LOOKUP, ""java:global/b""))
    .build().getOperation();
    ModelTestUtils.checkOutcome(services.executeOperation(compositeOp));
}",test order dependency,4
153,androidx_androidx,testOneTimeRequest_noInitialDelay_withConstraintNetworkConnected,"@Test
public void testOneTimeRequest_noInitialDelay_withConstraintNetworkConnected() {
    val now = System.currentTimeMillis() ;
    when(mTaskConverter.now()).thenReturn(now) ;
    val constraints = Constraints.Builder().setRequiredNetworkType(NetworkType.METERED).setRequiresCharging(true).build() ;
    val request = OneTimeWorkRequestBuilder<TestWorker>()
    .setConstraints(constraints)
    .build() ;
    val task = mTaskConverter.convert(request.workSpec) ;
    val expected = request.workSpec.calculateNextRunTime() ;
    val offset = offset(expected, now) ;
    assertEquals(task.serviceName, WorkManagerGcmService::class.java.name) ;
    assertEquals(task.isPersisted, false) ;
    assertEquals(task.isUpdateCurrent, true) ;
    assertEquals(task.requiredNetwork, Task.NETWORK_STATE_CONNECTED) ;
    assertEquals(task.requiresCharging, true) ;
    assertEquals(task.windowStart, offset) ;
    assertEquals(task.windowEnd, offset + EXECUTION_WINDOW_SIZE_IN_SECONDS) ;
}",time,2
157,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testStoredContext,"@Test
public void testStoredContext() throws Exception {
    final ServiceName bindingName = ServiceName.JBOSS.append(""foo-stored"").append(""again"");
    bindObject(bindingName, new Context() {
        @Override
        public Object lookup(Name name) throws NamingException {
            if (""blah/blah2"".equals(name.toString())) {
                return new Integer(5);
            }
            return null;
        }
        @Override
        public Object lookup(String name) throws NamingException {
            return lookup(new CompositeName(name));
        }
        @Override
        public void bind(Name name, Object obj) throws NamingException {
        }
        @Override
        public void bind(String name, Object obj) throws NamingException {
        }
        @Override
        public void rebind(Name name, Object obj) throws NamingException {
        }
        @Override
        public void rebind(String name, Object obj) throws NamingException {
        }
        @Override
        public void unbind(Name name) throws NamingException {
        }
        @Override
        public void unbind(String name) throws NamingException {
        }
        @Override
        public void rename(Name oldName, Name newName) throws NamingException {
        }
        @Override
        public void rename(String oldName, String newName) throws NamingException {
        }
        @Override
        public NamingEnumeration<NameClassPair> list(Name name) throws NamingException {
            return null;
        }
        @Override
        public NamingEnumeration<NameClassPair> list(String name) throws NamingException {
            return null;
        }
        @Override
        public NamingEnumeration<Binding> listBindings(Name name) throws NamingException {
            if (!""hi/there"".equals(name.toString()))
            throw new IllegalArgumentException(""Expected hi/there"");
            return null;
        }
        @Override
        public NamingEnumeration<Binding> listBindings(String name) throws NamingException {
            return null;
        }
        @Override
        public void destroySubcontext(Name name) throws NamingException {
        }
        @Override
        public void destroySubcontext(String name) throws NamingException {
        }
        @Override
        public Context createSubcontext(Name name) throws NamingException {
            return null;
        }
        @Override
        public Context createSubcontext(String name) throws NamingException {
            return null;
        }
        @Override
        public Object lookupLink(Name name) throws NamingException {
            return null;
        }
        @Override
        public Object lookupLink(String name) throws NamingException {
            return null;
        }
        @Override
        public NameParser getNameParser(Name name) throws NamingException {
            return null;
        }
        @Override
        public NameParser getNameParser(String name) throws NamingException {
            return null;
        }
        @Override
        public Name composeName(Name name, Name prefix) throws NamingException {
            return null;
        }
        @Override
        public String composeName(String name, String prefix) throws NamingException {
            return null;
        }
        @Override
        public Object addToEnvironment(String propName, Object propVal) throws NamingException {
            return null;
        }
        @Override
        public Object removeFromEnvironment(String propName) throws NamingException {
            return null;
        }
        @Override
        public Hashtable<?, ?> getEnvironment() throws NamingException {
            return null;
        }
        @Override
        public void close() throws NamingException {
        }
        @Override
        public String getNameInNamespace() throws NamingException {
            return null;
        }
    });
    final NamingContext ctx = new NamingContext(new CompositeName(), store, null);
    final Object obj = ctx.lookup(new CompositeName(""foo-stored/again/blah/blah2""));
    ctx.listBindings(""foo-stored/again/hi/there"");
    assertNotNull(obj);
    assertEquals(new Integer(5), obj);
}",test order dependency,4
158,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBindAndRetrieveObjectFactoryFromInitialContext,"@Test
public void testBindAndRetrieveObjectFactoryFromInitialContext() throws Exception {
    final Reference reference = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null);
    namingStore.bind(new CompositeName(""test""), reference);
    final InitialContext initialContext = new InitialContext();
    final Object result = initialContext.lookup(""test"");
    assertTrue(result instanceof String);
    assertEquals(""Test ParsedResult"", result);
}",test order dependency,4
159,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireOneLevelEvent,"@Test
public void testFireOneLevelEvent() throws Exception {
    final NamingEventCoordinator coordinator = new NamingEventCoordinator();
    final CollectingListener objectListener = new CollectingListener(0);
    coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
    final CollectingListener subtreeListener = new CollectingListener(0);
    coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
    final CollectingListener oneLevelListener = new CollectingListener(1);
    coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);
    coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.ONELEVEL_SCOPE);
    oneLevelListener.latch.await(1, TimeUnit.SECONDS);
    assertTrue(objectListener.capturedEvents.isEmpty());
    assertTrue(subtreeListener.capturedEvents.isEmpty());
    assertEquals(1, oneLevelListener.capturedEvents.size());
}",test order dependency,4
162,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupWitResolveResult,"@Test
public void testLookupWitResolveResult() throws Exception {
    namingStore.bind(new CompositeName(""test/nested""), ""test"");
    final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""blahh"", ""test""), TestObjectFactoryWithNameResolution.class.getName(), null);
    namingStore.bind(new CompositeName(""comp""), reference);
    Object result = namingContext.lookup(new CompositeName(""comp/nested""));
    assertEquals(""test"", result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test/nested"", ""lookup"")), namingContext, ""comp/nested"");
    assertEquals(""test"", result);
}",test order dependency,4
166,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRejectionEAP7,"@Test
public void testRejectionsEAP7() throws Exception {
    testTransformer(""subsystem.xml"", ModelTestControllerVersion.EAP_7_0_0, ModelVersion.create(2, 0), ""wildfly-naming"");
}",test order dependency,4
169,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBindNested,"@Test
public void testBindNested() throws Exception {
    final Name name = new CompositeName(""nested/test"");
    final Object value = new Object();
    WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
    try {
        store.bind(name, value);
    } finally {
        WritableServiceBasedNamingStore.popOwner();
    }
    assertEquals(value, store.lookup(name));
}",test order dependency,4
173,apache_hadoop,TestPathData.testQualifiedUriContents,"@Test
public void testQualifiedUriContents() throws Exception {
    dirString = fs.makeQualified(new Path(""d1"")).toString();
    item = new PathData(dirString, conf);
    PathData[] items = item.getDirectoryContents();
    assertEquals(sortedString(dirString + ""/f1"", dirString + ""/f1.1"", dirString + ""/f2""), sortedString(items));
}",test order dependency,4
175,apache_beam,testRateLimitingMax,"@Test
public void testRateLimitingMax() {
    int n = 10;
    double rate = 10.0;
    long duration = runWithRate(n, rate, new IdentityFn<Integer>());
    long perElementPause = (long) (1000L / rate);
    long minDuration = (n - 1) * perElementPause;
    Assert.assertThat(duration, greaterThan(minDuration));
}",time,2
178,salesforce_reactive-grpc,ChainedCallIntegrationTest.servicesCanCallOtherServices,"@Test
public void servicesCanCallOtherServices() throws InterruptedException {
    ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
    Mono<String> chain =
    Mono.just(request(""X"")).compose(stub::sayHello).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).as(stub::sayHelloRespStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).compose(stub::sayHelloBothStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).as(stub::sayHelloReqStream).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).compose(stub::sayHello).map(HelloResponse::getMessage).doOnSuccess(System.out::println);
    StepVerifier.create(chain).expectNext(""[<{[X]}> :: </[X]/> :: <\\[X]\\> :: <([X])>]"").expectComplete().verify(Duration.ofSeconds(2));
}",concurrency,1
188,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupBindingUsingNestedContext,"@Test
public void testLookupBindingUsingNestedContext() throws Exception {
    final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean"");
    final Object value = new Object();
    bindObject(bindingName, value);
    Object context = store.lookup(new CompositeName(""foo""));
    assertNotNull(context);
    assertTrue(context instanceof Context);
    Object obj = Context.class.cast(context).lookup(new CompositeName(""bar/baz/TestBean""));
    assertNotNull(obj);
    assertEquals(value, obj);
    context = Context.class.cast(context).lookup(new CompositeName(""bar""));
    obj = Context.class.cast(context).lookup(new CompositeName(""baz/TestBean""));
    assertNotNull(obj);
    assertEquals(value, obj);
    context = Context.class.cast(context).lookup(new CompositeName(""baz""));
    obj = Context.class.cast(context).lookup(new CompositeName(""TestBean""));
    assertNotNull(obj);
    assertEquals(value, obj);
}",test order dependency,4
192,aws_aws-sdk-java-v2,S3TransferManagerListenerTest.upload_success_shouldInvokeListener,"@Test
public void upload_success_shouldInvokeListener() throws Exception {
    TransferListener listener = mock(TransferListener.class);
    Path path = newTempFile();
    Files.write(path, randomBytes(contentLength));
    UploadRequest uploadRequest = UploadRequest.builder().putObjectRequest(( r) -> r.bucket(""bucket"").key(""key"")).source(path).overrideConfiguration(( b) -> b.addListener(listener)).build();
    Upload upload = tm.upload(uploadRequest);
    upload.completionFuture().join();
    ArgumentCaptor<TransferListener.Context.TransferInitiated> captor1 = ArgumentCaptor.forClass(TransferInitiated.class);
    verify(listener, times(1)).transferInitiated(captor1.capture());
    TransferListener.Context.TransferInitiated ctx1 = captor1.getValue();
    assertThat(ctx1.request()).isSameAs(uploadRequest);
    assertThat(ctx1.progressSnapshot().transferSizeInBytes()).hasValue(contentLength);
    assertThat(ctx1.progressSnapshot().bytesTransferred()).isZero();
    ArgumentCaptor<TransferListener.Context.BytesTransferred> captor2 = ArgumentCaptor.forClass(BytesTransferred.class);
    verify(listener, times(1)).bytesTransferred(captor2.capture());
    TransferListener.Context.BytesTransferred ctx2 = captor2.getValue();
    assertThat(ctx2.request()).isSameAs(uploadRequest);
    assertThat(ctx2.progressSnapshot().transferSizeInBytes()).hasValue(contentLength);
    assertThat(ctx2.progressSnapshot().bytesTransferred()).isPositive();
    ArgumentCaptor<TransferListener.Context.TransferComplete> captor3 = ArgumentCaptor.forClass(TransferComplete.class);
    verify(listener, times(1)).transferComplete(captor3.capture());
    TransferListener.Context.TransferComplete ctx3 = captor3.getValue();
    assertThat(ctx3.request()).isSameAs(uploadRequest);
    assertThat(ctx3.progressSnapshot().transferSizeInBytes()).hasValue(contentLength);
    assertThat(ctx3.progressSnapshot().bytesTransferred()).isEqualTo(contentLength);
    assertThat(ctx3.completedTransfer()).isSameAs(upload.completionFuture().get());
    verifyNoMoreInteractions(listener);
}",async wait,0
194,netty_netty,testAutomaticStartStop,"@Test
public void testAutomaticStartStop() throws Exception {
    final TestRunnable task = new TestRunnable(500);
    e.execute(task);
    Thread thread = e.thread;
    assertThat(thread, is(not(nullValue())));
    assertThat(thread.isAlive(), is(true));
    Thread.sleep(1500);
    assertThat(thread.isAlive(), is(false));
    assertThat(task.ran.get(), is(true));
    task.ran.set(false);
    e.execute(task);
    assertThat(e.thread, not(sameInstance(thread)));
    thread = e.thread;
    Thread.sleep(1500);
    assertThat(thread.isAlive(), is(false));
    assertThat(task.ran.get(), is(true));
}",async wait,0
196,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBind,"@Test
public void testBind() throws Exception {
    Name name = new CompositeName(""test"");
    final Object value = new Object();
    namingContext.bind(name, value);
    assertEquals(value, namingStore.lookup(name));
    name = new CompositeName(""securitytest"");
    testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""securitytest"", value);
    assertEquals(value, namingStore.lookup(name));
}",test order dependency,4
198,apache_hadoop,TestPathData.testCwdContents,"@Test
public void testCwdContents() throws Exception {
    dirString = Path.CUR_DIR;
    item = new PathData(dirString, conf);
    PathData[] items = item.getDirectoryContents();
    assertEquals(sortedString(""d1"", ""d2""), sortedString(items));
}",test order dependency,4
201,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupBinding.2.,"@Test
public void testLookupBinding() throws Exception {
    final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"");
    final Object value = new Object();
    bindObject(bindingName, value);
    final Object obj = store.lookup(new CompositeName(""foo/bar""));
    assertNotNull(obj);
    assertEquals(value, obj);
}",test order dependency,4
208,vespa-engine_vespa,testNodeMetricsDb,"@Test
public void testNodeMetricsDb() {
    ManualClock clock = new ManualClock();
    NodeMetricsDb db = new NodeMetricsDb();
    List<NodeMetrics.MetricValue> values = new ArrayList<>();
    for (int i = 0; i < 40; i++) {
        values.add(new NodeMetrics.MetricValue(""host0"", ""cpu.util"", clock.instant().getEpochSecond(), 0.9f));
        clock.advance(Duration.ofHours(1));
    }
    db.add(values);
    assertEquals(29, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.cpu,    List.of(""host0"")).measurementCount());
    assertEquals( 0, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.memory, List.of(""host0"")).measurementCount());
    db.gc(clock);
    assertEquals(23, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.cpu,    List.of(""host0"")).measurementCount());
    assertEquals( 0, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.memory, List.of(""host0"")).measurementCount());
}",time,2
209,apache_hadoop,TestHftpFileSystem.testHftpCustomDefaultPorts,"@Test
public void testHftpCustomDefaultPorts() throws IOException {
    resetFileSystem();
    Configuration conf = new Configuration();
    conf.setInt(""dfs.http.port"", 123);
    conf.setInt(""dfs.https.port"", 456);
    URI uri = URI.create();
    HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf)));
    assertEquals(123, fs.getDefaultPort());
    assertEquals(456, fs.getDefaultSecurePort());
    assertEquals(uri, fs.getUri());
    assertEquals(""127.0.0.1:456"", fs.getCanonicalServiceName());
}",test order dependency,4
210,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testBindReferenceable,"@Test
public void testBindReferenceable() throws Exception {
    Name name = new CompositeName(""test"");
    final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr"");
    namingContext.bind(name, referenceable);
    Object result = namingContext.lookup(name);
    assertEquals(referenceable.addr, result);
    name = new CompositeName(""securitytest"");
    testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""securitytest"", referenceable);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""securitytest"");
    assertEquals(referenceable.addr, result);
}",test order dependency,4
212,square_okhttp,HttpOverHttp2Test.recoverFromCancelReusesConnection,"@Test
public void recoverFromCancelReusesConnection() throws Exception {
    CountDownLatch responseDequeuedLatch = new CountDownLatch(1);
    CountDownLatch requestCanceledLatch = new CountDownLatch(1);
    QueueDispatcher dispatcher = new QueueDispatcher() {
        @Override
        public MockResponse dispatch(RecordedRequest request) throws InterruptedException {
            MockResponse response = super.dispatch(request);
            responseDequeuedLatch.countDown();
            requestCanceledLatch.await();
            return response;
        }
    };
    server.setDispatcher(dispatcher);
    dispatcher.enqueueResponse(new MockResponse().setBodyDelay(10, TimeUnit.SECONDS).setBody(""abc""));
    dispatcher.enqueueResponse(new MockResponse().setBody(""def""));
    client = client.newBuilder().dns(new DoubleInetAddressDns()).build();
    callAndCancel(0, responseDequeuedLatch, requestCanceledLatch);
    Call call = client.newCall(new Request.Builder().url(server.url(""/"")).build());
    Response response = call.execute();
    assertThat(response.body().string()).isEqualTo(""def"");
    assertThat(server.takeRequest().getSequenceNumber()).isEqualTo(1);
}",async wait,0
217,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireAllEvent,"@Test
public void testFireAllEvent() throws Exception {
    final NamingEventCoordinator coordinator = new NamingEventCoordinator();
    final CollectingListener objectListener = new CollectingListener(1);
    coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
    final CollectingListener subtreeListener = new CollectingListener(1);
    coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
    final CollectingListener oneLevelListener = new CollectingListener(1);
    coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);
    coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE, EventContext.ONELEVEL_SCOPE, EventContext.SUBTREE_SCOPE);
    objectListener.latch.await(1, TimeUnit.SECONDS);
    oneLevelListener.latch.await(1, TimeUnit.SECONDS);
    subtreeListener.latch.await(1, TimeUnit.SECONDS);
    assertEquals(1, objectListener.capturedEvents.size());
    assertEquals(1, subtreeListener.capturedEvents.size());
    assertEquals(1, oneLevelListener.capturedEvents.size());
}",test order dependency,4
220,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRebind,"@Test
public void testRebind() throws Exception {
    final Name name = new CompositeName(""test"");
    final Object value = new Object();
    namingStore.bind(name, value);
    Object newValue = new Object();
    namingContext.rebind(name, newValue);
    assertEquals(newValue, namingStore.lookup(name));
    newValue = new Object();
    testActionPermission(JndiPermission.ACTION_REBIND, namingContext, ""test"", newValue);
    assertEquals(newValue, namingStore.lookup(name));
}",test order dependency,4
223,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testList,"@Test
public void testList() throws Exception {
    bindList();
    NamingEnumeration<NameClassPair> results = namingContext.list(new CompositeName());
    checkListResults(results);
    results = (NamingEnumeration<NameClassPair>) testActionPermission(JndiPermission.ACTION_LIST, namingContext, null);
    checkListResults(results);
}",test order dependency,4
227,cdancy_jenkins-rest,JobsApiLiveTest.testGetJobListFromRoot,"@Test
@Test(dependsOnMethods = ""testCreateJob"")
public void testGetJobListFromRoot() {
    JobList output = api().jobList("""");
    assertNotNull(output);
    assertFalse(output.jobs().isEmpty());
    assertEquals(output.jobs().size(), 2);
}",test order dependency,4
231,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListBindings,"@Test
public void testListBindings() throws Exception {
    bindList();
    NamingEnumeration<Binding> results = namingContext.listBindings(new CompositeName());
    checkListResults(results);
    results = (NamingEnumeration<Binding>) testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, namingContext, null);
    checkListResults(results);
}",test order dependency,4
232,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListWithContinuation,"@Test
public void testListWithContinuation() throws Exception {
    bindListWithContinuations();
    NamingEnumeration<NameClassPair> results = namingContext.list(new CompositeName(""comp""));
    checkListWithContinuationsResults(results);
    results = (NamingEnumeration<NameClassPair>) testActionPermission(JndiPermission.ACTION_LIST, Arrays.asList(
    new JndiPermission(""test"", ""list"")), namingContext, ""comp"");
    checkListWithContinuationsResults(results);
}",test order dependency,4
246,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookupNameNotFound,"@Test
public void testLookupNameNotFound() throws Exception {
    try {
        namingContext.lookup(new CompositeName(""test""));
        fail(""Should have thrown and NameNotFoundException"");
    } catch (NameNotFoundException expected) {
    }
    try {
        testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
        fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
    } catch (NameNotFoundException expected) {
    }
}",test order dependency,4
247,apache_hadoop,TestSecurityUtil.testBuildDTServiceName,"@Test
public void testBuildDTServiceName() {
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
}",test order dependency,4
251,apache_hadoop,TestUnderReplicatedBlocks.testSetrepIncWithUnderReplicatedBlocks,"@Test
public void testSetrepIncWithUnderReplicatedBlocks() throws Exception {
    Configuration conf = new HdfsConfiguration();
    final short REPLICATION_FACTOR = 2;
    final String FILE_NAME = ""/testFile"";
    final Path FILE_PATH = new Path(FILE_NAME);
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(REPLICATION_FACTOR + 1).build();
    try {
        final FileSystem fs = cluster.getFileSystem();
        DFSTestUtil.createFile(fs, FILE_PATH, 1L, REPLICATION_FACTOR, 1L);
        DFSTestUtil.waitReplication(fs, FILE_PATH, REPLICATION_FACTOR);
        final BlockManager bm = cluster.getNamesystem().getBlockManager();
        ExtendedBlock b = DFSTestUtil.getFirstBlock(fs, FILE_PATH);
        DatanodeDescriptor dn = bm.blocksMap.nodeIterator(b.getLocalBlock()).next();
        bm.addToInvalidates(b.getLocalBlock(), dn);
        bm.blocksMap.removeNode(b.getLocalBlock(), dn);
        FsShell shell = new FsShell(conf);
        assertEquals(0, shell.run(new String[]{ ""-setrep"", ""-w"", Integer.toString(1 + REPLICATION_FACTOR), FILE_NAME }));
    } finally {
        cluster.shutdown();
    }
}",async wait,0
256,apache_hadoop,TestDelegationTokenForProxyUser.testWebHdfsDoAs,"@Test
public void testWebHdfsDoAs() throws Exception {
    LOG.info(""START: testWebHdfsDoAs()"");
    ((Log4JLogger) (LOG)).getLogger().setLevel(ALL);
    ((Log4JLogger) (LOG)).getLogger().setLevel(ALL);
    final UserGroupInformation ugi = UserGroupInformation.createRemoteUser(REAL_USER);
    LOG.info(""ugi.getShortUserName()="" + ugi.getShortUserName());
    final WebHdfsFileSystem webhdfs = WebHdfsTestUtil.getWebHdfsFileSystemAs(ugi, config);
    final Path root = new Path(""/"");
    cluster.getFileSystem().setPermission(root, new FsPermission(((short) (0777))));
    {
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, GETHOMEDIRECTORY, root, new DoAsParam(PROXY_USER));
        final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK);
        conn.disconnect();
        final Object responsePath = m.get(Path.class.getSimpleName());
        LOG.info(""responsePath="" + responsePath);
        Assert.assertEquals(""/user/"" + PROXY_USER, responsePath);
    }
    {
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, GETHOMEDIRECTORY, root, new DoAsParam(PROXY_USER) {
            @Override
            public String getName() {
                return ""DOas"";
            }
        });
        final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK);
        conn.disconnect();
        final Object responsePath = m.get(Path.class.getSimpleName());
        LOG.info(""responsePath="" + responsePath);
        Assert.assertEquals(""/user/"" + PROXY_USER, responsePath);
    }
    final Path f = new Path(""/testWebHdfsDoAs/a.txt"");
    {
        final PutOpParam.Op op = Op.CREATE;
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, op, f, new DoAsParam(PROXY_USER));
        HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        conn = WebHdfsTestUtil.twoStepWrite(webhdfs, op, conn);
        final FSDataOutputStream out = WebHdfsTestUtil.write(webhdfs, op, conn, 4096);
        out.write(""Hello, webhdfs user!"".getBytes());
        out.close();
        final FileStatus status = webhdfs.getFileStatus(f);
        LOG.info(""status.getOwner()="" + status.getOwner());
        Assert.assertEquals(PROXY_USER, status.getOwner());
    }
    {
        final PostOpParam.Op op = Op.APPEND;
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, op, f, new DoAsParam(PROXY_USER));
        HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        conn = WebHdfsTestUtil.twoStepWrite(webhdfs, op, conn);
        final FSDataOutputStream out = WebHdfsTestUtil.write(webhdfs, op, conn, 4096);
        out.write(""\nHello again!"".getBytes());
        out.close();
        final FileStatus status = webhdfs.getFileStatus(f);
        LOG.info(""status.getOwner()="" + status.getOwner());
        LOG.info(""status.getLen()  ="" + status.getLen());
        Assert.assertEquals(PROXY_USER, status.getOwner());
    }
}",test order dependency,4
258,apache_hadoop,TestMetricsSystemImpl.testInitFirstVerifyCallBacks,"@Test
public void testInitFirstVerifyCallBacks() throws Exception {
    DefaultMetricsSystem.shutdown();
    new ConfigBuilder().add(""*.period"", 8).add(""test.sink.test.class"", TestSink.class.getName()).add(""test.*.source.filter.exclude"", ""s0"").add(""test.source.s1.metric.filter.exclude"", ""X*"").add(""test.sink.sink1.metric.filter.exclude"", ""Y*"").add(""test.sink.sink2.metric.filter.exclude"", ""Y*"").save(TestMetricsConfig.getTestFilename(""hadoop-metrics2-test""));
    MetricsSystemImpl ms = new MetricsSystemImpl(""Test"");
    ms.start();
    ms.register(""s0"", ""s0 desc"", new TestSource(""s0rec""));
    TestSource s1 = ms.register(""s1"", ""s1 desc"", new TestSource(""s1rec""));
    s1.c1.incr();
    s1.xxx.incr();
    s1.g1.set(2);
    s1.yyy.incr(2);
    s1.s1.add(0);
    MetricsSink sink1 = mock(MetricsSink.class);
    MetricsSink sink2 = mock(MetricsSink.class);
    ms.registerSink(""sink1"", ""sink1 desc"", sink1);
    ms.registerSink(""sink2"", ""sink2 desc"", sink2);
    ms.publishMetricsNow();
    try {
        verify(sink1, timeout(200).times(2)).putMetrics(r1.capture());
        verify(sink2, timeout(200).times(2)).putMetrics(r2.capture());
    } finally {
        ms.stop();
        ms.shutdown();
    }
    List<MetricsRecord> mr1 = r1.getAllValues();
    List<MetricsRecord> mr2 = r2.getAllValues();
    checkMetricsRecords(mr1);
    assertEquals(""output"", mr1, mr2);
}",unordered collections,3
260,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRebindReferenceable,"@Test
public void testRebindReferenceable() throws Exception {
    final Name name = new CompositeName(""test"");
    final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr"");
    namingContext.bind(name, referenceable);
    TestObjectReferenceable newReferenceable = new TestObjectReferenceable(""newAddr"");
    namingContext.rebind(name, newReferenceable);
    Object result = namingContext.lookup(name);
    assertEquals(newReferenceable.addr, result);
    newReferenceable = new TestObjectReferenceable(""yetAnotherNewAddr"");
    testActionPermission(JndiPermission.ACTION_REBIND, namingContext, ""test"", newReferenceable);
    result = namingContext.lookup(name);
    assertEquals(newReferenceable.addr, result);
}",test order dependency,4
268,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRebind.2,"@Test
public void testRebind() throws Exception {
    final Name name = new CompositeName(""test"");
    final Object value = new Object();
    final Object newValue = new Object();
    WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
    try {
        store.bind(name, value);
        store.rebind(name, newValue);
    } finally {
        WritableServiceBasedNamingStore.popOwner();
    }
    assertEquals(newValue, store.lookup(name));
}",test order dependency,4
269,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testUnbind,"@Test
public void testUnbind() throws Exception {
    final Name name = new CompositeName(""test"");
    final Object value = new Object();
    namingStore.bind(name, value);
    namingContext.unbind(name);
    try {
        namingStore.lookup(name);
        fail(""Should have thrown name not found"");
    } catch (NameNotFoundException expect) {}
    testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""test"", value);
    testActionPermission(JndiPermission.ACTION_UNBIND, namingContext, ""test"");
    try {
        namingStore.lookup(name);
        fail(""Should have thrown name not found"");
    } catch (NameNotFoundException expect) {}
}",test order dependency,4
273,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireMultipleLevelEvent,"@Test
public void testFireMultiLevelEvent() throws Exception {
    final NamingEventCoordinator coordinator = new NamingEventCoordinator();
    final CollectingListener subtreeListener = new CollectingListener(1);
    coordinator.addListener(""foo"", EventContext.SUBTREE_SCOPE, subtreeListener);
    final CollectingListener subtreeListenerTwo = new CollectingListener(1);
    coordinator.addListener(""foo/bar"", EventContext.SUBTREE_SCOPE, subtreeListenerTwo);
    final CollectingListener subtreeListenerThree = new CollectingListener(1);
    coordinator.addListener(""foo/bar/baz"", EventContext.SUBTREE_SCOPE, subtreeListenerThree);
    coordinator.fireEvent(context, new CompositeName(""foo/bar/baz/boo""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE, EventContext.ONELEVEL_SCOPE, EventContext.SUBTREE_SCOPE);
    subtreeListener.latch.await(1, TimeUnit.SECONDS);
    subtreeListenerTwo.latch.await(1, TimeUnit.SECONDS);
    subtreeListenerThree.latch.await(1, TimeUnit.SECONDS);
    assertEquals(1, subtreeListener.capturedEvents.size());
    assertEquals(1, subtreeListenerTwo.capturedEvents.size());
    assertEquals(1, subtreeListenerThree.capturedEvents.size());
}",test order dependency,4
275,androidx_androidx,testOneTimeRequest_noInitialDelay,"@Test
public void testOneTimeRequest_noInitialDelay() {
    val request = OneTimeWorkRequestBuilder<TestWorker>().build();
    val task = mTaskConverter.convert(request.workSpec);
    assertEquals(task.serviceName, WorkManagerGcmService::class.java.name);
    assertEquals(task.isPersisted, false);
    assertEquals(task.isUpdateCurrent, true);
    assertEquals(task.requiredNetwork, Task.NETWORK_STATE_ANY);
    assertEquals(task.requiresCharging, false);
    assertEquals(task.windowStart, 0L);
    assertEquals(task.windowEnd, 0L + EXECUTION_WINDOW_SIZE_IN_SECONDS);
}",time,2
277,androidx_androidx,testGettersAfterConnected,"@Test
public void testGettersAfterConnected() throws InterruptedException {
    prepareLooper();
    final int state = MediaPlayerBase.PLAYER_STATE_PLAYING;
    final long position = 150000;
    final long bufferedPosition = 900000;
    final float speed = 0.5f;
    mPlayer.mLastPlayerState = state;
    mPlayer.mCurrentPosition = position;
    mPlayer.mBufferedPosition = bufferedPosition;
    mPlayer.mPlaybackSpeed = speed;
    long time = System.currentTimeMillis();
    MediaController2 controller = createController(mSession.getToken());
    assertEquals(state, controller.getPlayerState());
    assertEquals(bufferedPosition, controller.getBufferedPosition());
    assertEquals(speed, controller.getPlaybackSpeed());
    long elapsedTime = System.currentTimeMillis() - time;
    final long tolerance = 10;
    assertEquals(position + speed * elapsedTime, controller.getCurrentPosition(), tolerance);
}",time,2
278,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testFireSubTreeEvent,"@Test
public void testFireSubTreeEvent() throws Exception {
    final NamingEventCoordinator coordinator = new NamingEventCoordinator();
    final CollectingListener objectListener = new CollectingListener(0);
    coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
    final CollectingListener subtreeListener = new CollectingListener(1);
    coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
    final CollectingListener oneLevelListener = new CollectingListener(0);
    coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);
    coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.SUBTREE_SCOPE);
    subtreeListener.latch.await(1, TimeUnit.SECONDS);
    assertTrue(objectListener.capturedEvents.isEmpty());
    assertTrue(oneLevelListener.capturedEvents.isEmpty());
    assertEquals(1, subtreeListener.capturedEvents.size());
}",test order dependency,4
287,apache_commons-lang,RecursiveToStringStyleTest.testPerson,"@Test
public void testPerson() {
    final Person p = new Person();
    p.name = ""John Doe"";
    p.age = 33;
    p.smoker = false;
    p.job = new Job();
    p.job.title = ""Manager"";
    final String pBaseStr = (p.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(p));
    final String pJobStr = (p.job.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(p.job));
    assertEquals(((pBaseStr + ""[name=John Doe,age=33,smoker=false,job="") + pJobStr) + ""[title=Manager]]"", new ReflectionToStringBuilder(p, new RecursiveToStringStyle()).toString());
}",unordered collections,3
290,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListBindingsNameNotFound,"@Test
public void testListBindingsNameNotFound() throws Exception {
    try {
        namingContext.listBindings(new CompositeName(""test""));
        fail(""Should have thrown and NameNotFoundException"");
    } catch (NameNotFoundException expected) {
    }
    try {
        testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, namingContext, ""test"");
        fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
    } catch (NameNotFoundException expected) {
    }
}",test order dependency,4
291,trinodb_trino,testAuthenticationFromMultipleThreadsWithCachedToken,"@Test
public void testAuthenticationFromMultipleThreadsWithCachedToken()
{
    ExecutorService executor = newCachedThreadPool(daemonThreadsNamed(this.getClass().getName() + ""%n""));
    MockTokenPoller tokenPoller = new MockTokenPoller()
    .withResult(URI.create(""http://token.uri""), successful(new Token(""valid-token"")));
    MockRedirectHandler redirectHandler = new MockRedirectHandler()
    .sleepOnRedirect(Duration.ofMillis(10));
    ExternalAuthenticator authenticator = new ExternalAuthenticator(redirectHandler, tokenPoller, KnownToken.memoryCached(), Duration.ofSeconds(1));
    List<Future<Request>> requests = times(
    4, () -> authenticator.authenticate(null, getUnauthorizedResponse(""Bearer x_token_server=\""http://token.uri\"", x_redirect_server=\""http://redirect.uri\"""")))
    .map(executor::submit)
    .collect(toImmutableList());
    ConcurrentRequestAssertion assertion = new ConcurrentRequestAssertion(requests);
    assertion.requests()
    .extracting(Request::headers)
    .extracting(headers -> headers.get(AUTHORIZATION))
    .containsOnly(""Bearer valid-token"");
    assertion.assertThatNoExceptionsHasBeenThrown();
    assertThat(redirectHandler.getRedirectionCount()).isEqualTo(1);
}",concurrency,1
297,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testRegisterURLSchemeHandler,"@Test
public void testRegisterURLSchemeHandler() throws Exception {
    InitialContext ictx = new InitialContext(null);
    try {
        ictx.lookup(""foobar:something"");
        Assert.fail(""Precondition: the foobar: scheme should not yet be registered"");
    } catch (NamingException ne) {
    }
    ObjectFactory tof = new TestObjectFactory();
    InitialContext.addUrlContextFactory(""foobar"", tof);
    String something = (String) ictx.lookup(""foobar:something"");
    Assert.assertTrue(""The object should now be provided by our TestObjectFactory"", something.startsWith(""TestObject:""));
    try {
        InitialContext.removeUrlContextFactory(""foobar:"", new TestObjectFactory());
        Assert.fail(""Should throw an IllegalArgumentException since the associated factory object doesn't match the registration"");
    } catch (IllegalArgumentException iae) {
    }
    Assert.assertEquals(""The foobar: scheme should still be registered"", something, ictx.lookup(""foobar:something""));
    InitialContext.removeUrlContextFactory(""foobar"", tof);
    try {
        ictx.lookup(""foobar:something"");
        Assert.fail(""The foobar: scheme should not be registered any more"");
    } catch (NamingException ne) {
    }
}",test order dependency,4
301,apache_hadoop,TestFairScheduler.testContinuousScheduling,"@Test
public void testContinuousScheduling() throws Exception {
    FairScheduler fs = new FairScheduler();
    Configuration conf = createConfiguration();
    conf.setBoolean(CONTINUOUS_SCHEDULING_ENABLED, true);
    fs.reinitialize(conf, resourceManager.getRMContext());
    Assert.assertTrue(""Continuous scheduling should be enabled."", fs.isContinuousSchedulingEnabled());
    RMNode node1 = MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1, ""127.0.0.1"");
    NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
    fs.handle(nodeEvent1);
    Assert.assertEquals(fs.getClusterCapacity().getMemory(), 8 * 1024);
    Assert.assertEquals(fs.getClusterCapacity().getVirtualCores(), 8);
    ApplicationAttemptId appAttemptId = createAppAttemptId(this.APP_ID++, this.ATTEMPT_ID++);
    fs.addApplication(appAttemptId, ""queue11"", ""user11"");
    List<ResourceRequest> ask = new ArrayList<ResourceRequest>();
    ResourceRequest request = createResourceRequest(1024, 1, ANY, 1, 1, true);
    ask.add(request);
    fs.allocate(appAttemptId, ask, new ArrayList<ContainerId>(), null, null);
    Thread.sleep(fs.getConf().getContinuousSchedulingSleepMs() + 500);
    Resource consumption = fs.applications.get(appAttemptId).getCurrentConsumption();
    Assert.assertEquals(1024, consumption.getMemory());
    Assert.assertEquals(1, consumption.getVirtualCores());
}",async wait,0
308,apache_camel,FtpReconnectAttemptServerStoppedIT.testFromFileToFtp,"@Test
public void testFromFileToFtp() throws Exception {
    service.suspend();
    template.sendBodyAndHeader(""file:{{ftp.root.dir}}/reconnect"", ""Hello World"", FILE_NAME, ""hello.txt"");
    MockEndpoint mock = getMockEndpoint(""mock:result"");
    mock.expectedMessageCount(0);
    Thread.sleep(3000);
    assertMockEndpointsSatisfied();
    mock.reset();
    mock.expectedMessageCount(1);
    service.resume();
    Thread.sleep(3000);
    assertMockEndpointsSatisfied();
}",async wait,0
312,androidx_androidx,testPredictiveLayoutAdd2,"@Test
public void testPredictiveLayoutAdd2() throws Throwable {
    preparePredictiveLayout();
    mActivityTestRule.runOnUiThread(new Runnable() {
        @Override
        public void run() {
            mActivity.addItems(50, new int[]{300, 300, 300, 300});
        }
    });
    waitForItemAnimationStart();
    waitForItemAnimation(5000);
    assertEquals(54, mGridView.getSelectedPosition());
    assertEquals(RecyclerView.SCROLL_STATE_IDLE, mGridView.getScrollState());
}",async wait,0
313,androidx_androidx,onReceive,"@Test
public class Test {
    public void onReceive() {
        object broadcastReceiver = TestBroadcast();
        context.registerReceiver(
        broadcastReceiver,
        IntentFilter(BROADCAST_ACTION)
        );
        String value = ""value"" ;
        context.sendBroadcast(Intent(BROADCAST_ACTION).putExtra(EXTRA_STRING, value));
        shadowOf(getMainLooper()).idle() ;
        assertWithMessage(""Broadcast receiver did not execute"")
        .that(broadcastReceiver.broadcastExecuted.await(1, SECONDS))
        .isTrue();
        assertThat(broadcastReceiver.extraValue.get()).isEqualTo(value);
        assertThat(broadcastReceiver.job.get().isCancelled).isTrue();
    }
}",async wait,0
314,apache_hadoop,TestWritableName.testSetName,"@Test
public void testSetName() throws Exception {
    Configuration conf = new Configuration();
    WritableName.setName(SimpleWritable.class, testName);
    Class<?> test = WritableName.getClass(testName, conf);
    assertTrue(test.equals(SimpleWritable.class));
}",test order dependency,4
315,square_okhttp,DuplexTest.duplexWithRedirect,"@Test
public void duplexWithRedirect() throws Exception {
    enableProtocol(HTTP_2);
    MockDuplexResponseBody mockDuplexResponseBody = enqueueResponseWithBody(new MockResponse().clearHeaders().setResponseCode(HttpURLConnection.HTTP_MOVED_PERM).addHeader(""Location: /b""), new MockDuplexResponseBody().sendResponse(""/a has moved!\n"").requestIOException().exhaustResponse());
    server.enqueue(new MockResponse().setBody(""this is /b""));
    Call call = client.newCall(new Request.Builder().url(server.url(""/"")).post(new AsyncRequestBody()).build());
    try (final Response response = call.execute()) {
        BufferedSource responseBody = response.body().source();
        assertThat(responseBody.readUtf8Line()).isEqualTo(""this is /b"");
    }
    BufferedSink requestBody = ((AsyncRequestBody) (call.request().body())).takeSink();
    try {
        requestBody.writeUtf8(""request body\n"");
        requestBody.flush();
        fail();
    } catch (IOException expected) {
        assertThat(expected.getMessage()).isEqualTo(""stream was reset: CANCEL"");
    }
    mockDuplexResponseBody.awaitSuccess();
    assertThat(listener.recordedEventTypes()).containsExactly(""CallStart"", ""DnsStart"", ""DnsEnd"", ""ConnectStart"", ""SecureConnectStart"", ""SecureConnectEnd"", ""ConnectEnd"", ""ConnectionAcquired"", ""RequestHeadersStart"", ""RequestHeadersEnd"", ""RequestBodyStart"", ""ResponseHeadersStart"", ""ResponseHeadersEnd"", ""ResponseBodyStart"", ""ResponseBodyEnd"", ""RequestHeadersStart"", ""RequestHeadersEnd"", ""ResponseHeadersStart"", ""ResponseHeadersEnd"", ""ResponseBodyStart"", ""ResponseBodyEnd"", ""ConnectionReleased"", ""CallEnd"", ""RequestFailed"");
}",async wait,0
321,apache_hadoop,TestPeerCache.testAddAndRetrieve,"@Test
public void testAddAndRetrieve() throws Exception {
    PeerCache cache = PeerCache.getInstance(3, 100000);
    DatanodeID dnId = new DatanodeID(""192.168.0.1"",
    ""fakehostname"", ""fake_storage_id"",
    100, 101, 102);
    FakePeer peer = new FakePeer(dnId, false);
    cache.put(dnId, peer);
    assertTrue(!peer.isClosed());
    assertEquals(1, cache.size());
    assertEquals(peer, cache.get(dnId, false));
    assertEquals(0, cache.size());
    cache.close();
}",test order dependency,4
327,apache_hadoop,TestDFSIO.testRead,"@Test
public void testRead() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.readTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_READ, execTime);
}",test order dependency,4
330,androidx_androidx,invalidationInAnotherInstance_closed,"@Test
public void invalidationInAnotherInstance_closed() throws Exception {
    final SampleDatabase db1 = openDatabase(true);
    final SampleDatabase db2 = openDatabase(true);
    final SampleDatabase db3 = openDatabase(true);
    final CountDownLatch invalidated1 = prepareTableObserver(db1);
    final Pair<CountDownLatch, CountDownLatch> changed1 = prepareLiveDataObserver(db1);
    final CountDownLatch invalidated2 = prepareTableObserver(db2);
    final Pair<CountDownLatch, CountDownLatch> changed2 = prepareLiveDataObserver(db2);
    final CountDownLatch invalidated3 = prepareTableObserver(db3);
    final Pair<CountDownLatch, CountDownLatch> changed3 = prepareLiveDataObserver(db3);
    db2.getCustomerDao().insert(CUSTOMER_1);
    assertTrue(invalidated1.await(3, TimeUnit.SECONDS));
    assertTrue(changed1.first.await(3, TimeUnit.SECONDS));
    assertTrue(invalidated2.await(3, TimeUnit.SECONDS));
    assertTrue(changed2.first.await(3, TimeUnit.SECONDS));
    assertTrue(invalidated3.await(3, TimeUnit.SECONDS));
    assertTrue(changed3.first.await(3, TimeUnit.SECONDS));
    db3.close();
    db2.getCustomerDao().insert(CUSTOMER_2);
    assertTrue(changed1.second.await(3, TimeUnit.SECONDS));
    assertTrue(changed2.second.await(3, TimeUnit.SECONDS));
    assertFalse(changed3.second.await(300, TimeUnit.MILLISECONDS));
}",async wait,0
331,androidx_androidx,testSetCallbackWithNull,"@Test
public void testSetCallbackWithNull() throws Exception {
    mSession.setActive(true);
    mCallback.reset(1);
    mSession.setCallback(null, mHandler);
    assertEquals(""Callback shouldn't be called."", 0, mCallback.mOnPlayCalledCount);
}",async wait,0
337,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testOnlyExternalContextAllowsCache,"@Test
public void testOnlyExternalContextAllowsCache() throws Exception {
    KernelServices services = createKernelServicesBuilder(AdditionalInitialization.MANAGEMENT)
    .build();
    Assert.assertTrue(services.isSuccessfulBoot());
    List<ModelNode> list = parse(ModelTestUtils.readResource(this.getClass(), ""subsystem.xml""));
    for (ModelNode addOp : list) {
        PathAddress addr = PathAddress.pathAddress(addOp.require(ModelDescriptionConstants.OP_ADDR));
        if (addr.size() == 2 && addr.getLastElement().getKey().equals(NamingSubsystemModel.BINDING) && BindingType.forName(addOp.get(NamingBindingResourceDefinition.BINDING_TYPE.getName()).asString()) != BindingType.EXTERNAL_CONTEXT) {
            addOp.get(NamingBindingResourceDefinition.CACHE.getName()).set(true);
            services.executeForFailure(addOp);
            addOp.remove(NamingBindingResourceDefinition.CACHE.getName());
            ModelTestUtils.checkOutcome(services.executeOperation(addOp));
            ModelTestUtils.checkFailed(services.executeOperation(Util.getWriteAttributeOperation(addr, NamingBindingResourceDefinition.CACHE.getName(), new ModelNode(true))));
        } else {
            ModelTestUtils.checkOutcome(services.executeOperation(addOp));
        }
    }",test order dependency,4
338,apache_hadoop,TestHftpFileSystem.testHftpCustomUriPortWithDefaultPorts,"@Test
public void testHftpCustomUriPortWithDefaultPorts() throws IOException {
    resetFileSystem();
    Configuration conf = new Configuration();
    URI uri = URI.create() ;
    HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf)));
    assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, fs.getDefaultPort());
    assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getDefaultSecurePort());
    assertEquals(uri, fs.getUri());
    assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getCanonicalServiceName());
}",test order dependency,4
351,androidx_androidx,testStopTimer_withCleanUp,"@Test
public void testStopTimer_withCleanUp() throws InterruptedException {
    TestTimeLimitExceededListener listenerSpy = spy(mListener);
    mWorkTimer.startTimer(WORKSPEC_ID_1, 100, listenerSpy);
    mWorkTimer.stopTimer(WORKSPEC_ID_1);
    Thread.sleep(100);
    verify(listenerSpy, times(0)).onTimeLimitExceeded(WORKSPEC_ID_1);
    assertThat(mWorkTimer.getTimerMap().size(), is(0));
    assertThat(mWorkTimer.getListeners().size(), is(0));
}",async wait,0
352,ctco_cukes,b483e1a8f261b80a66291a42fc455256b0b5059c.shouldReturnBodyWhenEnabledAndNoMax,"@Test
public void shouldReturnBodyWhenEnabledAndNoMax() {
    String body = ""{\n"" +
    ""  \""error\"": \""not found\""\n"" +
    ""}"";
    HttpResponseFacade mock = mock(HttpResponseFacade.class);
    when(mock.response()).thenReturn(generateResponse(
    ""application/json"",
    404,
    body.getBytes()));
    ((HttpAssertionFacadeImpl) facade).facade = mock;
    world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true"");
    validateException(
    200,
    ""1 expectation failed.\n"" +
    ""Expected status code \""200\"" but was \""404\"" with body:\n"" +
    ""\""\""\""\n"" +
    body +
    ""\n\""\""\"".\n"");
}",test order dependency,4
357,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testLookup,"@Test
public void testLookup() throws Exception {
    final Name name = new CompositeName(""test"");
    final Object object = new Object();
    namingStore.bind(name, object);
    Object result = namingContext.lookup(name);
    assertEquals(object, result);
    result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
    assertEquals(object, result);
}",test order dependency,4
360,apache_hadoop,TestPeerCache.testExpiry,"@Test
public void testExpiry() throws Exception {
    final int CAPACITY = 3;
    final int EXPIRY_PERIOD = 10;
    PeerCache cache = PeerCache.getInstance(CAPACITY, EXPIRY_PERIOD);
    DatanodeID dnIds[] = new DatanodeID[CAPACITY];
    FakePeer peers[] = new FakePeer[CAPACITY];
    for (int i = 0; i < CAPACITY; ++i) {
        dnIds[i] = new DatanodeID(""192.168.0.1"",
        ""fakehostname_"" + i, ""fake_storage_id"",
        100, 101, 102);
        peers[i] = new FakePeer(dnIds[i], false);
    }
    for (int i = 0; i < CAPACITY; ++i) {
        cache.put(dnIds[i], peers[i]);
    }
    Thread.sleep(EXPIRY_PERIOD * 50);
    assertEquals(0, cache.size());
    for (int i = 0; i < CAPACITY; ++i) {
        assertTrue(peers[i].isClosed());
    }
    Thread.sleep(EXPIRY_PERIOD * 50);
    cache.close();
}",test order dependency,4
361,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListBindings.2.,"@Test
public void testListBindings() throws Exception {
    final Object value = new Object();
    bindObject(ServiceName.JBOSS.append(""TestBean""), value);
    bindObject(ServiceName.JBOSS.append(""foo"", ""TestBean""), value);
    bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""TestBean""), value);
    bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean""), value);
    store.add(ServiceName.JBOSS.append(""foos"", ""bar""));
    store.add(ServiceName.JBOSS.append(""fo"", ""bar""));
    store.add(ServiceName.JBOSS.append(""foo"", ""ba"", ""baz""));
    store.add(ServiceName.JBOSS.append(""foo"", ""bart"", ""baz""));
    store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""ba""));
    store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""bazt""));
    store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""art""));
    store.add(ServiceName.JBOSS.append(""other"", ""one""));
    List<Binding> list = store.listBindings(new CompositeName(""""));
    assertEquals(5, list.size());
    assertContains(list, ""TestBean"", Object.class);
    assertContains(list, ""foo"", NamingContext.class);
    assertContains(list, ""fo"", NamingContext.class);
    assertContains(list, ""foos"", NamingContext.class);
    assertContains(list, ""other"", NamingContext.class);
    list = store.listBindings(new CompositeName(""foo""));
    assertEquals(4, list.size());
    assertContains(list, ""TestBean"", Object.class);
    assertContains(list, ""ba"", NamingContext.class);
    assertContains(list, ""bart"", NamingContext.class);
    assertContains(list, ""bar"", NamingContext.class);
    for (Binding binding : list) {
        if (binding.getName().equals(""bar"")) {
            final Object bean = Context.class.cast(binding.getObject()).lookup(""TestBean"");
            assertNotNull(bean);
            assertEquals(value, bean);
        }
    }
}",test order dependency,4
365,wildfly_wildfly,b19048b72669fc0e96665b1b125dc1fda21f5993.testListBindingsWithContinuation,"@Test
public void testListBindingsWithContinuation() throws Exception {
    bindListWithContinuations();
    NamingEnumeration<Binding> results = namingContext.listBindings(new CompositeName(""comp""));
    checkListWithContinuationsResults(results);
    results = (NamingEnumeration<Binding>) testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, Arrays.asList(
    new JndiPermission(""test"", ""listBindings"")), namingContext, ""comp"");
    checkListWithContinuationsResults(results);
}",test order dependency,4
367,apache_hadoop,TestSecurityUtil.testBuildTokenServiceSockAddr,"@Test
public void testBuildTokenServiceSockAddr() {
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""LocalHost"", 123)).toString());
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""127.0.0.1"", 123)).toString());
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(NetUtils.createSocketAddr(""127.0.0.1"", 123)).toString());
}",test order dependency,4
368,apache_hadoop,TestDFSIO.testWrite,"@Test
public void testWrite() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.writeTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_WRITE, execTime);
}",test order dependency,4
281,apache_hadoop,TestOffsetRange.testConstructor1,"  @Test(expected = IllegalArgumentException.class)
  public void testConstructor1() throws IOException {
    new OffsetRange(0, 0);
  }
",non-flaky,5
282,apache_hadoop,TestOffsetRange.testConstructor2,"  @Test(expected = IllegalArgumentException.class)
  public void testConstructor2() throws IOException {
    new OffsetRange(-1, 0);
  }
",non-flaky,5
283,apache_hadoop,TestOffsetRange.testConstructor3,"  @Test(expected = IllegalArgumentException.class)
  public void testConstructor3() throws IOException {
    new OffsetRange(-3, -1);
  }
",non-flaky,5
284,apache_hadoop,TestOffsetRange.testConstructor4,"  @Test(expected = IllegalArgumentException.class)
  public void testConstructor4() throws IOException {
    new OffsetRange(-3, 100);
  }
",non-flaky,5
285,apache_hadoop,TestOffsetRange.testCompare,"  @Test
  public void testCompare() throws IOException {
    OffsetRange r1 = new OffsetRange(0, 1);
    OffsetRange r2 = new OffsetRange(1, 3);
    OffsetRange r3 = new OffsetRange(1, 3);
    OffsetRange r4 = new OffsetRange(3, 4);

    assertEquals(0, OffsetRange.ReverseComparatorOnMin.compare(r2, r3));
    assertEquals(0, OffsetRange.ReverseComparatorOnMin.compare(r2, r2));
    assertTrue(OffsetRange.ReverseComparatorOnMin.compare(r2, r1) < 0);
    assertTrue(OffsetRange.ReverseComparatorOnMin.compare(r2, r4) > 0);
  }
",non-flaky,5
286,apache_hadoop,TestReaddir.testReaddirBasic,"  @Test
  public void testReaddirBasic() throws IOException {
    // Get inodeId of /tmp
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);

    // Create related part of the XDR request
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeLongAsHyper(0); // cookie
    xdr_req.writeLongAsHyper(0); // verifier
    xdr_req.writeInt(100); // count

    READDIR3Response response = nfsd.readdir(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    List<Entry3> dirents = response.getDirList().getEntries();
    assertTrue(dirents.size() == 5); // inculding dot, dotdot

    // Test start listing from f2
    status = nn.getRpcServer().getFileInfo(testdir + ""/f2"");
    long f2Id = status.getFileId();

    // Create related part of the XDR request
    xdr_req = new XDR();
    handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeLongAsHyper(f2Id); // cookie
    xdr_req.writeLongAsHyper(0); // verifier
    xdr_req.writeInt(100); // count

    response = nfsd.readdir(xdr_req.asReadOnlyWrap(), securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    dirents = response.getDirList().getEntries();
    assertTrue(dirents.size() == 1);
    Entry3 entry = dirents.get(0);
    assertTrue(entry.getName().equals(""f3""));

    // When the cookie is deleted, list starts over no including dot, dotdot
    hdfs.delete(new Path(testdir + ""/f2""), false);

    response = nfsd.readdir(xdr_req.asReadOnlyWrap(), securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    dirents = response.getDirList().getEntries();
    assertTrue(dirents.size() == 2); // No dot, dotdot
  }
",non-flaky,5
287,apache_hadoop,TestReaddir.testReaddirPlus,"  @Test
  public void testReaddirPlus() throws IOException {
    // Get inodeId of /tmp
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    
    // Create related part of the XDR request
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeLongAsHyper(0); // cookie
    xdr_req.writeLongAsHyper(0); // verifier
    xdr_req.writeInt(100); // dirCount
    xdr_req.writeInt(1000); // maxCount

    READDIRPLUS3Response responsePlus = nfsd.readdirplus(xdr_req
        .asReadOnlyWrap(), securityHandler, new InetSocketAddress(""localhost"",
        1234));
    List<EntryPlus3> direntPlus = responsePlus.getDirListPlus().getEntries();
    assertTrue(direntPlus.size() == 5); // including dot, dotdot

    // Test start listing from f2
    status = nn.getRpcServer().getFileInfo(testdir + ""/f2"");
    long f2Id = status.getFileId();

    // Create related part of the XDR request
    xdr_req = new XDR();
    handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeLongAsHyper(f2Id); // cookie
    xdr_req.writeLongAsHyper(0); // verifier
    xdr_req.writeInt(100); // dirCount
    xdr_req.writeInt(1000); // maxCount

    responsePlus = nfsd.readdirplus(xdr_req.asReadOnlyWrap(), securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    direntPlus = responsePlus.getDirListPlus().getEntries();
    assertTrue(direntPlus.size() == 1);
    EntryPlus3 entryPlus = direntPlus.get(0);
    assertTrue(entryPlus.getName().equals(""f3""));

    // When the cookie is deleted, list starts over no including dot, dotdot
    hdfs.delete(new Path(testdir + ""/f2""), false);

    responsePlus = nfsd.readdirplus(xdr_req.asReadOnlyWrap(), securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    direntPlus = responsePlus.getDirListPlus().getEntries();
    assertTrue(direntPlus.size() == 2); // No dot, dotdot
  }
",non-flaky,5
288,apache_hadoop,TestWrites.testAlterWriteRequest,"  @Test
  public void testAlterWriteRequest() throws IOException {
    int len = 20;
    byte[] data = new byte[len];
    ByteBuffer buffer = ByteBuffer.wrap(data);

    for (int i = 0; i < len; i++) {
      buffer.put((byte) i);
    }
    buffer.flip();
    int originalCount = buffer.array().length;
    WRITE3Request request = new WRITE3Request(new FileHandle(), 0, data.length,
        WriteStableHow.UNSTABLE, buffer);

    WriteCtx writeCtx1 = new WriteCtx(request.getHandle(), request.getOffset(),
        request.getCount(), WriteCtx.INVALID_ORIGINAL_COUNT,
        request.getStableHow(), request.getData(), null, 1, false,
        WriteCtx.DataState.NO_DUMP);

    Assert.assertTrue(writeCtx1.getData().array().length == originalCount);

    // Now change the write request
    OpenFileCtx.alterWriteRequest(request, 12);

    WriteCtx writeCtx2 = new WriteCtx(request.getHandle(), request.getOffset(),
        request.getCount(), originalCount, request.getStableHow(),
        request.getData(), null, 2, false, WriteCtx.DataState.NO_DUMP);
    ByteBuffer appendedData = writeCtx2.getData();

    int position = appendedData.position();
    int limit = appendedData.limit();
    Assert.assertTrue(position == 12);
    Assert.assertTrue(limit - position == 8);
    Assert.assertTrue(appendedData.get(position) == (byte) 12);
    Assert.assertTrue(appendedData.get(position + 1) == (byte) 13);
    Assert.assertTrue(appendedData.get(position + 2) == (byte) 14);
    Assert.assertTrue(appendedData.get(position + 7) == (byte) 19);

    // Test current file write offset is at boundaries
    buffer.position(0);
    request = new WRITE3Request(new FileHandle(), 0, data.length,
        WriteStableHow.UNSTABLE, buffer);
    OpenFileCtx.alterWriteRequest(request, 1);
    WriteCtx writeCtx3 = new WriteCtx(request.getHandle(), request.getOffset(),
        request.getCount(), originalCount, request.getStableHow(),
        request.getData(), null, 2, false, WriteCtx.DataState.NO_DUMP);
    appendedData = writeCtx3.getData();
    position = appendedData.position();
    limit = appendedData.limit();
    Assert.assertTrue(position == 1);
    Assert.assertTrue(limit - position == 19);
    Assert.assertTrue(appendedData.get(position) == (byte) 1);
    Assert.assertTrue(appendedData.get(position + 18) == (byte) 19);

    // Reset buffer position before test another boundary
    buffer.position(0);
    request = new WRITE3Request(new FileHandle(), 0, data.length,
        WriteStableHow.UNSTABLE, buffer);
    OpenFileCtx.alterWriteRequest(request, 19);
    WriteCtx writeCtx4 = new WriteCtx(request.getHandle(), request.getOffset(),
        request.getCount(), originalCount, request.getStableHow(),
        request.getData(), null, 2, false, WriteCtx.DataState.NO_DUMP);
    appendedData = writeCtx4.getData();
    position = appendedData.position();
    limit = appendedData.limit();
    Assert.assertTrue(position == 19);
    Assert.assertTrue(limit - position == 1);
    Assert.assertTrue(appendedData.get(position) == (byte) 19);
  }
",non-flaky,5
289,apache_hadoop,TestWrites.testCheckCommit,"  @Test
  public void testCheckCommit() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);

    NfsConfiguration conf = new NfsConfiguration();
    conf.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, false);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(conf), false, conf);

    COMMIT_STATUS ret;

    // Test inactive open file context
    ctx.setActiveStatusForTest(false);
    Channel ch = Mockito.mock(Channel.class);
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_INACTIVE_CTX);

    ctx.getPendingWritesForTest().put(new OffsetRange(5, 10),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_INACTIVE_WITH_PENDING_WRITE);

    // Test request with non zero commit offset
    ctx.setActiveStatusForTest(true);
    Mockito.when(fos.getPos()).thenReturn((long) 10);
    ctx.setNextOffsetForTest(10);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
    // Do_SYNC state will be updated to FINISHED after data sync
    ret = ctx.checkCommit(dfsClient, 5, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);
    
    status = ctx.checkCommitInternal(10, ch, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
    ret = ctx.checkCommit(dfsClient, 10, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);

    ConcurrentNavigableMap<Long, CommitCtx> commits = ctx
        .getPendingCommitsForTest();
    Assert.assertTrue(commits.size() == 0);
    ret = ctx.checkCommit(dfsClient, 11, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_WAIT);
    Assert.assertTrue(commits.size() == 1);
    long key = commits.firstKey();
    Assert.assertTrue(key == 11);

    // Test request with zero commit offset
    commits.remove(new Long(11));
    // There is one pending write [5,10]
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_WAIT);
    Assert.assertTrue(commits.size() == 1);
    key = commits.firstKey();
    Assert.assertTrue(key == 9);

    // Empty pending writes
    ctx.getPendingWritesForTest().remove(new OffsetRange(5, 10));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);
  }
",non-flaky,5
290,apache_hadoop,TestWrites.testCheckCommitLargeFileUpload,"  @Test
  public void testCheckCommitLargeFileUpload() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);

    NfsConfiguration conf = new NfsConfiguration();
    conf.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, true);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(conf), false, conf);

    COMMIT_STATUS ret;

    // Test inactive open file context
    ctx.setActiveStatusForTest(false);
    Channel ch = Mockito.mock(Channel.class);
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_INACTIVE_CTX);

    ctx.getPendingWritesForTest().put(new OffsetRange(10, 15),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_INACTIVE_WITH_PENDING_WRITE);

    // Test request with non zero commit offset
    ctx.setActiveStatusForTest(true);
    Mockito.when(fos.getPos()).thenReturn((long) 8);
    ctx.setNextOffsetForTest(10);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
    // Do_SYNC state will be updated to FINISHED after data sync
    ret = ctx.checkCommit(dfsClient, 5, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);
    
    // Test commit sequential writes
    status = ctx.checkCommitInternal(10, ch, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    ret = ctx.checkCommit(dfsClient, 10, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);

    // Test commit non-sequential writes
    ConcurrentNavigableMap<Long, CommitCtx> commits = ctx
        .getPendingCommitsForTest();
    Assert.assertTrue(commits.size() == 1);
    ret = ctx.checkCommit(dfsClient, 16, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_SUCCESS);
    Assert.assertTrue(commits.size() == 1);
    
    // Test request with zero commit offset
    commits.remove(new Long(10));
    // There is one pending write [10,15]
    ret = ctx.checkCommitInternal(0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    
    ret = ctx.checkCommitInternal(9, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    Assert.assertTrue(commits.size() == 2);

    // Empty pending writes. nextOffset=10, flushed pos=8
    ctx.getPendingWritesForTest().remove(new OffsetRange(10, 15));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    
    // Empty pending writes
    ctx.setNextOffsetForTest((long) 8); // flushed pos = 8
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);
    
  }
",non-flaky,5
291,apache_hadoop,TestWrites.testCheckCommitAixCompatMode,"  @Test
  public void testCheckCommitAixCompatMode() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);

    NfsConfiguration conf = new NfsConfiguration();
    conf.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, false);
    // Enable AIX compatibility mode.
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(new NfsConfiguration()), true, conf);
    
    // Test fall-through to pendingWrites check in the event that commitOffset
    // is greater than the number of bytes we've so far flushed.
    Mockito.when(fos.getPos()).thenReturn((long) 2);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_FINISHED);
    
    // Test the case when we actually have received more bytes than we're trying
    // to commit.
    ctx.getPendingWritesForTest().put(new OffsetRange(0, 10),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    Mockito.when(fos.getPos()).thenReturn((long) 10);
    ctx.setNextOffsetForTest((long)10);
    status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
  }
",non-flaky,5
292,apache_hadoop,TestWrites.testCheckCommitFromRead,"  @Test
  public void testCheckCommitFromRead() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);
    NfsConfiguration config = new NfsConfiguration();

    config.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, false);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(config), false, config);

    FileHandle h = new FileHandle(1); // fake handle for ""/dumpFilePath""
    COMMIT_STATUS ret;
    WriteManager wm = new WriteManager(new ShellBasedIdMapping(config), config, false);
    assertTrue(wm.addOpenFileStream(h, ctx));
    
    // Test inactive open file context
    ctx.setActiveStatusForTest(false);
    Channel ch = Mockito.mock(Channel.class);
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals( COMMIT_STATUS.COMMIT_INACTIVE_CTX, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 0));
    
    ctx.getPendingWritesForTest().put(new OffsetRange(10, 15),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_INACTIVE_WITH_PENDING_WRITE, ret);
    assertEquals(Nfs3Status.NFS3ERR_IO, wm.commitBeforeRead(dfsClient, h, 0));
    
    // Test request with non zero commit offset
    ctx.setActiveStatusForTest(true);
    Mockito.when(fos.getPos()).thenReturn((long) 10);
    ctx.setNextOffsetForTest((long)10);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, ch, 1, attr, false);
    assertEquals(COMMIT_STATUS.COMMIT_DO_SYNC, status);
    // Do_SYNC state will be updated to FINISHED after data sync
    ret = ctx.checkCommit(dfsClient, 5, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_FINISHED, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 5));
 
    status = ctx.checkCommitInternal(10, ch, 1, attr, true);
    assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
    ret = ctx.checkCommit(dfsClient, 10, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_FINISHED, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 10));

    ConcurrentNavigableMap<Long, CommitCtx> commits = ctx
        .getPendingCommitsForTest();
    assertTrue(commits.size() == 0);
    ret = ctx.checkCommit(dfsClient, 11, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_WAIT, ret);
    assertEquals(0, commits.size()); // commit triggered by read doesn't wait
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 11));

    // Test request with zero commit offset
    // There is one pending write [5,10]
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_WAIT, ret);
    assertEquals(0, commits.size());
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 0));

    // Empty pending writes
    ctx.getPendingWritesForTest().remove(new OffsetRange(10, 15));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_FINISHED, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 0));
  }
",non-flaky,5
293,apache_hadoop,TestWrites.testCheckCommitFromReadLargeFileUpload,"  @Test
  public void testCheckCommitFromReadLargeFileUpload() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);
    NfsConfiguration config = new NfsConfiguration();

    config.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, true);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(config), false, config);

    FileHandle h = new FileHandle(1); // fake handle for ""/dumpFilePath""
    COMMIT_STATUS ret;
    WriteManager wm = new WriteManager(new ShellBasedIdMapping(config), config, false);
    assertTrue(wm.addOpenFileStream(h, ctx));
    
    // Test inactive open file context
    ctx.setActiveStatusForTest(false);
    Channel ch = Mockito.mock(Channel.class);
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals( COMMIT_STATUS.COMMIT_INACTIVE_CTX, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 0));
    
    ctx.getPendingWritesForTest().put(new OffsetRange(10, 15),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_INACTIVE_WITH_PENDING_WRITE, ret);
    assertEquals(Nfs3Status.NFS3ERR_IO, wm.commitBeforeRead(dfsClient, h, 0));
    
    // Test request with non zero commit offset
    ctx.setActiveStatusForTest(true);
    Mockito.when(fos.getPos()).thenReturn((long) 6);
    ctx.setNextOffsetForTest((long)10);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, ch, 1, attr, false);
    assertEquals(COMMIT_STATUS.COMMIT_DO_SYNC, status);
    // Do_SYNC state will be updated to FINISHED after data sync
    ret = ctx.checkCommit(dfsClient, 5, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_FINISHED, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 5));
 
    // Test request with sequential writes
    status = ctx.checkCommitInternal(9, ch, 1, attr, true);
    assertTrue(status == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    ret = ctx.checkCommit(dfsClient, 9, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_SPECIAL_WAIT, ret);
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 9));

    // Test request with non-sequential writes
    ConcurrentNavigableMap<Long, CommitCtx> commits = ctx
        .getPendingCommitsForTest();
    assertTrue(commits.size() == 0);
    ret = ctx.checkCommit(dfsClient, 16, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_SPECIAL_SUCCESS, ret);
    assertEquals(0, commits.size()); // commit triggered by read doesn't wait
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 16));

    // Test request with zero commit offset
    // There is one pending write [10,15]
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_SPECIAL_WAIT, ret);
    assertEquals(0, commits.size());
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 0));

    // Empty pending writes
    ctx.getPendingWritesForTest().remove(new OffsetRange(10, 15));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_SPECIAL_WAIT, ret);
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 0));
  }
",non-flaky,5
294,apache_hadoop,TestWrites.testWriteStableHow,"  @Test
  public void testWriteStableHow() throws IOException, InterruptedException {
    NfsConfiguration config = new NfsConfiguration();
    DFSClient client = null;
    MiniDFSCluster cluster = null;
    RpcProgramNfs3 nfsd;
    SecurityHandler securityHandler = Mockito.mock(SecurityHandler.class);
    Mockito.when(securityHandler.getUser()).thenReturn(
        System.getProperty(""user.name""));
    String currentUser = System.getProperty(""user.name"");
    config.set(
            DefaultImpersonationProvider.getTestProvider().
                getProxySuperuserGroupConfKey(currentUser),
            ""*"");
    config.set(
            DefaultImpersonationProvider.getTestProvider().
                getProxySuperuserIpConfKey(currentUser),
            ""*"");
    ProxyUsers.refreshSuperUserGroupsConfiguration(config);

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();
      client = new DFSClient(DFSUtilClient.getNNAddress(config), config);
      int namenodeId = Nfs3Utils.getNamenodeId(config);

      // Use emphral port in case tests are running in parallel
      config.setInt(""nfs3.mountd.port"", 0);
      config.setInt(""nfs3.server.port"", 0);
      
      // Start nfs
      Nfs3 nfs3 = new Nfs3(config);
      nfs3.startServiceInternal(false);
      nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();

      HdfsFileStatus status = client.getFileInfo(""/"");
      FileHandle rootHandle = new FileHandle(status.getFileId(), namenodeId);
      // Create file1
      CREATE3Request createReq = new CREATE3Request(rootHandle, ""file1"",
          Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
      XDR createXdr = new XDR();
      createReq.serialize(createXdr);
      CREATE3Response createRsp = nfsd.create(createXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));
      FileHandle handle = createRsp.getObjHandle();

      // Test DATA_SYNC
      byte[] buffer = new byte[10];
      for (int i = 0; i < 10; i++) {
        buffer[i] = (byte) i;
      }
      WRITE3Request writeReq = new WRITE3Request(handle, 0, 10,
          WriteStableHow.DATA_SYNC, ByteBuffer.wrap(buffer));
      XDR writeXdr = new XDR();
      writeReq.serialize(writeXdr);
      nfsd.write(writeXdr.asReadOnlyWrap(), null, 1, securityHandler,
          new InetSocketAddress(""localhost"", 1234));

      waitWrite(nfsd, handle, 60000);

      // Readback
      READ3Request readReq = new READ3Request(handle, 0, 10);
      XDR readXdr = new XDR();
      readReq.serialize(readXdr);
      READ3Response readRsp = nfsd.read(readXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));

      assertTrue(Arrays.equals(buffer, readRsp.getData().array()));

      // Test FILE_SYNC

      // Create file2
      CREATE3Request createReq2 = new CREATE3Request(rootHandle, ""file2"",
          Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
      XDR createXdr2 = new XDR();
      createReq2.serialize(createXdr2);
      CREATE3Response createRsp2 = nfsd.create(createXdr2.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));
      FileHandle handle2 = createRsp2.getObjHandle();

      WRITE3Request writeReq2 = new WRITE3Request(handle2, 0, 10,
          WriteStableHow.FILE_SYNC, ByteBuffer.wrap(buffer));
      XDR writeXdr2 = new XDR();
      writeReq2.serialize(writeXdr2);
      nfsd.write(writeXdr2.asReadOnlyWrap(), null, 1, securityHandler,
          new InetSocketAddress(""localhost"", 1234));

      waitWrite(nfsd, handle2, 60000);

      // Readback
      READ3Request readReq2 = new READ3Request(handle2, 0, 10);
      XDR readXdr2 = new XDR();
      readReq2.serialize(readXdr2);
      READ3Response readRsp2 = nfsd.read(readXdr2.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));

      assertTrue(Arrays.equals(buffer, readRsp2.getData().array()));
      // FILE_SYNC should sync the file size
      status = client.getFileInfo(""/file2"");
      assertTrue(status.getLen() == 10);

    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
295,apache_hadoop,TestWrites.testOOOWrites,"  @Test
  public void testOOOWrites() throws IOException, InterruptedException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    RpcProgramNfs3 nfsd;
    final int bufSize = 32;
    final int numOOO = 3;
    SecurityHandler securityHandler = Mockito.mock(SecurityHandler.class);
    Mockito.when(securityHandler.getUser()).thenReturn(
        System.getProperty(""user.name""));
    String currentUser = System.getProperty(""user.name"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserGroupConfKey(currentUser),
        ""*"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserIpConfKey(currentUser),
        ""*"");
    ProxyUsers.refreshSuperUserGroupsConfiguration(config);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();

      Nfs3 nfs3 = new Nfs3(config);
      nfs3.startServiceInternal(false);
      nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();

      DFSClient dfsClient = new DFSClient(DFSUtilClient.getNNAddress(config),
          config);
      int namenodeId = Nfs3Utils.getNamenodeId(config);
      HdfsFileStatus status = dfsClient.getFileInfo(""/"");
      FileHandle rootHandle = new FileHandle(status.getFileId(), namenodeId);

      CREATE3Request createReq = new CREATE3Request(rootHandle,
          ""out-of-order-write"" + System.currentTimeMillis(),
          Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
      XDR createXdr = new XDR();
      createReq.serialize(createXdr);
      CREATE3Response createRsp = nfsd.create(createXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));
      FileHandle handle = createRsp.getObjHandle();

      byte[][] oooBuf = new byte[numOOO][bufSize];
      for (int i = 0; i < numOOO; i++) {
        Arrays.fill(oooBuf[i], (byte) i);
      }

      for (int i = 0; i < numOOO; i++) {
        final long offset = (numOOO - 1 - i) * bufSize;
        WRITE3Request writeReq = new WRITE3Request(handle, offset, bufSize,
            WriteStableHow.UNSTABLE, ByteBuffer.wrap(oooBuf[i]));
        XDR writeXdr = new XDR();
        writeReq.serialize(writeXdr);
        nfsd.write(writeXdr.asReadOnlyWrap(), null, 1, securityHandler,
            new InetSocketAddress(""localhost"", 1234));
      }

      waitWrite(nfsd, handle, 60000);
      READ3Request readReq = new READ3Request(handle, bufSize, bufSize);
      XDR readXdr = new XDR();
      readReq.serialize(readXdr);
      READ3Response readRsp = nfsd.read(readXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", config.getInt(
              NfsConfigKeys.DFS_NFS_SERVER_PORT_KEY,
              NfsConfigKeys.DFS_NFS_SERVER_PORT_DEFAULT)));
      assertTrue(Arrays.equals(oooBuf[1], readRsp.getData().array()));
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
296,apache_hadoop,TestWrites.testOverlappingWrites,"  @Test
  public void testOverlappingWrites() throws IOException, InterruptedException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    RpcProgramNfs3 nfsd;
    final int bufSize = 32;
    SecurityHandler securityHandler = Mockito.mock(SecurityHandler.class);
    Mockito.when(securityHandler.getUser()).thenReturn(
        System.getProperty(""user.name""));
    String currentUser = System.getProperty(""user.name"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserGroupConfKey(currentUser),
        ""*"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserIpConfKey(currentUser),
        ""*"");
    ProxyUsers.refreshSuperUserGroupsConfiguration(config);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();

      Nfs3 nfs3 = new Nfs3(config);
      nfs3.startServiceInternal(false);
      nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();

      DFSClient dfsClient = new DFSClient(DFSUtilClient.getNNAddress(config),
          config);
      int namenodeId = Nfs3Utils.getNamenodeId(config);
      HdfsFileStatus status = dfsClient.getFileInfo(""/"");
      FileHandle rootHandle = new FileHandle(status.getFileId(), namenodeId);

      CREATE3Request createReq = new CREATE3Request(rootHandle,
          ""overlapping-writes"" + System.currentTimeMillis(),
          Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
      XDR createXdr = new XDR();
      createReq.serialize(createXdr);
      CREATE3Response createRsp = nfsd.create(createXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));
      FileHandle handle = createRsp.getObjHandle();
      byte[] buffer = new byte[bufSize];
      for (int i = 0; i < bufSize; i++) {
        buffer[i] = (byte) i;
      }
      int[][] ranges = new int[][] {
          {0, 10},
          {5, 7},
          {5, 5},
          {10, 6},
          {18, 6},
          {20, 6},
          {28, 4},
          {16, 2},
          {25, 4}
      };
      for (int i = 0; i < ranges.length; i++) {
        int x[] = ranges[i];
        byte[] tbuffer = new byte[x[1]];
        for (int j = 0; j < x[1]; j++) {
          tbuffer[j] = buffer[x[0] + j];
        }
        WRITE3Request writeReq = new WRITE3Request(handle, (long)x[0], x[1],
            WriteStableHow.UNSTABLE, ByteBuffer.wrap(tbuffer));
        XDR writeXdr = new XDR();
        writeReq.serialize(writeXdr);
        nfsd.write(writeXdr.asReadOnlyWrap(), null, 1, securityHandler,
            new InetSocketAddress(""localhost"", 1234));
      }

      waitWrite(nfsd, handle, 60000);
      READ3Request readReq = new READ3Request(handle, 0, bufSize);
      XDR readXdr = new XDR();
      readReq.serialize(readXdr);
      READ3Response readRsp = nfsd.read(readXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", config.getInt(
              NfsConfigKeys.DFS_NFS_SERVER_PORT_KEY,
              NfsConfigKeys.DFS_NFS_SERVER_PORT_DEFAULT)));

      assertTrue(Arrays.equals(buffer, readRsp.getData().array()));
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
297,apache_hadoop,TestWrites.testCheckSequential,"  @Test
  public void testCheckSequential() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);
    NfsConfiguration config = new NfsConfiguration();

    config.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, false);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(config), false, config);
    
    ctx.getPendingWritesForTest().put(new OffsetRange(5, 10),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ctx.getPendingWritesForTest().put(new OffsetRange(10, 15),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ctx.getPendingWritesForTest().put(new OffsetRange(20, 25),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));

    assertTrue(!ctx.checkSequential(5, 4));
    assertTrue(ctx.checkSequential(9, 5));
    assertTrue(ctx.checkSequential(10, 5));
    assertTrue(ctx.checkSequential(14, 5));
    assertTrue(!ctx.checkSequential(15, 5));
    assertTrue(!ctx.checkSequential(20, 5));
    assertTrue(!ctx.checkSequential(25, 5));
    assertTrue(!ctx.checkSequential(999, 5));
  }
",non-flaky,5
298,apache_hadoop,TestNfs3HttpServer.testHttpServer,"  @Test
  public void testHttpServer() throws Exception {
    Nfs3 nfs = new Nfs3(conf);
    nfs.startServiceInternal(false);
    RpcProgramNfs3 nfsd = (RpcProgramNfs3) nfs.getRpcProgram();
    Nfs3HttpServer infoServer = nfsd.getInfoServer();

    String urlRoot = infoServer.getServerURI().toString();

    // Check default servlets.
    String pageContents = DFSTestUtil.urlGet(new URL(urlRoot + ""/jmx""));
    assertTrue(""Bad contents: "" + pageContents,
        pageContents.contains(""java.lang:type=""));
    System.out.println(""pc:"" + pageContents);

    int port = infoServer.getSecurePort();
    assertTrue(""Can't get https port"", port > 0);
  }
",non-flaky,5
299,apache_hadoop,TestRpcProgramNfs3.testGetattr,"  @Test(timeout = 60000)
  public void testGetattr() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    GETATTR3Request req = new GETATTR3Request(handle);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    GETATTR3Response response1 = nfsd.getattr(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    GETATTR3Response response2 = nfsd.getattr(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
300,apache_hadoop,TestRpcProgramNfs3.testSetattr,"  @Test(timeout = 60000)
  public void testSetattr() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    SetAttr3 symAttr = new SetAttr3(0, 1, 0, 0, null, null,
        EnumSet.of(SetAttrField.UID));
    SETATTR3Request req = new SETATTR3Request(handle, symAttr, false, null);
    req.serialize(xdr_req);

    // Attempt by an unprivileged user should fail.
    SETATTR3Response response1 = nfsd.setattr(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    SETATTR3Response response2 = nfsd.setattr(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
301,apache_hadoop,TestRpcProgramNfs3.testLookup,"  @Test(timeout = 60000)
  public void testLookup() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    LOOKUP3Request lookupReq = new LOOKUP3Request(handle, ""bar"");
    XDR xdr_req = new XDR();
    lookupReq.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    LOOKUP3Response response1 = nfsd.lookup(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    LOOKUP3Response response2 = nfsd.lookup(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
302,apache_hadoop,TestRpcProgramNfs3.testAccess,"  @Test(timeout = 60000)
  public void testAccess() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    ACCESS3Request req = new ACCESS3Request(handle);
    req.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    ACCESS3Response response1 = nfsd.access(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    ACCESS3Response response2 = nfsd.access(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
303,apache_hadoop,TestRpcProgramNfs3.testReadlink,"  @Test(timeout = 60000)
  public void testReadlink() throws Exception {
    // Create a symlink first.
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    SYMLINK3Request req = new SYMLINK3Request(handle, ""fubar"", new SetAttr3(),
        ""bar"");
    req.serialize(xdr_req);
    
    SYMLINK3Response response = nfsd.symlink(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response.getStatus());

    // Now perform readlink operations.
    FileHandle handle2 = response.getObjFileHandle();
    XDR xdr_req2 = new XDR();
    READLINK3Request req2 = new READLINK3Request(handle2);
    req2.serialize(xdr_req2);

    // Attempt by an unpriviledged user should fail.
    READLINK3Response response1 = nfsd.readlink(xdr_req2.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    READLINK3Response response2 = nfsd.readlink(xdr_req2.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
304,apache_hadoop,TestRpcProgramNfs3.testRead,"  @Test(timeout = 60000)
  public void testRead() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);

    READ3Request readReq = new READ3Request(handle, 0, 5);
    XDR xdr_req = new XDR();
    readReq.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    READ3Response response1 = nfsd.read(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    READ3Response response2 = nfsd.read(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
305,apache_hadoop,TestRpcProgramNfs3.testEncryptedReadWrite,"  @Test(timeout = 120000)
  public void testEncryptedReadWrite() throws Exception {
    final int len = 8192;

    final Path zone = new Path(""/zone"");
    hdfs.mkdirs(zone);
    dfsAdmin.createEncryptionZone(zone, TEST_KEY, NO_TRASH);

    final byte[] buffer = new byte[len];
    for (int i = 0; i < len; i++) {
      buffer[i] = (byte) i;
    }

    final String encFile1 = ""/zone/myfile"";
    createFileUsingNfs(encFile1, buffer);
    commit(encFile1, len);
    assertArrayEquals(""encFile1 not equal"",
        getFileContentsUsingNfs(encFile1, len),
        getFileContentsUsingDfs(encFile1, len));

    /*
     * Same thing except this time create the encrypted file using DFS.
     */
    final String encFile2 = ""/zone/myfile2"";
    final Path encFile2Path = new Path(encFile2);
    DFSTestUtil.createFile(hdfs, encFile2Path, len, (short) 1, 0xFEED);
    assertArrayEquals(""encFile2 not equal"",
        getFileContentsUsingNfs(encFile2, len),
        getFileContentsUsingDfs(encFile2, len));
  }
",non-flaky,5
306,apache_hadoop,TestRpcProgramNfs3.testWrite,"  @Test(timeout = 60000)
  public void testWrite() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);

    byte[] buffer = new byte[10];
    for (int i = 0; i < 10; i++) {
      buffer[i] = (byte) i;
    }

    WRITE3Request writeReq = new WRITE3Request(handle, 0, 10,
        WriteStableHow.DATA_SYNC, ByteBuffer.wrap(buffer));
    XDR xdr_req = new XDR();
    writeReq.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    WRITE3Response response1 = nfsd.write(xdr_req.asReadOnlyWrap(),
        null, 1, securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    WRITE3Response response2 = nfsd.write(xdr_req.asReadOnlyWrap(),
        null, 1, securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect response:"", null, response2);
  }
",non-flaky,5
307,apache_hadoop,TestRpcProgramNfs3.testCreate,"  @Test(timeout = 60000)
  public void testCreate() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    CREATE3Request req = new CREATE3Request(handle, ""fubar"",
        Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    CREATE3Response response1 = nfsd.create(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    CREATE3Response response2 = nfsd.create(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
308,apache_hadoop,TestRpcProgramNfs3.testMkdir,"  @Test(timeout = 60000)
  public void testMkdir() throws Exception {//FixME
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    MKDIR3Request req = new MKDIR3Request(handle, ""fubar1"", new SetAttr3());
    req.serialize(xdr_req);
    
    // Attempt to mkdir by an unprivileged user should fail.
    MKDIR3Response response1 = nfsd.mkdir(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    XDR xdr_req2 = new XDR();
    MKDIR3Request req2 = new MKDIR3Request(handle, ""fubar2"", new SetAttr3());
    req2.serialize(xdr_req2);
    
    // Attempt to mkdir by a privileged user should pass.
    MKDIR3Response response2 = nfsd.mkdir(xdr_req2.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
309,apache_hadoop,TestRpcProgramNfs3.testSymlink,"  @Test(timeout = 60000)
  public void testSymlink() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    SYMLINK3Request req = new SYMLINK3Request(handle, ""fubar"", new SetAttr3(),
        ""bar"");
    req.serialize(xdr_req);

    // Attempt by an unprivileged user should fail.
    SYMLINK3Response response1 = nfsd.symlink(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a privileged user should pass.
    SYMLINK3Response response2 = nfsd.symlink(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
310,apache_hadoop,TestRpcProgramNfs3.testRemove,"  @Test(timeout = 60000)
  public void testRemove() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    REMOVE3Request req = new REMOVE3Request(handle, ""bar"");
    req.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    REMOVE3Response response1 = nfsd.remove(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    REMOVE3Response response2 = nfsd.remove(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
311,apache_hadoop,TestRpcProgramNfs3.testRmdir,"  @Test(timeout = 60000)
  public void testRmdir() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    RMDIR3Request req = new RMDIR3Request(handle, ""foo"");
    req.serialize(xdr_req);

    // Attempt by an unprivileged user should fail.
    RMDIR3Response response1 = nfsd.rmdir(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a privileged user should pass.
    RMDIR3Response response2 = nfsd.rmdir(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
312,apache_hadoop,TestRpcProgramNfs3.testRename,"  @Test(timeout = 60000)
  public void testRename() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    RENAME3Request req = new RENAME3Request(handle, ""bar"", handle, ""fubar"");
    req.serialize(xdr_req);
    
    // Attempt by an unprivileged user should fail.
    RENAME3Response response1 = nfsd.rename(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a privileged user should pass.
    RENAME3Response response2 = nfsd.rename(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
313,apache_hadoop,TestRpcProgramNfs3.testReaddir,"  @Test(timeout = 60000)
  public void testReaddir() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    READDIR3Request req = new READDIR3Request(handle, 0, 0, 100);
    req.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    READDIR3Response response1 = nfsd.readdir(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    READDIR3Response response2 = nfsd.readdir(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
314,apache_hadoop,TestRpcProgramNfs3.testReaddirplus,"  @Test(timeout = 60000)
  public void testReaddirplus() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    READDIRPLUS3Request req = new READDIRPLUS3Request(handle, 0, 0, 3, 2);
    req.serialize(xdr_req);
    
    // Attempt by an unprivileged user should fail.
    READDIRPLUS3Response response1 = nfsd.readdirplus(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a privileged user should pass.
    READDIRPLUS3Response response2 = nfsd.readdirplus(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
315,apache_hadoop,TestRpcProgramNfs3.testFsstat,"  @Test(timeout = 60000)
  public void testFsstat() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    FSSTAT3Request req = new FSSTAT3Request(handle);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    FSSTAT3Response response1 = nfsd.fsstat(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    FSSTAT3Response response2 = nfsd.fsstat(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
316,apache_hadoop,TestRpcProgramNfs3.testFsinfo,"  @Test(timeout = 60000)
  public void testFsinfo() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    FSINFO3Request req = new FSINFO3Request(handle);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    FSINFO3Response response1 = nfsd.fsinfo(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    FSINFO3Response response2 = nfsd.fsinfo(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
317,apache_hadoop,TestRpcProgramNfs3.testPathconf,"  @Test(timeout = 60000)
  public void testPathconf() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    PATHCONF3Request req = new PATHCONF3Request(handle);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    PATHCONF3Response response1 = nfsd.pathconf(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    PATHCONF3Response response2 = nfsd.pathconf(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
318,apache_hadoop,TestRpcProgramNfs3.testCommit,"  @Test(timeout = 60000)
  public void testCommit() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    COMMIT3Request req = new COMMIT3Request(handle, 0, 5);
    req.serialize(xdr_req);

    Channel ch = Mockito.mock(Channel.class);

    // Attempt by an unpriviledged user should fail.
    COMMIT3Response response1 = nfsd.commit(xdr_req.asReadOnlyWrap(),
        ch, 1, securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    COMMIT3Response response2 = nfsd.commit(xdr_req.asReadOnlyWrap(),
        ch, 1, securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect COMMIT3Response:"", null, response2);
  }
",non-flaky,5
319,apache_hadoop,TestRpcProgramNfs3.testIdempotent,"  @Test(timeout=10000)
  public void testIdempotent() {
    Object[][] procedures = {
        { Nfs3Constant.NFSPROC3.NULL, 1 },
        { Nfs3Constant.NFSPROC3.GETATTR, 1 },
        { Nfs3Constant.NFSPROC3.SETATTR, 1 },
        { Nfs3Constant.NFSPROC3.LOOKUP, 1 },
        { Nfs3Constant.NFSPROC3.ACCESS, 1 },
        { Nfs3Constant.NFSPROC3.READLINK, 1 },
        { Nfs3Constant.NFSPROC3.READ, 1 },
        { Nfs3Constant.NFSPROC3.WRITE, 1 },
        { Nfs3Constant.NFSPROC3.CREATE, 0 },
        { Nfs3Constant.NFSPROC3.MKDIR, 0 },
        { Nfs3Constant.NFSPROC3.SYMLINK, 0 },
        { Nfs3Constant.NFSPROC3.MKNOD, 0 },
        { Nfs3Constant.NFSPROC3.REMOVE, 0 },
        { Nfs3Constant.NFSPROC3.RMDIR, 0 },
        { Nfs3Constant.NFSPROC3.RENAME, 0 },
        { Nfs3Constant.NFSPROC3.LINK, 0 },
        { Nfs3Constant.NFSPROC3.READDIR, 1 },
        { Nfs3Constant.NFSPROC3.READDIRPLUS, 1 },
        { Nfs3Constant.NFSPROC3.FSSTAT, 1 },
        { Nfs3Constant.NFSPROC3.FSINFO, 1 },
        { Nfs3Constant.NFSPROC3.PATHCONF, 1 },
        { Nfs3Constant.NFSPROC3.COMMIT, 1 } };
    for (Object[] procedure : procedures) {
      boolean idempotent = procedure[1].equals(Integer.valueOf(1));
      Nfs3Constant.NFSPROC3 proc = (Nfs3Constant.NFSPROC3)procedure[0];
      if (idempotent) {
        Assert.assertTrue((""Procedure "" + proc + "" should be idempotent""),
            proc.isIdempotent());
      } else {
        Assert.assertFalse((""Procedure "" + proc + "" should be non-idempotent""),
            proc.isIdempotent());
      }
    }
  }
",non-flaky,5
320,apache_hadoop,TestRpcProgramNfs3.testDeprecatedKeys,"  @Test
  public void testDeprecatedKeys() {
    NfsConfiguration conf = new NfsConfiguration();
    conf.setInt(""nfs3.server.port"", 998);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_SERVER_PORT_KEY, 0) == 998);

    conf.setInt(""nfs3.mountd.port"", 999);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_MOUNTD_PORT_KEY, 0) == 999);

    conf.set(""dfs.nfs.exports.allowed.hosts"", ""host1"");
    assertTrue(conf.get(CommonConfigurationKeys.NFS_EXPORTS_ALLOWED_HOSTS_KEY)
        .equals(""host1""));

    conf.setInt(""dfs.nfs.exports.cache.expirytime.millis"", 1000);
    assertTrue(conf.getInt(
        Nfs3Constant.NFS_EXPORTS_CACHE_EXPIRYTIME_MILLIS_KEY, 0) == 1000);

    conf.setInt(""hadoop.nfs.userupdate.milly"", 10);
    assertTrue(conf.getInt(IdMappingConstant.USERGROUPID_UPDATE_MILLIS_KEY, 0) == 10);

    conf.set(""dfs.nfs3.dump.dir"", ""/nfs/tmp"");
    assertTrue(conf.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY).equals(
        ""/nfs/tmp""));

    conf.setBoolean(""dfs.nfs3.enableDump"", false);
    assertTrue(conf.getBoolean(NfsConfigKeys.DFS_NFS_FILE_DUMP_KEY, true) == false);

    conf.setInt(""dfs.nfs3.max.open.files"", 500);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_MAX_OPEN_FILES_KEY, 0) == 500);

    conf.setInt(""dfs.nfs3.stream.timeout"", 6000);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_KEY, 0) == 6000);

    conf.set(""dfs.nfs3.export.point"", ""/dir1"");
    assertTrue(conf.get(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY).equals(""/dir1""));
  }
",non-flaky,5
321,apache_hadoop,TestNfs3Utils.testGetAccessRightsForUserGroup,"  @Test
  public void testGetAccessRightsForUserGroup() throws IOException {
    Nfs3FileAttributes attr = Mockito.mock(Nfs3FileAttributes.class);
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(3);
    Mockito.when(attr.getMode()).thenReturn(448); // 700
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSREG.toValue());
    assertEquals(""No access should be allowed as UID does not match attribute over mode 700"",
      0, Nfs3Utils.getAccessRightsForUserGroup(3, 3, null, attr));
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(3);
    Mockito.when(attr.getMode()).thenReturn(56); // 070
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSREG.toValue());
    assertEquals(""No access should be allowed as GID does not match attribute over mode 070"",
      0, Nfs3Utils.getAccessRightsForUserGroup(2, 4, null, attr));
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(3);
    Mockito.when(attr.getMode()).thenReturn(7); // 007
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSREG.toValue());
    assertEquals(""Access should be allowed as mode is 007 and UID/GID do not match"",
      61 /* RWX */, Nfs3Utils.getAccessRightsForUserGroup(1, 4, new int[] {5, 6}, attr));
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(10);
    Mockito.when(attr.getMode()).thenReturn(288); // 440
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSREG.toValue());
    assertEquals(""Access should be allowed as mode is 440 and Aux GID does match"",
      1 /* R */, Nfs3Utils.getAccessRightsForUserGroup(3, 4, new int[] {5, 16, 10}, attr));
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(10);
    Mockito.when(attr.getMode()).thenReturn(448); // 700
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSDIR.toValue());
    assertEquals(""Access should be allowed for dir as mode is 700 and UID does match"",
      31 /* Lookup */, Nfs3Utils.getAccessRightsForUserGroup(2, 4, new int[] {5, 16, 10}, attr));
    assertEquals(""No access should be allowed for dir as mode is 700 even though GID does match"",
      0, Nfs3Utils.getAccessRightsForUserGroup(3, 10, new int[] {5, 16, 4}, attr));
    assertEquals(""No access should be allowed for dir as mode is 700 even though AuxGID does match"",
      0, Nfs3Utils.getAccessRightsForUserGroup(3, 20, new int[] {5, 10}, attr));
    
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(10);
    Mockito.when(attr.getMode()).thenReturn(457); // 711
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSDIR.toValue());
    assertEquals(""Access should be allowed for dir as mode is 711 and GID matches"",
        2 /* Lookup */, Nfs3Utils.getAccessRightsForUserGroup(3, 10, new int[] {5, 16, 11}, attr));
  }
",non-flaky,5
322,apache_hadoop,TestDFSClientCache.testEviction,"  @Test
  public void testEviction() throws IOException {
    NfsConfiguration conf = new NfsConfiguration();
    conf.set(FileSystem.FS_DEFAULT_NAME_KEY, ""hdfs://localhost"");

    // Only one entry will be in the cache
    final int MAX_CACHE_SIZE = 1;

    DFSClientCache cache = new DFSClientCache(conf, MAX_CACHE_SIZE);

    int namenodeId = Nfs3Utils.getNamenodeId(conf);
    DFSClient c1 = cache.getDfsClient(""test1"", namenodeId);
    assertTrue(cache.getDfsClient(""test1"", namenodeId)
        .toString().contains(""ugi=test1""));
    assertEquals(c1, cache.getDfsClient(""test1"", namenodeId));
    assertFalse(isDfsClientClose(c1));

    cache.getDfsClient(""test2"", namenodeId);
    assertTrue(isDfsClientClose(c1));
    assertTrue(""cache size should be the max size or less"",
        cache.getClientCache().size() <= MAX_CACHE_SIZE);
  }
",non-flaky,5
323,apache_hadoop,TestDFSClientCache.testGetUserGroupInformationSecure,"  @Test
  public void testGetUserGroupInformationSecure() throws IOException {
    String userName = ""user1"";
    String currentUser = ""test-user"";


    NfsConfiguration conf = new NfsConfiguration();
    conf.set(FileSystem.FS_DEFAULT_NAME_KEY, ""hdfs://localhost"");
    UserGroupInformation currentUserUgi
            = UserGroupInformation.createRemoteUser(currentUser);
    currentUserUgi.setAuthenticationMethod(KERBEROS);
    UserGroupInformation.setLoginUser(currentUserUgi);

    DFSClientCache cache = new DFSClientCache(conf);
    UserGroupInformation ugiResult
            = cache.getUserGroupInformation(userName, currentUserUgi);

    assertThat(ugiResult.getUserName(), is(userName));
    assertThat(ugiResult.getRealUser(), is(currentUserUgi));
    assertThat(
            ugiResult.getAuthenticationMethod(),
            is(UserGroupInformation.AuthenticationMethod.PROXY));
  }
",non-flaky,5
324,apache_hadoop,TestDFSClientCache.testGetUserGroupInformation,"  @Test
  public void testGetUserGroupInformation() throws IOException {
    String userName = ""user1"";
    String currentUser = ""currentUser"";

    UserGroupInformation currentUserUgi = UserGroupInformation
            .createUserForTesting(currentUser, new String[0]);
    NfsConfiguration conf = new NfsConfiguration();
    conf.set(FileSystem.FS_DEFAULT_NAME_KEY, ""hdfs://localhost"");
    DFSClientCache cache = new DFSClientCache(conf);
    UserGroupInformation ugiResult
            = cache.getUserGroupInformation(userName, currentUserUgi);

    assertThat(ugiResult.getUserName(), is(userName));
    assertThat(ugiResult.getRealUser(), is(currentUserUgi));
    assertThat(
            ugiResult.getAuthenticationMethod(),
            is(UserGroupInformation.AuthenticationMethod.PROXY));
  }
",non-flaky,5
325,apache_hadoop,TestViewfsWithNfs3.testNumExports,"  @Test
  public void testNumExports() throws Exception {
    Assert.assertEquals(mountd.getExports().size(),
        viewFs.getChildFileSystems().length);
  }
",non-flaky,5
326,apache_hadoop,TestViewfsWithNfs3.testPaths,"  @Test
  public void testPaths() throws Exception {
    Assert.assertEquals(hdfs1.resolvePath(new Path(""/user1/file1"")),
        viewFs.resolvePath(new Path(""/hdfs1/file1"")));
    Assert.assertEquals(hdfs1.resolvePath(new Path(""/user1/file2"")),
        viewFs.resolvePath(new Path(""/hdfs1/file2"")));
    Assert.assertEquals(hdfs2.resolvePath(new Path(""/user2/dir2"")),
        viewFs.resolvePath(new Path(""/hdfs2/dir2"")));
  }
",non-flaky,5
327,apache_hadoop,TestViewfsWithNfs3.testFileStatus,"  @Test
  public void testFileStatus() throws Exception {
    HdfsFileStatus status = nn1.getRpcServer().getFileInfo(""/user1/file1"");
    FileStatus st = viewFs.getFileStatus(new Path(""/hdfs1/file1""));
    Assert.assertEquals(st.isDirectory(), status.isDirectory());

    HdfsFileStatus status2 = nn2.getRpcServer().getFileInfo(""/user2/dir2"");
    FileStatus st2 = viewFs.getFileStatus(new Path(""/hdfs2/dir2""));
    Assert.assertEquals(st2.isDirectory(), status2.isDirectory());
  }
",non-flaky,5
328,apache_hadoop,TestViewfsWithNfs3.testNfsAccessNN1,"  @Test (timeout = 60000)
  public void testNfsAccessNN1() throws Exception {
    HdfsFileStatus status = nn1.getRpcServer().getFileInfo(""/user1/file1"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs1.getUri());
    testNfsGetAttrResponse(status.getFileId(), namenodeId, Nfs3Status.NFS3_OK);
  }
",non-flaky,5
329,apache_hadoop,TestViewfsWithNfs3.testNfsAccessNN2,"  @Test (timeout = 60000)
  public void testNfsAccessNN2() throws Exception {
    HdfsFileStatus status = nn2.getRpcServer().getFileInfo(""/user2/dir2"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs2.getUri());
    testNfsGetAttrResponse(status.getFileId(), namenodeId, Nfs3Status.NFS3_OK);
  }
",non-flaky,5
330,apache_hadoop,TestViewfsWithNfs3.testWrongNfsAccess,"  @Test (timeout = 60000)
  public void testWrongNfsAccess() throws Exception {
    DFSTestUtil.createFile(viewFs, new Path(""/hdfs1/file3""), 0, (short) 1, 0);
    HdfsFileStatus status = nn1.getRpcServer().getFileInfo(""/user1/file3"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs2.getUri());
    testNfsGetAttrResponse(status.getFileId(), namenodeId,
        Nfs3Status.NFS3ERR_IO);
  }
",non-flaky,5
331,apache_hadoop,TestViewfsWithNfs3.testNfsWriteNN1,"  @Test (timeout = 60000)
  public void testNfsWriteNN1() throws Exception {
    HdfsFileStatus status = nn1.getRpcServer().getFileInfo(""/user1/write1"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs1.getUri());
    testNfsWriteResponse(status.getFileId(), namenodeId);
  }
",non-flaky,5
332,apache_hadoop,TestViewfsWithNfs3.testNfsWriteNN2,"  @Test (timeout = 60000)
  public void testNfsWriteNN2() throws Exception {
    HdfsFileStatus status = nn2.getRpcServer().getFileInfo(""/user2/write2"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs2.getUri());
    testNfsWriteResponse(status.getFileId(), namenodeId);
  }
",non-flaky,5
333,apache_hadoop,TestViewfsWithNfs3.testNfsRenameMultiNN,"  @Test (timeout = 60000)
  public void testNfsRenameMultiNN() throws Exception {
    HdfsFileStatus fromFileStatus = nn1.getRpcServer().getFileInfo(""/user1"");
    int fromNNId = Nfs3Utils.getNamenodeId(config, hdfs1.getUri());
    FileHandle fromHandle =
        new FileHandle(fromFileStatus.getFileId(), fromNNId);

    HdfsFileStatus toFileStatus = nn2.getRpcServer().getFileInfo(""/user2"");
    int toNNId = Nfs3Utils.getNamenodeId(config, hdfs2.getUri());
    FileHandle toHandle = new FileHandle(toFileStatus.getFileId(), toNNId);

    HdfsFileStatus statusBeforeRename =
        nn1.getRpcServer().getFileInfo(""/user1/renameMultiNN"");
    Assert.assertEquals(statusBeforeRename.isDirectory(), false);

    testNfsRename(fromHandle, ""renameMultiNN"",
        toHandle, ""renameMultiNNFail"", Nfs3Status.NFS3ERR_INVAL);

    HdfsFileStatus statusAfterRename =
        nn2.getRpcServer().getFileInfo(""/user2/renameMultiNNFail"");
    Assert.assertEquals(statusAfterRename, null);

    statusAfterRename = nn1.getRpcServer().getFileInfo(""/user1/renameMultiNN"");
    Assert.assertEquals(statusAfterRename.isDirectory(), false);
  }
",non-flaky,5
334,apache_hadoop,TestViewfsWithNfs3.testNfsRenameSingleNN,"  @Test (timeout = 60000)
  public void testNfsRenameSingleNN() throws Exception {
    HdfsFileStatus fromFileStatus = nn1.getRpcServer().getFileInfo(""/user1"");
    int fromNNId = Nfs3Utils.getNamenodeId(config, hdfs1.getUri());
    FileHandle fromHandle =
        new FileHandle(fromFileStatus.getFileId(), fromNNId);

    HdfsFileStatus statusBeforeRename =
        nn1.getRpcServer().getFileInfo(""/user1/renameSingleNN"");
    Assert.assertEquals(statusBeforeRename.isDirectory(), false);

    testNfsRename(fromHandle, ""renameSingleNN"",
        fromHandle, ""renameSingleNNSucess"", Nfs3Status.NFS3_OK);

    HdfsFileStatus statusAfterRename =
        nn1.getRpcServer().getFileInfo(""/user1/renameSingleNNSucess"");
    Assert.assertEquals(statusAfterRename.isDirectory(), false);

    statusAfterRename =
        nn1.getRpcServer().getFileInfo(""/user1/renameSingleNN"");
    Assert.assertEquals(statusAfterRename, null);
  }
",non-flaky,5
335,apache_hadoop,TestOpenFileCtxCache.testEviction,"  @Test
  public void testEviction() throws IOException, InterruptedException {
    NfsConfiguration conf = new NfsConfiguration();

    // Only two entries will be in the cache
    conf.setInt(NfsConfigKeys.DFS_NFS_MAX_OPEN_FILES_KEY, 2);

    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);

    OpenFileCtx context1 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context2 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context3 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context4 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context5 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));

    OpenFileCtxCache cache = new OpenFileCtxCache(conf, 10 * 60 * 100);

    boolean ret = cache.put(new FileHandle(1), context1);
    assertTrue(ret);
    Thread.sleep(1000);
    ret = cache.put(new FileHandle(2), context2);
    assertTrue(ret);
    ret = cache.put(new FileHandle(3), context3);
    assertFalse(ret);
    assertTrue(cache.size() == 2);

    // Wait for the oldest stream to be evict-able, insert again
    Thread.sleep(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);
    assertTrue(cache.size() == 2);

    ret = cache.put(new FileHandle(3), context3);
    assertTrue(ret);
    assertTrue(cache.size() == 2);
    assertTrue(cache.get(new FileHandle(1)) == null);

    // Test inactive entry is evicted immediately
    context3.setActiveStatusForTest(false);
    ret = cache.put(new FileHandle(4), context4);
    assertTrue(ret);

    // Now the cache has context2 and context4
    // Test eviction failure if all entries have pending work.
    context2.getPendingWritesForTest().put(new OffsetRange(0, 100),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    context4.getPendingCommitsForTest().put(new Long(100),
        new CommitCtx(0, null, 0, attr));
    Thread.sleep(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);
    ret = cache.put(new FileHandle(5), context5);
    assertFalse(ret);
  }
",non-flaky,5
336,apache_hadoop,TestOpenFileCtxCache.testScan,"  @Test
  public void testScan() throws IOException, InterruptedException {
    NfsConfiguration conf = new NfsConfiguration();

    // Only two entries will be in the cache
    conf.setInt(NfsConfigKeys.DFS_NFS_MAX_OPEN_FILES_KEY, 2);

    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);

    OpenFileCtx context1 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context2 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context3 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context4 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));

    OpenFileCtxCache cache = new OpenFileCtxCache(conf, 10 * 60 * 100);

    // Test cleaning expired entry
    boolean ret = cache.put(new FileHandle(1), context1);
    assertTrue(ret);
    ret = cache.put(new FileHandle(2), context2);
    assertTrue(ret);
    Thread.sleep(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT + 1);
    cache.scan(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);
    assertTrue(cache.size() == 0);

    // Test cleaning inactive entry
    ret = cache.put(new FileHandle(3), context3);
    assertTrue(ret);
    ret = cache.put(new FileHandle(4), context4);
    assertTrue(ret);
    context3.setActiveStatusForTest(false);
    cache.scan(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_DEFAULT);
    assertTrue(cache.size() == 1);
    assertTrue(cache.get(new FileHandle(3)) == null);
    assertTrue(cache.get(new FileHandle(4)) != null);
  }
",non-flaky,5
337,apache_hadoop,TestClientAccessPrivilege.testClientAccessPrivilegeForRemove,"  @Test(timeout = 60000)
  public void testClientAccessPrivilegeForRemove() throws Exception {
    // Configure ro access for nfs1 service
    config.set(""dfs.nfs.exports.allowed.hosts"", ""* ro"");

    // Start nfs
    Nfs3 nfs = new Nfs3(config);
    nfs.startServiceInternal(false);

    RpcProgramNfs3 nfsd = (RpcProgramNfs3) nfs.getRpcProgram();

    // Create a remove request
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);

    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeString(""f1"");

    // Remove operation
    REMOVE3Response response = nfsd.remove(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));

    // Assert on return code
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response.getStatus());

  }
",non-flaky,5
338,apache_hadoop,TestExportsTable.testHdfsExportPoint,"  @Test
  public void testHdfsExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;

    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();

      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);

      Mountd mountd = nfsServer.getMountd();
      RpcProgramMountd rpcMount = (RpcProgramMountd) mountd.getRpcProgram();
      assertTrue(rpcMount.getExports().size() == 1);

      String exportInMountd = rpcMount.getExports().get(0);
      assertTrue(exportInMountd.equals(""/""));

    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
339,apache_hadoop,TestExportsTable.testViewFsMultipleExportPoint,"  @Test
  public void testViewFsMultipleExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    String clusterName = RandomStringUtils.randomAlphabetic(10);

    String exportPoint = ""/hdfs1,/hdfs2"";
    config.setStrings(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY, exportPoint);
    config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY,
        FsConstants.VIEWFS_SCHEME + ""://"" + clusterName);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster =
          new MiniDFSCluster.Builder(config).nnTopology(
              MiniDFSNNTopology.simpleFederatedTopology(2))
              .numDataNodes(2)
              .build();
      cluster.waitActive();
      DistributedFileSystem hdfs1 = cluster.getFileSystem(0);
      DistributedFileSystem hdfs2 = cluster.getFileSystem(1);
      cluster.waitActive();
      Path base1 = new Path(""/user1"");
      Path base2 = new Path(""/user2"");
      hdfs1.delete(base1, true);
      hdfs2.delete(base2, true);
      hdfs1.mkdirs(base1);
      hdfs2.mkdirs(base2);
      ConfigUtil.addLink(config, clusterName, ""/hdfs1"",
          hdfs1.makeQualified(base1).toUri());
      ConfigUtil.addLink(config, clusterName, ""/hdfs2"",
          hdfs2.makeQualified(base2).toUri());

      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);

      Mountd mountd = nfsServer.getMountd();
      RpcProgramMountd rpcMount = (RpcProgramMountd) mountd.getRpcProgram();
      assertTrue(rpcMount.getExports().size() == 2);

      String exportInMountd1 = rpcMount.getExports().get(0);
      assertTrue(exportInMountd1.equals(""/hdfs1""));

      String exportInMountd2 = rpcMount.getExports().get(1);
      assertTrue(exportInMountd2.equals(""/hdfs2""));

    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
340,apache_hadoop,TestExportsTable.testViewFsInternalExportPoint,"  @Test
  public void testViewFsInternalExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    String clusterName = RandomStringUtils.randomAlphabetic(10);

    String exportPoint = ""/hdfs1/subpath"";
    config.setStrings(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY, exportPoint);
    config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY,
        FsConstants.VIEWFS_SCHEME + ""://"" + clusterName);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster =
          new MiniDFSCluster.Builder(config).nnTopology(
              MiniDFSNNTopology.simpleFederatedTopology(2))
              .numDataNodes(2)
              .build();
      cluster.waitActive();
      DistributedFileSystem hdfs1 = cluster.getFileSystem(0);
      DistributedFileSystem hdfs2 = cluster.getFileSystem(1);
      cluster.waitActive();
      Path base1 = new Path(""/user1"");
      Path base2 = new Path(""/user2"");
      hdfs1.delete(base1, true);
      hdfs2.delete(base2, true);
      hdfs1.mkdirs(base1);
      hdfs2.mkdirs(base2);
      ConfigUtil.addLink(config, clusterName, ""/hdfs1"",
          hdfs1.makeQualified(base1).toUri());
      ConfigUtil.addLink(config, clusterName, ""/hdfs2"",
          hdfs2.makeQualified(base2).toUri());
      Path subPath = new Path(base1, ""subpath"");
      hdfs1.delete(subPath, true);
      hdfs1.mkdirs(subPath);

      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);

      Mountd mountd = nfsServer.getMountd();
      RpcProgramMountd rpcMount = (RpcProgramMountd) mountd.getRpcProgram();
      assertTrue(rpcMount.getExports().size() == 1);

      String exportInMountd = rpcMount.getExports().get(0);
      assertTrue(exportInMountd.equals(exportPoint));
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
341,apache_hadoop,TestExportsTable.testViewFsRootExportPoint,"  @Test
  public void testViewFsRootExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    String clusterName = RandomStringUtils.randomAlphabetic(10);

    String exportPoint = ""/"";
    config.setStrings(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY, exportPoint);
    config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY,
        FsConstants.VIEWFS_SCHEME + ""://"" + clusterName);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster =
          new MiniDFSCluster.Builder(config).nnTopology(
              MiniDFSNNTopology.simpleFederatedTopology(2))
              .numDataNodes(2)
              .build();
      cluster.waitActive();
      DistributedFileSystem hdfs1 = cluster.getFileSystem(0);
      DistributedFileSystem hdfs2 = cluster.getFileSystem(1);
      cluster.waitActive();
      Path base1 = new Path(""/user1"");
      Path base2 = new Path(""/user2"");
      hdfs1.delete(base1, true);
      hdfs2.delete(base2, true);
      hdfs1.mkdirs(base1);
      hdfs2.mkdirs(base2);
      ConfigUtil.addLink(config, clusterName, ""/hdfs1"",
          hdfs1.makeQualified(base1).toUri());
      ConfigUtil.addLink(config, clusterName, ""/hdfs2"",
          hdfs2.makeQualified(base2).toUri());

      exception.expect(FileSystemException.class);
      exception.
          expectMessage(""Only HDFS is supported as underlyingFileSystem, ""
              + ""fs scheme:viewfs"");
      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
342,apache_hadoop,TestExportsTable.testHdfsInternalExportPoint,"  @Test
  public void testHdfsInternalExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;

    String exportPoint = ""/myexport1"";
    config.setStrings(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY, exportPoint);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");
    Path base = new Path(exportPoint);

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();
      DistributedFileSystem hdfs = cluster.getFileSystem(0);
      hdfs.delete(base, true);
      hdfs.mkdirs(base);

      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);

      Mountd mountd = nfsServer.getMountd();
      RpcProgramMountd rpcMount = (RpcProgramMountd) mountd.getRpcProgram();
      assertTrue(rpcMount.getExports().size() == 1);

      String exportInMountd = rpcMount.getExports().get(0);
      assertTrue(exportInMountd.equals(exportPoint));

    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
343,apache_hadoop,TestExportsTable.testInvalidFsExport,"  @Test
  public void testInvalidFsExport() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;

    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();
      config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY,
          FsConstants.LOCAL_FS_URI.toString());

      exception.expect(FileSystemException.class);
      exception.
          expectMessage(""Only HDFS is supported as underlyingFileSystem, ""
              + ""fs scheme:file"");
      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
344,apache_hadoop,TestMountd.testStart,"  @Test
  public void testStart() throws IOException {
    // Start minicluster
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(config).numDataNodes(1)
        .build();
    cluster.waitActive();
    
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    
    int newTimeoutMillis = 1000; // 1s
    // Set the new portmap rpc timeout values and check
    config.setInt(NfsConfigKeys.NFS_UDP_CLIENT_PORTMAP_TIMEOUT_MILLIS_KEY,
                  newTimeoutMillis);
    assertTrue(config.getInt(
                      NfsConfigKeys.NFS_UDP_CLIENT_PORTMAP_TIMEOUT_MILLIS_KEY,
          0) == newTimeoutMillis);

    // Start nfs
    Nfs3 nfs3 = new Nfs3(config);
    nfs3.startServiceInternal(false);

    RpcProgramMountd mountd = (RpcProgramMountd) nfs3.getMountd()
        .getRpcProgram();
    mountd.nullOp(new XDR(), 1234, InetAddress.getByName(""localhost""));
    assertTrue(mountd.getPortmapUdpTimeoutMillis() == newTimeoutMillis);
    RpcProgramNfs3 nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();
    nfsd.nullProcedure();
    assertTrue(nfsd.getPortmapUdpTimeoutMillis() == newTimeoutMillis);
    
    cluster.shutdown();
  }
",non-flaky,5
345,apache_hadoop,TestNetworkTopology.testContains,"  @Test
  public void testContains() throws Exception {
    DatanodeDescriptor nodeNotInMap = 
      DFSTestUtil.getDatanodeDescriptor(""8.8.8.8"", ""/d2/r4"");
    for (int i=0; i < dataNodes.length; i++) {
      assertTrue(cluster.contains(dataNodes[i]));
    }
    assertFalse(cluster.contains(nodeNotInMap));
  }
",non-flaky,5
346,apache_hadoop,TestNetworkTopology.testNumOfChildren,"  @Test
  public void testNumOfChildren() throws Exception {
    assertEquals(cluster.getNumOfLeaves(), dataNodes.length);
  }
",non-flaky,5
347,apache_hadoop,TestNetworkTopology.testCreateInvalidTopology,"  @Test
  public void testCreateInvalidTopology() throws Exception {
    NetworkTopology invalCluster =
        NetworkTopology.getInstance(new Configuration());
    DatanodeDescriptor invalDataNodes[] = new DatanodeDescriptor[] {
        DFSTestUtil.getDatanodeDescriptor(""1.1.1.1"", ""/d1/r1""),
        DFSTestUtil.getDatanodeDescriptor(""2.2.2.2"", ""/d1/r1""),
        DFSTestUtil.getDatanodeDescriptor(""3.3.3.3"", ""/d1"")
    };
    invalCluster.add(invalDataNodes[0]);
    invalCluster.add(invalDataNodes[1]);
    try {
      invalCluster.add(invalDataNodes[2]);
      fail(""expected InvalidTopologyException"");
    } catch (NetworkTopology.InvalidTopologyException e) {
      assertTrue(e.getMessage().startsWith(""Failed to add ""));
      assertTrue(e.getMessage().contains(
          ""You cannot have a rack and a non-rack node at the same "" +
          ""level of the network topology.""));
    }
  }
",non-flaky,5
348,apache_hadoop,TestNetworkTopology.testRacks,"  @Test
  public void testRacks() throws Exception {
    assertEquals(cluster.getNumOfRacks(), 6);
    assertTrue(cluster.isOnSameRack(dataNodes[0], dataNodes[1]));
    assertFalse(cluster.isOnSameRack(dataNodes[1], dataNodes[2]));
    assertTrue(cluster.isOnSameRack(dataNodes[2], dataNodes[3]));
    assertTrue(cluster.isOnSameRack(dataNodes[3], dataNodes[4]));
    assertFalse(cluster.isOnSameRack(dataNodes[4], dataNodes[5]));
    assertTrue(cluster.isOnSameRack(dataNodes[5], dataNodes[6]));
  }
",non-flaky,5
349,apache_hadoop,TestNetworkTopology.testGetDistance,"  @Test
  public void testGetDistance() throws Exception {
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[0]), 0);
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[1]), 2);
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[3]), 4);
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[6]), 6);
    // verify the distance is zero as long as two nodes have the same path.
    // They don't need to refer to the same object.
    NodeBase node1 = new NodeBase(dataNodes[0].getHostName(),
        dataNodes[0].getNetworkLocation());
    NodeBase node2 = new NodeBase(dataNodes[0].getHostName(),
        dataNodes[0].getNetworkLocation());
    assertEquals(0, cluster.getDistance(node1, node2));
    // verify the distance can be computed by path.
    // They don't need to refer to the same object or parents.
    NodeBase node3 = new NodeBase(dataNodes[3].getHostName(),
        dataNodes[3].getNetworkLocation());
    NodeBase node4 = new NodeBase(dataNodes[6].getHostName(),
        dataNodes[6].getNetworkLocation());
    assertEquals(0, NetworkTopology.getDistanceByPath(node1, node2));
    assertEquals(4, NetworkTopology.getDistanceByPath(node2, node3));
    assertEquals(6, NetworkTopology.getDistanceByPath(node2, node4));
  }
",non-flaky,5
350,apache_hadoop,TestNetworkTopology.testSortByDistance,"  @Test
  public void testSortByDistance() throws Exception {
    DatanodeDescriptor[] testNodes = new DatanodeDescriptor[3];
    
    // array contains both local node & local rack node
    testNodes[0] = dataNodes[1];
    testNodes[1] = dataNodes[2];
    testNodes[2] = dataNodes[0];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[0]);
    assertTrue(testNodes[1] == dataNodes[1]);
    assertTrue(testNodes[2] == dataNodes[2]);

    // array contains both local node & local rack node & decommissioned node
    DatanodeDescriptor[] dtestNodes = new DatanodeDescriptor[5];
    dtestNodes[0] = dataNodes[8];
    dtestNodes[1] = dataNodes[12];
    dtestNodes[2] = dataNodes[11];
    dtestNodes[3] = dataNodes[9];
    dtestNodes[4] = dataNodes[10];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[8], dtestNodes, dtestNodes.length - 2);
    assertTrue(dtestNodes[0] == dataNodes[8]);
    assertTrue(dtestNodes[1] == dataNodes[11]);
    assertTrue(dtestNodes[2] == dataNodes[12]);
    assertTrue(dtestNodes[3] == dataNodes[9]);
    assertTrue(dtestNodes[4] == dataNodes[10]);

    // array contains local node
    testNodes[0] = dataNodes[1];
    testNodes[1] = dataNodes[3];
    testNodes[2] = dataNodes[0];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[0]);
    assertTrue(testNodes[1] == dataNodes[1]);
    assertTrue(testNodes[2] == dataNodes[3]);

    // array contains local rack node
    testNodes[0] = dataNodes[5];
    testNodes[1] = dataNodes[3];
    testNodes[2] = dataNodes[1];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[1]);
    assertTrue(testNodes[1] == dataNodes[3]);
    assertTrue(testNodes[2] == dataNodes[5]);

    // array contains local rack node which happens to be in position 0
    testNodes[0] = dataNodes[1];
    testNodes[1] = dataNodes[5];
    testNodes[2] = dataNodes[3];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[1]);
    assertTrue(testNodes[1] == dataNodes[3]);
    assertTrue(testNodes[2] == dataNodes[5]);

    // Same as previous, but with a different random seed to test randomization
    testNodes[0] = dataNodes[1];
    testNodes[1] = dataNodes[5];
    testNodes[2] = dataNodes[3];
    cluster.setRandomSeed(0xDEAD);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[1]);
    assertTrue(testNodes[1] == dataNodes[3]);
    assertTrue(testNodes[2] == dataNodes[5]);

    // Array of just rack-local nodes
    // Expect a random first node
    DatanodeDescriptor first = null;
    boolean foundRandom = false;
    for (int i=5; i<=7; i++) {
      testNodes[0] = dataNodes[5];
      testNodes[1] = dataNodes[6];
      testNodes[2] = dataNodes[7];
      cluster.sortByDistance(dataNodes[i], testNodes, testNodes.length);
      if (first == null) {
        first = testNodes[0];
      } else {
        if (first != testNodes[0]) {
          foundRandom = true;
          break;
        }
      }
    }
    assertTrue(""Expected to find a different first location"", foundRandom);

    // Array of just remote nodes
    // Expect random first node
    first = null;
    for (int i = 1; i <= 4; i++) {
      testNodes[0] = dataNodes[13];
      testNodes[1] = dataNodes[14];
      testNodes[2] = dataNodes[15];
      cluster.sortByDistance(dataNodes[i], testNodes, testNodes.length);
      if (first == null) {
        first = testNodes[0];
      } else {
        if (first != testNodes[0]) {
          foundRandom = true;
          break;
        }
      }
    }
    assertTrue(""Expected to find a different first location"", foundRandom);

    //Reader is not a datanode, but is in one of the datanode's rack.
    testNodes[0] = dataNodes[0];
    testNodes[1] = dataNodes[5];
    testNodes[2] = dataNodes[8];
    Node rackClient = new NodeBase(""/d3/r1/25.25.25"");
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(rackClient, testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[8]);
    assertTrue(testNodes[1] == dataNodes[5]);
    assertTrue(testNodes[2] == dataNodes[0]);

    //Reader is not a datanode , but is in one of the datanode's data center.
    testNodes[0] = dataNodes[8];
    testNodes[1] = dataNodes[5];
    testNodes[2] = dataNodes[0];
    Node dcClient = new NodeBase(""/d1/r2/25.25.25"");
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dcClient, testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[0]);
    assertTrue(testNodes[1] == dataNodes[5]);
    assertTrue(testNodes[2] == dataNodes[8]);

  }
",non-flaky,5
351,apache_hadoop,TestNetworkTopology.testRemove,"  @Test
  public void testRemove() throws Exception {
    for(int i=0; i<dataNodes.length; i++) {
      cluster.remove(dataNodes[i]);
    }
    for(int i=0; i<dataNodes.length; i++) {
      assertFalse(cluster.contains(dataNodes[i]));
    }
    assertEquals(0, cluster.getNumOfLeaves());
    assertEquals(0, cluster.clusterMap.getChildren().size());
    for(int i=0; i<dataNodes.length; i++) {
      cluster.add(dataNodes[i]);
    }
  }
",non-flaky,5
352,apache_hadoop,TestNetworkTopology.testChooseRandomExcludedNode,"  @Test
  public void testChooseRandomExcludedNode() {
    String scope = ""~"" + NodeBase.getPath(dataNodes[0]);
    Map<Node, Integer> frequency = pickNodesAtRandom(100, scope, null);

    for (Node key : dataNodes) {
      // all nodes except the first should be more than zero
      assertTrue(frequency.get(key) > 0 || key == dataNodes[0]);
    }
  }
",non-flaky,5
353,apache_hadoop,TestNetworkTopology.testChooseRandomExcludedRack,"  @Test
  public void testChooseRandomExcludedRack() {
    Map<Node, Integer> frequency = pickNodesAtRandom(100, ""~"" + ""/d2"", null);
    // all the nodes on the second rack should be zero
    for (int j = 0; j < dataNodes.length; j++) {
      int freq = frequency.get(dataNodes[j]);
      if (dataNodes[j].getNetworkLocation().startsWith(""/d2"")) {
        assertEquals(0, freq);
      } else {
        assertTrue(freq > 0);
      }
    }
  }
",non-flaky,5
354,apache_hadoop,TestNetworkTopology.testChooseRandomExcludedNodeList,"  @Test
  public void testChooseRandomExcludedNodeList() {
    String scope = ""~"" + NodeBase.getPath(dataNodes[0]);
    Set<Node> excludedNodes = new HashSet<>();
    excludedNodes.add(dataNodes[3]);
    excludedNodes.add(dataNodes[5]);
    excludedNodes.add(dataNodes[7]);
    excludedNodes.add(dataNodes[9]);
    excludedNodes.add(dataNodes[13]);
    excludedNodes.add(dataNodes[18]);
    Map<Node, Integer> frequency = pickNodesAtRandom(100, scope, excludedNodes);

    assertEquals(""dn[3] should be excluded"", 0,
        frequency.get(dataNodes[3]).intValue());
    assertEquals(""dn[5] should be exclude18d"", 0,
        frequency.get(dataNodes[5]).intValue());
    assertEquals(""dn[7] should be excluded"", 0,
        frequency.get(dataNodes[7]).intValue());
    assertEquals(""dn[9] should be excluded"", 0,
        frequency.get(dataNodes[9]).intValue());
    assertEquals(""dn[13] should be excluded"", 0,
        frequency.get(dataNodes[13]).intValue());
    assertEquals(""dn[18] should be excluded"", 0,
        frequency.get(dataNodes[18]).intValue());
    for (Node key : dataNodes) {
      if (excludedNodes.contains(key)) {
        continue;
      }
      // all nodes except the first should be more than zero
      assertTrue(frequency.get(key) > 0 || key == dataNodes[0]);
    }
  }
",non-flaky,5
355,apache_hadoop,TestNetworkTopology.testChooseRandomExcludeAllNodes,"  @Test
  public void testChooseRandomExcludeAllNodes() {
    String scope = ""~"" + NodeBase.getPath(dataNodes[0]);
    Set<Node> excludedNodes = new HashSet<>();
    for (int i = 0; i < dataNodes.length; i++) {
      excludedNodes.add(dataNodes[i]);
    }
    Map<Node, Integer> frequency = pickNodesAtRandom(100, scope, excludedNodes);
    for (Node key : dataNodes) {
      // all nodes except the first should be more than zero
      assertTrue(frequency.get(key) == 0);
    }
  }
",non-flaky,5
356,apache_hadoop,TestNetworkTopology.testInvalidNetworkTopologiesNotCachedInHdfs,"  @Test(timeout=180000)
  public void testInvalidNetworkTopologiesNotCachedInHdfs() throws Exception {
    // start a cluster
    Configuration conf = new HdfsConfiguration();
    MiniDFSCluster cluster = null;
    try {
      // bad rack topology
      String racks[] = { ""/a/b"", ""/c"" };
      String hosts[] = { ""foo1.example.com"", ""foo2.example.com"" };
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).
          racks(racks).hosts(hosts).build();
      cluster.waitActive();
      
      NamenodeProtocols nn = cluster.getNameNodeRpc();
      Assert.assertNotNull(nn);
      
      // Wait for one DataNode to register.
      // The other DataNode will not be able to register up because of the rack mismatch.
      DatanodeInfo[] info;
      while (true) {
        info = nn.getDatanodeReport(DatanodeReportType.LIVE);
        Assert.assertFalse(info.length == 2);
        if (info.length == 1) {
          break;
        }
        Thread.sleep(1000);
      }
      // Set the network topology of the other node to the match the network
      // topology of the node that came up.
      int validIdx = info[0].getHostName().equals(hosts[0]) ? 0 : 1;
      int invalidIdx = validIdx == 1 ? 0 : 1;
      StaticMapping.addNodeToRack(hosts[invalidIdx], racks[validIdx]);
      LOG.info(""datanode "" + validIdx + "" came up with network location "" + 
        info[0].getNetworkLocation());

      // Restart the DN with the invalid topology and wait for it to register.
      cluster.restartDataNode(invalidIdx);
      Thread.sleep(5000);
      while (true) {
        info = nn.getDatanodeReport(DatanodeReportType.LIVE);
        if (info.length == 2) {
          break;
        }
        if (info.length == 0) {
          LOG.info(""got no valid DNs"");
        } else if (info.length == 1) {
          LOG.info(""got one valid DN: "" + info[0].getHostName() +
              "" (at "" + info[0].getNetworkLocation() + "")"");
        }
        Thread.sleep(1000);
      }
      Assert.assertEquals(info[0].getNetworkLocation(),
                          info[1].getNetworkLocation());
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
357,apache_hadoop,TestPermission.testBackwardCompatibility,"  @Test
  public void testBackwardCompatibility() {
    // Test 1 - old configuration key with decimal 
    // umask value should be handled when set using 
    // FSPermission.setUMask() API
    FsPermission perm = new FsPermission((short)18);
    Configuration conf = new Configuration();
    FsPermission.setUMask(conf, perm);
    assertEquals(18, FsPermission.getUMask(conf).toShort());

    // Test 2 - new configuration key is handled
    conf = new Configuration();
    conf.set(FsPermission.UMASK_LABEL, ""022"");
    assertEquals(18, FsPermission.getUMask(conf).toShort());

    // Test 3 - equivalent valid umask
    conf = new Configuration();
    conf.set(FsPermission.UMASK_LABEL, ""0022"");
    assertEquals(18, FsPermission.getUMask(conf).toShort());

    // Test 4 - invalid umask
    conf = new Configuration();
    conf.set(FsPermission.UMASK_LABEL, ""1222"");
    try {
      FsPermission.getUMask(conf);
      fail(""expect IllegalArgumentException happen"");
    } catch (IllegalArgumentException e) {
     //pass, exception successfully trigger
    }

    // Test 5 - invalid umask
    conf = new Configuration();
    conf.set(FsPermission.UMASK_LABEL, ""01222"");
    try {
      FsPermission.getUMask(conf);
      fail(""expect IllegalArgumentException happen"");
    } catch (IllegalArgumentException e) {
     //pass, exception successfully trigger
    }
  }
",non-flaky,5
358,apache_hadoop,TestPermission.testCreate,"  @Test
  public void testCreate() throws Exception {
    Configuration conf = new HdfsConfiguration();
    conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, true);
    conf.set(FsPermission.UMASK_LABEL, ""000"");
    MiniDFSCluster cluster = null;
    FileSystem fs = null;

    try {
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
      cluster.waitActive();
      fs = FileSystem.get(conf);
      FsPermission rootPerm = checkPermission(fs, ""/"", null);
      FsPermission inheritPerm = FsPermission.createImmutable(
          (short)(rootPerm.toShort() | 0300));

      FsPermission dirPerm = new FsPermission((short)0777);
      fs.mkdirs(new Path(""/a1/a2/a3""), dirPerm);
      checkPermission(fs, ""/a1"", dirPerm);
      checkPermission(fs, ""/a1/a2"", dirPerm);
      checkPermission(fs, ""/a1/a2/a3"", dirPerm);

      dirPerm = new FsPermission((short)0123);
      FsPermission permission = FsPermission.createImmutable(
        (short)(dirPerm.toShort() | 0300));
      fs.mkdirs(new Path(""/aa/1/aa/2/aa/3""), dirPerm);
      checkPermission(fs, ""/aa/1"", permission);
      checkPermission(fs, ""/aa/1/aa/2"", permission);
      checkPermission(fs, ""/aa/1/aa/2/aa/3"", dirPerm);

      FsPermission filePerm = new FsPermission((short)0444);
      Path p = new Path(""/b1/b2/b3.txt"");
      FSDataOutputStream out = fs.create(p, filePerm,
          true, conf.getInt(CommonConfigurationKeys.IO_FILE_BUFFER_SIZE_KEY, 4096),
          fs.getDefaultReplication(p), fs.getDefaultBlockSize(p), null);
      out.write(123);
      out.close();
      checkPermission(fs, ""/b1"", inheritPerm);
      checkPermission(fs, ""/b1/b2"", inheritPerm);
      checkPermission(fs, ""/b1/b2/b3.txt"", filePerm);
      
      conf.set(FsPermission.UMASK_LABEL, ""022"");
      permission = 
        FsPermission.createImmutable((short)0666);
      FileSystem.mkdirs(fs, new Path(""/c1""), new FsPermission(permission));
      FileSystem.create(fs, new Path(""/c1/c2.txt""),
          new FsPermission(permission));
      checkPermission(fs, ""/c1"", permission);
      checkPermission(fs, ""/c1/c2.txt"", permission);
    } finally {
      try {
        if(fs != null) fs.close();
      } catch(Exception e) {
        LOG.error(StringUtils.stringifyException(e));
      }
      try {
        if(cluster != null) cluster.shutdown();
      } catch(Exception e) {
        LOG.error(StringUtils.stringifyException(e));
      }
    }
  }
",non-flaky,5
359,apache_hadoop,TestPermission.testFilePermission,"  @Test
  public void testFilePermission() throws Exception {
    final Configuration conf = new HdfsConfiguration();
    conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, true);
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    cluster.waitActive();

    try {
      nnfs = FileSystem.get(conf);
      // test permissions on files that do not exist
      assertFalse(nnfs.exists(CHILD_FILE1));
      try {
        nnfs.setPermission(CHILD_FILE1, new FsPermission((short)0777));
        assertTrue(false);
      }
      catch(java.io.FileNotFoundException e) {
        LOG.info(""GOOD: got "" + e);
      }
      
      // make sure nn can take user specified permission (with default fs
      // permission umask applied)
      FSDataOutputStream out = nnfs.create(CHILD_FILE1, new FsPermission(
          (short) 0777), true, 1024, (short) 1, 1024, null);
      FileStatus status = nnfs.getFileStatus(CHILD_FILE1);
      // FS_PERMISSIONS_UMASK_DEFAULT is 0022
      assertTrue(status.getPermission().toString().equals(""rwxr-xr-x""));
      nnfs.delete(CHILD_FILE1, false);
      
      // following dir/file creations are legal
      nnfs.mkdirs(CHILD_DIR1);
      status = nnfs.getFileStatus(CHILD_DIR1);
      assertThat(""Expect 755 = 777 (default dir) - 022 (default umask)"",
          status.getPermission().toString(), is(""rwxr-xr-x""));
      out = nnfs.create(CHILD_FILE1);
      status = nnfs.getFileStatus(CHILD_FILE1);
      assertTrue(status.getPermission().toString().equals(""rw-r--r--""));
      byte data[] = new byte[FILE_LEN];
      RAN.nextBytes(data);
      out.write(data);
      out.close();
      nnfs.setPermission(CHILD_FILE1, new FsPermission(""700""));
      status = nnfs.getFileStatus(CHILD_FILE1);
      assertTrue(status.getPermission().toString().equals(""rwx------""));

      // mkdirs with null permission
      nnfs.mkdirs(CHILD_DIR3, null);
      status = nnfs.getFileStatus(CHILD_DIR3);
      assertThat(""Expect 755 = 777 (default dir) - 022 (default umask)"",
          status.getPermission().toString(), is(""rwxr-xr-x""));

      // following read is legal
      byte dataIn[] = new byte[FILE_LEN];
      FSDataInputStream fin = nnfs.open(CHILD_FILE1);
      int bytesRead = fin.read(dataIn);
      assertTrue(bytesRead == FILE_LEN);
      for(int i=0; i<FILE_LEN; i++) {
        assertEquals(data[i], dataIn[i]);
      }

      // test execution bit support for files
      nnfs.setPermission(CHILD_FILE1, new FsPermission(""755""));
      status = nnfs.getFileStatus(CHILD_FILE1);
      assertTrue(status.getPermission().toString().equals(""rwxr-xr-x""));
      nnfs.setPermission(CHILD_FILE1, new FsPermission(""744""));
      status = nnfs.getFileStatus(CHILD_FILE1);
      assertTrue(status.getPermission().toString().equals(""rwxr--r--""));
      nnfs.setPermission(CHILD_FILE1, new FsPermission(""700""));
      
      ////////////////////////////////////////////////////////////////
      // test illegal file/dir creation
      UserGroupInformation userGroupInfo = 
        UserGroupInformation.createUserForTesting(USER_NAME, GROUP_NAMES );
      
      userfs = DFSTestUtil.getFileSystemAs(userGroupInfo, conf);

      // make sure mkdir of a existing directory that is not owned by 
      // this user does not throw an exception.
      userfs.mkdirs(CHILD_DIR1);
      
      // illegal mkdir
      assertTrue(!canMkdirs(userfs, CHILD_DIR2));

      // illegal file creation
      assertTrue(!canCreate(userfs, CHILD_FILE2));

      // illegal file open
      assertTrue(!canOpen(userfs, CHILD_FILE1));

      nnfs.setPermission(ROOT_PATH, new FsPermission((short)0755));
      nnfs.setPermission(CHILD_DIR1, new FsPermission(""777""));
      nnfs.setPermission(new Path(""/""), new FsPermission((short)0777));
      final Path RENAME_PATH = new Path(""/foo/bar"");
      userfs.mkdirs(RENAME_PATH);
      assertTrue(canRename(userfs, RENAME_PATH, CHILD_DIR1));
      // test permissions on files that do not exist
      assertFalse(userfs.exists(CHILD_FILE3));
      try {
        userfs.setPermission(CHILD_FILE3, new FsPermission((short) 0777));
        fail(""setPermission should fail for non-exist file"");
      } catch (java.io.FileNotFoundException ignored) {
      }

      // Make sure any user can create file in root.
      nnfs.setPermission(ROOT_PATH, new FsPermission(""777""));

      testSuperCanChangeOwnerGroup();
      testNonSuperCanChangeToOwnGroup();
      testNonSuperCannotChangeToOtherGroup();
      testNonSuperCannotChangeGroupForOtherFile();
      testNonSuperCannotChangeGroupForNonExistentFile();
      testNonSuperCannotChangeOwner();
      testNonSuperCannotChangeOwnerForOtherFile();
      testNonSuperCannotChangeOwnerForNonExistentFile();
    } finally {
      cluster.shutdown();
    }
  }
",non-flaky,5
360,apache_hadoop,TestPermissionSymlinks.testDelete,"  @Test(timeout = 5000)
  public void testDelete() throws Exception {
    fs.setPermission(linkParent, new FsPermission((short) 0555));
    doDeleteLinkParentNotWritable();

    fs.setPermission(linkParent, new FsPermission((short) 0777));
    fs.setPermission(targetParent, new FsPermission((short) 0555));
    fs.setPermission(target, new FsPermission((short) 0555));
    doDeleteTargetParentAndTargetNotWritable();
  }
",non-flaky,5
361,apache_hadoop,TestPermissionSymlinks.testAclDelete,"  @Test
  public void testAclDelete() throws Exception {
    fs.setAcl(linkParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doDeleteLinkParentNotWritable();

    fs.setAcl(linkParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    fs.setAcl(targetParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doDeleteTargetParentAndTargetNotWritable();
  }
",non-flaky,5
362,apache_hadoop,TestPermissionSymlinks.testReadWhenTargetNotReadable,"  @Test(timeout = 5000)
  public void testReadWhenTargetNotReadable() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0000));
    doReadTargetNotReadable();
  }
",non-flaky,5
363,apache_hadoop,TestPermissionSymlinks.testAclReadTargetNotReadable,"  @Test
  public void testAclReadTargetNotReadable() throws Exception {
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, READ_WRITE),
      aclEntry(ACCESS, USER, user.getUserName(), NONE),
      aclEntry(ACCESS, GROUP, READ),
      aclEntry(ACCESS, OTHER, READ)));
    doReadTargetNotReadable();
  }
",non-flaky,5
364,apache_hadoop,TestPermissionSymlinks.testFileStatus,"  @Test(timeout = 5000)
  public void testFileStatus() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0000));
    doGetFileLinkStatusTargetNotReadable();
  }
",non-flaky,5
365,apache_hadoop,TestPermissionSymlinks.testAclGetFileLinkStatusTargetNotReadable,"  @Test
  public void testAclGetFileLinkStatusTargetNotReadable() throws Exception {
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, READ_WRITE),
      aclEntry(ACCESS, USER, user.getUserName(), NONE),
      aclEntry(ACCESS, GROUP, READ),
      aclEntry(ACCESS, OTHER, READ)));
    doGetFileLinkStatusTargetNotReadable();
  }
",non-flaky,5
366,apache_hadoop,TestPermissionSymlinks.testRenameLinkTargetNotWritableFC,"  @Test(timeout = 5000)
  public void testRenameLinkTargetNotWritableFC() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0555));
    fs.setPermission(targetParent, new FsPermission((short) 0555));
    doRenameLinkTargetNotWritableFC();
  }
",non-flaky,5
367,apache_hadoop,TestPermissionSymlinks.testAclRenameTargetNotWritableFC,"  @Test
  public void testAclRenameTargetNotWritableFC() throws Exception {
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    fs.setAcl(targetParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doRenameLinkTargetNotWritableFC();
  }
",non-flaky,5
368,apache_hadoop,TestPermissionSymlinks.testRenameSrcNotWritableFC,"  @Test(timeout = 5000)
  public void testRenameSrcNotWritableFC() throws Exception {
    fs.setPermission(linkParent, new FsPermission((short) 0555));
    doRenameSrcNotWritableFC();
  }
",non-flaky,5
369,apache_hadoop,TestPermissionSymlinks.testAclRenameSrcNotWritableFC,"  @Test
  public void testAclRenameSrcNotWritableFC() throws Exception {
    fs.setAcl(linkParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doRenameSrcNotWritableFC();
  }
",non-flaky,5
370,apache_hadoop,TestPermissionSymlinks.testRenameLinkTargetNotWritableFS,"  @Test(timeout = 5000)
  public void testRenameLinkTargetNotWritableFS() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0555));
    fs.setPermission(targetParent, new FsPermission((short) 0555));
    doRenameLinkTargetNotWritableFS();
  }
",non-flaky,5
371,apache_hadoop,TestPermissionSymlinks.testAclRenameTargetNotWritableFS,"  @Test
  public void testAclRenameTargetNotWritableFS() throws Exception {
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    fs.setAcl(targetParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doRenameLinkTargetNotWritableFS();
  }
",non-flaky,5
372,apache_hadoop,TestPermissionSymlinks.testRenameSrcNotWritableFS,"  @Test(timeout = 5000)
  public void testRenameSrcNotWritableFS() throws Exception {
    fs.setPermission(linkParent, new FsPermission((short) 0555));
    doRenameSrcNotWritableFS();
  }
",non-flaky,5
373,apache_hadoop,TestPermissionSymlinks.testAclRenameSrcNotWritableFS,"  @Test
  public void testAclRenameSrcNotWritableFS() throws Exception {
    fs.setAcl(linkParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doRenameSrcNotWritableFS();
  }
",non-flaky,5
374,apache_hadoop,TestPermissionSymlinks.run,"  @Test
  public void testAccess() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0002));
    fs.setAcl(target, Arrays.asList(
        aclEntry(ACCESS, USER, ALL),
        aclEntry(ACCESS, GROUP, NONE),
        aclEntry(ACCESS, USER, user.getShortUserName(), WRITE),
        aclEntry(ACCESS, OTHER, WRITE)));
    FileContext myfc = user.doAs(new PrivilegedExceptionAction<FileContext>() {
      @Override
      public FileContext run() throws IOException {
        return FileContext.getFileContext(conf);
      }
",non-flaky,5
375,apache_hadoop,TestRefreshUserMappings.testGroupMappingRefresh,"  @Test
  public void testGroupMappingRefresh() throws Exception {
    DFSAdmin admin = new DFSAdmin(config);
    String [] args =  new String[]{""-refreshUserToGroupsMappings""};
    Groups groups = Groups.getUserToGroupsMappingService(config);
    String user = UserGroupInformation.getCurrentUser().getUserName();
    System.out.println(""first attempt:"");
    List<String> g1 = groups.getGroups(user);
    String [] str_groups = new String [g1.size()];
    g1.toArray(str_groups);
    System.out.println(Arrays.toString(str_groups));
    
    System.out.println(""second attempt, should be same:"");
    List<String> g2 = groups.getGroups(user);
    g2.toArray(str_groups);
    System.out.println(Arrays.toString(str_groups));
    for(int i=0; i<g2.size(); i++) {
      assertEquals(""Should be same group "", g1.get(i), g2.get(i));
    }
    admin.run(args);
    System.out.println(""third attempt(after refresh command), should be different:"");
    List<String> g3 = groups.getGroups(user);
    g3.toArray(str_groups);
    System.out.println(Arrays.toString(str_groups));
    for(int i=0; i<g3.size(); i++) {
      assertFalse(""Should be different group: "" + g1.get(i) + "" and "" + g3.get(i), 
          g1.get(i).equals(g3.get(i)));
    }
    
    // test time out
    Thread.sleep(groupRefreshTimeoutSec*1100);
    System.out.println(""fourth attempt(after timeout), should be different:"");
    List<String> g4 = groups.getGroups(user);
    g4.toArray(str_groups);
    System.out.println(Arrays.toString(str_groups));
    for(int i=0; i<g4.size(); i++) {
      assertFalse(""Should be different group "", g3.get(i).equals(g4.get(i)));
    }
  }
",non-flaky,5
376,apache_hadoop,TestRefreshUserMappings.testRefreshSuperUserGroupsConfiguration,"  @Test
  public void testRefreshSuperUserGroupsConfiguration() throws Exception {
    final String SUPER_USER = ""super_user"";
    final List<String> groupNames1 = new ArrayList<>();
    groupNames1.add(""gr1"");
    groupNames1.add(""gr2"");
    final List<String> groupNames2 = new ArrayList<>();
    groupNames2.add(""gr3"");
    groupNames2.add(""gr4"");

    //keys in conf
    String userKeyGroups = DefaultImpersonationProvider.getTestProvider().
        getProxySuperuserGroupConfKey(SUPER_USER);
    String userKeyHosts = DefaultImpersonationProvider.getTestProvider().
        getProxySuperuserIpConfKey (SUPER_USER);
    
    config.set(userKeyGroups, ""gr3,gr4,gr5""); // superuser can proxy for this group
    config.set(userKeyHosts,""127.0.0.1"");
    ProxyUsers.refreshSuperUserGroupsConfiguration(config);
    
    UserGroupInformation ugi1 = mock(UserGroupInformation.class);
    UserGroupInformation ugi2 = mock(UserGroupInformation.class);
    UserGroupInformation suUgi = mock(UserGroupInformation.class);
    when(ugi1.getRealUser()).thenReturn(suUgi);
    when(ugi2.getRealUser()).thenReturn(suUgi);

    when(suUgi.getShortUserName()).thenReturn(SUPER_USER); // super user
    when(suUgi.getUserName()).thenReturn(SUPER_USER+""L""); // super user
     
    when(ugi1.getShortUserName()).thenReturn(""user1"");
    when(ugi2.getShortUserName()).thenReturn(""user2"");
    
    when(ugi1.getUserName()).thenReturn(""userL1"");
    when(ugi2.getUserName()).thenReturn(""userL2"");

    // set groups for users
    when(ugi1.getGroups()).thenReturn(groupNames1);
    when(ugi2.getGroups()).thenReturn(groupNames2);


    // check before
    try {
      ProxyUsers.authorize(ugi1, ""127.0.0.1"");
      fail(""first auth for "" + ugi1.getShortUserName() + "" should've failed "");
    } catch (AuthorizationException e) {
      // expected
      System.err.println(""auth for "" + ugi1.getUserName() + "" failed"");
    }
    try {
      ProxyUsers.authorize(ugi2, ""127.0.0.1"");
      System.err.println(""auth for "" + ugi2.getUserName() + "" succeeded"");
      // expected
    } catch (AuthorizationException e) {
      fail(""first auth for "" + ugi2.getShortUserName() + "" should've succeeded: "" + e.getLocalizedMessage());
    }
    
    // refresh will look at configuration on the server side
    // add additional resource with the new value
    // so the server side will pick it up
    String rsrc = ""testGroupMappingRefresh_rsrc.xml"";
    addNewConfigResource(rsrc, userKeyGroups, ""gr2"", userKeyHosts, ""127.0.0.1"");  
    
    DFSAdmin admin = new DFSAdmin(config);
    String [] args = new String[]{""-refreshSuperUserGroupsConfiguration""};
    admin.run(args);
    
    try {
      ProxyUsers.authorize(ugi2, ""127.0.0.1"");
      fail(""second auth for "" + ugi2.getShortUserName() + "" should've failed "");
    } catch (AuthorizationException e) {
      // expected
      System.err.println(""auth for "" + ugi2.getUserName() + "" failed"");
    }
    try {
      ProxyUsers.authorize(ugi1, ""127.0.0.1"");
      System.err.println(""auth for "" + ugi1.getUserName() + "" succeeded"");
      // expected
    } catch (AuthorizationException e) {
      fail(""second auth for "" + ugi1.getShortUserName() + "" should've succeeded: "" + e.getLocalizedMessage());
    }
    
    
  }
",non-flaky,5
377,apache_hadoop,TestFcHdfsSetUMask.testMkdirWithExistingDirClear,"  @Test
  public void testMkdirWithExistingDirClear() throws IOException {
    testMkdirWithExistingDir(BLANK_TEST_UMASK, BLANK_PERMISSIONS);
  }
",non-flaky,5
378,apache_hadoop,TestFcHdfsSetUMask.testMkdirWithExistingDirOpen,"  @Test
  public void testMkdirWithExistingDirOpen() throws IOException {
    testMkdirWithExistingDir(WIDE_OPEN_TEST_UMASK, WIDE_OPEN_PERMISSIONS);
  }
",non-flaky,5
379,apache_hadoop,TestFcHdfsSetUMask.testMkdirWithExistingDirMiddle,"  @Test
  public void testMkdirWithExistingDirMiddle() throws IOException {
    testMkdirWithExistingDir(USER_GROUP_OPEN_TEST_UMASK,
        USER_GROUP_OPEN_PERMISSIONS);
  }
",non-flaky,5
380,apache_hadoop,TestFcHdfsSetUMask.testMkdirRecursiveWithNonExistingDirClear,"  @Test
  public void testMkdirRecursiveWithNonExistingDirClear() throws IOException {
    // by default parent directories have -wx------ bits set
    testMkdirRecursiveWithNonExistingDir(BLANK_TEST_UMASK, BLANK_PERMISSIONS, 
        PARENT_PERMS_FOR_BLANK_PERMISSIONS);
  }
",non-flaky,5
20912,NationalSecurityAgency_timely,MetricHistogramTest.testMin,"    @Test
    public void testMin() throws Exception {
        Assert.assertEquals(1.0D, m.min(), 0.0D);
    }
",non-flaky,5
20913,NationalSecurityAgency_timely,MetricHistogramTest.testMax,"    @Test
    public void testMax() throws Exception {
        Assert.assertEquals(100.0D, m.max(), 0.0D);
    }
",non-flaky,5
20914,NationalSecurityAgency_timely,MetricHistogramTest.testAvg,"    @Test
    public void testAvg() throws Exception {
        int sum = 0;
        for (int i = 1; i <= 100; i++) {
            sum += i;
        }
        Assert.assertEquals((sum / 100.0D), m.avg(), 0.0D);
    }
",non-flaky,5
20915,NationalSecurityAgency_timely,MetricHistogramTest.testCount,"    @Test
    public void testCount() throws Exception {
        Assert.assertEquals(100.0D, m.count(), 0.0D);
    }
",non-flaky,5
20916,NationalSecurityAgency_timely,MetricHistogramTest.test50thPercentile,"    @Test
    public void test50thPercentile() throws Exception {
        Assert.assertEquals(50.0D, m.getPercentile(50), 0.0D);
    }
",non-flaky,5
20917,NationalSecurityAgency_timely,MetricHistogramTest.test75thPercentile,"    @Test
    public void test75thPercentile() throws Exception {
        Assert.assertEquals(75.0D, m.getPercentile(75), 0.0D);
    }
",non-flaky,5
20918,NationalSecurityAgency_timely,MetricHistogramTest.test90thPercentile,"    @Test
    public void test90thPercentile() throws Exception {
        Assert.assertEquals(90.0D, m.getPercentile(90), 0.0D);
    }
",non-flaky,5
20919,NationalSecurityAgency_timely,MetricHistogramTest.test99thPercentile,"    @Test
    public void test99thPercentile() throws Exception {
        Assert.assertEquals(99.0D, m.getPercentile(99), 0.0D);
    }
",non-flaky,5
20920,NationalSecurityAgency_timely,MetricHistogramTest.testSerialization,"    @Test
    public void testSerialization() throws Exception {
        MetricParser metricParser = new MetricParser();
        Tag t1 = new Tag(""tag1=value1"");
        Tag t2 = new Tag(""tag2=value2"");
        Tag avg = new Tag(""sample=avg"");
        Tag min = new Tag(""sample=min"");
        Tag max = new Tag(""sample=max"");
        Tag sum = new Tag(""sample=sum"");
        Tag count = new Tag(""sample=count"");
        Tag p50 = new Tag(""sample=50p"");
        Tag p75 = new Tag(""sample=75p"");
        Tag p90 = new Tag(""sample=90p"");
        Tag p99 = new Tag(""sample=99p"");

        List<Tag> tags = new ArrayList<>();
        tags.add(t1);
        tags.add(t2);
        m.initialize(""sys.cpu.user"", tags);

        byte[] bytes = m.serialize(m);
        String puts = new String(bytes);
        for (String put : puts.split(""\n"")) {
            Metric metric = metricParser.parse(put);
            Assert.assertEquals(""sys.cpu.user_summarized"", metric.getName());
            metric.getTags().forEach(t -> {
                Assert.assertTrue(
                        t.equals(t1) || t.equals(t2) || t.equals(avg) || t.equals(min) || t.equals(max) || t.equals(sum)
                                || t.equals(count) || t.equals(p50) || t.equals(p75) || t.equals(p90) || t.equals(p99));
            });
        }
    }
",non-flaky,5
20921,NationalSecurityAgency_timely,WriteTimelyPluginTest.testWrite,"    @Test
    public void testWrite() throws Exception {
        Thread t = new Thread(server);
        t.start();
        setupPlugin();
        while (!server.ready()) {
            Thread.sleep(1000);
        }
        Assert.assertEquals(0, plugin.write(createMetric()));
        Thread.sleep(100);
        Assert.assertTrue(server.messageReceived());
        plugin.shutdown();
        server.shutdown();
        t.join();
    }
",non-flaky,5
20922,NationalSecurityAgency_timely,WriteTimelyPluginTest.testWriteAfterServerRestart,"    @Test
    public void testWriteAfterServerRestart() throws Exception {
        Thread t = new Thread(server);
        t.start();
        setupPlugin();
        while (!server.ready()) {
            Thread.sleep(1000);
        }
        Assert.assertEquals(0, plugin.write(createMetric()));
        Thread.sleep(100);
        Assert.assertTrue(server.messageReceived());
        server.shutdown();
        t.join();
        Thread.sleep(2000);

        server.create();
        Thread t2 = new Thread(server);
        t2.start();
        // Need to call this again because the server is not guaranteed to be
        // listening on the same local port as the first time that it was
        // started
        setupPlugin();
        while (!server.ready()) {
            Thread.sleep(1000);
            // Keep sending metrics to plugin to force reconnect
            int result = plugin.write(createMetric());
            System.out.println(""Wrote to client, result: "" + result);
            Assert.assertEquals(0, result);
        }
        Assert.assertEquals(0, plugin.write(createMetric()));
        Thread.sleep(1000);
        Assert.assertTrue(server.messageReceived());
        plugin.shutdown();
        server.shutdown();
        t2.join();
    }
",non-flaky,5
20923,NationalSecurityAgency_timely,MetricParserTest.testParseWithEscapedCharacters,"    @Test
    public void testParseWithEscapedCharacters() {

        MetricParser parser = new MetricParser();
        Metric m = parser.parse(""put mymetric 12341234 5.0 tag1=value1,value1 tag2=value2=value2"");

        Assert.assertEquals(""mymetric"", m.getName());
        Assert.assertEquals(12341234, (long) m.getValue().getTimestamp());
        Assert.assertEquals(5.0, (double) m.getValue().getMeasure(), 0);
        List<Tag> expected = new ArrayList<>();
        expected.add(new Tag(""tag1"", ""value1,value1""));
        expected.add(new Tag(""tag2"", ""value2=value2""));
        Assert.assertEquals(expected, m.getTags());
    }
",non-flaky,5
20924,NationalSecurityAgency_timely,MetricParserTest.testParseMalformatted,"    @Test
    public void testParseMalformatted() {

        MetricParser parser = new MetricParser();
        try {
            // parser should throw an exception
            parser.parse(""put mymetric 12341234 5.0 tag1 tag2=value2"");
            Assert.fail();
        } catch (IllegalArgumentException e) {

        }
    }
",non-flaky,5
20925,NationalSecurityAgency_timely,TagListParserTest.testListParse,"    @Test
    public void testListParse() {
        String value = ""tag1=value1,tag2=value2"";
        List<Tag> tags = new TagListParser().parse(value);
        Assert.assertEquals(2, tags.size());
        Assert.assertEquals(new Tag(""tag1"", ""value1""), tags.get(0));
        Assert.assertEquals(new Tag(""tag2"", ""value2""), tags.get(1));
    }
",non-flaky,5
20926,NationalSecurityAgency_timely,TagListParserTest.testListCombine,"    @Test
    public void testListCombine() {
        List<Tag> tags = new ArrayList<>();
        tags.add(new Tag(""tag1"", ""value1""));
        tags.add(new Tag(""tag2"", ""value2""));
        String combined = new TagListParser().combine(tags);
        Assert.assertEquals(""tag1=value1,tag2=value2"", combined);
    }
",non-flaky,5
20927,NationalSecurityAgency_timely,TagListParserTest.testListCombineMap,"    @Test
    public void testListCombineMap() {
        Map<String, String> map = new TreeMap<>();
        map.put(""tag1"", ""value1"");
        map.put(""tag2"", ""value2"");
        String combined = new TagListParser().combine(map);
        Assert.assertEquals(""tag1=value1,tag2=value2"", combined);
    }
",non-flaky,5
20928,NationalSecurityAgency_timely,TagListParserTest.testParseTagsWithCommas,"    @Test
    public void testParseTagsWithCommas() {

        try {
            String s = ""tag1=value1,tag2=3.4.3_(default\\,_Date\\,_Time)_"";
            new TagListParser().parse(s);
        } catch (Exception e) {
            Assert.fail(e.getMessage());
        }
    }
",non-flaky,5
20929,NationalSecurityAgency_timely,MetricTest.testEquals,"    @Test
    public void testEquals() {
        Metric m1 = Metric.newBuilder().name(""m1"").tag(""t1"", ""v1"").tag(""t2"", ""v2"").value(1, 0.0).build();
        Metric m2 = Metric.newBuilder().name(""m1"").tag(""t2"", ""v2"").tag(""t1"", ""v1"").value(1, 0.0).build();

        assertTrue(m1.equals(m2));
        assertTrue(m2.equals(m1));

        Metric m3 = Metric.newBuilder().name(""m1"").tag(""t1"", ""v1"").value(1, 0.0).build();
        assertFalse(m1.equals(m3));

        Metric m4 = Metric.newBuilder().name(""m4"").tag(""t2"", ""v2"").tag(""t1"", ""v1"").value(1, 0.0).build();
        assertFalse(m1.equals(m4));

        Metric m5 = Metric.newBuilder().name(""m1"").tag(""t3"", ""v3"").tag(""t2"", ""v2"").tag(""t1"", ""v1"").value(1, 0.0)
                .build();
        assertFalse(m1.equals(m5));

        Metric m6 = Metric.newBuilder().name(""m1"").tag(""t2"", ""v2"").tag(""t1"", ""v1"").value(2, 0.0).build();
        assertFalse(m1.equals(m6));

        Metric m7 = Metric.newBuilder().name(""m1"").tag(""t2"", ""v2"").tag(""t1"", ""v1"").value(1, 1.0).build();
        assertFalse(m1.equals(m7));
    }
",non-flaky,5
20930,NationalSecurityAgency_timely,MetricTest.testJson,"    @Test
    public void testJson() throws IOException {
        ObjectMapper mapper = new ObjectMapper();

        String expectedJson = ""{\""name\"":\""m1\"",\""timestamp\"":1,\""measure\"":1.0,\""tags\"":[{\""k1\"":\""v1\""}]}"";

        Metric m1 = Metric.newBuilder().name(""m1"").tag(""k1"", ""v1"").value(1, 1.0).build();

        Metric expectedMetric = mapper.readValue(expectedJson, Metric.class);

        assertTrue(m1.equals(expectedMetric));

        expectedJson = ""{\""name\"":\""m1\"",\""tags\"":[{\""k1\"":\""v1\""}],\""timestamp\"":5,\""measure\"":5.0}"";
        expectedMetric = mapper.readValue(expectedJson, Metric.class);

        assertEquals((long) expectedMetric.getValue().getTimestamp(), 5L);
        assertEquals(expectedMetric.getValue().getMeasure(), 5.0D, 0.0);

    }
",non-flaky,5
20931,NationalSecurityAgency_timely,SerializationTest.testBasicAuth,"    @Test
    public void testBasicAuth() throws Exception {
        BasicAuthLogin login = new BasicAuthLogin();
        login.setUsername(""test"");
        login.setPassword(""pass"");
        testSerialization(login);
    }
",non-flaky,5
20932,NationalSecurityAgency_timely,SerializationTest.testCreateSubscription,"    @Test
    public void testCreateSubscription() throws Exception {
        CreateSubscription create = new CreateSubscription();
        create.setSubscriptionId(""1234"");
        testSerialization(create);
    }
",non-flaky,5
20933,NationalSecurityAgency_timely,SerializationTest.testCloseSubscription,"    @Test
    public void testCloseSubscription() throws Exception {
        CloseSubscription close = new CloseSubscription();
        close.setSubscriptionId(""1234"");
        testSerialization(close);
    }
",non-flaky,5
20934,NationalSecurityAgency_timely,SerializationTest.testAddSubscription,"    @Test
    public void testAddSubscription() throws Exception {
        AddSubscription add = new AddSubscription();
        add.setSubscriptionId(""1234"");
        add.setMetric(""sys.cpu.user"");
        testSerialization(add);
    }
",non-flaky,5
20935,NationalSecurityAgency_timely,SerializationTest.testRemoveSubscription,"    @Test
    public void testRemoveSubscription() throws Exception {
        RemoveSubscription remove = new RemoveSubscription();
        remove.setSubscriptionId(""1234"");
        remove.setMetric(""sys.cpu.user"");
        testSerialization(remove);
    }
",non-flaky,5
20936,NationalSecurityAgency_timely,AuthCacheTest.testSessionIdNull,"    @Test(expected = IllegalArgumentException.class)
    public void testSessionIdNull() throws Exception {
        AuthCache.getAuthorizations("""");
    }
",non-flaky,5
20937,NationalSecurityAgency_timely,AuthCacheTest.testGetAuths,"    @Test
    public void testGetAuths() throws Exception {
        Authorizations a = AuthCache.getAuthorizations(cookie);
        Assert.assertEquals(""A,B,C"", a.toString());
    }
",non-flaky,5
20938,NationalSecurityAgency_timely,AuthenticationServiceTest.testBasicAuthenticationFailure,"    @Test(expected = BadCredentialsException.class)
    public void testBasicAuthenticationFailure() {
        UsernamePasswordAuthenticationToken token = new UsernamePasswordAuthenticationToken(""test"", ""test2"");
        AuthenticationService.getAuthenticationManager().authenticate(token);
    }
",non-flaky,5
20939,NationalSecurityAgency_timely,AuthenticationServiceTest.testBasicAuthenticationLogin,"    @Test
    public void testBasicAuthenticationLogin() {
        UsernamePasswordAuthenticationToken token = new UsernamePasswordAuthenticationToken(""test"", ""test1"");
        Authentication auth = AuthenticationService.getAuthenticationManager().authenticate(token);
        Collection<? extends GrantedAuthority> authorizations = auth.getAuthorities();
        authorizations.forEach(a -> {
            Assert.assertTrue(
                    a.getAuthority().equals(""A"") || a.getAuthority().equals(""B"") || a.getAuthority().equals(""C""));
        });
    }
",non-flaky,5
20940,NationalSecurityAgency_timely,AuthenticationServiceTest.testX509AuthenticationLogin,"    @Test
    public void testX509AuthenticationLogin() {
        PreAuthenticatedAuthenticationToken token = new PreAuthenticatedAuthenticationToken(""example.com"",
                ""doesn't matter what I put here"");
        Authentication auth = AuthenticationService.getAuthenticationManager().authenticate(token);
        Collection<? extends GrantedAuthority> authorizations = auth.getAuthorities();
        authorizations.forEach(a -> {
            Assert.assertTrue(
                    a.getAuthority().equals(""D"") || a.getAuthority().equals(""E"") || a.getAuthority().equals(""F""));
        });
    }
",non-flaky,5
20941,NationalSecurityAgency_timely,AuthenticationServiceTest.testX509AuthenticationLoginFailed,"    @Test(expected = UsernameNotFoundException.class)
    public void testX509AuthenticationLoginFailed() {
        PreAuthenticatedAuthenticationToken token = new PreAuthenticatedAuthenticationToken(""bad.example.com"",
                ""doesn't matter what I put here"");
        Authentication auth = AuthenticationService.getAuthenticationManager().authenticate(token);
        Collection<? extends GrantedAuthority> authorizations = auth.getAuthorities();
        authorizations.forEach(a -> {
            Assert.assertTrue(
                    a.getAuthority().equals(""D"") || a.getAuthority().equals(""E"") || a.getAuthority().equals(""F""));
        });
    }
",non-flaky,5
20942,NationalSecurityAgency_timely,TimeSeriesGroupingIteratorTest.testMovingAverage,"    @Test
    public void testMovingAverage() throws Exception {
        SortedMapIterator source = new SortedMapIterator(table);
        TimeSeriesGroupingIterator iter = new TimeSeriesGroupingIterator();
        IteratorSetting settings = new IteratorSetting(100, TimeSeriesGroupingIterator.class);
        settings.addOption(TimeSeriesGroupingIterator.FILTER, ""0.20,0.20,0.20,0.20,0.20"");
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);

        for (int i = 4; i < 100; i++) {
            checkNextResult(iter, new double[] { i - 4, i - 3, i - 2, i - 1, i });
        }
        assertFalse(iter.hasTop());
    }
",non-flaky,5
20943,NationalSecurityAgency_timely,TimeSeriesGroupingIteratorTest.testMultipleTimeSeriesMovingAverage,"    @Test
    public void testMultipleTimeSeriesMovingAverage() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        List<Tag> tags1 = new ArrayList<>();
        tags1.add(new Tag(""host"", ""r01n01""));
        List<Tag> tags2 = new ArrayList<>();
        tags2.add(new Tag(""host"", ""r01n02""));
        for (int i = 0; i < 100; i++) {
            ts += 1000;
            Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags1);
            byte[] row = MetricAdapter.encodeRowKey(m);
            Key k = new Key(row, tags1.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
            table.put(k, v);
            Metric m2 = new Metric(""sys.cpu.user"", ts, i * 2.0D, tags2);
            byte[] row2 = MetricAdapter.encodeRowKey(m2);
            Key k2 = new Key(row2, tags2.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v2 = new Value(MetricAdapter.encodeValue(m2.getValue().getMeasure()));
            table.put(k2, v2);
        }
        SortedMapIterator source = new SortedMapIterator(table);
        TimeSeriesGroupingIterator iter = new TimeSeriesGroupingIterator();
        IteratorSetting settings = new IteratorSetting(100, TimeSeriesGroupingIterator.class);
        settings.addOption(TimeSeriesGroupingIterator.FILTER, ""0.20,0.20,0.20,0.20,0.20"");
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);

        // this section changed when the key structure changed so that identical
        // colFam values sorted consecutively within an given time period
        for (int i = 4; i < 100; i++) {
            checkNextResult(iter, new double[] { i - 4, i - 3, i - 2, i - 1, i });
        }
        for (int i = 4; i < 100; i++) {
            checkNextResult(iter, new double[] { (i - 4) * 2, (i - 3) * 2, (i - 2) * 2, (i - 1) * 2, i * 2 });
        }
        assertFalse(iter.hasTop());

    }
",non-flaky,5
20944,NationalSecurityAgency_timely,TimeSeriesGroupingIteratorTest.testTimeSeriesDropOff,"    @Test
    public void testTimeSeriesDropOff() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        List<Tag> tags1 = new ArrayList<>();
        tags1.add(new Tag(""host"", ""r01n01""));
        List<Tag> tags2 = new ArrayList<>();
        tags2.add(new Tag(""host"", ""r01n02""));
        for (int i = 0; i < 100; i++) {
            ts += 1000;
            Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags1);
            byte[] row = MetricAdapter.encodeRowKey(m);
            Key k = new Key(row, tags1.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
            table.put(k, v);
            if (i < 50) {
                // only populate this series 50 times
                Metric m2 = new Metric(""sys.cpu.user"", ts, i * 2.0D, tags2);
                byte[] row2 = MetricAdapter.encodeRowKey(m2);
                Key k2 = new Key(row2, tags2.get(0).join().getBytes(StandardCharsets.UTF_8),
                        MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v2 = new Value(MetricAdapter.encodeValue(m2.getValue().getMeasure()));
                table.put(k2, v2);
            }
        }

        SortedMapIterator source = new SortedMapIterator(table);
        TimeSeriesGroupingIterator iter = new TimeSeriesGroupingIterator();
        IteratorSetting settings = new IteratorSetting(100, TimeSeriesGroupingIterator.class);
        settings.addOption(TimeSeriesGroupingIterator.FILTER, ""0.20,0.20,0.20,0.20,0.20"");
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);

        // this section changed when the key structure changed so that identical
        // colFam values sorted consecutively within an given time period
        for (int i = 4; i < 100; i++) {
            System.out.println(i);
            checkNextResult(iter, new double[] { i - 4, i - 3, i - 2, i - 1, i });
        }
        for (int i = 4; i < 50; i++) {
            System.out.println(i);
            checkNextResult(iter, new double[] { (i - 4) * 2, (i - 3) * 2, (i - 2) * 2, (i - 1) * 2, i * 2 });
        }
        assertFalse(iter.hasTop());
    }
",non-flaky,5
20945,NationalSecurityAgency_timely,TimeSeriesGroupingIteratorTest.testAdditionalTimeSeries,"    @Test
    public void testAdditionalTimeSeries() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        List<Tag> tags1 = new ArrayList<>();
        tags1.add(new Tag(""host"", ""r01n01""));
        List<Tag> tags2 = new ArrayList<>();
        tags2.add(new Tag(""host"", ""r01n02""));
        for (int i = 0; i < 100; i++) {
            ts += 1000;
            Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags1);
            byte[] row = MetricAdapter.encodeRowKey(m);
            Key k = new Key(row, tags1.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
            table.put(k, v);
            if (i > 50) {
                // only populate this series 50 times
                Metric m2 = new Metric(""sys.cpu.user"", ts, i * 2.0D, tags2);
                byte[] row2 = MetricAdapter.encodeRowKey(m2);
                Key k2 = new Key(row2, tags2.get(0).join().getBytes(StandardCharsets.UTF_8),
                        MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v2 = new Value(MetricAdapter.encodeValue(m2.getValue().getMeasure()));
                table.put(k2, v2);
            }
        }
        SortedMapIterator source = new SortedMapIterator(table);
        TimeSeriesGroupingIterator iter = new TimeSeriesGroupingIterator();
        IteratorSetting settings = new IteratorSetting(100, TimeSeriesGroupingIterator.class);
        settings.addOption(TimeSeriesGroupingIterator.FILTER, ""0.20,0.20,0.20,0.20,0.20"");
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);

        // this section changed when the key structure changed so that identical
        // colFam values sorted consecutively within an given time period
        for (int i = 4; i < 100; i++) {
            checkNextResult(iter, new double[] { i - 4, i - 3, i - 2, i - 1, i });
        }
        for (int i = 55; i < 100; i++) {
            checkNextResult(iter, new double[] { (i - 4) * 2, (i - 3) * 2, (i - 2) * 2, (i - 1) * 2, i * 2 });
        }

        assertFalse(iter.hasTop());

    }
",non-flaky,5
20946,NationalSecurityAgency_timely,TimeSeriesGroupingIteratorTest.testManySparseTimeSeries,"    @Test
    public void testManySparseTimeSeries() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        List<Tag> tags1 = new ArrayList<>();
        tags1.add(new Tag(""host"", ""r01n01""));
        List<Tag> tags2 = new ArrayList<>();
        tags2.add(new Tag(""host"", ""r01n02""));
        List<Tag> tags3 = new ArrayList<>();
        tags3.add(new Tag(""host"", ""r01n03""));
        for (int i = 0; i < 100; i++) {
            ts += 1000;
            Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags1);
            byte[] row = MetricAdapter.encodeRowKey(m);
            Key k = new Key(row, tags1.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
            table.put(k, v);
            // jitter the time on the second time series
            Metric m2 = new Metric(""sys.cpu.user"", ts + 50, i * 2.0D, tags2);
            byte[] row2 = MetricAdapter.encodeRowKey(m2);
            Key k2 = new Key(row2, tags2.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts + 50);
            Value v2 = new Value(MetricAdapter.encodeValue(m2.getValue().getMeasure()));
            table.put(k2, v2);
            Metric m3 = new Metric(""sys.cpu.user"", ts, i * 3.0D, tags3);
            byte[] row3 = MetricAdapter.encodeRowKey(m3);
            Key k3 = new Key(row3, tags3.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v3 = new Value(MetricAdapter.encodeValue(m3.getValue().getMeasure()));
            table.put(k3, v3);
        }

        SortedMapIterator source = new SortedMapIterator(table);
        TimeSeriesGroupingIterator iter = new TimeSeriesGroupingIterator();
        IteratorSetting settings = new IteratorSetting(100, TimeSeriesGroupingIterator.class);
        settings.addOption(TimeSeriesGroupingIterator.FILTER, ""0.20,0.20,0.20,0.20,0.20"");
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);

        LinkedList<Double> first = new LinkedList<>();
        first.add(0D);
        first.add(1D);
        first.add(2D);
        first.add(3D);
        first.add(4D);
        LinkedList<Double> second = new LinkedList<>();
        second.add(0D);
        second.add(2D);
        second.add(4D);
        second.add(6D);
        second.add(8D);
        LinkedList<Double> third = new LinkedList<>();
        third.add(0D);
        third.add(3D);
        third.add(6D);
        third.add(9D);
        third.add(12D);

        // this section changed when the key structure changed so that identical
        // colFam values sorted consecutively within an given time period
        for (int i = 4; i < 100; i++) {
            checkNextResult(iter, first);
            shiftAndAdd(first, 1);
        }
        for (int i = 4; i < 100; i++) {
            System.out.println(i);
            checkNextResult(iter, second);
            shiftAndAdd(second, 2);
        }
        for (int i = 4; i < 100; i++) {
            checkNextResult(iter, third);
            shiftAndAdd(third, 3);
        }
        assertFalse(iter.hasTop());
    }
",non-flaky,5
20947,NationalSecurityAgency_timely,RateIteratorTest.testConstantTimeRate,"    @Test
    public void testConstantTimeRate() throws Exception {
        SortedMapIterator source = new SortedMapIterator(table);
        RateIterator iter = new RateIterator();
        IteratorSetting settings = new IteratorSetting(100, RateIterator.class);
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);
        for (int i = 0; i < 99; i++) {
            assertTrue(iter.hasTop());
            assertEquals(0.001D, MetricAdapter.decodeValue(iter.getTopValue().get()), 0.0D);
            iter.next();
        }
        assertFalse(iter.hasTop());
    }
",non-flaky,5
20948,NationalSecurityAgency_timely,RateIteratorTest.testRateWithTimeJitter,"    @Test
    public void testRateWithTimeJitter() throws Exception {
        table.clear();
        Random r = new Random(111131131L);
        long ts = System.currentTimeMillis();
        for (int i = 1; i <= 100; i++) {
            ts += 1000 + r.nextInt(100);
            Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags);
            byte[] row = MetricAdapter.encodeRowKey(m);
            Key k = new Key(row, tags.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
            table.put(k, v);
        }

        SortedMapIterator source = new SortedMapIterator(table);
        source.seek(new Range(), EMPTY_COL_FAMS, true);
        long prevTs = -1L;
        Double prevValue = null;
        List<Double> expected = new ArrayList<>();
        while (source.hasTop()) {
            Key k = source.getTopKey();
            Value v = source.getTopValue();
            if (prevTs != -1L) {
                Double thisValue = MetricAdapter.decodeValue(v.get());
                expected.add((thisValue + (prevValue * -1)) / (k.getTimestamp() - prevTs));
            }
            prevTs = k.getTimestamp();
            prevValue = MetricAdapter.decodeValue(v.get());
            source.next();
        }

        assertEquals(99, expected.size());
        source = new SortedMapIterator(table);
        RateIterator iter = new RateIterator();
        IteratorSetting settings = new IteratorSetting(100, RateIterator.class);
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);
        for (int i = 0; i < 99; i++) {
            assertTrue(iter.hasTop());
            assertEquals(expected.get(i), MetricAdapter.decodeValue(iter.getTopValue().get()), 0.0D);
            iter.next();
        }
        assertFalse(iter.hasTop());
    }
",non-flaky,5
20949,NationalSecurityAgency_timely,RateIteratorTest.testCounterRate,"    @Test
    public void testCounterRate() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        for (int j = 0; j < 10; j++) {
            for (int i = 1; i <= 10; i++) {
                ts += 1000;
                Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags);
                byte[] row = MetricAdapter.encodeRowKey(m);
                Key k = new Key(row, tags.get(0).join().getBytes(StandardCharsets.UTF_8),
                        MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
                table.put(k, v);
            }
        }

        SortedMapIterator source = new SortedMapIterator(table);
        RateIterator iter = new RateIterator();
        IteratorSetting settings = new IteratorSetting(100, RateIterator.class);

        QueryRequest.RateOption option = new QueryRequest.RateOption();
        option.setCounter(true);
        option.setCounterMax(0);
        RateIterator.setRateOptions(settings, option);

        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);
        for (int i = 0; i < 99; i++) {
            assertTrue(iter.hasTop());
            assertEquals(0.001D, MetricAdapter.decodeValue(iter.getTopValue().get()), 0.0D);
            iter.next();
        }
        assertFalse(iter.hasTop());
    }
",non-flaky,5
20950,NationalSecurityAgency_timely,RateIteratorTest.testCounterRateWithMax,"    @Test
    public void testCounterRateWithMax() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        for (int j = 0; j < 10; j++) {
            for (int i = 0; i < 10; i++) {
                ts += 1000;
                Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags);
                byte[] row = MetricAdapter.encodeRowKey(m);
                Key k = new Key(row, tags.get(0).join().getBytes(StandardCharsets.UTF_8),
                        MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
                table.put(k, v);
            }
        }

        SortedMapIterator source = new SortedMapIterator(table);
        RateIterator iter = new RateIterator();
        IteratorSetting settings = new IteratorSetting(100, RateIterator.class);

        QueryRequest.RateOption option = new QueryRequest.RateOption();
        option.setCounter(true);
        option.setCounterMax(10);
        RateIterator.setRateOptions(settings, option);

        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);
        for (int i = 0; i < 99; i++) {
            assertTrue(iter.hasTop());
            assertEquals(0.001D, MetricAdapter.decodeValue(iter.getTopValue().get()), 0.0D);
            iter.next();
        }
        assertFalse(iter.hasTop());
    }
",non-flaky,5
20951,NationalSecurityAgency_timely,RateIteratorTest.testCounterRateWithReset,"    @Test
    public void testCounterRateWithReset() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        for (int j = 0; j < 10; j++) {
            for (int i = 0; i < 10; i++) {
                ts += 1000;
                Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags);
                byte[] row = MetricAdapter.encodeRowKey(m);
                Key k = new Key(row, tags.get(0).join().getBytes(StandardCharsets.UTF_8),
                        MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
                table.put(k, v);
            }
        }

        SortedMapIterator source = new SortedMapIterator(table);
        RateIterator iter = new RateIterator();
        IteratorSetting settings = new IteratorSetting(100, RateIterator.class);

        QueryRequest.RateOption option = new QueryRequest.RateOption();
        option.setCounter(true);
        option.setCounterMax(Long.MAX_VALUE);
        option.setResetValue(1);
        RateIterator.setRateOptions(settings, option);

        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);
        for (int i = 0; i < 99; i++) {
            assertTrue(iter.hasTop());
            assertEquals(((i + 1) % 10 == 0 ? 0.0D : 0.001D), MetricAdapter.decodeValue(iter.getTopValue().get()),
                    0.0D);
            iter.next();
        }
        assertFalse(iter.hasTop());
    }
",non-flaky,5
20952,NationalSecurityAgency_timely,MetricAgeOffIteratorTest.testDefaultMissing,"    @Test(expected = IllegalArgumentException.class)
    public void testDefaultMissing() throws Exception {
        SortedMap<Key, Value> table = new TreeMap<>();
        SortedKeyValueIterator<Key, Value> source = new SortedMapIterator(table);
        MetricAgeOffIterator iter = new MetricAgeOffIterator();
        HashMap<String, String> options = new HashMap<>();
        iter.init(source, options, null);
    }
",non-flaky,5
20953,NationalSecurityAgency_timely,MetricAgeOffIteratorTest.testDefault,"    @Test
    public void testDefault() throws Exception {
        SortedMap<Key, Value> table = new TreeMap<>();
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0], new byte[0], new byte[0],
                TEST_TIME), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 1), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 1), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 2), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 2), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 3), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 4), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 4), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 5), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 5), EMPTY_VALUE);

        SortedKeyValueIterator<Key, Value> source = new SortedMapIterator(table);
        MetricAgeOffIterator iter = new MetricAgeOffIterator();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffIterator.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        iter.init(source, options, null);
        iter.seek(new Range(), columnFamilies, true);
        int seen = 0;
        while (iter.hasTop()) {
            Key k = iter.getTopKey();
            Assert.assertTrue(k.getTimestamp() >= TEST_TIME && k.getTimestamp() <= TEST_TIME + 5);
            seen++;
            iter.next();
        }
        Assert.assertEquals(6, seen);
    }
",non-flaky,5
20954,NationalSecurityAgency_timely,MetricAgeOffIteratorTest.testMixed,"    @Test
    public void testMixed() throws Exception {
        SortedMap<Key, Value> table = new TreeMap<>();
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME), new byte[0], new byte[0], new byte[0],
                TEST_TIME), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 1), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 1), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 2), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 2), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 3), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 3), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 4), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 4), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 5), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 5), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0], new byte[0], new byte[0],
                TEST_TIME), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 1), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 1), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 2), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 2), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 3), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 4), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 4), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 5), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 5), EMPTY_VALUE);

        SortedKeyValueIterator<Key, Value> source = new SortedMapIterator(table);
        MetricAgeOffIterator iter = new MetricAgeOffIterator();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffIterator.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        iter.init(source, options, null);
        iter.seek(new Range(), columnFamilies, true);
        int seen = 0;
        while (iter.hasTop()) {
            Key k = iter.getTopKey();
            Assert.assertTrue(k.getTimestamp() >= TEST_TIME && k.getTimestamp() <= TEST_TIME + 5);
            seen++;
            iter.next();
        }
        Assert.assertEquals(12, seen);
    }
",non-flaky,5
20955,NationalSecurityAgency_timely,MetricAgeOffIteratorTest.testAgeoffMixed,"    @Test
    public void testAgeoffMixed() throws Exception {
        SortedMap<Key, Value> table = new TreeMap<>();
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME - (3 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME - (3 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME - (2 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME - (2 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME - (1 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME - (1 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME), new byte[0], new byte[0], new byte[0],
                TEST_TIME), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + ONE_DAY), new byte[0], new byte[0],
                new byte[0], TEST_TIME + ONE_DAY), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + (2 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME + (2 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME - (3 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME - (3 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME - (2 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME - (2 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME - (1 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME - (1 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0], new byte[0], new byte[0],
                TEST_TIME), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + ONE_DAY), new byte[0], new byte[0],
                new byte[0], TEST_TIME + ONE_DAY), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + (2 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME + (2 * ONE_DAY)), EMPTY_VALUE);

        SortedKeyValueIterator<Key, Value> source = new SortedMapIterator(table);
        MetricAgeOffIterator iter = new MetricAgeOffIterator();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffIterator.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        options.put(MetricAgeOffIterator.AGE_OFF_PREFIX + ""sys.cpu.user"", Integer.toString(2 * ONE_DAY));
        iter.init(source, options, null);
        iter.seek(new Range(), columnFamilies, true);
        int seen = 0;
        while (iter.hasTop()) {
            Key k = iter.getTopKey();
            Assert.assertTrue(
                    k.getTimestamp() >= (TEST_TIME - (2 * ONE_DAY)) && k.getTimestamp() <= TEST_TIME + (2 * ONE_DAY));
            seen++;
            iter.next();
        }
        Assert.assertEquals(7, seen);

    }
",non-flaky,5
20956,NationalSecurityAgency_timely,MetricAgeOffIteratorTest.testSeekPastEndKey,"    @Test
    public void testSeekPastEndKey() throws Exception {
        SortedMap<Key, Value> table = new TreeMap<>();
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0], new byte[0], new byte[0],
                TEST_TIME), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 1), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 1), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 2), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 2), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 3), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 4), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 4), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 5), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 5), EMPTY_VALUE);

        SortedKeyValueIterator<Key, Value> source = new SortedMapIterator(table);
        MetricAgeOffIterator iter = new MetricAgeOffIterator();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffIterator.AGE_OFF_PREFIX + ""default"", Integer.toString(1));
        iter.init(source, options, null);
        iter.seek(new Range(new Key(""sys.cpu.user""), true,
                new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0], new byte[0],
                        new byte[0], TEST_TIME + 3),
                true), columnFamilies, true);
        int seen = 0;
        while (iter.hasTop()) {
            Key k = iter.getTopKey();
            Assert.assertTrue(k.getTimestamp() >= TEST_TIME && k.getTimestamp() <= TEST_TIME + 5);
            seen++;
            iter.next();
        }
        Assert.assertEquals(0, seen);
    }
",non-flaky,5
20957,NationalSecurityAgency_timely,MetricAgeOffFilterTest.testDefaultMissing,"    @Test(expected = IllegalArgumentException.class)
    public void testDefaultMissing() throws Exception {
        MetricAgeOffFilter filter = new MetricAgeOffFilter();
        HashMap<String, String> options = new HashMap<>();
        filter.init(null, options, null);
    }
",non-flaky,5
20958,NationalSecurityAgency_timely,MetricAgeOffFilterTest.testDefault,"    @Test
    public void testDefault() throws Exception {
        MetricAgeOffFilter filter = new MetricAgeOffFilter();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffFilter.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        filter.init(null, options, null);
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0],
                new byte[0], new byte[0], TEST_TIME), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 1), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 1), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 2), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 2), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 3), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 4), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 4), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 5), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 5), null));
    }
",non-flaky,5
20959,NationalSecurityAgency_timely,MetricAgeOffFilterTest.testMixed,"    @Test
    public void testMixed() throws Exception {
        MetricAgeOffFilter filter = new MetricAgeOffFilter();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffFilter.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        filter.init(null, options, null);
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME), new byte[0],
                new byte[0], new byte[0], TEST_TIME), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 1), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 1), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 2), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 2), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 3), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 3), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 4), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 4), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 5), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 5), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0],
                new byte[0], new byte[0], TEST_TIME), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 1), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 1), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 2), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 2), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 3), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 4), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 4), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 5), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 5), null));
    }
",non-flaky,5
20960,NationalSecurityAgency_timely,MetricAgeOffFilterTest.testAgeoffMixed,"    @Test
    public void testAgeoffMixed() throws Exception {
        MetricAgeOffFilter filter = new MetricAgeOffFilter();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffFilter.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        options.put(MetricAgeOffFilter.AGE_OFF_PREFIX + ""sys.cpu.user"", Integer.toString(2 * ONE_DAY));
        filter.init(null, options, null);
        assertFalse(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME - (3 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME - (3 * ONE_DAY)), null));
        assertFalse(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME - (2 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME - (2 * ONE_DAY)), null));
        assertFalse(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME - (1 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME - (1 * ONE_DAY)), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME), new byte[0],
                new byte[0], new byte[0], TEST_TIME), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + ONE_DAY), new byte[0],
                new byte[0], new byte[0], TEST_TIME + ONE_DAY), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + (2 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME + (2 * ONE_DAY)), null));
        assertFalse(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME - (3 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME - (3 * ONE_DAY)), null));
        assertFalse(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME - (2 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME - (2 * ONE_DAY)), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME - (1 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME - (1 * ONE_DAY)), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0],
                new byte[0], new byte[0], TEST_TIME), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + ONE_DAY), new byte[0],
                new byte[0], new byte[0], TEST_TIME + ONE_DAY), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + (2 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME + (2 * ONE_DAY)), null));
    }
",non-flaky,5
20961,NationalSecurityAgency_timely,TagMatchingTest.testRegex1,"    @Test
    public void testRegex1() throws Exception {
        String tags = ""tag1=value1,tag2=value2,tag3=value3"";
        StringBuffer pattern = new StringBuffer();
        pattern.append(""(^|.*,)"");
        pattern.append(""tag2"");
        pattern.append(""="");
        pattern.append(""value2"");
        pattern.append(""(,.*|$)"");
        Pattern p = Pattern.compile(pattern.toString());
        assertTrue(p.matcher(tags).matches());
    }
",non-flaky,5
20962,NationalSecurityAgency_timely,TagMatchingTest.testRegex2,"    @Test
    public void testRegex2() throws Exception {
        String tags = ""tag1=value1,tag2=value2,tag3=value3"";
        StringBuffer pattern = new StringBuffer();
        pattern.append(""(^|.*,)"");
        pattern.append(""tag2"");
        pattern.append(""="");
        pattern.append(""value\\d"");
        pattern.append(""(,.*|$)"");
        Pattern p = Pattern.compile(pattern.toString());
        assertTrue(p.matcher(tags).matches());
    }
",non-flaky,5
20963,NationalSecurityAgency_timely,TagMatchingTest.testRegex3,"    @Test
    public void testRegex3() throws Exception {
        String tags = ""tag1=value1,tag2=value2,tag3=value3"";
        StringBuffer pattern = new StringBuffer();
        pattern.append(""(^|.*,)"");
        pattern.append(""tag2"");
        pattern.append(""="");
        pattern.append(""(value2|value3)"");
        pattern.append(""(,.*|$)"");
        Pattern p = Pattern.compile(pattern.toString());
        assertTrue(p.matcher(tags).matches());
    }
",non-flaky,5
20964,NationalSecurityAgency_timely,TestWrappedGorillaCompressor.testSerialization,"    @Test
    public void testSerialization() throws IOException, ClassNotFoundException {

        long start = System.currentTimeMillis();
        WrappedGorillaCompressor originalCompressor = new WrappedGorillaCompressor(start);
        long t = start;

        for (int x = 1; x <= 10; x++) {
            originalCompressor.addValue(t, 10);
            t = t + 1000;
        }
        originalCompressor.close();
        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
        ObjectOutputStream oos = new ObjectOutputStream(outputStream);
        oos.writeObject(originalCompressor);
        oos.close();

        ByteArrayInputStream inputStream = new ByteArrayInputStream(outputStream.toByteArray());
        ObjectInputStream ois = new ObjectInputStream(inputStream);
        WrappedGorillaCompressor copyCompressor = (WrappedGorillaCompressor) ois.readObject();

        GorillaDecompressor d = new GorillaDecompressor(new LongArrayInput(copyCompressor.getCompressorOutput()));

        LinkedList<Pair> q = new LinkedList<>();
        Pair p = null;
        while ((p = d.readPair()) != null) {
            q.add(p);
        }

        Assert.assertEquals(10, q.size());
        Assert.assertEquals(start, q.peekFirst().getTimestamp());
        Assert.assertEquals(start + 9000, q.peekLast().getTimestamp());
    }
",non-flaky,5
20965,NationalSecurityAgency_timely,TestWrappedGorillaCompressor.testHDFSWrite,"    @Test
    public void testHDFSWrite() throws Exception {

        try {
            Configuration configuration = new Configuration();
            FileSystem fs = FileSystem.get(new URI(""hdfs://localhost:8020""), configuration);
            GorillaStore store = new GorillaStore(fs, ""mymetric"", new timely.Configuration());

            long start = System.currentTimeMillis();
            WrappedGorillaCompressor originalCompressor = new WrappedGorillaCompressor(start);
            long t = start;

            for (int x = 1; x <= 10; x++) {
                originalCompressor.addValue(t, 10);
                t = t + 1000;
            }
            originalCompressor.close();

            store.writeCompressor(""mymetric"", originalCompressor);

            List<WrappedGorillaCompressor> archived = store.readCompressors(fs, new Path(""/timely/cache/mymetric""));

            for (WrappedGorillaCompressor c : archived) {

                GorillaDecompressor d = new GorillaDecompressor(new LongArrayInput(c.getCompressorOutput()));
                LinkedList<Pair> q = new LinkedList<>();
                Pair p = null;
                while ((p = d.readPair()) != null) {
                    q.add(p);
                }
            }
        } catch (Exception e) {
            System.out.println(e.getMessage());
        }
    }
",non-flaky,5
20966,NationalSecurityAgency_timely,TestDataStoreCacheIterator.testDownsampleIterator,"    @Test
    public void testDownsampleIterator() throws TimelyException {

        long BASETIME = System.currentTimeMillis();
        // align basetime to a downsample period
        BASETIME = BASETIME - (BASETIME % (1000 * 60));
        DataStoreCache mmStore = getMetricMemoryStore1(BASETIME);

        QueryRequest query = new QueryRequest();
        query.setStart(BASETIME);
        query.setEnd(BASETIME + 1440000);
        query.setMsResolution(true);
        QueryRequest.SubQuery subQuery = new QueryRequest.SubQuery();
        subQuery.setDownsample(Optional.of(""1m-avg""));
        subQuery.setMetric(""metric.number.1"");
        subQuery.addTag(""host"", "".*"");
        query.setQueries(Collections.singleton(subQuery));

        SortedKeyValueIterator<org.apache.accumulo.core.data.Key, org.apache.accumulo.core.data.Value> itr = null;
        try {
            long firstTimestamp = -1;
            long lastTimestamp = -1;
            int numSamples = 0;
            itr = mmStore.setupIterator(query, subQuery, new Authorizations(), Long.MAX_VALUE);
            while (itr.hasTop()) {
                itr.next();
                Map<Set<Tag>, Aggregation> aggregations = AggregationIterator.decodeValue(itr.getTopValue());
                for (Map.Entry<Set<Tag>, Aggregation> entry : aggregations.entrySet()) {
                    for (Sample s : entry.getValue()) {
                        numSamples++;
                        if (firstTimestamp == -1) {
                            firstTimestamp = s.timestamp;
                        }
                        lastTimestamp = s.timestamp;
                    }
                }
            }
            Assert.assertEquals(""First timestamp incorrect"", BASETIME, firstTimestamp);
            Assert.assertEquals(""Last timestamp incorrect"", BASETIME + 1440000, lastTimestamp);
            Assert.assertEquals(""Number of samples incorrect"", 50, numSamples);
        } catch (IOException | ClassNotFoundException e) {
            LOG.error(""exception in test"", e);
        }
    }
",non-flaky,5
20967,NationalSecurityAgency_timely,TestDataStoreCacheIterator.testRateIterator,"    @Test
    public void testRateIterator() throws TimelyException {

        long BASETIME = System.currentTimeMillis();
        // align basetime to a downsample period
        BASETIME = BASETIME - (BASETIME % 1000);
        DataStoreCache mmStore = getMetricMemoryStore2(BASETIME);

        QueryRequest query = new QueryRequest();
        query.setStart(BASETIME);
        query.setEnd(BASETIME + 1440000);
        query.setMsResolution(true);
        QueryRequest.SubQuery subQuery = new QueryRequest.SubQuery();
        subQuery.setDownsample(Optional.of(""1ms-avg""));
        subQuery.setMetric(""metric.number.1"");
        subQuery.addTag(""host"", "".*"");
        QueryRequest.RateOption rateOption = new QueryRequest.RateOption();
        rateOption.setCounter(false);
        subQuery.setRate(true);
        subQuery.setRateOptions(rateOption);
        query.setQueries(Collections.singleton(subQuery));

        int x = 0;
        SortedKeyValueIterator<org.apache.accumulo.core.data.Key, org.apache.accumulo.core.data.Value> itr = null;
        try {
            // long firstTimestamp = Long.MAX_VALUE;
            long firstTimestamp = -1;
            long lastTimestamp = -1;
            int numSamples = 0;
            itr = mmStore.setupIterator(query, subQuery, new Authorizations(), Long.MAX_VALUE);
            while (itr.hasTop()) {
                itr.next();
                Map<Set<Tag>, Aggregation> aggregations = AggregationIterator.decodeValue(itr.getTopValue());
                for (Map.Entry<Set<Tag>, Aggregation> entry : aggregations.entrySet()) {
                    for (Sample s : entry.getValue()) {
                        numSamples++;
                        if (firstTimestamp == -1) {
                            firstTimestamp = s.timestamp;
                        }
                        lastTimestamp = s.timestamp;
                        // if (s.timestamp < firstTimestamp) {
                        // firstTimestamp = s.timestamp;
                        // }
                        // if (s.timestamp > lastTimestamp) {
                        // lastTimestamp = s.timestamp;
                        // }
                    }
                }
            }
            Assert.assertEquals(""First timestamp incorrect"", BASETIME + 1000, firstTimestamp);
            Assert.assertEquals(""Last timestamp incorrect"", BASETIME + 1440000, lastTimestamp);
            Assert.assertEquals(""Number of samples incorrect"", 2880, numSamples);
        } catch (IOException | ClassNotFoundException e) {
            LOG.error(""exception in test"", e);
        }
    }
",non-flaky,5
20968,NationalSecurityAgency_timely,TestGorillaStore.testOne,"    @Test
    public void testOne() {

        GorillaStore gStore = new GorillaStore();

        long now = System.currentTimeMillis();
        gStore.addValue(now += 100, 1.123);
        gStore.addValue(now += 100, 2.314);
        gStore.addValue(now += 100, 3.856);
        gStore.addValue(now += 100, 4.7678);
        gStore.addValue(now += 100, 5.8966);
        gStore.addValue(now += 100, 6.0976);
        gStore.addValue(now += 100, 1.2345);

        List<WrappedGorillaDecompressor> decompressorList = gStore.getDecompressors(0, Long.MAX_VALUE);
        Pair pair = null;
        for (WrappedGorillaDecompressor w : decompressorList) {
            while ((pair = w.readPair()) != null) {
                System.out.println(pair.getTimestamp() + "" --> "" + pair.getDoubleValue());
            }
        }

        System.out.println(""---------------"");

        gStore.addValue(now += 100, 2.3456);
        gStore.addValue(now += 100, 3.4567);

        decompressorList = gStore.getDecompressors(0, Long.MAX_VALUE);
        pair = null;
        for (WrappedGorillaDecompressor w : decompressorList) {
            while ((pair = w.readPair()) != null) {
                System.out.println(pair.getTimestamp() + "" --> "" + pair.getDoubleValue());
            }
        }
    }
",non-flaky,5
20969,NationalSecurityAgency_timely,TestGorillaStore.testExtentOfStorage,"    @Test
    public void testExtentOfStorage() {

        GorillaStore gStore = new GorillaStore();

        HashMap<String, String> tags = new HashMap<>();
        tags.put(""host"", ""localhost"");

        long start = System.currentTimeMillis();
        long timestamp = start;

        for (int x = 1; x <= 100; x++) {

            System.out.println(""adding value x:"" + x);
            gStore.addValue(timestamp, 2.0);
            timestamp = timestamp + 1000;

            if (x % 10 == 0) {
                gStore.archiveCurrentCompressor();
            }
            if (x < 50) {
                continue;
            }

            System.out.println(""fetching values x:"" + x);
            long totalObservations = 0;

            List<WrappedGorillaDecompressor> decompressorList = gStore.getDecompressors(start, timestamp);
            Pair pair = null;
            for (WrappedGorillaDecompressor w : decompressorList) {
                while ((pair = w.readPair()) != null) {
                    totalObservations++;
                    // System.out.println(pair.getTimestamp() + "" --> "" +
                    // pair.getDoubleValue());
                }
            }

            Assert.assertEquals(""Unexpected number of total observations"", x, totalObservations);

        }

    }
",non-flaky,5
20970,NationalSecurityAgency_timely,TestMemoryDataStore.testOne,"    @Test
    public void testOne() throws TimelyException {

        long now = System.currentTimeMillis();
        DataStoreCache mmStore = getMetricMemoryStore1(now);

        QueryRequest query = new QueryRequest();
        query.setStart(now);
        query.setEnd(now + 100000);
        query.setMsResolution(true);
        QueryRequest.SubQuery subQuery = new QueryRequest.SubQuery();
        subQuery.setDownsample(Optional.of(""5s-avg""));
        subQuery.setMetric(""mymetric"");
        subQuery.addTag(""host"", "".*"");
        query.setQueries(Collections.singleton(subQuery));

        try {
            List<QueryResponse> responseList = mmStore.query(query);
            for (QueryResponse response : responseList) {
                System.out.println(response.toString());
            }
        } catch (TimelyException e) {
            e.printStackTrace();
        }
    }
",non-flaky,5
20971,NationalSecurityAgency_timely,TestMemoryDataStore.testStorage,"    @Test
    public void testStorage() throws TimelyException {

        long now = System.currentTimeMillis();
        DataStoreCache mmStore = getMetricMemoryStore2(now);

        QueryRequest query = new QueryRequest();
        query.setStart(now);
        query.setEnd(now + 86400000);
        query.setMsResolution(true);
        QueryRequest.SubQuery subQuery = new QueryRequest.SubQuery();
        subQuery.setDownsample(Optional.of(""5m-avg""));
        subQuery.setMetric(""metric.number.1"");
        subQuery.addTag(""host"", "".*"");
        query.setQueries(Collections.singleton(subQuery));

        try {
            List<QueryResponse> responseList = mmStore.query(query);
            for (QueryResponse response : responseList) {
                System.out.println(response.toString());
            }
        } catch (TimelyException e) {
            e.printStackTrace();
        }
    }
",non-flaky,5
20972,NationalSecurityAgency_timely,TestMemoryDataStore.TestExtentOfStorage,"    @Test
    public void TestExtentOfStorage() {
        DataStoreCache mmStore = new DataStoreCache(configuration);

        HashMap<String, String> tags = new HashMap<>();
        tags.put(""host"", ""localhost"");

        long start = System.currentTimeMillis();
        long timestamp = start;

        for (int x = 1; x <= 100; x++) {

            Metric m = createMetric(""test.metric"", tags, 2.0, timestamp);
            mmStore.store(m);
            mmStore.flushCaches(-1);
            timestamp = timestamp + 60000;

            QueryRequest query = new QueryRequest();
            query.setStart(start);
            query.setEnd(start + 86400000);
            query.setMsResolution(true);
            QueryRequest.SubQuery subQuery = new QueryRequest.SubQuery();
            // subQuery.setDownsample(Optional.of(""5m-avg""));
            subQuery.setMetric(""test.metric"");
            query.setQueries(Collections.singleton(subQuery));

            try {
                List<QueryResponse> responseList = mmStore.query(query);
                long totalObservations = 0;
                for (QueryResponse r : responseList) {
                    totalObservations += r.getDps().size();
                }
                Assert.assertEquals(""Unexpected number of total observations"", x, totalObservations);

            } catch (TimelyException e) {
                e.printStackTrace();
            }

        }

    }
",non-flaky,5
20973,NationalSecurityAgency_timely,WebSocketRequestDeserializationTest.testCreateDeserialization,"    @Test
    public void testCreateDeserialization() throws Exception {
        // @formatter:off
		String json = ""{ ""
				       + ""\""operation\"" : \""create\"",""
				       + "" \""sessionId\"": \""1234\""""
				    + ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(CreateSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((CreateSubscription) request).getSessionId());
    }
",non-flaky,5
20974,NationalSecurityAgency_timely,WebSocketRequestDeserializationTest.testRemoveDeserialization,"    @Test
    public void testRemoveDeserialization() throws Exception {
        // @formatter:off
		String json = ""{ ""
				       + ""\""operation\"" : \""remove\"",""
				       + "" \""sessionId\"": \""1234\"",""
				       + "" \""metric\"" : \""sys.cpu.user\""""
				    + ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(RemoveSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((RemoveSubscription) request).getSessionId());
        Assert.assertEquals(""sys.cpu.user"", ((RemoveSubscription) request).getMetric());
    }
",non-flaky,5
20975,NationalSecurityAgency_timely,WebSocketRequestDeserializationTest.testCloseDeserialization,"    @Test
    public void testCloseDeserialization() throws Exception {
        // @formatter:off
		String json = ""{ ""
				       + ""\""operation\"" : \""close\"",""
				       + "" \""sessionId\"": \""1234\""""
				    + ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(CloseSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((CloseSubscription) request).getSessionId());
    }
",non-flaky,5
20976,NationalSecurityAgency_timely,WebSocketRequestDeserializationTest.testAddDeserialization,"    @Test
    public void testAddDeserialization() throws Exception {
        // @formatter:off
		String json = ""{"" +
						""\""operation\"" : \""add\"","" +
						""\""sessionId\"" : \""1234\"","" +
					    "" \""metric\"" : \""sys.cpu.user\"""" +
					  ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(AddSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((AddSubscription) request).getSessionId());
        Assert.assertEquals(""sys.cpu.user"", ((AddSubscription) request).getMetric());
        Assert.assertEquals(false, ((AddSubscription) request).getTags().isPresent());
        Assert.assertEquals(false, ((AddSubscription) request).getStartTime().isPresent());
    }
",non-flaky,5
20977,NationalSecurityAgency_timely,WebSocketRequestDeserializationTest.testAddDeserializationWithTime,"    @Test
    public void testAddDeserializationWithTime() throws Exception {
        // @formatter:off
		String json = ""{"" +
						""\""operation\"" : \""add\"","" +
						""\""sessionId\"" : \""1234\"","" +
					    ""\""metric\"" : \""sys.cpu.user\"","" +
						""\""startTime\"" : \""1000\"""" +
					  ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(AddSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((AddSubscription) request).getSessionId());
        Assert.assertEquals(""sys.cpu.user"", ((AddSubscription) request).getMetric());
        Assert.assertEquals(false, ((AddSubscription) request).getTags().isPresent());
        Assert.assertEquals(true, ((AddSubscription) request).getStartTime().isPresent());
        long time = ((AddSubscription) request).getStartTime().get();
        Assert.assertEquals(1000L, time);
    }
",non-flaky,5
20978,NationalSecurityAgency_timely,WebSocketRequestDeserializationTest.testAddDeserializationWithTimeAndTags,"    @Test
    public void testAddDeserializationWithTimeAndTags() throws Exception {
        // @formatter:off
		String json = ""{"" +
						""\""operation\"" : \""add\"","" +
						""\""sessionId\"" : \""1234\"","" +
					    ""\""metric\"" : \""sys.cpu.user\"","" +
						""\""tags\"" : {"" +
					       ""\""tag2\"" : \""value2\"","" +
					       ""\""tag1\"" : \""value1\"""" +
					    ""},"" +
						""\""startTime\"" : \""1000\"","" +
					    ""\""endTime\"" : \""2000\""""+
					  ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(AddSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((AddSubscription) request).getSessionId());
        Assert.assertEquals(""sys.cpu.user"", ((AddSubscription) request).getMetric());
        Assert.assertEquals(true, ((AddSubscription) request).getTags().isPresent());
        Map<String, String> tags = ((AddSubscription) request).getTags().get();
        Assert.assertTrue(tags.containsKey(""tag1""));
        Assert.assertEquals(""value1"", tags.get(""tag1""));
        Assert.assertTrue(tags.containsKey(""tag2""));
        Assert.assertEquals(""value2"", tags.get(""tag2""));
        Assert.assertEquals(true, ((AddSubscription) request).getStartTime().isPresent());
        long start = ((AddSubscription) request).getStartTime().get();
        Assert.assertEquals(1000L, start);
        Assert.assertEquals(true, ((AddSubscription) request).getEndTime().isPresent());
        long end = ((AddSubscription) request).getEndTime().get();
        Assert.assertEquals(2000L, end);
    }
",non-flaky,5
20979,NationalSecurityAgency_timely,WebSocketRequestDeserializationTest.testAddDeserializationWithStartAndDelayTimeAndTags,"    @Test
    public void testAddDeserializationWithStartAndDelayTimeAndTags() throws Exception {
        // @formatter:off
		String json = ""{"" +
						""\""operation\"" : \""add\"","" +
						""\""sessionId\"" : \""1234\"","" +
					    ""\""metric\"" : \""sys.cpu.user\"","" +
						""\""tags\"" : {"" +
					       ""\""tag2\"" : \""value2\"","" +
					       ""\""tag1\"" : \""value1\"""" +
					    ""},"" +
						""\""startTime\"" : \""1000\"","" +
					    ""\""delayTime\"" : \""500\"""" +
					  ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(AddSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((AddSubscription) request).getSessionId());
        Assert.assertEquals(""sys.cpu.user"", ((AddSubscription) request).getMetric());
        Assert.assertEquals(true, ((AddSubscription) request).getTags().isPresent());
        Map<String, String> tags = ((AddSubscription) request).getTags().get();
        Assert.assertTrue(tags.containsKey(""tag1""));
        Assert.assertEquals(""value1"", tags.get(""tag1""));
        Assert.assertTrue(tags.containsKey(""tag2""));
        Assert.assertEquals(""value2"", tags.get(""tag2""));
        Assert.assertEquals(true, ((AddSubscription) request).getStartTime().isPresent());
        long time = ((AddSubscription) request).getStartTime().get();
        Assert.assertEquals(1000L, time);
        long delay = ((AddSubscription) request).getDelayTime().get();
        Assert.assertEquals(500L, delay);
    }
",non-flaky,5
20980,NationalSecurityAgency_timely,MetaTest.testToKeys,"    @Test
    public void testToKeys() {
        Meta one = new Meta(""sys.cpu.user"", ""tag1"", ""value1"");
        List<Key> keys = one.toKeys();
        Assert.assertTrue(keys.contains(new Key(""m:sys.cpu.user"")));
        Assert.assertTrue(keys.contains(new Key(""t:sys.cpu.user"", ""tag1"")));
        Assert.assertTrue(keys.contains(new Key(""v:sys.cpu.user"", ""tag1"", ""value1"")));
    }
",non-flaky,5
20981,NationalSecurityAgency_timely,SearchLookupResponseTest.testResponse1,"    @Test
    public void testResponse1() throws Exception {
        SearchLookupResponse response = new SearchLookupResponse();
        response.setType(""LOOKUP"");
        response.setMetric(""sys.cpu.user"");
        response.putTag(""host"", ""localhost"");
        response.putTag(""rack"", ""r1"");
        response.setTime(1500);
        List<Result> results = new ArrayList<>();
        Result r1 = new Result();
        r1.setMetric(""sys.cpu.idle"");
        r1.setTsuid(""000011000008203D00"");
        r1.putTag(""host"", ""localhost"");
        r1.putTag(""rack"", ""r1"");
        Result r2 = new Result();
        r2.setMetric(""sys.cpu.user"");
        r2.setTsuid(""000011000008203D01"");
        r2.putTag(""host"", ""localhost"");
        r2.putTag(""rack"", ""r1"");
        results.add(r1);
        results.add(r2);
        response.setResults(results);
        response.setTotalResults(results.size());
        String r = JsonUtil.getObjectMapper().writeValueAsString(response);
        String expected = ""{\""type\"":\""LOOKUP\"",\""metric\"":\""sys.cpu.user\"",\""tags\"":{\""rack\"":\""r1\"",\""host\"":\""localhost\""},\""limit\"":0,\""time\"":1500,\""totalResults\"":2,\""results\"":[{\""tags\"":{\""rack\"":\""r1\"",\""host\"":\""localhost\""},\""metric\"":\""sys.cpu.idle\"",\""tsuid\"":\""000011000008203D00\""},{\""tags\"":{\""rack\"":\""r1\"",\""host\"":\""localhost\""},\""metric\"":\""sys.cpu.user\"",\""tsuid\"":\""000011000008203D01\""}]}"";
        Assert.assertEquals(expected, r);
        SearchLookupResponse slr = JsonUtil.getObjectMapper().readValue(r, SearchLookupResponse.class);
        Assert.assertEquals(response, slr);
    }
",non-flaky,5
20982,NationalSecurityAgency_timely,MetricsResponseTest.testGenerateHtml,"    @Test
    public void testGenerateHtml() throws Exception {
        Configuration cfg = TestConfiguration.createMinimalConfigurationForTest();
        MetaCache cache = MetaCacheFactory.getCache(cfg);
        cache.add(new Meta(""sys.cpu.user"", ""host"", ""localhost""));
        cache.add(new Meta(""sys.cpu.user"", ""instance"", ""0""));
        cache.add(new Meta(""sys.cpu.idle"", ""host"", ""localhost""));
        cache.add(new Meta(""sys.cpu.idle"", ""instance"", ""0""));
        TestMetricsResponse r = new TestMetricsResponse(cfg);
        String html = r.generateHtml().toString();
        Assert.assertTrue(html.contains(""<td>sys.cpu.idle</td>""));
        Assert.assertTrue(html.contains(""<td>host=localhost instance=0 </td>""));
        Assert.assertTrue(html.contains(""<td>sys.cpu.user</td>""));
        Assert.assertTrue(html.contains(""<td>host=localhost instance=0 </td>""));
    }
",non-flaky,5
20983,NationalSecurityAgency_timely,MetricsResponseTest.testGenerateHtmlWithIgnoredTags,"    @Test
    public void testGenerateHtmlWithIgnoredTags() throws Exception {
        Configuration cfg = TestConfiguration.createMinimalConfigurationForTest();
        cfg.getMetricsReportIgnoredTags().add(""instance"");
        MetaCache cache = MetaCacheFactory.getCache(cfg);
        cache.add(new Meta(""sys.cpu.user"", ""host"", ""localhost""));
        cache.add(new Meta(""sys.cpu.user"", ""instance"", ""0""));
        cache.add(new Meta(""sys.cpu.idle"", ""host"", ""localhost""));
        cache.add(new Meta(""sys.cpu.idle"", ""instance"", ""0""));
        TestMetricsResponse r = new TestMetricsResponse(cfg);
        String html = r.generateHtml().toString();
        Assert.assertTrue(html.contains(""<td>sys.cpu.idle</td>""));
        Assert.assertTrue(html.contains(""<td>host=localhost </td>""));
        Assert.assertTrue(html.contains(""<td>sys.cpu.user</td>""));
        Assert.assertTrue(html.contains(""<td>host=localhost </td>""));
    }
",non-flaky,5
20984,NationalSecurityAgency_timely,SuggestResponseTest.testSuggestResponseEmpty,"    @Test
    public void testSuggestResponseEmpty() throws Exception {
        SuggestResponse response = new SuggestResponse();
        String r = JsonUtil.getObjectMapper().writeValueAsString(response);
        Assert.assertEquals(""[]"", r);
    }
",non-flaky,5
20985,NationalSecurityAgency_timely,SuggestResponseTest.testSuggestResponse,"    @Test
    public void testSuggestResponse() throws Exception {
        SuggestResponse response = new SuggestResponse();
        response.addSuggestion(""sys.cpu.idle"");
        response.addSuggestion(""sys.cpu.user"");
        String r = JsonUtil.getObjectMapper().writeValueAsString(response);
        Assert.assertEquals(""[\""sys.cpu.idle\"",\""sys.cpu.user\""]"", r);
    }
",non-flaky,5
20986,NationalSecurityAgency_timely,AggregatorsResponseTest.testAggregatorsResponseEmpty,"    @Test
    public void testAggregatorsResponseEmpty() throws Exception {
        AggregatorsResponse response = new AggregatorsResponse();
        String r = JsonUtil.getObjectMapper().writeValueAsString(response);
        Assert.assertEquals(""[]"", r);
    }
",non-flaky,5
20987,NationalSecurityAgency_timely,AggregatorsResponseTest.testAggregatorsResponse,"    @Test
    public void testAggregatorsResponse() throws Exception {
        AggregatorsResponse response = new AggregatorsResponse();
        response.addAggregator(""min"");
        response.addAggregator(""max"");
        String r = JsonUtil.getObjectMapper().writeValueAsString(response);
        Assert.assertEquals(""[\""min\"",\""max\""]"", r);
    }
",non-flaky,5
20988,NationalSecurityAgency_timely,QueryResponseTest.testEmptyResponse,"    @Test
    public void testEmptyResponse() throws Exception {
        String r = JsonUtil.getObjectMapper().writeValueAsString(Collections.emptyList());
        Assert.assertEquals(""[]"", r);
    }
",non-flaky,5
20989,NationalSecurityAgency_timely,QueryResponseTest.testOneResponse,"    @Test
    public void testOneResponse() throws Exception {
        QueryResponse r = new QueryResponse();
        r.setMetric(""sys.cpu.user"");
        r.putTag(""host"", ""localhost"");
        r.putTag(""rack"", ""r1"");
        r.putDps(""1234567890"", 4.5);
        r.putDps(""1234567900"", 3.5);
        r.putDps(""1234567910"", 2.5);
        String result = JsonUtil.getObjectMapper().writeValueAsString(Collections.singletonList(r));
        String expected = ""[{\""metric\"":\""sys.cpu.user\"",\""tags\"":{\""rack\"":\""r1\"",\""host\"":\""localhost\""},\""aggregatedTags\"":[],\""dps\"":{\""1234567890\"":4.5,\""1234567900\"":3.5,\""1234567910\"":2.5}}]"";
        Assert.assertEquals(expected, result);
    }
",non-flaky,5
20990,NationalSecurityAgency_timely,MessageFormatTest.testNumberFormat,"    @Test
    public void testNumberFormat() {
        String m = ""sys.cpu.user"";
        long time = System.currentTimeMillis();
        double value = ThreadLocalRandom.current().nextDouble(0.0D, 100.0D);
        String put = MessageFormat.format(FMT, m, time, value, ""host=localhost"", ""rack=r1"");
        NumberFormat formattedDouble = DecimalFormat.getInstance();
        formattedDouble.setMaximumFractionDigits(3);
        String newValue = formattedDouble.format(value);
        Assert.assertEquals(""put sys.cpu.user "" + time + "" "" + newValue + "" host=localhost rack=r1"", put);
    }
",non-flaky,5
20991,NationalSecurityAgency_timely,MetaKeySetTest.testContents,"    @Test
    public void testContents() {
        Meta one = new Meta(""sys.cpu.user"", ""tag1"", ""value1"");
        Meta two = new Meta(""sys.cpu.user"", ""tag2"", ""value2"");
        Meta three = new Meta(""sys.cpu.user"", ""tag3"", ""value3"");
        MetaKeySet mks = new MetaKeySet();
        mks.addAll(one.toKeys());
        mks.addAll(two.toKeys());
        mks.addAll(three.toKeys());
        Assert.assertEquals(7, mks.size());
        Assert.assertTrue(mks.contains(new Key(""m:sys.cpu.user"")));
        Assert.assertTrue(mks.contains(new Key(""t:sys.cpu.user"", ""tag1"")));
        Assert.assertTrue(mks.contains(new Key(""t:sys.cpu.user"", ""tag2"")));
        Assert.assertTrue(mks.contains(new Key(""t:sys.cpu.user"", ""tag3"")));
        Assert.assertTrue(mks.contains(new Key(""v:sys.cpu.user"", ""tag1"", ""value1"")));
        Assert.assertTrue(mks.contains(new Key(""v:sys.cpu.user"", ""tag2"", ""value2"")));
        Assert.assertTrue(mks.contains(new Key(""v:sys.cpu.user"", ""tag3"", ""value3"")));
    }
",non-flaky,5
20992,NationalSecurityAgency_timely,MetaKeySetTest.testToMutations,"    @Test
    public void testToMutations() {
        Meta one = new Meta(""sys.cpu.user"", ""tag1"", ""value1"");
        Meta two = new Meta(""sys.cpu.user"", ""tag2"", ""value2"");
        Meta three = new Meta(""sys.cpu.user"", ""tag3"", ""value3"");
        MetaKeySet mks = new MetaKeySet();
        mks.addAll(one.toKeys());
        mks.addAll(two.toKeys());
        mks.addAll(three.toKeys());
        List<Mutation> muts = mks.toMutations();
        Mutation e1 = new Mutation(""m:sys.cpu.user"");
        e1.put("""", """", MetaKeySet.NULL_VALUE);
        Mutation e2 = new Mutation(""t:sys.cpu.user"");
        e2.put(""tag1"", """", MetaKeySet.NULL_VALUE);
        e2.put(""tag2"", """", MetaKeySet.NULL_VALUE);
        e2.put(""tag3"", """", MetaKeySet.NULL_VALUE);
        Mutation e3 = new Mutation(""v:sys.cpu.user"");
        e3.put(""tag1"", ""value1"", MetaKeySet.NULL_VALUE);
        e3.put(""tag2"", ""value2"", MetaKeySet.NULL_VALUE);
        e3.put(""tag3"", ""value3"", MetaKeySet.NULL_VALUE);
        Assert.assertEquals(3, muts.size());
        Assert.assertTrue(muts.contains(e1));
        Assert.assertTrue(muts.contains(e2));
        Assert.assertTrue(muts.contains(e3));
    }
",non-flaky,5
20993,NationalSecurityAgency_timely,AggregationTest.simple,"    @Test
    public void simple() {
        Aggregation asample = new Aggregation(new Avg());
        for (int i = 10; i < 30; i++) {
            asample.add(i, i - 10);
        }
        for (int i = 10; i < 30; i++) {
            asample.add(i, i);
        }
        int i = 0;
        for (Sample sample : asample) {
            assertEquals(10 + i, sample.timestamp);
            assertTrue(sample.timestamp < 30);
            assertEquals(i + 5, (int) sample.value);
            i++;
        }
        assertEquals(20, i);
        asample = new Aggregation(new Sum());
        for (int j = 0; j < 5; j++) {
            for (int k = 10; k < 100; k++) {
                asample.add(k, j + 0.);
            }
        }
        i = 0;
        for (Sample sample : asample) {
            assertEquals(10 + i, sample.timestamp);
            assertEquals((1 + 2 + 3 + 4), sample.value, 0.0D);
            i++;
        }
        assertEquals(100 - 10, i);
    }
",non-flaky,5
20994,NationalSecurityAgency_timely,DownsampleTest.simple,"    @Test
    public void simple() {
        Downsample dsample = new Downsample(10, 30, 1, new Avg());
        for (int i = 10; i < 30; i++) {
            dsample.add(i, i - 10);
        }
        int i = 0;
        for (Sample sample : dsample) {
            assertEquals(10 + i, sample.timestamp);
            assertTrue(sample.timestamp < 30);
            assertEquals(i, (int) sample.value);
            i++;
        }
        assertEquals(20, i);
        dsample = new Downsample(10, 100, 7, new Sum());
        for (int j = 0; j < 5; j++) {
            for (int k = 10; k < 100; k++) {
                dsample.add(k, j + 0.);
            }
        }
        i = 0;
        for (Sample sample : dsample) {
            assertEquals((1 + 2 + 3 + 4) * Math.min(7, (100 - (10 + i * 7))), sample.value, 0.0D);
            assertEquals(10 + i * 7, sample.timestamp);
            i++;
        }
        assertEquals((100 - 10) / 7 + 1, i);
        dsample = new Downsample(10, 30, 10, new Avg());
        for (int j = 10; j < 30; j++) {
            for (int k = 0; k < 10; k++) {
                dsample.add(j, k + 0.);
            }
        }
        for (int j = 0; j < 100; j++) {
            dsample.add(15, 0);
        }
        i = 0;
        for (Sample sample : dsample) {
            if (i == 0) {
                assertEquals(2.25, sample.value, 0.0D);
            } else {
                assertEquals(4.5, sample.value, 0.0D);
            }
            assertEquals(10 * i + 10, sample.timestamp);
            i++;
        }
        assertEquals(2, i);
    }
",non-flaky,5
20995,NationalSecurityAgency_timely,DownsampleTest.testCombineTrivial,"    @Test
    public void testCombineTrivial() throws Exception {
        Downsample ds = new Downsample(0, 1000, 100, new Avg());
        for (int i = 0; i < 1000; i += 100) {
            ds.add(i, .2);
        }
        Downsample result = Downsample.combineDownsample(Collections.singleton(ds), null);
        int count = 0;
        for (Sample s : result) {
            assertEquals(.2, s.value, 0.0D);
            count++;
        }
        assertEquals(10, count);
    }
",non-flaky,5
20996,NationalSecurityAgency_timely,DownsampleTest.testCombineMissingReport,"    @Test
    public void testCombineMissingReport() throws Exception {
        Downsample ds = new Downsample(0, 1000, 100, new Avg());
        for (int i = 0; i < 1000; i += 100) {
            if (i != 700) {
                ds.add(i, .2);
            }
        }
        Downsample result = Downsample.combineDownsample(Collections.singleton(ds), null);
        int count = 0;
        for (Sample s : result) {
            assertEquals(.2, s.value, 0.0D);
            count++;
        }
        assertEquals(9, count);
    }
",non-flaky,5
20997,NationalSecurityAgency_timely,DownsampleTest.testDownsampleStartCalculation,"    @Test
    public void testDownsampleStartCalculation() throws Exception {
        long queryStart = System.currentTimeMillis() - 86400000;
        long period = 60000;
        long keyTimestamp = queryStart + (86400000 / 2 + 3256);

        Set<Long> expectedStartTimes = new HashSet<>();
        for (long i = queryStart; i < queryStart + 86400000; i += period) {
            expectedStartTimes.add(i);
        }
        assertEquals(1440, expectedStartTimes.size());

        long sampleStart = keyTimestamp - ((keyTimestamp - queryStart) % period);
        assertTrue(expectedStartTimes.contains(sampleStart));

    }
",non-flaky,5
20998,NationalSecurityAgency_timely,AggregationIteratorTest.simpleGetOneSample,"    @Test
    public void simpleGetOneSample() throws Exception {
        // check that data gets pulled out
        AggregationIterator iter = new AggregationIterator();
        Map<Set<Tag>, Aggregation> samples = runQuery(iter, testData1, 100);
        assertEquals(1, samples.size());
        for (Entry<Set<Tag>, Aggregation> entry : samples.entrySet()) {
            Set<Tag> tags = entry.getKey();
            assertEquals(1, tags.size());
            assertEquals(Collections.singleton(new Tag(""host"", "".*"")), tags);
            long ts = 0;
            int count = 0;
            for (Sample sample : entry.getValue()) {
                assertEquals(ts, sample.timestamp);
                ts += 100;
                assertEquals(0.2, sample.value, 0.0001);
                count++;
            }
            assertEquals(1000, ts);
            assertEquals(10, count);
        }
    }
",non-flaky,5
20999,NationalSecurityAgency_timely,AggregationIteratorTest.simpleAggregatedSample,"    @Test
    public void simpleAggregatedSample() throws Exception {
        AggregationIterator iter = new AggregationIterator();
        Map<Set<Tag>, Aggregation> samples = runQuery(iter, testData2, 100);
        assertEquals(1, samples.size());
        for (Entry<Set<Tag>, Aggregation> entry : samples.entrySet()) {
            Set<Tag> tags = entry.getKey();
            assertEquals(1, tags.size());
            assertEquals(Collections.singleton(new Tag(""host"", "".*"")), tags);
            long ts = 0;
            int count = 0;
            for (Sample sample : entry.getValue()) {
                assertEquals(ts, sample.timestamp);
                ts += 100;
                assertEquals(count == 0 ? 0.2 : (count == 10 ? 0.5 : 0.35), sample.value, 0.0001);
                count++;
            }
            assertEquals(11, count);
        }
    }
",non-flaky,5
21000,NationalSecurityAgency_timely,DownsampleIteratorTest.simpleGetOneSample,"    @Test
    public void simpleGetOneSample() throws Exception {
        // check that data gets pulled out
        DownsampleIterator iter = new DownsampleIterator();
        Map<Set<Tag>, Downsample> samples = runQuery(iter, testData1, 100, -1);
        assertEquals(1, samples.size());
        for (Entry<Set<Tag>, Downsample> entry : samples.entrySet()) {
            Set<Tag> tags = entry.getKey();
            assertEquals(1, tags.size());
            assertEquals(Collections.singleton(new Tag(""host"", ""host1"")), tags);
            long ts = 0;
            for (Sample sample : entry.getValue()) {
                assertEquals(ts, sample.timestamp);
                ts += 100;
                assertEquals(0.2, sample.value, 0.0001);
            }
            assertEquals(1000, ts);
        }
    }
",non-flaky,5
21001,NationalSecurityAgency_timely,DownsampleIteratorTest.simpleGetTwoSamples,"    @Test
    public void simpleGetTwoSamples() throws Exception {
        DownsampleIterator iter = new DownsampleIterator();
        Map<Set<Tag>, Downsample> samples = runQuery(iter, testData2, 100, -1);
        assertEquals(2, samples.size());
        for (Tag tag : new Tag[] { new Tag(""host"", ""host1""), new Tag(""host"", ""host2"") }) {
            Downsample dsample = samples.get(Collections.singleton(tag));
            assertNotNull(dsample);
            long ts = 0;
            double value = .2;
            if (tag.getValue().equals(""host2"")) {
                value = .5;
            }
            int count = 0;
            for (Sample sample : dsample) {
                assertEquals(ts, sample.timestamp);
                ts += 100;
                assertEquals(value, sample.value, 0.0001);
                count++;
            }
            assertEquals(10, count);
        }
    }
",non-flaky,5
21002,NationalSecurityAgency_timely,DownsampleIteratorTest.simpleTestDownsampling,"    @Test
    public void simpleTestDownsampling() throws Exception {
        DownsampleIterator iter = new DownsampleIterator();
        Map<Set<Tag>, Downsample> samples = runQuery(iter, testData2, 200, -1);
        assertEquals(2, samples.size());
        for (Tag tag : new Tag[] { new Tag(""host"", ""host1""), new Tag(""host"", ""host2"") }) {
            Downsample dsample = samples.get(Collections.singleton(tag));
            assertNotNull(dsample);
            long ts = 0;
            double value = .2;
            if (tag.getValue().equals(""host2"")) {
                value = .5;
            }
            int count = 0;
            for (Sample sample : dsample) {
                assertEquals(ts, sample.timestamp);
                ts += 200;
                assertEquals(value, sample.value, 0.0001);
                count++;
            }
            assertEquals(5, count);
        }
    }
",non-flaky,5
21003,NationalSecurityAgency_timely,DownsampleIteratorTest.memoryEstimatorTestSmallObjects,"    @Test
    public void memoryEstimatorTestSmallObjects() {
        long maxMemory = 1000;
        long start = System.currentTimeMillis();
        long period = 500l;
        long sizeOfObjects = 20;
        SampleObject o = new SampleObject();
        DownsampleMemoryEstimator memoryEstimator = new DownsampleMemoryEstimator(maxMemory, start, period);
        boolean shouldReturn = false;
        for (long x = 100; x <= 5000; x += 100) {
            long timestamp = start + x;
            o.setSizeInBytes(o.sizeInBytes() + sizeOfObjects);
            shouldReturn = memoryEstimator.shouldReturnBasedOnMemoryUsage(timestamp, o);
            if (memoryEstimator.isNewBucket()) {
                long memoryPercentageUsedCalculated = Math.round((double) o.sizeInBytes() / maxMemory * 100);
                long memoryPercentageUsedEstimate = Math.round(memoryEstimator.getMemoryUsedPercentage());
                long percentError = Math.round(Math.abs(memoryPercentageUsedCalculated - memoryPercentageUsedEstimate)
                        / memoryPercentageUsedCalculated * 100);
                assertTrue(percentError == 0);
            }

            if (shouldReturn) {
                o.setSizeInBytes(0);
                memoryEstimator.reset();
            }
        }
        assertTrue(shouldReturn);
    }
",non-flaky,5
21004,NationalSecurityAgency_timely,DownsampleIteratorTest.memoryEstimatorTestLargeObjects,"    @Test
    public void memoryEstimatorTestLargeObjects() {
        long maxMemory = 10000;
        long start = System.currentTimeMillis();
        long period = 500l;
        long sizeOfObjects = 200;
        SampleObject o = new SampleObject();
        DownsampleMemoryEstimator memoryEstimator = new DownsampleMemoryEstimator(maxMemory, start, period);
        boolean shouldReturn = false;
        for (long x = 100; x <= 5000; x += 100) {
            long timestamp = start + x;
            o.setSizeInBytes(o.sizeInBytes() + sizeOfObjects);
            shouldReturn = memoryEstimator.shouldReturnBasedOnMemoryUsage(timestamp, o);
            if (memoryEstimator.isNewBucket()) {
                long memoryPercentageUsedCalculated = Math.round((double) o.sizeInBytes() / maxMemory * 100);
                long memoryPercentageUsedEstimate = Math.round(memoryEstimator.getMemoryUsedPercentage());
                long percentError = Math.round(Math.abs(memoryPercentageUsedCalculated - memoryPercentageUsedEstimate)
                        / memoryPercentageUsedCalculated * 100);
                assertTrue(percentError == 0);
                assertTrue(memoryEstimator.isHighVolumeBuckets());
            }

            if (shouldReturn) {
                o.setSizeInBytes(0);
                memoryEstimator.reset();
            }
        }
        assertTrue(shouldReturn);
    }
",non-flaky,5
21005,NationalSecurityAgency_timely,DownsampleIteratorTest.testDownsampleCombining,"    @Test
    public void testDownsampleCombining() throws Exception {

        int numTagVariations = 2;
        int sampleInterval = 50;
        int elapsedTime = 100;
        int skipInterval = 10;
        SortedMap<Key, Value> testData3 = createTestData3(elapsedTime, skipInterval, numTagVariations);
        DownsampleIterator iter = new DownsampleIterator();
        Map<Set<Tag>, Downsample> samples = runQuery(iter, testData3, sampleInterval, 1000);
        assertEquals(numTagVariations, samples.size());
        long totalBuckets = 0;
        for (Entry<Set<Tag>, Downsample> entry : samples.entrySet()) {
            totalBuckets = totalBuckets + entry.getValue().getNumBuckets();
        }
        assertEquals((elapsedTime / sampleInterval) * numTagVariations, totalBuckets);
    }
",non-flaky,5
21006,NationalSecurityAgency_timely,TimelyTcpIT.testVersion,"    @Test
    public void testVersion() throws Exception {
        final TestServer m = new TestServer(conf);
        m.run();
        try (Socket sock = new Socket(""127.0.0.1"", 54321);
                PrintWriter writer = new PrintWriter(sock.getOutputStream(), true);) {
            writer.write(""version\n"");
            writer.flush();
            while (1 != m.getTcpRequests().getCount()) {
                Thread.sleep(5);
            }
            Assert.assertEquals(1, m.getTcpRequests().getResponses().size());
            Assert.assertEquals(VersionRequest.class, m.getTcpRequests().getResponses().get(0).getClass());
            VersionRequest v = (VersionRequest) m.getTcpRequests().getResponses().get(0);
            Assert.assertEquals(VersionRequest.VERSION, v.getVersion());
        } finally {
            m.shutdown();
        }
    }
",non-flaky,5
21007,NationalSecurityAgency_timely,TimelyTcpIT.testPut,"    @Test
    public void testPut() throws Exception {
        final TestServer m = new TestServer(conf);
        m.run();
        try (Socket sock = new Socket(""127.0.0.1"", 54321);
                PrintWriter writer = new PrintWriter(sock.getOutputStream(), true);) {
            writer.write(""put sys.cpu.user "" + TEST_TIME + "" 1.0 tag1=value1 tag2=value2\n"");
            writer.flush();
            while (1 != m.getTcpRequests().getCount()) {
                Thread.sleep(5);
            }
            Assert.assertEquals(1, m.getTcpRequests().getResponses().size());
            Assert.assertEquals(MetricRequest.class, m.getTcpRequests().getResponses().get(0).getClass());
            final MetricRequest actual = (MetricRequest) m.getTcpRequests().getResponses().get(0);
            // @formatter:off
            final MetricRequest expected = new MetricRequest(
                    Metric.newBuilder()
                            .name(""sys.cpu.user"")
                            .value(TEST_TIME, 1.0D)
                            .tag(new Tag(""tag1"", ""value1""))
                            .tag(new Tag(""tag2"", ""value2""))
                            .build()
            );
            // @formatter on
            Assert.assertEquals(expected, actual);
        } finally {
            m.shutdown();
        }
    }
",non-flaky,5
21008,NationalSecurityAgency_timely,TimelyTcpIT.testPutMultiple,"    @Test
    public void testPutMultiple() throws Exception {

        final TestServer m = new TestServer(conf);
        m.run();
        try (Socket sock = new Socket(""127.0.0.1"", 54321);
                PrintWriter writer = new PrintWriter(sock.getOutputStream(), true)) {
            // @formatter:off
            writer.write(""put sys.cpu.user "" + TEST_TIME + "" 1.0 tag1=value1 tag2=value2\n""
                       + ""put sys.cpu.idle "" + (TEST_TIME + 1) + "" 1.0 tag3=value3 tag4=value4\n"");
            writer.flush();
            while (2 != m.getTcpRequests().getCount()) {
                Thread.sleep(5);
            }
            Assert.assertEquals(2, m.getTcpRequests().getResponses().size());
            Assert.assertEquals(MetricRequest.class, m.getTcpRequests().getResponses().get(0).getClass());
            MetricRequest actual = (MetricRequest) m.getTcpRequests().getResponses().get(0);
            MetricRequest expected = new MetricRequest(
                    Metric.newBuilder()
                            .name(""sys.cpu.user"")
                            .value(TEST_TIME, 1.0D)
                            .tag(new Tag(""tag1"", ""value1""))
                            .tag(new Tag(""tag2"", ""value2""))
                            .build()
            );
            Assert.assertEquals(expected, actual);

            Assert.assertEquals(MetricRequest.class, m.getTcpRequests().getResponses().get(1).getClass());
            actual = (MetricRequest) m.getTcpRequests().getResponses().get(1);
            expected = new MetricRequest(
                    Metric.newBuilder()
                        .name(""sys.cpu.idle"")
                        .value(TEST_TIME + 1, 1.0D)
                        .tag(new Tag(""tag3"", ""value3""))
                        .tag(new Tag(""tag4"", ""value4""))
                        .build()
            );
            // @formatter:on
            Assert.assertEquals(expected, actual);

        } finally {
            m.shutdown();
        }
    }
",non-flaky,5
21009,NationalSecurityAgency_timely,TimelyTcpIT.testPutMultipleBinary,"    @Test
    public void testPutMultipleBinary() throws Exception {

        FlatBufferBuilder builder = new FlatBufferBuilder(1);

        int[] metric = new int[2];
        Map<String, String> t = new HashMap<>();
        t.put(""tag1"", ""value1"");
        t.put(""tag2"", ""value2"");
        metric[0] = createMetric(builder, ""sys.cpu.user"", TEST_TIME, 1.0D, t);
        t = new HashMap<>();
        t.put(""tag3"", ""value3"");
        t.put(""tag4"", ""value4"");
        metric[1] = createMetric(builder, ""sys.cpu.idle"", TEST_TIME + 1, 1.0D, t);

        int metricVector = timely.api.flatbuffer.Metrics.createMetricsVector(builder, metric);

        timely.api.flatbuffer.Metrics.startMetrics(builder);
        timely.api.flatbuffer.Metrics.addMetrics(builder, metricVector);
        int metrics = timely.api.flatbuffer.Metrics.endMetrics(builder);
        timely.api.flatbuffer.Metrics.finishMetricsBuffer(builder, metrics);

        ByteBuffer binary = builder.dataBuffer();
        byte[] data = new byte[binary.remaining()];
        binary.get(data, 0, binary.remaining());
        LOG.debug(""Sending {} bytes"", data.length);

        final TestServer m = new TestServer(conf);
        m.run();
        try (Socket sock = new Socket(""127.0.0.1"", 54321);) {
            sock.getOutputStream().write(data);
            sock.getOutputStream().flush();
            while (2 != m.getTcpRequests().getCount()) {
                LOG.debug(""Thread sleeping"");
                Thread.sleep(5);
            }
            Assert.assertEquals(2, m.getTcpRequests().getResponses().size());
            Assert.assertEquals(MetricRequest.class, m.getTcpRequests().getResponses().get(0).getClass());
            // @formatter:off
            MetricRequest actual = (MetricRequest) m.getTcpRequests().getResponses().get(0);
            MetricRequest expected = new MetricRequest(
                    Metric.newBuilder()
                            .name(""sys.cpu.user"")
                            .value(TEST_TIME, 1.0D)
                            .tag(new Tag(""tag1"", ""value1""))
                            .tag(new Tag(""tag2"", ""value2""))
                            .build()
            );
            Assert.assertEquals(expected, actual);

            Assert.assertEquals(MetricRequest.class, m.getTcpRequests().getResponses().get(1).getClass());
            actual = (MetricRequest) m.getTcpRequests().getResponses().get(1);
            expected = new MetricRequest(
                    Metric.newBuilder()
                            .name(""sys.cpu.idle"")
                            .value(TEST_TIME + 1, 1.0D)
                            .tag(new Tag(""tag3"", ""value3""))
                            .tag(new Tag(""tag4"", ""value4""))
                            .build()
            );
            // @formatter:on
            Assert.assertEquals(expected, actual);

        } finally {
            m.shutdown();
        }
    }
",non-flaky,5
21010,NationalSecurityAgency_timely,TimelyTcpIT.testPutInvalidTimestamp,"    @Test
    public void testPutInvalidTimestamp() throws Exception {
        final TestServer m = new TestServer(conf);
        m.run();
        try (Socket sock = new Socket(""127.0.0.1"", 54321);
                PrintWriter writer = new PrintWriter(sock.getOutputStream(), true);
                BufferedReader reader = new BufferedReader(new InputStreamReader(sock.getInputStream()));) {
            writer.write(""put sys.cpu.user "" + TEST_TIME + ""Z"" + "" 1.0 tag1=value1 tag2=value2\n"");
            writer.flush();
            sleepUninterruptibly(WAIT_SECONDS, TimeUnit.SECONDS);
            Assert.assertEquals(0, m.getTcpRequests().getCount());
        } finally {
            m.shutdown();
        }
    }
",non-flaky,5
21011,NationalSecurityAgency_timely,TimelyTcpIT.testPersistence,"    @Test
    public void testPersistence() throws Exception {
        final Server s = new Server(conf);
        s.run();
        try {
            put(""sys.cpu.user "" + TEST_TIME + "" 1.0 tag1=value1 tag2=value2"",
                    ""sys.cpu.idle "" + (TEST_TIME + 1) + "" 1.0 tag3=value3 tag4=value4"",
                    ""sys.cpu.idle "" + (TEST_TIME + 2) + "" 1.0 tag3=value3 tag4=value4"");
            sleepUninterruptibly(WAIT_SECONDS, TimeUnit.SECONDS);
        } finally {
            s.shutdown();
        }
        final ZooKeeperInstance inst = new ZooKeeperInstance(mac.getClientConfig());
        final Connector connector = inst.getConnector(""root"", new PasswordToken(""secret"".getBytes(UTF_8)));
        assertTrue(connector.namespaceOperations().exists(""timely""));
        assertTrue(connector.tableOperations().exists(""timely.metrics""));
        assertTrue(connector.tableOperations().exists(""timely.meta""));
        int count = 0;
        for (final Entry<Key, Value> entry : connector.createScanner(""timely.metrics"", Authorizations.EMPTY)) {
            LOG.info(""Entry: "" + entry);
            final double value = ByteBuffer.wrap(entry.getValue().get()).getDouble();
            assertEquals(1.0, value, 1e-9);
            count++;
        }
        assertEquals(6, count);
        count = 0;
        for (final Entry<Key, Value> entry : connector.createScanner(""timely.meta"", Authorizations.EMPTY)) {
            LOG.info(""Meta entry: "" + entry);
            count++;
        }
        assertEquals(10, count);
        // count w/out versioning iterator to make sure that the optimization
        // for writing is working
        connector.tableOperations().removeIterator(""timely.meta"", ""vers"", EnumSet.of(IteratorScope.scan));
        // wait for zookeeper propagation
        sleepUninterruptibly(WAIT_SECONDS, TimeUnit.SECONDS);
        count = 0;
        for (final Entry<Key, Value> entry : connector.createScanner(""timely.meta"", Authorizations.EMPTY)) {
            LOG.info(""Meta no vers iter: "" + entry);
            count++;
        }
        assertEquals(10, count);
    }
",non-flaky,5
21164,swankjesse_dex,OldClassTest.setCount,"    @TestAnnotation(""libcore.java.lang.OldClassTest$ExtendTestClass"")
        public void setCount(int value) {

        }
",non-flaky,5
21165,swankjesse_dex,OldClassTest.getLocalClass,"    @TestAnnotation(""libcore.java.lang.OldClassTest$PublicTestClass"")
        public Object getLocalClass() {
            class LocalClass {}
            Object returnedObject = new LocalClass();
            return returnedObject;
        }
",non-flaky,5
21166,swankjesse_dex,MethodTest.annotatedMethod,"        @TestAnno
        public void annotatedMethod(){}

",non-flaky,5
21167,androidx_androidx,PreferenceGroupInitialExpandedChildrenCountTest.createPreferenceGroupAdapter_displayTopLevelPreferences,"    @Test
    public void createPreferenceGroupAdapter_displayTopLevelPreferences() {
        // No limit, should display all 10 preferences
        PreferenceGroupAdapter preferenceGroupAdapter = new PreferenceGroupAdapter(mScreen);
        assertPreferencesAreExpanded(preferenceGroupAdapter);

        // Limit > child count, should display all 10 preferences
        mScreen.setInitialExpandedChildrenCount(TOTAL_PREFERENCE + 4);
        preferenceGroupAdapter = new PreferenceGroupAdapter(mScreen);
        assertPreferencesAreExpanded(preferenceGroupAdapter);

        // Limit = child count, should display all 10 preferences
        mScreen.setInitialExpandedChildrenCount(TOTAL_PREFERENCE);
        preferenceGroupAdapter = new PreferenceGroupAdapter(mScreen);
        assertPreferencesAreExpanded(preferenceGroupAdapter);

        // Limit < child count, should display up to the limit + expand button
        mScreen.setInitialExpandedChildrenCount(INITIAL_EXPANDED_COUNT);
        preferenceGroupAdapter = new PreferenceGroupAdapter(mScreen);
        assertPreferencesAreCollapsed(preferenceGroupAdapter);
        for (int i = 0; i < INITIAL_EXPANDED_COUNT; i++) {
            assertEquals(mPreferenceList.get(i), preferenceGroupAdapter.getItem(i));
        }
        assertEquals(CollapsiblePreferenceGroupController.ExpandButton.class,
                preferenceGroupAdapter.getItem(INITIAL_EXPANDED_COUNT).getClass());
    }
",non-flaky,5
21168,androidx_androidx,PreferenceGroupInitialExpandedChildrenCountTest.createPreferenceGroupAdapter_displayNestedPreferences,"    @Test
    public void createPreferenceGroupAdapter_displayNestedPreferences() {
        final PreferenceScreen screen = mPreferenceManager.createPreferenceScreen(mContext);
        screen.setKey(PREFERENCE_KEY);
        final List<Preference> preferenceList = new ArrayList<>();

        // Add 2 preferences and 2 categories to screen
        createTestPreferences(screen, preferenceList, 2);
        createTestPreferencesCategory(screen, preferenceList, 4);
        createTestPreferencesCategory(screen, preferenceList, 4);

        // No limit, should display all 10 preferences + 2 categories
        PreferenceGroupAdapter preferenceGroupAdapter = new PreferenceGroupAdapter(screen);
        assertEquals(TOTAL_PREFERENCE + 2, preferenceGroupAdapter.getItemCount());

        // Limit > child count, should display all 10 preferences + 2 categories
        screen.setInitialExpandedChildrenCount(TOTAL_PREFERENCE + 4);
        preferenceGroupAdapter = new PreferenceGroupAdapter(screen);
        assertEquals(TOTAL_PREFERENCE + 2, preferenceGroupAdapter.getItemCount());

        // Limit = child count, should display all 10 preferences + 2 categories
        screen.setInitialExpandedChildrenCount(TOTAL_PREFERENCE);
        preferenceGroupAdapter = new PreferenceGroupAdapter(screen);
        assertEquals(TOTAL_PREFERENCE + 2, preferenceGroupAdapter.getItemCount());

        // Limit < child count, should display 2 preferences and the first 3 preference in the
        // category + expand button
        screen.setInitialExpandedChildrenCount(INITIAL_EXPANDED_COUNT);
        preferenceGroupAdapter = new PreferenceGroupAdapter(screen);
        assertEquals(INITIAL_EXPANDED_COUNT + 2, preferenceGroupAdapter.getItemCount());
        for (int i = 0; i <= INITIAL_EXPANDED_COUNT; i++) {
            assertEquals(preferenceList.get(i), preferenceGroupAdapter.getItem(i));
        }
        assertEquals(CollapsiblePreferenceGroupController.ExpandButton.class,
                preferenceGroupAdapter.getItem(INITIAL_EXPANDED_COUNT + 1).getClass());
    }
",non-flaky,5
21169,androidx_androidx,PreferenceGroupInitialExpandedChildrenCountTest.createPreferenceGroupAdapter_setExpandButtonSummary,"    @Test
    public void createPreferenceGroupAdapter_setExpandButtonSummary() {
        mScreen.setInitialExpandedChildrenCount(INITIAL_EXPANDED_COUNT);
        PreferenceGroupAdapter preferenceGroupAdapter = new PreferenceGroupAdapter(mScreen);
        // Preference 5 to Preference 9 are collapsed
        CharSequence summary = mPreferenceList.get(INITIAL_EXPANDED_COUNT).getTitle();
        for (int i = INITIAL_EXPANDED_COUNT + 1; i < TOTAL_PREFERENCE; i++) {
            summary = mContext.getString(R.string.summary_collapsed_preference_list,
                    summary, mPreferenceList.get(i).getTitle());
        }
        final Preference expandButton = preferenceGroupAdapter.getItem(INITIAL_EXPANDED_COUNT);
        assertEquals(summary, expandButton.getSummary());
    }
",non-flaky,5
21170,androidx_androidx,PreferenceGroupInitialExpandedChildrenCountTest.createPreferenceGroupAdapter_expandButtonSummaryShouldListVisiblePreferencesOnly,"    @Test
    public void createPreferenceGroupAdapter_expandButtonSummaryShouldListVisiblePreferencesOnly() {
        mScreen.setInitialExpandedChildrenCount(INITIAL_EXPANDED_COUNT);
        mPreferenceList.get(INITIAL_EXPANDED_COUNT + 1).setVisible(false);
        mPreferenceList.get(INITIAL_EXPANDED_COUNT + 4).setVisible(false);
        PreferenceGroupAdapter preferenceGroupAdapter = new PreferenceGroupAdapter(mScreen);
        // Preference 5 to Preference 9 are collapsed, only preferences 5, 7, 8 are visible
        CharSequence summary = mPreferenceList.get(INITIAL_EXPANDED_COUNT).getTitle();
        summary = mContext.getString(R.string.summary_collapsed_preference_list,
                summary, mPreferenceList.get(INITIAL_EXPANDED_COUNT + 2).getTitle());
        summary = mContext.getString(R.string.summary_collapsed_preference_list,
                summary, mPreferenceList.get(INITIAL_EXPANDED_COUNT + 3).getTitle());
        final Preference expandButton = preferenceGroupAdapter.getItem(INITIAL_EXPANDED_COUNT);
        assertEquals(summary, expandButton.getSummary());
    }
",non-flaky,5
21171,androidx_androidx,PreferenceGroupInitialExpandedChildrenCountTest.clickExpandButton_shouldShowAllPreferences,"    @Test
    public void clickExpandButton_shouldShowAllPreferences() {
        mScreen.setInitialExpandedChildrenCount(INITIAL_EXPANDED_COUNT);

        // First showing 5 preference with expand button
        PreferenceGroupAdapter preferenceGroupAdapter =
                PreferenceGroupAdapter.createInstanceWithCustomHandler(mScreen, mHandler);
        assertPreferencesAreCollapsed(preferenceGroupAdapter);

        // Click the expand button, should review all preferences
        final Preference expandButton = preferenceGroupAdapter.getItem(INITIAL_EXPANDED_COUNT);
        expandButton.performClick();
        assertPreferencesAreExpanded(preferenceGroupAdapter);
    }
",non-flaky,5
21172,androidx_androidx,PreferenceGroupInitialExpandedChildrenCountTest.onPreferenceVisibilityChange_shouldSyncPreferencesIfCollapsed,"    @Test
    public void onPreferenceVisibilityChange_shouldSyncPreferencesIfCollapsed() {
        // No limit set, should not sync preference
        PreferenceGroupAdapter preferenceGroupAdapter =
                PreferenceGroupAdapter.createInstanceWithCustomHandler(mScreen, mHandler);
        preferenceGroupAdapter.onPreferenceVisibilityChange(mPreferenceList.get(3));
        verify(mHandler, never()).sendMessageDelayed(any(Message.class), anyLong());

        // Has limit set, should sync preference
        mScreen.setInitialExpandedChildrenCount(INITIAL_EXPANDED_COUNT);
        preferenceGroupAdapter =
                PreferenceGroupAdapter.createInstanceWithCustomHandler(mScreen, mHandler);
        preferenceGroupAdapter.onPreferenceVisibilityChange(mPreferenceList.get(3));
        verify(mHandler).sendMessageDelayed(any(Message.class), anyLong());

        // Preferences expanded already, should not sync preference
        final Preference expandButton = preferenceGroupAdapter.getItem(INITIAL_EXPANDED_COUNT);
        expandButton.performClick();
        reset(mHandler);
        preferenceGroupAdapter.onPreferenceVisibilityChange(mPreferenceList.get(3));
        verify(mHandler, never()).sendMessageDelayed(any(Message.class), anyLong());
    }
",non-flaky,5
21173,androidx_androidx,PreferenceGroupInitialExpandedChildrenCountTest.saveInstanceState_shouldSaveMaxNumberOfChildrenToShow,"    @Test
    public void saveInstanceState_shouldSaveMaxNumberOfChildrenToShow() {
        // No limit set, should save max value
        Parcelable state = mScreen.onSaveInstanceState();
        assertEquals(PreferenceGroup.SavedState.class, state.getClass());
        assertEquals(Integer.MAX_VALUE,
                ((PreferenceGroup.SavedState) state).mInitialExpandedChildrenCount);

        // Has limit set, should save limit
        mScreen.setInitialExpandedChildrenCount(INITIAL_EXPANDED_COUNT);
        state = mScreen.onSaveInstanceState();
        assertEquals(PreferenceGroup.SavedState.class, state.getClass());
        assertEquals(INITIAL_EXPANDED_COUNT,
                ((PreferenceGroup.SavedState) state).mInitialExpandedChildrenCount);
    }
",non-flaky,5
21174,androidx_androidx,PreferenceGroupInitialExpandedChildrenCountTest.restoreInstanceState_noChange_shouldDoNothing,"    @Test
    public void restoreInstanceState_noChange_shouldDoNothing() {
        PreferenceGroup.SavedState state;

        // Initialized as expanded, restore as expanded, should remain expanded
        state = new PreferenceGroup.SavedState(
                Preference.BaseSavedState.EMPTY_STATE, Integer.MAX_VALUE);
        PreferenceGroupAdapter preferenceGroupAdapter =
                PreferenceGroupAdapter.createInstanceWithCustomHandler(mScreen, mHandler);
        mScreen.onRestoreInstanceState(state);
        assertPreferencesAreExpanded(preferenceGroupAdapter);
        verify(mHandler, never()).sendMessageDelayed(any(Message.class), anyLong());

        // Initialized as collapsed, restore as collapsed, should remain collapsed
        mScreen.setInitialExpandedChildrenCount(INITIAL_EXPANDED_COUNT);
        state = new PreferenceGroup.SavedState(
                Preference.BaseSavedState.EMPTY_STATE, INITIAL_EXPANDED_COUNT);
        preferenceGroupAdapter =
                PreferenceGroupAdapter.createInstanceWithCustomHandler(mScreen, mHandler);
        mScreen.onRestoreInstanceState(state);
        assertPreferencesAreCollapsed(preferenceGroupAdapter);
        verify(mHandler, never()).sendMessageDelayed(any(Message.class), anyLong());
    }
",non-flaky,5
21175,androidx_androidx,PreferenceGroupInitialExpandedChildrenCountTest.restoreHierarchyState_previouslyCollapsed_shouldRestoreToCollapsedState,"    @Test
    public void restoreHierarchyState_previouslyCollapsed_shouldRestoreToCollapsedState() {
        PreferenceGroup.SavedState state =
                new PreferenceGroup.SavedState(
                        Preference.BaseSavedState.EMPTY_STATE, Integer.MAX_VALUE);
        // Initialized as expanded, restore as collapsed, should collapse
        state.mInitialExpandedChildrenCount = INITIAL_EXPANDED_COUNT;
        mScreen.setInitialExpandedChildrenCount(Integer.MAX_VALUE);
        PreferenceGroupAdapter preferenceGroupAdapter =
                PreferenceGroupAdapter.createInstanceWithCustomHandler(mScreen, mHandler);
        mScreen.onRestoreInstanceState(state);
        verify(mHandler).sendMessageDelayed(any(Message.class), anyLong());
        assertPreferencesAreCollapsed(preferenceGroupAdapter);
    }
",non-flaky,5
21176,androidx_androidx,PreferenceGroupInitialExpandedChildrenCountTest.restoreHierarchyState_previouslyExpanded_shouldRestoreToExpandedState,"    @Test
    public void restoreHierarchyState_previouslyExpanded_shouldRestoreToExpandedState() {
        PreferenceGroup.SavedState state =
                new PreferenceGroup.SavedState(
                        Preference.BaseSavedState.EMPTY_STATE, Integer.MAX_VALUE);
        // Initialized as collapsed, restore as expanded, should expand
        state.mInitialExpandedChildrenCount = Integer.MAX_VALUE;
        mScreen.setInitialExpandedChildrenCount(INITIAL_EXPANDED_COUNT);
        PreferenceGroupAdapter preferenceGroupAdapter =
                PreferenceGroupAdapter.createInstanceWithCustomHandler(mScreen, mHandler);
        mScreen.onRestoreInstanceState(state);
        verify(mHandler).sendMessageDelayed(any(Message.class), anyLong());
        assertPreferencesAreExpanded(preferenceGroupAdapter);
    }
",non-flaky,5
21177,androidx_androidx,PreferenceVisibilityTest.testPreferencesAreCreatedWithTheVisibilitySetInXml,"    @Test
    public void testPreferencesAreCreatedWithTheVisibilitySetInXml() {
        final Context context = InstrumentationRegistry.getTargetContext();
        final PreferenceManager manager = new PreferenceManager(context);
        final PreferenceScreen screen = manager.inflateFromResource(context,
                R.layout.test_visibility,
                null);

        // Preference without visibility set should be visible
        assertTrue(screen.getPreference(0).isVisible());
        // Preference with visibility set to true should be visible
        assertTrue(screen.getPreference(1).isVisible());
        // Preference with visibility set to false should not be invisible
        assertFalse(screen.getPreference(2).isVisible());
    }
",non-flaky,5
21178,androidx_androidx,SimplePreferenceComparisonCallbackTest.testNull,"    @Test
    public void testNull() throws Exception {
        assertTrue(""Compare all null"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));
    }
",non-flaky,5
21179,androidx_androidx,SimplePreferenceComparisonCallbackTest.testClassComparison,"    @Test
    public void testClassComparison() throws Exception {
        final Preference checkboxPreference =
                new CheckBoxPreference(InstrumentationRegistry.getTargetContext());
        assertFalse(""Compare class"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, checkboxPreference));
    }
",non-flaky,5
21180,androidx_androidx,SimplePreferenceComparisonCallbackTest.testDetached,"    @Test
    public void testDetached() throws Exception {
        mPref1.onDetached();
        mPref1.onAttached();
        assertFalse(""Compare same, detached"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref1));
    }
",non-flaky,5
21181,androidx_androidx,SimplePreferenceComparisonCallbackTest.testTitleComparison,"    @Test
    public void testTitleComparison() throws Exception {
        mPref1.setTitle(""value 1"");

        assertFalse(""Compare non-null to null"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));
        assertFalse(""Compare null to non-null"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref2, mPref1));

        mPref2.setTitle(""value 1"");

        assertTrue(""Compare identical"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));

        mPref2.setTitle(""value 2"");

        assertFalse(""Compare different"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));
    }
",non-flaky,5
21182,androidx_androidx,SimplePreferenceComparisonCallbackTest.testSummaryComparison,"    @Test
    public void testSummaryComparison() throws Exception {
        mPref1.setSummary(""value 1"");

        assertFalse(""Compare non-null to null"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));
        assertFalse(""Compare null to non-null"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref2, mPref1));

        mPref2.setSummary(""value 1"");

        assertTrue(""Compare identical"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));

        mPref2.setSummary(""value 2"");

        assertFalse(""Compare different"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));
    }
",non-flaky,5
21183,androidx_androidx,SimplePreferenceComparisonCallbackTest.testIconComparison,"    @Test
    public void testIconComparison() throws Exception {
        final Drawable drawable1 = new ComparisonDrawable(1);
        final Drawable drawable1a = new ComparisonDrawable(1);
        final Drawable drawable2 = new ComparisonDrawable(2);

        mPref1.setIcon(drawable1);

        assertFalse(""Compare non-null to null"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));
        assertFalse(""Compare null to non-null"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref2, mPref1));

        mPref2.setIcon(drawable1);

        assertTrue(""Compare aliased"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));

        mPref2.setIcon(drawable1a);

        assertTrue(""Compare equal"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));

        mPref2.setIcon(drawable2);

        assertFalse(""Compare unequal"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));
    }
",non-flaky,5
21184,androidx_androidx,SimplePreferenceComparisonCallbackTest.testEnabledComparison,"    @Test
    public void testEnabledComparison() throws Exception {
        mPref1.setEnabled(true);
        mPref2.setEnabled(true);

        assertTrue(""Compare enabled"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));

        mPref2.setEnabled(false);

        assertFalse(""Compare enabled/disabled"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));
        assertFalse(""Compare disable/enabled"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref2, mPref1));

        mPref1.setEnabled(false);

        assertTrue(""Compare disabled"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));
    }
",non-flaky,5
21185,androidx_androidx,SimplePreferenceComparisonCallbackTest.testSelectableComparison,"    @Test
    public void testSelectableComparison() throws Exception {
        mPref1.setSelectable(true);
        mPref2.setSelectable(true);

        assertTrue(""Compare selectable"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));

        mPref2.setSelectable(false);

        assertFalse(""Compare selectable/unselectable"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));
        assertFalse(""Compare unselectable/selectable"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref2, mPref1));

        mPref1.setSelectable(false);

        assertTrue(""Compare unselectable"",
                mComparisonCallback.arePreferenceContentsTheSame(mPref1, mPref2));
    }
",non-flaky,5
21186,androidx_androidx,SimplePreferenceComparisonCallbackTest.testTwoStateComparison,"    @Test
    public void testTwoStateComparison() throws Exception {
        final TwoStatePreference checkbox1 =
                new CheckBoxPreference(InstrumentationRegistry.getTargetContext());
        final TwoStatePreference checkbox2 =
                new CheckBoxPreference(InstrumentationRegistry.getTargetContext());

        checkbox1.setChecked(true);
        checkbox2.setChecked(true);

        assertTrue(""Compare checked"",
                mComparisonCallback.arePreferenceContentsTheSame(checkbox1, checkbox2));

        checkbox2.setChecked(false);

        assertFalse(""Compare checked/unchecked"",
                mComparisonCallback.arePreferenceContentsTheSame(checkbox1, checkbox2));
        assertFalse(""Compare unchecked/checked"",
                mComparisonCallback.arePreferenceContentsTheSame(checkbox2, checkbox1));

        checkbox1.setChecked(false);

        assertTrue(""Compare unchecked"",
                mComparisonCallback.arePreferenceContentsTheSame(checkbox1, checkbox2));
    }
",non-flaky,5
21187,androidx_androidx,SimplePreferenceComparisonCallbackTest.testDropDownComparison,"    @Test
    public void testDropDownComparison() throws Exception {
        final Preference dropdown1 =
                new DropDownPreference(InstrumentationRegistry.getTargetContext());
        final Preference dropdown2 =
                new DropDownPreference(InstrumentationRegistry.getTargetContext());

        assertTrue(""Compare aliased drop down pref"",
                mComparisonCallback.arePreferenceContentsTheSame(dropdown1, dropdown1));
        assertFalse(""Compare distinct drop down prefs"",
                mComparisonCallback.arePreferenceContentsTheSame(dropdown1, dropdown2));
    }
",non-flaky,5
21188,androidx_androidx,PreferenceIconSpaceTest.bindViewHolder_iconSpaceReserved_shouldReserveIconSpace,"    @Test
    public void bindViewHolder_iconSpaceReserved_shouldReserveIconSpace() {
        PreferenceViewHolder holder = PreferenceViewHolder.createInstanceForTests(mViewGroup);
        mPreference.setIconSpaceReserved(true);
        mPreference.onBindViewHolder(holder);

        verify(mIconView).setVisibility(View.INVISIBLE);
        verify(mImageFrame).setVisibility(View.INVISIBLE);
    }
",non-flaky,5
21189,androidx_androidx,PreferenceIconSpaceTest.bindViewHolder_iconSpaceNotReserved_shouldNotReserveIconSpace,"    @Test
    public void bindViewHolder_iconSpaceNotReserved_shouldNotReserveIconSpace() {
        PreferenceViewHolder holder = PreferenceViewHolder.createInstanceForTests(mViewGroup);
        mPreference.setIconSpaceReserved(false);
        mPreference.onBindViewHolder(holder);

        verify(mIconView).setVisibility(View.GONE);
        verify(mImageFrame).setVisibility(View.GONE);
    }
",non-flaky,5
21190,androidx_androidx,PreferenceIconSpaceTest.bindViewHolder_hasIcon_shouldDisplayIcon,"    @Test
    public void bindViewHolder_hasIcon_shouldDisplayIcon() {
        PreferenceViewHolder holder = PreferenceViewHolder.createInstanceForTests(mViewGroup);
        mPreference.setIcon(new ColorDrawable(Color.BLACK));
        mPreference.onBindViewHolder(holder);

        verify(mIconView).setVisibility(View.VISIBLE);
        verify(mImageFrame).setVisibility(View.VISIBLE);
    }
",non-flaky,5
21191,androidx_androidx,PreferenceDataStoreTest.testThatDataStoreIsNullByDefault,"    @Test
    public void testThatDataStoreIsNullByDefault() {
        Preference preference = new Preference(mContext);
        mScreen.addPreference(preference);

        assertNull(preference.getPreferenceDataStore());
        assertNotNull(preference.getSharedPreferences());

        assertNull(mManager.getPreferenceDataStore());
        assertNotNull(mManager.getSharedPreferences());
    }
",non-flaky,5
21192,androidx_androidx,PreferenceDataStoreTest.testSetGetOnPreference,"    @Test
    public void testSetGetOnPreference() {
        Preference preference = new Preference(mContext);

        preference.setPreferenceDataStore(mDataStore);

        assertEquals(mDataStore, preference.getPreferenceDataStore());
    }
",non-flaky,5
21193,androidx_androidx,PreferenceDataStoreTest.testSetGetOnPreferenceManager,"    @Test
    public void testSetGetOnPreferenceManager() {
        mManager.setPreferenceDataStore(mDataStore);

        assertEquals(mDataStore, mManager.getPreferenceDataStore());
        assertNull(mManager.getSharedPreferences());
    }
",non-flaky,5
21194,androidx_androidx,PreferenceDataStoreTest.testSetOnPreferenceManagerGetOnPreference,"    @Test
    public void testSetOnPreferenceManagerGetOnPreference() {
        Preference preference = new Preference(mContext);
        mScreen.addPreference(preference);

        mManager.setPreferenceDataStore(mDataStore);

        assertEquals(mDataStore, preference.getPreferenceDataStore());
        assertNull(preference.getSharedPreferences());
    }
",non-flaky,5
21195,androidx_androidx,PreferenceDataStoreTest.testDataStoresHierarchy,"    @Test
    public void testDataStoresHierarchy() {
        mPreference.setPreferenceDataStore(mDataStore);
        PreferenceDataStore secondaryDataStore = mock(PreferenceDataStore.class,
                Mockito.CALLS_REAL_METHODS);
        mManager.setPreferenceDataStore(secondaryDataStore);
        mScreen.addPreference(mPreference);

        mPreference.putString(TEST_STR);

        // Check that the Preference returns the correct data store.
        assertEquals(mDataStore, mPreference.getPreferenceDataStore());

        // Check that the secondary data store assigned to the manager was NOT used.
        verifyZeroInteractions(secondaryDataStore);

        // Check that the primary data store assigned directly to the preference was used.
        verify(mDataStore, atLeastOnce()).putString(eq(KEY), anyString());
    }
",non-flaky,5
21196,androidx_androidx,PreferenceDataStoreTest.testInitialValueIsFromDataStoreOnPreference,"    @Test
    public void testInitialValueIsFromDataStoreOnPreference() {
        when(mDataStore.getBoolean(anyString(), anyBoolean())).thenReturn(true);

        CheckBoxPreference pref = new CheckBoxPreference(mContext);
        pref.setKey(""CheckboxTestPref"");
        pref.setPreferenceDataStore(mDataStore);

        mScreen.addPreference(pref);

        assertTrue(pref.isChecked());
    }
",non-flaky,5
21197,androidx_androidx,PreferenceDataStoreTest.testInitialValueIsFromDataStoreOnPreferenceManager,"    @Test
    public void testInitialValueIsFromDataStoreOnPreferenceManager() {
        when(mDataStore.getBoolean(anyString(), anyBoolean())).thenReturn(true);

        mManager.setPreferenceDataStore(mDataStore);
        CheckBoxPreference pref = new CheckBoxPreference(mContext);
        pref.setKey(""CheckboxTestPref"");

        mScreen.addPreference(pref);

        assertTrue(pref.isChecked());
    }
",non-flaky,5
21198,androidx_androidx,PreferenceDataStoreTest.testPutStringWithDataStoreOnPref,"    @Test
    public void testPutStringWithDataStoreOnPref() {
        mPreference.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        putStringTestCommon();
    }
",non-flaky,5
21199,androidx_androidx,PreferenceDataStoreTest.testPutStringWithDataStoreOnMgr,"    @Test
    public void testPutStringWithDataStoreOnMgr() {
        mManager.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        putStringTestCommon();
    }
",non-flaky,5
21200,androidx_androidx,PreferenceDataStoreTest.testGetStringWithDataStoreOnPref,"    @Test
    public void testGetStringWithDataStoreOnPref() {
        mPreference.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);

        mPreference.getString(TEST_STR);

        verify(mDataStore, atLeastOnce()).getString(eq(KEY), eq(TEST_STR));
    }
",non-flaky,5
21201,androidx_androidx,PreferenceDataStoreTest.testGetStringWithDataStoreOnMgr,"    @Test
    public void testGetStringWithDataStoreOnMgr() {
        mManager.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);

        mPreference.getString(TEST_STR);

        verify(mDataStore, atLeastOnce()).getString(eq(KEY), eq(TEST_STR));
    }
",non-flaky,5
21202,androidx_androidx,PreferenceDataStoreTest.testDefaultStringValue,"    @Test
    public void testDefaultStringValue() {
        mPreference.setPreferenceDataStore(mDataStore);
        mPreference.setDefaultValue(TEST_DEFAULT_STR);
        mSharedPref.edit().putString(KEY, TEST_WRONG_STR).commit();
        mScreen.addPreference(mPreference);
        mSharedPref.edit().remove(KEY).commit();
        assertEquals(TEST_DEFAULT_STR, mPreference.getDefaultValue());
    }
",non-flaky,5
21203,androidx_androidx,PreferenceDataStoreTest.testPutStringSetWithDataStoreOnPref,"    @Test
    public void testPutStringSetWithDataStoreOnPref() {
        mPreference.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        putStringSetTestCommon();
    }
",non-flaky,5
21204,androidx_androidx,PreferenceDataStoreTest.testPutStringSetWithDataStoreOnMgr,"    @Test
    public void testPutStringSetWithDataStoreOnMgr() {
        mManager.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        putStringSetTestCommon();
    }
",non-flaky,5
21205,androidx_androidx,PreferenceDataStoreTest.testGetStringSetWithDataStoreOnPref,"    @Test
    public void testGetStringSetWithDataStoreOnPref() {
        mPreference.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        Set<String> testSet = new HashSet<>();

        mPreference.getStringSet(testSet);

        verify(mDataStore, atLeastOnce()).getStringSet(eq(KEY), eq(testSet));
    }
",non-flaky,5
21206,androidx_androidx,PreferenceDataStoreTest.testGetStringSetWithDataStoreOnMgr,"    @Test
    public void testGetStringSetWithDataStoreOnMgr() {
        mManager.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        Set<String> testSet = new HashSet<>();

        mPreference.getStringSet(testSet);

        verify(mDataStore, atLeastOnce()).getStringSet(eq(KEY), eq(testSet));
    }
",non-flaky,5
21207,androidx_androidx,PreferenceDataStoreTest.testPutIntWithDataStoreOnPref,"    @Test
    public void testPutIntWithDataStoreOnPref() {
        mPreference.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        putIntTestCommon();
    }
",non-flaky,5
21208,androidx_androidx,PreferenceDataStoreTest.testPutIntWithDataStoreOnMgr,"    @Test
    public void testPutIntWithDataStoreOnMgr() {
        mManager.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        putIntTestCommon();
    }
",non-flaky,5
21209,androidx_androidx,PreferenceDataStoreTest.testGetIntWithDataStoreOnPref,"    @Test
    public void testGetIntWithDataStoreOnPref() {
        mPreference.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);

        mPreference.getInt(1);

        verify(mDataStore, atLeastOnce()).getInt(eq(KEY), eq(1));
    }
",non-flaky,5
21210,androidx_androidx,PreferenceDataStoreTest.testGetIntWithDataStoreOnMgr,"    @Test
    public void testGetIntWithDataStoreOnMgr() {
        mManager.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);

        mPreference.getInt(1);

        verify(mDataStore, atLeastOnce()).getInt(eq(KEY), eq(1));
    }
",non-flaky,5
21211,androidx_androidx,PreferenceDataStoreTest.testPutLongWithDataStoreOnPref,"    @Test
    public void testPutLongWithDataStoreOnPref() {
        mPreference.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        putLongTestCommon();
    }
",non-flaky,5
21212,androidx_androidx,PreferenceDataStoreTest.testPutLongWithDataStoreOnMgr,"    @Test
    public void testPutLongWithDataStoreOnMgr() {
        mManager.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        putLongTestCommon();
    }
",non-flaky,5
21213,androidx_androidx,PreferenceDataStoreTest.testGetLongWithDataStoreOnPref,"    @Test
    public void testGetLongWithDataStoreOnPref() {
        mPreference.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);

        mPreference.getLong(1L);

        verify(mDataStore, atLeastOnce()).getLong(eq(KEY), eq(1L));
    }
",non-flaky,5
21214,androidx_androidx,PreferenceDataStoreTest.testGetLongWithDataStoreOnMgr,"    @Test
    public void testGetLongWithDataStoreOnMgr() {
        mManager.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);

        mPreference.getLong(1L);

        verify(mDataStore, atLeastOnce()).getLong(eq(KEY), eq(1L));
    }
",non-flaky,5
21215,androidx_androidx,PreferenceDataStoreTest.testPutFloatWithDataStoreOnPref,"    @Test
    public void testPutFloatWithDataStoreOnPref() {
        mPreference.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        putFloatTestCommon();
    }
",non-flaky,5
21216,androidx_androidx,PreferenceDataStoreTest.testPutFloatWithDataStoreOnMgr,"    @Test
    public void testPutFloatWithDataStoreOnMgr() {
        mManager.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        putFloatTestCommon();
    }
",non-flaky,5
21217,androidx_androidx,PreferenceDataStoreTest.testGetFloatWithDataStoreOnPref,"    @Test
    public void testGetFloatWithDataStoreOnPref() {
        mPreference.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);

        mPreference.getFloat(1f);

        verify(mDataStore, atLeastOnce()).getFloat(eq(KEY), eq(1f));
    }
",non-flaky,5
21218,androidx_androidx,PreferenceDataStoreTest.testGetFloatWithDataStoreOnMgr,"    @Test
    public void testGetFloatWithDataStoreOnMgr() {
        mManager.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);

        mPreference.getFloat(1f);

        verify(mDataStore, atLeastOnce()).getFloat(eq(KEY), eq(1f));
    }
",non-flaky,5
21219,androidx_androidx,PreferenceDataStoreTest.testPutBooleanWithDataStoreOnPref,"    @Test
    public void testPutBooleanWithDataStoreOnPref() {
        mPreference.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        putBooleanTestCommon();
    }
",non-flaky,5
21220,androidx_androidx,PreferenceDataStoreTest.testPutBooleanWithDataStoreOnMgr,"    @Test
    public void testPutBooleanWithDataStoreOnMgr() {
        mManager.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);
        putBooleanTestCommon();
    }
",non-flaky,5
21221,androidx_androidx,PreferenceDataStoreTest.testGetBooleanWithDataStoreOnPref,"    @Test
    public void testGetBooleanWithDataStoreOnPref() {
        mPreference.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);

        mPreference.getBoolean(true);

        verify(mDataStore, atLeastOnce()).getBoolean(eq(KEY), eq(true));
    }
",non-flaky,5
21222,androidx_androidx,PreferenceDataStoreTest.testGetBooleanWithDataStoreOnMgr,"    @Test
    public void testGetBooleanWithDataStoreOnMgr() {
        mManager.setPreferenceDataStore(mDataStore);
        mScreen.addPreference(mPreference);

        mPreference.getBoolean(true);

        verify(mDataStore, atLeastOnce()).getBoolean(eq(KEY), eq(true));
    }
",non-flaky,5
21223,androidx_androidx,PreferenceDataStoreTest.testSharedPrefNotNullIfNoDS,"    @Test
    public void testSharedPrefNotNullIfNoDS() {
        mScreen.addPreference(mPreference);

        assertNotNull(mPreference.getSharedPreferences());
    }
",non-flaky,5
21224,androidx_androidx,PreferenceDataStoreTest.testSharedPrefNotNullIfNoDSMgr,"    @Test
    public void testSharedPrefNotNullIfNoDSMgr() {
        assertNotNull(mManager.getSharedPreferences());
    }
",non-flaky,5
21225,androidx_androidx,PreferenceDataStoreTest.testSharedPrefNullIfWithDS,"    @Test
    public void testSharedPrefNullIfWithDS() {
        mScreen.addPreference(mPreference);

        mPreference.setPreferenceDataStore(mDataStore);

        assertNull(mPreference.getSharedPreferences());
    }
",non-flaky,5
21226,androidx_androidx,PreferenceDataStoreTest.testSharedPrefNullIfWithDSMgr,"    @Test
    public void testSharedPrefNullIfWithDSMgr() {
        mManager.setPreferenceDataStore(mDataStore);

        assertNull(mManager.getSharedPreferences());
    }
",non-flaky,5
21227,androidx_androidx,ExpandablePreferenceTest.expandablePreference_inPreferenceScreen_collapsesCorrectly,"    @Test
    public void expandablePreference_inPreferenceScreen_collapsesCorrectly() {

        mScreen.setKey(""screen"");
        mScreen.setInitialExpandedChildrenCount(1);

        mScreen.addPreference(mPreference1);
        mScreen.addPreference(mPreference2);
        mScreen.addPreference(mPreference3);

        PreferenceGroupAdapter preferenceGroupAdapter = new PreferenceGroupAdapter(mScreen);

        assertEquals(2, preferenceGroupAdapter.getItemCount());

        assertEquals(mPreference1, preferenceGroupAdapter.getItem(0));
        assertEquals(""Advanced"", preferenceGroupAdapter.getItem(1).getTitle());
        assertEquals(""Preference 2, Preference 3"", preferenceGroupAdapter.getItem(1).getSummary());
    }
",non-flaky,5
21228,androidx_androidx,ExpandablePreferenceTest.expandablePreference_inCategory_collapsesCorrectly,"    @Test
    public void expandablePreference_inCategory_collapsesCorrectly() {
        PreferenceCategory category = new PreferenceCategory(mContext);

        mScreen.addPreference(category);

        category.setKey(""category"");
        category.setInitialExpandedChildrenCount(1);

        category.addPreference(mPreference1);
        category.addPreference(mPreference2);
        category.addPreference(mPreference3);

        PreferenceGroupAdapter preferenceGroupAdapter = new PreferenceGroupAdapter(mScreen);

        assertEquals(3, preferenceGroupAdapter.getItemCount());

        assertEquals(category, preferenceGroupAdapter.getItem(0));
        assertEquals(mPreference1, preferenceGroupAdapter.getItem(1));
        assertEquals(""Advanced"", preferenceGroupAdapter.getItem(2).getTitle());
        assertEquals(""Preference 2, Preference 3"", preferenceGroupAdapter.getItem(2).getSummary());
    }
",non-flaky,5
21229,androidx_androidx,ExpandablePreferenceTest.expandablePreference_inNestedCategory_collapsesCorrectly,"    @Test
    public void expandablePreference_inNestedCategory_collapsesCorrectly() {
        PreferenceCategory category = new PreferenceCategory(mContext);
        PreferenceCategory nestedCategory = new PreferenceCategory(mContext);

        mScreen.addPreference(category);
        category.addPreference(nestedCategory);

        nestedCategory.setKey(""nested_category"");
        nestedCategory.setInitialExpandedChildrenCount(1);

        nestedCategory.addPreference(mPreference1);
        nestedCategory.addPreference(mPreference2);
        nestedCategory.addPreference(mPreference3);

        PreferenceGroupAdapter preferenceGroupAdapter = new PreferenceGroupAdapter(mScreen);

        assertEquals(4, preferenceGroupAdapter.getItemCount());

        assertEquals(category, preferenceGroupAdapter.getItem(0));
        assertEquals(nestedCategory, preferenceGroupAdapter.getItem(1));
        assertEquals(mPreference1, preferenceGroupAdapter.getItem(2));
        assertEquals(""Advanced"", preferenceGroupAdapter.getItem(3).getTitle());
        assertEquals(""Preference 2, Preference 3"", preferenceGroupAdapter.getItem(3).getSummary());
    }
",non-flaky,5
21230,androidx_androidx,ExpandablePreferenceTest.expandablePreference_inCategoryContainingAnotherCategory_collapsesCorrectly,"    @Test
    public void expandablePreference_inCategoryContainingAnotherCategory_collapsesCorrectly() {
        PreferenceCategory category = new PreferenceCategory(mContext);
        PreferenceCategory nestedCategory = new PreferenceCategory(mContext);

        mScreen.addPreference(category);

        category.setKey(""nested_category"");
        category.setInitialExpandedChildrenCount(1);

        category.addPreference(mPreference1);
        category.addPreference(nestedCategory);
        nestedCategory.addPreference(mPreference2);
        nestedCategory.addPreference(mPreference3);

        PreferenceGroupAdapter preferenceGroupAdapter = new PreferenceGroupAdapter(mScreen);

        assertEquals(3, preferenceGroupAdapter.getItemCount());

        assertEquals(category, preferenceGroupAdapter.getItem(0));
        assertEquals(mPreference1, preferenceGroupAdapter.getItem(1));
        assertEquals(""Advanced"", preferenceGroupAdapter.getItem(2).getTitle());
        assertEquals(""Preference 2, Preference 3"", preferenceGroupAdapter.getItem(2).getSummary());

        // If the nested category has a title, display that in the summary instead of the children
        final String title = ""Category"";
        nestedCategory.setTitle(title);

        preferenceGroupAdapter = new PreferenceGroupAdapter(mScreen);

        assertEquals(3, preferenceGroupAdapter.getItemCount());

        assertEquals(category, preferenceGroupAdapter.getItem(0));
        assertEquals(mPreference1, preferenceGroupAdapter.getItem(1));
        assertEquals(""Advanced"", preferenceGroupAdapter.getItem(2).getTitle());
        assertEquals(title, preferenceGroupAdapter.getItem(2).getSummary());
    }
",non-flaky,5
21231,androidx_androidx,ExpandablePreferenceTest.nestedExpandablePreferences_notAllowed_shouldThrowAnException,"    @Test(expected = IllegalArgumentException.class)
    public void nestedExpandablePreferences_notAllowed_shouldThrowAnException() {
        PreferenceCategory category = new PreferenceCategory(mContext);
        PreferenceCategory nestedCategory = new PreferenceCategory(mContext);

        mScreen.addPreference(category);
        category.addPreference(nestedCategory);

        category.setKey(""category"");
        category.setInitialExpandedChildrenCount(1);

        nestedCategory.setKey(""nested_category"");
        nestedCategory.setInitialExpandedChildrenCount(1);

        // Trying to nest expandable preferences should throw an exception
        new PreferenceGroupAdapter(mScreen);
    }
",non-flaky,5
21232,androidx_androidx,PreferencePersistTest.string_retrieveWhenEmpty_returnsDefault,"    @Test
    public void string_retrieveWhenEmpty_returnsDefault() {
        final String expected = ""Default"";

        String result = mPreference.getString(expected);

        assertEquals(expected, result);
    }
",non-flaky,5
21233,androidx_androidx,PreferencePersistTest.string_persist_getsStoredToSharedPrefs,"    @Test
    public void string_persist_getsStoredToSharedPrefs() {
        final String expected = ""Test"";

        boolean wasPersisted = mPreference.putString(expected);

        assertTrue(wasPersisted);
        assertEquals(expected, mSharedPref.getString(KEY, null));
    }
",non-flaky,5
21234,androidx_androidx,PreferencePersistTest.string_persistWhileDisabled_notPersisted,"    @Test
    public void string_persistWhileDisabled_notPersisted() {
        mPreference.setPersistent(false);

        boolean wasPersisted = mPreference.putString(""Test"");

        assertFalse(wasPersisted);
        assertNull(mSharedPref.getString(KEY, null));
    }
",non-flaky,5
21235,androidx_androidx,PreferencePersistTest.string_persistAndRetrieve_returnsPersistedValue,"    @Test
    public void string_persistAndRetrieve_returnsPersistedValue() {
        final String expected = ""Test"";

        mPreference.putString(expected);
        String result = mPreference.getString(""Default"");

        assertEquals(expected, result);
    }
",non-flaky,5
21236,androidx_androidx,PreferencePersistTest.string_persistTwiceAndRetrieve_returnsSecondValue,"    @Test
    public void string_persistTwiceAndRetrieve_returnsSecondValue() {
        final String expected = ""Second"";

        mPreference.putString(""First"");
        mPreference.putString(expected);
        String result = mPreference.getString(""Default"");

        assertEquals(expected, result);
    }
",non-flaky,5
21237,androidx_androidx,PreferencePersistTest.stringSet_retrieveWhenEmpty_returnsDefault,"    @Test
    public void stringSet_retrieveWhenEmpty_returnsDefault() {
        final Set<String> expected = TEST_DEFAULT_STR_SET;

        Set<String> result = mPreference.getStringSet(expected);

        assertThat(result, containsInAnyOrder(expected.toArray()));
    }
",non-flaky,5
21238,androidx_androidx,PreferencePersistTest.stringSet_persist_getsStoredToSharedPrefs,"    @Test
    public void stringSet_persist_getsStoredToSharedPrefs() {
        boolean wasPersisted = mPreference.putStringSet(TEST_DEFAULT_STR_SET);

        assertTrue(wasPersisted);
        assertThat(mSharedPref.getStringSet(KEY, null),
                containsInAnyOrder(TEST_DEFAULT_STR_SET.toArray()));
    }
",non-flaky,5
21239,androidx_androidx,PreferencePersistTest.stringSet_persistWhileDisabled_notPersisted,"    @Test
    public void stringSet_persistWhileDisabled_notPersisted() {
        mPreference.setPersistent(false);

        boolean wasPersisted = mPreference.putStringSet(TEST_STR_SET);

        assertFalse(wasPersisted);
        assertNull(mSharedPref.getString(KEY, null));
    }
",non-flaky,5
21240,androidx_androidx,PreferencePersistTest.stringSet_persistAndRetrieve_returnsPersistedValue,"    @Test
    public void stringSet_persistAndRetrieve_returnsPersistedValue() {
        final Set<String> expected = TEST_STR_SET;

        mPreference.putStringSet(expected);
        Set<String> result = mPreference.getStringSet(TEST_DEFAULT_STR_SET);

        assertThat(result, containsInAnyOrder(expected.toArray()));
    }
",non-flaky,5
21241,androidx_androidx,PreferencePersistTest.stringSet_persistTwiceAndRetrieve_returnsSecondValue,"    @Test
    public void stringSet_persistTwiceAndRetrieve_returnsSecondValue() {
        final Set<String> expected = TEST_STR_SET2;

        mPreference.putStringSet(TEST_STR_SET);
        mPreference.putStringSet(expected);
        Set<String> result = mPreference.getStringSet(TEST_DEFAULT_STR_SET);

        assertThat(result, containsInAnyOrder(expected.toArray()));
    }
",non-flaky,5
21242,androidx_androidx,PreferencePersistTest.int_retrieveWhenEmpty_returnsDefault,"    @Test
    public void int_retrieveWhenEmpty_returnsDefault() {
        final int expected = 1;
        int result = mPreference.getInt(expected);

        assertEquals(expected, result);
    }
",non-flaky,5
21243,androidx_androidx,PreferencePersistTest.int_persist_getsStoredToSharedPrefs,"    @Test
    public void int_persist_getsStoredToSharedPrefs() {
        final int expected = 1;

        boolean wasPersisted = mPreference.putInt(expected);

        assertTrue(wasPersisted);
        assertEquals(expected, mSharedPref.getInt(KEY, -1));
    }
",non-flaky,5
21244,androidx_androidx,PreferencePersistTest.int_persistWhileDisabled_notPersisted,"    @Test
    public void int_persistWhileDisabled_notPersisted() {
        mPreference.setPersistent(false);

        boolean wasPersisted = mPreference.putInt(1);

        assertFalse(wasPersisted);
        assertEquals(-1, mSharedPref.getLong(KEY, -1));
    }
",non-flaky,5
21245,androidx_androidx,PreferencePersistTest.int_persistAndRetrieve_returnsPersistedValue,"    @Test
    public void int_persistAndRetrieve_returnsPersistedValue() {
        final int expected = 1;

        mPreference.putInt(expected);
        int result = mPreference.getInt(-1);

        assertEquals(expected, result);
    }
",non-flaky,5
21246,androidx_androidx,PreferencePersistTest.int_persistTwiceAndRetrieve_returnsSecondValue,"    @Test
    public void int_persistTwiceAndRetrieve_returnsSecondValue() {
        final int expected = 2;

        mPreference.putInt(1);
        mPreference.putInt(expected);
        int result = mPreference.getInt(-1);

        assertEquals(expected, result);
    }
",non-flaky,5
21247,androidx_androidx,PreferencePersistTest.long_retrieveWhenEmpty_returnsDefault,"    @Test
    public void long_retrieveWhenEmpty_returnsDefault() {
        assertEquals(1, mPreference.getLong(1));
    }
",non-flaky,5
21248,androidx_androidx,PreferencePersistTest.long_persist_getsStoredToSharedPrefs,"    @Test
    public void long_persist_getsStoredToSharedPrefs() {
        final long expected = 1;

        boolean wasPersisted = mPreference.putLong(expected);

        assertTrue(wasPersisted);
        assertEquals(expected, mSharedPref.getLong(KEY, -1));
    }
",non-flaky,5
21249,androidx_androidx,PreferencePersistTest.long_persistWhileDisabled_notPersisted,"    @Test
    public void long_persistWhileDisabled_notPersisted() {
        mPreference.setPersistent(false);

        boolean wasPersisted = mPreference.putLong(1);

        assertFalse(wasPersisted);
        assertEquals(-1, mSharedPref.getLong(KEY, -1));
    }
",non-flaky,5
21250,androidx_androidx,PreferencePersistTest.long_persistAndRetrieve_returnsPersistedValue,"    @Test
    public void long_persistAndRetrieve_returnsPersistedValue() {
        final long expected = 1;

        mPreference.putLong(expected);
        long result = mPreference.getLong(-1);

        assertEquals(expected, result);
    }
",non-flaky,5
21251,androidx_androidx,PreferencePersistTest.long_persistTwiceAndRetrieve_returnsSecondValue,"    @Test
    public void long_persistTwiceAndRetrieve_returnsSecondValue() {
        final long expected = 2;

        mPreference.putLong(1);
        mPreference.putLong(expected);
        long result = mPreference.getLong(-1);

        assertEquals(expected, result);
    }
",non-flaky,5
21252,androidx_androidx,PreferencePersistTest.float_retrieveWhenEmpty_returnsDefault,"    @Test
    public void float_retrieveWhenEmpty_returnsDefault() {
        assertEquals(1, mPreference.getFloat(1), FLOAT_PRECISION);
    }
",non-flaky,5
21253,androidx_androidx,PreferencePersistTest.float_persist_getsStoredToSharedPrefs,"    @Test
    public void float_persist_getsStoredToSharedPrefs() {
        final float expected = 1;

        boolean wasPersisted = mPreference.putFloat(expected);

        assertTrue(wasPersisted);
        assertEquals(expected, mSharedPref.getFloat(KEY, -1), FLOAT_PRECISION);
    }
",non-flaky,5
21254,androidx_androidx,PreferencePersistTest.float_persistWhileDisabled_notPersisted,"    @Test
    public void float_persistWhileDisabled_notPersisted() {
        mPreference.setPersistent(false);

        boolean wasPersisted = mPreference.putFloat(1);

        assertFalse(wasPersisted);
        assertEquals(-1, mSharedPref.getFloat(KEY, -1), FLOAT_PRECISION);
    }
",non-flaky,5
21255,androidx_androidx,PreferencePersistTest.float_persistAndRetrieve_returnsPersistedValue,"    @Test
    public void float_persistAndRetrieve_returnsPersistedValue() {
        final float expected = 1;

        mPreference.putFloat(expected);
        float result = mPreference.getFloat(-1);

        assertEquals(expected, result, FLOAT_PRECISION);
    }
",non-flaky,5
21256,androidx_androidx,PreferencePersistTest.float_persistTwiceAndRetrieve_returnsSecondValue,"    @Test
    public void float_persistTwiceAndRetrieve_returnsSecondValue() {
        final float expected = 2;

        mPreference.putFloat(1);
        mPreference.putFloat(expected);
        float result = mPreference.getFloat(-1);

        assertEquals(expected, result, FLOAT_PRECISION);
    }
",non-flaky,5
21257,androidx_androidx,PreferencePersistTest.boolean_retrieveWhenEmpty_returnsDefault,"    @Test
    public void boolean_retrieveWhenEmpty_returnsDefault() {
        final boolean expected = true;

        boolean result = mPreference.getBoolean(expected);

        assertEquals(expected, result);
    }
",non-flaky,5
21258,androidx_androidx,PreferencePersistTest.boolean_persist_getsStoredToSharedPrefs,"    @Test
    public void boolean_persist_getsStoredToSharedPrefs() {
        final boolean expected = true;

        boolean wasPersisted = mPreference.putBoolean(expected);

        assertTrue(wasPersisted);
        assertEquals(expected, mSharedPref.getBoolean(KEY, !expected));
    }
",non-flaky,5
21259,androidx_androidx,PreferencePersistTest.boolean_persistWhileDisabled_notPersisted,"    @Test
    public void boolean_persistWhileDisabled_notPersisted() {
        mPreference.setPersistent(false);

        boolean wasPersisted = mPreference.putBoolean(true);

        assertFalse(wasPersisted);
        assertEquals(false, mSharedPref.getBoolean(KEY, false));
    }
",non-flaky,5
21260,androidx_androidx,PreferencePersistTest.boolean_persistAndRetrieve_returnsPersistedValue,"    @Test
    public void boolean_persistAndRetrieve_returnsPersistedValue() {
        final boolean expected = true;

        mPreference.putBoolean(expected);
        boolean result = mPreference.getBoolean(!expected);

        assertEquals(expected, result);
    }
",non-flaky,5
21261,androidx_androidx,PreferencePersistTest.boolean_persistTwiceAndRetrieve_returnsSecondValue,"    @Test
    public void boolean_persistTwiceAndRetrieve_returnsSecondValue() {
        final boolean expected = false;

        mPreference.putBoolean(!expected);
        mPreference.putBoolean(expected);
        boolean result = mPreference.getBoolean(!expected);

        assertEquals(expected, result);
    }
",non-flaky,5
21262,androidx_androidx,PreferenceParentGroupTest.parentAddRemoveTest,"    @Test
    public void parentAddRemoveTest() {
        PreferenceManager manager = new PreferenceManager(mContext);

        PreferenceScreen screen = manager.createPreferenceScreen(mContext);
        assertNull(screen.getParent());

        PreferenceCategory category = new PreferenceCategory(mContext);
        assertNull(category.getParent());

        CheckBoxPreference pref = new CheckBoxPreference(mContext);
        assertNull(pref.getParent());

        screen.addPreference(category);
        assertEquals(screen, category.getParent());

        category.addPreference(pref);
        assertEquals(category, pref.getParent());

        screen.removePreference(category);
        assertNull(category.getParent());

        category.removePreference(pref);
        assertNull(pref.getParent());
    }
",non-flaky,5
21263,androidx_androidx,PreferenceParentGroupTest.parentReassignTest,"    @Test
    public void parentReassignTest() {
        PreferenceManager manager = new PreferenceManager(mContext);

        PreferenceScreen screen = manager.createPreferenceScreen(mContext);

        PreferenceCategory category1 = new PreferenceCategory(mContext);
        screen.addPreference(category1);
        PreferenceCategory category2 = new PreferenceCategory(mContext);
        screen.addPreference(category2);

        CheckBoxPreference pref = new CheckBoxPreference(mContext);
        assertNull(pref.getParent());

        category1.addPreference(pref);
        assertEquals(category1, pref.getParent());

        category1.removePreference(pref);
        category2.addPreference(pref);
        assertEquals(category2, pref.getParent());
    }
",non-flaky,5
21264,androidx_androidx,PreferenceParentGroupTest.parentDoubleAddTest,"    @Test
    public void parentDoubleAddTest() throws InterruptedException {
        PreferenceManager manager = new PreferenceManager(mContext);

        PreferenceScreen screen = manager.createPreferenceScreen(mContext);

        PreferenceCategory category1 = new PreferenceCategory(mContext);
        screen.addPreference(category1);
        PreferenceCategory category2 = new PreferenceCategory(mContext);
        screen.addPreference(category2);

        CheckBoxPreference pref = new CheckBoxPreference(mContext);
        assertNull(pref.getParent());

        category1.addPreference(pref);
        category2.addPreference(pref);

        assertEquals(category2, pref.getParent());
    }
",non-flaky,5
21265,androidx_androidx,PreferenceSingleLineTitleTest.bindViewHolder_singleLineTitleNotSet_shouldNotSetSingleLine,"    @Test
    public void bindViewHolder_singleLineTitleNotSet_shouldNotSetSingleLine() {
        PreferenceViewHolder holder = PreferenceViewHolder.createInstanceForTests(mViewGroup);
        mPreference.onBindViewHolder(holder);

        verify(mTitleView, never()).setSingleLine(anyBoolean());
    }
",non-flaky,5
21266,androidx_androidx,PreferenceSingleLineTitleTest.bindViewHolder_singleLineTitleSetToTrue_shouldSetSingleLineToTrue,"    @Test
    public void bindViewHolder_singleLineTitleSetToTrue_shouldSetSingleLineToTrue() {
        PreferenceViewHolder holder = PreferenceViewHolder.createInstanceForTests(mViewGroup);
        mPreference.setSingleLineTitle(true);
        mPreference.onBindViewHolder(holder);

        verify(mTitleView).setSingleLine(true);
    }
",non-flaky,5
26696,MundaneImmortal_pair-distribution-app,PairingBoardTest.testParseDevOpsCompany,"	@Test
	public void testParseDevOpsCompany() {
		PairingBoard pairingBoard = new PairingBoard(null, null, null);
		
		assertThat(pairingBoard.parseDevOpsCompanies(""devops:company""), is(new String[] {""company""}));
		assertThat(pairingBoard.parseDevOpsCompanies(""devops:company,companyb""), is(new String[] {""company"", ""companyb""}));
		assertThat(pairingBoard.parseDevOpsCompanies(""devops:""), is(new String[] {}));
	}
",non-flaky,5
26697,MundaneImmortal_pair-distribution-app,PairTest.testGetAndSetDevs,"	@Test
	public void testGetAndSetDevs()  {
		Pair subject = new Pair();
		subject.setDevs(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		
		assertThat(subject.getDevs(), is(equalTo(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")))));
	}
",non-flaky,5
26698,MundaneImmortal_pair-distribution-app,PairTest.testGetAndSetDevsWithNullValues,"	@Test
	public void testGetAndSetDevsWithNullValues()  {
		Pair subject = new Pair();
		subject.setDevs(Arrays.asList(null, new Developer(""dev2"")));
		
		assertThat(subject.getDevs(), is(equalTo(Arrays.asList(new Developer(""dev2"")))));
	}
",non-flaky,5
26699,MundaneImmortal_pair-distribution-app,PairTest.testAddDev,"	@Test
	public void testAddDev()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.getDevs(), is(equalTo(Arrays.asList(new Developer(""dev1"")))));
	}
",non-flaky,5
26700,MundaneImmortal_pair-distribution-app,PairTest.testAddDevWithNull,"	@Test
	public void testAddDevWithNull()  {
		Pair subject = new Pair();
		
		subject.addDev(null);
		
		assertThat(subject.getDevs().isEmpty(), is(true));
	}
",non-flaky,5
26701,MundaneImmortal_pair-distribution-app,PairTest.testHasDev,"	@Test
	public void testHasDev()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.hasDev(new Developer(""dev1"")), is(true));
	}
",non-flaky,5
26702,MundaneImmortal_pair-distribution-app,PairTest.testGetOtherDev,"	@Test
	public void testGetOtherDev()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		
		assertThat(subject.getOtherDev(new Developer(""dev1"")), is(equalTo(new Developer(""dev2""))));
	}
",non-flaky,5
26703,MundaneImmortal_pair-distribution-app,PairTest.testOtherDevWithOneDev,"	@Test
	public void testOtherDevWithOneDev()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.getOtherDev(new Developer(""dev1"")), nullValue());
	}
",non-flaky,5
26704,MundaneImmortal_pair-distribution-app,PairTest.testIsComplete,"	@Test
	public void testIsComplete()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		
		assertThat(subject.isComplete(), is(true));
	}
",non-flaky,5
26705,MundaneImmortal_pair-distribution-app,PairTest.testIsCompleteWithOneDev,"	@Test
	public void testIsCompleteWithOneDev()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.isComplete(), is(false));
	}
",non-flaky,5
26706,MundaneImmortal_pair-distribution-app,PairTest.testToString,"	@Test
	public void testToString()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.toString(), is(equalTo(""Pair [devs=[dev1], opsPair=false, locked=false]"")));
	}
",non-flaky,5
26707,MundaneImmortal_pair-distribution-app,PairTest.testHashCode,"	@Test
	public void testHashCode()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.hashCode(), is(equalTo(subject2.hashCode())));
	}
",non-flaky,5
26708,MundaneImmortal_pair-distribution-app,PairTest.testHashCodeNotEqual,"	@Test
	public void testHashCodeNotEqual()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev2"")));
		
		assertThat(subject.hashCode(), is(not(equalTo(subject2.hashCode()))));
	}
",non-flaky,5
26709,MundaneImmortal_pair-distribution-app,PairTest.testEqual,"	@Test
	public void testEqual()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.equals(subject2), is(true));
	}
",non-flaky,5
26710,MundaneImmortal_pair-distribution-app,PairTest.testEqualWithOpsTrue,"	@Test
	public void testEqualWithOpsTrue()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		subject.setOpsPair(true);
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev1"")));
		subject2.setOpsPair(true);
		
		assertThat(subject.equals(subject2), is(true));
	}
",non-flaky,5
26711,MundaneImmortal_pair-distribution-app,PairTest.testEqualDifferentPairs,"	@Test
	public void testEqualDifferentPairs()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev2"")));
		
		assertThat(subject.equals(subject2), is(false));
	}
",non-flaky,5
26712,MundaneImmortal_pair-distribution-app,PairTest.testIsSolo,"	@Test
	public void testIsSolo()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		
		assertThat(subject.equals(subject2), is(false));
	}
",non-flaky,5
26713,MundaneImmortal_pair-distribution-app,PairTest.testIsBuildPairFalse,"	@Test
	public void testIsBuildPairFalse()  {
		Pair subject = new Pair();
		
		subject.setBuildPair(false);
		
		assertThat(subject.isBuildPair(), is(false));
	}
",non-flaky,5
26714,MundaneImmortal_pair-distribution-app,PairTest.testIsBuildPairTrue,"	@Test
	public void testIsBuildPairTrue()  {
		Pair subject = new Pair();
		
		subject.setBuildPair(true);
		
		assertThat(subject.isBuildPair(), is(true));
	}
",non-flaky,5
26715,MundaneImmortal_pair-distribution-app,PairTest.testIsCommunitydPairFalse,"	@Test
	public void testIsCommunitydPairFalse()  {
		Pair subject = new Pair();
		
		subject.setCommunityPair(false);
		
		assertThat(subject.isCommunityPair(), is(false));
	}
",non-flaky,5
26716,MundaneImmortal_pair-distribution-app,PairTest.testIsOpsPairTrue,"	@Test
	public void testIsOpsPairTrue()  {
		Pair subject = new Pair();
		
		subject.setOpsPair(true);
		
		assertThat(subject.isOpsPair(), is(true));
	}
",non-flaky,5
26717,MundaneImmortal_pair-distribution-app,PairTest.testIsOpsPairFalse,"	@Test
	public void testIsOpsPairFalse()  {
		Pair subject = new Pair();
		
		subject.setOpsPair(false);
		
		assertThat(subject.isOpsPair(), is(false));
	}
",non-flaky,5
26718,MundaneImmortal_pair-distribution-app,PairTest.testIsCommunityPairTrue,"	@Test
	public void testIsCommunityPairTrue()  {
		Pair subject = new Pair();
		
		subject.setCommunityPair(true);
		
		assertThat(subject.isCommunityPair(), is(true));
	}
",non-flaky,5
26719,MundaneImmortal_pair-distribution-app,PairTest.testTrackDefault,"	@Test
	public void testTrackDefault() {
		Pair subject = new Pair();
		
		assertThat(subject.getTrack(), is(""""));
	}
",non-flaky,5
26720,MundaneImmortal_pair-distribution-app,PairTest.testTrackSet,"	@Test
	public void testTrackSet() {
		Pair subject = new Pair();
		
		subject.setTrack(""track"");
		
		assertThat(subject.getTrack(), is(""track""));
	}
",non-flaky,5
26721,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testGetPairsReturnOnlyDevPairs,"	@Test
	public void testGetPairsReturnOnlyDevPairs() {
		List<DayPairs> pairsListFromDevs = getPairsListFromDevs(getStandardDevs(), false);
		Pair opsPair = pairsListFromDevs.get(0).getPairByTrack(""track1"");
		opsPair.setOpsPair(true);
		
		List<Pair> pairs = new OpsPairCombinations(pairsListFromDevs).getPairs();
		
		assertThat(pairs.contains(opsPair), is(true));
		assertThat(pairs.size(), is(1));
	}
",non-flaky,5
26722,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testGetPastPairs,"	@Test
	public void testGetPastPairs() {
		List<Developer> standardDevs = getStandardDevs();
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(getPairsListFromDevs(standardDevs));
		
		
		assertThat(devPairCombinations.getPastPairs(0), is(getPairsListFromDevs(standardDevs).get(0).getPairs().values().stream().collect(Collectors.toList())));
		assertThat(devPairCombinations.getPastPairs(1), is(getPairsListFromDevs(standardDevs).get(1).getPairs().values().stream().collect(Collectors.toList())));
		assertThat(devPairCombinations.getPastPairs(2), is(getPairsListFromDevs(standardDevs).get(2).getPairs().values().stream().collect(Collectors.toList())));
	}
",non-flaky,5
26723,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testGetPastPairsFiltersOps,"	@Test
	public void testGetPastPairsFiltersOps() {
		List<DayPairs> pairsListFromDevs = getPairsListFromDevs(getStandardDevs(), false);
		Pair opsPair = pairsListFromDevs.get(0).getPairByTrack(""track1"");
		opsPair.setOpsPair(true);
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(pairsListFromDevs);
		
		
		assertThat(devPairCombinations.getPastPairs(0), is(Arrays.asList(pairsListFromDevs.get(0).getPairByTrack(""track1""))));
	}
",non-flaky,5
26724,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testGetPastPairsForMissingHistory,"	@Test
	public void testGetPastPairsForMissingHistory() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairs(3), is(nullValue()));
	}
",non-flaky,5
26725,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testGetPastPairByTrack,"	@Test
	public void testGetPastPairByTrack() {
		List<Developer> standardDevs = getStandardDevs();
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(getPairsListFromDevs(standardDevs));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(0, ""track1""), is(getPairsListFromDevs(standardDevs).get(0).getPairByTrack(""track1"")));
		assertThat(devPairCombinations.getPastPairByTrack(1, ""track2""), is(getPairsListFromDevs(standardDevs).get(1).getPairByTrack(""track2"")));
		assertThat(devPairCombinations.getPastPairByTrack(2, ""track1""), is(getPairsListFromDevs(standardDevs).get(2).getPairByTrack(""track1"")));
	}
",non-flaky,5
26726,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testGetPastPairByTrackThrowsRuntimeErrorForOpsPair,"	@Test(expected =  RuntimeException.class)
	public void testGetPastPairByTrackThrowsRuntimeErrorForOpsPair() {
		List<DayPairs> pairsListFromDevs = getPairsListFromDevs(getStandardDevs(), false);
		Pair opsPair = pairsListFromDevs.get(0).getPairByTrack(""track1"");
		opsPair.setOpsPair(true);
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(pairsListFromDevs);
		
		
		devPairCombinations.getPastPairByTrack(0, ""track2"");
	}
",non-flaky,5
26727,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testGetPastPairByTrackForMissingHistory,"	@Test
	public void testGetPastPairByTrackForMissingHistory() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(3, ""track1""), is(nullValue()));
	}
",non-flaky,5
26728,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testGetPastPairByTrackForMissingTrack,"	@Test
	public void testGetPastPairByTrackForMissingTrack() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(1, ""track5""), is(nullValue()));
	}
",non-flaky,5
26729,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testIsRotationTimeForEmptyHistory,"	@Test
	public void testIsRotationTimeForEmptyHistory() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(new ArrayList<>());
		Company company = new Company(""myCompany"");
		company.setDevOpsRotationStrategy(""weekly"");
		devPairCombinations.setCompany(company);

		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1""), getStandardDevs(), false), is(false));
	}
",non-flaky,5
26730,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testIsRotationTimeForEmptyHistoryWithEveryDayRotation,"	@Test
	public void testIsRotationTimeForEmptyHistoryWithEveryDayRotation() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(new ArrayList<>());
		Company company = new Company(""myCompany"");
		company.setDevOpsRotationStrategy(""weekly"");
		devPairCombinations.setCompany(company);

		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1""), getStandardDevs(), true), is(false));
	}
",non-flaky,5
26731,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testIsRotationTimeForEmptyHistoryWithEveryDayRotationAnNoWeeklyRotation,"	@Test
	public void testIsRotationTimeForEmptyHistoryWithEveryDayRotationAnNoWeeklyRotation() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(new ArrayList<>());

		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1""), getStandardDevs(), true), is(true));
	}
",non-flaky,5
26732,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testIsRotationTimeForSameWeek,"	@Test
	public void testIsRotationTimeForSameWeek() {
		List<Developer> standardDevs = getStandardDevs();
		DayPairs pairs = new DayPairs();
		pairs.setDate(new Date());
		pairs.addPair(""track1"", new Pair(Arrays.asList(standardDevs.get(0), standardDevs.get(1)), true, ""track1""));
		
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(Arrays.asList(pairs));
		Company company = new Company(""myCompany"");
		company.setDevOpsRotationStrategy(""weekly"");
		devPairCombinations.setCompany(company);
		
		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1""), standardDevs, false), is(false));
	}
",non-flaky,5
26733,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testIsRotationTimeForSameWeekWithEveryDayRotation,"	@Test
	public void testIsRotationTimeForSameWeekWithEveryDayRotation() {
		List<Developer> standardDevs = getStandardDevs();
		DayPairs pairs = new DayPairs();
		pairs.setDate(new Date());
		pairs.addPair(""track1"", new Pair(Arrays.asList(standardDevs.get(0), standardDevs.get(1)), true, ""track1""));
		
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(Arrays.asList(pairs));
		Company company = new Company(""myCompany"");
		company.setDevOpsRotationStrategy(""weekly"");
		devPairCombinations.setCompany(company);

		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1""), standardDevs, true), is(false));
	}
",non-flaky,5
26734,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testIsRotationForDifferentWeekPairs,"	@Test
	public void testIsRotationForDifferentWeekPairs() {
		List<Developer> standardDevs = getStandardDevs();
		DayPairs pairs = new DayPairs();
		pairs.setDate(getDateWeeksBefore(1));
		pairs.addPair(""track1"", new Pair(Arrays.asList(standardDevs.get(0), standardDevs.get(1)), true, ""track1""));
		
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(Arrays.asList(pairs));
		Company company = new Company(""myCompany"");
		company.setDevOpsRotationStrategy(""weekly"");
		devPairCombinations.setCompany(company);

		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1""), standardDevs, false), is(true));
	}
",non-flaky,5
26735,MundaneImmortal_pair-distribution-app,DeveloperTest.testId,"	@Test
	public void testId() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.getId(), is(""developerId""));
	}
",non-flaky,5
26736,MundaneImmortal_pair-distribution-app,DeveloperTest.testCompanyDefault,"	@Test
	public void testCompanyDefault() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.getCompany().getName(), is(""""));
	}
",non-flaky,5
26737,MundaneImmortal_pair-distribution-app,DeveloperTest.testCompany,"	@Test
	public void testCompany() {
		Developer developer = new Developer(""developerId"");
		developer.setCompany(new Company(""my-company""));
		
		assertThat(developer.getCompany().getName(), is(""my-company""));
	}
",non-flaky,5
26738,MundaneImmortal_pair-distribution-app,DeveloperTest.testNew,"	@Test
	public void testNew() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.getNew(), is(false));
		
		developer.setNew(true);
		
		assertThat(developer.getNew(), is(true));
	}
",non-flaky,5
26739,MundaneImmortal_pair-distribution-app,DeveloperTest.testHasContext,"	@Test
	public void testHasContext() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.hasContext(), is(false));
		
		developer.setHasContext(true);
		
		assertThat(developer.hasContext(), is(true));
	}
",non-flaky,5
26740,MundaneImmortal_pair-distribution-app,DeveloperTest.testCompareTo,"	@Test
	public void testCompareTo() {
		Developer developer = new Developer(""developerId"");
		Developer developer2 = new Developer(""developerId2"");
		
		assertThat(developer.getId().compareTo(developer2.getId()), is(-1));
		assertThat(developer2.getId().compareTo(developer.getId()), is(1));
		assertThat(developer.getId().compareTo(developer.getId()), is(0));
	}
",non-flaky,5
26741,MundaneImmortal_pair-distribution-app,DeveloperTest.testHashCodeOfEqualInstances,"	@Test
	public void testHashCodeOfEqualInstances() {
		Developer developer = new Developer(""developerId"");
		Developer sameDeveloper = new Developer(""developerId"");
		
		assertThat(developer.hashCode(), is(sameDeveloper.hashCode()));
	}
",non-flaky,5
26742,MundaneImmortal_pair-distribution-app,DeveloperTest.testHashCodeOfDifferentInstances,"	@Test
	public void testHashCodeOfDifferentInstances() {
		Developer developer = new Developer(""developerId"");
		Developer differentDeveloper = new Developer(""developerId2"");
		
		assertThat(developer.hashCode(), is(not(differentDeveloper.hashCode())));
	}
",non-flaky,5
26743,MundaneImmortal_pair-distribution-app,DeveloperTest.testEqualsOfEqualInstances,"	@Test
	public void testEqualsOfEqualInstances() {
		Developer developer = new Developer(""developerId"");
		Developer sameDeveloper = new Developer(""developerId"");
		
		assertThat(developer.equals(sameDeveloper), is(true));
		assertThat(sameDeveloper.equals(developer), is(true));
	}
",non-flaky,5
26744,MundaneImmortal_pair-distribution-app,DeveloperTest.testEqualsOfDifferentInstances,"	@Test
	public void testEqualsOfDifferentInstances() {
		Developer developer = new Developer(""developerId"");
		Developer differentDeveloper = new Developer(""developerId2"");
		
		assertThat(developer.equals(differentDeveloper), is(false));
		assertThat(differentDeveloper.equals(developer), is(false));
	}
",non-flaky,5
26745,MundaneImmortal_pair-distribution-app,DeveloperTest.testToString,"	@Test
	public void testToString() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.toString(), is(""developerId""));
	}
",non-flaky,5
26746,MundaneImmortal_pair-distribution-app,DeveloperTest.testGetTrackWeightDefault,"	@Test
	public void testGetTrackWeightDefault() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.getTrackWeight(""track""), is(0));
	}
",non-flaky,5
26747,MundaneImmortal_pair-distribution-app,DeveloperTest.testGetTrackWeightOne,"	@Test
	public void testGetTrackWeightOne() {
		Developer developer = new Developer(""developerId"");
		
		developer.updateTrackWeight(""track"");
		
		assertThat(developer.getTrackWeight(""track""), is(1));
	}
",non-flaky,5
26748,MundaneImmortal_pair-distribution-app,DeveloperTest.testGetPairingDaysDefault,"	@Test
	public void testGetPairingDaysDefault() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.getPairingDays(), is(0));
	}
",non-flaky,5
26749,MundaneImmortal_pair-distribution-app,DeveloperTest.testGetPairingDaysOne,"	@Test
	public void testGetPairingDaysOne() {
		Developer developer = new Developer(""developerId"");
		
		developer.udpatePairingDays();
		
		assertThat(developer.getPairingDays(), is(1));
	}
",non-flaky,5
26750,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testGetPairsReturnOnlyDevPairs,"	@Test
	public void testGetPairsReturnOnlyDevPairs() {
		List<DayPairs> pairsListFromDevs = getPairsListFromDevs(getStandardDevs());
		Pair opsPair = pairsListFromDevs.get(0).getPairByTrack(""track1"");
		opsPair.setOpsPair(true);
		
		List<Pair> pairs = new DevPairCombinations(pairsListFromDevs).getPairs();
		
		assertThat(pairs.size(), is(5));
		for (Pair pair : pairs) {
			assertThat(pair.isOpsPair(), is(false));
		}
	}
",non-flaky,5
26751,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testGetPastPairs,"	@Test
	public void testGetPastPairs() {
		List<Developer> standardDevs = getStandardDevs();
		DevPairCombinations devPairCombinations = new DevPairCombinations(getPairsListFromDevs(standardDevs));
		
		
		assertThat(devPairCombinations.getPastPairs(0), is(getPairsListFromDevs(standardDevs).get(0).getPairs().values().stream().collect(Collectors.toList())));
		assertThat(devPairCombinations.getPastPairs(1), is(getPairsListFromDevs(standardDevs).get(1).getPairs().values().stream().collect(Collectors.toList())));
		assertThat(devPairCombinations.getPastPairs(2), is(getPairsListFromDevs(standardDevs).get(2).getPairs().values().stream().collect(Collectors.toList())));
	}
",non-flaky,5
26752,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testGetPastPairsFiltersOps,"	@Test
	public void testGetPastPairsFiltersOps() {
		List<DayPairs> pairsListFromDevs = getPairsListFromDevs(getStandardDevs());
		Pair opsPair = pairsListFromDevs.get(0).getPairByTrack(""track1"");
		opsPair.setOpsPair(true);
		DevPairCombinations devPairCombinations = new DevPairCombinations(pairsListFromDevs);
		
		
		assertThat(devPairCombinations.getPastPairs(0), is(Arrays.asList(pairsListFromDevs.get(0).getPairByTrack(""track2""))));
	}
",non-flaky,5
26753,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testGetPastPairsForMissingHistory,"	@Test
	public void testGetPastPairsForMissingHistory() {
		DevPairCombinations devPairCombinations = new DevPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairs(3), is(nullValue()));
	}
",non-flaky,5
26754,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testGetPastPairByTrack,"	@Test
	public void testGetPastPairByTrack() {
		List<Developer> standardDevs = getStandardDevs();
		DevPairCombinations devPairCombinations = new DevPairCombinations(getPairsListFromDevs(standardDevs));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(0, ""track1""), is(getPairsListFromDevs(standardDevs).get(0).getPairByTrack(""track1"")));
		assertThat(devPairCombinations.getPastPairByTrack(1, ""track2""), is(getPairsListFromDevs(standardDevs).get(1).getPairByTrack(""track2"")));
		assertThat(devPairCombinations.getPastPairByTrack(2, ""track1""), is(getPairsListFromDevs(standardDevs).get(2).getPairByTrack(""track1"")));
	}
",non-flaky,5
26755,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testGetPastPairByTrackThrowsRuntimeErrorForOpsPair,"	@Test(expected =  RuntimeException.class)
	public void testGetPastPairByTrackThrowsRuntimeErrorForOpsPair() {
		List<DayPairs> pairsListFromDevs = getPairsListFromDevs(getStandardDevs());
		Pair opsPair = pairsListFromDevs.get(0).getPairByTrack(""track1"");
		opsPair.setOpsPair(true);
		DevPairCombinations devPairCombinations = new DevPairCombinations(pairsListFromDevs);
		
		
		assertThat(devPairCombinations.getPastPairByTrack(0, ""track1""), is(Arrays.asList(getPairsListFromDevs(getStandardDevs()).get(0).getPairByTrack(""track1""))));
	}
",non-flaky,5
26756,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testGetPastPairByTrackForMissingHistory,"	@Test
	public void testGetPastPairByTrackForMissingHistory() {
		DevPairCombinations devPairCombinations = new DevPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(3, ""track1""), is(nullValue()));
	}
",non-flaky,5
26757,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testGetPastPairByTrackForMissingTrack,"	@Test
	public void testGetPastPairByTrackForMissingTrack() {
		DevPairCombinations devPairCombinations = new DevPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(1, ""track4""), is(nullValue()));
	}
",non-flaky,5
26758,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testIsRotationTimeForTwoDayPair,"	@Test
	public void testIsRotationTimeForTwoDayPair() {
		List<Developer> standardDevs = getStandardDevs();
		DevPairCombinations devPairCombinations = new DevPairCombinations(getPairsListFromDevs(standardDevs));
		
		
		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1"", ""track2""), standardDevs, false), is(true));
	}
",non-flaky,5
26759,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testIsRotationTimeForNewDevUnconformPair,"	@Test
	public void testIsRotationTimeForNewDevUnconformPair() {
		List<Developer> standardDevs = getStandardDevs();
		standardDevs.stream().forEach(developer -> developer.setNew(true));
		List<DayPairs> pastPairs = getPairsListFromDevs(standardDevs);
		pastPairs.remove(2);
		pastPairs.remove(1);		
		DevPairCombinations devPairCombinations = new DevPairCombinations(pastPairs);
		
		
		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1"", ""track2""), standardDevs, false), is(true));
	}
",non-flaky,5
26760,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testIsRotationForOneDayPair,"	@Test
	public void testIsRotationForOneDayPair() {
		List<Developer> standardDevs = getStandardDevs();
		List<DayPairs> pastPairs = getPairsListFromDevs(standardDevs);
		pastPairs.remove(2);
		pastPairs.remove(1);
		DevPairCombinations devPairCombinations = new DevPairCombinations(pastPairs);
		
		
		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1"", ""track2""), standardDevs, false), is(false));
	}
",non-flaky,5
26761,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testIsRotationForOneDayPairWithEveryDayRotation,"	@Test
	public void testIsRotationForOneDayPairWithEveryDayRotation() {
		List<Developer> standardDevs = getStandardDevs();
		List<DayPairs> pastPairs = getPairsListFromDevs(standardDevs);
		pastPairs.remove(2);
		pastPairs.remove(1);
		DevPairCombinations devPairCombinations = new DevPairCombinations(pastPairs);
		
		
		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1"", ""track2""), standardDevs, true), is(true));
	}
",non-flaky,5
26762,MundaneImmortal_pair-distribution-app,DayPairsTest.testGetPairsNewInstance,"	@Test
	public void testGetPairsNewInstance() {
		assertThat(new DayPairs().getPairs().isEmpty(), is(true));
	}
",non-flaky,5
26763,MundaneImmortal_pair-distribution-app,DayPairsTest.testAddPairAndGetTracks,"	@Test
	public void testAddPairAndGetTracks(){
		HashMap<String, Pair> expectedPairs = new HashMap<String, Pair>();
		expectedPairs.put(""testTrack"", new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2""))));
		DayPairs pairs = new DayPairs();
		pairs.addPair(""testTrack"", expectedPairs.get(""testTrack""));
		
		assertThat(pairs.getPairs(), is(equalTo(expectedPairs)));
		assertThat(pairs.getTracks(), is(equalTo(new HashSet<>(Arrays.asList(""testTrack"")))));
	}
",non-flaky,5
26764,MundaneImmortal_pair-distribution-app,DayPairsTest.testSetDate,"	@Test
	public void testSetDate() throws ParseException {
		DayPairs pairs = new DayPairs();
		Date expectedDate = new Date();
		pairs.setDate(expectedDate);
		
		assertThat(pairs.getDate(), is(equalTo(getDateWithoutTime(expectedDate))));
	}
",non-flaky,5
26765,MundaneImmortal_pair-distribution-app,DayPairsTest.testGetDate,"	@Test
	public void testGetDate() throws ParseException {
		assertThat(new DayPairs().getDate(), is(equalTo(getDateWithoutTime(new Date()))));
	}
",non-flaky,5
26766,MundaneImmortal_pair-distribution-app,DayPairsTest.testCompareTo,"	@Test
	public void testCompareTo() {
		DayPairs todaysPairs = new DayPairs();
		todaysPairs.setDate(new Date());
		DayPairs yesterdayPairs = new DayPairs();
		yesterdayPairs.setDate(getYesterdayDate());
		
		assertThat(todaysPairs.compareTo(yesterdayPairs), is(equalTo(1)));
		assertThat(yesterdayPairs.compareTo(todaysPairs), is(equalTo(-1)));
		assertThat(todaysPairs.compareTo(todaysPairs), is(equalTo(0)));
	}
",non-flaky,5
26767,MundaneImmortal_pair-distribution-app,DayPairsTest.testGetPairByTrack,"	@Test
	public void testGetPairByTrack() {
		Pair pair1 = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		Pair pair2 = new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")));
		DayPairs pairs = new DayPairs();
		pairs.addPair(""track1"", pair1);
		pairs.addPair(""track2"", pair2);
		
		assertThat(pairs.getPairByTrack(""track1""), is(equalTo(pair1)));
		assertThat(pairs.getPairByTrack(""track2""), is(equalTo(pair2)));
	}
",non-flaky,5
26768,MundaneImmortal_pair-distribution-app,DayPairsTest.testHashCode,"	@Test
	public void testHashCode() {
		DayPairs pairsOfToday = new DayPairs();
		DayPairs differentPairsOfToday = new DayPairs();
		DayPairs yesterdayPairs = new DayPairs();
		yesterdayPairs.setDate(getYesterdayDate());
		Pair pair1 = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		Pair pair2 = new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")));
		pairsOfToday.addPair(""track1"", pair1);
		differentPairsOfToday.addPair(""track2"", pair2);
		yesterdayPairs.addPair(""track1"", pair1);
		
		assertThat(pairsOfToday.hashCode(), is(equalTo(differentPairsOfToday.hashCode())));
		assertThat(yesterdayPairs.hashCode(), is(not(equalTo(pairsOfToday.hashCode()))));
	}
",non-flaky,5
26769,MundaneImmortal_pair-distribution-app,DayPairsTest.testEquals,"	@Test
	public void testEquals() {
		DayPairs pairsOfToday = new DayPairs();
		DayPairs differentPairsOfToday = new DayPairs();
		DayPairs yesterdayPairs = new DayPairs();
		yesterdayPairs.setDate(getYesterdayDate());
		Pair pair1 = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		Pair pair2 = new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")));
		pairsOfToday.addPair(""track1"", pair1);
		differentPairsOfToday.addPair(""track2"", pair2);
		yesterdayPairs.addPair(""track1"", pair1);
		
		assertThat(pairsOfToday, is(equalTo(differentPairsOfToday)));
		assertThat(yesterdayPairs, is(not(equalTo(pairsOfToday))));
	}
",non-flaky,5
26770,MundaneImmortal_pair-distribution-app,DayPairsTest.testToString,"	@Test
	public void testToString() {
		DayPairs pairs = new DayPairs();
		Pair pair = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		pairs.addPair(""track"", pair);
		
		assertThat(pairs.toString(), is(equalTo(""Pairs [pairs="" + pairs.getPairs() + "", date="" + pairs.format(pairs.getDate()) + ""]"")));
	}
",non-flaky,5
26771,MundaneImmortal_pair-distribution-app,DayPairsTest.testHasPair,"	@Test
	public void testHasPair() {
		DayPairs pairs = new DayPairs();
		Pair pair = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		Pair differentPair = new Pair();
		pairs.addPair(""track"", pair);
		
		assertThat(pairs.hasPair(pair), is(true));
		assertThat(pairs.hasPair(differentPair), is(false));
	}
",non-flaky,5
26772,MundaneImmortal_pair-distribution-app,DayPairsTest.testReplacePairWith,"	@Test
	public void testReplacePairWith() {
		DayPairs pairs = new DayPairs();
		Pair pair = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		Pair differentPair = new Pair();
		pairs.addPair(""track"", pair);
		
		assertThat(pairs.hasPair(pair), is(true));
		assertThat(pairs.hasPair(differentPair), is(false));
		
		pairs.replacePairWith(pair, differentPair);
		
		assertThat(pairs.hasPair(pair), is(false));
		assertThat(pairs.hasPair(differentPair), is(true));
	}
",non-flaky,5
26773,MundaneImmortal_pair-distribution-app,DayPairsTest.testGetTrackByPair,"	@Test
	public void testGetTrackByPair() {
		DayPairs pairs = new DayPairs();
		Pair pair = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		Pair differentPair = new Pair();
		pairs.addPair(""track"", pair);
		
		assertThat(pairs.getTrackByPair(pair), is(equalTo(""track"")));
		assertThat(pairs.getTrackByPair(differentPair), is(nullValue()));
	}
",non-flaky,5
26774,MundaneImmortal_pair-distribution-app,DayPairsTest.testSimpleDateFormatNotPersisted,"	@Test
	public void testSimpleDateFormatNotPersisted() throws NoSuchFieldException, SecurityException {
		DayPairs pairs = new DayPairs();
		Field dateFormatterField = pairs.getClass().getDeclaredField(""dateFormatter"");
		dateFormatterField.setAccessible(true);
		Transient annotation = dateFormatterField.getAnnotation(Transient.class);
		
		assertThat(annotation, is(not(nullValue())));
	}
",non-flaky,5
26775,MundaneImmortal_pair-distribution-app,CompanyTest.testGetCompanyName,"	@Test
	public void testGetCompanyName() {
		assertThat(new Company(""company"").getName(), is(""company""));
	}
",non-flaky,5
26776,MundaneImmortal_pair-distribution-app,CompanyTest.testGetCompanyNameWithSaces,"	@Test
	public void testGetCompanyNameWithSaces() {
		assertThat(new Company(""  company  "").getName(), is(""company""));
	}
",non-flaky,5
26777,MundaneImmortal_pair-distribution-app,CompanyTest.testGetCompanyNameWithUpperCase,"	@Test
	public void testGetCompanyNameWithUpperCase() {
		assertThat(new Company(""COMPANY"").getName(), is(""company""));
	}
",non-flaky,5
26778,MundaneImmortal_pair-distribution-app,CompanyTest.testGetCompanyOriginalName,"	@Test
	public void testGetCompanyOriginalName() {
		assertThat(new Company(""Company"").getOriginalName(), is(""Company""));
	}
",non-flaky,5
26779,MundaneImmortal_pair-distribution-app,CompanyTest.testGetTrack,"	@Test
	public void testGetTrack() {
		assertThat(new Company(""Company"").getTrack(), is(""COMPANY-ops/interrupt""));
	}
",non-flaky,5
26780,MundaneImmortal_pair-distribution-app,CompanyTest.testGetCompanyExperiencedDevs,"	@Test
	public void testGetCompanyExperiencedDevs() {
		Developer developerCompanyA = new Developer(""a"");
		developerCompanyA.setCompany(new Company(""a""));
		Developer newDeveloperCompanyA = new Developer(""a"");
		newDeveloperCompanyA.setCompany(new Company(""a""));
		newDeveloperCompanyA.setNew(true);
		Developer developerCompanyB = new Developer(""b"");
		developerCompanyB.setCompany(new Company(""b""));
		
		List<Developer> companyDevs = new Company(""a"").getCompanyExperiencedDevs(Arrays.asList(developerCompanyA, developerCompanyB, newDeveloperCompanyA));
		
		assertThat(companyDevs.size(), is(1));
		assertThat(companyDevs.get(0), is(developerCompanyA));
	}
",non-flaky,5
26781,MundaneImmortal_pair-distribution-app,CompanyTest.testGetCompanyTracks,"	@Test
	public void testGetCompanyTracks() {
		List<String> tracks = Arrays.asList(""other-company-track"", ""company-track"", ""companyB-track"");
		
		String companyTrack = new Company(""Company"").getCompanyTrack(tracks);
		
		assertThat(companyTrack, is(""company-track""));
	}
",non-flaky,5
26782,MundaneImmortal_pair-distribution-app,CompanyTest.testGetCompanyTracksNoHit,"	@Test
	public void testGetCompanyTracksNoHit() {
		List<String> tracks = Arrays.asList(""other-company-track"", ""third-track"");
		
		String companyTrack = new Company(""Company"").getCompanyTrack(tracks);
		
		assertThat(companyTrack, is(nullValue()));
	}
",non-flaky,5
26783,MundaneImmortal_pair-distribution-app,CompanyTest.testIsCompanyTrack,"	@Test
	public void testIsCompanyTrack() {
		boolean isCompanyTrack = new Company(""Company"").isCompanyTrack(""company-track"");
		
		assertThat(isCompanyTrack, is(true));
	}
",non-flaky,5
26784,MundaneImmortal_pair-distribution-app,CompanyTest.testIsCompanyTrackFalse,"	@Test
	public void testIsCompanyTrackFalse() {
		boolean isCompanyTrack = new Company(""Company"").isCompanyTrack(""companyB-track"");

		assertThat(isCompanyTrack, is(false));
	}
",non-flaky,5
26785,MundaneImmortal_pair-distribution-app,CompanyTest.testIsDevOpsRotationWeekly,"	@Test
	public void testIsDevOpsRotationWeekly() {
		Company company = new Company(""Company"");

		company.setDevOpsRotationStrategy(""weekly"");

		assertThat(company.isDevOpsRotationWeekly(), is(true));
	}
",non-flaky,5
26786,MundaneImmortal_pair-distribution-app,CompanyTest.testIsDevOpsRotationWeeklyFalse,"	@Test
	public void testIsDevOpsRotationWeeklyFalse() {
		Company company = new Company(""Company"");

		company.setDevOpsRotationStrategy("""");
		assertThat(company.isDevOpsRotationWeekly(), is(false));

		company.setDevOpsRotationStrategy(""foo"");
		assertThat(company.isDevOpsRotationWeekly(), is(false));
	}
",non-flaky,5
26787,MundaneImmortal_pair-distribution-app,CompanyTest.testGetCompanyDevs,"	@Test
	public void testGetCompanyDevs() {
		Developer developerCompanyA = new Developer(""a"");
		developerCompanyA.setCompany(new Company(""a""));
		Developer newDeveloperCompanyA = new Developer(""a"");
		newDeveloperCompanyA.setCompany(new Company(""a""));
		newDeveloperCompanyA.setNew(true);
		Developer developerCompanyB = new Developer(""b"");
		developerCompanyB.setCompany(new Company(""b""));

		List<Developer> companyDevs = new Company(""a"").getDevs(Arrays.asList(developerCompanyA, developerCompanyB, newDeveloperCompanyA));

		assertThat(companyDevs, is(Arrays.asList(developerCompanyA, newDeveloperCompanyA)));
	}
",non-flaky,5
26788,MundaneImmortal_pair-distribution-app,DayPairsHelperTest.testUpdateDataBaseWithTrelloContentWithException,"	@Test(expected = RuntimeException.class)
	public void testUpdateDataBaseWithTrelloContentWithException() {
		List<DayPairs> pairsList = getPairsListFromDevs(getStandardDevs());
		when(trelloPairsRepository.findByDate(pairsList.get(2).getDate())).thenReturn(pairsList);

		subject.updateDataBaseWithTrelloContent(pairsList);
	}
",non-flaky,5
26789,MundaneImmortal_pair-distribution-app,DayPairsHelperTest.testUpdateDataBaseWithTrelloContent,"	@Test
	public void testUpdateDataBaseWithTrelloContent() {
		List<DayPairs> pairsList = getPairsListFromDevs(getStandardDevs());
		DayPairs oldPairs = new DayPairs();
		oldPairs.setDate(pairsList.get(0).getDate());
		oldPairs.addPair(""oldTrack"", new Pair());
		when(trelloPairsRepository.findByDate(pairsList.get(0).getDate())).thenReturn(Arrays.asList(oldPairs));
		when(trelloPairsRepository.findByDate(pairsList.get(1).getDate())).thenReturn(Arrays.asList());

		subject.updateDataBaseWithTrelloContent(pairsList);

		verify(trelloPairsRepository, atLeast(1)).save(pairsList.get(0));
		verify(trelloPairsRepository, atLeast(1)).save(pairsList.get(1));
	}
",non-flaky,5
26790,MundaneImmortal_pair-distribution-app,DayPairsHelperTest.testBuildPairsWeightFromPastPairing,"	@Test
	public void testBuildPairsWeightFromPastPairing() {
		PairCombinations pairs = getPairsList();
		List<Developer> devs = getStandardDevs();

		Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);

		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")))), is(2));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev3"")))), is(0));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev4"")))), is(1));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev2""), new Developer(""dev3"")))), is(1));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev2""), new Developer(""dev4"")))), is(0));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")))), is(2));
	}
",non-flaky,5
26791,MundaneImmortal_pair-distribution-app,DayPairsHelperTest.testAdaptPairsWeightForNewDevelopers,"	@Test
	public void testAdaptPairsWeightForNewDevelopers() {

		Developer developer1 = new Developer(""dev1"");
		developer1.setNew(true);
		Developer developer2 = new Developer(""dev2"");
		developer2.setNew(true);
		Developer developer3 = new Developer(""dev3"");
		Developer developer4 = new Developer(""dev4"");
		List<Developer> devs = Arrays.asList(developer1, developer2, developer3, developer4);
		PairCombinations pairs = new DevPairCombinations(getPairsListFromDevs(devs));

		Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);
		subject.adaptPairsWeight(pairsWeight, devs);

		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")))), is(102));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev3"")))), is(0));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev4"")))), is(1));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev2""), new Developer(""dev3"")))), is(1));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev2""), new Developer(""dev4"")))), is(0));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")))), is(2));
	}
",non-flaky,5
26792,MundaneImmortal_pair-distribution-app,DayPairsHelperTest.testGenerateNewDayPairs,"	@Test
	public void testGenerateNewDayPairs() {
		PairCombinations pairs = getPairsList();
		List<Developer> devs = getStandardDevs();
		List<String> tracks = Arrays.asList(""track1"", ""track2"", ""track3"");
		Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);
		subject.buildDevelopersPairingDays(pairs, devs);
		
		DayPairs dayPairs = subject.generateNewDayPairs(tracks, devs, pairs, pairsWeight, getStandardCompanies());

		assertThat(dayPairs.getTracks().size(), is(2));
		assertThat(dayPairs.getTracks(), containsInAnyOrder(""track1"", ""track2""));
		assertThat(dayPairs.getPairByTrack(""track1""),
				is(not(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2""))))));
		assertThat(dayPairs.getPairByTrack(""track2""),
				is(not(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4""))))));
		
		boolean trackOneHasContext = dayPairs.getPairByTrack(""track1"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track1"").getSecondDev().hasContext();
		boolean trackTwoHasContext = dayPairs.getPairByTrack(""track2"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track2"").getSecondDev().hasContext();
		assertThat(trackOneHasContext, is(true));
		assertThat(trackTwoHasContext, is(true));
	}
",non-flaky,5
26793,MundaneImmortal_pair-distribution-app,DayPairsHelperTest.testGenerateNewDayPairsWithEverydayRotation,"	@Test
	public void testGenerateNewDayPairsWithEverydayRotation() {
		PairCombinations pairs = getPairsList();
		List<Developer> devs = getStandardDevs();
		List<String> tracks = Arrays.asList(""track1"", ""track2"", ""track3"");
		Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);
		subject.buildDevelopersPairingDays(pairs, devs);
		
		DayPairsHelper subjectWithEverydayRotation = new DayPairsHelper(trelloPairsRepository, true);
		DayPairs dayPairs = subjectWithEverydayRotation.generateNewDayPairs(tracks, devs, pairs, pairsWeight, getStandardCompanies());

		assertThat(dayPairs.getTracks().size(), is(2));
		assertThat(dayPairs.getTracks(), containsInAnyOrder(""track1"", ""track2""));
		assertThat(dayPairs.getPairByTrack(""track1""),
				is(not(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2""))))));
		assertThat(dayPairs.getPairByTrack(""track2""),
				is(not(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4""))))));
		
		boolean trackOneHasDev2 = dayPairs.getPairByTrack(""track1"").getFirstDev().equals(new Developer(""dev2"")) || dayPairs.getPairByTrack(""track1"").getSecondDev().equals(new Developer(""dev2""));
		boolean trackTwoHasDev4 = dayPairs.getPairByTrack(""track2"").getFirstDev().equals(new Developer(""dev4"")) || dayPairs.getPairByTrack(""track2"").getSecondDev().equals(new Developer(""dev4""));
		assertThat(trackOneHasDev2, is(true));
		assertThat(trackTwoHasDev4, is(true));
	}
",non-flaky,5
26794,MundaneImmortal_pair-distribution-app,DayPairsHelperTest.testGenerateNewDayPairsWithSmallestWeight,"	@Test
	public void testGenerateNewDayPairsWithSmallestWeight() {
		PairCombinations pairs = getLongPairsList();
		List<Developer> devs = Arrays.asList(new Developer(""dev1""), new Developer(""dev2""), new Developer(""dev3""),
				new Developer(""dev4""), new Developer(""dev5""), new Developer(""dev6""));
		List<String> tracks = Arrays.asList(""track1"", ""track2"", ""track3"");
		Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);
		subject.buildDevelopersPairingDays(pairs, devs);
		
		DayPairs dayPairs = subject.generateNewDayPairs(tracks, devs, pairs, pairsWeight, getStandardCompanies());

		assertThat(dayPairs.getTracks().size(), is(3));
		assertThat(dayPairs.getTracks(), containsInAnyOrder(""track1"", ""track2"", ""track3""));
		System.out.println(dayPairs.getPairs());
		assertThat(dayPairs.hasPair(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev6"")))), is(true));
		assertThat(dayPairs.hasPair(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev2"")))), is(true));
		assertThat(dayPairs.hasPair(new Pair(Arrays.asList(new Developer(""dev5""), new Developer(""dev4"")))), is(true));
	}
",non-flaky,5
26795,MundaneImmortal_pair-distribution-app,DayPairsHelperTest.testGenerateNewDayPairsSoloRequired,"	@Test
	public void testGenerateNewDayPairsSoloRequired() {
		PairCombinations pairs = getPairsList();
		List<Developer> devs = Arrays.asList(new Developer(""dev1""), new Developer(""dev2""), new Developer(""dev3""));
		List<String> tracks = Arrays.asList(""track1"", ""track2"", ""track3"");
		Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);

		DayPairs dayPairs = subject.generateNewDayPairs(tracks, devs, pairs, pairsWeight, getStandardCompanies());

		assertThat(dayPairs.getTracks().size(), is(2));
		assertThat(dayPairs.getTracks(), containsInAnyOrder(""track1"", ""track2""));
		assertThat(dayPairs.getPairByTrack(""track1""),
				is((new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2""))))));
	}
",non-flaky,5
26827,wildfly_wildfly,JndiPermissionTestCase.testNameImplies,"    @Test
    public void testNameImplies() {
        // check the compat <<ALL BINDINGS>> name
        assertEquals(new JndiPermission(""<<ALL BINDINGS>>"", ""*""), new JndiPermission(""-"", ""*""));

        // check the root - name
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission(""-"", ""*"")));
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission("""", ""*"")));
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission(""foo"", ""*"")));
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission(""foo/"", ""*"")));
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission(""foo/bar/baz/zap"", ""*"")));
        assertTrue(new JndiPermission(""-"", ""*"").implies(new JndiPermission(""java:foo"", ""*"")));

        // check the non-root - name
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""/-"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""/"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""//"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""////"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""/foo/"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""/foo/bar/baz/zap"", ""*"")));
        assertTrue(new JndiPermission(""/-"", ""*"").implies(new JndiPermission(""java:/foo"", ""*"")));

        assertTrue(new JndiPermission(""foo/-"", ""*"").implies(new JndiPermission(""foo/-"", ""*"")));
        assertTrue(new JndiPermission(""foo/-"", ""*"").implies(new JndiPermission(""foo/foo"", ""*"")));
        assertTrue(new JndiPermission(""foo/-"", ""*"").implies(new JndiPermission(""foo/foo"", ""*"")));
        assertTrue(new JndiPermission(""foo/-"", ""*"").implies(new JndiPermission(""foo/foo/"", ""*"")));
        assertTrue(new JndiPermission(""foo/-"", ""*"").implies(new JndiPermission(""foo/foo/bar/baz/zap"", ""*"")));
        assertTrue(new JndiPermission(""foo/-"", ""*"").implies(new JndiPermission(""java:foo/foo"", ""*"")));

        // check the * name
        assertTrue(new JndiPermission(""*"", ""*"").implies(new JndiPermission("""", ""*"")));
        assertTrue(new JndiPermission(""*"", ""*"").implies(new JndiPermission(""foo"", ""*"")));
        assertFalse(new JndiPermission(""*"", ""*"").implies(new JndiPermission(""foo/bar"", ""*"")));
        assertFalse(new JndiPermission(""*"", ""*"").implies(new JndiPermission(""foo/"", ""*"")));
        assertFalse(new JndiPermission(""*"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));
        assertTrue(new JndiPermission(""*/*"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));
        assertTrue(new JndiPermission(""/*"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));
        assertTrue(new JndiPermission(""*/foo"", ""*"").implies(new JndiPermission(""/foo"", ""*"")));

        // check java: support
        assertEquals(new JndiPermission(""java:"", ""*""), new JndiPermission("""", ""*""));
        assertEquals(new JndiPermission(""java:/"", ""*""), new JndiPermission(""/"", ""*""));
        assertEquals(new JndiPermission(""java:-"", ""*""), new JndiPermission(""-"", ""*""));
        assertEquals(new JndiPermission(""java:*"", ""*""), new JndiPermission(""*"", ""*""));
    }
",non-flaky,5
26828,wildfly_wildfly,JndiPermissionTestCase.testActions,"    @Test
    public void testActions() {
        assertEquals(new JndiPermission(""foo"", ""*""), new JndiPermission(""foo"", ""all""));
        assertEquals(new JndiPermission(""foo"", ""*""), new JndiPermission(""foo"", ""lookup,bind,rebind,unbind,list,listBindings,createSubcontext,destroySubcontext,addNamingListener""));
        assertEquals(new JndiPermission(""foo"", ""*""), new JndiPermission(""foo"", ""unbind,list,listBindings,createSubcontext,destroySubcontext,addNamingListener,lookup,bind,rebind""));

        assertTrue(new JndiPermission(""foo"", ""*"").implies(new JndiPermission(""foo"", ""lookup"")));
        assertTrue(new JndiPermission(""foo"", """").implies(new JndiPermission(""foo"", """")));
        assertTrue(new JndiPermission(""foo"", ""*"").implies(new JndiPermission(""foo"", """")));
        assertFalse(new JndiPermission(""foo"", """").implies(new JndiPermission(""foo"", ""bind"")));
        assertTrue(new JndiPermission(""foo"", """").withActions(""bind"").implies(new JndiPermission(""foo"", ""bind"")));
        assertFalse(new JndiPermission(""foo"", ""unbind"").withoutActions(""unbind"").implies(new JndiPermission(""foo"", ""unbind"")));
    }
",non-flaky,5
26829,wildfly_wildfly,JndiPermissionTestCase.testCollection,"    @Test
    public void testCollection() {
        final PermissionCollection permissionCollection = new JndiPermission("""", """").newPermissionCollection();
        Enumeration<Permission> e;
        permissionCollection.add(new JndiPermission(""foo/bar"", ""lookup,bind""));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind"")));
        assertFalse(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind,unbind"")));
        assertFalse(permissionCollection.implies(new JndiPermission(""foo/bar"", ""unbind"")));
        assertNotNull(e = permissionCollection.elements());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""foo/bar"", ""lookup,bind""), e.nextElement());
        assertFalse(e.hasMoreElements());
        permissionCollection.add(new JndiPermission(""foo/bar"", ""unbind""));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind,unbind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""unbind"")));
        assertNotNull(e = permissionCollection.elements());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""foo/bar"", ""lookup,bind,unbind""), e.nextElement());
        assertFalse(e.hasMoreElements());
        permissionCollection.add(new JndiPermission(""-"", ""lookup""));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind,unbind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""unbind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""baz/zap"", ""lookup"")));
        assertTrue(permissionCollection.implies(new JndiPermission("""", ""lookup"")));
        assertFalse(permissionCollection.implies(new JndiPermission(""baz/zap"", ""lookup,bind,unbind"")));
        assertFalse(permissionCollection.implies(new JndiPermission(""baz/zap"", ""unbind"")));
        assertNotNull(e = permissionCollection.elements());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""foo/bar"", ""lookup,bind,unbind""), e.nextElement());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""-"", ""lookup""), e.nextElement());
        assertFalse(e.hasMoreElements());
        permissionCollection.add(new JndiPermission(""-"", ""bind,unbind""));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""lookup,bind,unbind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""foo/bar"", ""unbind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""baz/zap"", ""lookup"")));
        assertTrue(permissionCollection.implies(new JndiPermission("""", ""lookup"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""baz/zap"", ""lookup,bind,unbind"")));
        assertTrue(permissionCollection.implies(new JndiPermission(""baz/zap"", ""unbind"")));
        assertNotNull(e = permissionCollection.elements());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""-"", ""lookup,bind,unbind""), e.nextElement());
        assertFalse(e.hasMoreElements());
    }
",non-flaky,5
26830,wildfly_wildfly,JndiPermissionTestCase.testSecurity,"    @Test
    public void testSecurity() {
        assertEquals(new JndiPermission(""-"", Integer.MAX_VALUE).getActionBits(), JndiPermission.ACTION_ALL);
        assertEquals(new JndiPermission(""-"", Integer.MAX_VALUE), new JndiPermission(""-"", ""*""));
    }
",non-flaky,5
26831,wildfly_wildfly,JndiPermissionTestCase.testSerialization,"    @Test
    public void testSerialization() {
        final JndiPermission jndiPermission = new JndiPermission(""foo/blap/-"", ""bind,lookup"");
        assertEquals(jndiPermission, ((SerializedJndiPermission)jndiPermission.writeReplace()).readResolve());
    }
",non-flaky,5
26832,wildfly_wildfly,JndiPermissionTestCase.testCollectionSecurity,"    @Test
    public void testCollectionSecurity() {
        final PermissionCollection permissionCollection = new JndiPermission("""", """").newPermissionCollection();
        permissionCollection.add(new JndiPermission(""foo/bar"", ""unbind,rebind""));
        permissionCollection.setReadOnly();
        try {
            permissionCollection.add(new JndiPermission(""fob/baz"", ""unbind,rebind""));
            fail(""Expected exception"");
        } catch (SecurityException ignored) {
        }
    }
",non-flaky,5
26833,wildfly_wildfly,JndiPermissionTestCase.testCollectionSerialization,"    @Test
    public void testCollectionSerialization() {
        final PermissionCollection permissionCollection = new JndiPermission("""", """").newPermissionCollection();
        permissionCollection.add(new JndiPermission(""foo/bar"", ""createSubcontext,rebind""));
        permissionCollection.add(new JndiPermission(""foo"", ""addNamingListener""));
        permissionCollection.add(new JndiPermission(""-"", ""lookup,rebind""));
        final PermissionCollection other = (PermissionCollection) ((SerializedJndiPermissionCollection) ((JndiPermissionCollection)permissionCollection).writeReplace()).readResolve();
        Enumeration<Permission> e;
        assertNotNull(e = other.elements());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""foo/bar"", ""createSubcontext,rebind""), e.nextElement());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""foo"", ""addNamingListener""), e.nextElement());
        assertTrue(e.hasMoreElements());
        assertEquals(new JndiPermission(""-"", ""lookup,rebind""), e.nextElement());
        assertFalse(e.hasMoreElements());
    }
",non-flaky,5
26834,wildfly_wildfly,ExternalContextsNavigableSetTestCase.testGetParentContext,"    @Test
    public void testGetParentContext() throws Exception {
        final ServiceName nameA = ServiceName.JBOSS.append(""a"");
        final ServiceName nameP = ServiceName.JBOSS.append(""p"");
        final ServiceName namePC = ServiceName.JBOSS.append(""p"",""c"");
        final ServiceName nameZ = ServiceName.JBOSS.append(""z"");
        ExternalContextsNavigableSet set = new ExternalContextsNavigableSet();
        set.addExternalContext(nameP);
        assertNull(set.getParentExternalContext(nameA));
        assertNull(set.getParentExternalContext(nameP));
        assertNotNull(set.getParentExternalContext(namePC));
        assertEquals(nameP, set.getParentExternalContext(namePC));
        assertNull(set.getParentExternalContext(nameZ));
    }
",non-flaky,5
26835,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testBindNoOwner,"    @Test
    public void testBindNoOwner() throws Exception {
        try {
            store.bind(new CompositeName(""test""), new Object());
            fail(""Should have failed with a read-only context exception"");
        } catch (UnsupportedOperationException expected) {
        }
    }
",non-flaky,5
26836,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testBind,"    @Test
    public void testBind() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object value = new Object();
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.bind(name, value);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
        assertEquals(value, store.lookup(name));
    }
",non-flaky,5
26837,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testBindNested,"    @Test
    public void testBindNested() throws Exception {
        final Name name = new CompositeName(""nested/test"");
        final Object value = new Object();
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.bind(name, value);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
        assertEquals(value, store.lookup(name));
    }
",non-flaky,5
26838,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testUnbind,"    @Test
    public void testUnbind() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object value = new Object();
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.bind(name, value);
            store.unbind(name);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
        try {
            store.lookup(name);
            fail(""Should have thrown name not found"");
        } catch (NameNotFoundException expect) {
        }
    }
",non-flaky,5
26839,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testUnBindNoOwner,"    @Test
    public void testUnBindNoOwner() throws Exception {
        try {
            store.unbind(new CompositeName(""test""));
            fail(""Should have failed with a read-only context exception"");
        } catch (UnsupportedOperationException expected) {
        }
    }
",non-flaky,5
26840,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testCreateSubcontext,"    @Test
    public void testCreateSubcontext() throws Exception {
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            assertTrue(((NamingContext) store.createSubcontext(new CompositeName(""test""))).getNamingStore() instanceof WritableServiceBasedNamingStore);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
    }
",non-flaky,5
26841,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testCreateSubContextNoOwner,"    @Test
    public void testCreateSubContextNoOwner() throws Exception {
        try {
            store.createSubcontext(new CompositeName(""test""));
            fail(""Should have failed with a read-only context exception"");
        } catch (UnsupportedOperationException expected) {
        }
    }
",non-flaky,5
26842,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testRebind,"    @Test
    public void testRebind() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object value = new Object();
        final Object newValue = new Object();
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.bind(name, value);
            store.rebind(name, newValue);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
        assertEquals(newValue, store.lookup(name));
    }
",non-flaky,5
26843,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testRebindNoOwner,"    @Test
    public void testRebindNoOwner() throws Exception {
        try {
            store.rebind(new CompositeName(""test""), new Object());
            fail(""Should have failed with a read-only context exception"");
        } catch (UnsupportedOperationException expected) {
        }
    }
",non-flaky,5
26844,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testPermissions,"    @Test
    public void testPermissions() throws Exception {

        final NamingContext namingContext = new NamingContext(store, null);
        final String name = ""a/b"";
        final Object value = new Object();
        ArrayList<JndiPermission> permissions = new ArrayList<JndiPermission>();

        // simple bind test, note that permission must have absolute path
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            permissions.add(new JndiPermission(store.getBaseName()+""/""+name,""bind,list,listBindings""));
            store.bind(new CompositeName(name), value);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }

        // all of these lookup should work
        permissions.set(0,new JndiPermission(store.getBaseName()+""/""+name,JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name));
        permissions.set(0,new JndiPermission(store.getBaseName()+""/-"",JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name));
                permissions.set(0,new JndiPermission(store.getBaseName()+""/a/*"",JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name));
        permissions.set(0,new JndiPermission(store.getBaseName()+""/a/-"",JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name));
        permissions.set(0,new JndiPermission(""<<ALL BINDINGS>>"",JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name));
        permissions.set(0,new JndiPermission(store.getBaseName()+""/""+name,JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, store.getBaseName()+""/""+name));
        NamingContext aNamingContext = (NamingContext) namingContext.lookup(""a"");
        permissions.set(0,new JndiPermission(store.getBaseName()+""/""+name,JndiPermission.ACTION_LOOKUP));
        assertEquals(value, testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, aNamingContext, ""b""));
        // this lookup should not work, no permission
        try {
            testActionWithPermission(JndiPermission.ACTION_LOOKUP, Collections.<JndiPermission>emptyList(), namingContext, name);
            fail(""Should have failed due to missing permission"");
        } catch (AccessControlException e) {

        }
        // a permission which only allows entries in store.getBaseName()
        try {
            permissions.set(0,new JndiPermission(store.getBaseName()+""/*"",JndiPermission.ACTION_LOOKUP));
            testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name);
            fail(""Should have failed due to missing permission"");
        } catch (AccessControlException e) {

        }
        // permissions which are not absolute paths (do not include store base name, i.e. java:)
        try {
            permissions.set(0,new JndiPermission(name,JndiPermission.ACTION_LOOKUP));
            testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name);
            fail(""Should have failed due to missing permission"");
        } catch (AccessControlException e) {

        }
        if (! ""java:"".equals(store.getBaseName().toString())) {
            try {
                permissions.set(0,new JndiPermission(""/""+name,JndiPermission.ACTION_LOOKUP));
                testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name);
                fail(""Should have failed due to missing permission"");
            } catch (AccessControlException e) {

            }
            try {
                permissions.set(0,new JndiPermission(""/-"",JndiPermission.ACTION_LOOKUP));
                testActionWithPermission(JndiPermission.ACTION_LOOKUP, permissions, namingContext, name);
                fail(""Should have failed due to missing permission"");
            } catch (AccessControlException e) {
            }
        }
    }
",non-flaky,5
26845,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testOwnerBindingReferences,"    @Test
    public void testOwnerBindingReferences() throws Exception {
        final Name name = new CompositeName(""test"");
        final ServiceName serviceName = store.buildServiceName(name);
        final Object value = new Object();

        // ensure bind does not exists
        try {
            store.lookup(name);
            fail(""Should have thrown name not found"");
        } catch (NameNotFoundException expect) {
        }
        final RuntimeBindReleaseService.References duBindingReferences = (RuntimeBindReleaseService.References) container.getService(JndiNamingDependencyProcessor.serviceName(OWNER_FOO)).getValue();
        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.bind(name, value);
            // Foo's RuntimeBindReleaseService should now have a reference to the new bind
            assertTrue(duBindingReferences.contains(serviceName));

            store.rebind(name, value);
            // after rebind, Foo's RuntimeBindReleaseService should continue to have a reference to the bind
            assertTrue(duBindingReferences.contains(serviceName));

            store.unbind(name);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
    }
",non-flaky,5
26846,wildfly_wildfly,WritableServiceBasedNamingStoreTestCase.testMultipleOwnersBindingReferences,"    @Test
    public void testMultipleOwnersBindingReferences() throws Exception {
        final Name name = new CompositeName(""test"");
        final ServiceName serviceName = store.buildServiceName(name);
        final Object value = new Object();

        // ensure bind does not exists
        try {
            store.lookup(name);
            fail(""Should have thrown name not found"");
        } catch (NameNotFoundException expect) {
        }
        // ensure the owners RuntimeBindReleaseService have no reference to the future bind
        final RuntimeBindReleaseService.References fooDuBindingReferences = (RuntimeBindReleaseService.References) container.getService(JndiNamingDependencyProcessor.serviceName(OWNER_FOO)).getValue();
        assertFalse(fooDuBindingReferences.contains(serviceName));
        final RuntimeBindReleaseService.References barDuBindingReferences = (RuntimeBindReleaseService.References) container.getService(JndiNamingDependencyProcessor.serviceName(OWNER_BAR)).getValue();
        assertFalse(barDuBindingReferences.contains(serviceName));

        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.bind(name, value);
            // Foo's RuntimeBindReleaseService should now have a reference to the new bind
            assertTrue(fooDuBindingReferences.contains(serviceName));
            // Bar's RuntimeBindReleaseService reference to the bind should not exist
            assertFalse(barDuBindingReferences.contains(serviceName));
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }

        WritableServiceBasedNamingStore.pushOwner(OWNER_BAR);
        try {
            store.rebind(name, value);
            // after rebind, Foo's RuntimeBindReleaseService reference to the bind should still exist
            assertTrue(fooDuBindingReferences.contains(serviceName));
            // after rebind, Bar's RuntimeBindReleaseService reference to the bind should now exist
            assertTrue(barDuBindingReferences.contains(serviceName));
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }

        WritableServiceBasedNamingStore.pushOwner(OWNER_FOO);
        try {
            store.unbind(name);
        } finally {
            WritableServiceBasedNamingStore.popOwner();
        }
    }
",non-flaky,5
26847,wildfly_wildfly,NamingSubsystemTestCase.testSchemaOfSubsystemTemplates,"    @Test
    public void testSchemaOfSubsystemTemplates() throws Exception {
        super.testSchemaOfSubsystemTemplates();
    }
",non-flaky,5
26848,wildfly_wildfly,NamingSubsystemTestCase.testOnlyExternalContextAllowsCache,"    @Test
    public void testOnlyExternalContextAllowsCache() throws Exception {
        KernelServices services = createKernelServicesBuilder(AdditionalInitialization.MANAGEMENT)
                .build();
        Assert.assertTrue(services.isSuccessfulBoot());

        List<ModelNode> list = parse(ModelTestUtils.readResource(this.getClass(), ""subsystem.xml""));

        for (ModelNode addOp : list) {
            PathAddress addr = PathAddress.pathAddress(addOp.require(ModelDescriptionConstants.OP_ADDR));
            if (addr.size() == 2 && addr.getLastElement().getKey().equals(NamingSubsystemModel.BINDING) && BindingType.forName(addOp.get(NamingBindingResourceDefinition.BINDING_TYPE.getName()).asString()) != BindingType.EXTERNAL_CONTEXT) {
                //Add the cache attribute and make sure it fails
                addOp.get(NamingBindingResourceDefinition.CACHE.getName()).set(true);
                services.executeForFailure(addOp);

                //Remove the cache attribute and make sure it succeeds
                addOp.remove(NamingBindingResourceDefinition.CACHE.getName());
                ModelTestUtils.checkOutcome(services.executeOperation(addOp));

                //Try to write the cache attribute, which should fail
                ModelTestUtils.checkFailed(services.executeOperation(Util.getWriteAttributeOperation(addr, NamingBindingResourceDefinition.CACHE.getName(), new ModelNode(true))));

            } else {
                ModelTestUtils.checkOutcome(services.executeOperation(addOp));
            }
        }


    }
",non-flaky,5
26849,wildfly_wildfly,NamingSubsystemTestCase.testCompositeBindingOps,"    @Test
    public void testCompositeBindingOps() throws Exception {
        final KernelServices services = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build();
        // add binding 'alookup' through composite op
        // note that a binding-type of 'lookup' requires 'lookup' attr value, which in this case is set by a followup step
        final ModelNode addr = Operations.createAddress(ModelDescriptionConstants.SUBSYSTEM, NamingExtension.SUBSYSTEM_NAME, NamingSubsystemModel.BINDING, ""java:global/alookup"");
        final ModelNode addOp = Operations.createAddOperation(addr);
        addOp.get(NamingSubsystemModel.BINDING_TYPE).set(NamingSubsystemModel.LOOKUP);
        final ModelNode compositeOp = Operations.CompositeOperationBuilder.create()
                .addStep(addOp)
                .addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.LOOKUP, ""java:global/a""))
                .build().getOperation();
        ModelTestUtils.checkOutcome(services.executeOperation(compositeOp));
    }
",non-flaky,5
26850,wildfly_wildfly,NamingSubsystemTestCase.testCompositeBindingUpdate,"    @Test
    public void testCompositeBindingUpdate() throws Exception {
        final KernelServices services = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build();
        // updates binding 'a' through composite op
        // binding-type used is lookup, op should succeed even if lookup value is set by a followup step
        final ModelNode addr = Operations.createAddress(ModelDescriptionConstants.SUBSYSTEM, NamingExtension.SUBSYSTEM_NAME, NamingSubsystemModel.BINDING, ""java:global/a"");
        final ModelNode compositeOp = Operations.CompositeOperationBuilder.create()
                .addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.BINDING_TYPE, NamingSubsystemModel.LOOKUP))
                .addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.LOOKUP, ""java:global/b""))
                .build().getOperation();
        ModelTestUtils.checkOutcome(services.executeOperation(compositeOp));
    }
",non-flaky,5
26851,wildfly_wildfly,NamingSubsystemTestCase.testRejectionsEAP7,"    @Test
    public void testRejectionsEAP7() throws Exception {
        testTransformer(""subsystem.xml"", ModelTestControllerVersion.EAP_7_0_0, ModelVersion.create(2, 0), ""wildfly-naming"");
    }
",non-flaky,5
26852,wildfly_wildfly,NamingSubsystemTestCase.testRejectionsEAP6,"    @Test
    public void testRejectionsEAP6() throws Exception {
        testTransformer(""subsystem.xml"", ModelTestControllerVersion.EAP_6_4_0, ModelVersion.create(1, 3),""jboss-as-naming"");
    }
",non-flaky,5
26853,wildfly_wildfly,ObjectFactoryTestCase.testBindAndRetrieveObjectFactoryFromNamingContext,"    @Test
    public void testBindAndRetrieveObjectFactoryFromNamingContext() throws Exception {
        final Reference reference = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null);
        namingStore.bind(new CompositeName(""test""), reference);

        final Object result = namingContext.lookup(""test"");
        assertTrue(result instanceof String);
        assertEquals(""Test ParsedResult"", result);
    }
",non-flaky,5
26854,wildfly_wildfly,ObjectFactoryTestCase.testBindAndRetrieveObjectFactoryFromInitialContext,"    @Test
    public void testBindAndRetrieveObjectFactoryFromInitialContext() throws Exception {
        final Reference reference = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null);
        namingStore.bind(new CompositeName(""test""), reference);

        final InitialContext initialContext = new InitialContext();
        final Object result = initialContext.lookup(""test"");
        assertTrue(result instanceof String);
        assertEquals(""Test ParsedResult"", result);
    }
",non-flaky,5
26855,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testLookupBase,"    @Test
    public void testLookupBase() throws Exception {
        final Object obj = store.lookup(new CompositeName());
        assertNotNull(obj);
    }
",non-flaky,5
26856,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testLookupBinding,"    @Test
    public void testLookupBinding() throws Exception {
        final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"");
        final Object value = new Object();
        bindObject(bindingName, value);

        final Object obj = store.lookup(new CompositeName(""foo/bar""));
        assertNotNull(obj);
        assertEquals(value, obj);
    }
",non-flaky,5
26857,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testLookupParentContext,"    @Test
    public void testLookupParentContext() throws Exception {
        final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"");
        store.add(bindingName);
        final Object obj = store.lookup(new CompositeName(""foo""));
        assertNotNull(obj);
        assertTrue(obj instanceof Context);
    }
",non-flaky,5
26858,wildfly_wildfly,ServiceBasedNamingStoreTestCase.lookup,"    @Test
    public void testStoredContext() throws Exception {
        final ServiceName bindingName = ServiceName.JBOSS.append(""foo-stored"").append(""again"");
        bindObject(bindingName, new Context() {
            @Override
            public Object lookup(Name name) throws NamingException {
                if (""blah/blah2"".equals(name.toString())) {
                    return new Integer(5);
                }

                return null;
            }
",non-flaky,5
26859,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testLookupNestedContext,"    @Test
    public void testLookupNestedContext() throws Exception {
        final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean"");
        store.add(bindingName);
        store.add(ServiceName.JBOSS.append(""foos"", ""bar""));
        store.add(ServiceName.JBOSS.append(""fo"", ""bar""));
        store.add(ServiceName.JBOSS.append(""foo"", ""ba""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bart""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""ba""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""bazt""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""art""));

        Object obj = store.lookup(new CompositeName(""foo""));
        assertNotNull(obj);
        assertTrue(obj instanceof Context);

        obj = Context.class.cast(obj).lookup(new CompositeName(""bar""));
        assertNotNull(obj);
        assertTrue(obj instanceof Context);

        obj = Context.class.cast(obj).lookup(new CompositeName(""baz""));
        assertNotNull(obj);
        assertTrue(obj instanceof Context);
    }
",non-flaky,5
26860,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testLookupBindingUsingNestedContext,"    @Test
    public void testLookupBindingUsingNestedContext() throws Exception {
        final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean"");
        final Object value = new Object();
        bindObject(bindingName, value);

        Object context = store.lookup(new CompositeName(""foo""));
        assertNotNull(context);
        assertTrue(context instanceof Context);

        Object obj = Context.class.cast(context).lookup(new CompositeName(""bar/baz/TestBean""));
        assertNotNull(obj);
        assertEquals(value, obj);

        context = Context.class.cast(context).lookup(new CompositeName(""bar""));
        obj = Context.class.cast(context).lookup(new CompositeName(""baz/TestBean""));
        assertNotNull(obj);
        assertEquals(value, obj);


        context = Context.class.cast(context).lookup(new CompositeName(""baz""));
        obj = Context.class.cast(context).lookup(new CompositeName(""TestBean""));
        assertNotNull(obj);
        assertEquals(value, obj);
    }
",non-flaky,5
26861,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testList,"    @Test
    public void testList() throws Exception {
        final Object value = new Object();
        bindObject(ServiceName.JBOSS.append(""TestBean""), value);
        bindObject(ServiceName.JBOSS.append(""foo"", ""TestBean""), value);
        bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""TestBean""), value);
        bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean""), value);

        store.add(ServiceName.JBOSS.append(""foos"", ""bar""));
        store.add(ServiceName.JBOSS.append(""fo"", ""bar""));
        store.add(ServiceName.JBOSS.append(""foo"", ""ba"", ""baz""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bart"", ""baz""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""ba""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""bazt""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""art""));
        store.add(ServiceName.JBOSS.append(""other"", ""one""));

        List<NameClassPair> list = store.list(new CompositeName(""""));
        assertEquals(5, list.size());
        assertContains(list, ""TestBean"", Object.class);
        assertContains(list, ""foo"", Context.class);
        assertContains(list, ""fo"", Context.class);
        assertContains(list, ""foos"", Context.class);
        assertContains(list, ""other"", Context.class);


        list = store.list(new CompositeName(""foo""));
        assertEquals(4, list.size());
        assertContains(list, ""TestBean"", Object.class);
        assertContains(list, ""ba"", Context.class);
        assertContains(list, ""bart"", Context.class);
        assertContains(list, ""bar"", Context.class);
    }
",non-flaky,5
26862,wildfly_wildfly,ServiceBasedNamingStoreTestCase.testListBindings,"    @Test
    public void testListBindings() throws Exception {
        final Object value = new Object();
        bindObject(ServiceName.JBOSS.append(""TestBean""), value);
        bindObject(ServiceName.JBOSS.append(""foo"", ""TestBean""), value);
        bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""TestBean""), value);
        bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean""), value);

        store.add(ServiceName.JBOSS.append(""foos"", ""bar""));
        store.add(ServiceName.JBOSS.append(""fo"", ""bar""));
        store.add(ServiceName.JBOSS.append(""foo"", ""ba"", ""baz""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bart"", ""baz""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""ba""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""bazt""));
        store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""art""));
        store.add(ServiceName.JBOSS.append(""other"", ""one""));

        List<Binding> list = store.listBindings(new CompositeName(""""));
        assertEquals(5, list.size());
        assertContains(list, ""TestBean"", Object.class);
        assertContains(list, ""foo"", NamingContext.class);
        assertContains(list, ""fo"", NamingContext.class);
        assertContains(list, ""foos"", NamingContext.class);
        assertContains(list, ""other"", NamingContext.class);


        list = store.listBindings(new CompositeName(""foo""));
        assertEquals(4, list.size());
        assertContains(list, ""TestBean"", Object.class);
        assertContains(list, ""ba"", NamingContext.class);
        assertContains(list, ""bart"", NamingContext.class);
        assertContains(list, ""bar"", NamingContext.class);

        for (Binding binding : list) {
            if (binding.getName().equals(""bar"")) {
                final Object bean = Context.class.cast(binding.getObject()).lookup(""TestBean"");
                assertNotNull(bean);
                assertEquals(value, bean);
            }
        }
    }
",non-flaky,5
26863,wildfly_wildfly,InitialContextTestCase.testRegisterURLSchemeHandler,"    @Test
    public void testRegisterURLSchemeHandler() throws Exception {
        InitialContext ictx = new InitialContext(null);

        try {
            ictx.lookup(""foobar:something"");
            Assert.fail(""Precondition: the foobar: scheme should not yet be registered"");
        } catch (NamingException ne) {
            // good
        }

        ObjectFactory tof = new TestObjectFactory();
        InitialContext.addUrlContextFactory(""foobar"", tof);
        String something = (String) ictx.lookup(""foobar:something"");
        Assert.assertTrue(""The object should now be provided by our TestObjectFactory"", something.startsWith(""TestObject:""));

        try {
            InitialContext.removeUrlContextFactory(""foobar:"", new TestObjectFactory());
            Assert.fail(""Should throw an IllegalArgumentException since the associated factory object doesn't match the registration"");
        } catch (IllegalArgumentException iae) {
            // good;
        }

        Assert.assertEquals(""The foobar: scheme should still be registered"", something, ictx.lookup(""foobar:something""));

        InitialContext.removeUrlContextFactory(""foobar"", tof);
        try {
            ictx.lookup(""foobar:something"");
            Assert.fail(""The foobar: scheme should not be registered any more"");
        } catch (NamingException ne) {
            // good
        }
    }
",non-flaky,5
26864,wildfly_wildfly,NamingEventCoordinatorTestCase.testFireObjectEvent,"    @Test
    public void testFireObjectEvent() throws Exception {
        final NamingEventCoordinator coordinator = new NamingEventCoordinator();

        final CollectingListener objectListener = new CollectingListener(1);
        coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
        final CollectingListener subtreeListener = new CollectingListener(0);
        coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
        final CollectingListener oneLevelListener = new CollectingListener(0);
        coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);

        coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE);

        objectListener.latch.await(1, TimeUnit.SECONDS);

        assertEquals(1, objectListener.capturedEvents.size());
        assertTrue(oneLevelListener.capturedEvents.isEmpty());
        assertTrue(subtreeListener.capturedEvents.isEmpty());
    }
",non-flaky,5
26865,wildfly_wildfly,NamingEventCoordinatorTestCase.testFireSubTreeEvent,"    @Test
    public void testFireSubTreeEvent() throws Exception {
        final NamingEventCoordinator coordinator = new NamingEventCoordinator();

        final CollectingListener objectListener = new CollectingListener(0);
        coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
        final CollectingListener subtreeListener = new CollectingListener(1);
        coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
        final CollectingListener oneLevelListener = new CollectingListener(0);
        coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);

        coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.SUBTREE_SCOPE);

        subtreeListener.latch.await(1, TimeUnit.SECONDS);

        assertTrue(objectListener.capturedEvents.isEmpty());
        assertTrue(oneLevelListener.capturedEvents.isEmpty());
        assertEquals(1, subtreeListener.capturedEvents.size());
    }
",non-flaky,5
26866,wildfly_wildfly,NamingEventCoordinatorTestCase.testFireOneLevelEvent,"    @Test
    public void testFireOneLevelEvent() throws Exception {
        final NamingEventCoordinator coordinator = new NamingEventCoordinator();

        final CollectingListener objectListener = new CollectingListener(0);
        coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
        final CollectingListener subtreeListener = new CollectingListener(0);
        coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
        final CollectingListener oneLevelListener = new CollectingListener(1);
        coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);

        coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.ONELEVEL_SCOPE);

        oneLevelListener.latch.await(1, TimeUnit.SECONDS);

        assertTrue(objectListener.capturedEvents.isEmpty());
        assertTrue(subtreeListener.capturedEvents.isEmpty());
        assertEquals(1, oneLevelListener.capturedEvents.size());
    }
",non-flaky,5
26867,wildfly_wildfly,NamingEventCoordinatorTestCase.testFireAllEvent,"    @Test
    public void testFireAllEvent() throws Exception {
        final NamingEventCoordinator coordinator = new NamingEventCoordinator();

        final CollectingListener objectListener = new CollectingListener(1);
        coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener);
        final CollectingListener subtreeListener = new CollectingListener(1);
        coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener);
        final CollectingListener oneLevelListener = new CollectingListener(1);
        coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);

        coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE, EventContext.ONELEVEL_SCOPE, EventContext.SUBTREE_SCOPE);

        objectListener.latch.await(1, TimeUnit.SECONDS);
        oneLevelListener.latch.await(1, TimeUnit.SECONDS);
        subtreeListener.latch.await(1, TimeUnit.SECONDS);

        assertEquals(1, objectListener.capturedEvents.size());
        assertEquals(1, subtreeListener.capturedEvents.size());
        assertEquals(1, oneLevelListener.capturedEvents.size());
    }
",non-flaky,5
26868,wildfly_wildfly,NamingEventCoordinatorTestCase.testFireMultiLevelEvent,"    @Test
    public void testFireMultiLevelEvent() throws Exception {
        final NamingEventCoordinator coordinator = new NamingEventCoordinator();

        final CollectingListener subtreeListener = new CollectingListener(1);
        coordinator.addListener(""foo"", EventContext.SUBTREE_SCOPE, subtreeListener);

        final CollectingListener subtreeListenerTwo = new CollectingListener(1);
        coordinator.addListener(""foo/bar"", EventContext.SUBTREE_SCOPE, subtreeListenerTwo);

        final CollectingListener subtreeListenerThree = new CollectingListener(1);
        coordinator.addListener(""foo/bar/baz"", EventContext.SUBTREE_SCOPE, subtreeListenerThree);

        coordinator.fireEvent(context, new CompositeName(""foo/bar/baz/boo""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE, EventContext.ONELEVEL_SCOPE, EventContext.SUBTREE_SCOPE);

        subtreeListener.latch.await(1, TimeUnit.SECONDS);
        subtreeListenerTwo.latch.await(1, TimeUnit.SECONDS);
        subtreeListenerThree.latch.await(1, TimeUnit.SECONDS);

        assertEquals(1, subtreeListener.capturedEvents.size());
        assertEquals(1, subtreeListenerTwo.capturedEvents.size());
        assertEquals(1, subtreeListenerThree.capturedEvents.size());
    }
",non-flaky,5
26869,wildfly_wildfly,NamingContextTestCase.testLookup,"    @Test
    public void testLookup() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        namingStore.bind(name, object);

        Object result = namingContext.lookup(name);
        assertEquals(object, result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
        assertEquals(object, result);
    }
",non-flaky,5
26870,wildfly_wildfly,NamingContextTestCase.testLookupReference,"    @Test
    public void testLookupReference() throws Exception {
        final Name name = new CompositeName(""test"");
        final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""blah"", ""test""), TestObjectFactory.class.getName(), null);
        namingStore.bind(name, reference);

        Object result = namingContext.lookup(name);
        assertEquals(""test"", result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
        assertEquals(""test"", result);
    }
",non-flaky,5
26871,wildfly_wildfly,NamingContextTestCase.testLookupWithContinuation,"    @Test
    public void testLookupWithContinuation() throws Exception {
        namingStore.bind(new CompositeName(""comp/nested""), ""test"");

        final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""nns"", ""comp""), TestObjectFactoryWithNameResolution.class.getName(), null);
        namingStore.bind(new CompositeName(""test""), reference);

        Object result = namingContext.lookup(new CompositeName(""test/nested""));
        assertEquals(""test"", result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""comp/nested"", ""lookup"")), namingContext, ""test/nested"");
        assertEquals(""test"", result);
    }
",non-flaky,5
26872,wildfly_wildfly,NamingContextTestCase.testLookupWitResolveResult,"    @Test
    public void testLookupWitResolveResult() throws Exception {
        namingStore.bind(new CompositeName(""test/nested""), ""test"");

        final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""blahh"", ""test""), TestObjectFactoryWithNameResolution.class.getName(), null);
        namingStore.bind(new CompositeName(""comp""), reference);

        Object result = namingContext.lookup(new CompositeName(""comp/nested""));
        assertEquals(""test"", result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test/nested"", ""lookup"")), namingContext, ""comp/nested"");
        assertEquals(""test"", result);
    }
",non-flaky,5
26873,wildfly_wildfly,NamingContextTestCase.testLookupLink,"    @Test
    public void testLookupLink() throws Exception {
        final Name name = new CompositeName(""test"");
        namingStore.bind(name, ""testValue"", String.class);
        final Name linkName = new CompositeName(""link"");
        namingStore.bind(linkName, new LinkRef(""./test""));
        Object result = namingContext.lookup(linkName);
        assertEquals(""testValue"", result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link"");
        assertEquals(""testValue"", result);

        System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
        namingStore.rebind(linkName, new LinkRef(name));
        result = namingContext.lookup(linkName);
        assertEquals(""testValue"", result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link"");
        assertEquals(""testValue"", result);
    }
",non-flaky,5
26874,wildfly_wildfly,NamingContextTestCase.testLookupContextLink,"    @Test
    public void testLookupContextLink() throws Exception {
        final Name name = new CompositeName(""test/value"");
        namingStore.bind(name, ""testValue"");
        final Name linkName = new CompositeName(""link"");
        namingStore.bind(linkName, new LinkRef(""./test""));
        Object result = namingContext.lookup(""link/value"");
        assertEquals(""testValue"", result);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup""),
                new JndiPermission(""test/value"", ""lookup"")), namingContext, ""link/value"");

        assertEquals(""testValue"", result);
    }
",non-flaky,5
26875,wildfly_wildfly,NamingContextTestCase.testLookupNameNotFound,"    @Test
    public void testLookupNameNotFound() throws Exception {
        try {
            namingContext.lookup(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch (NameNotFoundException expected) {
        }

        //the same with security permissions
        try {
            testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test"");
            fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
        } catch (NameNotFoundException expected) {
        }
    }
",non-flaky,5
26876,wildfly_wildfly,NamingContextTestCase.testLookupEmptyName,"    @Test
    public void testLookupEmptyName() throws Exception {
        Object result = namingContext.lookup(new CompositeName());
        assertTrue(result instanceof NamingContext);
        result = namingContext.lookup(new CompositeName(""""));
        assertTrue(result instanceof NamingContext);

        //the same with security permissions
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, null);
        assertTrue(result instanceof NamingContext);
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, """");
        assertTrue(result instanceof NamingContext);
    }
",non-flaky,5
26877,wildfly_wildfly,NamingContextTestCase.testBind,"    @Test
    public void testBind() throws Exception {
        Name name = new CompositeName(""test"");
        final Object value = new Object();
        namingContext.bind(name, value);
        assertEquals(value, namingStore.lookup(name));

        //the same with security permissions
        name = new CompositeName(""securitytest"");
        testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""securitytest"", value);
        assertEquals(value, namingStore.lookup(name));
    }
",non-flaky,5
26878,wildfly_wildfly,NamingContextTestCase.testBindReferenceable,"    @Test
    public void testBindReferenceable() throws Exception {
        Name name = new CompositeName(""test"");
        final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr"");
        namingContext.bind(name, referenceable);
        Object result = namingContext.lookup(name);
        assertEquals(referenceable.addr, result);

        //the same with security permissions
        name = new CompositeName(""securitytest"");
        testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""securitytest"", referenceable);
        result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""securitytest"");
        assertEquals(referenceable.addr, result);
    }
",non-flaky,5
26879,wildfly_wildfly,NamingContextTestCase.testUnbind,"    @Test
    public void testUnbind() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object value = new Object();
        namingStore.bind(name, value);
        namingContext.unbind(name);
        try {
            namingStore.lookup(name);
            fail(""Should have thrown name not found"");
        } catch (NameNotFoundException expect) {}

        //the same with security permissions
        testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""test"", value);
        testActionPermission(JndiPermission.ACTION_UNBIND, namingContext, ""test"");
        try {
            namingStore.lookup(name);
            fail(""Should have thrown name not found"");
        } catch (NameNotFoundException expect) {}
    }
",non-flaky,5
26880,wildfly_wildfly,NamingContextTestCase.testCreateSubcontext,"    @Test
    public void testCreateSubcontext() throws Exception {
        assertTrue(namingContext.createSubcontext(new CompositeName(""test"")) instanceof NamingContext);

        //the same with security permissions
        assertTrue(testActionPermission(JndiPermission.ACTION_CREATE_SUBCONTEXT, namingContext, ""securitytest"") instanceof NamingContext);
    }
",non-flaky,5
26881,wildfly_wildfly,NamingContextTestCase.testRebind,"    @Test
    public void testRebind() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object value = new Object();
        namingStore.bind(name, value);
        Object newValue = new Object();
        namingContext.rebind(name, newValue);
        assertEquals(newValue, namingStore.lookup(name));

        //the same with security permissions
        newValue = new Object();
        testActionPermission(JndiPermission.ACTION_REBIND, namingContext, ""test"", newValue);
        assertEquals(newValue, namingStore.lookup(name));
    }
",non-flaky,5
26882,wildfly_wildfly,NamingContextTestCase.testRebindReferenceable,"    @Test
    public void testRebindReferenceable() throws Exception {
        final Name name = new CompositeName(""test"");
        final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr"");
        namingContext.bind(name, referenceable);
        TestObjectReferenceable newReferenceable = new TestObjectReferenceable(""newAddr"");
        namingContext.rebind(name, newReferenceable);
        Object result = namingContext.lookup(name);
        assertEquals(newReferenceable.addr, result);

        //the same with security permissions
        newReferenceable = new TestObjectReferenceable(""yetAnotherNewAddr"");
        testActionPermission(JndiPermission.ACTION_REBIND, namingContext, ""test"", newReferenceable);
        result = namingContext.lookup(name);
        assertEquals(newReferenceable.addr, result);
    }
",non-flaky,5
26883,wildfly_wildfly,NamingContextTestCase.testListNameNotFound,"    @Test
    public void testListNameNotFound() throws Exception {
        try {
            namingContext.list(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch (NameNotFoundException expected) {
        }

        //the same with security permissions
        try {
            testActionPermission(JndiPermission.ACTION_LIST, namingContext, ""test"");
            fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
        } catch (NameNotFoundException expected) {
        }
    }
",non-flaky,5
26884,wildfly_wildfly,NamingContextTestCase.testList,"    @Test
    public void testList() throws Exception {
        bindList();

        NamingEnumeration<NameClassPair> results = namingContext.list(new CompositeName());
        checkListResults(results);

        //the same with security permissions
        results = (NamingEnumeration<NameClassPair>) testActionPermission(JndiPermission.ACTION_LIST, namingContext, null);
        checkListResults(results);
    }
",non-flaky,5
26885,wildfly_wildfly,NamingContextTestCase.testListWithContinuation,"    @Test
    public void testListWithContinuation() throws Exception {
        bindListWithContinuations();

        NamingEnumeration<NameClassPair> results = namingContext.list(new CompositeName(""comp""));
        checkListWithContinuationsResults(results);

        //the same with security permissions
        results = (NamingEnumeration<NameClassPair>) testActionPermission(JndiPermission.ACTION_LIST, Arrays.asList(
                new JndiPermission(""test"", ""list"")), namingContext, ""comp"");

        checkListWithContinuationsResults(results);
    }
",non-flaky,5
26886,wildfly_wildfly,NamingContextTestCase.testListBindingsNameNotFound,"    @Test
    public void testListBindingsNameNotFound() throws Exception {
        try {
            namingContext.listBindings(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch (NameNotFoundException expected) {
        }

        //the same with security permissions
        try {
            testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, namingContext, ""test"");
            fail(""Should have thrown and NameNotFoundException with appropriate permissions"");
        } catch (NameNotFoundException expected) {
        }
    }
",non-flaky,5
26887,wildfly_wildfly,NamingContextTestCase.testListBindings,"    @Test
    public void testListBindings() throws Exception {
        bindList();

        NamingEnumeration<Binding> results = namingContext.listBindings(new CompositeName());
        checkListResults(results);

        //the same with security permissions
        results = (NamingEnumeration<Binding>) testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, namingContext, null);
        checkListResults(results);
    }
",non-flaky,5
26888,wildfly_wildfly,NamingContextTestCase.testListBindingsWithContinuation,"    @Test
    public void testListBindingsWithContinuation() throws Exception {
        bindListWithContinuations();

        NamingEnumeration<Binding> results = namingContext.listBindings(new CompositeName(""comp""));
        checkListWithContinuationsResults(results);

        //the same with security permissions
        results = (NamingEnumeration<Binding>) testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, Arrays.asList(
                new JndiPermission(""test"", ""listBindings"")), namingContext, ""comp"");

        checkListWithContinuationsResults(results);
    }
",non-flaky,5
26889,wildfly_wildfly,InMemoryNamingStoreTestCase.testBindEmptyName,"    @Test
    public void testBindEmptyName() throws Exception {
        try {
            nameStore.bind(new CompositeName(), new Object(), Object.class);
            fail(""Should have thrown and InvalidNameException"");
        } catch(InvalidNameException expected){}

        try {
            nameStore.bind(new CompositeName(""""), new Object(), Object.class);
            fail(""Should have thrown and InvalidNameException"");
        } catch(InvalidNameException expected){}
    }
",non-flaky,5
26890,wildfly_wildfly,InMemoryNamingStoreTestCase.testBindAndLookup,"    @Test
    public void testBindAndLookup() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        nameStore.bind(name, object, Object.class);
        final Object result = nameStore.lookup(name);
        assertEquals(object, result);
    }
",non-flaky,5
26891,wildfly_wildfly,InMemoryNamingStoreTestCase.testLookupNameNotFound,"    @Test
    public void testLookupNameNotFound() throws Exception {
        try {
            nameStore.lookup(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch(NameNotFoundException expected) {}
    }
",non-flaky,5
26892,wildfly_wildfly,InMemoryNamingStoreTestCase.testLookupEmptyName,"    @Test
    public void testLookupEmptyName() throws Exception {
        Object result = nameStore.lookup(new CompositeName());
        assertTrue(result instanceof NamingContext);
        result = nameStore.lookup(new CompositeName(""""));
        assertTrue(result instanceof NamingContext);
    }
",non-flaky,5
26893,wildfly_wildfly,InMemoryNamingStoreTestCase.testBindAndLookupResolveResult,"    @Test
    public void testBindAndLookupResolveResult() throws Exception {
        final Name name = new CompositeName(""test"");
        final Reference reference = new Reference(Context.class.getName());
        nameStore.bind(name, reference, Context.class);
        final Object result = nameStore.lookup(new CompositeName(""test/value""));
        assertTrue(result instanceof ResolveResult);
    }
",non-flaky,5
26894,wildfly_wildfly,InMemoryNamingStoreTestCase.testUnbindNotFound,"    @Test
    public void testUnbindNotFound() throws Exception {
        try {
            nameStore.unbind(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch(NameNotFoundException expected) {}
    }
",non-flaky,5
26895,wildfly_wildfly,InMemoryNamingStoreTestCase.testBindUnbindLookup,"    @Test
    public void testBindUnbindLookup() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        nameStore.bind(name, object, Object.class);
        final Object result = nameStore.lookup(name);
        assertEquals(object, result);
        nameStore.unbind(name);
        try {
            nameStore.lookup(name);
            fail(""Should have thrown and NameNotFoundException"");
        } catch(NameNotFoundException expected) {}
    }
",non-flaky,5
26896,wildfly_wildfly,InMemoryNamingStoreTestCase.testRebindEmptyName,"    @Test
    public void testRebindEmptyName() throws Exception {
        try {
            nameStore.rebind(new CompositeName(), new Object(), Object.class);
            fail(""Should have thrown and InvalidNameException"");
        } catch(InvalidNameException expected){}

        try {
            nameStore.rebind(new CompositeName(""""), new Object(), Object.class);
            fail(""Should have thrown and InvalidNameException"");
        } catch(InvalidNameException expected){}
    }
",non-flaky,5
26897,wildfly_wildfly,InMemoryNamingStoreTestCase.testRebindInvalidContext,"    @Test
    public void testRebindInvalidContext() throws Exception {
        try {
            nameStore.rebind(new CompositeName(""subcontext/test""), new Object(), Object.class);
            fail(""Should have thrown and NameNotFoundException"");
        } catch(NameNotFoundException expected){}
    }
",non-flaky,5
26898,wildfly_wildfly,InMemoryNamingStoreTestCase.testRebindAndLookup,"    @Test
    public void testRebindAndLookup() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        nameStore.rebind(name, object, Object.class);
        final Object result = nameStore.lookup(name);
        assertEquals(object, result);
    }
",non-flaky,5
26899,wildfly_wildfly,InMemoryNamingStoreTestCase.testBindAndRebind,"    @Test
    public void testBindAndRebind() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        nameStore.bind(name, object, Object.class);
        assertEquals(object, nameStore.lookup(name));
        final Object objectTwo = new Object();
        nameStore.rebind(name, objectTwo, Object.class);
        assertEquals(objectTwo, nameStore.lookup(name));
    }
",non-flaky,5
26900,wildfly_wildfly,InMemoryNamingStoreTestCase.testListNameNotFound,"    @Test
    public void testListNameNotFound() throws Exception {
        try {
            nameStore.list(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch(NameNotFoundException expected) {}
    }
",non-flaky,5
26901,wildfly_wildfly,InMemoryNamingStoreTestCase.testList,"    @Test
    public void testList() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        nameStore.bind(name, object, Object.class);
        final Name nameTwo = new CompositeName(""testTwo"");
        final Object objectTwo = new Object();
        nameStore.bind(nameTwo, objectTwo, Object.class);
        final Name nameThree = new CompositeName(""testThree"");
        final Object objectThree = new Object();
        nameStore.bind(nameThree, objectThree, Object.class);

        nameStore.bind(new CompositeName(""testContext/test""), ""test"");

        final List<NameClassPair> results = nameStore.list(new CompositeName());
        assertEquals(4, results.size());
        final Set<String> expected = new HashSet<String>(Arrays.asList(""test"", ""testTwo"", ""testThree"", ""testContext""));
        for(NameClassPair result : results) {
            final String resultName = result.getName();
            if(""test"".equals(resultName) || ""testTwo"".equals(resultName) || ""testThree"".equals(resultName)) {
                assertEquals(Object.class.getName(), result.getClassName());
            } else if(""testContext"".equals(resultName)) {
                assertEquals(Context.class.getName(), result.getClassName());
            } else {
                fail(""Unknown result name: "" + resultName);
            }
            expected.remove(resultName);
        }
        assertTrue(""Not all expected results were returned"", expected.isEmpty());
    }
",non-flaky,5
26902,wildfly_wildfly,InMemoryNamingStoreTestCase.testListBindingsNameNotFound,"    @Test
    public void testListBindingsNameNotFound() throws Exception {
        try {
            nameStore.listBindings(new CompositeName(""test""));
            fail(""Should have thrown and NameNotFoundException"");
        } catch(NameNotFoundException expected) {}
    }
",non-flaky,5
26903,wildfly_wildfly,InMemoryNamingStoreTestCase.testListBindings,"    @Test
    public void testListBindings() throws Exception {
        final Name name = new CompositeName(""test"");
        final Object object = new Object();
        nameStore.bind(name, object);
        final Name nameTwo = new CompositeName(""testTwo"");
        final Object objectTwo = new Object();
        nameStore.bind(nameTwo, objectTwo);
        final Name nameThree = new CompositeName(""testThree"");
        final Object objectThree = new Object();
        nameStore.bind(nameThree, objectThree);

        nameStore.bind(new CompositeName(""testContext/test""), ""test"");

        final List<Binding> results = nameStore.listBindings(new CompositeName());
        assertEquals(4, results.size());
        final Set<String> expected = new HashSet<String>(Arrays.asList(""test"", ""testTwo"", ""testThree"", ""testContext""));
        for(Binding result : results) {
            final String resultName = result.getName();
            if(""test"".equals(resultName)) {
                assertEquals(Object.class.getName(), result.getClassName());
                assertEquals(object, result.getObject());
            } else if(""testTwo"".equals(resultName)) {
                assertEquals(Object.class.getName(), result.getClassName());
                assertEquals(objectTwo, result.getObject());
            } else if(""testThree"".equals(resultName)) {
                assertEquals(Object.class.getName(), result.getClassName());
                assertEquals(objectThree, result.getObject());
            } else if(""testContext"".equals(resultName)) {
                assertEquals(Context.class.getName(), result.getClassName());
            } else {
                fail(""Unknown result name: "" + resultName);
            }
            expected.remove(resultName);
        }
        assertTrue(""Not all expected results were returned"", expected.isEmpty());
    }
",non-flaky,5
26904,wildfly_wildfly,InMemoryNamingStoreTestCase.testAutoRemove,"    @Test
    public void testAutoRemove() throws Exception {
        nameStore.bind(new CompositeName(""test/item""), new Object());

        assertNotNull(nameStore.lookup(new CompositeName(""test/item"")));
        assertNotNull(nameStore.lookup(new CompositeName(""test"")));

        nameStore.unbind(new CompositeName(""test/item""));

        try {
            nameStore.lookup(new CompositeName(""test""));
            fail(""Should have throw name not found exception"");
        } catch (NameNotFoundException expected){}
    }
",non-flaky,5
26905,wildfly_wildfly,InitialContextFactoryTestCase.testInitialFactory,"    @Test
    public void testInitialFactory() throws Exception {
        // Test with sys prop
        System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
        InitialContext initialContext = new InitialContext();
        Context context = (Context) initialContext.lookup("""");
        assertTrue(context instanceof NamingContext);

        // Test with builder
        if (!NamingManager.hasInitialContextFactoryBuilder()) {
            NamingManager.setInitialContextFactoryBuilder(new InitialContextFactoryBuilder());
        }
        initialContext = new InitialContext();
        context = (Context) initialContext.lookup("""");
        assertTrue(context instanceof NamingContext);
    }
",non-flaky,5
26906,wildfly_wildfly,InitialContextFactoryTestCase.testJavaContext,"    @Test
    public void testJavaContext() throws Exception {
        System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName());
        System.setProperty(Context.URL_PKG_PREFIXES, ""org.jboss.as.naming.interfaces"");
        InitialContext initialContext = new InitialContext();
        Context context = (Context) initialContext.lookup(""java:"");
        assertTrue(context instanceof NamingContext);
    }
",non-flaky,5
26907,wildfly_wildfly,JSFSubsystemTransformersTestCase.testTransformersEAP700,"    @Test
    public void testTransformersEAP700() throws Exception {
        testTransformers(ModelTestControllerVersion.EAP_7_0_0, legacyVersion, ""/jsf-transformers.xml"");
    }
",non-flaky,5
26908,wildfly_wildfly,JSFSubsystemTransformersTestCase.testRejectTransformersEAP700,"    @Test
    public void testRejectTransformersEAP700() throws Exception {
        doRejectTest(ModelTestControllerVersion.EAP_7_0_0, legacyVersion);
    }
",non-flaky,5
26909,wildfly_wildfly,JSFSubsystemTestCase.testSchemaOfSubsystemTemplates,"    @Test
    public void testSchemaOfSubsystemTemplates() throws Exception {
        super.testSchemaOfSubsystemTemplates();
    }
",non-flaky,5
26910,wildfly_wildfly,JSFModuleIdFactoryTestCase.noModulePathTest,"     @Test
     public void noModulePathTest() {
     JSFModuleIdFactory factory = JSFModuleIdFactory.getInstance();
     Assert.assertEquals(1, factory.getActiveJSFVersions().size());

     Assert.assertEquals(API_MODULE, factory.getApiModId(""main"").getName());
     Assert.assertEquals(""main"", factory.getApiModId(""main"").getSlot());
     Assert.assertEquals(IMPL_MODULE, factory.getImplModId(""main"").getName());
     Assert.assertEquals(""main"", factory.getImplModId(""main"").getSlot());
     Assert.assertEquals(INJECTION_MODULE, factory.getInjectionModId(""main"").getName());
     Assert.assertEquals(""main"", factory.getInjectionModId(""main"").getSlot());
     } */
",non-flaky,5
26911,wildfly_wildfly,JSFModuleIdFactoryTestCase.getActiveJSFVersionsTest,"    @Test
    public void getActiveJSFVersionsTest() {
        List<String> versions = factory.getActiveJSFVersions();
        Assert.assertEquals(3, versions.size());
        Assert.assertTrue(versions.contains(""main""));
        Assert.assertFalse(versions.contains(""1.2""));
        Assert.assertTrue(versions.contains(""myfaces""));
        Assert.assertTrue(versions.contains(""myfaces2""));
    }
",non-flaky,5
26912,wildfly_wildfly,JSFModuleIdFactoryTestCase.computeSlotTest,"    @Test
    public void computeSlotTest() {
        Assert.assertEquals(""main"", factory.computeSlot(""main""));
        Assert.assertEquals(""main"", factory.computeSlot(null));
        Assert.assertEquals(""main"", factory.computeSlot(JsfVersionMarker.JSF_2_0));
        Assert.assertEquals(""myfaces2"", factory.computeSlot(""myfaces2""));
    }
",non-flaky,5
26913,wildfly_wildfly,JSFModuleIdFactoryTestCase.validSlotTest,"    @Test
    public void validSlotTest() {
        Assert.assertTrue(factory.isValidJSFSlot(""main""));
        Assert.assertFalse(factory.isValidJSFSlot(""1.2""));
        Assert.assertTrue(factory.isValidJSFSlot(""myfaces""));
        Assert.assertTrue(factory.isValidJSFSlot(""myfaces2""));
        Assert.assertTrue(factory.isValidJSFSlot(JsfVersionMarker.JSF_2_0));
        Assert.assertFalse(factory.isValidJSFSlot(JsfVersionMarker.WAR_BUNDLES_JSF_IMPL));
        Assert.assertFalse(factory.isValidJSFSlot(""bogus""));
        Assert.assertFalse(factory.isValidJSFSlot(""bogus2""));
   }
",non-flaky,5
26914,wildfly_wildfly,JSFModuleIdFactoryTestCase.modIdsTest,"    @Test
    public void modIdsTest() {
        Assert.assertEquals(API_MODULE, factory.getApiModId(""main"").getName());
        Assert.assertEquals(""main"", factory.getApiModId(""main"").getSlot());
        Assert.assertEquals(IMPL_MODULE, factory.getImplModId(""main"").getName());
        Assert.assertEquals(""main"", factory.getImplModId(""main"").getSlot());
        Assert.assertEquals(INJECTION_MODULE, factory.getInjectionModId(""main"").getName());
        Assert.assertEquals(""main"", factory.getInjectionModId(""main"").getSlot());

        Assert.assertEquals(API_MODULE, factory.getApiModId(""myfaces"").getName());
        Assert.assertEquals(""myfaces"", factory.getApiModId(""myfaces"").getSlot());
        Assert.assertEquals(IMPL_MODULE, factory.getImplModId(""myfaces"").getName());
        Assert.assertEquals(""myfaces"", factory.getImplModId(""myfaces"").getSlot());
        Assert.assertEquals(INJECTION_MODULE, factory.getInjectionModId(""myfaces"").getName());
        Assert.assertEquals(""myfaces"", factory.getInjectionModId(""myfaces"").getSlot());

        Assert.assertEquals(API_MODULE, factory.getApiModId(""myfaces2"").getName());
        Assert.assertEquals(""myfaces2"", factory.getApiModId(""myfaces2"").getSlot());
        Assert.assertEquals(IMPL_MODULE, factory.getImplModId(""myfaces2"").getName());
        Assert.assertEquals(""myfaces2"", factory.getImplModId(""myfaces2"").getSlot());
        Assert.assertEquals(INJECTION_MODULE, factory.getInjectionModId(""myfaces2"").getName());
        Assert.assertEquals(""myfaces2"", factory.getInjectionModId(""myfaces2"").getSlot());
    }
",non-flaky,5
26915,wildfly_wildfly,MailSubsystem10TestCase.testParseSubsystem,"    @Test
    public void testParseSubsystem() throws Exception {
        //Parse the subsystem xml into operations
        List<ModelNode> operations = super.parse(getSubsystemXml());

        ///Check that we have the expected number of operations
        //log.info(""operations: "" + operations);
        //log.info(""operations.size: "" + operations.size());
        Assert.assertEquals(7, operations.size());

        //Check that each operation has the correct content
        ModelNode addSubsystem = operations.get(0);
        Assert.assertEquals(ADD, addSubsystem.get(OP).asString());
        PathAddress addr = PathAddress.pathAddress(addSubsystem.get(OP_ADDR));
        Assert.assertEquals(1, addr.size());
        PathElement element = addr.getElement(0);
        Assert.assertEquals(SUBSYSTEM, element.getKey());
        Assert.assertEquals(MailExtension.SUBSYSTEM_NAME, element.getValue());
    }
",non-flaky,5
26916,wildfly_wildfly,MailTransformersTestCase.testTransformerEAP700,"    @Test
    public void testTransformerEAP700() throws Exception {
        testTransformation(ModelTestControllerVersion.EAP_7_0_0, MODEL_VERSION_EAP70);
    }
",non-flaky,5
26917,wildfly_wildfly,MailTransformersTestCase.testTransformerEAP640,"    @Test
    public void testTransformerEAP640() throws Exception {
        testTransformation(ModelTestControllerVersion.EAP_6_4_0, MODEL_VERSION_EAP6X);
    }
",non-flaky,5
26918,wildfly_wildfly,MailTransformersTestCase.testRejectingTransformersEAP_7_0_0,"    @Test
    public void testRejectingTransformersEAP_7_0_0() throws Exception {
        testRejectingTransformers(EAP_7_0_0, MODEL_VERSION_EAP70);
    }
",non-flaky,5
26919,wildfly_wildfly,MailTransformersTestCase.testRejectingTransformersEAP_6_4_0,"    @Test
    public void testRejectingTransformersEAP_6_4_0() throws Exception {
        testRejectingTransformers(EAP_6_4_0, MODEL_VERSION_EAP6X);
    }
",non-flaky,5
26920,wildfly_wildfly,MailSubsystem20TestCase.testExpressions,"    @Test
    public void testExpressions() throws Exception {
        standardSubsystemTest(""subsystem_1_1_expressions.xml"", false);
    }
",non-flaky,5
26921,wildfly_wildfly,MailSubsystem20TestCase.test11,"    @Test
    public void test11() throws Exception {
        standardSubsystemTest(""subsystem_1_1.xml"", false);
    }
",non-flaky,5
26922,wildfly_wildfly,MailSubsystem20TestCase.test12,"    @Test
    public void test12() throws Exception {
        standardSubsystemTest(""subsystem_1_2.xml"", false);
    }
",non-flaky,5
26923,wildfly_wildfly,MailSubsystem20TestCase.testRuntime,"    @Test
    public void testRuntime() throws Exception {
        KernelServicesBuilder builder = createKernelServicesBuilder(new DefaultInitializer())
                .setSubsystemXml(getSubsystemXml());
        KernelServices mainServices = builder.build();
        if (!mainServices.isSuccessfulBoot()) {
            Assert.fail(mainServices.getBootError().toString());
        }
        ServiceController<?> javaMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""defaultMail""));
        javaMailService.setMode(ServiceController.Mode.ACTIVE);
        Session session = (Session) javaMailService.getValue();
        Assert.assertNotNull(""session should not be null"", session);
        Properties properties = session.getProperties();
        Assert.assertNotNull(""smtp host should be set"", properties.getProperty(""mail.smtp.host""));
        Assert.assertNotNull(""pop3 host should be set"", properties.getProperty(""mail.pop3.host""));
        Assert.assertNotNull(""imap host should be set"", properties.getProperty(""mail.imap.host""));

        ServiceController<?> defaultMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""default2""));
        session = (Session) defaultMailService.getValue();
        Assert.assertEquals(""Debug should be true"", true, session.getDebug());


        ServiceController<?> customMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""custom""));
        session = (Session) customMailService.getValue();
        properties = session.getProperties();
        String host = properties.getProperty(""mail.smtp.host"");
        Assert.assertNotNull(""smtp host should be set"", host);
        Assert.assertEquals(""mail.example.com"", host);

        Assert.assertEquals(""localhost"", properties.get(""mail.pop3.host"")); //this one should be read out of socket binding
        Assert.assertEquals(""some-custom-prop-value"", properties.get(""mail.pop3.custom_prop"")); //this one should be extra property
        Assert.assertEquals(""fully-qualified-prop-name"", properties.get(""some.fully.qualified.property"")); //this one should be extra property

        MailSessionService service = (MailSessionService) customMailService.getService();
        Credentials credentials = service.getConfig().getCustomServers()[0].getCredentials();
        Assert.assertEquals(credentials.getUsername(), ""username"");
        Assert.assertEquals(credentials.getPassword(), ""password"");


    }
",non-flaky,5
26924,wildfly_wildfly,MailSubsystem30TestCase.testSchemaOfSubsystemTemplates,"    @Test
    public void testSchemaOfSubsystemTemplates() throws Exception {
        super.testSchemaOfSubsystemTemplates();
    }
",non-flaky,5
26925,wildfly_wildfly,MailSubsystem30TestCase.testRuntime,"    @Test
    public void testRuntime() throws Exception {
        KernelServicesBuilder builder = createKernelServicesBuilder(new DefaultInitializer())
                .setSubsystemXml(getSubsystemXml());
        KernelServices mainServices = builder.build();
        if (!mainServices.isSuccessfulBoot()) {
            Assert.fail(mainServices.getBootError().toString());
        }
        ServiceController<?> javaMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""defaultMail""));
        javaMailService.setMode(ServiceController.Mode.ACTIVE);
        Session session = (Session) javaMailService.getValue();
        Assert.assertNotNull(""session should not be null"", session);
        Properties properties = session.getProperties();
        Assert.assertNotNull(""smtp host should be set"", properties.getProperty(""mail.smtp.host""));
        Assert.assertNotNull(""pop3 host should be set"", properties.getProperty(""mail.pop3.host""));
        Assert.assertNotNull(""imap host should be set"", properties.getProperty(""mail.imap.host""));
        PasswordAuthentication auth = session.requestPasswordAuthentication(InetAddress.getLocalHost(), 25, ""smtp"", """", """");
        Assert.assertEquals(""nobody"", auth.getUserName());
        Assert.assertEquals(""pass"", auth.getPassword());

        ServiceController<?> defaultMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""default2""));
        session = (Session) defaultMailService.getValue();
        Assert.assertEquals(""Debug should be true"", true, session.getDebug());


        ServiceController<?> customMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""custom""));
        session = (Session) customMailService.getValue();
        properties = session.getProperties();
        String host = properties.getProperty(""mail.smtp.host"");
        Assert.assertNotNull(""smtp host should be set"", host);
        Assert.assertEquals(""mail.example.com"", host);

        Assert.assertEquals(""localhost"", properties.get(""mail.pop3.host"")); //this one should be read out of socket binding
        Assert.assertEquals(""some-custom-prop-value"", properties.get(""mail.pop3.custom_prop"")); //this one should be extra property
        Assert.assertEquals(""fully-qualified-prop-name"", properties.get(""some.fully.qualified.property"")); //this one should be extra property

        MailSessionService service = (MailSessionService) customMailService.getService();
        Credentials credentials = service.getConfig().getCustomServers()[0].getCredentials();
        Assert.assertEquals(credentials.getUsername(), ""username"");
        Assert.assertEquals(credentials.getPassword(), ""password"");


    }
",non-flaky,5
26926,wildfly_wildfly,MailSubsystemTestBase.testOperations,"    @Test
    public void testOperations() throws Exception {
        KernelServicesBuilder builder = createKernelServicesBuilder(new DefaultInitializer())
                .setSubsystemXml(getSubsystemXml());
        KernelServices mainServices = builder.build();
        if (!mainServices.isSuccessfulBoot()) {
            Assert.fail(mainServices.getBootError().toString());
        }

        PathAddress sessionAddress = PathAddress.pathAddress(MailExtension.SUBSYSTEM_PATH, PathElement.pathElement(MailExtension.MAIL_SESSION_PATH.getKey(), ""defaultMail""));
        ModelNode result;

        ModelNode removeServerOp = Util.createRemoveOperation(sessionAddress.append(""server"", ""imap""));
        removeServerOp.get(OPERATION_HEADERS).get(ALLOW_RESOURCE_SERVICE_RESTART).set(true);
        result = mainServices.executeOperation(removeServerOp);
        checkResult(result);

        ModelNode addServerOp = Util.createAddOperation(sessionAddress.append(""server"", ""imap""));
        addServerOp.get(OPERATION_HEADERS).get(ALLOW_RESOURCE_SERVICE_RESTART).set(true);
        addServerOp.get(""outbound-socket-binding-ref"").set(""mail-imap"");
        addServerOp.get(""username"").set(""user"");
        addServerOp.get(""password"").set(""pswd"");

        result = mainServices.executeOperation(addServerOp);
        checkResult(result);

        checkResult(mainServices.executeOperation(removeServerOp)); //to make sure noting is left behind
        checkResult(mainServices.executeOperation(addServerOp));

        ModelNode writeOp = Util.createEmptyOperation(WRITE_ATTRIBUTE_OPERATION, sessionAddress);
        writeOp.get(OPERATION_HEADERS).get(ALLOW_RESOURCE_SERVICE_RESTART).set(true);
        writeOp.get(""name"").set(""debug"");
        writeOp.get(""value"").set(false);
        result = mainServices.executeOperation(writeOp);
        checkResult(result);


        ServiceController<?> javaMailService = mainServices.getContainer().getService(MailSessionDefinition.SESSION_CAPABILITY.getCapabilityServiceName(""defaultMail""));
        javaMailService.setMode(ServiceController.Mode.ACTIVE);
        Session session = (Session) javaMailService.getValue();
        Assert.assertNotNull(""session should not be null"", session);
        Properties properties = session.getProperties();
        Assert.assertNotNull(""smtp host should be set"", properties.getProperty(""mail.smtp.host""));
        Assert.assertNotNull(""imap host should be set"", properties.getProperty(""mail.imap.host""));


        PathAddress nonExisting = PathAddress.pathAddress(MailExtension.SUBSYSTEM_PATH, PathElement.pathElement(MailExtension.MAIL_SESSION_PATH.getKey(), ""non-existing-session""));
        ModelNode addSession = Util.createAddOperation(nonExisting);
        addSession.get(""jndi-name"").set(""java:/bah"");
        checkResult(mainServices.executeOperation(addSession));
        removeServerOp = Util.createRemoveOperation(nonExisting.append(""server"", ""imap""));
        //removeServerOp.get(OPERATION_HEADERS).get(ALLOW_RESOURCE_SERVICE_RESTART).set(true);
        result = mainServices.executeOperation(removeServerOp);
        checkForFailure(result);


    }
",non-flaky,5
33831,apache_camel,TwoTimerWithJMXIssue.testFromWithNoOutputs,"    @Test
    public void testFromWithNoOutputs() throws Exception {
        MockEndpoint mock = getMockEndpoint(""mock:result"");
        mock.expectedMinimumMessageCount(2);

        assertMockEndpointsSatisfied();

        assertTrue(counter >= 2, ""Counter should be 2 or higher"");
    }
",non-flaky,5
33832,apache_camel,FileAsyncStressManually.testAsyncStress,"    @Test
    public void testAsyncStress() throws Exception {
        // do not test on windows
        assumeFalse(isPlatform(""windows""));

        // test by starting the unit test FileAsyncStressFileDropper in another
        // JVM

        MockEndpoint mock = getMockEndpoint(""mock:result"");
        mock.expectedMinimumMessageCount(250);

        assertMockEndpointsSatisfied();
    }
",non-flaky,5
33833,apache_camel,FileAsyncStressFileDropper.testDropInNewFiles,"    @Test
    public void testDropInNewFiles() throws Exception {
        // do not test on windows
        assumeFalse(isPlatform(""windows""));

        MockEndpoint mock = getMockEndpoint(""mock:result"");
        mock.expectedMinimumMessageCount(250);

        assertMockEndpointsSatisfied();
    }
",non-flaky,5
33834,apache_camel,Queue2QueueExample.clean,"    @BeforeEach
    public void clean() {
        template.sendBodyAndHeader(ironQueue1, ""fo"", IronMQConstants.OPERATION, IronMQConstants.CLEARQUEUE);
        template.sendBodyAndHeader(ironQueue2, ""fo"", IronMQConstants.OPERATION, IronMQConstants.CLEARQUEUE);
    }
",non-flaky,5
33835,apache_camel,Queue2QueueExample.testSendMessagesBetweenQueues,"    @Test
    public void testSendMessagesBetweenQueues() throws Exception {
        getMockEndpoint(""mock:result"").expectedMessageCount(100);
        for (int i = 1; i <= 100; i++) {
            String payloadToSend = PAYLOAD.replace(""#"", """" + i);
            template.sendBody(""direct:start"", payloadToSend);
        }
        assertMockEndpointsSatisfied(2, TimeUnit.MINUTES);
    }
",non-flaky,5
33836,apache_camel,FileCopyExample.clean,"    @BeforeEach
    public void clean() {
        template.sendBodyAndHeader(ironMQEndpoint, ""fo"", IronMQConstants.OPERATION, IronMQConstants.CLEARQUEUE);
        deleteDirectory(""target/out"");
    }
",non-flaky,5
33837,apache_camel,FileCopyExample.testCopyFileOverIronMQ,"    @Test
    public void testCopyFileOverIronMQ() throws Exception {
        getMockEndpoint(""mock:result"").expectedMessageCount(1);
        assertMockEndpointsSatisfied();
        assertFileExists(""target/out/test.txt"");
    }
",non-flaky,5
33838,apache_camel,FhirConfigurationIT.testConfiguration,"    @Test
    public void testConfiguration() throws Exception {
        FhirEndpoint endpoint = getMandatoryEndpoint(TEST_URI, FhirEndpoint.class);
        GenericClient client = (GenericClient) endpoint.getClient();
        FhirConfiguration configuration = endpoint.getConfiguration();
        assertEquals(this.componentConfiguration, configuration);
        assertEquals(""http://localhost:8080/hapi-fhir-jpaserver-example/baseDstu3"", client.getUrlBase());
        assertEquals(EncodingEnum.JSON, client.getEncoding());
        assertEquals(SummaryEnum.TEXT, client.getSummary());
        List<Object> interceptors = client.getInterceptorService().getAllRegisteredInterceptors();
        assertEquals(5, interceptors.size());

        long counter = context.adapt(ExtendedCamelContext.class).getBeanIntrospection().getInvokedCounter();
        assertEquals(0, counter, ""Should not use reflection"");
    }
",non-flaky,5
33839,apache_camel,FhirOperationIT.testOnInstance,"    @Test
    public void testOnInstance() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());
        // parameter type is String
        headers.put(""CamelFhir.name"", ""everything"");
        // parameter type is org.hl7.fhir.instance.model.api.IBaseParameters
        headers.put(""CamelFhir.parameters"", null);
        // parameter type is Class
        headers.put(""CamelFhir.outputParameterType"", Parameters.class);
        headers.put(""CamelFhir.useHttpGet"", Boolean.FALSE);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", null);
        // parameter type is java.util.Map
        headers.put(""CamelFhir.extraParameters"", null);

        final Parameters result = requestBodyAndHeaders(""direct://ON_INSTANCE"", null, headers);

        LOG.debug(""onInstance: "" + result);
        assertNotNull(result, ""onInstance result"");
        Bundle bundle = (Bundle) result.getParameter().get(0).getResource();
        assertNotNull(bundle, ""onInstance result"");
        IdType id = bundle.getEntry().get(0).getResource().getIdElement().toUnqualifiedVersionless();
        assertEquals(patient.getIdElement().toUnqualifiedVersionless(), id);
    }
",non-flaky,5
33840,apache_camel,FhirOperationIT.testOnInstanceVersion,"    @Test
    public void testOnInstanceVersion() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());
        // parameter type is String
        headers.put(""CamelFhir.name"", ""everything"");
        // parameter type is org.hl7.fhir.instance.model.api.IBaseParameters
        headers.put(""CamelFhir.parameters"", null);
        // parameter type is Class
        headers.put(""CamelFhir.outputParameterType"", Parameters.class);
        headers.put(""CamelFhir.useHttpGet"", Boolean.FALSE);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", null);
        // parameter type is java.util.Map
        headers.put(""CamelFhir.extraParameters"", null);

        final Parameters result = requestBodyAndHeaders(""direct://ON_INSTANCE_VERSION"", null, headers);

        LOG.debug(""onInstance: "" + result);
        assertNotNull(result, ""onInstance result"");
        Bundle bundle = (Bundle) result.getParameter().get(0).getResource();
        assertNotNull(bundle, ""onInstance result"");
        IdType id = bundle.getEntry().get(0).getResource().getIdElement().toUnqualifiedVersionless();
        assertEquals(patient.getIdElement().toUnqualifiedVersionless(), id);
    }
",non-flaky,5
33841,apache_camel,FhirOperationIT.testOnServer,"    @Test
    public void testOnServer() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.name"", ""$get-resource-counts"");
        // parameter type is org.hl7.fhir.instance.model.api.IBaseParameters
        headers.put(""CamelFhir.parameters"", null);
        // parameter type is Class
        headers.put(""CamelFhir.outputParameterType"", Parameters.class);
        headers.put(""CamelFhir.useHttpGet"", Boolean.TRUE);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", null);
        // parameter type is java.util.Map
        headers.put(""CamelFhir.extraParameters"", null);

        final Parameters result = requestBodyAndHeaders(""direct://ON_SERVER"", null, headers);
        assertNotNull(result, ""onServer result"");
    }
",non-flaky,5
33842,apache_camel,FhirOperationIT.testOnType,"    @Test
    public void testOnType() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resourceType"", Patient.class);
        // parameter type is String
        headers.put(""CamelFhir.name"", ""everything"");
        // parameter type is org.hl7.fhir.instance.model.api.IBaseParameters
        headers.put(""CamelFhir.parameters"", null);
        // parameter type is Class
        headers.put(""CamelFhir.outputParameterType"", Parameters.class);
        headers.put(""CamelFhir.useHttpGet"", Boolean.FALSE);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", null);
        // parameter type is java.util.Map
        headers.put(""CamelFhir.extraParameters"", null);

        final org.hl7.fhir.instance.model.api.IBaseResource result = requestBodyAndHeaders(""direct://ON_TYPE"", null, headers);

        assertNotNull(result, ""onType result"");
        LOG.debug(""onType: "" + result);
    }
",non-flaky,5
33843,apache_camel,FhirOperationIT.testProcessMessage,"    @Test
    public void testProcessMessage() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.respondToUri"", null);
        // parameter type is org.hl7.fhir.instance.model.api.IBaseBundle
        headers.put(""CamelFhir.msgBundle"", null);
        headers.put(""CamelFhir.asynchronous"", Boolean.FALSE);
        // parameter type is Class
        headers.put(""CamelFhir.responseClass"", null);
        // parameter type is java.util.Map
        headers.put(""CamelFhir.extraParameters"", null);

        final org.hl7.fhir.instance.model.api.IBaseBundle result
                = requestBodyAndHeaders(""direct://PROCESS_MESSAGE"", null, headers);

        assertNotNull(result, ""processMessage result"");
        LOG.debug(""processMessage: "" + result);
    }
",non-flaky,5
33844,apache_camel,FhirTransactionIT.testWithBundle,"    @Test
    public void testWithBundle() throws Exception {
        // using org.hl7.fhir.instance.model.api.IBaseBundle message body for single parameter ""bundle""
        Bundle result = requestBody(""direct://WITH_BUNDLE"", createTransactionBundle());

        assertNotNull(result, ""withBundle result"");
        assertTrue(result.getEntry().get(0).getResponse().getStatus().contains(""Created""));
        LOG.debug(""withBundle: "" + result);
    }
",non-flaky,5
33845,apache_camel,FhirTransactionIT.testWithStringBundle,"    @Test
    public void testWithStringBundle() throws Exception {
        Bundle transactionBundle = createTransactionBundle();
        String stringBundle = fhirContext.newJsonParser().encodeResourceToString(transactionBundle);

        // using String message body for single parameter ""sBundle""
        final String result = requestBody(""direct://WITH_STRING_BUNDLE"", stringBundle);

        assertNotNull(result, ""withBundle result"");
        assertTrue(result.contains(""Bundle""));
        LOG.debug(""withBundle: "" + result);
    }
",non-flaky,5
33846,apache_camel,FhirTransactionIT.testWithResources,"    @Test
    public void testWithResources() throws Exception {
        Patient oscar = new Patient().addName(new HumanName().addGiven(""Oscar"").setFamily(""Peterson""));
        Patient bobbyHebb = new Patient().addName(new HumanName().addGiven(""Bobby"").setFamily(""Hebb""));
        List<IBaseResource> patients = new ArrayList<>(2);
        patients.add(oscar);
        patients.add(bobbyHebb);

        // using java.util.List message body for single parameter ""resources""
        List<IBaseResource> result = requestBody(""direct://WITH_RESOURCES"", patients);

        assertNotNull(result, ""withResources result"");
        LOG.debug(""withResources: "" + result);
        assertEquals(2, result.size());
    }
",non-flaky,5
33847,apache_camel,FhirTransactionIT.testWithResourcesSummaryEnum,"    @Test
    public void testWithResourcesSummaryEnum() throws Exception {
        Patient oscar = new Patient().addName(new HumanName().addGiven(""Oscar"").setFamily(""Peterson""));
        Patient bobbyHebb = new Patient().addName(new HumanName().addGiven(""Bobby"").setFamily(""Hebb""));
        List<IBaseResource> patients = new ArrayList<>(2);
        patients.add(oscar);
        patients.add(bobbyHebb);
        final Map<String, Object> headers = new HashMap<>();
        headers.put(ExtraParameters.SUMMARY_ENUM.getHeaderName(), SummaryEnum.DATA);

        // using java.util.List message body for single parameter ""resources""
        List<IBaseResource> result = requestBodyAndHeaders(""direct://WITH_RESOURCES"", patients, headers);

        assertNotNull(result, ""withResources result"");
        LOG.debug(""withResources: "" + result);
        assertEquals(2, result.size());
    }
",non-flaky,5
33848,apache_camel,FhirCapabilitiesIT.testOfType,"    @Test
    public void testOfType() throws Exception {
        org.hl7.fhir.instance.model.api.IBaseConformance result = requestBody(""direct://OF_TYPE"", CapabilityStatement.class);

        LOG.debug(""ofType: "" + result);
        assertNotNull(result, ""ofType result"");
        assertEquals(Enumerations.PublicationStatus.ACTIVE, ((CapabilityStatement) result).getStatus());
    }
",non-flaky,5
33849,apache_camel,FhirCapabilitiesIT.testEncodeJSON,"    @Test
    public void testEncodeJSON() throws Exception {
        Map<String, Object> headers = new HashMap<>();
        headers.put(ExtraParameters.ENCODE_JSON.getHeaderName(), Boolean.TRUE);

        org.hl7.fhir.instance.model.api.IBaseConformance result
                = requestBodyAndHeaders(""direct://OF_TYPE"", CapabilityStatement.class, headers);

        LOG.debug(""ofType: "" + result);
        assertNotNull(result, ""ofType result"");
        assertEquals(Enumerations.PublicationStatus.ACTIVE, ((CapabilityStatement) result).getStatus());
    }
",non-flaky,5
33850,apache_camel,FhirDeleteIT.testDeleteResource,"    @Test
    public void testDeleteResource() throws Exception {
        assertTrue(patientExists());
        // using org.hl7.fhir.instance.model.api.IBaseResource message body for single parameter ""resource""
        IBaseOperationOutcome result = requestBody(""direct://RESOURCE"", this.patient);

        LOG.debug(""resource: "" + result);
        assertNotNull(result, ""resource result"");
        assertFalse(patientExists());
    }
",non-flaky,5
33851,apache_camel,FhirDeleteIT.testDeleteResourceById,"    @Test
    public void testDeleteResourceById() throws Exception {
        assertTrue(patientExists());

        // using org.hl7.fhir.instance.model.api.IIdType message body for single parameter ""id""
        IBaseOperationOutcome result = requestBody(""direct://RESOURCE_BY_ID"", this.patient.getIdElement());

        LOG.debug(""resourceById: "" + result);
        assertNotNull(result, ""resourceById result"");
        assertFalse(patientExists());
    }
",non-flaky,5
33852,apache_camel,FhirDeleteIT.testDeleteResourceByStringId,"    @Test
    public void testDeleteResourceByStringId() throws Exception {
        assertTrue(patientExists());

        Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.type"", ""Patient"");
        // parameter type is String
        headers.put(""CamelFhir.stringId"", this.patient.getIdElement().getIdPart());

        IBaseOperationOutcome result = requestBodyAndHeaders(""direct://RESOURCE_BY_STRING_ID"", null, headers);

        LOG.debug(""resourceById: "" + result);
        assertNotNull(result, ""resourceById result"");
        assertFalse(patientExists());
    }
",non-flaky,5
33853,apache_camel,FhirDeleteIT.testDeleteResourceConditionalByUrl,"    @Test
    public void testDeleteResourceConditionalByUrl() throws Exception {
        assertTrue(patientExists());

        IBaseOperationOutcome result
                = requestBody(""direct://RESOURCE_CONDITIONAL_BY_URL"", ""Patient?given=Vincent&family=Freeman"");

        LOG.debug(""resourceConditionalByUrl: "" + result);
        assertNotNull(result, ""resourceConditionalByUrl result"");
        assertFalse(patientExists());
    }
",non-flaky,5
33854,apache_camel,FhirDeleteIT.testDeleteResourceConditionalByUrlCacheControlDirective,"    @Test
    public void testDeleteResourceConditionalByUrlCacheControlDirective() throws Exception {
        assertTrue(patientExists());
        Map<String, Object> headers = new HashMap<>();
        headers.put(ExtraParameters.CACHE_CONTROL_DIRECTIVE.getHeaderName(), new CacheControlDirective().setNoCache(true));

        IBaseOperationOutcome result = requestBodyAndHeaders(""direct://RESOURCE_CONDITIONAL_BY_URL"",
                ""Patient?given=Vincent&family=Freeman"", headers);

        LOG.debug(""resourceConditionalByUrl: "" + result);
        assertNotNull(result, ""resourceConditionalByUrl result"");
        assertFalse(patientExists());
    }
",non-flaky,5
33855,apache_camel,FhirValidateIT.testResource,"    @Test
    public void testResource() throws Exception {
        Patient bobbyHebb = new Patient().addName(new HumanName().addGiven(""Bobby"").setFamily(""Hebb""));
        // using org.hl7.fhir.instance.model.api.IBaseResource message body for single parameter ""resource""
        MethodOutcome result = requestBody(""direct://RESOURCE"", bobbyHebb);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertNotNull(result.getOperationOutcome());
        assertTrue(((OperationOutcome) result.getOperationOutcome()).getText().getDivAsString()
                .contains(""No issues detected during validation""));
    }
",non-flaky,5
33856,apache_camel,FhirValidateIT.testResourceAsString,"    @Test
    public void testResourceAsString() throws Exception {
        Patient bobbyHebb = new Patient().addName(new HumanName().addGiven(""Bobby"").setFamily(""Hebb""));
        // using org.hl7.fhir.instance.model.api.IBaseResource message body for single parameter ""resource""
        MethodOutcome result
                = requestBody(""direct://RESOURCE_AS_STRING"", this.fhirContext.newXmlParser().encodeResourceToString(bobbyHebb));

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertNotNull(result.getOperationOutcome());
        assertTrue(((OperationOutcome) result.getOperationOutcome()).getText().getDivAsString()
                .contains(""No issues detected during validation""));
    }
",non-flaky,5
33857,apache_camel,FhirPatchIT.testPatchById,"    @Test
    public void testPatchById() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.patchBody"", PATCH);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", null);

        MethodOutcome result = requestBodyAndHeaders(""direct://PATCH_BY_ID"", null, headers);
        assertNotNull(result, ""patchById result"");
        assertActive(result);
    }
",non-flaky,5
33858,apache_camel,FhirPatchIT.testPatchByStringId,"    @Test
    public void testPatchByStringId() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.patchBody"", PATCH);
        // parameter type is String
        headers.put(""CamelFhir.stringId"", this.patient.getId());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", null);

        MethodOutcome result = requestBodyAndHeaders(""direct://PATCH_BY_SID"", null, headers);
        assertActive(result);
    }
",non-flaky,5
33859,apache_camel,FhirPatchIT.testPatchByStringIdPreferResponseTypes,"    @Test
    public void testPatchByStringIdPreferResponseTypes() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.patchBody"", PATCH);
        // parameter type is String
        headers.put(""CamelFhir.stringId"", this.patient.getId());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", null);

        List<Class<? extends IBaseResource>> preferredResponseTypes = new ArrayList<>();
        preferredResponseTypes.add(Patient.class);
        headers.put(ExtraParameters.PREFER_RESPONSE_TYPES.getHeaderName(), preferredResponseTypes);

        MethodOutcome result = requestBodyAndHeaders(""direct://PATCH_BY_SID"", null, headers);
        assertActive(result);
    }
",non-flaky,5
33860,apache_camel,FhirPatchIT.testPatchByUrl,"    @Test
    public void testPatchByUrl() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.patchBody"", PATCH);
        // parameter type is String
        headers.put(""CamelFhir.url"", ""Patient?given=Vincent&family=Freeman"");
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", null);

        MethodOutcome result = requestBodyAndHeaders(""direct://PATCH_BY_URL"", null, headers);

        assertNotNull(result, ""patchByUrl result"");
        LOG.debug(""patchByUrl: "" + result);
        assertActive(result);
    }
",non-flaky,5
33861,apache_camel,FhirCustomClientConfigurationIT.testConfigurationWithCustomClient,"    @Test
    public void testConfigurationWithCustomClient() throws Exception {
        FhirEndpoint endpoint = getMandatoryEndpoint(TEST_URI_CUSTOM_CLIENT, FhirEndpoint.class);
        IGenericClient client = endpoint.getClient();
        assertTrue(client instanceof CustomClient);
    }
",non-flaky,5
33862,apache_camel,FhirCustomClientConfigurationIT.testConfigurationWithCustomFactory,"    @Test
    public void testConfigurationWithCustomFactory() throws Exception {
        FhirEndpoint endpoint = getMandatoryEndpoint(TEST_URI_CUSTOM_CLIENT_FACTORY, FhirEndpoint.class);
        IGenericClient client = endpoint.getClient();
        assertTrue(client instanceof CustomClient);
    }
",non-flaky,5
33863,apache_camel,FhirCreateIT.testCreateResource,"    @Test
    public void testCreateResource() throws Exception {
        Patient patient = new Patient().addName(new HumanName().addGiven(""Vincent"").setFamily(""Freeman""));

        MethodOutcome result = requestBody(""direct://RESOURCE"", patient);

        LOG.debug(""resource: "" + result);
        assertNotNull(result, ""resource result"");
        assertTrue(result.getCreated());
    }
",non-flaky,5
33864,apache_camel,FhirCreateIT.testCreateStringResource,"    @Test
    public void testCreateStringResource() throws Exception {
        Patient patient = new Patient().addName(new HumanName().addGiven(""Vincent"").setFamily(""Freeman""));
        String patientString = this.fhirContext.newXmlParser().encodeResourceToString(patient);

        MethodOutcome result = requestBody(""direct://RESOURCE_STRING"", patientString);

        LOG.debug(""resource: "" + result);
        assertNotNull(result, ""resource result"");
        assertTrue(result.getCreated());
    }
",non-flaky,5
33865,apache_camel,FhirCreateIT.testCreateStringResourceEncodeXml,"    @Test
    public void testCreateStringResourceEncodeXml() throws Exception {
        Patient patient = new Patient().addName(new HumanName().addGiven(""Vincent"").setFamily(""Freeman""));
        String patientString = this.fhirContext.newXmlParser().encodeResourceToString(patient);
        Map<String, Object> headers = new HashMap<>();
        headers.put(ExtraParameters.ENCODE_XML.getHeaderName(), Boolean.TRUE);
        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE_STRING"", patientString, headers);

        LOG.debug(""resource: "" + result);
        assertNotNull(result, ""resource result"");
        assertTrue(result.getCreated());
    }
",non-flaky,5
33866,apache_camel,FhirHistoryIT.testOnInstance,"    @Test
    public void testOnInstance() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        headers.put(""CamelFhir.id"", this.patient.getIdElement());
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", Bundle.class);
        // parameter type is Integer
        headers.put(""CamelFhir.count"", 1);

        Bundle result = requestBodyAndHeaders(""direct://ON_INSTANCE"", null, headers);

        LOG.debug(""onInstance: "" + result);
        assertNotNull(result, ""onInstance result"");
        assertEquals(1, result.getEntry().size());
    }
",non-flaky,5
33867,apache_camel,FhirHistoryIT.testOnServer,"    @Test
    public void testOnServer() throws Exception {
        Map<String, Object> headers = new HashMap<>();
        headers.put(""CamelFhir.returnType"", Bundle.class);
        headers.put(""CamelFhir.count"", 1);
        Bundle result = requestBodyAndHeaders(""direct://ON_SERVER"", null, headers);

        LOG.debug(""onServer: "" + result);
        assertNotNull(result, ""onServer result"");
        assertEquals(1, result.getEntry().size());
    }
",non-flaky,5
33868,apache_camel,FhirHistoryIT.testOnType,"    @Test
    public void testOnType() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resourceType"", Patient.class);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", Bundle.class);
        // parameter type is Integer
        headers.put(""CamelFhir.count"", 1);

        Bundle result = requestBodyAndHeaders(""direct://ON_TYPE"", null, headers);

        LOG.debug(""onType: "" + result);
        assertNotNull(result, ""onType result"");
        assertEquals(1, result.getEntry().size());
    }
",non-flaky,5
33869,apache_camel,FhirHistoryIT.testOnTypeWithSubsetElements,"    @Test
    public void testOnTypeWithSubsetElements() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resourceType"", Patient.class);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", Bundle.class);
        // parameter type is Integer
        headers.put(""CamelFhir.count"", 1);
        // only include the identifier and name
        headers.put(ExtraParameters.SUBSET_ELEMENTS.getHeaderName(), new String[] { ""identifier"", ""name"" });

        Bundle result = requestBodyAndHeaders(""direct://ON_TYPE"", null, headers);

        LOG.debug(""onType: "" + result);
        assertNotNull(result, ""onType result"");
        assertEquals(1, result.getEntry().size());
    }
",non-flaky,5
33870,apache_camel,FhirUpdateIT.testResource,"    @Test
    public void testResource() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resource"", this.patient);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
",non-flaky,5
33871,apache_camel,FhirUpdateIT.testResourceNoId,"    @Test
    public void testResourceNoId() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resource"", this.patient);
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
",non-flaky,5
33872,apache_camel,FhirUpdateIT.testResourceStringId,"    @Test
    public void testResourceStringId() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resource"", this.patient);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.stringId"", this.patient.getIdElement().getIdPart());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE_WITH_STRING_ID"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
",non-flaky,5
33873,apache_camel,FhirUpdateIT.testResourceAsString,"    @Test
    public void testResourceAsString() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resourceAsString"", this.fhirContext.newJsonParser().encodeResourceToString(this.patient));
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE_AS_STRING"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
",non-flaky,5
33874,apache_camel,FhirUpdateIT.testResourceAsStringWithStringId,"    @Test
    public void testResourceAsStringWithStringId() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resourceAsString"", this.fhirContext.newJsonParser().encodeResourceToString(this.patient));
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.stringId"", this.patient.getIdElement().getIdPart());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE_AS_STRING_WITH_STRING_ID"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
",non-flaky,5
33875,apache_camel,FhirUpdateIT.testResourceBySearchUrl,"    @Test
    public void testResourceBySearchUrl() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        String url = ""Patient?"" + Patient.SP_IDENTIFIER + '=' + URLEncoder.encode(this.patient.getId(), ""UTF-8"");
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resource"", this.patient);
        // parameter type is String
        headers.put(""CamelFhir.url"", url);
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE_BY_SEARCH_URL"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
",non-flaky,5
33876,apache_camel,FhirUpdateIT.testResourceBySearchUrlAndResourceAsString,"    @Test
    public void testResourceBySearchUrlAndResourceAsString() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        String url = ""Patient?"" + Patient.SP_IDENTIFIER + '=' + URLEncoder.encode(this.patient.getId(), ""UTF-8"");
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resourceAsString"", this.fhirContext.newJsonParser().encodeResourceToString(this.patient));
        // parameter type is String
        headers.put(""CamelFhir.url"", url);
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE_BY_SEARCH_URL_AND_RESOURCE_AS_STRING"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
",non-flaky,5
33877,apache_camel,FhirSearchIT.testSearchByUrl,"    @Test
    public void testSearchByUrl() throws Exception {
        String url = ""Patient?given=Vincent&family=Freeman&_format=json"";
        Bundle result = requestBody(""direct://SEARCH_BY_URL"", url);

        LOG.debug(""searchByUrl: "" + result);
        assertNotNull(result, ""searchByUrl result"");
        Patient patient = (Patient) result.getEntry().get(0).getResource();
        assertNotNull(patient);
        assertEquals(""Freeman"", patient.getName().get(0).getFamily());
    }
",non-flaky,5
33878,apache_camel,FhirLoadPageIT.testByUrl,"    @Test
    public void testByUrl() throws Exception {
        String url = ""Patient?_count=2"";
        Bundle bundle = this.fhirClient.search()
                .byUrl(url)
                .returnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_NEXT));

        String nextPageLink = bundle.getLink(""next"").getUrl();

        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.url"", nextPageLink);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", Bundle.class);

        IBaseBundle result = requestBodyAndHeaders(""direct://BY_URL"", null, headers);

        LOG.debug(""byUrl: "" + result);
        assertNotNull(result, ""byUrl result"");
    }
",non-flaky,5
33879,apache_camel,FhirLoadPageIT.testNext,"    @Test
    public void testNext() throws Exception {
        String url = ""Patient?_count=2"";
        Bundle bundle = this.fhirClient.search()
                .byUrl(url)
                .returnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_NEXT));

        // using org.hl7.fhir.instance.model.api.IBaseBundle message body for single parameter ""bundle""
        Bundle result = requestBody(""direct://NEXT"", bundle);

        assertNotNull(result, ""next result"");
        LOG.debug(""next: "" + result);
    }
",non-flaky,5
33880,apache_camel,FhirLoadPageIT.testPrevious,"    @Test
    public void testPrevious() throws Exception {
        String url = ""Patient?_count=2"";
        Bundle bundle = this.fhirClient.search()
                .byUrl(url)
                .returnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_NEXT));

        String nextPageLink = bundle.getLink(""next"").getUrl();
        bundle = this.fhirClient.loadPage().byUrl(nextPageLink).andReturnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_PREV));

        // using org.hl7.fhir.instance.model.api.IBaseBundle message body for single parameter ""bundle""
        Bundle result = requestBody(""direct://PREVIOUS"", bundle);

        LOG.debug(""previous: "" + result);
        assertNotNull(result, ""previous result"");
    }
",non-flaky,5
33881,apache_camel,FhirLoadPageIT.testPreviousWithEncodingEnum,"    @Test
    public void testPreviousWithEncodingEnum() throws Exception {
        String url = ""Patient?_count=2"";
        Bundle bundle = this.fhirClient.search()
                .byUrl(url)
                .returnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_NEXT));

        String nextPageLink = bundle.getLink(""next"").getUrl();
        bundle = this.fhirClient.loadPage().byUrl(nextPageLink).andReturnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_PREV));
        Map<String, Object> headers = new HashMap<>();
        headers.put(ExtraParameters.ENCODING_ENUM.getHeaderName(), EncodingEnum.XML);

        // using org.hl7.fhir.instance.model.api.IBaseBundle message body for single parameter ""bundle""
        Bundle result = requestBodyAndHeaders(""direct://PREVIOUS"", bundle, headers);

        LOG.debug(""previous: "" + result);
        assertNotNull(result, ""previous result"");
    }
",non-flaky,5
33882,apache_camel,FhirLoadPageIT.populateServer,"    @BeforeEach
    public void populateServer() {
        List<IBaseResource> input = new ArrayList<>();

        Patient p1 = new Patient();
        p1.addName().setFamily(""PATIENT1"");
        input.add(p1);

        Patient p2 = new Patient();
        p2.addName().setFamily(""PATIENT2"");
        input.add(p2);

        input.add(new Patient().addName(new HumanName().setFamily(""PATIENT3"")));

        List<IBaseResource> response = fhirClient.transaction()
                .withResources(input)
                .encodedJson()
                .execute();
        assertEquals(3, response.size());
    }
",non-flaky,5
33883,apache_camel,FhirMetaIT.testAdd,"    @Test
    public void testAdd() throws Exception {
        //assert no meta
        Meta meta = fhirClient.meta().get(Meta.class).fromResource(this.patient.getIdElement()).execute();
        assertEquals(0, meta.getTag().size());
        Meta inMeta = new Meta();
        inMeta.addTag().setSystem(""urn:system1"").setCode(""urn:code1"");
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseMetaType
        headers.put(""CamelFhir.meta"", inMeta);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());

        IBaseMetaType result = requestBodyAndHeaders(""direct://ADD"", null, headers);

        LOG.debug(""add: "" + result);
        assertNotNull(result, ""add result"");
        assertEquals(1, result.getTag().size());
    }
",non-flaky,5
33884,apache_camel,FhirMetaIT.testDelete,"    @Test
    public void testDelete() throws Exception {
        //assert no meta
        Meta meta = fhirClient.meta().get(Meta.class).fromResource(this.patient.getIdElement()).execute();
        assertEquals(0, meta.getTag().size());
        Meta inMeta = new Meta();
        inMeta.addTag().setSystem(""urn:system1"").setCode(""urn:code1"");
        // add meta
        meta = fhirClient.meta().add().onResource(this.patient.getIdElement()).meta(inMeta).execute();
        assertEquals(1, meta.getTag().size());

        //delete meta
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseMetaType
        headers.put(""CamelFhir.meta"", meta);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());

        IBaseMetaType result = requestBodyAndHeaders(""direct://DELETE"", null, headers);

        LOG.debug(""delete: "" + result);
        assertNotNull(result, ""delete result"");
        assertEquals(0, result.getTag().size());
    }
",non-flaky,5
33885,apache_camel,FhirMetaIT.testGetFromResource,"    @Test
    public void testGetFromResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.metaType"", Meta.class);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());

        IBaseMetaType result = requestBodyAndHeaders(""direct://GET_FROM_RESOURCE"", null, headers);

        LOG.debug(""getFromResource: "" + result);
        assertNotNull(result, ""getFromResource result"");
        assertEquals(0, result.getTag().size());
    }
",non-flaky,5
33886,apache_camel,FhirMetaIT.testGetFromServer,"    @Test
    public void testGetFromServer() throws Exception {
        // using Class message body for single parameter ""metaType""
        IBaseMetaType result = requestBody(""direct://GET_FROM_SERVER"", Meta.class);
        assertNotNull(result, ""getFromServer result"");
        LOG.debug(""getFromServer: "" + result);
    }
",non-flaky,5
33887,apache_camel,FhirMetaIT.testGetFromType,"    @Test
    public void testGetFromType() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.metaType"", Meta.class);
        // parameter type is String
        headers.put(""CamelFhir.resourceType"", ""Patient"");

        IBaseMetaType result = requestBodyAndHeaders(""direct://GET_FROM_TYPE"", null, headers);

        LOG.debug(""getFromType: "" + result);
        assertNotNull(result, ""getFromType result"");
    }
",non-flaky,5
33888,apache_camel,FhirMetaIT.testGetFromTypePreferResponseType,"    @Test
    public void testGetFromTypePreferResponseType() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.metaType"", Meta.class);
        // parameter type is String
        headers.put(""CamelFhir.resourceType"", ""Patient"");
        headers.put(ExtraParameters.PREFER_RESPONSE_TYPE.getHeaderName(), Patient.class);

        Meta result = requestBodyAndHeaders(""direct://GET_FROM_TYPE"", null, headers);

        LOG.debug(""getFromType: "" + result);
        assertNotNull(result, ""getFromType result"");
    }
",non-flaky,5
33889,apache_camel,FhirExtraParametersIT.testEncodeRequestToXml,"    @Test
    public void testEncodeRequestToXml() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // encode request to XML
        headers.put(ExtraParameters.ENCODE_XML.getHeaderName(), Boolean.TRUE);
        String url = ""Patient?given=Vincent&family=Freeman&_format=json"";

        Bundle result = requestBodyAndHeaders(""direct://SEARCH_BY_URL"", url, headers);

        LOG.debug(""searchByUrl: "" + result);
        assertNotNull(result, ""searchByUrl result"");
        Patient patient = (Patient) result.getEntry().get(0).getResource();
        assertNotNull(patient);
        assertEquals(""Freeman"", patient.getName().get(0).getFamily());
    }
",non-flaky,5
33890,apache_camel,FhirReadIT.testResourceById,"    @Test
    public void testResourceById() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", patient.getIdElement());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_ID"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
33891,apache_camel,FhirReadIT.testResourceByLongId,"    @Test
    public void testResourceByLongId() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is Long
        headers.put(""CamelFhir.longId"", Long.valueOf(patient.getIdElement().getIdPart()));

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_LONG_ID"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
33892,apache_camel,FhirReadIT.testResourceByStringId,"    @Test
    public void testResourceByStringId() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is Long
        headers.put(""CamelFhir.stringId"", patient.getIdElement().getIdPart());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_STRING_ID"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
33893,apache_camel,FhirReadIT.testResourceByIdAndStringResource,"    @Test
    public void testResourceByIdAndStringResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resourceClass"", ""Patient"");
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", patient.getIdElement());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_ID_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
33894,apache_camel,FhirReadIT.testResourceByLongIdAndStringResource,"    @Test
    public void testResourceByLongIdAndStringResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is Long
        headers.put(""CamelFhir.longId"", Long.valueOf(patient.getIdElement().getIdPart()));

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_LONG_ID_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
33895,apache_camel,FhirReadIT.testResourceByStringIdAndStringResource,"    @Test
    public void testResourceByStringIdAndStringResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is Long
        headers.put(""CamelFhir.stringId"", patient.getIdElement().getIdPart());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_STRING_ID_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
33896,apache_camel,FhirReadIT.testResourceByStringIdAndVersion,"    @Test
    public void testResourceByStringIdAndVersion() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is Long
        headers.put(""CamelFhir.stringId"", patient.getIdElement().getIdPart());
        // parameter type is String
        headers.put(""CamelFhir.version"", patient.getIdElement().getVersionIdPart());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_STRING_ID_AND_VERSION"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
33897,apache_camel,FhirReadIT.testResourceByStringIdAndVersionWithResourceClass,"    @Test
    public void testResourceByStringIdAndVersionWithResourceClass() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resourceClass"", ""Patient"");
        // parameter type is Long
        headers.put(""CamelFhir.stringId"", patient.getIdElement().getIdPart());
        // parameter type is String
        headers.put(""CamelFhir.version"", patient.getIdElement().getVersionIdPart());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_STRING_ID_AND_VERSION_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
33898,apache_camel,FhirReadIT.testResourceByiUrl,"    @Test
    public void testResourceByiUrl() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.iUrl"", new IdType(this.patient.getId()));

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_IURL"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
33899,apache_camel,FhirReadIT.testResourceByUrl,"    @Test
    public void testResourceByUrl() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is String
        headers.put(""CamelFhir.url"", this.patient.getId());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_URL"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
33900,apache_camel,FhirReadIT.testResourceByStringUrlAndStringResource,"    @Test
    public void testResourceByStringUrlAndStringResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.resourceClass"", ""Patient"");
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.iUrl"", new IdType(this.patient.getId()));

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_STRING_URL_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
33901,apache_camel,FhirReadIT.testResourceByUrlAndStringResource,"    @Test
    public void testResourceByUrlAndStringResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.resourceClass"", ""Patient"");
        // parameter type is String
        headers.put(""CamelFhir.url"", this.patient.getId());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_URL_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
33902,apache_camel,FhirReadIT.testResourceByUrlAndStringResourcePrettyPrint,"    @Test
    public void testResourceByUrlAndStringResourcePrettyPrint() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.resourceClass"", ""Patient"");
        // parameter type is String
        headers.put(""CamelFhir.url"", this.patient.getId());
        headers.put(ExtraParameters.PRETTY_PRINT.getHeaderName(), Boolean.TRUE);

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_URL_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
33903,apache_camel,Hl7v2PatientToFhirPatientIT.testUnmarshalWithExplicitUTF16Charset,"    @Test
    public void testUnmarshalWithExplicitUTF16Charset() throws Exception {
        MockEndpoint mock = getMockEndpoint(""mock:result"");
        mock.setExpectedMessageCount(1);

        // Message with explicit encoding in MSH
        String charset = ""ASCII"";
        byte[] body = HL7_MESSAGE.getBytes(Charset.forName(charset));
        template.sendBodyAndHeader(""direct:input"", new ByteArrayInputStream(body), Exchange.CHARSET_NAME, charset);

        mock.assertIsSatisfied();

        MethodOutcome result = mock.getExchanges().get(0).getIn().getBody(MethodOutcome.class);
        assertNotNull(result, ""resource result"");
        assertTrue(result.getCreated());
    }
",non-flaky,5
33904,apache_camel,ReleaseProducerIntegrationIT.configure,"    @Test
            public void configure() {
                from(""direct:start"").to(""beanstalk:"" + tubeName + ""?command=release"").to(""mock:result"");
            }
",non-flaky,5
33905,apache_camel,BuryProducerIntegrationIT.configure,"    @Test
            public void configure() {
                from(""direct:start"").to(""beanstalk:"" + tubeName + ""?command=bury"").to(""mock:result"");
            }
",non-flaky,5
33906,apache_camel,TouchProducerIntegrationIT.configure,"    @Test
            public void configure() {
                from(""direct:start"").to(""beanstalk:"" + tubeName + ""?command=touch"").to(""mock:result"");
            }
",non-flaky,5
33907,apache_camel,DeleteProducerIntegrationIT.configure,"    @Test
            public void configure() {
                from(""direct:start"").to(""beanstalk:"" + tubeName + ""?command=delete"").to(""mock:result"");
            }
",non-flaky,5
33908,apache_camel,PutProducerIntegrationIT.configure,"    @Test
            public void configure() {
                from(""direct:start"").to(""beanstalk:"" + tubeName + ""?jobPriority=1000&jobTimeToRun=5"").to(""mock:result"");
            }
",non-flaky,5
33909,apache_camel,ConsumerIntegrationIT.configure,"    @Test
            public void configure() {
                from(""beanstalk:"" + tubeName).to(""mock:result"");
            }
",non-flaky,5
33910,apache_camel,GridFsProducerOperationsIT.testOperations,"    @Test
    public void testOperations() throws Exception {
        Map<String, Object> headers = new HashMap<>();
        assertFalse(gridFSBucket.find(eq(FILE_NAME)).cursor().hasNext());

        headers.put(Exchange.FILE_NAME, FILE_NAME);
        headers.put(Exchange.CONTENT_TYPE, ""text/plain"");
        template.requestBodyAndHeaders(""direct:create"", FILE_DATA, headers);
        assertTrue(gridFSBucket.find(eq(GridFsConstants.GRIDFS_FILE_KEY_FILENAME, FILE_NAME)).cursor().hasNext());
        assertEquals(1, template.requestBodyAndHeaders(""direct:count"", null, headers, Long.class).longValue());
        Exchange result = template.request(""direct:findOne"", exchange -> exchange.getMessage().setHeaders(headers));
        assertTrue(result.getMessage().getHeader(Exchange.FILE_LENGTH, Long.class) > 0);
        assertNotNull(result.getMessage().getHeader(Exchange.FILE_LAST_MODIFIED));

        InputStream ins = result.getMessage().getBody(InputStream.class);
        assertNotNull(ins);
        byte b[] = new byte[2048];
        int i = ins.read(b);
        assertEquals(FILE_DATA, new String(b, 0, i, StandardCharsets.UTF_8));

        headers.put(Exchange.FILE_NAME, ""2-"" + FILE_NAME);
        headers.put(GridFsEndpoint.GRIDFS_CHUNKSIZE, 10);
        headers.put(GridFsEndpoint.GRIDFS_METADATA, ""{'foo': 'bar'}"");

        template.requestBodyAndHeaders(""direct:create"", FILE_DATA + ""data2"", headers);
        assertEquals(1, template.requestBodyAndHeaders(""direct:count"", null, headers, Long.class).longValue());
        assertEquals(2, template.requestBody(""direct:count"", null, Long.class).longValue());

        String s = template.requestBody(""direct:listAll"", null, String.class);
        assertTrue(s.contains(""2-"" + FILE_NAME));
        template.requestBodyAndHeaders(""direct:remove"", null, headers);
        assertEquals(1, template.requestBody(""direct:count"", null, Long.class).longValue());
        s = template.requestBodyAndHeader(""direct:listAll"", null, Exchange.FILE_NAME, ""2-"" + FILE_NAME, String.class);
        assertFalse(s.contains(""2-"" + FILE_NAME));
    }
",non-flaky,5
33911,apache_camel,GridFsProducerOperationsIT.process,"    @Test
    public void testRemoveByObjectId() {
        Map<String, Object> headers = new HashMap<>();
        headers.put(Exchange.FILE_NAME, FILE_NAME);

        Exchange result = template.request(
                ""mongodb-gridfs:myDb?database={{mongodb.testDb}}&operation=create&bucket="" + getBucket(), new Processor() {
                    @Override
                    public void process(Exchange exchange) throws Exception {
                        exchange.getMessage().setBody(FILE_DATA);
                        exchange.getMessage().setHeaders(headers);
                    }
",non-flaky,5
33912,apache_camel,GridFsConsumerIT.testTimestamp,"    @Test
    public void testTimestamp() throws Exception {
        runTest(""direct:create"", gridFSBucket);
    }
",non-flaky,5
33913,apache_camel,GridFsConsumerIT.testAttribute,"    @Test
    public void testAttribute() throws Exception {
        runTest(""direct:create-a"", GridFSBuckets.create(mongo.getDatabase(""test""), getBucket() + ""-a""));
    }
",non-flaky,5
33914,apache_camel,GridFsConsumerIT.testPersistentTS,"    @Test
    public void testPersistentTS() throws Exception {
        runTest(""direct:create-pts"", GridFSBuckets.create(mongo.getDatabase(""test""), getBucket() + ""-pts""));
    }
",non-flaky,5
33915,apache_camel,GridFsConsumerIT.process,"    @Test
    public void testCustomFileQuery() throws Exception {
        Map<String, Object> headers = new HashMap<>();
        headers.put(Exchange.FILE_NAME, FILE_NAME);

        Exchange result = template.request(
                ""mongodb-gridfs:myDb?database={{mongodb.testDb}}&operation=create&bucket=customFileFilterTest"",
                new Processor() {
                    @Override
                    public void process(Exchange exchange) throws Exception {
                        exchange.getMessage().setBody(FILE_DATA);
                        exchange.getMessage().setHeaders(headers);
                    }
",non-flaky,5
33916,apache_camel,LdifRouteIT.setup,"    @BeforeEach
    public void setup() throws Exception {
        // Create the LDAPConnection
        ldapContext = getWiredContext(service);

        SimpleRegistry reg = getSimpleRegistry();
        camel = new DefaultCamelContext(reg);
        template = camel.createProducerTemplate();
    }
",non-flaky,5
33917,apache_camel,LdifRouteIT.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        if (camel != null) {
            camel.stop();
        }
    }
",non-flaky,5
33918,apache_camel,LdifRouteIT.addOne,"    @Test
    public void addOne() throws Exception {
        camel.addRoutes(createRouteBuilder(ENDPOINT_LDIF));
        camel.start();

        Endpoint endpoint = camel.getEndpoint(ENDPOINT_START);
        Exchange exchange = endpoint.createExchange();

        // then we set the LDAP filter on the in body
        URL loc = this.getClass().getResource(""/org/apache/camel/component/ldif/AddOne.ldif"");
        exchange.getIn().setBody(loc.toString());

        // now we send the exchange to the endpoint, and receives the response
        // from Camel
        Exchange out = template.send(endpoint, exchange);

        // Check the results
        List<String> ldifResults = defaultLdapModuleOutAssertions(out);
        assertThat(ldifResults, notNullValue());
        assertThat(ldifResults.size(), equalTo(2)); // Container and user
        assertThat(ldifResults.get(0), equalTo(""success""));
        assertThat(ldifResults.get(1), equalTo(""success""));

        // Check LDAP
        SearchResult sr;
        NamingEnumeration<SearchResult> searchResults = ldapContext.search(""dc=example,dc=org"", ""(uid=test*)"", SEARCH_CONTROLS);
        assertNotNull(searchResults);

        checkDN(""uid=test1"", searchResults);
    }
",non-flaky,5
33919,apache_camel,LdifRouteIT.deleteOne,"    @Test
    public void deleteOne() throws Exception {
        setupData(""/org/apache/camel/component/ldif/DeleteOneSetup.ldif"");

        camel.addRoutes(createRouteBuilder(ENDPOINT_LDIF));
        camel.start();

        Endpoint endpoint = camel.getEndpoint(ENDPOINT_START);
        Exchange exchange = endpoint.createExchange();

        // then we set the LDAP filter on the in body
        URL loc = this.getClass().getResource(""/org/apache/camel/component/ldif/DeleteOne.ldif"");
        exchange.getIn().setBody(loc.toString());

        // now we send the exchange to the endpoint, and receives the response
        // from Camel
        Exchange out = template.send(endpoint, exchange);

        // Check the results
        List<String> ldifResults = defaultLdapModuleOutAssertions(out);
        assertThat(ldifResults, notNullValue());
        assertThat(ldifResults.size(), equalTo(1));
        assertThat(ldifResults.get(0), equalTo(""success""));

        // Check LDAP
        NamingEnumeration<SearchResult> searchResults = ldapContext.search(""dc=example,dc=org"", ""(uid=test*)"", SEARCH_CONTROLS);
        // test2
        while (searchResults.hasMore()) {
            assertThat(searchResults.next().getName(), not(containsString(""test2"")));
        }
    }
",non-flaky,5
33920,apache_camel,LdifRouteIT.addDuplicate,"    @Test
    public void addDuplicate() throws Exception {
        setupData(""/org/apache/camel/component/ldif/AddDuplicateSetup.ldif"");

        camel.addRoutes(createRouteBuilder(ENDPOINT_LDIF));
        camel.start();

        Endpoint endpoint = camel.getEndpoint(ENDPOINT_START);
        Exchange exchange = endpoint.createExchange();

        // then we set the LDAP filter on the in body
        URL loc = this.getClass().getResource(""/org/apache/camel/component/ldif/AddDuplicate.ldif"");
        exchange.getIn().setBody(loc.toString());

        // now we send the exchange to the endpoint, and receives the response
        // from Camel
        Exchange out = template.send(endpoint, exchange);

        // Check the results
        List<String> ldifResults = defaultLdapModuleOutAssertions(out);
        assertThat(ldifResults, notNullValue());
        assertThat(ldifResults.size(), equalTo(1));
        assertThat(ldifResults.get(0), not(equalTo(""success"")));
    }
",non-flaky,5
33921,apache_camel,LdifRouteIT.modify,"    @Test
    public void modify() throws Exception {
        setupData(""/org/apache/camel/component/ldif/ModifySetup.ldif"");

        camel.addRoutes(createRouteBuilder(ENDPOINT_LDIF));
        camel.start();

        Endpoint endpoint = camel.getEndpoint(ENDPOINT_START);
        Exchange exchange = endpoint.createExchange();

        // then we set the LDAP filter on the in body
        URL loc = this.getClass().getResource(""/org/apache/camel/component/ldif/Modify.ldif"");
        exchange.getIn().setBody(loc.toString());

        // now we send the exchange to the endpoint, and receives the response
        // from Camel
        Exchange out = template.send(endpoint, exchange);

        // Check the results
        List<String> ldifResults = defaultLdapModuleOutAssertions(out);
        assertThat(ldifResults, notNullValue());
        assertThat(ldifResults.size(), equalTo(1));
        assertThat(ldifResults.get(0), equalTo(""success""));

        // Check LDAP
        SearchResult sr;
        NamingEnumeration<SearchResult> searchResults = ldapContext.search(""dc=example,dc=org"", ""(uid=test*)"", SEARCH_CONTROLS);
        assertNotNull(searchResults);

        boolean uidFound = false;
        while (searchResults.hasMore()) {
            sr = searchResults.next();
            if (sr.getName().contains(""uid=test4"")) {
                uidFound = true;

                // Check the attributes of the search result
                Attributes attribs = sr.getAttributes();
                assertNotNull(attribs);
                Attribute attrib = attribs.get(""sn"");
                assertNotNull(attribs);
                assertThat(1, equalTo(attrib.size()));
                assertThat(""5"", equalTo(attrib.get(0).toString()));
            }
        }

        assertThat(""uid=test4 not found"", uidFound, equalTo(true));
    }
",non-flaky,5
33922,apache_camel,LdifRouteIT.modRdn,"    @Test
    public void modRdn() throws Exception {
        setupData(""/org/apache/camel/component/ldif/ModRdnSetup.ldif"");

        camel.addRoutes(createRouteBuilder(ENDPOINT_LDIF));
        camel.start();

        Endpoint endpoint = camel.getEndpoint(ENDPOINT_START);
        Exchange exchange = endpoint.createExchange();

        // then we set the LDAP filter on the in body
        URL loc = this.getClass().getResource(""/org/apache/camel/component/ldif/ModRdn.ldif"");
        exchange.getIn().setBody(loc.toString());

        // now we send the exchange to the endpoint, and receives the response
        // from Camel
        Exchange out = template.send(endpoint, exchange);

        // Check the results
        List<String> ldifResults = defaultLdapModuleOutAssertions(out);
        assertThat(ldifResults, notNullValue());
        assertThat(ldifResults.size(), equalTo(1));
        assertThat(ldifResults.get(0), equalTo(""success""));

        // Check LDAP
        NamingEnumeration<SearchResult> searchResults = ldapContext.search(""dc=example,dc=org"", ""(uid=test*)"", SEARCH_CONTROLS);
        assertNotNull(searchResults);

        checkDN(""uid=test6"", searchResults);
    }
",non-flaky,5
33923,apache_camel,LdifRouteIT.modDn,"    @Test
    public void modDn() throws Exception {
        setupData(""/org/apache/camel/component/ldif/ModDnSetup.ldif"");

        camel.addRoutes(createRouteBuilder(ENDPOINT_LDIF));
        camel.start();

        Endpoint endpoint = camel.getEndpoint(ENDPOINT_START);
        Exchange exchange = endpoint.createExchange();

        // then we set the LDAP filter on the in body
        URL loc = this.getClass().getResource(""/org/apache/camel/component/ldif/ModDn.ldif"");
        exchange.getIn().setBody(loc.toString());

        // now we send the exchange to the endpoint, and receives the response
        // from Camel
        Exchange out = template.send(endpoint, exchange);

        // Check the results
        List<String> ldifResults = defaultLdapModuleOutAssertions(out);
        assertThat(ldifResults, notNullValue());
        assertThat(ldifResults.size(), equalTo(1));
        assertThat(ldifResults.get(0), equalTo(""success""));

        // Check LDAP
        NamingEnumeration<SearchResult> searchResults = ldapContext.search(""dc=example,dc=org"", ""(uid=test*)"", SEARCH_CONTROLS);
        assertNotNull(searchResults);

        checkDN(""uid=test7"", searchResults);
    }
",non-flaky,5
33924,apache_camel,CordaConsumerVaultTrackByWithSortingIT.vaultTrackByWithSortingTest,"    @Test
    public void vaultTrackByWithSortingTest() throws Exception {
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
    }
",non-flaky,5
33925,apache_camel,CordaConsumerVaultTrackByCriteriaIT.vaultTrackByCriteriaTest,"    @Test
    public void vaultTrackByCriteriaTest() throws Exception {
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
    }
",non-flaky,5
33926,apache_camel,CordaConsumerVaultTrackIT.vaultTrackTest,"    @Test
    public void vaultTrackTest() throws Exception {
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
    }
",non-flaky,5
33927,apache_camel,CordaConsumerStateMachineFeedIT.stateMachineFeedTest,"    @Test
    public void stateMachineFeedTest() throws Exception {
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
    }
",non-flaky,5
33928,apache_camel,CordaConsumerVaultTrackByIT.vaultTrackByTest,"    @Test
    public void vaultTrackByTest() throws Exception {
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
    }
",non-flaky,5
33929,apache_camel,CordaConsumerStartTrackedFlowDynamicIT.startTrackedFlowDynamicTest,"    @Test
    public void startTrackedFlowDynamicTest() throws Exception {
        //Expects CamelFlow is deployed on the node
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
        assertEquals(""Hello world!"", mockResult.getExchanges().get(0).getIn().getBody());
    }
",non-flaky,5
33930,apache_camel,CordaProducerIT.currentNodeTimeTest,"    @Test
    public void currentNodeTimeTest() throws Exception {
        Exchange exchange = createExchangeWithBodyAndHeader(null, OPERATION, CURRENT_NODE_TIME);
        template.send(exchange);
        Object body = exchange.getIn().getBody();
        assertNotNull(body);
        Object exception = exchange.getException();
        assertNull(exception);
    }
",non-flaky,5
43026,trinodb_trino,TestDevelopmentLoaderConfig.testDefaults,"    @Test
    public void testDefaults()
    {
        assertRecordedDefaults(recordDefaults(DevelopmentLoaderConfig.class)
                .setPlugins("""")
                .setMavenLocalRepository(ArtifactResolver.USER_LOCAL_REPO)
                .setMavenRemoteRepository(ArtifactResolver.MAVEN_CENTRAL_URI));
    }
",non-flaky,5
43027,trinodb_trino,TestDevelopmentLoaderConfig.testExplicitPropertyMappings,"    @Test
    public void testExplicitPropertyMappings()
    {
        Map<String, String> properties = new ImmutableMap.Builder<String, String>()
                .put(""plugin.bundles"", ""a,b,c"")
                .put(""maven.repo.local"", ""local-repo"")
                .put(""maven.repo.remote"", ""remote-a,remote-b"")
                .buildOrThrow();

        DevelopmentLoaderConfig expected = new DevelopmentLoaderConfig()
                .setPlugins(ImmutableList.of(""a"", ""b"", ""c""))
                .setMavenLocalRepository(""local-repo"")
                .setMavenRemoteRepository(ImmutableList.of(""remote-a"", ""remote-b""));

        assertFullMapping(properties, expected);
    }
",non-flaky,5
43028,trinodb_trino,BaseDynamicPartitionPruningTest.testJoinWithEmptyBuildSide,"    @Test(timeOut = 30_000)
    public void testJoinWithEmptyBuildSide()
    {
        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem JOIN supplier ON partitioned_lineitem.suppkey = supplier.suppkey AND supplier.name = 'abc'"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        assertEquals(probeStats.getInputPositions(), 0L);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);

        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertEquals(domainStats.getSimplifiedDomain(), none(BIGINT).toString(getSession().toConnectorSession()));
        assertTrue(domainStats.getCollectionDuration().isPresent());
    }
",non-flaky,5
43029,trinodb_trino,BaseDynamicPartitionPruningTest.testJoinWithSelectiveBuildSide,"    @Test(timeOut = 30_000)
    public void testJoinWithSelectiveBuildSide()
    {
        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem JOIN supplier ON partitioned_lineitem.suppkey = supplier.suppkey "" +
                ""AND supplier.name = 'Supplier#000000001'"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        // Probe-side is partially scanned
        assertEquals(probeStats.getInputPositions(), 615L);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);

        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertEquals(domainStats.getSimplifiedDomain(), singleValue(BIGINT, 1L).toString(getSession().toConnectorSession()));
    }
",non-flaky,5
43030,trinodb_trino,BaseDynamicPartitionPruningTest.testJoinWithNonSelectiveBuildSide,"    @Test(timeOut = 30_000)
    public void testJoinWithNonSelectiveBuildSide()
    {
        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem JOIN supplier ON partitioned_lineitem.suppkey = supplier.suppkey"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        // Probe-side is fully scanned
        assertEquals(probeStats.getInputPositions(), LINEITEM_COUNT);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);

        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertThat(domainStats.getSimplifiedDomain())
                .isEqualTo(getSimplifiedDomainString(1L, 100L, 100, BIGINT));
    }
",non-flaky,5
43031,trinodb_trino,BaseDynamicPartitionPruningTest.testJoinLargeBuildSideRangeDynamicFiltering,"    @Test(timeOut = 30_000)
    public void testJoinLargeBuildSideRangeDynamicFiltering()
    {
        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem JOIN orders ON partitioned_lineitem.orderkey = orders.orderkey"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        // Probe-side is fully scanned because the build-side is too large for dynamic filtering
        assertEquals(probeStats.getInputPositions(), LINEITEM_COUNT);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);

        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertEquals(
                domainStats.getSimplifiedDomain(),
                Domain.create(ValueSet.ofRanges(range(BIGINT, 1L, true, 60000L, true)), false)
                        .toString(getSession().toConnectorSession()));
    }
",non-flaky,5
43032,trinodb_trino,BaseDynamicPartitionPruningTest.testJoinWithMultipleDynamicFiltersOnProbe,"    @Test(timeOut = 30_000)
    public void testJoinWithMultipleDynamicFiltersOnProbe()
    {
        // supplier names Supplier#000000001 and Supplier#000000002 match suppkey 1 and 2
        @Language(""SQL"") String selectQuery = ""SELECT * FROM ("" +
                ""SELECT supplier.suppkey FROM "" +
                ""partitioned_lineitem JOIN tpch.tiny.supplier ON partitioned_lineitem.suppkey = supplier.suppkey AND supplier.name IN ('Supplier#000000001', 'Supplier#000000002')"" +
                "") t JOIN supplier ON t.suppkey = supplier.suppkey AND supplier.suppkey IN (2, 3)"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        // Probe-side is partially scanned
        assertEquals(probeStats.getInputPositions(), 558L);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 2L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 2L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 2);

        List<DynamicFilterDomainStats> domainStats = dynamicFiltersStats.getDynamicFilterDomainStats();
        assertThat(domainStats).map(DynamicFilterDomainStats::getSimplifiedDomain)
                .containsExactlyInAnyOrder(
                        getSimplifiedDomainString(2L, 3L, 2, BIGINT),
                        getSimplifiedDomainString(2L, 2L, 1, BIGINT));
    }
",non-flaky,5
43033,trinodb_trino,BaseDynamicPartitionPruningTest.testJoinWithImplicitCoercion,"    @Test(timeOut = 30_000)
    public void testJoinWithImplicitCoercion()
    {
        // setup partitioned fact table with integer suppkey
        createLineitemTable(""partitioned_lineitem_int"", ImmutableList.of(""orderkey"", ""CAST(suppkey as int) suppkey_int""), ImmutableList.of(""suppkey_int""));
        assertQuery(
                ""SELECT count(*) FROM partitioned_lineitem_int"",
                ""VALUES "" + LINEITEM_COUNT);

        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem_int l JOIN supplier s ON l.suppkey_int = s.suppkey AND s.name = 'Supplier#000000001'"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(""partitioned_lineitem_int""));
        // Probe-side is partially scanned
        assertEquals(probeStats.getInputPositions(), 615L);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);
        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertEquals(domainStats.getSimplifiedDomain(), singleValue(BIGINT, 1L).toString(getSession().toConnectorSession()));
    }
",non-flaky,5
43034,trinodb_trino,BaseDynamicPartitionPruningTest.testSemiJoinWithEmptyBuildSide,"    @Test(timeOut = 30_000)
    public void testSemiJoinWithEmptyBuildSide()
    {
        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem WHERE suppkey IN (SELECT suppkey FROM supplier WHERE name = 'abc')"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        assertEquals(probeStats.getInputPositions(), 0L);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);

        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertEquals(domainStats.getSimplifiedDomain(), none(BIGINT).toString(getSession().toConnectorSession()));
    }
",non-flaky,5
43035,trinodb_trino,BaseDynamicPartitionPruningTest.testSemiJoinWithSelectiveBuildSide,"    @Test(timeOut = 30_000)
    public void testSemiJoinWithSelectiveBuildSide()
    {
        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem WHERE suppkey IN (SELECT suppkey FROM supplier WHERE name = 'Supplier#000000001')"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        // Probe-side is partially scanned
        assertEquals(probeStats.getInputPositions(), 615L);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);

        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertEquals(domainStats.getSimplifiedDomain(), singleValue(BIGINT, 1L).toString(getSession().toConnectorSession()));
    }
",non-flaky,5
43036,trinodb_trino,BaseDynamicPartitionPruningTest.testSemiJoinWithNonSelectiveBuildSide,"    @Test(timeOut = 30_000)
    public void testSemiJoinWithNonSelectiveBuildSide()
    {
        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem WHERE suppkey IN (SELECT suppkey FROM supplier)"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        // Probe-side is fully scanned
        assertEquals(probeStats.getInputPositions(), LINEITEM_COUNT);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);

        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertThat(domainStats.getSimplifiedDomain())
                .isEqualTo(getSimplifiedDomainString(1L, 100L, 100, BIGINT));
    }
",non-flaky,5
43037,trinodb_trino,BaseDynamicPartitionPruningTest.testSemiJoinLargeBuildSideRangeDynamicFiltering,"    @Test(timeOut = 30_000)
    public void testSemiJoinLargeBuildSideRangeDynamicFiltering()
    {
        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem WHERE orderkey IN (SELECT orderkey FROM orders)"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        // Probe-side is fully scanned because the build-side is too large for dynamic filtering
        assertEquals(probeStats.getInputPositions(), LINEITEM_COUNT);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);

        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertEquals(
                domainStats.getSimplifiedDomain(),
                Domain.create(ValueSet.ofRanges(range(BIGINT, 1L, true, 60000L, true)), false)
                        .toString(getSession().toConnectorSession()));
    }
",non-flaky,5
43038,trinodb_trino,BaseDynamicPartitionPruningTest.testRightJoinWithEmptyBuildSide,"    @Test(timeOut = 30_000)
    public void testRightJoinWithEmptyBuildSide()
    {
        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem l RIGHT JOIN supplier s ON l.suppkey = s.suppkey WHERE name = 'abc'"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        assertEquals(probeStats.getInputPositions(), 0L);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);

        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertEquals(domainStats.getSimplifiedDomain(), none(BIGINT).toString(getSession().toConnectorSession()));
    }
",non-flaky,5
43039,trinodb_trino,BaseDynamicPartitionPruningTest.testRightJoinWithSelectiveBuildSide,"    @Test(timeOut = 30_000)
    public void testRightJoinWithSelectiveBuildSide()
    {
        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem l RIGHT JOIN supplier s ON l.suppkey = s.suppkey WHERE name = 'Supplier#000000001'"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        // Probe-side is partially scanned
        assertEquals(probeStats.getInputPositions(), 615L);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);

        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertEquals(domainStats.getSimplifiedDomain(), singleValue(BIGINT, 1L).toString(getSession().toConnectorSession()));
    }
",non-flaky,5
43040,trinodb_trino,BaseDynamicPartitionPruningTest.testRightJoinWithNonSelectiveBuildSide,"    @Test(timeOut = 30_000)
    public void testRightJoinWithNonSelectiveBuildSide()
    {
        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem l RIGHT JOIN supplier s ON l.suppkey = s.suppkey"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        // Probe-side is fully scanned
        assertEquals(probeStats.getInputPositions(), LINEITEM_COUNT);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);

        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertThat(domainStats.getSimplifiedDomain())
                .isEqualTo(getSimplifiedDomainString(1L, 100L, 100, BIGINT));
    }
",non-flaky,5
43041,trinodb_trino,BaseConnectorTest.ensureTestNamingConvention,"    @Test
    public void ensureTestNamingConvention()
    {
        // Enforce a naming convention to make code navigation easier.
        assertThat(getClass().getName())
                .endsWith(""ConnectorTest"");
    }
",non-flaky,5
43042,trinodb_trino,BaseConnectorTest.testColumnsInReverseOrder,"    @Test
    public void testColumnsInReverseOrder()
    {
        assertQuery(""SELECT shippriority, clerk, totalprice FROM orders"");
    }
",non-flaky,5
43043,trinodb_trino,BaseConnectorTest.testCharVarcharComparison,"    @Test
    public void testCharVarcharComparison()
    {
        skipTestUnless(hasBehavior(SUPPORTS_CREATE_TABLE));

        try (TestTable table = new TestTable(
                getQueryRunner()::execute,
                ""test_char_varchar"",
                ""(k, v) AS VALUES"" +
                        ""   (-1, CAST(NULL AS char(3))), "" +
                        ""   (3, CAST('   ' AS char(3))),"" +
                        ""   (6, CAST('x  ' AS char(3)))"")) {
            // varchar of length shorter than column's length
            assertQuery(
                    ""SELECT k, v FROM "" + table.getName() + "" WHERE v = CAST('  ' AS varchar(2))"",
                    // The value is included because both sides of the comparison are coerced to char(3)
                    ""VALUES (3, '   ')"");

            // varchar of length longer than column's length
            assertQuery(
                    ""SELECT k, v FROM "" + table.getName() + "" WHERE v = CAST('  ' AS varchar(4))"",
                    // The value is included because both sides of the comparison are coerced to char(4)
                    ""VALUES (3, '   ')"");

            // value that's not all-spaces
            assertQuery(
                    ""SELECT k, v FROM "" + table.getName() + "" WHERE v = CAST('x ' AS varchar(2))"",
                    // The value is included because both sides of the comparison are coerced to char(3)
                    ""VALUES (6, 'x  ')"");
        }
    }
",non-flaky,5
43044,trinodb_trino,BaseConnectorTest.testVarcharCharComparison,"    @Test
    public void testVarcharCharComparison()
    {
        skipTestUnless(hasBehavior(SUPPORTS_CREATE_TABLE));

        try (TestTable table = new TestTable(
                getQueryRunner()::execute,
                ""test_varchar_char"",
                ""(k, v) AS VALUES"" +
                        ""   (-1, CAST(NULL AS varchar(3))), "" +
                        ""   (0, CAST('' AS varchar(3))),"" +
                        ""   (1, CAST(' ' AS varchar(3))), "" +
                        ""   (2, CAST('  ' AS varchar(3))), "" +
                        ""   (3, CAST('   ' AS varchar(3))),"" +
                        ""   (4, CAST('x' AS varchar(3))),"" +
                        ""   (5, CAST('x ' AS varchar(3))),"" +
                        ""   (6, CAST('x  ' AS varchar(3)))"")) {
            assertQuery(
                    ""SELECT k, v FROM "" + table.getName() + "" WHERE v = CAST('  ' AS char(2))"",
                    // The 3-spaces value is included because both sides of the comparison are coerced to char(3)
                    ""VALUES (0, ''), (1, ' '), (2, '  '), (3, '   ')"");

            // value that's not all-spaces
            assertQuery(
                    ""SELECT k, v FROM "" + table.getName() + "" WHERE v = CAST('x ' AS char(2))"",
                    // The 3-spaces value is included because both sides of the comparison are coerced to char(3)
                    ""VALUES (4, 'x'), (5, 'x '), (6, 'x  ')"");
        }
    }
",non-flaky,5
43045,trinodb_trino,BaseConnectorTest.testAggregation,"    @Test
    public void testAggregation()
    {
        assertQuery(""SELECT sum(orderkey) FROM orders"");
        assertQuery(""SELECT sum(totalprice) FROM orders"");
        assertQuery(""SELECT max(comment) FROM nation"");

        assertQuery(""SELECT count(*) FROM orders"");
        assertQuery(""SELECT count(*) FROM orders WHERE orderkey > 10"");
        assertQuery(""SELECT count(*) FROM (SELECT * FROM orders LIMIT 10)"");
        assertQuery(""SELECT count(*) FROM (SELECT * FROM orders WHERE orderkey > 10 LIMIT 10)"");

        assertQuery(""SELECT DISTINCT regionkey FROM nation"");
        assertQuery(""SELECT regionkey FROM nation GROUP BY regionkey"");

        // TODO support aggregation pushdown with GROUPING SETS
        assertQuery(
                ""SELECT regionkey, nationkey FROM nation GROUP BY GROUPING SETS ((regionkey), (nationkey))"",
                ""SELECT NULL, nationkey FROM nation "" +
                        ""UNION ALL SELECT DISTINCT regionkey, NULL FROM nation"");
        assertQuery(
                ""SELECT regionkey, nationkey, count(*) FROM nation GROUP BY GROUPING SETS ((), (regionkey), (nationkey), (regionkey, nationkey))"",
                ""SELECT NULL, NULL, count(*) FROM nation "" +
                        ""UNION ALL SELECT NULL, nationkey, 1 FROM nation "" +
                        ""UNION ALL SELECT regionkey, NULL, count(*) FROM nation GROUP BY regionkey "" +
                        ""UNION ALL SELECT regionkey, nationkey, 1 FROM nation"");

        assertQuery(""SELECT count(regionkey) FROM nation"");
        assertQuery(""SELECT count(DISTINCT regionkey) FROM nation"");
        assertQuery(""SELECT regionkey, count(*) FROM nation GROUP BY regionkey"");

        assertQuery(""SELECT min(regionkey), max(regionkey) FROM nation"");
        assertQuery(""SELECT min(DISTINCT regionkey), max(DISTINCT regionkey) FROM nation"");
        assertQuery(""SELECT regionkey, min(regionkey), min(name), max(regionkey), max(name) FROM nation GROUP BY regionkey"");

        assertQuery(""SELECT sum(regionkey) FROM nation"");
        assertQuery(""SELECT sum(DISTINCT regionkey) FROM nation"");
        assertQuery(""SELECT regionkey, sum(regionkey) FROM nation GROUP BY regionkey"");

        assertQuery(
                ""SELECT avg(nationkey) FROM nation"",
                ""SELECT avg(CAST(nationkey AS double)) FROM nation"");
        assertQuery(
                ""SELECT avg(DISTINCT nationkey) FROM nation"",
                ""SELECT avg(DISTINCT CAST(nationkey AS double)) FROM nation"");
        assertQuery(
                ""SELECT regionkey, avg(nationkey) FROM nation GROUP BY regionkey"",
                ""SELECT regionkey, avg(CAST(nationkey AS double)) FROM nation GROUP BY regionkey"");
    }
",non-flaky,5
43046,trinodb_trino,BaseConnectorTest.testExactPredicate,"    @Test
    public void testExactPredicate()
    {
        assertQueryReturnsEmptyResult(""SELECT * FROM orders WHERE orderkey = 10"");

        // filtered column is selected
        assertQuery(""SELECT custkey, orderkey FROM orders WHERE orderkey = 32"", ""VALUES (1301, 32)"");

        // filtered column is not selected
        assertQuery(""SELECT custkey FROM orders WHERE orderkey = 32"", ""VALUES (1301)"");
    }
",non-flaky,5
43047,trinodb_trino,BaseConnectorTest.testInListPredicate,"    @Test
    public void testInListPredicate()
    {
        assertQueryReturnsEmptyResult(""SELECT * FROM orders WHERE orderkey IN (10, 11, 20, 21)"");

        // filtered column is selected
        assertQuery(""SELECT custkey, orderkey FROM orders WHERE orderkey IN (7, 10, 32, 33)"", ""VALUES (392, 7), (1301, 32), (670, 33)"");

        // filtered column is not selected
        assertQuery(""SELECT custkey FROM orders WHERE orderkey IN (7, 10, 32, 33)"", ""VALUES (392), (1301), (670)"");
    }
",non-flaky,5
43048,trinodb_trino,BaseConnectorTest.testIsNullPredicate,"    @Test
    public void testIsNullPredicate()
    {
        assertQueryReturnsEmptyResult(""SELECT * FROM orders WHERE orderkey IS NULL"");
        assertQueryReturnsEmptyResult(""SELECT * FROM orders WHERE orderkey = 10 OR orderkey IS NULL"");

        // filtered column is selected
        assertQuery(""SELECT custkey, orderkey FROM orders WHERE orderkey = 32 OR orderkey IS NULL"", ""VALUES (1301, 32)"");

        // filtered column is not selected
        assertQuery(""SELECT custkey FROM orders WHERE orderkey = 32 OR orderkey IS NULL"", ""VALUES (1301)"");
    }
",non-flaky,5
43049,trinodb_trino,BaseConnectorTest.testLikePredicate,"    @Test
    public void testLikePredicate()
    {
        // filtered column is not selected
        assertQuery(""SELECT orderkey FROM orders WHERE orderpriority LIKE '5-L%'"");

        // filtered column is selected
        assertQuery(""SELECT orderkey, orderpriority FROM orders WHERE orderpriority LIKE '5-L%'"");

        // filtered column is not selected
        assertQuery(""SELECT orderkey FROM orders WHERE orderpriority LIKE '5-L__'"");

        // filtered column is selected
        assertQuery(""SELECT orderkey, orderpriority FROM orders WHERE orderpriority LIKE '5-L__'"");
    }
",non-flaky,5
43050,trinodb_trino,BaseConnectorTest.testMultipleRangesPredicate,"    @Test
    public void testMultipleRangesPredicate()
    {
        // List columns explicitly. Some connectors do not maintain column ordering.
        assertQuery("""" +
                ""SELECT orderkey, custkey, orderstatus, totalprice, orderdate, orderpriority, clerk, shippriority, comment "" +
                ""FROM orders "" +
                ""WHERE orderkey BETWEEN 10 AND 50"");
    }
",non-flaky,5
43051,trinodb_trino,BaseConnectorTest.testRangePredicate,"    @Test
    public void testRangePredicate()
    {
        // List columns explicitly. Some connectors do not maintain column ordering.
        assertQuery("""" +
                ""SELECT orderkey, custkey, orderstatus, totalprice, orderdate, orderpriority, clerk, shippriority, comment "" +
                ""FROM orders "" +
                ""WHERE orderkey BETWEEN 10 AND 50"");
    }
",non-flaky,5
43052,trinodb_trino,BaseConnectorTest.testPredicateReflectedInExplain,"    @Test
    public void testPredicateReflectedInExplain()
    {
        // Even if the predicate is pushed down into the table scan, it should still be reflected in EXPLAIN (via ConnectorTableHandle.toString)
        assertExplain(
                ""EXPLAIN SELECT name FROM nation WHERE nationkey = 42"",
                ""(predicate|filterPredicate|constraint).{0,10}(nationkey|NATIONKEY)"");
    }
",non-flaky,5
43053,trinodb_trino,BaseConnectorTest.testSortItemsReflectedInExplain,"    @Test
    public void testSortItemsReflectedInExplain()
    {
        // Even if the sort items are pushed down into the table scan, it should still be reflected in EXPLAIN (via ConnectorTableHandle.toString)
        @Language(""RegExp"") String expectedPattern = hasBehavior(SUPPORTS_TOPN_PUSHDOWN)
                ? ""sortOrder=\\[(?i:nationkey):.* DESC NULLS LAST] limit=5""
                : ""\\[5 by \\((?i:nationkey) DESC NULLS LAST\\)]"";

        assertExplain(
                ""EXPLAIN SELECT name FROM nation ORDER BY nationkey DESC NULLS LAST LIMIT 5"",
                expectedPattern);
    }
",non-flaky,5
43054,trinodb_trino,BaseConnectorTest.testConcurrentScans,"    @Test
    public void testConcurrentScans()
    {
        String unionMultipleTimes = join("" UNION ALL "", nCopies(25, ""SELECT * FROM orders""));
        assertQuery(""SELECT sum(if(rand() >= 0, orderkey)) FROM ("" + unionMultipleTimes + "")"", ""VALUES 11246812500"");
    }
",non-flaky,5
43055,trinodb_trino,BaseConnectorTest.testSelectAll,"    @Test
    public void testSelectAll()
    {
        assertQuery(""SELECT * FROM orders"");
    }
",non-flaky,5
43056,trinodb_trino,BaseConnectorTest.testJoinWithEmptySides,"    @Test(timeOut = 300_000, dataProvider = ""joinDistributionTypes"")
    public void testJoinWithEmptySides(JoinDistributionType joinDistributionType)
    {
        Session session = noJoinReordering(joinDistributionType);
        // empty build side
        assertQuery(session, ""SELECT count(*) FROM nation JOIN region ON nation.regionkey = region.regionkey AND region.name = ''"", ""VALUES 0"");
        assertQuery(session, ""SELECT count(*) FROM nation JOIN region ON nation.regionkey = region.regionkey AND region.regionkey < 0"", ""VALUES 0"");
        // empty probe side
        assertQuery(session, ""SELECT count(*) FROM region JOIN nation ON nation.regionkey = region.regionkey AND region.name = ''"", ""VALUES 0"");
        assertQuery(session, ""SELECT count(*) FROM nation JOIN region ON nation.regionkey = region.regionkey AND region.regionkey < 0"", ""VALUES 0"");
    }
",non-flaky,5
43057,trinodb_trino,BaseConnectorTest.testJoin,"    @Test
    public void testJoin()
    {
        Session session = Session.builder(getSession())
                .setSystemProperty(IGNORE_STATS_CALCULATOR_FAILURES, ""false"")
                .build();

        // 2 inner joins, eligible for join reodering
        assertQuery(
                session,
                ""SELECT c.name, n.name, r.name "" +
                        ""FROM nation n "" +
                        ""JOIN customer c ON c.nationkey = n.nationkey "" +
                        ""JOIN region r ON n.regionkey = r.regionkey"");

        // 2 inner joins, eligible for join reodering, where one table has a filter
        assertQuery(
                session,
                ""SELECT c.name, n.name, r.name "" +
                        ""FROM nation n "" +
                        ""JOIN customer c ON c.nationkey = n.nationkey "" +
                        ""JOIN region r ON n.regionkey = r.regionkey "" +
                        ""WHERE n.name = 'ARGENTINA'"");

        // 2 inner joins, eligible for join reodering, on top of aggregation
        assertQuery(
                session,
                ""SELECT c.name, n.name, n.count, r.name "" +
                        ""FROM (SELECT name, regionkey, nationkey, count(*) count FROM nation GROUP BY name, regionkey, nationkey) n "" +
                        ""JOIN customer c ON c.nationkey = n.nationkey "" +
                        ""JOIN region r ON n.regionkey = r.regionkey"");
    }
",non-flaky,5
43058,trinodb_trino,BaseConnectorTest.testDescribeTable,"    @Test
    public void testDescribeTable()
    {
        MaterializedResult expectedColumns = MaterializedResult.resultBuilder(getSession(), VARCHAR, VARCHAR, VARCHAR, VARCHAR)
                .row(""orderkey"", ""bigint"", """", """")
                .row(""custkey"", ""bigint"", """", """")
                .row(""orderstatus"", ""varchar(1)"", """", """")
                .row(""totalprice"", ""double"", """", """")
                .row(""orderdate"", ""date"", """", """")
                .row(""orderpriority"", ""varchar(15)"", """", """")
                .row(""clerk"", ""varchar(15)"", """", """")
                .row(""shippriority"", ""integer"", """", """")
                .row(""comment"", ""varchar(79)"", """", """")
                .build();
        MaterializedResult actualColumns = computeActual(""DESCRIBE orders"");
        assertEquals(actualColumns, expectedColumns);
    }
",non-flaky,5
43059,trinodb_trino,BaseConnectorTest.testMaterializedView,"    @Test
    public void testMaterializedView()
    {
        if (!hasBehavior(SUPPORTS_CREATE_MATERIALIZED_VIEW)) {
            assertQueryFails(""CREATE MATERIALIZED VIEW nation_mv AS SELECT * FROM nation"", ""This connector does not support creating materialized views"");
            return;
        }

        QualifiedObjectName view = new QualifiedObjectName(
                getSession().getCatalog().orElseThrow(),
                getSession().getSchema().orElseThrow(),
                ""test_materialized_view_"" + randomTableSuffix());
        QualifiedObjectName otherView = new QualifiedObjectName(
                getSession().getCatalog().orElseThrow(),
                ""other_schema"",
                ""test_materialized_view_"" + randomTableSuffix());
        QualifiedObjectName viewWithComment = new QualifiedObjectName(
                getSession().getCatalog().orElseThrow(),
                getSession().getSchema().orElseThrow(),
                ""test_materialized_view_with_comment_"" + randomTableSuffix());

        createTestingMaterializedView(view, Optional.empty());
        createTestingMaterializedView(otherView, Optional.of(""sarcastic comment""));
        createTestingMaterializedView(viewWithComment, Optional.of(""mv_comment""));

        // verify comment
        MaterializedResult materializedRows = computeActual(""SHOW CREATE MATERIALIZED VIEW "" + viewWithComment);
        assertThat((String) materializedRows.getOnlyValue()).contains(""COMMENT 'mv_comment'"");
        assertThat(query(
                ""SELECT table_name, comment FROM system.metadata.table_comments "" +
                        ""WHERE catalog_name = '"" + view.getCatalogName() + ""' AND "" +
                        ""schema_name = '"" + view.getSchemaName() + ""'""))
                .skippingTypesCheck()
                .containsAll(""VALUES ('"" + view.getObjectName() + ""', null), ('"" + viewWithComment.getObjectName() + ""', 'mv_comment')"");

        // reading
        assertThat(query(""SELECT * FROM "" + view))
                .skippingTypesCheck()
                .matches(""SELECT * FROM nation"");
        assertThat(query(""SELECT * FROM "" + viewWithComment))
                .skippingTypesCheck()
                .matches(""SELECT * FROM nation"");

        // table listing
        assertThat(query(""SHOW TABLES""))
                .skippingTypesCheck()
                .containsAll(""VALUES '"" + view.getObjectName() + ""'"");
        // information_schema.tables without table_name filter
        assertThat(query(
                ""SELECT table_name, table_type FROM information_schema.tables "" +
                        ""WHERE table_schema = '"" + view.getSchemaName() + ""'""))
                .skippingTypesCheck()
                .containsAll(""VALUES ('"" + view.getObjectName() + ""', 'BASE TABLE')""); // TODO table_type should probably be ""* VIEW""
        // information_schema.tables with table_name filter
        assertQuery(
                ""SELECT table_name, table_type FROM information_schema.tables "" +
                        ""WHERE table_schema = '"" + view.getSchemaName() + ""' and table_name = '"" + view.getObjectName() + ""'"",
                ""VALUES ('"" + view.getObjectName() + ""', 'BASE TABLE')"");

        // system.jdbc.tables without filter
        assertThat(query(""SELECT table_schem, table_name, table_type FROM system.jdbc.tables""))
                .skippingTypesCheck()
                .containsAll(""VALUES ('"" + view.getSchemaName() + ""', '"" + view.getObjectName() + ""', 'TABLE')"");

        // system.jdbc.tables with table prefix filter
        assertQuery(
                ""SELECT table_schem, table_name, table_type "" +
                        ""FROM system.jdbc.tables "" +
                        ""WHERE table_cat = '"" + view.getCatalogName() + ""' AND "" +
                        ""table_schem = '"" + view.getSchemaName() + ""' AND "" +
                        ""table_name = '"" + view.getObjectName() + ""'"",
                ""VALUES ('"" + view.getSchemaName() + ""', '"" + view.getObjectName() + ""', 'TABLE')"");

        // column listing
        assertThat(query(""SHOW COLUMNS FROM "" + view.getObjectName()))
                .projected(0) // column types can very between connectors
                .skippingTypesCheck()
                .matches(""VALUES 'nationkey', 'name', 'regionkey', 'comment'"");

        assertThat(query(""DESCRIBE "" + view.getObjectName()))
                .projected(0) // column types can very between connectors
                .skippingTypesCheck()
                .matches(""VALUES 'nationkey', 'name', 'regionkey', 'comment'"");

        // information_schema.columns without table_name filter
        assertThat(query(
                ""SELECT table_name, column_name "" +
                        ""FROM information_schema.columns "" +
                        ""WHERE table_schema = '"" + view.getSchemaName() + ""'""))
                .skippingTypesCheck()
                .containsAll(
                        ""SELECT * FROM (VALUES '"" + view.getObjectName() + ""') "" +
                                ""CROSS JOIN UNNEST(ARRAY['nationkey', 'name', 'regionkey', 'comment'])"");

        // information_schema.columns with table_name filter
        assertThat(query(
                ""SELECT table_name, column_name "" +
                        ""FROM information_schema.columns "" +
                        ""WHERE table_schema = '"" + view.getSchemaName() + ""' and table_name = '"" + view.getObjectName() + ""'""))
                .skippingTypesCheck()
                .containsAll(
                        ""SELECT * FROM (VALUES '"" + view.getObjectName() + ""') "" +
                                ""CROSS JOIN UNNEST(ARRAY['nationkey', 'name', 'regionkey', 'comment'])"");

        // view-specific listings
        checkInformationSchemaViewsForMaterializedView(view.getSchemaName(), view.getObjectName());

        // system.jdbc.columns without filter
        @Language(""SQL"") String expectedValues = ""VALUES ('"" + view.getSchemaName() + ""', '"" + view.getObjectName() + ""', 'nationkey'), "" +
                ""('"" + view.getSchemaName() + ""', '"" + view.getObjectName() + ""', 'name'), "" +
                ""('"" + view.getSchemaName() + ""', '"" + view.getObjectName() + ""', 'regionkey'), "" +
                ""('"" + view.getSchemaName() + ""', '"" + view.getObjectName() + ""', 'comment')"";
        assertThat(query(
                ""SELECT table_schem, table_name, column_name FROM system.jdbc.columns""))
                .skippingTypesCheck()
                .containsAll(expectedValues);

        // system.jdbc.columns with schema filter
        assertThat(query(
                ""SELECT table_schem, table_name, column_name "" +
                        ""FROM system.jdbc.columns "" +
                        ""WHERE table_schem LIKE '%"" + view.getSchemaName() + ""%'""))
                .skippingTypesCheck()
                .containsAll(expectedValues);

        // system.jdbc.columns with table filter
        assertQuery(
                ""SELECT table_schem, table_name, column_name "" +
                        ""FROM system.jdbc.columns "" +
                        ""WHERE table_name LIKE '%"" + view.getObjectName() + ""%'"",
                expectedValues);

        // details
        assertThat(((String) computeScalar(""SHOW CREATE MATERIALIZED VIEW "" + view.getObjectName())))
                .matches(""(?s)"" +
                        ""CREATE MATERIALIZED VIEW \\Q"" + view + ""\\E"" +
                        "".* AS\n"" +
                        ""SELECT \\*\n"" +
                        ""FROM\n"" +
                        ""  nation"");

        // we only want to test filtering materialized views in different schemas,
        // `viewWithComment` is in the same schema as `view` so it is not needed
        assertUpdate(""DROP MATERIALIZED VIEW "" + viewWithComment);

        // test filtering materialized views in system metadata table
        assertThat(query(listMaterializedViewsSql(""catalog_name = '"" + view.getCatalogName() + ""'"")))
                .skippingTypesCheck()
                .containsAll(getTestingMaterializedViewsResultRows(view, otherView));

        assertThat(query(
                listMaterializedViewsSql(
                        ""catalog_name = '"" + otherView.getCatalogName() + ""'"",
                        ""schema_name = '"" + otherView.getSchemaName() + ""'"")))
                .skippingTypesCheck()
                .containsAll(getTestingMaterializedViewsResultRow(otherView, ""sarcastic comment""));

        assertThat(query(
                listMaterializedViewsSql(
                        ""catalog_name = '"" + view.getCatalogName() + ""'"",
                        ""schema_name = '"" + view.getSchemaName() + ""'"",
                        ""name = '"" + view.getObjectName() + ""'"")))
                .skippingTypesCheck()
                .containsAll(getTestingMaterializedViewsResultRow(view, """"));

        assertThat(query(
                listMaterializedViewsSql(""schema_name LIKE '%"" + view.getSchemaName() + ""%'"")))
                .skippingTypesCheck()
                .containsAll(getTestingMaterializedViewsResultRow(view, """"));

        assertThat(query(
                listMaterializedViewsSql(""name LIKE '%"" + view.getObjectName() + ""%'"")))
                .skippingTypesCheck()
                .containsAll(getTestingMaterializedViewsResultRow(view, """"));

        // verify write in transaction
        if (!hasBehavior(SUPPORTS_MULTI_STATEMENT_WRITES)) {
            assertThatThrownBy(() -> inTransaction(session -> computeActual(session, ""REFRESH MATERIALIZED VIEW "" + view)))
                    .hasMessageMatching(""Catalog only supports writes using autocommit: \\w+"");
        }

        assertUpdate(""DROP MATERIALIZED VIEW "" + view);
        assertUpdate(""DROP MATERIALIZED VIEW "" + otherView);

        assertQueryReturnsEmptyResult(listMaterializedViewsSql(""name = '"" + view.getObjectName() + ""'""));
        assertQueryReturnsEmptyResult(listMaterializedViewsSql(""name = '"" + otherView.getObjectName() + ""'""));
        assertQueryReturnsEmptyResult(listMaterializedViewsSql(""name = '"" + viewWithComment.getObjectName() + ""'""));
    }
",non-flaky,5
43060,trinodb_trino,BaseConnectorTest.testRenameMaterializedView,"    @Test
    public void testRenameMaterializedView()
    {
        skipTestUnless(hasBehavior(SUPPORTS_CREATE_MATERIALIZED_VIEW));

        String schema = ""rename_mv_test"";
        Session session = Session.builder(getSession())
                .setSchema(schema)
                .build();

        QualifiedObjectName originalMaterializedView = new QualifiedObjectName(
                session.getCatalog().orElseThrow(),
                session.getSchema().orElseThrow(),
                ""test_materialized_view_rename_"" + randomTableSuffix());

        createTestingMaterializedView(originalMaterializedView, Optional.empty());

        String renamedMaterializedView = ""test_materialized_view_rename_new_"" + randomTableSuffix();
        if (!hasBehavior(SUPPORTS_RENAME_MATERIALIZED_VIEW)) {
            assertQueryFails(session, ""ALTER MATERIALIZED VIEW "" + originalMaterializedView + "" RENAME TO "" + renamedMaterializedView, ""This connector does not support renaming materialized views"");
            assertUpdate(session, ""DROP MATERIALIZED VIEW "" + originalMaterializedView);
            return;
        }

        // simple rename
        assertUpdate(session, ""ALTER MATERIALIZED VIEW "" + originalMaterializedView + "" RENAME TO "" + renamedMaterializedView);
        assertTestingMaterializedViewQuery(schema, renamedMaterializedView);
        // verify new name in the system.metadata.materialized_views
        assertQuery(session, ""SELECT catalog_name, schema_name FROM system.metadata.materialized_views WHERE name = '"" + renamedMaterializedView + ""'"",
                format(""VALUES ('%s', '%s')"", originalMaterializedView.getCatalogName(), originalMaterializedView.getSchemaName()));
        assertQueryReturnsEmptyResult(session, listMaterializedViewsSql(""name = '"" + originalMaterializedView.getObjectName() + ""'""));

        // rename with IF EXISTS on existing materialized view
        String testExistsMaterializedViewName = ""test_materialized_view_rename_exists_"" + randomTableSuffix();
        assertUpdate(session, ""ALTER MATERIALIZED VIEW IF EXISTS "" + renamedMaterializedView + "" RENAME TO "" + testExistsMaterializedViewName);
        assertTestingMaterializedViewQuery(schema, testExistsMaterializedViewName);

        // rename with upper-case, not delimited identifier
        String uppercaseName = ""TEST_MATERIALIZED_VIEW_RENAME_UPPERCASE_"" + randomTableSuffix();
        assertUpdate(session, ""ALTER MATERIALIZED VIEW "" + testExistsMaterializedViewName + "" RENAME TO "" + uppercaseName);
        assertTestingMaterializedViewQuery(schema, uppercaseName.toLowerCase(ENGLISH)); // Ensure select allows for lower-case, not delimited identifier

        String otherSchema = ""rename_mv_other_schema"";
        assertUpdate(format(""CREATE SCHEMA IF NOT EXISTS %s"", otherSchema));
        if (hasBehavior(SUPPORTS_RENAME_MATERIALIZED_VIEW_ACROSS_SCHEMAS)) {
            assertUpdate(session, ""ALTER MATERIALIZED VIEW "" + uppercaseName + "" RENAME TO "" + otherSchema + ""."" + originalMaterializedView.getObjectName());
            assertTestingMaterializedViewQuery(otherSchema, originalMaterializedView.getObjectName());

            assertUpdate(session, ""DROP MATERIALIZED VIEW "" + otherSchema + ""."" + originalMaterializedView.getObjectName());
        }
        else {
            assertQueryFails(
                    session,
                    ""ALTER MATERIALIZED VIEW "" + uppercaseName + "" RENAME TO "" + otherSchema + ""."" + originalMaterializedView.getObjectName(),
                    ""Materialized View rename across schemas is not supported"");
            assertUpdate(session, ""DROP MATERIALIZED VIEW "" + uppercaseName);
        }

        assertFalse(getQueryRunner().tableExists(session, originalMaterializedView.toString()));
        assertFalse(getQueryRunner().tableExists(session, renamedMaterializedView));
        assertFalse(getQueryRunner().tableExists(session, testExistsMaterializedViewName));

        // rename with IF EXISTS on NOT existing materialized view
        assertUpdate(session, ""ALTER TABLE IF EXISTS "" + originalMaterializedView + "" RENAME TO "" + renamedMaterializedView);
        assertQueryReturnsEmptyResult(session, listMaterializedViewsSql(""name = '"" + originalMaterializedView.getObjectName() + ""'""));
        assertQueryReturnsEmptyResult(session, listMaterializedViewsSql(""name = '"" + renamedMaterializedView + ""'""));
    }
",non-flaky,5
43061,trinodb_trino,BaseConnectorTest.testViewAndMaterializedViewTogether,"    @Test
    public void testViewAndMaterializedViewTogether()
    {
        if (!hasBehavior(SUPPORTS_CREATE_MATERIALIZED_VIEW) || !hasBehavior(SUPPORTS_CREATE_VIEW)) {
            return;
        }
        // Validate that it is possible to have views and materialized views defined at the same time and both are operational

        String schemaName = getSession().getSchema().orElseThrow();

        String regularViewName = ""test_views_together_normal_"" + randomTableSuffix();
        assertUpdate(""CREATE VIEW "" + regularViewName + "" AS SELECT * FROM region"");

        String materializedViewName = ""test_views_together_materialized_"" + randomTableSuffix();
        assertUpdate(""CREATE MATERIALIZED VIEW "" + materializedViewName + "" AS SELECT * FROM nation"");

        // both should be accessible via information_schema.views
        // TODO: actually it is not the cased now hence overridable `checkInformationSchemaViewsForMaterializedView`
        assertThat(query(""SELECT table_name FROM information_schema.views WHERE table_schema = '"" + schemaName + ""'""))
                .skippingTypesCheck()
                .containsAll(""VALUES '"" + regularViewName + ""'"");
        checkInformationSchemaViewsForMaterializedView(schemaName, materializedViewName);

        // check we can query from both
        assertThat(query(""SELECT * FROM "" + regularViewName)).containsAll(""SELECT * FROM region"");
        assertThat(query(""SELECT * FROM "" + materializedViewName)).containsAll(""SELECT * FROM nation"");

        assertUpdate(""DROP VIEW "" + regularViewName);
        assertUpdate(""DROP MATERIALIZED VIEW "" + materializedViewName);
    }
",non-flaky,5
43062,trinodb_trino,BaseConnectorTest.testExplainAnalyze,"    @Test
    public void testExplainAnalyze()
    {
        assertExplainAnalyze(""EXPLAIN ANALYZE SELECT * FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SELECT count(*), clerk FROM orders GROUP BY clerk"");
        assertExplainAnalyze(
                ""EXPLAIN ANALYZE SELECT x + y FROM ("" +
                        ""   SELECT orderdate, COUNT(*) x FROM orders GROUP BY orderdate) a JOIN ("" +
                        ""   SELECT orderdate, COUNT(*) y FROM orders GROUP BY orderdate) b ON a.orderdate = b.orderdate"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SELECT count(*), clerk FROM orders GROUP BY clerk UNION ALL SELECT sum(orderkey), clerk FROM orders GROUP BY clerk"");

        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW COLUMNS FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE EXPLAIN SELECT count(*) FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE EXPLAIN ANALYZE SELECT count(*) FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW FUNCTIONS"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW TABLES"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW SCHEMAS"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW CATALOGS"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW SESSION"");
    }
",non-flaky,5
43063,trinodb_trino,BaseConnectorTest.testExplainAnalyzeVerbose,"    @Test
    public void testExplainAnalyzeVerbose()
    {
        assertExplainAnalyze(""EXPLAIN ANALYZE VERBOSE SELECT * FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE VERBOSE SELECT rank() OVER (PARTITION BY orderkey ORDER BY clerk DESC) FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE VERBOSE SELECT rank() OVER (PARTITION BY orderkey ORDER BY clerk DESC) FROM orders WHERE orderkey < 0"");
    }
",non-flaky,5
43064,trinodb_trino,BaseConnectorTest.testTableSampleSystem,"    @Test
    public void testTableSampleSystem()
    {
        MaterializedResult fullSample = computeActual(""SELECT orderkey FROM orders TABLESAMPLE SYSTEM (100)"");
        MaterializedResult emptySample = computeActual(""SELECT orderkey FROM orders TABLESAMPLE SYSTEM (0)"");
        MaterializedResult randomSample = computeActual(""SELECT orderkey FROM orders TABLESAMPLE SYSTEM (50)"");
        MaterializedResult all = computeActual(""SELECT orderkey FROM orders"");

        assertContains(all, fullSample);
        assertEquals(emptySample.getMaterializedRows().size(), 0);
        assertTrue(all.getMaterializedRows().size() >= randomSample.getMaterializedRows().size());
    }
",non-flaky,5
43065,trinodb_trino,BaseConnectorTest.testTableSampleWithFiltering,"    @Test
    public void testTableSampleWithFiltering()
    {
        MaterializedResult emptySample = computeActual(""SELECT DISTINCT orderkey, orderdate FROM orders TABLESAMPLE SYSTEM (99) WHERE orderkey BETWEEN 0 AND 0"");
        MaterializedResult halfSample = computeActual(""SELECT DISTINCT orderkey, orderdate FROM orders TABLESAMPLE SYSTEM (50) WHERE orderkey BETWEEN 0 AND 9999999999"");
        MaterializedResult all = computeActual(""SELECT orderkey, orderdate FROM orders"");

        assertEquals(emptySample.getMaterializedRows().size(), 0);
        // Assertions need to be loose here because SYSTEM sampling random selects data on split boundaries. In this case either all the data will be selected, or
        // none of it. Sampling with a 100% ratio is ignored, so that also cannot be used to guarantee results.
        assertTrue(all.getMaterializedRows().size() >= halfSample.getMaterializedRows().size());
    }
",non-flaky,5
43066,trinodb_trino,BaseConnectorTest.testShowCreateTable,"    @Test
    public void testShowCreateTable()
    {
        assertThat((String) computeActual(""SHOW CREATE TABLE orders"").getOnlyValue())
                // If the connector reports additional column properties, the expected value needs to be adjusted in the test subclass
                .matches(""CREATE TABLE \\w+\\.\\w+\\.orders \\Q(\n"" +
                        ""   orderkey bigint,\n"" +
                        ""   custkey bigint,\n"" +
                        ""   orderstatus varchar(1),\n"" +
                        ""   totalprice double,\n"" +
                        ""   orderdate date,\n"" +
                        ""   orderpriority varchar(15),\n"" +
                        ""   clerk varchar(15),\n"" +
                        ""   shippriority integer,\n"" +
                        ""   comment varchar(79)\n"" +
                        "")"");
    }
",non-flaky,5
43067,trinodb_trino,BaseConnectorTest.testSelectInformationSchemaTables,"    @Test
    public void testSelectInformationSchemaTables()
    {
        String catalog = getSession().getCatalog().get();
        String schema = getSession().getSchema().get();
        String schemaPattern = schema.replaceAll(""^."", ""_"");

        assertQuery(""SELECT table_name FROM information_schema.tables WHERE table_schema = '"" + schema + ""' AND table_name = 'orders'"", ""VALUES 'orders'"");
        assertQuery(""SELECT table_name FROM information_schema.tables WHERE table_schema LIKE '"" + schema + ""' AND table_name LIKE '%rders'"", ""VALUES 'orders'"");
        assertQuery(""SELECT table_name FROM information_schema.tables WHERE table_schema LIKE '"" + schemaPattern + ""' AND table_name LIKE '%rders'"", ""VALUES 'orders'"");
        assertQuery(
                ""SELECT table_name FROM information_schema.tables "" +
                        ""WHERE table_catalog = '"" + catalog + ""' AND table_schema LIKE '"" + schema + ""' AND table_name LIKE '%orders'"",
                ""VALUES 'orders'"");
        assertQuery(""SELECT table_name FROM information_schema.tables WHERE table_catalog = 'something_else'"", ""SELECT '' WHERE false"");

        assertQuery(
                ""SELECT DISTINCT table_name FROM information_schema.tables WHERE table_schema = 'information_schema' OR rand() = 42 ORDER BY 1"",
                ""VALUES "" +
                        ""('applicable_roles'), "" +
                        ""('columns'), "" +
                        ""('enabled_roles'), "" +
                        ""('role_authorization_descriptors'), "" +
                        ""('roles'), "" +
                        ""('schemata'), "" +
                        ""('table_privileges'), "" +
                        ""('tables'), "" +
                        ""('views')"");
    }
",non-flaky,5
43068,trinodb_trino,BaseConnectorTest.testSelectInformationSchemaColumns,"    @Test
    public void testSelectInformationSchemaColumns()
    {
        String catalog = getSession().getCatalog().get();
        String schema = getSession().getSchema().get();
        String schemaPattern = schema.replaceAll("".$"", ""_"");

        @Language(""SQL"") String ordersTableWithColumns = ""VALUES "" +
                ""('orders', 'orderkey'), "" +
                ""('orders', 'custkey'), "" +
                ""('orders', 'orderstatus'), "" +
                ""('orders', 'totalprice'), "" +
                ""('orders', 'orderdate'), "" +
                ""('orders', 'orderpriority'), "" +
                ""('orders', 'clerk'), "" +
                ""('orders', 'shippriority'), "" +
                ""('orders', 'comment')"";

        assertQuery(""SELECT table_schema FROM information_schema.columns WHERE table_schema = '"" + schema + ""' GROUP BY table_schema"", ""VALUES '"" + schema + ""'"");
        assertQuery(""SELECT table_name FROM information_schema.columns WHERE table_name = 'orders' GROUP BY table_name"", ""VALUES 'orders'"");
        assertQuery(""SELECT table_name, column_name FROM information_schema.columns WHERE table_schema = '"" + schema + ""' AND table_name = 'orders'"", ordersTableWithColumns);
        assertQuery(""SELECT table_name, column_name FROM information_schema.columns WHERE table_schema = '"" + schema + ""' AND table_name LIKE '%rders'"", ordersTableWithColumns);
        assertQuery(""SELECT table_name, column_name FROM information_schema.columns WHERE table_schema LIKE '"" + schemaPattern + ""' AND table_name LIKE '_rder_'"", ordersTableWithColumns);
        assertQuery(
                ""SELECT table_name, column_name FROM information_schema.columns "" +
                        ""WHERE table_catalog = '"" + catalog + ""' AND table_schema = '"" + schema + ""' AND table_name LIKE '%orders%'"",
                ordersTableWithColumns);

        assertQuerySucceeds(""SELECT * FROM information_schema.columns"");
        assertQuery(""SELECT DISTINCT table_name, column_name FROM information_schema.columns WHERE table_name LIKE '_rders'"", ordersTableWithColumns);
        assertQuerySucceeds(""SELECT * FROM information_schema.columns WHERE table_catalog = '"" + catalog + ""'"");
        assertQuerySucceeds(""SELECT * FROM information_schema.columns WHERE table_catalog = '"" + catalog + ""' AND table_schema = '"" + schema + ""'"");
        assertQuery(""SELECT table_name, column_name FROM information_schema.columns WHERE table_catalog = '"" + catalog + ""' AND table_schema = '"" + schema + ""' AND table_name LIKE '_rders'"", ordersTableWithColumns);
        assertQuerySucceeds(""SELECT * FROM information_schema.columns WHERE table_catalog = '"" + catalog + ""' AND table_name LIKE '%'"");
        assertQuery(""SELECT column_name FROM information_schema.columns WHERE table_catalog = 'something_else'"", ""SELECT '' WHERE false"");

        assertQuery(
                ""SELECT DISTINCT table_name FROM information_schema.columns WHERE table_schema = 'information_schema' OR rand() = 42 ORDER BY 1"",
                ""VALUES "" +
                        ""('applicable_roles'), "" +
                        ""('columns'), "" +
                        ""('enabled_roles'), "" +
                        ""('role_authorization_descriptors'), "" +
                        ""('roles'), "" +
                        ""('schemata'), "" +
                        ""('table_privileges'), "" +
                        ""('tables'), "" +
                        ""('views')"");
    }
",non-flaky,5
43069,trinodb_trino,BaseConnectorTest.testShowCreateInformationSchema,"    @Test
    public void testShowCreateInformationSchema()
    {
        assertThat(query(""SHOW CREATE SCHEMA information_schema""))
                .skippingTypesCheck()
                .matches(format(""VALUES 'CREATE SCHEMA %s.information_schema'"", getSession().getCatalog().orElseThrow()));
    }
",non-flaky,5
43070,trinodb_trino,BaseConnectorTest.testShowCreateInformationSchemaTable,"    @Test
    public void testShowCreateInformationSchemaTable()
    {
        assertQueryFails(""SHOW CREATE VIEW information_schema.schemata"", ""line 1:1: Relation '\\w+.information_schema.schemata' is a table, not a view"");
        assertQueryFails(""SHOW CREATE MATERIALIZED VIEW information_schema.schemata"", ""line 1:1: Relation '\\w+.information_schema.schemata' is a table, not a materialized view"");

        assertThat((String) computeScalar(""SHOW CREATE TABLE information_schema.schemata""))
                .isEqualTo(""CREATE TABLE "" + getSession().getCatalog().orElseThrow() + "".information_schema.schemata (\n"" +
                        ""   catalog_name varchar,\n"" +
                        ""   schema_name varchar\n"" +
                        "")"");
    }
",non-flaky,5
43071,trinodb_trino,BaseConnectorTest.testRollback,"    @Test
    public void testRollback()
    {
        skipTestUnless(hasBehavior(SUPPORTS_MULTI_STATEMENT_WRITES));

        String table = ""test_rollback_"" + randomTableSuffix();
        computeActual(format(""CREATE TABLE %s (x int)"", table));

        assertThatThrownBy(() ->
                inTransaction(session -> {
                    assertUpdate(session, format(""INSERT INTO %s VALUES (42)"", table), 1);
                    throw new RollbackException();
                }))
                .isInstanceOf(RollbackException.class);

        assertQuery(format(""SELECT count(*) FROM %s"", table), ""SELECT 0"");
    }
",non-flaky,5
43072,trinodb_trino,BaseConnectorTest.testWriteNotAllowedInTransaction,"    @Test
    public void testWriteNotAllowedInTransaction()
    {
        skipTestUnless(!hasBehavior(SUPPORTS_MULTI_STATEMENT_WRITES));

        assertWriteNotAllowedInTransaction(SUPPORTS_CREATE_SCHEMA, ""CREATE SCHEMA write_not_allowed"");
        assertWriteNotAllowedInTransaction(SUPPORTS_CREATE_TABLE, ""CREATE TABLE write_not_allowed (x int)"");
        assertWriteNotAllowedInTransaction(SUPPORTS_CREATE_TABLE, ""DROP TABLE region"");
        assertWriteNotAllowedInTransaction(SUPPORTS_CREATE_TABLE_WITH_DATA, ""CREATE TABLE write_not_allowed AS SELECT * FROM region"");
        assertWriteNotAllowedInTransaction(SUPPORTS_CREATE_VIEW, ""CREATE VIEW write_not_allowed AS SELECT * FROM region"");
        assertWriteNotAllowedInTransaction(SUPPORTS_CREATE_MATERIALIZED_VIEW, ""CREATE MATERIALIZED VIEW write_not_allowed AS SELECT * FROM region"");
        assertWriteNotAllowedInTransaction(SUPPORTS_RENAME_TABLE, ""ALTER TABLE region RENAME TO region_name"");
        assertWriteNotAllowedInTransaction(SUPPORTS_INSERT, ""INSERT INTO region (regionkey) VALUES (123)"");
        assertWriteNotAllowedInTransaction(SUPPORTS_DELETE, ""DELETE FROM region WHERE regionkey = 123"");

        // REFRESH MATERIALIZED VIEW is tested in testMaterializedView
    }
",non-flaky,5
43073,trinodb_trino,BaseConnectorTest.testRenameSchema,"    @Test
    public void testRenameSchema()
    {
        if (!hasBehavior(SUPPORTS_RENAME_SCHEMA)) {
            String schemaName = getSession().getSchema().orElseThrow();
            assertQueryFails(
                    format(""ALTER SCHEMA %s RENAME TO %s"", schemaName, schemaName + randomTableSuffix()),
                    ""This connector does not support renaming schemas"");
            return;
        }

        if (!hasBehavior(SUPPORTS_CREATE_SCHEMA)) {
            throw new SkipException(""Skipping as connector does not support CREATE SCHEMA"");
        }

        String schemaName = ""test_rename_schema_"" + randomTableSuffix();
        try {
            assertUpdate(""CREATE SCHEMA "" + schemaName);
            assertUpdate(""ALTER SCHEMA "" + schemaName + "" RENAME TO "" + schemaName + ""_renamed"");
        }
        finally {
            assertUpdate(""DROP SCHEMA IF EXISTS "" + schemaName);
            assertUpdate(""DROP SCHEMA IF EXISTS "" + schemaName + ""_renamed"");
        }
    }
",non-flaky,5
43074,trinodb_trino,BaseConnectorTest.testRenameTableAcrossSchema,"    @Test
    public void testRenameTableAcrossSchema()
    {
        if (!hasBehavior(SUPPORTS_RENAME_TABLE_ACROSS_SCHEMAS)) {
            if (!hasBehavior(SUPPORTS_RENAME_TABLE)) {
                throw new SkipException(""Skipping since rename table is not supported at all"");
            }
            assertQueryFails(""ALTER TABLE nation RENAME TO other_schema.yyyy"", ""This connector does not support renaming tables across schemas"");
            return;
        }

        if (!hasBehavior(SUPPORTS_CREATE_SCHEMA)) {
            throw new AssertionError(""Cannot test ALTER TABLE RENAME across schemas without CREATE SCHEMA, the test needs to be implemented in a connector-specific way"");
        }

        if (!hasBehavior(SUPPORTS_CREATE_TABLE)) {
            throw new AssertionError(""Cannot test ALTER TABLE RENAME across schemas without CREATE TABLE, the test needs to be implemented in a connector-specific way"");
        }

        String tableName = ""test_rename_old_"" + randomTableSuffix();
        assertUpdate(""CREATE TABLE "" + tableName + "" AS SELECT 123 x"", 1);

        String schemaName = ""test_schema_"" + randomTableSuffix();
        assertUpdate(""CREATE SCHEMA "" + schemaName);

        String renamedTable = schemaName + "".test_rename_new_"" + randomTableSuffix();
        assertUpdate(""ALTER TABLE "" + tableName + "" RENAME TO "" + renamedTable);

        assertFalse(getQueryRunner().tableExists(getSession(), tableName));
        assertQuery(""SELECT x FROM "" + renamedTable, ""VALUES 123"");

        assertUpdate(""DROP TABLE "" + renamedTable);
        assertUpdate(""DROP SCHEMA "" + schemaName);

        assertFalse(getQueryRunner().tableExists(getSession(), tableName));
        assertFalse(getQueryRunner().tableExists(getSession(), renamedTable));
    }
",non-flaky,5
43075,trinodb_trino,BaseConnectorTest.testInsertIntoNotNullColumn,"    @Test
    public void testInsertIntoNotNullColumn()
    {
        skipTestUnless(hasBehavior(SUPPORTS_CREATE_TABLE));

        if (!hasBehavior(SUPPORTS_NOT_NULL_CONSTRAINT)) {
            assertQueryFails(
                    ""CREATE TABLE not_null_constraint (not_null_col INTEGER NOT NULL)"",
                    format(""line 1:35: Catalog '%s' does not support non-null column for column name 'not_null_col'"", getSession().getCatalog().orElseThrow()));
            return;
        }

        try (TestTable table = new TestTable(getQueryRunner()::execute, ""insert_not_null"", ""(nullable_col INTEGER, not_null_col INTEGER NOT NULL)"")) {
            assertUpdate(format(""INSERT INTO %s (not_null_col) VALUES (2)"", table.getName()), 1);
            assertQuery(""SELECT * FROM "" + table.getName(), ""VALUES (NULL, 2)"");
            // The error message comes from remote databases when ConnectorMetadata.supportsMissingColumnsOnInsert is true
            assertQueryFails(format(""INSERT INTO %s (nullable_col) VALUES (1)"", table.getName()), errorMessageForInsertIntoNotNullColumn(""not_null_col""));
        }

        try (TestTable table = new TestTable(getQueryRunner()::execute, ""commuted_not_null"", ""(nullable_col BIGINT, not_null_col BIGINT NOT NULL)"")) {
            assertUpdate(format(""INSERT INTO %s (not_null_col) VALUES (2)"", table.getName()), 1);
            assertQuery(""SELECT * FROM "" + table.getName(), ""VALUES (NULL, 2)"");
            // This is enforced by the engine and not the connector
            assertQueryFails(format(""INSERT INTO %s (not_null_col, nullable_col) VALUES (NULL, 3)"", table.getName()), ""NULL value not allowed for NOT NULL column: not_null_col"");
        }
    }
",non-flaky,5
43076,trinodb_trino,BaseConnectorTest.verifySupportsDeleteDeclaration,"    @Test
    public void verifySupportsDeleteDeclaration()
    {
        if (hasBehavior(SUPPORTS_DELETE)) {
            // Covered by testDeleteAllDataFromTable
            return;
        }

        skipTestUnless(hasBehavior(SUPPORTS_CREATE_TABLE));
        try (TestTable table = new TestTable(getQueryRunner()::execute, ""test_supports_delete"", ""AS SELECT * FROM region"")) {
            assertQueryFails(""DELETE FROM "" + table.getName(), ""This connector does not support deletes"");
        }
    }
",non-flaky,5
43077,trinodb_trino,BaseConnectorTest.verifySupportsRowLevelDeleteDeclaration,"    @Test
    public void verifySupportsRowLevelDeleteDeclaration()
    {
        if (hasBehavior(SUPPORTS_ROW_LEVEL_DELETE)) {
            // Covered by testRowLevelDelete
            return;
        }

        skipTestUnless(hasBehavior(SUPPORTS_CREATE_TABLE));
        try (TestTable table = new TestTable(getQueryRunner()::execute, ""test_supports_row_level_delete"", ""AS SELECT * FROM region"")) {
            assertQueryFails(""DELETE FROM "" + table.getName() + "" WHERE regionkey = 2"", ""This connector does not support deletes"");
        }
    }
",non-flaky,5
43078,trinodb_trino,BaseConnectorTest.testDeleteAllDataFromTable,"    @Test
    public void testDeleteAllDataFromTable()
    {
        skipTestUnless(hasBehavior(SUPPORTS_CREATE_TABLE) && hasBehavior(SUPPORTS_DELETE));
        try (TestTable table = new TestTable(getQueryRunner()::execute, ""test_delete_all_data"", ""AS SELECT * FROM region"")) {
            // not using assertUpdate as some connectors provide update count and some not
            getQueryRunner().execute(""DELETE FROM "" + table.getName());
            assertQuery(""SELECT count(*) FROM "" + table.getName(), ""VALUES 0"");
        }
    }
",non-flaky,5
43079,trinodb_trino,BaseConnectorTest.testRowLevelDelete,"    @Test
    public void testRowLevelDelete()
    {
        skipTestUnless(hasBehavior(SUPPORTS_CREATE_TABLE) && hasBehavior(SUPPORTS_ROW_LEVEL_DELETE));
        // TODO (https://github.com/trinodb/trino/issues/5901) Use longer table name once Oracle version is updated
        try (TestTable table = new TestTable(getQueryRunner()::execute, ""test_row_delete"", ""AS SELECT * FROM region"")) {
            assertUpdate(""DELETE FROM "" + table.getName() + "" WHERE regionkey = 2"", 1);
            assertQuery(""SELECT count(*) FROM "" + table.getName(), ""VALUES 4"");
        }
    }
",non-flaky,5
43080,trinodb_trino,BaseConnectorTest.testUpdate,"    @Test
    public void testUpdate()
    {
        if (!hasBehavior(SUPPORTS_UPDATE)) {
            // Note this change is a no-op, if actually run
            assertQueryFails(""UPDATE nation SET nationkey = nationkey + regionkey WHERE regionkey < 1"", ""This connector does not support updates"");
            return;
        }

        try (TestTable table = new TestTable(getQueryRunner()::execute, ""test_update"", ""AS TABLE tpch.tiny.nation"")) {
            String tableName = table.getName();
            assertUpdate(""UPDATE "" + tableName + "" SET nationkey = 100 + nationkey WHERE regionkey = 2"", 5);
            assertThat(query(""SELECT * FROM "" + tableName))
                    .skippingTypesCheck()
                    .matches(""SELECT IF(regionkey=2, nationkey + 100, nationkey) nationkey, name, regionkey, comment FROM tpch.tiny.nation"");

            // UPDATE after UPDATE
            assertUpdate(""UPDATE "" + tableName + "" SET nationkey = nationkey * 2 WHERE regionkey IN (2,3)"", 10);
            assertThat(query(""SELECT * FROM "" + tableName))
                    .skippingTypesCheck()
                    .matches(""SELECT CASE regionkey WHEN 2 THEN 2*(nationkey+100) WHEN 3 THEN 2*nationkey ELSE nationkey END nationkey, name, regionkey, comment FROM tpch.tiny.nation"");
        }
    }
",non-flaky,5
43081,trinodb_trino,BaseConnectorTest.testUpdateRowConcurrently,"    @Test(timeOut = 60_000, invocationCount = 4)
    public void testUpdateRowConcurrently()
            throws Exception
",non-flaky,5
43082,trinodb_trino,BaseConnectorTest.testTruncateTable,"    @Test
    public void testTruncateTable()
    {
        if (!hasBehavior(SUPPORTS_TRUNCATE)) {
            assertQueryFails(""TRUNCATE TABLE nation"", ""This connector does not support truncating tables"");
            return;
        }

        skipTestUnless(hasBehavior(SUPPORTS_CREATE_TABLE));

        try (TestTable table = new TestTable(getQueryRunner()::execute, ""test_truncate"", ""AS SELECT * FROM region"")) {
            assertUpdate(""TRUNCATE TABLE "" + table.getName());
            assertQuery(""SELECT count(*) FROM "" + table.getName(), ""VALUES 0"");
        }
    }
",non-flaky,5
43083,trinodb_trino,BaseConnectorTest.testMaterializedViewColumnName,"    @Test(dataProvider = ""testColumnNameDataProvider"")
    public void testMaterializedViewColumnName(String columnName)
    {
        skipTestUnless(hasBehavior(SUPPORTS_CREATE_MATERIALIZED_VIEW));

        if (!requiresDelimiting(columnName)) {
            testMaterializedViewColumnName(columnName, false);
        }
        testMaterializedViewColumnName(columnName, true);
    }
",non-flaky,5
43084,trinodb_trino,AbstractTestIntegrationSmokeTest.ensureDistributedQueryRunner,"    @Test
    public void ensureDistributedQueryRunner()
    {
        assertThat(getQueryRunner().getNodeCount()).as(""query runner node count"")
                .isGreaterThanOrEqualTo(3);
    }
",non-flaky,5
43085,trinodb_trino,AbstractTestIntegrationSmokeTest.testColumnsInReverseOrder,"    @Test
    public void testColumnsInReverseOrder()
    {
        assertQuery(""SELECT shippriority, clerk, totalprice FROM orders"");
    }
",non-flaky,5
43086,trinodb_trino,AbstractTestIntegrationSmokeTest.testAggregation,"    @Test
    public void testAggregation()
    {
        assertQuery(""SELECT sum(orderkey) FROM orders"");
        assertQuery(""SELECT sum(totalprice) FROM orders"");
        assertQuery(""SELECT max(comment) FROM nation"");

        assertQuery(""SELECT count(*) FROM orders"");
        assertQuery(""SELECT count(*) FROM orders WHERE orderkey > 10"");
        assertQuery(""SELECT count(*) FROM (SELECT * FROM orders LIMIT 10)"");
        assertQuery(""SELECT count(*) FROM (SELECT * FROM orders WHERE orderkey > 10 LIMIT 10)"");

        assertQuery(""SELECT DISTINCT regionkey FROM nation"");
        assertQuery(""SELECT regionkey FROM nation GROUP BY regionkey"");

        // TODO support aggregation pushdown with GROUPING SETS
        assertQuery(
                ""SELECT regionkey, nationkey FROM nation GROUP BY GROUPING SETS ((regionkey), (nationkey))"",
                ""SELECT NULL, nationkey FROM nation "" +
                        ""UNION ALL SELECT DISTINCT regionkey, NULL FROM nation"");
        assertQuery(
                ""SELECT regionkey, nationkey, count(*) FROM nation GROUP BY GROUPING SETS ((), (regionkey), (nationkey), (regionkey, nationkey))"",
                ""SELECT NULL, NULL, count(*) FROM nation "" +
                        ""UNION ALL SELECT NULL, nationkey, 1 FROM nation "" +
                        ""UNION ALL SELECT regionkey, NULL, count(*) FROM nation GROUP BY regionkey "" +
                        ""UNION ALL SELECT regionkey, nationkey, 1 FROM nation"");

        assertQuery(""SELECT count(regionkey) FROM nation"");
        assertQuery(""SELECT count(DISTINCT regionkey) FROM nation"");
        assertQuery(""SELECT regionkey, count(*) FROM nation GROUP BY regionkey"");

        assertQuery(""SELECT min(regionkey), max(regionkey) FROM nation"");
        assertQuery(""SELECT min(DISTINCT regionkey), max(DISTINCT regionkey) FROM nation"");
        assertQuery(""SELECT regionkey, min(regionkey), min(name), max(regionkey), max(name) FROM nation GROUP BY regionkey"");

        assertQuery(""SELECT sum(regionkey) FROM nation"");
        assertQuery(""SELECT sum(DISTINCT regionkey) FROM nation"");
        assertQuery(""SELECT regionkey, sum(regionkey) FROM nation GROUP BY regionkey"");

        assertQuery(
                ""SELECT avg(nationkey) FROM nation"",
                ""SELECT avg(CAST(nationkey AS double)) FROM nation"");
        assertQuery(
                ""SELECT avg(DISTINCT nationkey) FROM nation"",
                ""SELECT avg(DISTINCT CAST(nationkey AS double)) FROM nation"");
        assertQuery(
                ""SELECT regionkey, avg(nationkey) FROM nation GROUP BY regionkey"",
                ""SELECT regionkey, avg(CAST(nationkey AS double)) FROM nation GROUP BY regionkey"");
    }
",non-flaky,5
43087,trinodb_trino,AbstractTestIntegrationSmokeTest.testExactPredicate,"    @Test
    public void testExactPredicate()
    {
        assertQueryReturnsEmptyResult(""SELECT * FROM orders WHERE orderkey = 10"");

        // filtered column is selected
        assertQuery(""SELECT custkey, orderkey FROM orders WHERE orderkey = 32"", ""VALUES (1301, 32)"");

        // filtered column is not selected
        assertQuery(""SELECT custkey FROM orders WHERE orderkey = 32"", ""VALUES (1301)"");
    }
",non-flaky,5
43088,trinodb_trino,AbstractTestIntegrationSmokeTest.testInListPredicate,"    @Test
    public void testInListPredicate()
    {
        assertQueryReturnsEmptyResult(""SELECT * FROM orders WHERE orderkey IN (10, 11, 20, 21)"");

        // filtered column is selected
        assertQuery(""SELECT custkey, orderkey FROM orders WHERE orderkey IN (7, 10, 32, 33)"", ""VALUES (392, 7), (1301, 32), (670, 33)"");

        // filtered column is not selected
        assertQuery(""SELECT custkey FROM orders WHERE orderkey IN (7, 10, 32, 33)"", ""VALUES (392), (1301), (670)"");
    }
",non-flaky,5
43089,trinodb_trino,AbstractTestIntegrationSmokeTest.testIsNullPredicate,"    @Test
    public void testIsNullPredicate()
    {
        assertQueryReturnsEmptyResult(""SELECT * FROM orders WHERE orderkey IS NULL"");
        assertQueryReturnsEmptyResult(""SELECT * FROM orders WHERE orderkey = 10 OR orderkey IS NULL"");

        // filtered column is selected
        assertQuery(""SELECT custkey, orderkey FROM orders WHERE orderkey = 32 OR orderkey IS NULL"", ""VALUES (1301, 32)"");

        // filtered column is not selected
        assertQuery(""SELECT custkey FROM orders WHERE orderkey = 32 OR orderkey IS NULL"", ""VALUES (1301)"");
    }
",non-flaky,5
43090,trinodb_trino,AbstractTestIntegrationSmokeTest.testLikePredicate,"    @Test
    public void testLikePredicate()
    {
        // filtered column is not selected
        assertQuery(""SELECT orderkey FROM orders WHERE orderpriority LIKE '5-L%'"");

        // filtered column is selected
        assertQuery(""SELECT orderkey, orderpriority FROM orders WHERE orderpriority LIKE '5-L%'"");

        // filtered column is not selected
        assertQuery(""SELECT orderkey FROM orders WHERE orderpriority LIKE '5-L__'"");

        // filtered column is selected
        assertQuery(""SELECT orderkey, orderpriority FROM orders WHERE orderpriority LIKE '5-L__'"");
    }
",non-flaky,5
43091,trinodb_trino,AbstractTestIntegrationSmokeTest.testLimit,"    @Test
    public void testLimit()
    {
        assertEquals(computeActual(""SELECT * FROM orders LIMIT 10"").getRowCount(), 10);
    }
",non-flaky,5
43092,trinodb_trino,AbstractTestIntegrationSmokeTest.testMultipleRangesPredicate,"    @Test
    public void testMultipleRangesPredicate()
    {
        // List columns explicitly. Some connectors do not maintain column ordering.
        assertQuery("""" +
                ""SELECT orderkey, custkey, orderstatus, totalprice, orderdate, orderpriority, clerk, shippriority, comment "" +
                ""FROM orders "" +
                ""WHERE orderkey BETWEEN 10 AND 50"");
    }
",non-flaky,5
43093,trinodb_trino,AbstractTestIntegrationSmokeTest.testRangePredicate,"    @Test
    public void testRangePredicate()
    {
        // List columns explicitly. Some connectors do not maintain column ordering.
        assertQuery("""" +
                ""SELECT orderkey, custkey, orderstatus, totalprice, orderdate, orderpriority, clerk, shippriority, comment "" +
                ""FROM orders "" +
                ""WHERE orderkey BETWEEN 10 AND 50"");
    }
",non-flaky,5
43094,trinodb_trino,AbstractTestIntegrationSmokeTest.testConcurrentScans,"    @Test
    public void testConcurrentScans()
    {
        String unionMultipleTimes = join("" UNION ALL "", nCopies(25, ""SELECT * FROM orders""));
        assertQuery(""SELECT sum(if(rand() >= 0, orderkey)) FROM ("" + unionMultipleTimes + "")"", ""VALUES 11246812500"");
    }
",non-flaky,5
43095,trinodb_trino,AbstractTestIntegrationSmokeTest.testSelectAll,"    @Test
    public void testSelectAll()
    {
        assertQuery(""SELECT * FROM orders"");
    }
",non-flaky,5
43096,trinodb_trino,AbstractTestIntegrationSmokeTest.testJoinWithEmptySides,"    @Test(timeOut = 300_000, dataProvider = ""joinDistributionTypes"")
    public void testJoinWithEmptySides(JoinDistributionType joinDistributionType)
    {
        Session session = noJoinReordering(joinDistributionType);
        // empty build side
        assertQuery(session, ""SELECT count(*) FROM nation JOIN region ON nation.regionkey = region.regionkey AND region.name = ''"", ""VALUES 0"");
        assertQuery(session, ""SELECT count(*) FROM nation JOIN region ON nation.regionkey = region.regionkey AND region.regionkey < 0"", ""VALUES 0"");
        // empty probe side
        assertQuery(session, ""SELECT count(*) FROM region JOIN nation ON nation.regionkey = region.regionkey AND region.name = ''"", ""VALUES 0"");
        assertQuery(session, ""SELECT count(*) FROM nation JOIN region ON nation.regionkey = region.regionkey AND region.regionkey < 0"", ""VALUES 0"");
    }
",non-flaky,5
43097,trinodb_trino,AbstractTestIntegrationSmokeTest.testJoin,"    @Test
    public void testJoin()
    {
        Session session = Session.builder(getSession())
                .setSystemProperty(IGNORE_STATS_CALCULATOR_FAILURES, ""false"")
                .build();

        // 2 inner joins, eligible for join reodering
        assertQuery(
                session,
                ""SELECT c.name, n.name, r.name "" +
                        ""FROM nation n "" +
                        ""JOIN customer c ON c.nationkey = n.nationkey "" +
                        ""JOIN region r ON n.regionkey = r.regionkey"");

        // 2 inner joins, eligible for join reodering, where one table has a filter
        assertQuery(
                session,
                ""SELECT c.name, n.name, r.name "" +
                        ""FROM nation n "" +
                        ""JOIN customer c ON c.nationkey = n.nationkey "" +
                        ""JOIN region r ON n.regionkey = r.regionkey "" +
                        ""WHERE n.name = 'ARGENTINA'"");

        // 2 inner joins, eligible for join reodering, on top of aggregation
        assertQuery(
                session,
                ""SELECT c.name, n.name, n.count, r.name "" +
                        ""FROM (SELECT name, regionkey, nationkey, count(*) count FROM nation GROUP BY name, regionkey, nationkey) n "" +
                        ""JOIN customer c ON c.nationkey = n.nationkey "" +
                        ""JOIN region r ON n.regionkey = r.regionkey"");
    }
",non-flaky,5
43098,trinodb_trino,AbstractTestIntegrationSmokeTest.testShowSchemas,"    @Test
    public void testShowSchemas()
    {
        MaterializedResult actualSchemas = computeActual(""SHOW SCHEMAS"").toTestTypes();

        MaterializedResult.Builder resultBuilder = MaterializedResult.resultBuilder(getSession(), VARCHAR)
                .row(getSession().getSchema().orElse(""tpch""));

        assertContains(actualSchemas, resultBuilder.build());
    }
",non-flaky,5
43099,trinodb_trino,AbstractTestIntegrationSmokeTest.testShowTables,"    @Test
    public void testShowTables()
    {
        MaterializedResult actualTables = computeActual(""SHOW TABLES"").toTestTypes();
        MaterializedResult expectedTables = MaterializedResult.resultBuilder(getSession(), VARCHAR)
                .row(""orders"")
                .build();
        assertContains(actualTables, expectedTables);
    }
",non-flaky,5
43100,trinodb_trino,AbstractTestIntegrationSmokeTest.testDescribeTable,"    @Test
    public void testDescribeTable()
    {
        MaterializedResult expectedColumns = MaterializedResult.resultBuilder(getSession(), VARCHAR, VARCHAR, VARCHAR, VARCHAR)
                .row(""orderkey"", ""bigint"", """", """")
                .row(""custkey"", ""bigint"", """", """")
                .row(""orderstatus"", ""varchar(1)"", """", """")
                .row(""totalprice"", ""double"", """", """")
                .row(""orderdate"", ""date"", """", """")
                .row(""orderpriority"", ""varchar(15)"", """", """")
                .row(""clerk"", ""varchar(15)"", """", """")
                .row(""shippriority"", ""integer"", """", """")
                .row(""comment"", ""varchar(79)"", """", """")
                .build();
        MaterializedResult actualColumns = computeActual(""DESCRIBE orders"");
        assertEquals(actualColumns, expectedColumns);
    }
",non-flaky,5
43101,trinodb_trino,AbstractTestIntegrationSmokeTest.testExplainAnalyze,"    @Test
    public void testExplainAnalyze()
    {
        assertExplainAnalyze(""EXPLAIN ANALYZE SELECT * FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SELECT count(*), clerk FROM orders GROUP BY clerk"");
        assertExplainAnalyze(
                ""EXPLAIN ANALYZE SELECT x + y FROM ("" +
                        ""   SELECT orderdate, COUNT(*) x FROM orders GROUP BY orderdate) a JOIN ("" +
                        ""   SELECT orderdate, COUNT(*) y FROM orders GROUP BY orderdate) b ON a.orderdate = b.orderdate"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SELECT count(*), clerk FROM orders GROUP BY clerk UNION ALL SELECT sum(orderkey), clerk FROM orders GROUP BY clerk"");

        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW COLUMNS FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE EXPLAIN SELECT count(*) FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE EXPLAIN ANALYZE SELECT count(*) FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW FUNCTIONS"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW TABLES"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW SCHEMAS"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW CATALOGS"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW SESSION"");
    }
",non-flaky,5
43102,trinodb_trino,AbstractTestIntegrationSmokeTest.testExplainAnalyzeVerbose,"    @Test
    public void testExplainAnalyzeVerbose()
    {
        assertExplainAnalyze(""EXPLAIN ANALYZE VERBOSE SELECT * FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE VERBOSE SELECT rank() OVER (PARTITION BY orderkey ORDER BY clerk DESC) FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE VERBOSE SELECT rank() OVER (PARTITION BY orderkey ORDER BY clerk DESC) FROM orders WHERE orderkey < 0"");
    }
",non-flaky,5
43103,trinodb_trino,AbstractTestIntegrationSmokeTest.testTableSampleSystem,"    @Test
    public void testTableSampleSystem()
    {
        MaterializedResult fullSample = computeActual(""SELECT orderkey FROM orders TABLESAMPLE SYSTEM (100)"");
        MaterializedResult emptySample = computeActual(""SELECT orderkey FROM orders TABLESAMPLE SYSTEM (0)"");
        MaterializedResult randomSample = computeActual(""SELECT orderkey FROM orders TABLESAMPLE SYSTEM (50)"");
        MaterializedResult all = computeActual(""SELECT orderkey FROM orders"");

        assertContains(all, fullSample);
        assertEquals(emptySample.getMaterializedRows().size(), 0);
        assertTrue(all.getMaterializedRows().size() >= randomSample.getMaterializedRows().size());
    }
",non-flaky,5
43104,trinodb_trino,AbstractTestIntegrationSmokeTest.testTableSampleWithFiltering,"    @Test
    public void testTableSampleWithFiltering()
    {
        MaterializedResult emptySample = computeActual(""SELECT DISTINCT orderkey, orderdate FROM orders TABLESAMPLE SYSTEM (99) WHERE orderkey BETWEEN 0 AND 0"");
        MaterializedResult halfSample = computeActual(""SELECT DISTINCT orderkey, orderdate FROM orders TABLESAMPLE SYSTEM (50) WHERE orderkey BETWEEN 0 AND 9999999999"");
        MaterializedResult all = computeActual(""SELECT orderkey, orderdate FROM orders"");

        assertEquals(emptySample.getMaterializedRows().size(), 0);
        // Assertions need to be loose here because SYSTEM sampling random selects data on split boundaries. In this case either all the data will be selected, or
        // none of it. Sampling with a 100% ratio is ignored, so that also cannot be used to guarantee results.
        assertTrue(all.getMaterializedRows().size() >= halfSample.getMaterializedRows().size());
    }
",non-flaky,5
43105,trinodb_trino,AbstractTestIntegrationSmokeTest.testShowCreateTable,"    @Test
    public void testShowCreateTable()
    {
        assertThat((String) computeScalar(""SHOW CREATE TABLE orders""))
                // If the connector reports additional column properties, the expected value needs to be adjusted in the test subclass
                .matches(""CREATE TABLE \\w+\\.\\w+\\.orders \\Q(\n"" +
                        ""   orderkey bigint,\n"" +
                        ""   custkey bigint,\n"" +
                        ""   orderstatus varchar(1),\n"" +
                        ""   totalprice double,\n"" +
                        ""   orderdate date,\n"" +
                        ""   orderpriority varchar(15),\n"" +
                        ""   clerk varchar(15),\n"" +
                        ""   shippriority integer,\n"" +
                        ""   comment varchar(79)\n"" +
                        "")"");
    }
",non-flaky,5
43106,trinodb_trino,AbstractTestIntegrationSmokeTest.testSelectInformationSchemaTables,"    @Test
    public void testSelectInformationSchemaTables()
    {
        String catalog = getSession().getCatalog().get();
        String schema = getSession().getSchema().get();
        String schemaPattern = schema.replaceAll(""^."", ""_"");

        assertQuery(""SELECT table_name FROM information_schema.tables WHERE table_schema = '"" + schema + ""' AND table_name = 'orders'"", ""VALUES 'orders'"");
        assertQuery(""SELECT table_name FROM information_schema.tables WHERE table_schema LIKE '"" + schema + ""' AND table_name LIKE '%rders'"", ""VALUES 'orders'"");
        assertQuery(""SELECT table_name FROM information_schema.tables WHERE table_schema LIKE '"" + schemaPattern + ""' AND table_name LIKE '%rders'"", ""VALUES 'orders'"");
        assertQuery(
                ""SELECT table_name FROM information_schema.tables "" +
                        ""WHERE table_catalog = '"" + catalog + ""' AND table_schema LIKE '"" + schema + ""' AND table_name LIKE '%orders'"",
                ""VALUES 'orders'"");
        assertQuery(""SELECT table_name FROM information_schema.tables WHERE table_catalog = 'something_else'"", ""SELECT '' WHERE false"");

        assertQuery(
                ""SELECT DISTINCT table_name FROM information_schema.tables WHERE table_schema = 'information_schema' OR rand() = 42 ORDER BY 1"",
                ""VALUES "" +
                        ""('applicable_roles'), "" +
                        ""('columns'), "" +
                        ""('enabled_roles'), "" +
                        ""('role_authorization_descriptors'), "" +
                        ""('roles'), "" +
                        ""('schemata'), "" +
                        ""('table_privileges'), "" +
                        ""('tables'), "" +
                        ""('views')"");
    }
",non-flaky,5
43107,trinodb_trino,AbstractTestIntegrationSmokeTest.testSelectInformationSchemaColumns,"    @Test
    public void testSelectInformationSchemaColumns()
    {
        String catalog = getSession().getCatalog().get();
        String schema = getSession().getSchema().get();
        String schemaPattern = schema.replaceAll("".$"", ""_"");

        @Language(""SQL"") String ordersTableWithColumns = ""VALUES "" +
                ""('orders', 'orderkey'), "" +
                ""('orders', 'custkey'), "" +
                ""('orders', 'orderstatus'), "" +
                ""('orders', 'totalprice'), "" +
                ""('orders', 'orderdate'), "" +
                ""('orders', 'orderpriority'), "" +
                ""('orders', 'clerk'), "" +
                ""('orders', 'shippriority'), "" +
                ""('orders', 'comment')"";

        assertQuery(""SELECT table_schema FROM information_schema.columns WHERE table_schema = '"" + schema + ""' GROUP BY table_schema"", ""VALUES '"" + schema + ""'"");
        assertQuery(""SELECT table_name FROM information_schema.columns WHERE table_name = 'orders' GROUP BY table_name"", ""VALUES 'orders'"");
        assertQuery(""SELECT table_name, column_name FROM information_schema.columns WHERE table_schema = '"" + schema + ""' AND table_name = 'orders'"", ordersTableWithColumns);
        assertQuery(""SELECT table_name, column_name FROM information_schema.columns WHERE table_schema = '"" + schema + ""' AND table_name LIKE '%rders'"", ordersTableWithColumns);
        assertQuery(""SELECT table_name, column_name FROM information_schema.columns WHERE table_schema LIKE '"" + schemaPattern + ""' AND table_name LIKE '_rder_'"", ordersTableWithColumns);
        assertQuery(
                ""SELECT table_name, column_name FROM information_schema.columns "" +
                        ""WHERE table_catalog = '"" + catalog + ""' AND table_schema = '"" + schema + ""' AND table_name LIKE '%orders%'"",
                ordersTableWithColumns);

        assertQuerySucceeds(""SELECT * FROM information_schema.columns"");
        assertQuery(""SELECT DISTINCT table_name, column_name FROM information_schema.columns WHERE table_name LIKE '_rders'"", ordersTableWithColumns);
        assertQuerySucceeds(""SELECT * FROM information_schema.columns WHERE table_catalog = '"" + catalog + ""'"");
        assertQuerySucceeds(""SELECT * FROM information_schema.columns WHERE table_catalog = '"" + catalog + ""' AND table_schema = '"" + schema + ""'"");
        assertQuery(""SELECT table_name, column_name FROM information_schema.columns WHERE table_catalog = '"" + catalog + ""' AND table_schema = '"" + schema + ""' AND table_name LIKE '_rders'"", ordersTableWithColumns);
        assertQuerySucceeds(""SELECT * FROM information_schema.columns WHERE table_catalog = '"" + catalog + ""' AND table_name LIKE '%'"");
        assertQuery(""SELECT column_name FROM information_schema.columns WHERE table_catalog = 'something_else'"", ""SELECT '' WHERE false"");

        assertQuery(
                ""SELECT DISTINCT table_name FROM information_schema.columns WHERE table_schema = 'information_schema' OR rand() = 42 ORDER BY 1"",
                ""VALUES "" +
                        ""('applicable_roles'), "" +
                        ""('columns'), "" +
                        ""('enabled_roles'), "" +
                        ""('role_authorization_descriptors'), "" +
                        ""('roles'), "" +
                        ""('schemata'), "" +
                        ""('table_privileges'), "" +
                        ""('tables'), "" +
                        ""('views')"");
    }
",non-flaky,5
43108,trinodb_trino,BaseConnectorSmokeTest.ensureDistributedQueryRunner,"    @Test
    public void ensureDistributedQueryRunner()
    {
        assertThat(getQueryRunner().getNodeCount()).as(""query runner node count"")
                .isGreaterThanOrEqualTo(3);
    }
",non-flaky,5
43109,trinodb_trino,BaseConnectorSmokeTest.ensureTestNamingConvention,"    @Test
    public void ensureTestNamingConvention()
    {
        // Enforce a naming convention to make code navigation easier.
        assertThat(getClass().getName())
                .endsWith(""ConnectorSmokeTest"");
    }
",non-flaky,5
43110,trinodb_trino,BaseConnectorSmokeTest.testSelect,"    @Test
    public void testSelect()
    {
        assertQuery(""SELECT name FROM region"");
    }
",non-flaky,5
43111,trinodb_trino,BaseConnectorSmokeTest.testPredicate,"    @Test
    public void testPredicate()
    {
        assertQuery(""SELECT name, regionkey FROM nation WHERE nationkey = 10"");
        assertQuery(""SELECT name, regionkey FROM nation WHERE nationkey BETWEEN 5 AND 15"");
        assertQuery(""SELECT name, regionkey FROM nation WHERE name = 'EGYPT'"");
    }
",non-flaky,5
43112,trinodb_trino,BaseConnectorSmokeTest.testLimit,"    @Test
    public void testLimit()
    {
        assertQuery(""SELECT name FROM region LIMIT 5"");
    }
",non-flaky,5
43113,trinodb_trino,BaseConnectorSmokeTest.testTopN,"    @Test
    public void testTopN()
    {
        assertQuery(""SELECT regionkey FROM nation ORDER BY name LIMIT 3"");
    }
",non-flaky,5
43114,trinodb_trino,BaseConnectorSmokeTest.testAggregation,"    @Test
    public void testAggregation()
    {
        assertQuery(""SELECT sum(regionkey) FROM nation"");
        assertQuery(""SELECT sum(nationkey) FROM nation GROUP BY regionkey"");
    }
",non-flaky,5
43115,trinodb_trino,BaseConnectorSmokeTest.testHaving,"    @Test
    public void testHaving()
    {
        assertQuery(""SELECT regionkey, sum(nationkey) FROM nation GROUP BY regionkey HAVING sum(nationkey) = 58"", ""VALUES (4, 58)"");
    }
",non-flaky,5
43116,trinodb_trino,BaseConnectorSmokeTest.testJoin,"    @Test
    public void testJoin()
    {
        assertQuery(""SELECT n.name, r.name FROM nation n JOIN region r on n.regionkey = r.regionkey"");
    }
",non-flaky,5
43117,trinodb_trino,BaseConnectorSmokeTest.testCreateTable,"    @Test
    public void testCreateTable()
    {
        if (!hasBehavior(SUPPORTS_CREATE_TABLE)) {
            assertQueryFails(""CREATE TABLE xxxx (a bigint, b double)"", ""This connector does not support creating tables"");
            return;
        }

        String tableName = ""test_create_"" + randomTableSuffix();
        assertUpdate(""CREATE TABLE "" + tableName + "" (a bigint, b double)"");
        assertThat(query(""SELECT a, b FROM "" + tableName))
                .returnsEmptyResult();
        assertUpdate(""DROP TABLE "" + tableName);
    }
",non-flaky,5
43118,trinodb_trino,BaseConnectorSmokeTest.testCreateTableAsSelect,"    @Test
    public void testCreateTableAsSelect()
    {
        if (!hasBehavior(SUPPORTS_CREATE_TABLE_WITH_DATA)) {
            assertQueryFails(""CREATE TABLE xxxx AS SELECT BIGINT '42' a, DOUBLE '-38.5' b"", ""This connector does not support creating tables with data"");
            return;
        }

        String tableName = ""test_create_"" + randomTableSuffix();
        assertUpdate(""CREATE TABLE "" + tableName + "" AS SELECT BIGINT '42' a, DOUBLE '-38.5' b"", 1);
        assertThat(query(""SELECT CAST(a AS bigint), b FROM "" + tableName))
                .matches(""VALUES (BIGINT '42', -385e-1)"");
        assertUpdate(""DROP TABLE "" + tableName);
    }
",non-flaky,5
43119,trinodb_trino,BaseConnectorSmokeTest.testInsert,"    @Test
    public void testInsert()
    {
        if (!hasBehavior(SUPPORTS_INSERT)) {
            assertQueryFails(""INSERT INTO region (regionkey) VALUES (42)"", ""This connector does not support inserts"");
            return;
        }

        if (!hasBehavior(SUPPORTS_CREATE_TABLE)) {
            throw new AssertionError(""Cannot test INSERT without CREATE TABLE, the test needs to be implemented in a connector-specific way"");
        }

        try (TestTable table = new TestTable(getQueryRunner()::execute, ""test_insert_"", ""(a bigint, b double)"")) {
            assertUpdate(""INSERT INTO "" + table.getName() + "" (a, b) VALUES (42, -38.5)"", 1);
            assertThat(query(""SELECT CAST(a AS bigint), b FROM "" + table.getName()))
                    .matches(""VALUES (BIGINT '42', -385e-1)"");
        }
    }
",non-flaky,5
43120,trinodb_trino,BaseConnectorSmokeTest.verifySupportsDeleteDeclaration,"    @Test
    public void verifySupportsDeleteDeclaration()
    {
        if (hasBehavior(SUPPORTS_DELETE)) {
            // Covered by testDeleteAllDataFromTable
            return;
        }

        skipTestUnless(hasBehavior(SUPPORTS_CREATE_TABLE));
        try (TestTable table = new TestTable(getQueryRunner()::execute, ""test_supports_delete"", ""AS SELECT * FROM region"")) {
            assertQueryFails(""DELETE FROM "" + table.getName(), ""This connector does not support deletes"");
        }
    }
",non-flaky,5
43121,trinodb_trino,BaseConnectorSmokeTest.verifySupportsRowLevelDeleteDeclaration,"    @Test
    public void verifySupportsRowLevelDeleteDeclaration()
    {
        if (hasBehavior(SUPPORTS_ROW_LEVEL_DELETE)) {
            // Covered by testRowLevelDelete
            return;
        }

        skipTestUnless(hasBehavior(SUPPORTS_CREATE_TABLE));
        try (TestTable table = new TestTable(getQueryRunner()::execute, ""test_supports_row_level_delete"", ""AS SELECT * FROM region"")) {
            assertQueryFails(""DELETE FROM "" + table.getName() + "" WHERE regionkey = 2"", ""This connector does not support deletes"");
        }
    }
",non-flaky,5
43122,trinodb_trino,BaseConnectorSmokeTest.testDeleteAllDataFromTable,"    @Test
    public void testDeleteAllDataFromTable()
    {
        skipTestUnless(hasBehavior(SUPPORTS_CREATE_TABLE) && hasBehavior(SUPPORTS_DELETE));
        try (TestTable table = new TestTable(getQueryRunner()::execute, ""test_delete_all_data"", ""AS SELECT * FROM region"")) {
            // not using assertUpdate as some connectors provide update count and some do not
            getQueryRunner().execute(""DELETE FROM "" + table.getName());
            assertQuery(""SELECT count(*) FROM "" + table.getName(), ""VALUES 0"");
        }
    }
",non-flaky,5
43123,trinodb_trino,BaseConnectorSmokeTest.testRowLevelDelete,"    @Test
    public void testRowLevelDelete()
    {
        skipTestUnless(hasBehavior(SUPPORTS_CREATE_TABLE) && hasBehavior(SUPPORTS_ROW_LEVEL_DELETE));
        // TODO (https://github.com/trinodb/trino/issues/5901) Use longer table name once Oracle version is updated
        try (TestTable table = new TestTable(getQueryRunner()::execute, ""test_row_delete"", ""AS SELECT * FROM region"")) {
            assertUpdate(""DELETE FROM "" + table.getName() + "" WHERE regionkey = 2"", 1);
            assertThat(query(""SELECT * FROM "" + table.getName() + "" WHERE regionkey = 2""))
                    .returnsEmptyResult();
            assertThat(query(""SELECT cast(regionkey AS integer) FROM "" + table.getName()))
                    .skippingTypesCheck()
                    .matches(""VALUES 0, 1, 3, 4"");
        }
    }
",non-flaky,5
43124,trinodb_trino,BaseConnectorSmokeTest.testUpdate,"    @Test
    public void testUpdate()
    {
        if (!hasBehavior(SUPPORTS_UPDATE)) {
            // Note this change is a no-op, if actually run
            assertQueryFails(""UPDATE nation SET nationkey = nationkey + regionkey WHERE regionkey < 1"", ""This connector does not support updates"");
            return;
        }

        try (TestTable table = new TestTable(getQueryRunner()::execute, ""test_update"", ""AS TABLE tpch.tiny.nation"")) {
            String tableName = table.getName();
            assertUpdate(""UPDATE "" + tableName + "" SET nationkey = 100 + nationkey WHERE regionkey = 2"", 5);
            assertThat(query(""SELECT * FROM "" + tableName))
                    .skippingTypesCheck()
                    .matches(""SELECT IF(regionkey=2, nationkey + 100, nationkey) nationkey, name, regionkey, comment FROM tpch.tiny.nation"");
        }
    }
",non-flaky,5
43125,trinodb_trino,BaseConnectorSmokeTest.testCreateSchema,"    @Test
    public void testCreateSchema()
    {
        String schemaName = ""test_schema_create_"" + randomTableSuffix();
        if (!hasBehavior(SUPPORTS_CREATE_SCHEMA)) {
            assertQueryFails(""CREATE SCHEMA "" + schemaName, ""This connector does not support creating schemas"");
            return;
        }

        assertUpdate(""CREATE SCHEMA "" + schemaName);
        assertThat(query(""SHOW SCHEMAS""))
                .skippingTypesCheck()
                .containsAll(format(""VALUES '%s', '%s'"", getSession().getSchema().orElseThrow(), schemaName));
        assertUpdate(""DROP SCHEMA "" + schemaName);
    }
",non-flaky,5
59566,looly_hutool,CronPatternTest.matchAllTest,"	@Test
	public void matchAllTest() {
		CronPattern pattern;
		// 
		pattern = new CronPattern(""* * * * * *"");
		Assert.assertTrue(pattern.match(DateUtil.current(), true));
		Assert.assertTrue(pattern.match(DateUtil.current(), false));
	}
",non-flaky,5
59567,looly_hutool,CronPatternTest.matchAllTest2,"	@Test
	public void matchAllTest2() {
		// 5
		// 
		CronPattern pattern;
		// 
		pattern = new CronPattern(""* * * * *"");
		for(int i = 0; i < 1; i++) {
			Assert.assertTrue(pattern.match(DateUtil.current(), false));
		}
	}
",non-flaky,5
59568,looly_hutool,CronPatternTest.cronPatternTest,"	@Test
	public void cronPatternTest() {
		CronPattern pattern;

		// 12:11
		pattern = new CronPattern(""39 11 12 * * *"");
		assertMatch(pattern, ""12:11:39"");

		// 5[0,5,10,15,20,25,30,35,40,45,50,55]
		pattern = new CronPattern(""39 */5 * * * *"");
		assertMatch(pattern, ""12:00:39"");
		assertMatch(pattern, ""12:05:39"");
		assertMatch(pattern, ""12:10:39"");
		assertMatch(pattern, ""12:15:39"");
		assertMatch(pattern, ""12:20:39"");
		assertMatch(pattern, ""12:25:39"");
		assertMatch(pattern, ""12:30:39"");
		assertMatch(pattern, ""12:35:39"");
		assertMatch(pattern, ""12:40:39"");
		assertMatch(pattern, ""12:45:39"");
		assertMatch(pattern, ""12:50:39"");
		assertMatch(pattern, ""12:55:39"");

		// 2:01,3:01,4:01
		pattern = new CronPattern(""39 1 2-4 * * *"");
		assertMatch(pattern, ""02:01:39"");
		assertMatch(pattern, ""03:01:39"");
		assertMatch(pattern, ""04:01:39"");

		// 2:01,3:01,4:01
		pattern = new CronPattern(""39 1 2,3,4 * * *"");
		assertMatch(pattern, ""02:01:39"");
		assertMatch(pattern, ""03:01:39"");
		assertMatch(pattern, ""04:01:39"");

		// 08-07, 08-06
		pattern = new CronPattern(""39 0 0 6,7 8 *"");
		assertMatch(pattern, ""2016-08-07 00:00:39"");
		assertMatch(pattern, ""2016-08-06 00:00:39"");

		// 
		pattern = new CronPattern(""39 0 0 6,7 Aug *"");
		assertMatch(pattern, ""2016-08-06 00:00:39"");
		assertMatch(pattern, ""2016-08-07 00:00:39"");

		pattern = new CronPattern(""39 0 0 7 aug *"");
		assertMatch(pattern, ""2016-08-07 00:00:39"");

		// 
		pattern = new CronPattern(""39 0 0 * * Thu"");
		assertMatch(pattern, ""2017-02-09 00:00:39"");
		assertMatch(pattern, ""2017-02-09 00:00:39"");

	}
",non-flaky,5
59569,looly_hutool,CronPatternTest.CronPatternTest2,"	@Test
	public void CronPatternTest2() {
		CronPattern pattern = new CronPattern(""0/30 * * * *"");
		Assert.assertTrue(pattern.match(DateUtil.parse(""2018-10-09 12:00:00"").getTime(), false));
		Assert.assertTrue(pattern.match(DateUtil.parse(""2018-10-09 12:30:00"").getTime(), false));
		
		pattern = new CronPattern(""32 * * * *"");
		Assert.assertTrue(pattern.match(DateUtil.parse(""2018-10-09 12:32:00"").getTime(), false));
	}
",non-flaky,5
59570,looly_hutool,CronPatternTest.patternTest,"	@Test
	public void patternTest() {
		CronPattern pattern = new CronPattern(""* 0 4 * * ?"");
		assertMatch(pattern, ""2017-02-09 04:00:00"");
		assertMatch(pattern, ""2017-02-19 04:00:33"");

		// 6Quartz
		pattern = new CronPattern(""* 0 4 * * ?"");
		assertMatch(pattern, ""2017-02-09 04:00:00"");
		assertMatch(pattern, ""2017-02-19 04:00:33"");
	}
",non-flaky,5
59571,looly_hutool,CronPatternTest.rangePatternTest,"	@Test
	public void rangePatternTest() {
		CronPattern pattern = new CronPattern(""* 20/2 * * * ?"");
		assertMatch(pattern, ""2017-02-09 04:20:00"");
		assertMatch(pattern, ""2017-02-09 05:20:00"");
		assertMatch(pattern, ""2017-02-19 04:22:33"");

		pattern = new CronPattern(""* 2-20/2 * * * ?"");
		assertMatch(pattern, ""2017-02-09 04:02:00"");
		assertMatch(pattern, ""2017-02-09 05:04:00"");
		assertMatch(pattern, ""2017-02-19 04:20:33"");
	}
",non-flaky,5
59572,looly_hutool,CronPatternTest.lastTest,"	@Test
	public void lastTest() {
		// 
		CronPattern pattern = new CronPattern(""* * * L * ?"");
		assertMatch(pattern, ""2017-07-31 04:20:00"");
		assertMatch(pattern, ""2017-02-28 04:20:00"");

		// 
		pattern = new CronPattern(""* * * * L ?"");
		assertMatch(pattern, ""2017-12-02 04:20:00"");

		// 
		pattern = new CronPattern(""L L L * * ?"");
		assertMatch(pattern, ""2017-12-02 23:59:59"");
	}
",non-flaky,5
59573,looly_hutool,CronPatternTest.rangeYearTest,"	@Test(expected = CronException.class)
	public void rangeYearTest() {
		// year1970~2099
		CronPattern pattern = new CronPattern(""0/1 * * * 1/1 ? 2020-2120"");
	}
",non-flaky,5
59574,looly_hutool,CronPatternUtilTest.matchedDatesTest,"	@Test
	public void matchedDatesTest() {
		//30
		List<Date> matchedDates = CronPatternUtil.matchedDates(""0/30 * 8-18 * * ?"", DateUtil.parse(""2018-10-15 14:33:22""), 5, true);
		Assert.assertEquals(5, matchedDates.size());
		Assert.assertEquals(""2018-10-15 14:33:30"", matchedDates.get(0).toString());
		Assert.assertEquals(""2018-10-15 14:34:00"", matchedDates.get(1).toString());
		Assert.assertEquals(""2018-10-15 14:34:30"", matchedDates.get(2).toString());
		Assert.assertEquals(""2018-10-15 14:35:00"", matchedDates.get(3).toString());
		Assert.assertEquals(""2018-10-15 14:35:30"", matchedDates.get(4).toString());
	}
",non-flaky,5
59575,looly_hutool,CronPatternUtilTest.matchedDatesTest2,"	@Test
	public void matchedDatesTest2() {
		//
		List<Date> matchedDates = CronPatternUtil.matchedDates(""0 0 */1 * * *"", DateUtil.parse(""2018-10-15 14:33:22""), 5, true);
		Assert.assertEquals(5, matchedDates.size());
		Assert.assertEquals(""2018-10-15 15:00:00"", matchedDates.get(0).toString());
		Assert.assertEquals(""2018-10-15 16:00:00"", matchedDates.get(1).toString());
		Assert.assertEquals(""2018-10-15 17:00:00"", matchedDates.get(2).toString());
		Assert.assertEquals(""2018-10-15 18:00:00"", matchedDates.get(3).toString());
		Assert.assertEquals(""2018-10-15 19:00:00"", matchedDates.get(4).toString());
	}
",non-flaky,5
59576,looly_hutool,CronPatternUtilTest.matchedDatesTest3,"	@Test
	public void matchedDatesTest3() {
		//
		List<Date> matchedDates = CronPatternUtil.matchedDates(""0 0 */1 L * *"", DateUtil.parse(""2018-10-30 23:33:22""), 5, true);
		Assert.assertEquals(5, matchedDates.size());
		Assert.assertEquals(""2018-10-31 00:00:00"", matchedDates.get(0).toString());
		Assert.assertEquals(""2018-10-31 01:00:00"", matchedDates.get(1).toString());
		Assert.assertEquals(""2018-10-31 02:00:00"", matchedDates.get(2).toString());
		Assert.assertEquals(""2018-10-31 03:00:00"", matchedDates.get(3).toString());
		Assert.assertEquals(""2018-10-31 04:00:00"", matchedDates.get(4).toString());
	}
",non-flaky,5
59577,looly_hutool,CronTest.customCronTest,"	@Test
	public void customCronTest() {
		CronUtil.schedule(""*/2 * * * * *"", (Task) () -> Console.log(""Task excuted.""));

		// 
		CronUtil.setMatchSecond(true);
		CronUtil.start();

		ThreadUtil.waitForDie();
		Console.log(""Exit."");
	}
",non-flaky,5
59578,looly_hutool,CronTest.cronTest,"	@Test
	public void cronTest() {
		// 
		CronUtil.setMatchSecond(true);
		CronUtil.getScheduler().setDaemon(false);
		CronUtil.start();

		ThreadUtil.waitForDie();
		CronUtil.stop();
	}
",non-flaky,5
59579,looly_hutool,CronTest.onStart,"	@Test
	public void cronWithListenerTest() {
		CronUtil.getScheduler().addListener(new TaskListener() {
			@Override
			public void onStart(TaskExecutor executor) {
				Console.log(""Found task:[{}] start!"", executor.getCronTask().getId());
			}
",non-flaky,5
59580,looly_hutool,CronTest.addAndRemoveTest,"	@Test
	public void addAndRemoveTest() {
		String id = CronUtil.schedule(""*/2 * * * * *"", (Runnable) () -> Console.log(""task running : 2s""));

		Console.log(id);
		CronUtil.remove(id);

		// 
		CronUtil.setMatchSecond(true);
		CronUtil.start();
	}
",non-flaky,5
59581,looly_hutool,MailTest.sendWithFileTest,"	@Test
	public void sendWithFileTest() {
		MailUtil.send(""hutool@foxmail.com"", """", ""<h1>Hutool</h1>"", true, FileUtil.file(""d:/.txt""));
	}
",non-flaky,5
59582,looly_hutool,MailTest.sendWithLongNameFileTest,"	@Test
	public void sendWithLongNameFileTest() {
		//60
		MailUtil.send(""hutool@foxmail.com"", """", ""<h1>Hutool</h1>"", true, FileUtil.file(""d:/6-LongLong2018.3.12-3.16.xlsx""));
	}
",non-flaky,5
59583,looly_hutool,MailTest.sendWithImageTest,"	@Test
	public void sendWithImageTest() {
		Map<String, InputStream> map = new HashMap<>();
		map.put(""testImage"", FileUtil.getInputStream(""f:/test/me.png""));
		MailUtil.sendHtml(""hutool@foxmail.com"", """", ""<h1>Hutool</h1><img src=\""cid:testImage\"" />"", map);
	}
",non-flaky,5
59584,looly_hutool,MailTest.sendHtmlTest,"	@Test
	public void sendHtmlTest() {
		MailUtil.send(""hutool@foxmail.com"", """", ""<h1>Hutool</h1>"", true);
	}
",non-flaky,5
59585,looly_hutool,MailTest.sendByAccountTest,"	@Test
	public void sendByAccountTest() {
		MailAccount account = new MailAccount();
		account.setHost(""smtp.yeah.net"");
		account.setPort(465);
		account.setSslEnable(true);
		account.setFrom(""hutool@yeah.net"");
		account.setUser(""hutool"");
		account.setPass(""q1w2e3"");
		MailUtil.send(account, ""914104645@qq.com"", """", ""<h1>Hutool</h1>"", true);
	}
",non-flaky,5
59586,looly_hutool,MailTest.mailAccountTest,"	@Test
	public void mailAccountTest() {
		MailAccount account = new MailAccount();
		account.setFrom(""hutool@yeah.net"");
		account.setDebug(true);
		account.defaultIfEmpty();
		Properties props = account.getSmtpProps();
		Assert.assertEquals(""true"", props.getProperty(""mail.debug""));
	}
",non-flaky,5
59587,looly_hutool,MailAccountTest.parseSettingTest,"	@Test
	public void parseSettingTest() {
		MailAccount account = GlobalMailAccount.INSTANCE.getAccount();
		account.getSmtpProps();
		
		Assert.assertNotNull(account.getCharset());
		Assert.assertTrue(account.isSslEnable());
	}
",non-flaky,5
59588,looly_hutool,QrCodeUtilTest.generateTest,"	@Test
	public void generateTest() {
		final BufferedImage image = QrCodeUtil.generate(""https://hutool.cn/"", 300, 300);
		Assert.assertNotNull(image);
	}
",non-flaky,5
59589,looly_hutool,QrCodeUtilTest.generateCustomTest,"	@Test
	public void generateCustomTest() {
		QrConfig config = new QrConfig();
		config.setMargin(0);
		config.setForeColor(Color.CYAN);
		// 
		config.setBackColor(null);
		config.setErrorCorrection(ErrorCorrectionLevel.H);
		QrCodeUtil.generate(""https://hutool.cn/"", config, FileUtil.file(""d:/qrcodeCustom.png""));
	}
",non-flaky,5
59590,looly_hutool,QrCodeUtilTest.generateWithLogoTest,"	@Test
	public void generateWithLogoTest() {
		QrCodeUtil.generate(//
				""http://hutool.cn/"", //
				QrConfig.create().setImg(""e:/pic/face.jpg""), //
				FileUtil.file(""e:/qrcodeWithLogo.jpg""));
	}
",non-flaky,5
59591,looly_hutool,QrCodeUtilTest.decodeTest,"	@Test
	public void decodeTest() {
		String decode = QrCodeUtil.decode(FileUtil.file(""e:/pic/qr.png""));
		Console.log(decode);
	}
",non-flaky,5
59592,looly_hutool,QrCodeUtilTest.generateAsBase64Test,"	@Test
	public void generateAsBase64Test(){
		String base64 = QrCodeUtil.generateAsBase64(""http://hutool.cn/"", new QrConfig(400, 400), ""png"");
		System.out.println(base64);

		byte[] bytes = FileUtil.readBytes(
			new File(""d:/test/qr.png""));
		String encode = Base64.encode(bytes);
		String base641 = QrCodeUtil.generateAsBase64(""http://hutool.cn/"", new QrConfig(400, 400), ""png"", encode);
		System.out.println(base641);

	}
",non-flaky,5
59593,looly_hutool,PinyinUtilTest.getPinyinTest,"	@Test
	public void getPinyinTest(){
		final String pinyin = PinyinUtil.getPinyin("""", "" "");
		Assert.assertEquals(""ni hao"", pinyin);
	}
",non-flaky,5
59594,looly_hutool,PinyinUtilTest.getPinyinByPinyin4jTest,"	@Test
	public void getPinyinByPinyin4jTest() {
		final Pinyin4jEngine engine = new Pinyin4jEngine();
		final String pinyin = engine.getPinyin(""h"", "" "");
		Assert.assertEquals(""ni hao h"", pinyin);
	}
",non-flaky,5
59595,looly_hutool,PinyinUtilTest.getPinyinByBopomofo4jTest,"	@Test
	public void getPinyinByBopomofo4jTest() {
		final Bopomofo4jEngine engine = new Bopomofo4jEngine();
		final String pinyin = engine.getPinyin(""h"", "" "");
		Assert.assertEquals(""ni haoh"", pinyin);
	}
",non-flaky,5
59596,looly_hutool,PinyinUtilTest.getPinyinUpperCaseTest,"	@Test
	public void getPinyinUpperCaseTest(){
		final String pinyin = PinyinUtil.getPinyin("""", "" "");
		Assert.assertEquals(""ni hao yi"", pinyin);
	}
",non-flaky,5
59597,looly_hutool,PinyinUtilTest.getFirstLetterTest,"	@Test
	public void getFirstLetterTest(){
		final String result = PinyinUtil.getFirstLetter(""H"", "", "");
		Assert.assertEquals(""h, s, d, y, g"", result);
	}
",non-flaky,5
59598,looly_hutool,PinyinUtilTest.getFirstLetterByPinyin4jTest,"	@Test
	public void getFirstLetterByPinyin4jTest(){
		final Pinyin4jEngine engine = new Pinyin4jEngine();
		final String result = engine.getFirstLetter("""", """");
		Assert.assertEquals(""lh"", result);
	}
",non-flaky,5
59599,looly_hutool,PinyinUtilTest.getFirstLetterByBopomofo4jTest,"	@Test
	public void getFirstLetterByBopomofo4jTest(){
		final Bopomofo4jEngine engine = new Bopomofo4jEngine();
		final String result = engine.getFirstLetter("""", """");
		Assert.assertEquals(""lh"", result);
	}
",non-flaky,5
59600,looly_hutool,ArchiverTest.zipTest,"	@Test
	public void zipTest(){
		final File file = FileUtil.file(""d:/test/compress/test.zip"");
		StreamArchiver.create(CharsetUtil.CHARSET_UTF_8, ArchiveStreamFactory.ZIP, file)
				.add(FileUtil.file(""d:/Java""), (f)->{
					Console.log(""Add: {}"", f.getPath());
					return true;
				})
				.finish().close();
	}
",non-flaky,5
59601,looly_hutool,ArchiverTest.tarTest,"	@Test
	public void tarTest(){
		final File file = FileUtil.file(""d:/test/compress/test.tar"");
		StreamArchiver.create(CharsetUtil.CHARSET_UTF_8, ArchiveStreamFactory.TAR, file)
				.add(FileUtil.file(""d:/Java""), (f)->{
					Console.log(""Add: {}"", f.getPath());
					return true;
				})
				.finish().close();
	}
",non-flaky,5
59602,looly_hutool,ArchiverTest.cpioTest,"	@Test
	public void cpioTest(){
		final File file = FileUtil.file(""d:/test/compress/test.cpio"");
		StreamArchiver.create(CharsetUtil.CHARSET_UTF_8, ArchiveStreamFactory.CPIO, file)
				.add(FileUtil.file(""d:/Java""), (f)->{
					Console.log(""Add: {}"", f.getPath());
					return true;
				})
				.finish().close();
	}
",non-flaky,5
59603,looly_hutool,ArchiverTest.senvenZTest,"	@Test
	public void senvenZTest(){
		final File file = FileUtil.file(""d:/test/compress/test.7z"");
		CompressUtil.createArchiver(CharsetUtil.CHARSET_UTF_8, ArchiveStreamFactory.SEVEN_Z, file)
				.add(FileUtil.file(""d:/Java/apache-maven-3.6.3""), (f)->{
					Console.log(""Add: {}"", f.getPath());
					return true;
				})
				.finish().close();
	}
",non-flaky,5
59604,looly_hutool,ExtractorTest.zipTest,"	@Test
	public void zipTest(){
		Extractor extractor = CompressUtil.createExtractor(
				CharsetUtil.defaultCharset(),
				FileUtil.file(""d:/test/compress/test.zip""));

		extractor.extract(FileUtil.file(""d:/test/compress/test2/""));
	}
",non-flaky,5
59605,looly_hutool,ExtractorTest.sevenZTest,"	@Test
	public void sevenZTest(){
		Extractor extractor = CompressUtil.createExtractor(
				CharsetUtil.defaultCharset(),
				FileUtil.file(""d:/test/compress/test.7z""));

		extractor.extract(FileUtil.file(""d:/test/compress/test2/""));
	}
",non-flaky,5
59606,looly_hutool,ExpressionUtilTest.evalTest,"	@Test
	public void evalTest(){
		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = ExpressionUtil.eval(""a-(b-c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
",non-flaky,5
59607,looly_hutool,ExpressionUtilTest.jexlTest,"	@Test
	public void jexlTest(){
		ExpressionEngine engine = new JexlEngine();

		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = engine.eval(""a-(b-c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
",non-flaky,5
59608,looly_hutool,ExpressionUtilTest.mvelTest,"	@Test
	public void mvelTest(){
		ExpressionEngine engine = new MvelEngine();

		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = engine.eval(""a-(b-c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
",non-flaky,5
59609,looly_hutool,ExpressionUtilTest.jfireELTest,"	@Test
	public void jfireELTest(){
		ExpressionEngine engine = new JfireELEngine();

		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = engine.eval(""a-(b-c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
",non-flaky,5
59610,looly_hutool,ExpressionUtilTest.spELTest,"	@Test
	public void spELTest(){
		ExpressionEngine engine = new SpELEngine();

		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = engine.eval(""#a-(#b-#c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
",non-flaky,5
59611,looly_hutool,ExpressionUtilTest.rhinoTest,"	@Test
	public void rhinoTest(){
		ExpressionEngine engine = new RhinoEngine();

		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = engine.eval(""a-(b-c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
",non-flaky,5
59612,looly_hutool,AviatorTest.simpleTest,"	@Test
	public void simpleTest(){
		Foo foo = new Foo(100, 3.14f, new Date());
		ExpressionEngine engine = new AviatorEngine();
		String exp =
				""\""[foo i=\""+ foo.i + \"", f=\"" + foo.f + \"", date.year=\"" + (foo.date.year+1900) + \"", date.month=\"" + foo.date.month + \"", bars[0].name=\"" + #foo.bars[0].name + \""]\"""";
		String result = (String) engine.eval(exp, Dict.create().set(""foo"", foo));
		Assert.assertEquals(""[foo i=100, f=3.14, date.year=2020, date.month=10, bars[0].name=bar]"", result);

		// Assignment.
		exp = ""#foo.bars[0].name='hello aviator' ; #foo.bars[0].name"";
		result = (String) engine.eval(exp, Dict.create().set(""foo"", foo));
		Assert.assertEquals(""hello aviator"", result);
		Assert.assertEquals(""hello aviator"", foo.bars[0].getName());

		exp = ""foo.bars[0] = nil ; foo.bars[0]"";
		result = (String) engine.eval(exp, Dict.create().set(""foo"", foo));
		Console.log(""Execute expression: "" + exp);
		Assert.assertNull(result);
		Assert.assertNull(foo.bars[0]);
	}
",non-flaky,5
59613,looly_hutool,SpringUtilTest.registerBeanTest,"	@Test
	public void registerBeanTest() {
		Demo2 registerBean = new Demo2();
		registerBean.setId(123);
		registerBean.setName(""222"");
		SpringUtil.registerBean(""registerBean"", registerBean);

		Demo2 registerBean2 = SpringUtil.getBean(""registerBean"");
		Assert.assertEquals(123, registerBean2.getId());
		Assert.assertEquals(""222"", registerBean2.getName());
	}
",non-flaky,5
59614,looly_hutool,SpringUtilTest.getBeanTest,"	@Test
	public void getBeanTest(){
		final Demo2 testDemo = SpringUtil.getBean(""testDemo"");
		Assert.assertEquals(12345, testDemo.getId());
		Assert.assertEquals(""test"", testDemo.getName());
	}
",non-flaky,5
59615,looly_hutool,SpringUtilTest.getBeanWithTypeReferenceTest,"	@Test
	public void getBeanWithTypeReferenceTest() {
		Map<String, Object> mapBean = SpringUtil.getBean(new TypeReference<Map<String, Object>>() {});
		Assert.assertNotNull(mapBean);
		Assert.assertEquals(""value1"", mapBean.get(""key1""));
		Assert.assertEquals(""value2"", mapBean.get(""key2""));
	}
",non-flaky,5
59616,looly_hutool,EnableSprintUtilTest.test,"    @Test
    public void test() {
        // @EnableSpringUtil, 
        Assert.assertNotNull(SpringUtil.getApplicationContext());
        // , null
//        Assert.assertNull(SpringUtil.getApplicationContext());
    }
",non-flaky,5
59617,looly_hutool,BeanValidatorUtilTest.beanValidatorTest,"	@Test
	public void beanValidatorTest() {
		BeanValidationResult result = ValidationUtil.warpValidate(new TestClass());
		Assert.assertFalse(result.isSuccess());
		Assert.assertEquals(2, result.getErrorMessages().size());
	}
",non-flaky,5
59618,looly_hutool,BeanValidatorUtilTest.propertyValidatorTest,"	@Test
	public void propertyValidatorTest() {
		BeanValidationResult result = ValidationUtil.warpValidateProperty(new TestClass(), ""name"");
		Assert.assertFalse(result.isSuccess());
		Assert.assertEquals(1, result.getErrorMessages().size());
	}
",non-flaky,5
59619,looly_hutool,EmojiUtilTest.toUnicodeTest,"	@Test
	public void toUnicodeTest() {
		String emoji = EmojiUtil.toUnicode("":smile:"");
		Assert.assertEquals("""", emoji);
	}
",non-flaky,5
59620,looly_hutool,EmojiUtilTest.toAliasTest,"	@Test
	public void toAliasTest() {
		String alias = EmojiUtil.toAlias("""");
		Assert.assertEquals("":smile:"", alias);
	}
",non-flaky,5
59621,looly_hutool,EmojiUtilTest.containsEmojiTest,"	@Test
	public void containsEmojiTest() {
		boolean containsEmoji = EmojiUtil.containsEmoji(""EMOJ:"");
		Assert.assertEquals(containsEmoji, true);
		boolean notContainsEmoji = EmojiUtil.containsEmoji(""EMOJ:^_^"");
		Assert.assertEquals(notContainsEmoji, false);

	}
",non-flaky,5
59622,looly_hutool,JschUtilTest.bindPortTest,"	@Test
	public void bindPortTest() {
		//ssh10.1.1.1:22
		Session session = JschUtil.getSession(""looly.centos"", 22, ""test"", ""123456"");
		// 8080localhosthttp://localhost:8080/
		JschUtil.bindPort(session, ""172.20.12.123"", 8080, 8080);
	}
",non-flaky,5
59623,looly_hutool,JschUtilTest.bindRemotePort,"	@Test
	public void bindRemotePort() throws InterruptedException {
		// 
		Session session = JschUtil.getSession(""looly.centos"", 22, ""test"", ""123456"");
		// ssh80898000
		boolean b = JschUtil.bindRemotePort(session, 8089, ""localhost"", 8000);
		Assert.assertTrue(b);
		// 
//		while (true){
//			Thread.sleep(3000);
//		}
	}
",non-flaky,5
59624,looly_hutool,JschUtilTest.sftpTest,"	@Test
	public void sftpTest() {
		Session session = JschUtil.getSession(""looly.centos"", 22, ""root"", ""123456"");
		Sftp sftp = JschUtil.createSftp(session);
		sftp.mkDirs(""/opt/test/aaa/bbb"");
		Console.log(""OK"");
	}
",non-flaky,5
59625,looly_hutool,JschUtilTest.reconnectIfTimeoutTest,"	@Test
	public void reconnectIfTimeoutTest() throws InterruptedException {
		Session session = JschUtil.getSession(""sunnyserver"", 22,""mysftp"",""liuyang1234"");
		Sftp sftp = JschUtil.createSftp(session);

		Console.log(""pwd: "" + sftp.pwd());
		Console.log(""cd / : "" + sftp.cd(""/""));
		Console.log("""");
		Thread.sleep(30 * 1000);

		try{
			// isConnected()truepwdcd
			Console.log(""isConnected "" + sftp.getClient().isConnected());
			Console.log(""pwd: "" + sftp.pwd());
			Console.log(""cd / : "" + sftp.cd(""/""));
		}catch (JschRuntimeException e) {
			e.printStackTrace();
		}

		Console.log(""reconnectIfTimeout"");
		sftp.reconnectIfTimeout();

		Console.log(""pwd: "" + sftp.pwd());

		IoUtil.close(sftp);
	}
",non-flaky,5
59626,looly_hutool,JschUtilTest.getSessionTest,"	@Test
	public void getSessionTest(){
		JschUtil.getSession(""192.168.1.134"", 22, ""root"", ""aaa"", null);
	}
",non-flaky,5
59627,looly_hutool,FtpTest.cdTest,"	@Test
	public void cdTest() {
		Ftp ftp = new Ftp(""looly.centos"");
		
		ftp.cd(""/file/aaa"");
		Console.log(ftp.pwd());
		
		IoUtil.close(ftp);
	}
",non-flaky,5
59628,looly_hutool,FtpTest.uploadTest,"	@Test
	public void uploadTest() {
		Ftp ftp = new Ftp(""looly.centos"");
		
		List<String> ls = ftp.ls(""/file"");
		Console.log(ls);
		
		boolean upload = ftp.upload(""/file/aaa"", FileUtil.file(""E:/qrcodeWithLogo.jpg""));
		Console.log(upload);
		
		IoUtil.close(ftp);
	}
",non-flaky,5
59629,looly_hutool,FtpTest.reconnectIfTimeoutTest,"	@Test
	public void reconnectIfTimeoutTest() throws InterruptedException {
		Ftp ftp = new Ftp(""looly.centos"");

		Console.log(""pwd: "" + ftp.pwd());

		Console.log(""pwd"");
		Thread.sleep(35 * 1000);

		try{
			Console.log(""pwd: "" + ftp.pwd());
		}catch (FtpException e) {
			e.printStackTrace();
		}

		Console.log(""..."");
		ftp.reconnectIfTimeout();

		Console.log(""pwd: "" + ftp.pwd());

		IoUtil.close(ftp);
	}
",non-flaky,5
59630,looly_hutool,FtpTest.recursiveDownloadFolder,"	@Test
	public void recursiveDownloadFolder() {
		Ftp ftp = new Ftp(""looly.centos"");
		ftp.recursiveDownloadFolder(""/"",FileUtil.file(""d:/test/download""));

		IoUtil.close(ftp);
	}
",non-flaky,5
59631,looly_hutool,FtpTest.recursiveDownloadFolderSftp,"	@Test
	public void recursiveDownloadFolderSftp() {
		Sftp ftp = new Sftp(""127.0.0.1"", 22, ""test"", ""test"");

		ftp.cd(""/file/aaa"");
		Console.log(ftp.pwd());
		ftp.recursiveDownloadFolder(""/"",FileUtil.file(""d:/test/download""));

		IoUtil.close(ftp);
	}
",non-flaky,5
59632,looly_hutool,CglibUtilTest.copyTest,"	@Test
	public void copyTest() {
		SampleBean bean = new SampleBean();
		bean.setValue(""Hello world"");

		OtherSampleBean otherBean = new OtherSampleBean();
		CglibUtil.copy(bean, otherBean);
		Assert.assertEquals(""Hello world"", otherBean.getValue());

		OtherSampleBean otherBean2 = CglibUtil.copy(bean, OtherSampleBean.class);
		Assert.assertEquals(""Hello world"", otherBean2.getValue());
	}
",non-flaky,5
59633,looly_hutool,TokenizerUtilTest.createEngineTest,"	@Test
	public void createEngineTest() {
		// Ansj
		TokenizerEngine engine = TokenizerUtil.createEngine();
		Result result = engine.parse(text);
		checkResult(result);
	}
",non-flaky,5
59634,looly_hutool,TokenizerUtilTest.hanlpTest,"	@Test
	public void hanlpTest() {
		TokenizerEngine engine = new HanLPEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""        "", resultStr);
	}
",non-flaky,5
59635,looly_hutool,TokenizerUtilTest.ikAnalyzerTest,"	@Test
	public void ikAnalyzerTest() {
		TokenizerEngine engine = new IKAnalyzerEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""     "", resultStr);
	}
",non-flaky,5
59636,looly_hutool,TokenizerUtilTest.jcsegTest,"	@Test
	public void jcsegTest() {
		TokenizerEngine engine = new JcsegEngine();
		Result result = engine.parse(text);
		checkResult(result);
	}
",non-flaky,5
59637,looly_hutool,TokenizerUtilTest.jiebaTest,"	@Test
	public void jiebaTest() {
		TokenizerEngine engine = new JiebaEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""      "", resultStr);
	}
",non-flaky,5
59638,looly_hutool,TokenizerUtilTest.mmsegTest,"	@Test
	public void mmsegTest() {
		TokenizerEngine engine = new MmsegEngine();
		Result result = engine.parse(text);
		checkResult(result);
	}
",non-flaky,5
59639,looly_hutool,TokenizerUtilTest.smartcnTest,"	@Test
	public void smartcnTest() {
		TokenizerEngine engine = new SmartcnEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""        "", resultStr);
	}
",non-flaky,5
59640,looly_hutool,TokenizerUtilTest.wordTest,"	@Test
	public void wordTest() {
		TokenizerEngine engine = new WordEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""     "", resultStr);
	}
",non-flaky,5
59641,looly_hutool,TokenizerUtilTest.mynlpTest,"	@Test
	public void mynlpTest() {
		// JDK8
		TokenizerEngine engine = new MynlpEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""       "", resultStr);
	}
",non-flaky,5
59642,looly_hutool,VelocityTest.charsetTest,"	@Test
	public void charsetTest(){
		final TemplateConfig config = new TemplateConfig(""templates"", TemplateConfig.ResourceMode.CLASSPATH);
		config.setCustomEngine(VelocityEngine.class);
		config.setCharset(CharsetUtil.CHARSET_GBK);
		final TemplateEngine engine = TemplateUtil.createEngine(config);
		Template template = engine.getTemplate(""velocity_test_gbk.vtl"");
		String result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals("",hutool"", result);
	}
",non-flaky,5
59643,looly_hutool,ThymeleafTest.thymeleafEngineTest,"	@Test
	public void thymeleafEngineTest() {
		Map<String, Object> map1 = new HashMap<>();
		map1.put(""name"", ""a"");

		Map<String, Object> map2 = new HashMap<>();
		map2.put(""name"", ""b"");

		// 
		Map<String, Object> map3 = new HashMap<>();
		map3.put(""name"", DateUtil.parse(""2019-01-01""));

		List<Map<String, Object>> list = new ArrayList<>();
		list.add(map1);
		list.add(map2);
		list.add(map3);

		// 
		TemplateEngine engine = new ThymeleafEngine(new TemplateConfig());
		Template template = engine.getTemplate(""<h3 th:each=\""item : ${list}\"" th:text=\""${item.name}\""></h3>"");
		String render = template.render(Dict.create().set(""list"", list));
		Assert.assertEquals(""<h3>a</h3><h3>b</h3><h3>2019-01-01 00:00:00</h3>"", render);
	}
",non-flaky,5
59644,looly_hutool,ThymeleafTest.thymeleafEngineTest2,"	@Test
	public void thymeleafEngineTest2() {
		Map<String, Object> map1 = new HashMap<>();
		map1.put(""name"", ""a"");

		Map<String, Object> map2 = new HashMap<>();
		map2.put(""name"", ""b"");

		// 
		Map<String, Object> map3 = new HashMap<>();
		map3.put(""name"", DateUtil.parse(""2019-01-01""));

		List<Map<String, Object>> list = new ArrayList<>();
		list.add(map1);
		list.add(map2);
		list.add(map3);

		LinkedHashMap<String, Object> map = new LinkedHashMap<>();
		map.put(""list"", list);

		 hutoolApi(map);
		thymeleaf(map);
	}
",non-flaky,5
59645,looly_hutool,TemplateUtilTest.createEngineTest,"	@Test
	public void createEngineTest() {
		// , Beetl
		TemplateEngine engine = TemplateUtil.createEngine(new TemplateConfig());
		Template template = engine.getTemplate(""hello,${name}"");
		String result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result);

		// classpath
		engine = TemplateUtil.createEngine(new TemplateConfig(""templates"", ResourceMode.CLASSPATH));
		Template template2 = engine.getTemplate(""beetl_test.btl"");
		String result2 = template2.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result2);
	}
",non-flaky,5
59646,looly_hutool,TemplateUtilTest.beetlEngineTest,"	@Test
	public void beetlEngineTest() {
		// 
		TemplateEngine engine = new BeetlEngine(new TemplateConfig(""templates""));
		Template template = engine.getTemplate(""hello,${name}"");
		String result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result);

		// classpath
		engine = new BeetlEngine(new TemplateConfig(""templates"", ResourceMode.CLASSPATH));
		Template template2 = engine.getTemplate(""beetl_test.btl"");
		String result2 = template2.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result2);
	}
",non-flaky,5
59647,looly_hutool,TemplateUtilTest.rythmEngineTest,"	@Test
	public void rythmEngineTest() {
		// 
		TemplateEngine engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"").setCustomEngine(RythmEngine.class));
		Template template = engine.getTemplate(""hello,@name"");
		String result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result);

		// classpath
		Template template2 = engine.getTemplate(""rythm_test.tmpl"");
		String result2 = template2.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result2);
	}
",non-flaky,5
59648,looly_hutool,TemplateUtilTest.freemarkerEngineTest,"	@Test
	public void freemarkerEngineTest() {
		// 
		TemplateEngine engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"", ResourceMode.STRING).setCustomEngine(FreemarkerEngine.class));
		Template template = engine.getTemplate(""hello,${name}"");
		String result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result);
		
		//ClassPath
		engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"", ResourceMode.CLASSPATH).setCustomEngine(FreemarkerEngine.class));
		template = engine.getTemplate(""freemarker_test.ftl"");
		result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result);
	}
",non-flaky,5
59649,looly_hutool,TemplateUtilTest.velocityEngineTest,"	@Test
	public void velocityEngineTest() {
		// 
		TemplateEngine engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"", ResourceMode.STRING).setCustomEngine(VelocityEngine.class));
		Template template = engine.getTemplate("",$name"");
		String result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals("",hutool"", result);
		
		//ClassPath
		engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"", ResourceMode.CLASSPATH).setCustomEngine(VelocityEngine.class));
		template = engine.getTemplate(""velocity_test.vtl"");
		result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals("",hutool"", result);

		template = engine.getTemplate(""templates/velocity_test.vtl"");
		result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals("",hutool"", result);
	}
",non-flaky,5
59650,looly_hutool,TemplateUtilTest.enjoyEngineTest,"	@Test
	public void enjoyEngineTest() {
		// 
		TemplateEngine engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"").setCustomEngine(EnjoyEngine.class));
		Template template = engine.getTemplate(""#(x + 123)"");
		String result = template.render(Dict.create().set(""x"", 1));
		Assert.assertEquals(""124"", result);

		//ClassPath
		engine = new EnjoyEngine(
				new TemplateConfig(""templates"", ResourceMode.CLASSPATH).setCustomEngine(EnjoyEngine.class));
		template = engine.getTemplate(""enjoy_test.etl"");
		result = template.render(Dict.create().set(""x"", 1));
		Assert.assertEquals(""124"", result);
	}
",non-flaky,5
59651,looly_hutool,TemplateUtilTest.thymeleafEngineTest,"	@Test
	public void thymeleafEngineTest() {
		// 
		TemplateEngine engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"").setCustomEngine(ThymeleafEngine.class));
		Template template = engine.getTemplate(""<h3 th:text=\""${message}\""></h3>"");
		String result = template.render(Dict.create().set(""message"", ""Hutool""));
		Assert.assertEquals(""<h3>Hutool</h3>"", result);
		
		//ClassPath
		engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"", ResourceMode.CLASSPATH).setCustomEngine(ThymeleafEngine.class));
		template = engine.getTemplate(""thymeleaf_test.ttl"");
		result = template.render(Dict.create().set(""message"", ""Hutool""));
		Assert.assertEquals(""<h3>Hutool</h3>"", result);
	}
",non-flaky,5
59652,looly_hutool,TemplateUtilTest.renderToFileTest,"	@Test
	public void renderToFileTest() {
		TemplateEngine engine = new BeetlEngine(new TemplateConfig(""templates"", ResourceMode.CLASSPATH));
		Template template = engine.getTemplate(""freemarker_test.ftl"");

		final Map<String, Object> bindingMap = new HashMap<>();
		bindingMap.put(""name"", ""aa"");
		File outputFile = new File(""e:/test.txt"");
		template.render(bindingMap, outputFile);
	}
",non-flaky,5
59653,looly_hutool,BeetlUtilTest.renderStrTest,"	@Test
	public void renderStrTest() throws IOException {
		GroupTemplate groupTemplate = BeetlUtil.createGroupTemplate(new StringTemplateResourceLoader(), Configuration.defaultConfiguration());
		Template template = BeetlUtil.getTemplate(groupTemplate, ""hello,${name}"");
		String result = BeetlUtil.render(template, Dict.create().set(""name"", ""hutool""));

		Assert.assertEquals(""hello,hutool"", result);

		String renderFromStr = BeetlUtil.renderFromStr(""hello,${name}"", Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", renderFromStr);

	}
",non-flaky,5
59654,looly_hutool,AopTest.aopTest,"	@Test
	public void aopTest() {
		Animal cat = ProxyUtil.proxy(new Cat(), TimeIntervalAspect.class);
		String result = cat.eat();
		Assert.assertEquals("""", result);
		cat.seize();
	}
",non-flaky,5
59655,looly_hutool,AopTest.aopByAutoCglibTest,"	@Test
	public void aopByAutoCglibTest() {
		Dog dog = ProxyUtil.proxy(new Dog(), TimeIntervalAspect.class);
		String result = dog.eat();
		Assert.assertEquals("""", result);

		dog.seize();
	}
",non-flaky,5
59656,looly_hutool,AopTest.testCGLIBProxy,"	@Test
	public void testCGLIBProxy() {
		TagObj target = new TagObj();
		//
		target.setTag(""tag"");

		TagObj proxy = ProxyUtil.proxy(target, TimeIntervalAspect.class);
		//tag ()
		Assert.assertEquals(""tag"", proxy.getTag());
	}
",non-flaky,5
59657,looly_hutool,ScriptUtilTest.compileTest,"	@Test
	public void compileTest() {
		CompiledScript script = ScriptUtil.compile(""print('Script test!');"");
		try {
			script.eval();
		} catch (ScriptException e) {
			throw new ScriptRuntimeException(e);
		}
	}
",non-flaky,5
59658,looly_hutool,ScriptUtilTest.evalTest,"	@Test
	public void evalTest() {
		ScriptUtil.eval(""print('Script test!');"");
	}
",non-flaky,5
59659,looly_hutool,ScriptUtilTest.invokeTest,"	@Test
	public void invokeTest() {
		final Object result = ScriptUtil.invoke(ResourceUtil.readUtf8Str(""filter1.js""), ""filter1"", 2, 1);
		Assert.assertTrue((Boolean) result);
	}
",non-flaky,5
59660,looly_hutool,ScriptUtilTest.pythonTest,"	@Test
	public void pythonTest() throws ScriptException {
		final ScriptEngine pythonEngine = ScriptUtil.getPythonEngine();
		pythonEngine.eval(""print('Hello Python')"");
	}
",non-flaky,5
59661,looly_hutool,ScriptUtilTest.luaTest,"	@Test
	public void luaTest() throws ScriptException {
		final ScriptEngine engine = ScriptUtil.getLuaEngine();
		engine.eval(""print('Hello Lua')"");
	}
",non-flaky,5
59662,looly_hutool,ScriptUtilTest.groovyTest,"	@Test
	public void groovyTest() throws ScriptException {
		final ScriptEngine engine = ScriptUtil.getGroovyEngine();
		engine.eval(""println 'Hello Groovy'"");
	}
",non-flaky,5
59663,looly_hutool,SystemUtilTest.dumpTest,"	@Test
	public void dumpTest() {
		SystemUtil.dumpSystemInfo();
	}
",non-flaky,5
59664,looly_hutool,SystemUtilTest.getCurrentPidTest,"	@Test
	public void getCurrentPidTest() {
		long pid = SystemUtil.getCurrentPID();
		Assert.assertTrue(pid > 0);
	}
",non-flaky,5
59665,looly_hutool,SystemUtilTest.getJavaInfoTest,"	@Test
	public void getJavaInfoTest() {
		JavaInfo javaInfo = SystemUtil.getJavaInfo();
		Assert.assertNotNull(javaInfo);
	}
",non-flaky,5
76672,quarkusio_quarkus,ConfiguredBean.loadConfig,"@TestAnnotation
    public void loadConfig(TestBuildAndRunTimeConfig buildTimeConfig, TestRunTimeConfig runTimeConfig,
            FooRuntimeConfig fooRuntimeConfig) {
        System.out.printf(""loadConfig, buildTimeConfig=%s, runTimeConfig=%s, fooRuntimeConfig=%s%n"", buildTimeConfig,
                runTimeConfig, fooRuntimeConfig);
        this.buildTimeConfig = buildTimeConfig;
        this.runTimeConfig = runTimeConfig;
        this.fooRuntimeConfig = fooRuntimeConfig;
    }
",non-flaky,5
76673,quarkusio_quarkus,UnspecifiedPrefixConfigProperties.testConfiguredValues,"    @Test
    public void testConfiguredValues() {
        assertEquals(""quarkus"", dummyBean.getName());
        assertEquals(""hello"", dummyBean.getMessage());
    }
",non-flaky,5
76674,quarkusio_quarkus,HibernateET.testImport,"    @Test
    public void testImport() {
        RestAssured.when().get(""/my-entity/1"").then().body(is(""MyEntity:TEST ENTITY""));
    }
",non-flaky,5
76675,quarkusio_quarkus,CustomAuthEmbeddedBase.testSecureAccessFailure,"    @Test()
    public void testSecureAccessFailure() {
        RestAssured.when().get(""/secure-test"").then()
                .statusCode(401);
    }
",non-flaky,5
76676,quarkusio_quarkus,CustomAuthEmbeddedBase.testSecureRoleFailure,"    @Test()
    public void testSecureRoleFailure() {
        RestAssured.given().auth().preemptive().basic(""jdoe"", ""p4ssw0rd"")
                .when().get(""/secure-test"").then()
                .statusCode(403);
    }
",non-flaky,5
76677,quarkusio_quarkus,CustomAuthEmbeddedBase.testSecureAccessSuccess,"    @Test()
    public void testSecureAccessSuccess() {
        RestAssured.given().auth().preemptive().basic(""stuart"", ""test"")
                .when().get(""/secure-test"").then()
                .statusCode(200);
    }
",non-flaky,5
76678,quarkusio_quarkus,CustomAuthEmbeddedBase.testJaxrsGetFailure,"    @Test
    public void testJaxrsGetFailure() {
        RestAssured.when().get(""/jaxrs-secured/rolesClass"").then()
                .statusCode(401);
    }
",non-flaky,5
76679,quarkusio_quarkus,CustomAuthEmbeddedBase.testJaxrsGetRoleFailure,"    @Test
    public void testJaxrsGetRoleFailure() {
        RestAssured.given().auth().preemptive().basic(""jdoe"", ""p4ssw0rd"")
                .when().get(""/jaxrs-secured/rolesClass"").then()
                .statusCode(403);
    }
",non-flaky,5
76680,quarkusio_quarkus,CustomAuthEmbeddedBase.testJaxrsGetRoleSuccess,"    @Test
    public void testJaxrsGetRoleSuccess() {
        RestAssured.given().auth().preemptive().basic(""scott"", ""jb0ss"")
                .when().get(""/jaxrs-secured/rolesClass"").then()
                .statusCode(200);
    }
",non-flaky,5
76681,quarkusio_quarkus,CustomAuthEmbeddedBase.testJaxrsPathAdminRoleSuccess,"    @Test
    public void testJaxrsPathAdminRoleSuccess() {
        RestAssured.given().auth().preemptive().basic(""scott"", ""jb0ss"")
                .when().get(""/jaxrs-secured/parameterized-paths/my/banking/admin"").then()
                .statusCode(200);
    }
",non-flaky,5
76682,quarkusio_quarkus,CustomAuthEmbeddedBase.testJaxrsPathAdminRoleFailure,"    @Test
    public void testJaxrsPathAdminRoleFailure() {
        RestAssured.given().auth().preemptive().basic(""noadmin"", ""n0Adm1n"")
                .when().get(""/jaxrs-secured/parameterized-paths/my/banking/admin"").then()
                .statusCode(403);
    }
",non-flaky,5
76683,quarkusio_quarkus,CustomAuthEmbeddedBase.testJaxrsPathUserRoleSuccess,"    @Test
    public void testJaxrsPathUserRoleSuccess() {
        RestAssured.given().auth().preemptive().basic(""stuart"", ""test"")
                .when().get(""/jaxrs-secured/parameterized-paths/my/banking/view"").then()
                .statusCode(200);
    }
",non-flaky,5
76684,quarkusio_quarkus,CustomAuthEmbeddedBase.testJaxrsUserRoleSuccess,"    @Test
    public void testJaxrsUserRoleSuccess() {
        RestAssured.given().auth().preemptive().basic(""scott"", ""jb0ss"")
                .when().get(""/jaxrs-secured/subject/secured"").then()
                .statusCode(200)
                .body(equalTo(""scott""));
    }
",non-flaky,5
76685,quarkusio_quarkus,CustomAuthEmbeddedBase.testJaxrsGetPermitAll,"    @Test
    public void testJaxrsGetPermitAll() {
        RestAssured.when().get(""/jaxrs-secured/subject/unsecured"").then()
                .statusCode(200)
                .body(equalTo(""anonymous""));
    }
",non-flaky,5
76686,quarkusio_quarkus,CustomAuthEmbeddedBase.testJaxrsGetDenyAllWithoutAuth,"    @Test
    public void testJaxrsGetDenyAllWithoutAuth() {
        RestAssured.when().get(""/jaxrs-secured/subject/denied"").then()
                .statusCode(401);
    }
",non-flaky,5
76687,quarkusio_quarkus,CustomAuthEmbeddedBase.testJaxrsGetDenyAllWithAuth,"    @Test
    public void testJaxrsGetDenyAllWithAuth() {
        RestAssured.given().auth().preemptive().basic(""scott"", ""jb0ss"")
                .when().get(""/jaxrs-secured/subject/denied"").then()
                .statusCode(403);
    }
",non-flaky,5
76688,quarkusio_quarkus,TracerRouterUT.testTracer,"    @Test
    public void testTracer() {
        RestAssured.when().get(""/tracer"").then()
                .statusCode(200)
                .body(is(""Hello Tracer!""));
    }
",non-flaky,5
76689,quarkusio_quarkus,SimpleET.testHelloEndpoint,"    @Test
    public void testHelloEndpoint() {
        given()
                .when().get(""/hello"")
                .then()
                .statusCode(200)
                .body(is(""hello""));
    }
",non-flaky,5
76690,quarkusio_quarkus,SimpleET.testGreetingEndpoint,"    @Test
    public void testGreetingEndpoint() {
        String uuid = UUID.randomUUID().toString();
        given()
                .pathParam(""name"", uuid)
                .when().get(""/hello/greeting/{name}"")
                .then()
                .statusCode(200)
                .body(is(""hello "" + uuid));
    }
",non-flaky,5
76691,quarkusio_quarkus,ParamET.testHelloEndpoint,"    @Test
    public void testHelloEndpoint() {
        given()
                .when().get(""/hello"")
                .then()
                .statusCode(200)
                .body(is(""hello""));
    }
",non-flaky,5
76692,quarkusio_quarkus,TaggedET.t1,"    @Test
    public void t1() {
        given()
                .when().get(""/hello/greeting/foo"")
                .then()
                .statusCode(200)
                .body(is(""hello foo""));
    }
",non-flaky,5
76693,quarkusio_quarkus,TaggedET.t2,"    @Test
    public void t2() {
        given()
                .when().get(""/hello/greeting/foo"")
                .then()
                .statusCode(200)
                .body(is(""hello foo""));
    }
",non-flaky,5
76694,quarkusio_quarkus,TaggedET.t3,"    @Test
    public void t3() {
        given()
                .when().get(""/hello/greeting/foo"")
                .then()
                .statusCode(200)
                .body(is(""hello foo""));
    }
",non-flaky,5
76695,quarkusio_quarkus,TaggedET.t4,"    @Test
    public void t4() {
        given()
                .when().get(""/hello/greeting/foo"")
                .then()
                .statusCode(200)
                .body(is(""hello foo""));
    }
",non-flaky,5
76696,quarkusio_quarkus,TaggedET.t5,"    @Test
    public void t5() {
        given()
                .when().get(""/hello/greeting/foo"")
                .then()
                .statusCode(200)
                .body(is(""hello foo""));
    }
",non-flaky,5
76697,quarkusio_quarkus,UnitET.unitStyleTest2,"    @Test
    public void unitStyleTest2() {
        Assertions.assertEquals(""UNIT"", UnitService.service());
    }
",non-flaky,5
76698,quarkusio_quarkus,UnitET.unitStyleTest,"    @Test
    public void unitStyleTest() {
        HelloResource res = new HelloResource();
        Assertions.assertEquals(""Hi"", res.sayHello());
    }
",non-flaky,5
76699,quarkusio_quarkus,DuplicateSimpleET.testHelloEndpoint,"    @Test
    public void testHelloEndpoint() {
        given()
                .when().get(""/hello"")
                .then()
                .statusCode(200)
                .body(is(""hello""));
    }
",non-flaky,5
76700,quarkusio_quarkus,DuplicateSimpleET.testGreetingEndpoint,"    @Test
    public void testGreetingEndpoint() {
        String uuid = UUID.randomUUID().toString();
        given()
                .pathParam(""name"", uuid)
                .when().get(""/hello/greeting/{name}"")
                .then()
                .statusCode(200)
                .body(is(""hello "" + uuid));
    }
",non-flaky,5
76701,quarkusio_quarkus,FooET.foo,"    @Test
    public void foo() {
        given()
                .when().get(""/hello/greeting/foo"")
                .then()
                .statusCode(200)
                .body(is(""hello foo""));
    }
",non-flaky,5
76702,quarkusio_quarkus,BarET.bar,"    @Test
    public void bar() {
        given()
                .when().get(""/hello/greeting/foo"")
                .then()
                .statusCode(200)
                .body(is(""hello foo""));
    }
",non-flaky,5
76703,quarkusio_quarkus,SimpleET.testHelloEndpoint,"    @Test
    public void testHelloEndpoint() {
        given()
                .when().get(""/hello"")
                .then()
                .statusCode(200)
                .body(is(""hello""));
    }
",non-flaky,5
76704,quarkusio_quarkus,SimpleET.testGreetingEndpoint,"    @Test
    public void testGreetingEndpoint() {
        String uuid = UUID.randomUUID().toString();
        given()
                .pathParam(""name"", uuid)
                .when().get(""/hello/greeting/{name}"")
                .then()
                .statusCode(200)
                .body(is(""hello "" + uuid));
    }
",non-flaky,5
76705,quarkusio_quarkus,MongoDbRestDataPanacheIT.testDevServicesProperties,"    @Test
    public void testDevServicesProperties() {
        assertThat(context.devServicesProperties()).hasSize(1).containsKey(""quarkus.mongodb.connection-string"");
    }
",non-flaky,5
76706,quarkusio_quarkus,CoreReflectionInGraalITCase.testFieldAndGetterReflectionOnEntityFromServlet,"    @Test
    public void testFieldAndGetterReflectionOnEntityFromServlet() throws Exception {
        RestAssured.when().get(""/core/reflection"").then()
                .body(is(""OK""));
    }
",non-flaky,5
76707,quarkusio_quarkus,ResourcesITCase.excludedNative,"    @Test
    public void excludedNative() {
        RestAssured.when()
                .get(""/resources/test-resources/file.adoc"")
                .then()
                .statusCode(404);

        RestAssured.when()
                .get(""/resources/test-resources/excluded/unwanted.txt"")
                .then()
                .statusCode(404);

        RestAssured.when()
                .get(""/resources/META-INF/quarkus-native-resources.txt"")
                .then()
                .statusCode(404);
    }
",non-flaky,5
76708,quarkusio_quarkus,CharacterSetSupportITCase.testFieldAndGetterReflectionOnEntityFromServlet,"    @Test
    public void testFieldAndGetterReflectionOnEntityFromServlet() throws Exception {
        RestAssured.when().get(""/core/charsetsupport"").then()
                .body(is(""OK""));
    }
",non-flaky,5
76709,quarkusio_quarkus,RegisterForReflectionITCase.testSelfWithoutNested,"    @Test
    public void testSelfWithoutNested() {
        final String resourceA = BASE_PKG + "".ResourceA"";

        assertRegistration(""ResourceA"", resourceA);
        assertRegistration(""FAILED"", resourceA + ""$InnerClassOfA"");
        assertRegistration(""FAILED"", resourceA + ""$StaticClassOfA"");
        assertRegistration(""FAILED"", resourceA + ""$InterfaceOfA"");
    }
",non-flaky,5
76710,quarkusio_quarkus,RegisterForReflectionITCase.testSelfWithNested,"    @Test
    public void testSelfWithNested() {
        final String resourceB = BASE_PKG + "".ResourceB"";

        assertRegistration(""ResourceB"", resourceB);
        assertRegistration(""InnerClassOfB"", resourceB + ""$InnerClassOfB"");
        assertRegistration(""StaticClassOfB"", resourceB + ""$StaticClassOfB"");
        assertRegistration(""InterfaceOfB"", resourceB + ""$InterfaceOfB"");
        assertRegistration(""InnerInnerOfB"", resourceB + ""$InnerClassOfB$InnerInnerOfB"");
    }
",non-flaky,5
76711,quarkusio_quarkus,RegisterForReflectionITCase.testTargetWithNested,"    @Test
    public void testTargetWithNested() {
        final String resourceC = BASE_PKG + "".ResourceC"";

        assertRegistration(""FAILED"", resourceC);
        assertRegistration(""InaccessibleClassOfC"", resourceC + ""$InaccessibleClassOfC"");
        assertRegistration(""OtherInaccessibleClassOfC"", resourceC + ""$InaccessibleClassOfC$OtherInaccessibleClassOfC"");
    }
",non-flaky,5
76712,quarkusio_quarkus,RegisterForReflectionITCase.testTargetWithoutNested,"    @Test
    public void testTargetWithoutNested() {
        final String resourceD = BASE_PKG + "".ResourceD"";

        assertRegistration(""FAILED"", resourceD);
        assertRegistration(""StaticClassOfD"", resourceD + ""$StaticClassOfD"");
        assertRegistration(""FAILED"", resourceD + ""$StaticClassOfD$OtherAccessibleClassOfD"");
    }
",non-flaky,5
76713,quarkusio_quarkus,CoreSerializationInGraalITCase.testEntitySerializationFromServlet,"    @Test
    public void testEntitySerializationFromServlet() throws Exception {
        RestAssured.when().get(""/core/serialization"").then()
                .body(is(""OK""));
    }
",non-flaky,5
76714,quarkusio_quarkus,JPAReflectionInGraalITCase.testFieldAndGetterReflectionOnEntityFromServlet,"    @Test
    public void testFieldAndGetterReflectionOnEntityFromServlet() throws Exception {
        RestAssured.when().get(""/jpa/testreflection"").then()
                .body(is(""OK""));
    }
",non-flaky,5
76715,quarkusio_quarkus,QuarkusCodestartBuildIT.testRunTogetherCodestartsJava,"    @Test
    public void testRunTogetherCodestartsJava() throws Exception {
        generateProjectRunTests(""maven"", ""java"", getExtensionCodestarts());
    }
",non-flaky,5
76716,quarkusio_quarkus,QuarkusCodestartBuildIT.testRunTogetherCodestartsKotlin,"    @Test
    public void testRunTogetherCodestartsKotlin() throws Exception {
        generateProjectRunTests(""maven"", ""kotlin"", getExtensionCodestarts());
    }
",non-flaky,5
76717,quarkusio_quarkus,QuarkusCodestartBuildIT.testRunTogetherCodestartsScala,"    @Test
    public void testRunTogetherCodestartsScala() throws Exception {
        generateProjectRunTests(""maven"", ""scala"", getExtensionCodestarts());
    }
",non-flaky,5
76718,quarkusio_quarkus,QuarkusCodestartBuildIT.testGradle,"    @ParameterizedTest
    public void testGradle(String language) throws Exception {
        final List<String> codestarts = getExtensionCodestarts();
        generateProjectRunTests(""gradle"", language, codestarts);
    }
",non-flaky,5
76719,quarkusio_quarkus,QuarkusCodestartBuildIT.testGradleKotlinDSL,"    @ParameterizedTest
    public void testGradleKotlinDSL(String language) throws Exception {
        final List<String> codestarts = getExtensionCodestarts();
        generateProjectRunTests(""gradle-kotlin-dsl"", language, codestarts);
    }
",non-flaky,5
76720,quarkusio_quarkus,QuarkusCodestartBuildIT.testRunAloneCodestartsJava,"    @ParameterizedTest
    public void testRunAloneCodestartsJava(String codestart) throws Exception {
        generateProjectRunTests(""maven"", ""java"", singletonList(codestart));
    }
",non-flaky,5
76721,quarkusio_quarkus,QuarkusCodestartBuildIT.testRunAloneCodestartsKotlin,"    @ParameterizedTest
    public void testRunAloneCodestartsKotlin(String codestart) throws Exception {
        generateProjectRunTests(""maven"", ""kotlin"", singletonList(codestart));
    }
",non-flaky,5
76722,quarkusio_quarkus,QuarkusCodestartBuildIT.testRunAloneCodestartsScala,"    @ParameterizedTest
    public void testRunAloneCodestartsScala(String codestart) throws Exception {
        generateProjectRunTests(""maven"", ""scala"", singletonList(codestart));
    }
",non-flaky,5
76723,quarkusio_quarkus,QuarkusCodestartBuildIT.generateAzureFunctionsHttpExampleProjectRun,"    @Test
    public void generateAzureFunctionsHttpExampleProjectRun() throws Exception {
        generateProjectRunTests(""maven"", ""java"", singletonList(""azure-functions-http-example""));
    }
",non-flaky,5
76724,quarkusio_quarkus,JarRunnerIT.testNonAsciiDir,"    @Test
    public void testNonAsciiDir() throws Exception {
        final File testDir = initProject(""projects/classic"", ""projects/"");
        final RunningInvoker running = new RunningInvoker(testDir, false);

        final MavenProcessInvocationResult result = running.execute(Arrays.asList(""install"", ""-DskipTests""),
                Collections.emptyMap());
        await().atMost(1, TimeUnit.MINUTES).until(() -> result.getProcess() != null && !result.getProcess().isAlive());
        assertThat(running.log()).containsIgnoringCase(""BUILD SUCCESS"");
        running.stop();

        File output = new File(testDir, ""target/output.log"");
        output.createNewFile();

        Process process = doLaunch(new File(testDir, ""target/quarkus-app""), Paths.get(""quarkus-run.jar""), output,
                Collections.emptyList()).start();
        try {
            // Wait until server up
            dumpFileContentOnFailure(() -> {
                await().pollDelay(1, TimeUnit.SECONDS)
                        .atMost(1, TimeUnit.MINUTES).until(() -> DevModeTestUtils.getHttpResponse(""/app/hello/package"", 200));
                return null;
            }, output, ConditionTimeoutException.class);
        } finally {
            process.destroy();
        }

    }
",non-flaky,5
76725,quarkusio_quarkus,JarRunnerIT.testThatJarRunnerConsoleOutputWorksCorrectly,"    @Test
    public void testThatJarRunnerConsoleOutputWorksCorrectly() throws MavenInvocationException, IOException {
        File testDir = initProject(""projects/classic"", ""projects/project-classic-console-output"");
        RunningInvoker running = new RunningInvoker(testDir, false);

        MavenProcessInvocationResult result = running.execute(Arrays.asList(""package"", ""-DskipTests""), Collections.emptyMap());
        await().atMost(1, TimeUnit.MINUTES).until(() -> result.getProcess() != null && !result.getProcess().isAlive());
        assertThat(running.log()).containsIgnoringCase(""BUILD SUCCESS"");
        running.stop();

        Path jar = testDir.toPath().toAbsolutePath()
                .resolve(Paths.get(""target/quarkus-app/quarkus-run.jar""));
        File output = new File(testDir, ""target/output.log"");
        output.createNewFile();

        Process process = doLaunch(jar, output).start();
        try {
            // Wait until server up
            await()
                    .pollDelay(1, TimeUnit.SECONDS)
                    .atMost(1, TimeUnit.MINUTES).until(() -> DevModeTestUtils.getHttpResponse(""/app/hello/package"", 200));

            String logs = FileUtils.readFileToString(output, ""UTF-8"");

            assertThatOutputWorksCorrectly(logs);

            // test that the application name and version are properly set
            assertApplicationPropertiesSetCorrectly();
            assertResourceReadingFromClassPathWorksCorrectly("""");
            assertUsingProtectionDomainWorksCorrectly("""");
        } finally {
            process.destroy();
        }

    }
",non-flaky,5
76726,quarkusio_quarkus,JarRunnerIT.testPlatformPropertiesOverridenInApplicationProperties,"    @Test
    public void testPlatformPropertiesOverridenInApplicationProperties() throws Exception {
        final File testDir = initProject(""projects/platform-properties-overrides"",
                ""projects/platform-props-overriden-in-app-props"");
        final RunningInvoker running = new RunningInvoker(testDir, false);

        final MavenProcessInvocationResult result = running.execute(Arrays.asList(""install""),
                Collections.emptyMap());
        await().atMost(1, TimeUnit.MINUTES).until(() -> result.getProcess() != null && !result.getProcess().isAlive());
        assertThat(running.log()).containsIgnoringCase(""BUILD SUCCESS"");
        running.stop();

        File output = new File(testDir, ""app/target/output.log"");
        output.createNewFile();

        Process process = doLaunch(new File(testDir, ""app/target/quarkus-app""), Paths.get(""quarkus-run.jar""), output,
                Collections.emptyList()).start();
        try {
            Assertions.assertEquals(""builder-image is customized"", DevModeTestUtils.getHttpResponse(""/hello""));
        } finally {
            process.destroy();
        }
    }
",non-flaky,5
76727,quarkusio_quarkus,JarRunnerIT.testPlatformPropertiesOverridenOnCommandLine,"    @Test
    public void testPlatformPropertiesOverridenOnCommandLine() throws Exception {
        final File testDir = initProject(""projects/platform-properties-overrides"",
                ""projects/platform-props-overriden-on-cmd-line"");
        final RunningInvoker running = new RunningInvoker(testDir, false);

        final MavenProcessInvocationResult result = running.execute(
                Arrays.asList(""install -Dquarkus.native.builder-image=commandline -DskipTests""),
                Collections.emptyMap());
        await().atMost(1, TimeUnit.MINUTES).until(() -> result.getProcess() != null && !result.getProcess().isAlive());
        assertThat(running.log()).containsIgnoringCase(""BUILD SUCCESS"");
        running.stop();

        File output = new File(testDir, ""app/target/output.log"");
        output.createNewFile();

        Process process = doLaunch(new File(testDir, ""app/target/quarkus-app""), Paths.get(""quarkus-run.jar""), output,
                Collections.emptyList()).start();
        try {
            Assertions.assertEquals(""builder-image is commandline"", DevModeTestUtils.getHttpResponse(""/hello""));
        } finally {
            process.destroy();
        }
    }
",non-flaky,5
76728,quarkusio_quarkus,JarRunnerIT.testThatFastJarFormatWorks,"    @Test
    public void testThatFastJarFormatWorks() throws Exception {
        assertThatFastJarFormatWorks(null);
    }
",non-flaky,5
76729,quarkusio_quarkus,JarRunnerIT.testThatFastJarCustomOutputDirFormatWorks,"    @Test
    public void testThatFastJarCustomOutputDirFormatWorks() throws Exception {
        assertThatFastJarFormatWorks(""custom"");
    }
",non-flaky,5
76730,quarkusio_quarkus,JarRunnerIT.testThatMutableFastJarWorks,"    @Test
    public void testThatMutableFastJarWorks() throws Exception {
        assertThatMutableFastJarWorks(""providers"", ""providers"");
    }
",non-flaky,5
76731,quarkusio_quarkus,JarRunnerIT.testThatMutableFastJarWorksProvidersDirOutsideOutputDir,"    @Test
    public void testThatMutableFastJarWorksProvidersDirOutsideOutputDir() throws Exception {
        assertThatMutableFastJarWorks(""outsidedir"", "".."" + File.separator + ""providers"");
    }
",non-flaky,5
76732,quarkusio_quarkus,JarRunnerIT.testThatLegacyJarFormatWorks,"    @Test
    public void testThatLegacyJarFormatWorks() throws Exception {
        File testDir = initProject(""projects/rr-with-json-logging"", ""projects/rr-with-json-logging-legacy-jar"");
        RunningInvoker running = new RunningInvoker(testDir, false);

        MavenProcessInvocationResult result = running
                .execute(Arrays.asList(""package"",
                        ""-DskipTests"",
                        ""-Dquarkus.package.type=legacy-jar""), Collections.emptyMap());

        await().atMost(1, TimeUnit.MINUTES).until(() -> result.getProcess() != null && !result.getProcess().isAlive());
        assertThat(running.log()).containsIgnoringCase(""BUILD SUCCESS"");
        running.stop();

        Path jar = testDir.toPath().toAbsolutePath()
                .resolve(Paths.get(""target"",
                        JarResultBuildStep.DEFAULT_FAST_JAR_DIRECTORY_NAME,
                        ""quarkus-run.jar""));
        Assertions.assertFalse(Files.exists(jar));

        jar = testDir.toPath().toAbsolutePath()
                .resolve(Paths.get(""target/acme-1.0-SNAPSHOT-runner.jar""));
        Assertions.assertTrue(Files.exists(jar));

        Properties quarkusArtifactProperties = new Properties();
        quarkusArtifactProperties
                .load(new FileInputStream(testDir.toPath().resolve(""target"").resolve(""quarkus-artifact.properties"").toFile()));
        Assertions.assertEquals(""jar"", quarkusArtifactProperties.get(""type""));
        Assertions.assertEquals(""acme-1.0-SNAPSHOT-runner.jar"", quarkusArtifactProperties.get(""path""));

        File output = new File(testDir, ""target/output.log"");
        output.createNewFile();

        Properties properties = new Properties();
        properties
                .load(new FileInputStream(testDir.toPath().resolve(""target"").resolve(""quarkus-artifact.properties"").toFile()));
        Assertions.assertEquals(""jar"", properties.get(""type""));
        Assertions.assertEquals(""acme-1.0-SNAPSHOT-runner.jar"", properties.get(""path""));

        Process process = doLaunch(jar, output).start();
        try {
            // Wait until server up
            dumpFileContentOnFailure(() -> {
                await()
                        .pollDelay(1, TimeUnit.SECONDS)
                        .atMost(1, TimeUnit.MINUTES).until(() -> DevModeTestUtils.getHttpResponse(""/app/hello/package"", 200));
                return null;
            }, output, ConditionTimeoutException.class);

            String logs = FileUtils.readFileToString(output, ""UTF-8"");

            assertThat(logs).isNotEmpty().contains(""resteasy-reactive"");

            // test that the application name and version are properly set
            assertApplicationPropertiesSetCorrectly();
            assertResourceReadingFromClassPathWorksCorrectly("""");
            assertUsingProtectionDomainWorksCorrectly("""");
        } finally {
            process.destroy();
        }
    }
",non-flaky,5
76733,quarkusio_quarkus,JarRunnerIT.testThatAppCDSAreUsable,"    @Test
    public void testThatAppCDSAreUsable() throws Exception {
        File testDir = initProject(""projects/classic"", ""projects/project-classic-console-output-appcds"");
        RunningInvoker running = new RunningInvoker(testDir, false);

        MavenProcessInvocationResult result = running
                .execute(Arrays.asList(""package"", ""-DskipTests"", ""-Dquarkus.package.create-appcds=true""),
                        Collections.emptyMap());

        await().atMost(1, TimeUnit.MINUTES).until(() -> result.getProcess() != null && !result.getProcess().isAlive());
        assertThat(running.log()).containsIgnoringCase(""BUILD SUCCESS"");
        running.stop();

        Path jar = testDir.toPath().toAbsolutePath()
                .resolve(Paths.get(""target/quarkus-app/quarkus-run.jar""));
        File output = new File(testDir, ""target/output.log"");
        output.createNewFile();

        // by using '-Xshare:on' we ensure that the JVM will fail if for any reason is cannot use the AppCDS
        // '-Xlog:class+path=info' will print diagnostic information that is useful for debugging if something goes wrong
        Process process = doLaunch(jar.getFileName(), output,
                Arrays.asList(""-XX:SharedArchiveFile=app-cds.jsa"", ""-Xshare:on"", ""-Xlog:class+path=info""))
                        .directory(jar.getParent().toFile()).start();
        try {
            // Wait until server up
            dumpFileContentOnFailure(() -> {
                await()
                        .pollDelay(1, TimeUnit.SECONDS)
                        .atMost(1, TimeUnit.MINUTES).until(() -> DevModeTestUtils.getHttpResponse(""/app/hello/package"", 200));
                return null;
            }, output, ConditionTimeoutException.class);

            String logs = FileUtils.readFileToString(output, ""UTF-8"");

            assertThatOutputWorksCorrectly(logs);
        } finally {
            process.destroy();
        }

    }
",non-flaky,5
76734,quarkusio_quarkus,JarRunnerIT.testArcExcludeDependencyOnLocalModule,"    @Test
    public void testArcExcludeDependencyOnLocalModule() throws Exception {
        File testDir = initProject(""projects/arc-exclude-dependencies"");
        RunningInvoker running = new RunningInvoker(testDir, false);

        MavenProcessInvocationResult result = running.execute(Arrays.asList(""package"", ""-DskipTests""), Collections.emptyMap());
        await().atMost(1, TimeUnit.MINUTES).until(() -> result.getProcess() != null && !result.getProcess().isAlive());
        assertThat(running.log()).containsIgnoringCase(""BUILD SUCCESS"");
        running.stop();

        File targetDir = new File(testDir.getAbsoluteFile(), ""runner"" + File.separator + ""target"");
        Path jar = targetDir.toPath().toAbsolutePath()
                .resolve(Paths.get(""quarkus-app/quarkus-run.jar""));
        File output = new File(targetDir, ""output.log"");
        output.createNewFile();

        Process process = doLaunch(jar, output).start();
        try {
            // Wait until server up
            AtomicReference<String> response = new AtomicReference<>();
            await()
                    .pollDelay(1, TimeUnit.SECONDS)
                    .atMost(1, TimeUnit.MINUTES).until(() -> {
                        String ret = DevModeTestUtils.getHttpResponse(""/hello"", true);
                        response.set(ret);
                        return ret.contains(""hello:"");
                    });

            // Test that bean is not resolvable
            assertThat(response.get()).containsIgnoringCase(""hello:false"");
        } finally {
            process.destroy();
        }
    }
",non-flaky,5
76735,quarkusio_quarkus,CreateExtensionMojoIT.testCreateCoreExtension,"    @Test
    public void testCreateCoreExtension(TestInfo testInfo) throws Throwable {
        testDir = initProject(""projects/create-extension-quarkus-core"", ""output/create-extension-quarkus-core"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""extensionId"", ""my-ext"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        final Path testDirPath = testDir.toPath();
        assertThatDirectoryTreeMatchSnapshots(testInfo, testDirPath)
                .contains(
                        ""extensions/my-ext/pom.xml"",
                        ""extensions/my-ext/runtime/src/main/resources/META-INF/quarkus-extension.yaml"",
                        ""extensions/my-ext/deployment/src/main/java/org/acme/my/ext/deployment/MyExtProcessor.java"",
                        ""integration-tests/my-ext/pom.xml"",
                        ""integration-tests/my-ext/src/test/java/org/acme/my/ext/it/MyExtResourceTest.java"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""extensions/my-ext/pom.xml"");
        assertThatMatchSnapshot(testInfo, testDirPath,
                ""extensions/my-ext/runtime/src/main/resources/META-INF/quarkus-extension.yaml"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""bom/application/pom.xml"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""integration-tests/pom.xml"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""extensions/pom.xml"");
    }
",non-flaky,5
76736,quarkusio_quarkus,CreateExtensionMojoIT.testCreateCoreExtensionFromExtensionsDir,"    @Test
    public void testCreateCoreExtensionFromExtensionsDir(TestInfo testInfo) throws Throwable {
        testDir = initProject(""projects/create-extension-quarkus-core"", ""output/create-extension-quarkus-core-extensions-dir"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir.toPath().resolve(""extensions/"").toFile());

        Properties properties = new Properties();
        properties.put(""extensionId"", ""quarkus-my-ext"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        final Path testDirPath = testDir.toPath();
        assertThatDirectoryTreeMatchSnapshots(testInfo, testDirPath)
                .contains(
                        ""extensions/my-ext/pom.xml"",
                        ""extensions/my-ext/deployment/src/main/java/org/acme/my/ext/deployment/MyExtProcessor.java"",
                        ""integration-tests/my-ext/pom.xml"",
                        ""integration-tests/my-ext/src/test/java/org/acme/my/ext/it/MyExtResourceTest.java"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""extensions/my-ext/pom.xml"");
        assertThatMatchSnapshot(testInfo, testDirPath,
                ""extensions/my-ext/runtime/src/main/resources/META-INF/quarkus-extension.yaml"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""bom/application/pom.xml"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""integration-tests/pom.xml"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""extensions/pom.xml"");
    }
",non-flaky,5
76737,quarkusio_quarkus,CreateExtensionMojoIT.testCreateQuarkiverseExtension,"    @Test
    public void testCreateQuarkiverseExtension(TestInfo testInfo) throws Throwable {
        testDir = initEmptyProject(""output/create-quarkiverse-extension"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""groupId"", ""io.quarkiverse.my-quarki-ext"");
        properties.put(""extensionId"", ""my-quarki-ext"");
        properties.put(""quarkusVersion"", ""1.10.5.Final"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        final Path testDirPath = testDir.toPath();
        assertThatDirectoryTreeMatchSnapshots(testInfo, testDirPath)
                .contains(
                        ""quarkus-my-quarki-ext/pom.xml"",
                        ""quarkus-my-quarki-ext/deployment/src/main/java/io/quarkiverse/my/quarki/ext/deployment/MyQuarkiExtProcessor.java"",
                        ""quarkus-my-quarki-ext/integration-tests/pom.xml"",
                        ""quarkus-my-quarki-ext/integration-tests/src/test/java/io/quarkiverse/my/quarki/ext/it/MyQuarkiExtResourceTest.java"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""quarkus-my-quarki-ext/pom.xml"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""quarkus-my-quarki-ext/runtime/pom.xml"");
    }
",non-flaky,5
76738,quarkusio_quarkus,CreateExtensionMojoIT.testCreateStandaloneExtension,"    @Test
    public void testCreateStandaloneExtension(TestInfo testInfo) throws Throwable {
        testDir = initEmptyProject(""output/create-standalone-extension"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""groupId"", ""io.standalone"");
        properties.put(""extensionId"", ""my-own-ext"");
        properties.put(""namespaceId"", ""my-org-"");
        properties.put(""quarkusVersion"", ""1.10.5.Final"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        final Path testDirPath = testDir.toPath();
        assertThatDirectoryTreeMatchSnapshots(testInfo, testDirPath)
                .contains(
                        ""my-org-my-own-ext/pom.xml"",
                        ""my-org-my-own-ext/deployment/src/main/java/io/standalone/my/own/ext/deployment/MyOwnExtProcessor.java"",
                        ""my-org-my-own-ext/integration-tests/pom.xml"",
                        ""my-org-my-own-ext/integration-tests/src/test/java/io/standalone/my/own/ext/it/MyOwnExtResourceTest.java"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""my-org-my-own-ext/pom.xml"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""my-org-my-own-ext/runtime/pom.xml"");
    }
",non-flaky,5
76739,quarkusio_quarkus,RemoteDevMojoIT.testThatTheApplicationIsReloadedOnJavaChange,"    @Test
    public void testThatTheApplicationIsReloadedOnJavaChange()
            throws MavenInvocationException, IOException, InterruptedException {
        testDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-java-change-remote"");
        agentDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-java-change-local"");
        runAndCheck();

        // Edit the ""Hello"" message.
        File source = new File(agentDir, ""src/main/java/org/acme/HelloResource.java"");
        String uuid = UUID.randomUUID().toString();
        filter(source, Collections.singletonMap(""return \""hello\"";"", ""return \"""" + uuid + ""\"";""));

        // Wait until we get ""uuid""
        await()
                .pollDelay(1, TimeUnit.SECONDS)
                .atMost(1, TimeUnit.MINUTES).until(() -> DevModeTestUtils.getHttpResponse(""/app/hello"").contains(uuid));

        await()
                .pollDelay(1, TimeUnit.SECONDS)
                .pollInterval(1, TimeUnit.SECONDS)
                .until(source::isFile);

        filter(source, Collections.singletonMap(uuid, ""carambar""));

        // Wait until we get ""carambar""
        await()
                .pollDelay(1, TimeUnit.SECONDS)
                .atMost(1, TimeUnit.MINUTES).until(() -> DevModeTestUtils.getHttpResponse(""/app/hello"").contains(""carambar""));

        //also verify that the dev ui console is disabled
        DevModeTestUtils.getHttpResponse(""/q/dev"", 404, 10, TimeUnit.SECONDS);
    }
",non-flaky,5
76740,quarkusio_quarkus,RemoteDevMojoIT.foo,"    @Test
    public void testThatTheApplicationIsReloadedOnNewResource() throws MavenInvocationException, IOException {
        testDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-new-resource-remote"");
        agentDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-new-resource-local"");
        runAndCheck();

        File source = new File(agentDir, ""src/main/java/org/acme/MyNewResource.java"");
        String myNewResource = ""package org.acme;\n"" +
                ""\n"" +
                ""import javax.ws.rs.GET;\n"" +
                ""import javax.ws.rs.Path;\n"" +
                ""import javax.ws.rs.Produces;\n"" +
                ""import javax.ws.rs.core.MediaType;\n"" +
                ""\n"" +
                ""@Path(\""/foo\"")\n"" +
                ""public class MyNewResource {\n"" +

                ""    @GET\n"" +
                ""    @Produces(MediaType.TEXT_PLAIN)\n"" +
                ""    public String foo() {\n"" +
                ""        return \""bar\"";\n"" +
                ""    }\n"" +
",non-flaky,5
76741,quarkusio_quarkus,RemoteDevMojoIT.testThatTheApplicationIsReloadedOnConfigChange,"    @Test
    public void testThatTheApplicationIsReloadedOnConfigChange() throws MavenInvocationException, IOException {
        testDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-config-change-remote"");
        agentDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-config-change-local"");
        assertThat(testDir).isDirectory();
        runAndCheck();

        String resp = DevModeTestUtils.getHttpResponse();
        runningAgent = new RunningInvoker(agentDir, false);
        runningAgent.execute(Arrays.asList(""compile"", ""quarkus:remote-dev""), Collections.emptyMap());

        assertThat(resp).containsIgnoringCase(""ready"").containsIgnoringCase(""application"").containsIgnoringCase(""org.acme"")
                .containsIgnoringCase(""1.0-SNAPSHOT"");

        String greeting = DevModeTestUtils.getHttpResponse(""/app/hello/greeting"");
        assertThat(greeting).containsIgnoringCase(""bonjour"");

        File source = new File(agentDir, ""src/main/resources/application.properties"");
        await()
                .pollDelay(1, TimeUnit.SECONDS)
                .pollInterval(1, TimeUnit.SECONDS)
                .until(source::isFile);

        String uuid = UUID.randomUUID().toString();
        filter(source, Collections.singletonMap(""bonjour"", uuid));

        // Wait until we get ""uuid""
        await()
                .pollDelay(1, TimeUnit.SECONDS)
                .atMost(1, TimeUnit.MINUTES)
                .until(() -> DevModeTestUtils.getHttpResponse(""/app/hello/greeting"").contains(uuid));
    }
",non-flaky,5
76742,quarkusio_quarkus,RemoteDevMojoIT.testThatNewResourcesAreServed,"    @Test
    public void testThatNewResourcesAreServed() throws MavenInvocationException, IOException {
        testDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-resource-change-remote"");
        agentDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-resource-change-local"");
        runAndCheck();

        // Create a new resource
        File source = new File(agentDir, ""src/main/resources/META-INF/resources/lorem.txt"");
        FileUtils.write(source,
                ""Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua."",
                ""UTF-8"");
        await()
                .pollDelay(1, TimeUnit.SECONDS)
                .atMost(1, TimeUnit.MINUTES)
                .until(() -> DevModeTestUtils.getHttpResponse(""/lorem.txt"").contains(""Lorem ipsum""));

        // Update the resource
        String uuid = UUID.randomUUID().toString();
        FileUtils.write(source, uuid, ""UTF-8"");
        await()
                .pollDelay(1, TimeUnit.SECONDS)
                .atMost(1, TimeUnit.MINUTES)
                .until(() -> DevModeTestUtils.getHttpResponse(""/lorem.txt"").contains(uuid));

        // Delete the resource
        //TODO: not supported yet in remote dev
        //        source.delete();
        //        await()
        //                .pollDelay(1, TimeUnit.SECONDS)
        //                .atMost(1, TimeUnit.MINUTES)
        //                .until(() -> getHttpResponse(""/lorem.txt"", 404));
    }
",non-flaky,5
76743,quarkusio_quarkus,RemoteDevMojoIT.testThatApplicationRecoversCompilationIssue,"    @Test
    public void testThatApplicationRecoversCompilationIssue() throws MavenInvocationException, IOException {
        testDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-compilation-issue-remote"");
        agentDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-compilation-issue-local"");
        runAndCheck();

        // Edit the ""Hello"" message.
        File source = new File(agentDir, ""src/main/java/org/acme/HelloResource.java"");
        String uuid = UUID.randomUUID().toString();
        filter(source, Collections.singletonMap(""return \""hello\"";"", ""return \"""" + uuid + ""\"""")); // No semi-colon

        // Wait until we get ""uuid""
        AtomicReference<String> last = new AtomicReference<>();
        await()
                .pollDelay(1, TimeUnit.SECONDS)
                .atMost(1, TimeUnit.MINUTES).until(() -> {
                    String content = DevModeTestUtils.getHttpResponse(""/app/hello"", true);
                    last.set(content);
                    return content.contains(uuid);
                });

        assertThat(last.get()).containsIgnoringCase(""error"")
                .containsIgnoringCase(""return \"""" + uuid + ""\"""")
                .containsIgnoringCase(""compile"");

        await()
                .pollDelay(1, TimeUnit.SECONDS)
                .pollInterval(1, TimeUnit.SECONDS)
                .until(source::isFile);
        filter(source, Collections.singletonMap(""\"""" + uuid + ""\"""", ""\""carambar\"";""));

        // Wait until we get ""uuid""
        await()
                .pollDelay(1, TimeUnit.SECONDS)
                .atMost(1, TimeUnit.MINUTES).until(() -> DevModeTestUtils.getHttpResponse(""/app/hello"").contains(""carambar""));
    }
",non-flaky,5
76744,quarkusio_quarkus,RemoteDevMojoIT.get,"    @Test
    public void testThatNewBeanAreDiscovered() throws IOException, MavenInvocationException {
        testDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-new-bean-remote"");
        agentDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-run-new-bean-local"");
        runAndCheck();

        // Edit the ""Hello"" message.
        File source = new File(agentDir, ""src/main/java/org/acme/MyBean.java"");
        String content = ""package org.acme;\n"" +
                ""\n"" +
                ""import javax.enterprise.context.ApplicationScoped;\n"" +
                ""\n"" +
                ""@ApplicationScoped\n"" +
                ""public class MyBean {\n"" +
                ""\n"" +
                ""    public String get() {\n"" +
                ""        return \""message\"";\n"" +
                ""    }\n"" +
",non-flaky,5
76745,quarkusio_quarkus,CreateJBangProjectMojoIT.testProjectGeneration,"    @Test
    public void testProjectGeneration() throws MavenInvocationException, IOException {
        testDir = initEmptyProject(""projects/project-generation"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""outputDirectory"", ""jbang"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();
    }
",non-flaky,5
76746,quarkusio_quarkus,CreateProjectMojoIT.testProjectGenerationFromScratch,"    @Test
    public void testProjectGenerationFromScratch() throws MavenInvocationException, IOException {
        testDir = initEmptyProject(""projects/project-generation"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""org.acme"");
        properties.put(""projectArtifactId"", ""acme"");
        properties.put(""projectVersion"", ""1.0.0-SNAPSHOT"");

        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        // As the directory is not empty (log) navigate to the artifactID directory
        testDir = new File(testDir, ""acme"");

        assertThat(new File(testDir, ""pom.xml"")).isFile();
        assertThat(new File(testDir, ""src/main/java"")).isDirectory();
        assertThat(new File(testDir, ""src/main/resources/application.properties"")).isFile();

        String config = Files
                .asCharSource(new File(testDir, ""src/main/resources/application.properties""), Charsets.UTF_8)
                .read();
        assertThat(config).isEmpty();

        assertThat(new File(testDir, ""src/main/docker/Dockerfile.native"")).isFile();
        assertThat(new File(testDir, ""src/main/docker/Dockerfile.jvm"")).isFile();

        Model model = loadPom(testDir);
        final DependencyManagement dependencyManagement = model.getDependencyManagement();
        final List<Dependency> dependencies = dependencyManagement.getDependencies();
        assertThat(dependencies.stream()
                .anyMatch(d -> d.getArtifactId().equals(MojoUtils.TEMPLATE_PROPERTY_QUARKUS_PLATFORM_ARTIFACT_ID_VALUE)
                        && d.getVersion().equals(MojoUtils.TEMPLATE_PROPERTY_QUARKUS_PLATFORM_VERSION_VALUE)
                        && d.getScope().equals(""import"")
                        && d.getType().equals(""pom""))).isTrue();

        assertThat(
                model.getDependencies().stream().anyMatch(d -> d.getArtifactId().equalsIgnoreCase(""quarkus-resteasy"")
                        && d.getVersion() == null)).isTrue();

        assertThat(model.getProfiles()).hasSize(1);
        assertThat(model.getProfiles().get(0).getId()).isEqualTo(""native"");

        Xpp3Dom surefireSystemProperties = Optional.ofNullable(model.getBuild())
                .map(Build::getPlugins)
                .flatMap(plugins -> plugins.stream().filter(p -> p.getArtifactId().equals(""maven-surefire-plugin"")).findFirst())
                .map(Plugin::getConfiguration)
                .map(Xpp3Dom.class::cast)
                .map(cfg -> cfg.getChild(""systemPropertyVariables""))
                .orElse(null);
        assertThat(surefireSystemProperties).isNotNull();
        assertThat(surefireSystemProperties.getChild(""java.util.logging.manager""))
                .returns(LogManager.class.getName(), from(Xpp3Dom::getValue));
        assertThat(surefireSystemProperties.getChild(""maven.home""))
                .returns(""${maven.home}"", from(Xpp3Dom::getValue));
    }
",non-flaky,5
76747,quarkusio_quarkus,CreateProjectMojoIT.testProjectGenerationWithExistingPomFileWithPackagingJarShouldFail,"    @Test
    public void testProjectGenerationWithExistingPomFileWithPackagingJarShouldFail() throws Exception {
        testDir = initProject(""projects/simple-pom-it"", ""projects/project-generation-from-empty-pom"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);
        InvocationResult result = setup(new Properties());

        assertThat(result.getExitCode()).isOne();
    }
",non-flaky,5
76748,quarkusio_quarkus,CreateProjectMojoIT.testProjectGenerationWithExistingGradleFileShouldFail,"    @Test
    public void testProjectGenerationWithExistingGradleFileShouldFail() throws Exception {
        testDir = initProject(""projects/parent-gradle-it"", ""projects/project-generation-from-parent-gradle"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);
        InvocationResult result = setup(new Properties());

        assertThat(result.getExitCode()).isOne();
    }
",non-flaky,5
76749,quarkusio_quarkus,CreateProjectMojoIT.testGradleProjectGenerationWithExistingGradleFileShouldFail,"    @Test
    public void testGradleProjectGenerationWithExistingGradleFileShouldFail() throws Exception {
        testDir = initProject(""projects/parent-gradle-it"", ""projects/gradle-project-generation-from-parent-gradle"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);
        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""org.acme"");
        properties.put(""projectArtifactId"", ""acme"");
        properties.put(""className"", ""org.acme.MyResource"");
        properties.put(""buildTool"", ""gradle"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isOne();
    }
",non-flaky,5
76750,quarkusio_quarkus,CreateProjectMojoIT.testGradleProjectGenerationWithExistingPomFileShouldFail,"    @Test
    public void testGradleProjectGenerationWithExistingPomFileShouldFail() throws Exception {
        testDir = initProject(""projects/parent-pom-it"", ""projects/gradle-project-generation-from-parent-pom"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);
        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""org.acme"");
        properties.put(""projectArtifactId"", ""acme"");
        properties.put(""className"", ""org.acme.MyResource"");
        properties.put(""buildTool"", ""gradle"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isOne();
    }
",non-flaky,5
76751,quarkusio_quarkus,CreateProjectMojoIT.testProjectGenerationAsModuleWithExistingPomFileWithPackagingPom,"    @Test
    public void testProjectGenerationAsModuleWithExistingPomFileWithPackagingPom() throws Exception {
        testDir = initProject(""projects/parent-pom-it"", ""projects/project-generation-from-parent-pom"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        String projectArtifactId = ""acme"";
        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""io.acme.it"");
        properties.put(""projectArtifactId"", projectArtifactId);
        properties.put(""projectVersion"", ""1.0-SNAPSHOT"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        Model parentPomModel = loadPom(testDir);
        assertThat(parentPomModel.getModules()).isNotEmpty();
        assertThat(parentPomModel.getModules()).contains(projectArtifactId);

        Model modulePomModel = loadPom(new File(testDir, projectArtifactId));
        assertThat(modulePomModel.getParent()).isNotNull();
        assertThat(modulePomModel.getParent().getGroupId()).isEqualTo(""io.acme.it"");
        assertThat(modulePomModel.getParent().getArtifactId()).isEqualTo(""acme-parent-pom"");
        assertThat(modulePomModel.getParent().getVersion()).isEqualTo(""0.0.1.BUILD-SNAPSHOT"");
    }
",non-flaky,5
76752,quarkusio_quarkus,CreateProjectMojoIT.testProjectGenerationFromScratchWithResource,"    @Test
    public void testProjectGenerationFromScratchWithResource() throws Exception {
        testDir = initEmptyProject(""projects/project-generation-with-resource"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""org.acme"");
        properties.put(""projectArtifactId"", ""acme"");
        properties.put(""className"", ""org.acme.MyResource.java"");
        properties.put(""extensions"", ""resteasy"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        // As the directory is not empty (log) navigate to the artifactID directory
        testDir = new File(testDir, ""acme"");

        assertThat(new File(testDir, ""pom.xml"")).isFile();
        assertThat(new File(testDir, ""src/main/java"")).isDirectory();

        check(new File(testDir, ""src/main/java/org/acme/MyResource.java""), ""package org.acme;"");
    }
",non-flaky,5
76753,quarkusio_quarkus,CreateProjectMojoIT.testProjectGenerationWithInvalidPackage,"    @Test
    public void testProjectGenerationWithInvalidPackage() throws Exception {
        testDir = initEmptyProject(""projects/project-generation-invalid-package"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""org.acme"");
        properties.put(""projectArtifactId"", ""acme"");
        properties.put(""className"", ""org.acme.invalid-package-name.MyResource"");

        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isNotZero();
        assertThat(new File(testDir, ""src/main/java/org/acme"")).doesNotExist();
    }
",non-flaky,5
76754,quarkusio_quarkus,CreateProjectMojoIT.testProjectGenerationFromScratchWithMissingExtensionShouldFail,"    @Test
    public void testProjectGenerationFromScratchWithMissingExtensionShouldFail() throws Exception {
        testDir = initEmptyProject(""projects/project-generation-with-missing-extension"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""org.acme"");
        properties.put(""projectArtifactId"", ""acme"");
        properties.put(""className"", ""org.acme.MyResource"");
        properties.put(""extensions"", ""resteasy,smallrye-metrics,missing"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isOne();
    }
",non-flaky,5
76755,quarkusio_quarkus,CreateProjectMojoIT.testProjectGenerationFromScratchWithExtensions,"    @Test
    public void testProjectGenerationFromScratchWithExtensions() throws Exception {
        testDir = initEmptyProject(""projects/project-generation-with-resources-and-extension"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""org.acme"");
        properties.put(""projectArtifactId"", ""acme"");
        properties.put(""className"", ""org.acme.MyResource"");
        properties.put(""extensions"", ""resteasy,smallrye-metrics"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        // As the directory is not empty (log) navigate to the artifactID directory
        testDir = new File(testDir, ""acme"");

        assertThat(new File(testDir, ""pom.xml"")).isFile();
        assertThat(new File(testDir, ""src/main/java"")).isDirectory();

        check(new File(testDir, ""src/main/java/org/acme/MyResource.java""), ""package org.acme;"");

        assertThat(FileUtils.readFileToString(new File(testDir, ""pom.xml""), ""UTF-8""))
                .contains(""quarkus-resteasy"", ""quarkus-smallrye-metrics"").doesNotContain(""missing"");

        Model model = loadPom(testDir);
        assertThat(model.getDependencyManagement().getDependencies().stream()
                .anyMatch(d -> d.getArtifactId().equals(MojoUtils.TEMPLATE_PROPERTY_QUARKUS_PLATFORM_ARTIFACT_ID_VALUE)
                        && d.getVersion().equals(MojoUtils.TEMPLATE_PROPERTY_QUARKUS_PLATFORM_VERSION_VALUE)
                        && d.getScope().equals(""import"")
                        && d.getType().equals(""pom""))).isTrue();

        assertThat(
                model.getDependencies().stream().anyMatch(d -> d.getArtifactId().equalsIgnoreCase(""quarkus-resteasy"")
                        && d.getVersion() == null)).isTrue();

        assertThat(model.getDependencies().stream()
                .anyMatch(d -> d.getArtifactId().equalsIgnoreCase(""quarkus-smallrye-metrics"")
                        && d.getVersion() == null)).isTrue();
    }
",non-flaky,5
76756,quarkusio_quarkus,CreateProjectMojoIT.testGradleProjectGenerationFromScratchWithExtensions,"    @Test
    public void testGradleProjectGenerationFromScratchWithExtensions() throws Exception {
        testDir = initEmptyProject(""projects/gradle-project-generation-with-extensions"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""org.acme"");
        properties.put(""projectArtifactId"", ""acme"");
        properties.put(""className"", ""org.acme.MyResource"");
        properties.put(""extensions"", ""kotlin,resteasy,jackson"");
        properties.put(""buildTool"", ""gradle"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        // As the directory is not empty (log) navigate to the artifactID directory
        testDir = new File(testDir, ""acme"");

        assertThat(new File(testDir, ""build.gradle"")).isFile();
        assertThat(new File(testDir, ""gradlew.bat"")).isFile();
        assertThat(new File(testDir, ""gradlew"")).isFile();
        assertThat(new File(testDir, ""gradle/wrapper"")).isDirectory();
        assertThat(new File(testDir, ""src/main/kotlin"")).isDirectory();

        check(new File(testDir, ""src/main/kotlin/org/acme/MyResource.kt""), ""package org.acme"");

        assertThat(FileUtils.readFileToString(new File(testDir, ""build.gradle""), ""UTF-8""))
                .contains(""quarkus-kotlin"", ""quarkus-jackson"").doesNotContain(""missing"");
    }
",non-flaky,5
76757,quarkusio_quarkus,CreateProjectMojoIT.testProjectGenerationFromScratchWithCustomDependencies,"    @Test
    public void testProjectGenerationFromScratchWithCustomDependencies() throws Exception {
        testDir = initEmptyProject(""projects/project-generation-with-resource-and-custom-deps"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""org.acme"");
        properties.put(""projectArtifactId"", ""acme"");
        properties.put(""className"", ""org.acme.MyResource"");
        properties.put(""extensions"", ""resteasy,commons-io:commons-io:2.5"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        // As the directory is not empty (log) navigate to the artifactID directory
        testDir = new File(testDir, ""acme"");

        assertThat(new File(testDir, ""pom.xml"")).isFile();
        assertThat(new File(testDir, ""src/main/java/org/acme/MyResource.java"")).isFile();
        assertThat(FileUtils.readFileToString(new File(testDir, ""pom.xml""), ""UTF-8""))
                .contains(""commons-io"");

        Model model = loadPom(testDir);
        assertThat(model.getDependencyManagement().getDependencies().stream()
                .anyMatch(d -> d.getArtifactId().equals(MojoUtils.TEMPLATE_PROPERTY_QUARKUS_PLATFORM_ARTIFACT_ID_VALUE)
                        && d.getVersion().equals(MojoUtils.TEMPLATE_PROPERTY_QUARKUS_PLATFORM_VERSION_VALUE)
                        && d.getScope().equals(""import"")
                        && d.getType().equals(""pom""))).isTrue();

        assertThat(
                model.getDependencies().stream().anyMatch(d -> d.getArtifactId().equalsIgnoreCase(""quarkus-resteasy"")
                        && d.getVersion() == null)).isTrue();

        assertThat(model.getDependencies().stream().anyMatch(d -> d.getArtifactId().equalsIgnoreCase(""commons-io"")
                && d.getVersion().equalsIgnoreCase(""2.5""))).isTrue();
    }
",non-flaky,5
76758,quarkusio_quarkus,CreateProjectMojoIT.testProjectGenerationFromScratchWithAppConfigParameter,"    @Test
    public void testProjectGenerationFromScratchWithAppConfigParameter() throws MavenInvocationException, IOException {
        testDir = initEmptyProject(""projects/project-generation-with-config-param"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""org.acme"");
        properties.put(""projectArtifactId"", ""acme"");
        properties.put(""projectVersion"", ""1.0.0-SNAPSHOT"");

        List<String> configs = Arrays.asList(""custom.app.config1=val1"",
                ""custom.app.config2=val2"", ""lib.config=val3"");
        properties.put(""appConfig"", StringUtils.join(configs, "", ""));

        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        // As the directory is not empty (log) navigate to the artifactID directory
        testDir = new File(testDir, ""acme"");

        assertThat(new File(testDir, ""pom.xml"")).isFile();
        assertThat(new File(testDir, ""src/main/java"")).isDirectory();

        String file = Files
                .asCharSource(new File(testDir, ""src/main/resources/application.properties""), Charsets.UTF_8)
                .read();
        configs.forEach(conf -> Assertions.assertTrue(file.contains(conf)));

    }
",non-flaky,5
76759,quarkusio_quarkus,CreateProjectMojoIT.testThatDefaultPackageAreReplaced,"    @Test
    public void testThatDefaultPackageAreReplaced() throws Exception {
        testDir = initEmptyProject(""projects/default-package-test"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""className"", ""MyGreatResource"");
        properties.put(""extensions"", ""resteasy"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();
        // As the directory is not empty (log) navigate to the artifactID directory
        testDir = new File(testDir, ""code-with-quarkus"");
        check(new File(testDir, ""src/main/java/org/acme/MyGreatResource.java""),
                ""package org.acme;"");
    }
",non-flaky,5
76760,quarkusio_quarkus,CreateProjectMojoIT.cleanup,"    @AfterEach
    public void cleanup() {
        if (running != null) {
            running.stop();
        }
    }
",non-flaky,5
76761,quarkusio_quarkus,CreateProjectMojoIT.generateNewProjectAndRun,"    @Test
    public void generateNewProjectAndRun() throws Exception {
        testDir = initEmptyProject(""projects/project-generation-and-run"");

        // Scaffold the new project
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""org.acme"");
        properties.put(""projectArtifactId"", ""acme"");
        properties.put(""extensions"", ""resteasy"");
        properties.put(""className"", ""org.acme.HelloResource"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        // Run
        // As the directory is not empty (log) navigate to the artifactID directory
        testDir = new File(testDir, ""acme"");
        running = new RunningInvoker(testDir, false);
        final Properties mvnRunProps = new Properties();
        mvnRunProps.setProperty(""debug"", ""false"");
        running.execute(Arrays.asList(""compile"", ""quarkus:dev""), Collections.emptyMap(), mvnRunProps);

        String resp = DevModeTestUtils.getHttpResponse();

        assertThat(resp).containsIgnoringCase(""ready"").containsIgnoringCase(""application"").containsIgnoringCase(""org.acme"")
                .containsIgnoringCase(""1.0.0-SNAPSHOT"");

        String greeting = DevModeTestUtils.getHttpResponse(""/hello"");
        assertThat(greeting).containsIgnoringCase(""hello"");
    }
",non-flaky,5
76762,quarkusio_quarkus,NativeImageIT.testJavaLibraryPathAtRuntime,"    @Test
    public void testJavaLibraryPathAtRuntime() throws Exception {
        final File testDir = initProject(""projects/native-image-app"", ""projects/native-image-app-output"");
        final RunningInvoker running = new RunningInvoker(testDir, false);

        // trigger mvn package -Pnative -Dquarkus.ssl.native=true
        final String[] mvnArgs = new String[] { ""package"", ""-DskipTests"", ""-Pnative"", ""-Dquarkus.ssl.native=true"" };
        final MavenProcessInvocationResult result = running.execute(Arrays.asList(mvnArgs), Collections.emptyMap());
        await().atMost(10, TimeUnit.MINUTES).until(() -> result.getProcess() != null && !result.getProcess().isAlive());
        final String processLog = running.log();
        try {
            assertThat(processLog).containsIgnoringCase(""BUILD SUCCESS"");
        } catch (AssertionError ae) {
            // skip this test (instead of failing), if the native-image command wasn't available.
            // Bit brittle to rely on the log message, but it's OK in the context of this test
            Assumptions.assumeFalse(processLog.contains(""Cannot find the `native-image""),
                    ""Skipping test since native-image tool isn't available"");
            // native-image command was available but the build failed for some reason, throw the original error
            throw ae;
        } finally {
            running.stop();
        }

        // now that the native image is built, run it
        final Path nativeImageRunner = testDir.toPath().toAbsolutePath().resolve(Paths.get(""target/acme-1.0-SNAPSHOT-runner""));
        final Path tmpDir = Files.createTempDirectory(""native-image-test"");
        tmpDir.toFile().deleteOnExit();
        final Process nativeImageRunWithAdditionalLibPath = runNativeImage(nativeImageRunner,
                new String[] { ""-Djava.library.path="" + tmpDir.toString() });
        try {
            final String response = DevModeTestUtils.getHttpResponse(""/hello/javaLibraryPath"");
            Assertions.assertTrue(response.contains(tmpDir.toString()),
                    ""Response "" + response + "" for java.library.path was expected to contain the "" + tmpDir + "", but didn't"");
        } finally {
            nativeImageRunWithAdditionalLibPath.destroy();
        }

    }
",non-flaky,5
76763,quarkusio_quarkus,PackageIT.testUberJarMavenPluginConfiguration,"    @Test
    public void testUberJarMavenPluginConfiguration()
            throws MavenInvocationException, IOException, InterruptedException {
        testDir = initProject(""projects/uberjar-maven-plugin-config"");
        running = new RunningInvoker(testDir, false);
        final MavenProcessInvocationResult result = running.execute(Collections.singletonList(""package""),
                Collections.emptyMap());
        assertThat(result.getProcess().waitFor()).isEqualTo(0);

        verifyUberJar();
    }
",non-flaky,5
76764,quarkusio_quarkus,PackageIT.testQuarkusPackageOutputDirectory,"    @Test
    public void testQuarkusPackageOutputDirectory()
            throws MavenInvocationException, IOException, InterruptedException {
        testDir = initProject(""projects/quarkus.package.output-directory"");

        running = new RunningInvoker(testDir, false);
        // we do want to run the tests too
        final MavenProcessInvocationResult result = running.execute(Collections.singletonList(""package""),
                Collections.emptyMap());

        assertThat(result.getProcess().waitFor()).isEqualTo(0);

        File targetDir = getTargetDir();
        List<File> jars = getFilesEndingWith(targetDir, "".jar"");
        assertThat(jars).hasSize(1);

        targetDir = new File(targetDir, ""custom-output-dir"");
        assertThat(targetDir).exists();
        jars = getFilesEndingWith(targetDir, "".jar"");
        assertThat(jars).hasSize(1);
    }
",non-flaky,5
76765,quarkusio_quarkus,PackageIT.testDependencyOnPomMutableJar,"    @Test
    public void testDependencyOnPomMutableJar()
            throws MavenInvocationException, IOException, InterruptedException {
        testDir = initProject(""projects/dependency-on-pom"");

        running = new RunningInvoker(testDir, false);
        // we do want to run the tests too
        final MavenProcessInvocationResult result = running.execute(Collections.singletonList(""package""),
                Collections.emptyMap());

        assertThat(result.getProcess().waitFor()).isEqualTo(0);

        File targetDir = getTargetDir();
        List<File> jars = getFilesEndingWith(targetDir, "".jar"");
        assertThat(jars).hasSize(1);
    }
",non-flaky,5
76766,quarkusio_quarkus,PackageIT.testPackageWorksWhenUberjarIsTrue,"    @Test
    public void testPackageWorksWhenUberjarIsTrue()
            throws MavenInvocationException, IOException, InterruptedException {
        testDir = initProject(""projects/uberjar-check"");

        createAndVerifyUberJar();
        // ensure that subsequent package without clean also works
        createAndVerifyUberJar();
    }
",non-flaky,5
76767,quarkusio_quarkus,PackageIT.testCustomPackaging,"    @Test
    public void testCustomPackaging()
            throws Exception {
        testDir = getTargetDir(""projects/custom-packaging-plugin"");

        running = new RunningInvoker(testDir, false);
        MavenProcessInvocationResult result = running.execute(Collections.singletonList(""install""),
                Collections.emptyMap());
        assertThat(result.getProcess().waitFor()).isEqualTo(0);

        testDir = getTargetDir(""projects/custom-packaging-app"");

        running = new RunningInvoker(testDir, false);
        result = running.execute(Collections.singletonList(""package""),
                Collections.emptyMap());
        assertThat(result.getProcess().waitFor()).isEqualTo(0);

        final File targetDir = getTargetDir();
        final File[] files = targetDir.listFiles(f -> f.getName().endsWith("".jar""));
        Set<String> jarNames = new HashSet<>(files.length);
        for (File f : files) {
            jarNames.add(f.getName());
        }

        final Path runnerJar = getTargetDir().toPath().resolve(""quarkus-app"").resolve(""quarkus-run.jar"");
        Assertions.assertTrue(Files.exists(runnerJar), ""Runner jar "" + runnerJar + "" is missing"");
        assertZipEntriesCanBeOpenedAndClosed(runnerJar);
    }
",non-flaky,5
76768,quarkusio_quarkus,PackageIT.testRunnerUberJarHasValidCRC,"    @Test
    public void testRunnerUberJarHasValidCRC() throws Exception {
        testDir = initProject(""projects/uberjar-check"", ""projects/project-uberjar-crc"");

        running = new RunningInvoker(testDir, false);

        Properties p = new Properties();
        p.setProperty(""quarkus.package.type"", ""uber-jar"");
        final MavenProcessInvocationResult result = running.execute(Collections.singletonList(""package""),
                Collections.emptyMap(), p);
        assertThat(result.getProcess().waitFor()).isEqualTo(0);

        final File targetDir = getTargetDir();
        assertThat(getNumberOfFilesEndingWith(targetDir, "".jar"")).isEqualTo(1);
        assertThat(getNumberOfFilesEndingWith(targetDir, "".original"")).isEqualTo(1);

        final Path runnerJar = targetDir.toPath().resolve(""acme-1.0-SNAPSHOT-runner.jar"");
        Assertions.assertTrue(Files.exists(runnerJar), ""Runner jar "" + runnerJar + "" is missing"");
        assertZipEntriesCanBeOpenedAndClosed(runnerJar);
    }
",non-flaky,5
76769,quarkusio_quarkus,PackageIT.testLegacyJarHasValidCRC,"    @Test
    public void testLegacyJarHasValidCRC() throws Exception {
        testDir = initProject(""projects/uberjar-check"", ""projects/project-legacyjar-crc"");

        running = new RunningInvoker(testDir, false);
        final MavenProcessInvocationResult result = running.execute(Collections.singletonList(""package""),
                Collections.singletonMap(""QUARKUS_PACKAGE_TYPE"", ""legacy-jar""));

        assertThat(result.getProcess().waitFor()).isEqualTo(0);

        final File targetDir = getTargetDir();
        assertThat(getNumberOfFilesEndingWith(targetDir, "".jar"")).isEqualTo(2);

        final Path runnerJar = targetDir.toPath().resolve(""acme-1.0-SNAPSHOT-runner.jar"");
        Assertions.assertTrue(Files.exists(runnerJar), ""Runner jar "" + runnerJar + "" is missing"");
        assertZipEntriesCanBeOpenedAndClosed(runnerJar);
    }
",non-flaky,5
76770,quarkusio_quarkus,PackageIT.testFastJarHasValidCRC,"    @Test
    public void testFastJarHasValidCRC() throws Exception {
        testDir = initProject(""projects/uberjar-check"", ""projects/project-fastjar-crc"");

        running = new RunningInvoker(testDir, false);
        final MavenProcessInvocationResult result = running.execute(Collections.singletonList(""package""),
                Collections.emptyMap());

        assertThat(result.getProcess().waitFor()).isEqualTo(0);

        final Path runnerJar = getTargetDir().toPath().resolve(""quarkus-app"").resolve(""quarkus-run.jar"");
        Assertions.assertTrue(Files.exists(runnerJar), ""Runner jar "" + runnerJar + "" is missing"");
        assertZipEntriesCanBeOpenedAndClosed(runnerJar);
    }
",non-flaky,5
76771,quarkusio_quarkus,PackageIT.testQuarkusIndexDependencyOnLocalModule,"    @Test
    public void testQuarkusIndexDependencyOnLocalModule() throws Exception {
        testDir = initProject(""projects/quarkus-index-dependencies"");

        running = new RunningInvoker(testDir, false);
        final MavenProcessInvocationResult result = running.execute(Collections.singletonList(""package""),
                Collections.emptyMap());

        assertThat(result.getProcess().waitFor()).isEqualTo(0);

        final File targetDir = new File(testDir.getAbsoluteFile(), ""runner"" + File.separator + ""target"");

        final Path runnerJar = targetDir.toPath().resolve(""quarkus-app"").resolve(""quarkus-run.jar"");
        Assertions.assertTrue(Files.exists(runnerJar), ""Runner jar "" + runnerJar + "" is missing"");
        assertZipEntriesCanBeOpenedAndClosed(runnerJar);
    }
",non-flaky,5
78232,apache_beam,SimplePushbackSideInputDoFnRunnerTest.startFinishBundleDelegates,"  @Test
  public void startFinishBundleDelegates() {
    PushbackSideInputDoFnRunner runner = createRunner(ImmutableList.of(singletonView));

    assertThat(underlying.started, is(true));
    assertThat(underlying.finished, is(false));
    runner.finishBundle();
    assertThat(underlying.finished, is(true));
  }
",non-flaky,5
78233,apache_beam,SimplePushbackSideInputDoFnRunnerTest.processElementSideInputNotReady,"  @Test
  public void processElementSideInputNotReady() {
    when(reader.isReady(Mockito.eq(singletonView), Mockito.any(BoundedWindow.class)))
        .thenReturn(false);

    SimplePushbackSideInputDoFnRunner<Integer, Integer> runner =
        createRunner(ImmutableList.of(singletonView));

    WindowedValue<Integer> oneWindow =
        WindowedValue.of(
            2,
            new Instant(-2),
            new IntervalWindow(new Instant(-500L), new Instant(0L)),
            PaneInfo.ON_TIME_AND_ONLY_FIRING);
    Iterable<WindowedValue<Integer>> oneWindowPushback =
        runner.processElementInReadyWindows(oneWindow);
    assertThat(oneWindowPushback, containsInAnyOrder(oneWindow));
    assertThat(underlying.inputElems, emptyIterable());
  }
",non-flaky,5
78234,apache_beam,SimplePushbackSideInputDoFnRunnerTest.processElementSideInputNotReadyMultipleWindows,"  @Test
  public void processElementSideInputNotReadyMultipleWindows() {
    when(reader.isReady(Mockito.eq(singletonView), Mockito.any(BoundedWindow.class)))
        .thenReturn(false);

    SimplePushbackSideInputDoFnRunner<Integer, Integer> runner =
        createRunner(ImmutableList.of(singletonView));

    WindowedValue<Integer> multiWindow =
        WindowedValue.of(
            2,
            new Instant(-2),
            ImmutableList.of(
                new IntervalWindow(new Instant(-500L), new Instant(0L)),
                new IntervalWindow(BoundedWindow.TIMESTAMP_MIN_VALUE, new Instant(250L)),
                GlobalWindow.INSTANCE),
            PaneInfo.ON_TIME_AND_ONLY_FIRING);
    Iterable<WindowedValue<Integer>> multiWindowPushback =
        runner.processElementInReadyWindows(multiWindow);
    assertThat(multiWindowPushback, equalTo(multiWindow.explodeWindows()));
    assertThat(underlying.inputElems, emptyIterable());
  }
",non-flaky,5
78235,apache_beam,SimplePushbackSideInputDoFnRunnerTest.processElementSideInputNotReadySomeWindows,"  @Test
  public void processElementSideInputNotReadySomeWindows() {
    when(reader.isReady(Mockito.eq(singletonView), Mockito.eq(GlobalWindow.INSTANCE)))
        .thenReturn(false);
    when(reader.isReady(
            Mockito.eq(singletonView),
            org.mockito.AdditionalMatchers.not(Mockito.eq(GlobalWindow.INSTANCE))))
        .thenReturn(true);

    SimplePushbackSideInputDoFnRunner<Integer, Integer> runner =
        createRunner(ImmutableList.of(singletonView));

    IntervalWindow littleWindow = new IntervalWindow(new Instant(-500L), new Instant(0L));
    IntervalWindow bigWindow =
        new IntervalWindow(BoundedWindow.TIMESTAMP_MIN_VALUE, new Instant(250L));
    WindowedValue<Integer> multiWindow =
        WindowedValue.of(
            2,
            new Instant(-2),
            ImmutableList.of(littleWindow, bigWindow, GlobalWindow.INSTANCE),
            PaneInfo.NO_FIRING);
    Iterable<WindowedValue<Integer>> multiWindowPushback =
        runner.processElementInReadyWindows(multiWindow);
    assertThat(
        multiWindowPushback,
        containsInAnyOrder(WindowedValue.timestampedValueInGlobalWindow(2, new Instant(-2L))));
    assertThat(
        underlying.inputElems,
        containsInAnyOrder(
            WindowedValue.of(
                2, new Instant(-2), ImmutableList.of(littleWindow), PaneInfo.NO_FIRING),
            WindowedValue.of(2, new Instant(-2), ImmutableList.of(bigWindow), PaneInfo.NO_FIRING)));
  }
",non-flaky,5
78236,apache_beam,SimplePushbackSideInputDoFnRunnerTest.processElementSideInputReadyAllWindows,"  @Test
  public void processElementSideInputReadyAllWindows() {
    when(reader.isReady(Mockito.eq(singletonView), Mockito.any(BoundedWindow.class)))
        .thenReturn(true);

    ImmutableList<PCollectionView<?>> views = ImmutableList.of(singletonView);
    SimplePushbackSideInputDoFnRunner<Integer, Integer> runner = createRunner(views);

    WindowedValue<Integer> multiWindow =
        WindowedValue.of(
            2,
            new Instant(-2),
            ImmutableList.of(
                new IntervalWindow(new Instant(-500L), new Instant(0L)),
                new IntervalWindow(BoundedWindow.TIMESTAMP_MIN_VALUE, new Instant(250L)),
                GlobalWindow.INSTANCE),
            PaneInfo.ON_TIME_AND_ONLY_FIRING);
    Iterable<WindowedValue<Integer>> multiWindowPushback =
        runner.processElementInReadyWindows(multiWindow);
    assertThat(multiWindowPushback, emptyIterable());
    assertThat(
        underlying.inputElems,
        containsInAnyOrder(ImmutableList.copyOf(multiWindow.explodeWindows()).toArray()));
  }
",non-flaky,5
78237,apache_beam,SimplePushbackSideInputDoFnRunnerTest.processElementNoSideInputs,"  @Test
  public void processElementNoSideInputs() {
    SimplePushbackSideInputDoFnRunner<Integer, Integer> runner = createRunner(ImmutableList.of());

    WindowedValue<Integer> multiWindow =
        WindowedValue.of(
            2,
            new Instant(-2),
            ImmutableList.of(
                new IntervalWindow(new Instant(-500L), new Instant(0L)),
                new IntervalWindow(BoundedWindow.TIMESTAMP_MIN_VALUE, new Instant(250L)),
                GlobalWindow.INSTANCE),
            PaneInfo.ON_TIME_AND_ONLY_FIRING);
    Iterable<WindowedValue<Integer>> multiWindowPushback =
        runner.processElementInReadyWindows(multiWindow);
    assertThat(multiWindowPushback, emptyIterable());
    // Should preserve the compressed representation when there's no side inputs.
    assertThat(underlying.inputElems, containsInAnyOrder(multiWindow));
  }
",non-flaky,5
78238,apache_beam,SimplePushbackSideInputDoFnRunnerTest.testOnTimerCalled,"  @Test
  public void testOnTimerCalled() {
    PushbackSideInputDoFnRunner<Integer, Integer> runner = createRunner(ImmutableList.of());

    String timerId = ""fooTimer"";
    IntervalWindow window = new IntervalWindow(new Instant(4), new Instant(16));
    Instant timestamp = new Instant(72);

    // Mocking is not easily compatible with annotation analysis, so we manually record
    // the method call.
    runner.onTimer(timerId, window, new Instant(timestamp), TimeDomain.EVENT_TIME);

    assertThat(
        underlying.firedTimers,
        contains(
            TimerData.of(
                timerId,
                StateNamespaces.window(IntervalWindow.getCoder(), window),
                timestamp,
                TimeDomain.EVENT_TIME)));
  }
",non-flaky,5
78239,apache_beam,StateInternalsTest.testValue,"  @Test
  public void testValue() throws Exception {
    ValueState<String> value = underTest.state(NAMESPACE_1, STRING_VALUE_ADDR);

    // State instances are cached, but depend on the namespace.
    assertThat(underTest.state(NAMESPACE_1, STRING_VALUE_ADDR), equalTo(value));
    assertThat(underTest.state(NAMESPACE_2, STRING_VALUE_ADDR), not(equalTo(value)));

    assertThat(value.read(), Matchers.nullValue());
    value.write(""hello"");
    assertThat(value.read(), equalTo(""hello""));
    value.write(""world"");
    assertThat(value.read(), equalTo(""world""));

    value.clear();
    assertThat(value.read(), Matchers.nullValue());
    assertThat(underTest.state(NAMESPACE_1, STRING_VALUE_ADDR), equalTo(value));
  }
",non-flaky,5
78240,apache_beam,StateInternalsTest.testBag,"  @Test
  public void testBag() throws Exception {
    BagState<String> value = underTest.state(NAMESPACE_1, STRING_BAG_ADDR);

    // State instances are cached, but depend on the namespace.
    assertThat(value, equalTo(underTest.state(NAMESPACE_1, STRING_BAG_ADDR)));
    assertThat(value, not(equalTo(underTest.state(NAMESPACE_2, STRING_BAG_ADDR))));

    assertThat(value.read(), Matchers.emptyIterable());
    value.add(""hello"");
    assertThat(value.read(), containsInAnyOrder(""hello""));

    value.add(""world"");
    assertThat(value.read(), containsInAnyOrder(""hello"", ""world""));

    value.clear();
    assertThat(value.read(), Matchers.emptyIterable());
    assertThat(underTest.state(NAMESPACE_1, STRING_BAG_ADDR), equalTo(value));
  }
",non-flaky,5
78241,apache_beam,StateInternalsTest.testBagIsEmpty,"  @Test
  public void testBagIsEmpty() throws Exception {
    BagState<String> value = underTest.state(NAMESPACE_1, STRING_BAG_ADDR);

    assertThat(value.isEmpty().read(), Matchers.is(true));
    ReadableState<Boolean> readFuture = value.isEmpty();
    value.add(""hello"");
    assertThat(readFuture.read(), Matchers.is(false));

    value.clear();
    assertThat(readFuture.read(), Matchers.is(true));
  }
",non-flaky,5
78242,apache_beam,StateInternalsTest.testMergeBagIntoSource,"  @Test
  public void testMergeBagIntoSource() throws Exception {
    BagState<String> bag1 = underTest.state(NAMESPACE_1, STRING_BAG_ADDR);
    BagState<String> bag2 = underTest.state(NAMESPACE_2, STRING_BAG_ADDR);

    bag1.add(""Hello"");
    bag2.add(""World"");
    bag1.add(""!"");

    StateMerging.mergeBags(Arrays.asList(bag1, bag2), bag1);

    // Reading the merged bag gets both the contents
    assertThat(bag1.read(), containsInAnyOrder(""Hello"", ""World"", ""!""));
    assertThat(bag2.read(), Matchers.emptyIterable());
  }
",non-flaky,5
78243,apache_beam,StateInternalsTest.testMergeBagIntoNewNamespace,"  @Test
  public void testMergeBagIntoNewNamespace() throws Exception {
    BagState<String> bag1 = underTest.state(NAMESPACE_1, STRING_BAG_ADDR);
    BagState<String> bag2 = underTest.state(NAMESPACE_2, STRING_BAG_ADDR);
    BagState<String> bag3 = underTest.state(NAMESPACE_3, STRING_BAG_ADDR);

    bag1.add(""Hello"");
    bag2.add(""World"");
    bag1.add(""!"");

    StateMerging.mergeBags(Arrays.asList(bag1, bag2, bag3), bag3);

    // Reading the merged bag gets both the contents
    assertThat(bag3.read(), containsInAnyOrder(""Hello"", ""World"", ""!""));
    assertThat(bag1.read(), Matchers.emptyIterable());
    assertThat(bag2.read(), Matchers.emptyIterable());
  }
",non-flaky,5
78244,apache_beam,StateInternalsTest.testSet,"  @Test
  public void testSet() throws Exception {

    SetState<String> value = underTest.state(NAMESPACE_1, STRING_SET_ADDR);

    // State instances are cached, but depend on the namespace.
    assertThat(value, equalTo(underTest.state(NAMESPACE_1, STRING_SET_ADDR)));
    assertThat(value, not(equalTo(underTest.state(NAMESPACE_2, STRING_SET_ADDR))));

    // empty
    assertThat(value.read(), Matchers.emptyIterable());
    assertFalse(value.contains(""A"").read());

    // add
    value.add(""A"");
    value.add(""B"");
    value.add(""A"");
    assertFalse(value.addIfAbsent(""B"").read());
    assertThat(value.read(), containsInAnyOrder(""A"", ""B""));

    // remove
    value.remove(""A"");
    assertThat(value.read(), containsInAnyOrder(""B""));
    value.remove(""C"");
    assertThat(value.read(), containsInAnyOrder(""B""));

    // contains
    assertFalse(value.contains(""A"").read());
    assertTrue(value.contains(""B"").read());
    value.add(""C"");
    value.add(""D"");

    // readLater
    assertThat(value.readLater().read(), containsInAnyOrder(""B"", ""C"", ""D""));
    SetState<String> later = value.readLater();
    assertThat(later.read(), hasItems(""C"", ""D""));
    assertFalse(later.contains(""A"").read());

    // clear
    value.clear();
    assertThat(value.read(), Matchers.emptyIterable());
    assertThat(underTest.state(NAMESPACE_1, STRING_SET_ADDR), equalTo(value));
  }
",non-flaky,5
78245,apache_beam,StateInternalsTest.testSetIsEmpty,"  @Test
  public void testSetIsEmpty() throws Exception {

    SetState<String> value = underTest.state(NAMESPACE_1, STRING_SET_ADDR);

    assertThat(value.isEmpty().read(), Matchers.is(true));
    ReadableState<Boolean> readFuture = value.isEmpty();
    value.add(""hello"");
    assertThat(readFuture.read(), Matchers.is(false));

    value.clear();
    assertThat(readFuture.read(), Matchers.is(true));
  }
",non-flaky,5
78246,apache_beam,StateInternalsTest.testMergeSetIntoSource,"  @Test
  public void testMergeSetIntoSource() throws Exception {

    SetState<String> set1 = underTest.state(NAMESPACE_1, STRING_SET_ADDR);
    SetState<String> set2 = underTest.state(NAMESPACE_2, STRING_SET_ADDR);

    set1.add(""Hello"");
    set2.add(""Hello"");
    set2.add(""World"");
    set1.add(""!"");

    StateMerging.mergeSets(Arrays.asList(set1, set2), set1);

    // Reading the merged set gets both the contents
    assertThat(set1.read(), containsInAnyOrder(""Hello"", ""World"", ""!""));
    assertThat(set2.read(), Matchers.emptyIterable());
  }
",non-flaky,5
78247,apache_beam,StateInternalsTest.testMergeSetIntoNewNamespace,"  @Test
  public void testMergeSetIntoNewNamespace() throws Exception {

    SetState<String> set1 = underTest.state(NAMESPACE_1, STRING_SET_ADDR);
    SetState<String> set2 = underTest.state(NAMESPACE_2, STRING_SET_ADDR);
    SetState<String> set3 = underTest.state(NAMESPACE_3, STRING_SET_ADDR);

    set1.add(""Hello"");
    set2.add(""Hello"");
    set2.add(""World"");
    set1.add(""!"");

    StateMerging.mergeSets(Arrays.asList(set1, set2, set3), set3);

    // Reading the merged set gets both the contents
    assertThat(set3.read(), containsInAnyOrder(""Hello"", ""World"", ""!""));
    assertThat(set1.read(), Matchers.emptyIterable());
    assertThat(set2.read(), Matchers.emptyIterable());
  }
",non-flaky,5
78248,apache_beam,StateInternalsTest.testMap,"  @Test
  public void testMap() throws Exception {

    MapState<String, Integer> value = underTest.state(NAMESPACE_1, STRING_MAP_ADDR);

    // State instances are cached, but depend on the namespace.
    assertThat(value, equalTo(underTest.state(NAMESPACE_1, STRING_MAP_ADDR)));
    assertThat(value, not(equalTo(underTest.state(NAMESPACE_2, STRING_MAP_ADDR))));

    // put
    assertThat(value.entries().read(), Matchers.emptyIterable());
    value.put(""A"", 1);
    value.put(""B"", 2);
    value.put(""A"", 11);
    assertThat(value.putIfAbsent(""B"", 22).read(), equalTo(2));
    assertThat(
        value.entries().read(), containsInAnyOrder(MapEntry.of(""A"", 11), MapEntry.of(""B"", 2)));

    // remove
    value.remove(""A"");
    assertThat(value.entries().read(), containsInAnyOrder(MapEntry.of(""B"", 2)));
    value.remove(""C"");
    assertThat(value.entries().read(), containsInAnyOrder(MapEntry.of(""B"", 2)));

    // get
    assertNull(value.get(""A"").read());
    assertThat(value.get(""B"").read(), equalTo(2));
    value.put(""C"", 3);
    value.put(""D"", 4);
    assertThat(value.get(""C"").read(), equalTo(3));

    // iterate
    value.put(""E"", 5);
    value.remove(""C"");
    assertThat(value.keys().read(), containsInAnyOrder(""B"", ""D"", ""E""));
    assertThat(value.values().read(), containsInAnyOrder(2, 4, 5));
    assertThat(
        value.entries().read(),
        containsInAnyOrder(MapEntry.of(""B"", 2), MapEntry.of(""D"", 4), MapEntry.of(""E"", 5)));

    // readLater
    assertThat(value.get(""B"").readLater().read(), equalTo(2));
    assertNull(value.get(""A"").readLater().read());
    assertThat(
        value.entries().readLater().read(),
        containsInAnyOrder(MapEntry.of(""B"", 2), MapEntry.of(""D"", 4), MapEntry.of(""E"", 5)));

    // clear
    value.clear();
    assertThat(value.entries().read(), Matchers.emptyIterable());
    assertThat(underTest.state(NAMESPACE_1, STRING_MAP_ADDR), equalTo(value));
  }
",non-flaky,5
78249,apache_beam,StateInternalsTest.testCombiningValue,"  @Test
  public void testCombiningValue() throws Exception {

    GroupingState<Integer, Integer> value = underTest.state(NAMESPACE_1, SUM_INTEGER_ADDR);

    // State instances are cached, but depend on the namespace.
    assertEquals(value, underTest.state(NAMESPACE_1, SUM_INTEGER_ADDR));
    assertFalse(value.equals(underTest.state(NAMESPACE_2, SUM_INTEGER_ADDR)));

    assertThat(value.read(), equalTo(0));
    value.add(2);
    assertThat(value.read(), equalTo(2));

    value.add(3);
    assertThat(value.read(), equalTo(5));

    value.clear();
    assertThat(value.read(), equalTo(0));
    assertThat(underTest.state(NAMESPACE_1, SUM_INTEGER_ADDR), equalTo(value));
  }
",non-flaky,5
78250,apache_beam,StateInternalsTest.testCombiningIsEmpty,"  @Test
  public void testCombiningIsEmpty() throws Exception {
    GroupingState<Integer, Integer> value = underTest.state(NAMESPACE_1, SUM_INTEGER_ADDR);

    assertThat(value.isEmpty().read(), Matchers.is(true));
    ReadableState<Boolean> readFuture = value.isEmpty();
    value.add(5);
    assertThat(readFuture.read(), Matchers.is(false));

    value.clear();
    assertThat(readFuture.read(), Matchers.is(true));
  }
",non-flaky,5
78251,apache_beam,StateInternalsTest.testMergeCombiningValueIntoSource,"  @Test
  public void testMergeCombiningValueIntoSource() throws Exception {
    CombiningState<Integer, int[], Integer> value1 = underTest.state(NAMESPACE_1, SUM_INTEGER_ADDR);
    CombiningState<Integer, int[], Integer> value2 = underTest.state(NAMESPACE_2, SUM_INTEGER_ADDR);

    value1.add(5);
    value2.add(10);
    value1.add(6);

    assertThat(value1.read(), equalTo(11));
    assertThat(value2.read(), equalTo(10));

    // Merging clears the old values and updates the result value.
    StateMerging.mergeCombiningValues(Arrays.asList(value1, value2), value1);

    assertThat(value1.read(), equalTo(21));
    assertThat(value2.read(), equalTo(0));
  }
",non-flaky,5
78252,apache_beam,StateInternalsTest.testMergeCombiningValueIntoNewNamespace,"  @Test
  public void testMergeCombiningValueIntoNewNamespace() throws Exception {
    CombiningState<Integer, int[], Integer> value1 = underTest.state(NAMESPACE_1, SUM_INTEGER_ADDR);
    CombiningState<Integer, int[], Integer> value2 = underTest.state(NAMESPACE_2, SUM_INTEGER_ADDR);
    CombiningState<Integer, int[], Integer> value3 = underTest.state(NAMESPACE_3, SUM_INTEGER_ADDR);

    value1.add(5);
    value2.add(10);
    value1.add(6);

    StateMerging.mergeCombiningValues(Arrays.asList(value1, value2), value3);

    // Merging clears the old values and updates the result value.
    assertThat(value1.read(), equalTo(0));
    assertThat(value2.read(), equalTo(0));
    assertThat(value3.read(), equalTo(21));
  }
",non-flaky,5
78253,apache_beam,StateInternalsTest.testWatermarkEarliestState,"  @Test
  public void testWatermarkEarliestState() throws Exception {
    WatermarkHoldState value = underTest.state(NAMESPACE_1, WATERMARK_EARLIEST_ADDR);

    // State instances are cached, but depend on the namespace.
    assertEquals(value, underTest.state(NAMESPACE_1, WATERMARK_EARLIEST_ADDR));
    assertFalse(value.equals(underTest.state(NAMESPACE_2, WATERMARK_EARLIEST_ADDR)));

    assertThat(value.read(), Matchers.nullValue());
    value.add(new Instant(2000));
    assertThat(value.read(), equalTo(new Instant(2000)));

    value.add(new Instant(3000));
    assertThat(value.read(), equalTo(new Instant(2000)));

    value.add(new Instant(1000));
    assertThat(value.read(), equalTo(new Instant(1000)));

    value.clear();
    assertThat(value.read(), equalTo(null));
    assertThat(underTest.state(NAMESPACE_1, WATERMARK_EARLIEST_ADDR), equalTo(value));
  }
",non-flaky,5
78254,apache_beam,StateInternalsTest.testWatermarkLatestState,"  @Test
  public void testWatermarkLatestState() throws Exception {
    WatermarkHoldState value = underTest.state(NAMESPACE_1, WATERMARK_LATEST_ADDR);

    // State instances are cached, but depend on the namespace.
    assertEquals(value, underTest.state(NAMESPACE_1, WATERMARK_LATEST_ADDR));
    assertFalse(value.equals(underTest.state(NAMESPACE_2, WATERMARK_LATEST_ADDR)));

    assertThat(value.read(), Matchers.nullValue());
    value.add(new Instant(2000));
    assertThat(value.read(), equalTo(new Instant(2000)));

    value.add(new Instant(3000));
    assertThat(value.read(), equalTo(new Instant(3000)));

    value.add(new Instant(1000));
    assertThat(value.read(), equalTo(new Instant(3000)));

    value.clear();
    assertThat(value.read(), equalTo(null));
    assertThat(underTest.state(NAMESPACE_1, WATERMARK_LATEST_ADDR), equalTo(value));
  }
",non-flaky,5
78255,apache_beam,StateInternalsTest.testWatermarkEndOfWindowState,"  @Test
  public void testWatermarkEndOfWindowState() throws Exception {
    WatermarkHoldState value = underTest.state(NAMESPACE_1, WATERMARK_EOW_ADDR);

    // State instances are cached, but depend on the namespace.
    assertEquals(value, underTest.state(NAMESPACE_1, WATERMARK_EOW_ADDR));
    assertFalse(value.equals(underTest.state(NAMESPACE_2, WATERMARK_EOW_ADDR)));

    assertThat(value.read(), Matchers.nullValue());
    value.add(new Instant(2000));
    assertThat(value.read(), equalTo(new Instant(2000)));

    value.clear();
    assertThat(value.read(), equalTo(null));
    assertThat(underTest.state(NAMESPACE_1, WATERMARK_EOW_ADDR), equalTo(value));
  }
",non-flaky,5
78256,apache_beam,StateInternalsTest.testWatermarkStateIsEmpty,"  @Test
  public void testWatermarkStateIsEmpty() throws Exception {
    WatermarkHoldState value = underTest.state(NAMESPACE_1, WATERMARK_EARLIEST_ADDR);

    assertThat(value.isEmpty().read(), Matchers.is(true));
    ReadableState<Boolean> readFuture = value.isEmpty();
    value.add(new Instant(1000));
    assertThat(readFuture.read(), Matchers.is(false));

    value.clear();
    assertThat(readFuture.read(), Matchers.is(true));
  }
",non-flaky,5
78257,apache_beam,StateInternalsTest.testSetReadable,"  @Test
  public void testSetReadable() throws Exception {
    SetState<String> value = underTest.state(NAMESPACE_1, STRING_SET_ADDR);

    // test contains
    ReadableState<Boolean> readable = value.contains(""A"");
    value.add(""A"");
    assertFalse(readable.read());

    // test addIfAbsent
    value.addIfAbsent(""B"");
    assertTrue(value.contains(""B"").read());
  }
",non-flaky,5
78258,apache_beam,StateInternalsTest.testMapReadable,"  @Test
  public void testMapReadable() throws Exception {
    MapState<String, Integer> value = underTest.state(NAMESPACE_1, STRING_MAP_ADDR);

    // test iterable, should just return a iterable view of the values contained in this map.
    // The iterable is backed by the map, so changes to the map are reflected in the iterable.
    ReadableState<Iterable<String>> keys = value.keys();
    ReadableState<Iterable<Integer>> values = value.values();
    ReadableState<Iterable<Map.Entry<String, Integer>>> entries = value.entries();
    value.put(""A"", 1);
    assertFalse(Iterables.isEmpty(keys.read()));
    assertFalse(Iterables.isEmpty(values.read()));
    assertFalse(Iterables.isEmpty(entries.read()));

    // test get
    ReadableState<Integer> get = value.get(""B"");
    value.put(""B"", 2);
    assertNull(get.read());

    // test addIfAbsent
    value.putIfAbsent(""C"", 3);
    assertThat(value.get(""C"").read(), equalTo(3));
  }
",non-flaky,5
78259,apache_beam,StateInternalsTest.testBagWithBadCoderEquality,"  @Test
  public void testBagWithBadCoderEquality() throws Exception {
    // Ensure two instances of the bad coder are distinct; models user who fails to
    // override equals() or inherit from CustomCoder for StructuredCoder
    assertThat(
        new StringCoderWithIdentityEquality(), not(equalTo(new StringCoderWithIdentityEquality())));

    BagState<String> state1 = underTest.state(NAMESPACE_1, STRING_BAG_ADDR1);
    state1.add(""hello"");

    BagState<String> state2 = underTest.state(NAMESPACE_1, STRING_BAG_ADDR2);
    assertThat(state2.read(), containsInAnyOrder(""hello""));
  }
",non-flaky,5
78260,apache_beam,SplittableParDoProcessFnTest.testTrivialProcessFnPropagatesOutputWindowAndTimestamp,"  @Test
  public void testTrivialProcessFnPropagatesOutputWindowAndTimestamp() throws Exception {
    // Tests that ProcessFn correctly propagates the window and timestamp of the element
    // inside the KeyedWorkItem.
    // The underlying DoFn is actually monolithic, so this doesn't test splitting.
    DoFn<Integer, String> fn = new ToStringFn();

    Instant base = Instant.now();

    IntervalWindow w =
        new IntervalWindow(
            base.minus(Duration.standardMinutes(1)), base.plus(Duration.standardMinutes(1)));

    ProcessFnTester<Integer, String, SomeRestriction, Void, SomeRestrictionTracker> tester =
        new ProcessFnTester<>(
            base,
            fn,
            BigEndianIntegerCoder.of(),
            SerializableCoder.of(SomeRestriction.class),
            MAX_OUTPUTS_PER_BUNDLE,
            MAX_BUNDLE_DURATION);
    tester.startElement(
        WindowedValue.of(
            KV.of(42, new SomeRestriction()),
            base,
            Collections.singletonList(w),
            PaneInfo.ON_TIME_AND_ONLY_FIRING));

    assertEquals(
        Arrays.asList(
            TimestampedValue.of(""42a"", base),
            TimestampedValue.of(""42b"", base),
            TimestampedValue.of(""42c"", base)),
        tester.peekOutputElementsInWindow(w));
  }
",non-flaky,5
78261,apache_beam,SplittableParDoProcessFnTest.testUpdatesWatermark,"  @Test
  public void testUpdatesWatermark() throws Exception {
    DoFn<Instant, String> fn = new WatermarkUpdateFn();
    Instant base = Instant.now();

    ProcessFnTester<Instant, String, OffsetRange, Long, OffsetRangeTracker> tester =
        new ProcessFnTester<>(
            base,
            fn,
            InstantCoder.of(),
            SerializableCoder.of(OffsetRange.class),
            3,
            MAX_BUNDLE_DURATION);

    tester.startElement(base, new OffsetRange(0, 8));
    assertThat(tester.takeOutputElements(), hasItems(""0"", ""1"", ""2""));
    assertEquals(base.plus(Duration.standardSeconds(2)), tester.getWatermarkHold());

    assertTrue(tester.advanceProcessingTimeBy(Duration.standardSeconds(1)));
    assertThat(tester.takeOutputElements(), hasItems(""3"", ""4"", ""5""));
    assertEquals(base.plus(Duration.standardSeconds(5)), tester.getWatermarkHold());

    assertTrue(tester.advanceProcessingTimeBy(Duration.standardSeconds(1)));
    assertThat(tester.takeOutputElements(), hasItems(""6"", ""7""));
    assertEquals(null, tester.getWatermarkHold());
  }
",non-flaky,5
78262,apache_beam,SplittableParDoProcessFnTest.testResumeSetsTimer,"  @Test
  public void testResumeSetsTimer() throws Exception {
    DoFn<Integer, String> fn = new SelfInitiatedResumeFn();
    Instant base = Instant.now();
    ProcessFnTester<Integer, String, SomeRestriction, Void, SomeRestrictionTracker> tester =
        new ProcessFnTester<>(
            base,
            fn,
            BigEndianIntegerCoder.of(),
            SerializableCoder.of(SomeRestriction.class),
            MAX_OUTPUTS_PER_BUNDLE,
            MAX_BUNDLE_DURATION);

    tester.startElement(42, new SomeRestriction());
    assertThat(tester.takeOutputElements(), contains(""42""));

    // Should resume after 5 seconds: advancing by 3 seconds should have no effect.
    assertFalse(tester.advanceProcessingTimeBy(Duration.standardSeconds(3)));
    assertTrue(tester.takeOutputElements().isEmpty());

    // 6 seconds should be enough  should invoke the fn again.
    assertTrue(tester.advanceProcessingTimeBy(Duration.standardSeconds(3)));
    assertThat(tester.takeOutputElements(), contains(""42""));

    // Should again resume after 5 seconds: advancing by 3 seconds should again have no effect.
    assertFalse(tester.advanceProcessingTimeBy(Duration.standardSeconds(3)));
    assertTrue(tester.takeOutputElements().isEmpty());

    // 6 seconds should again be enough.
    assertTrue(tester.advanceProcessingTimeBy(Duration.standardSeconds(3)));
    assertThat(tester.takeOutputElements(), contains(""42""));
  }
",non-flaky,5
78263,apache_beam,SplittableParDoProcessFnTest.testResumeCarriesOverState,"  @Test
  public void testResumeCarriesOverState() throws Exception {
    DoFn<Integer, String> fn = new CounterFn(1);
    Instant base = Instant.now();
    ProcessFnTester<Integer, String, OffsetRange, Long, OffsetRangeTracker> tester =
        new ProcessFnTester<>(
            base,
            fn,
            BigEndianIntegerCoder.of(),
            SerializableCoder.of(OffsetRange.class),
            MAX_OUTPUTS_PER_BUNDLE,
            MAX_BUNDLE_DURATION);

    tester.startElement(42, new OffsetRange(0, 3));
    assertThat(tester.takeOutputElements(), contains(""42""));
    assertTrue(tester.advanceProcessingTimeBy(Duration.standardSeconds(1)));
    assertThat(tester.takeOutputElements(), contains(""43""));
    assertTrue(tester.advanceProcessingTimeBy(Duration.standardSeconds(1)));
    assertThat(tester.takeOutputElements(), contains(""44""));
    assertTrue(tester.advanceProcessingTimeBy(Duration.standardSeconds(1)));
    // After outputting all 3 items, should not output anything more.
    assertEquals(0, tester.takeOutputElements().size());
    // Should also not ask to resume.
    assertFalse(tester.advanceProcessingTimeBy(Duration.standardSeconds(1)));
  }
",non-flaky,5
78264,apache_beam,SplittableParDoProcessFnTest.testCheckpointsAfterNumOutputs,"  @Test
  public void testCheckpointsAfterNumOutputs() throws Exception {
    int max = 100;
    DoFn<Integer, String> fn = new CounterFn(Integer.MAX_VALUE);
    Instant base = Instant.now();
    int baseIndex = 42;

    ProcessFnTester<Integer, String, OffsetRange, Long, OffsetRangeTracker> tester =
        new ProcessFnTester<>(
            base,
            fn,
            BigEndianIntegerCoder.of(),
            SerializableCoder.of(OffsetRange.class),
            max,
            MAX_BUNDLE_DURATION);

    List<String> elements;

    // Create an fn that attempts to 2x output more than checkpointing allows.
    tester.startElement(baseIndex, new OffsetRange(0, 2 * max + max / 2));
    elements = tester.takeOutputElements();
    assertEquals(max, elements.size());
    // Should output the range [0, max)
    assertThat(elements, hasItem(String.valueOf(baseIndex)));
    assertThat(elements, hasItem(String.valueOf(baseIndex + max - 1)));

    assertTrue(tester.advanceProcessingTimeBy(Duration.standardSeconds(1)));
    elements = tester.takeOutputElements();
    assertEquals(max, elements.size());
    // Should output the range [max, 2*max)
    assertThat(elements, hasItem(String.valueOf(baseIndex + max)));
    assertThat(elements, hasItem(String.valueOf(baseIndex + 2 * max - 1)));

    assertTrue(tester.advanceProcessingTimeBy(Duration.standardSeconds(1)));
    elements = tester.takeOutputElements();
    assertEquals(max / 2, elements.size());
    // Should output the range [2*max, 2*max + max/2)
    assertThat(elements, hasItem(String.valueOf(baseIndex + 2 * max)));
    assertThat(elements, hasItem(String.valueOf(baseIndex + 2 * max + max / 2 - 1)));
    assertThat(elements, not(hasItem((String.valueOf(baseIndex + 2 * max + max / 2)))));
  }
",non-flaky,5
78265,apache_beam,SplittableParDoProcessFnTest.testCheckpointsAfterDuration,"  @Test
  public void testCheckpointsAfterDuration() throws Exception {
    // Don't bound number of outputs.
    int max = Integer.MAX_VALUE;
    // But bound bundle duration - the bundle should terminate.
    Duration maxBundleDuration = Duration.standardSeconds(1);
    // Create an fn that attempts to 2x output more than checkpointing allows.
    DoFn<Integer, String> fn = new CounterFn(Integer.MAX_VALUE);
    Instant base = Instant.now();
    int baseIndex = 42;

    ProcessFnTester<Integer, String, OffsetRange, Long, OffsetRangeTracker> tester =
        new ProcessFnTester<>(
            base,
            fn,
            BigEndianIntegerCoder.of(),
            SerializableCoder.of(OffsetRange.class),
            max,
            maxBundleDuration);

    List<String> elements;

    tester.startElement(baseIndex, new OffsetRange(0, Long.MAX_VALUE));
    // Bundle should terminate, and should do at least some processing.
    elements = tester.takeOutputElements();
    assertFalse(elements.isEmpty());
    // Bundle should have run for at least the requested duration.
    assertThat(
        Instant.now().getMillis() - base.getMillis(),
        greaterThanOrEqualTo(maxBundleDuration.getMillis()));
  }
",non-flaky,5
78266,apache_beam,SplittableParDoProcessFnTest.testInvokesLifecycleMethods,"  @Test
  public void testInvokesLifecycleMethods() throws Exception {
    DoFn<Integer, String> fn = new LifecycleVerifyingFn();
    try (ProcessFnTester<Integer, String, SomeRestriction, Void, SomeRestrictionTracker> tester =
        new ProcessFnTester<>(
            Instant.now(),
            fn,
            BigEndianIntegerCoder.of(),
            SerializableCoder.of(SomeRestriction.class),
            MAX_OUTPUTS_PER_BUNDLE,
            MAX_BUNDLE_DURATION)) {
      tester.startElement(42, new SomeRestriction());
    }
  }
",non-flaky,5
78267,apache_beam,LateDataUtilsTest.beforeEndOfGlobalWindowSame,"  @Test
  public void beforeEndOfGlobalWindowSame() {
    FixedWindows windowFn = FixedWindows.of(Duration.standardMinutes(5));
    Duration allowedLateness = Duration.standardMinutes(2);
    WindowingStrategy<?, ?> strategy =
        WindowingStrategy.globalDefault()
            .withWindowFn(windowFn)
            .withAllowedLateness(allowedLateness);

    IntervalWindow window = windowFn.assignWindow(new Instant(10));
    assertThat(
        LateDataUtils.garbageCollectionTime(window, strategy),
        equalTo(window.maxTimestamp().plus(allowedLateness)));
  }
",non-flaky,5
78268,apache_beam,LateDataUtilsTest.garbageCollectionTimeAfterEndOfGlobalWindow,"  @Test
  public void garbageCollectionTimeAfterEndOfGlobalWindow() {
    FixedWindows windowFn = FixedWindows.of(Duration.standardMinutes(5));
    WindowingStrategy<?, ?> strategy = WindowingStrategy.globalDefault().withWindowFn(windowFn);

    IntervalWindow window = windowFn.assignWindow(new Instant(BoundedWindow.TIMESTAMP_MAX_VALUE));
    assertThat(window.maxTimestamp(), equalTo(GlobalWindow.INSTANCE.maxTimestamp()));
    assertThat(
        LateDataUtils.garbageCollectionTime(window, strategy),
        equalTo(GlobalWindow.INSTANCE.maxTimestamp()));
  }
",non-flaky,5
78269,apache_beam,LateDataUtilsTest.garbageCollectionTimeAfterEndOfGlobalWindowWithLateness,"  @Test
  public void garbageCollectionTimeAfterEndOfGlobalWindowWithLateness() {
    FixedWindows windowFn = FixedWindows.of(Duration.standardMinutes(5));
    Duration allowedLateness = Duration.millis(Long.MAX_VALUE);
    WindowingStrategy<?, ?> strategy =
        WindowingStrategy.globalDefault()
            .withWindowFn(windowFn)
            .withAllowedLateness(allowedLateness);

    IntervalWindow window = windowFn.assignWindow(new Instant(-100));
    assertThat(
        window.maxTimestamp().plus(allowedLateness),
        Matchers.greaterThan(GlobalWindow.INSTANCE.maxTimestamp()));
    assertThat(
        LateDataUtils.garbageCollectionTime(window, strategy),
        equalTo(GlobalWindow.INSTANCE.maxTimestamp()));
  }
",non-flaky,5
78270,apache_beam,StateNamespacesTest.testStability,"  @Test
  public void testStability() {
    StateNamespace global = StateNamespaces.global();
    StateNamespace intervalWindow =
        StateNamespaces.window(intervalCoder, intervalWindow(1000, 87392));
    StateNamespace intervalWindowAndTrigger =
        StateNamespaces.windowAndTrigger(intervalCoder, intervalWindow(1000, 87392), 57);
    StateNamespace globalWindow =
        StateNamespaces.window(GlobalWindow.Coder.INSTANCE, GlobalWindow.INSTANCE);
    StateNamespace globalWindowAndTrigger =
        StateNamespaces.windowAndTrigger(GlobalWindow.Coder.INSTANCE, GlobalWindow.INSTANCE, 12);

    assertEquals(""/"", global.stringKey());
    assertEquals(""/gAAAAAABVWD4ogU/"", intervalWindow.stringKey());
    assertEquals(""/gAAAAAABVWD4ogU/1L/"", intervalWindowAndTrigger.stringKey());
    assertEquals(""//"", globalWindow.stringKey());
    assertEquals(""//C/"", globalWindowAndTrigger.stringKey());
  }
",non-flaky,5
78271,apache_beam,StateNamespacesTest.testIntervalWindowPrefixing,"  @Test
  public void testIntervalWindowPrefixing() {
    StateNamespace window = StateNamespaces.window(intervalCoder, intervalWindow(1000, 87392));
    StateNamespace windowAndTrigger =
        StateNamespaces.windowAndTrigger(intervalCoder, intervalWindow(1000, 87392), 57);
    assertThat(windowAndTrigger.stringKey(), Matchers.startsWith(window.stringKey()));
    assertThat(
        StateNamespaces.global().stringKey(),
        Matchers.not(Matchers.startsWith(window.stringKey())));
  }
",non-flaky,5
78272,apache_beam,StateNamespacesTest.testGlobalWindowPrefixing,"  @Test
  public void testGlobalWindowPrefixing() {
    StateNamespace window =
        StateNamespaces.window(GlobalWindow.Coder.INSTANCE, GlobalWindow.INSTANCE);
    StateNamespace windowAndTrigger =
        StateNamespaces.windowAndTrigger(GlobalWindow.Coder.INSTANCE, GlobalWindow.INSTANCE, 57);
    assertThat(windowAndTrigger.stringKey(), Matchers.startsWith(window.stringKey()));
    assertThat(
        StateNamespaces.global().stringKey(),
        Matchers.not(Matchers.startsWith(window.stringKey())));
  }
",non-flaky,5
78273,apache_beam,StateNamespacesTest.testFromStringGlobal,"  @Test
  public void testFromStringGlobal() {
    assertStringKeyRoundTrips(intervalCoder, StateNamespaces.global());
  }
",non-flaky,5
78274,apache_beam,StateNamespacesTest.testFromStringIntervalWindow,"  @Test
  public void testFromStringIntervalWindow() {
    assertStringKeyRoundTrips(
        intervalCoder, StateNamespaces.window(intervalCoder, intervalWindow(1000, 8000)));
    assertStringKeyRoundTrips(
        intervalCoder, StateNamespaces.window(intervalCoder, intervalWindow(1000, 8000)));

    assertStringKeyRoundTrips(
        intervalCoder,
        StateNamespaces.windowAndTrigger(intervalCoder, intervalWindow(1000, 8000), 18));
    assertStringKeyRoundTrips(
        intervalCoder,
        StateNamespaces.windowAndTrigger(intervalCoder, intervalWindow(1000, 8000), 19));
    assertStringKeyRoundTrips(
        intervalCoder,
        StateNamespaces.windowAndTrigger(intervalCoder, intervalWindow(2000, 8000), 19));
  }
",non-flaky,5
78275,apache_beam,StateNamespacesTest.testFromStringGlobalWindow,"  @Test
  public void testFromStringGlobalWindow() {
    assertStringKeyRoundTrips(GlobalWindow.Coder.INSTANCE, StateNamespaces.global());
    assertStringKeyRoundTrips(
        GlobalWindow.Coder.INSTANCE,
        StateNamespaces.window(GlobalWindow.Coder.INSTANCE, GlobalWindow.INSTANCE));
    assertStringKeyRoundTrips(
        GlobalWindow.Coder.INSTANCE,
        StateNamespaces.windowAndTrigger(GlobalWindow.Coder.INSTANCE, GlobalWindow.INSTANCE, 18));
  }
",non-flaky,5
78276,apache_beam,StateTagTest.testValueEquality,"  @Test
  public void testValueEquality() {
    StateTag<?> fooVarInt1 = StateTags.value(""foo"", VarIntCoder.of());
    StateTag<?> fooVarInt2 = StateTags.value(""foo"", VarIntCoder.of());
    StateTag<?> fooBigEndian = StateTags.value(""foo"", BigEndianIntegerCoder.of());
    StateTag<?> barVarInt = StateTags.value(""bar"", VarIntCoder.of());

    assertEquals(fooVarInt1, fooVarInt2);
    assertNotEquals(fooVarInt1, fooBigEndian);
    assertNotEquals(fooVarInt1, barVarInt);
  }
",non-flaky,5
78277,apache_beam,StateTagTest.testBagEquality,"  @Test
  public void testBagEquality() {
    StateTag<?> fooVarInt1 = StateTags.bag(""foo"", VarIntCoder.of());
    StateTag<?> fooVarInt2 = StateTags.bag(""foo"", VarIntCoder.of());
    StateTag<?> fooBigEndian = StateTags.bag(""foo"", BigEndianIntegerCoder.of());
    StateTag<?> barVarInt = StateTags.bag(""bar"", VarIntCoder.of());

    assertEquals(fooVarInt1, fooVarInt2);
    assertNotEquals(fooVarInt1, fooBigEndian);
    assertNotEquals(fooVarInt1, barVarInt);
  }
",non-flaky,5
78278,apache_beam,StateTagTest.testSetEquality,"  @Test
  public void testSetEquality() {
    StateTag<?> fooVarInt1 = StateTags.set(""foo"", VarIntCoder.of());
    StateTag<?> fooVarInt2 = StateTags.set(""foo"", VarIntCoder.of());
    StateTag<?> fooBigEndian = StateTags.set(""foo"", BigEndianIntegerCoder.of());
    StateTag<?> barVarInt = StateTags.set(""bar"", VarIntCoder.of());

    assertEquals(fooVarInt1, fooVarInt2);
    assertNotEquals(fooVarInt1, fooBigEndian);
    assertNotEquals(fooVarInt1, barVarInt);
  }
",non-flaky,5
78279,apache_beam,StateTagTest.testMapEquality,"  @Test
  public void testMapEquality() {
    StateTag<?> fooStringVarInt1 = StateTags.map(""foo"", StringUtf8Coder.of(), VarIntCoder.of());
    StateTag<?> fooStringVarInt2 = StateTags.map(""foo"", StringUtf8Coder.of(), VarIntCoder.of());
    StateTag<?> fooStringBigEndian =
        StateTags.map(""foo"", StringUtf8Coder.of(), BigEndianIntegerCoder.of());
    StateTag<?> fooVarIntBigEndian =
        StateTags.map(""foo"", VarIntCoder.of(), BigEndianIntegerCoder.of());
    StateTag<?> barStringVarInt = StateTags.map(""bar"", StringUtf8Coder.of(), VarIntCoder.of());

    assertEquals(fooStringVarInt1, fooStringVarInt2);
    assertNotEquals(fooStringVarInt1, fooStringBigEndian);
    assertNotEquals(fooStringBigEndian, fooVarIntBigEndian);
    assertNotEquals(fooStringVarInt1, fooVarIntBigEndian);
    assertNotEquals(fooStringVarInt1, barStringVarInt);
  }
",non-flaky,5
78280,apache_beam,StateTagTest.testWatermarkBagEquality,"  @Test
  public void testWatermarkBagEquality() {
    StateTag<?> foo1 = StateTags.watermarkStateInternal(""foo"", TimestampCombiner.EARLIEST);
    StateTag<?> foo2 = StateTags.watermarkStateInternal(""foo"", TimestampCombiner.EARLIEST);
    StateTag<?> bar = StateTags.watermarkStateInternal(""bar"", TimestampCombiner.EARLIEST);

    StateTag<?> bar2 = StateTags.watermarkStateInternal(""bar"", TimestampCombiner.LATEST);

    // Same id, same fn.
    assertEquals(foo1, foo2);
    // Different id, same fn.
    assertNotEquals(foo1, bar);
    // Same id, different fn.
    assertEquals(bar, bar2);
  }
",non-flaky,5
78281,apache_beam,StateTagTest.testCombiningValueEquality,"  @Test
  public void testCombiningValueEquality() {
    Combine.BinaryCombineIntegerFn maxFn = Max.ofIntegers();
    Coder<Integer> input1 = VarIntCoder.of();
    Coder<Integer> input2 = BigEndianIntegerCoder.of();
    Combine.BinaryCombineIntegerFn minFn = Min.ofIntegers();

    StateTag<?> fooCoder1Max1 = StateTags.combiningValueFromInputInternal(""foo"", input1, maxFn);
    StateTag<?> fooCoder1Max2 = StateTags.combiningValueFromInputInternal(""foo"", input1, maxFn);
    StateTag<?> fooCoder1Min = StateTags.combiningValueFromInputInternal(""foo"", input1, minFn);

    StateTag<?> fooCoder2Max = StateTags.combiningValueFromInputInternal(""foo"", input2, maxFn);
    StateTag<?> barCoder1Max = StateTags.combiningValueFromInputInternal(""bar"", input1, maxFn);

    // Same name, coder and combineFn
    assertEquals(fooCoder1Max1, fooCoder1Max2);
    assertEquals(
        StateTags.convertToBagTagInternal((StateTag) fooCoder1Max1),
        StateTags.convertToBagTagInternal((StateTag) fooCoder1Max2));

    // Different combineFn, but we treat them as equal since we only serialize the bits.
    assertEquals(fooCoder1Max1, fooCoder1Min);
    assertEquals(
        StateTags.convertToBagTagInternal((StateTag) fooCoder1Max1),
        StateTags.convertToBagTagInternal((StateTag) fooCoder1Min));

    // Different input coder coder.
    assertNotEquals(fooCoder1Max1, fooCoder2Max);
    assertNotEquals(
        StateTags.convertToBagTagInternal((StateTag) fooCoder1Max1),
        StateTags.convertToBagTagInternal((StateTag) fooCoder2Max));

    // These StateTags have different IDs.
    assertNotEquals(fooCoder1Max1, barCoder1Max);
    assertNotEquals(
        StateTags.convertToBagTagInternal((StateTag) fooCoder1Max1),
        StateTags.convertToBagTagInternal((StateTag) barCoder1Max));
  }
",non-flaky,5
78282,apache_beam,StateTagTest.testCombiningValueWithContextEquality,"  @Test
  public void testCombiningValueWithContextEquality() {
    CoderRegistry registry = CoderRegistry.createDefault();

    Combine.BinaryCombineIntegerFn maxFn = Max.ofIntegers();
    Combine.BinaryCombineIntegerFn minFn = Min.ofIntegers();

    Coder<int[]> accum1 = maxFn.getAccumulatorCoder(registry, VarIntCoder.of());
    Coder<int[]> accum2 = minFn.getAccumulatorCoder(registry, BigEndianIntegerCoder.of());

    StateTag<?> fooCoder1Max1 =
        StateTags.combiningValueWithContext(""foo"", accum1, CombineFnUtil.toFnWithContext(maxFn));
    StateTag<?> fooCoder1Max2 =
        StateTags.combiningValueWithContext(""foo"", accum1, CombineFnUtil.toFnWithContext(maxFn));
    StateTag<?> fooCoder1Min =
        StateTags.combiningValueWithContext(""foo"", accum1, CombineFnUtil.toFnWithContext(minFn));

    StateTag<?> fooCoder2Max =
        StateTags.combiningValueWithContext(""foo"", accum2, CombineFnUtil.toFnWithContext(maxFn));
    StateTag<?> barCoder1Max =
        StateTags.combiningValueWithContext(""bar"", accum1, CombineFnUtil.toFnWithContext(maxFn));

    // Same name, coder and combineFn
    assertEquals(fooCoder1Max1, fooCoder1Max2);
    assertEquals(
        StateTags.convertToBagTagInternal((StateTag) fooCoder1Max1),
        StateTags.convertToBagTagInternal((StateTag) fooCoder1Max2));
    // Different combineFn, but we treat them as equal since we only serialize the bits.
    assertEquals(fooCoder1Max1, fooCoder1Min);
    assertEquals(
        StateTags.convertToBagTagInternal((StateTag) fooCoder1Max1),
        StateTags.convertToBagTagInternal((StateTag) fooCoder1Min));

    // Different input coder coder.
    assertNotEquals(fooCoder1Max1, fooCoder2Max);
    assertNotEquals(
        StateTags.convertToBagTagInternal((StateTag) fooCoder1Max1),
        StateTags.convertToBagTagInternal((StateTag) fooCoder2Max));

    // These StateTags have different IDs.
    assertNotEquals(fooCoder1Max1, barCoder1Max);
    assertNotEquals(
        StateTags.convertToBagTagInternal((StateTag) fooCoder1Max1),
        StateTags.convertToBagTagInternal((StateTag) barCoder1Max));
  }
",non-flaky,5
78283,apache_beam,TimerInternalsTest.testTimerDataCoder,"  @Test
  public void testTimerDataCoder() throws Exception {
    CoderProperties.coderDecodeEncodeEqual(
        TimerDataCoder.of(GlobalWindow.Coder.INSTANCE),
        TimerData.of(
            ""arbitrary-id"", StateNamespaces.global(), new Instant(0), TimeDomain.EVENT_TIME));

    Coder<IntervalWindow> windowCoder = IntervalWindow.getCoder();
    CoderProperties.coderDecodeEncodeEqual(
        TimerDataCoder.of(windowCoder),
        TimerData.of(
            ""another-id"",
            StateNamespaces.window(
                windowCoder, new IntervalWindow(new Instant(0), new Instant(100))),
            new Instant(99),
            TimeDomain.PROCESSING_TIME));
  }
",non-flaky,5
78284,apache_beam,TimerInternalsTest.testCoderIsSerializableWithWellKnownCoderType,"  @Test
  public void testCoderIsSerializableWithWellKnownCoderType() {
    CoderProperties.coderSerializable(TimerDataCoder.of(GlobalWindow.Coder.INSTANCE));
  }
",non-flaky,5
78285,apache_beam,TimerInternalsTest.testCompareEqual,"  @Test
  public void testCompareEqual() {
    Instant timestamp = new Instant(100);
    StateNamespace namespace = StateNamespaces.global();
    TimerData timer = TimerData.of(""id"", namespace, timestamp, TimeDomain.EVENT_TIME);

    assertThat(
        timer, comparesEqualTo(TimerData.of(""id"", namespace, timestamp, TimeDomain.EVENT_TIME)));
  }
",non-flaky,5
78286,apache_beam,TimerInternalsTest.testCompareByTimestamp,"  @Test
  public void testCompareByTimestamp() {
    Instant firstTimestamp = new Instant(100);
    Instant secondTimestamp = new Instant(200);
    StateNamespace namespace = StateNamespaces.global();

    TimerData firstTimer = TimerData.of(namespace, firstTimestamp, TimeDomain.EVENT_TIME);
    TimerData secondTimer = TimerData.of(namespace, secondTimestamp, TimeDomain.EVENT_TIME);

    assertThat(firstTimer, lessThan(secondTimer));
  }
",non-flaky,5
78287,apache_beam,TimerInternalsTest.testCompareByDomain,"  @Test
  public void testCompareByDomain() {
    Instant timestamp = new Instant(100);
    StateNamespace namespace = StateNamespaces.global();

    TimerData eventTimer = TimerData.of(namespace, timestamp, TimeDomain.EVENT_TIME);
    TimerData procTimer = TimerData.of(namespace, timestamp, TimeDomain.PROCESSING_TIME);
    TimerData synchronizedProcTimer =
        TimerData.of(namespace, timestamp, TimeDomain.SYNCHRONIZED_PROCESSING_TIME);

    assertThat(eventTimer, lessThan(procTimer));
    assertThat(eventTimer, lessThan(synchronizedProcTimer));
    assertThat(procTimer, lessThan(synchronizedProcTimer));
  }
",non-flaky,5
78288,apache_beam,TimerInternalsTest.testCompareByNamespace,"  @Test
  public void testCompareByNamespace() {
    Instant timestamp = new Instant(100);
    IntervalWindow firstWindow = new IntervalWindow(new Instant(0), timestamp);
    IntervalWindow secondWindow = new IntervalWindow(timestamp, new Instant(200));
    Coder<IntervalWindow> windowCoder = IntervalWindow.getCoder();

    StateNamespace firstWindowNs = StateNamespaces.window(windowCoder, firstWindow);
    StateNamespace secondWindowNs = StateNamespaces.window(windowCoder, secondWindow);

    TimerData secondEventTime = TimerData.of(firstWindowNs, timestamp, TimeDomain.EVENT_TIME);
    TimerData thirdEventTime = TimerData.of(secondWindowNs, timestamp, TimeDomain.EVENT_TIME);

    assertThat(secondEventTime, lessThan(thirdEventTime));
  }
",non-flaky,5
78289,apache_beam,TimerInternalsTest.testCompareByTimerId,"  @Test
  public void testCompareByTimerId() {
    Instant timestamp = new Instant(100);
    StateNamespace namespace = StateNamespaces.global();

    TimerData id0Timer = TimerData.of(""id0"", namespace, timestamp, TimeDomain.EVENT_TIME);
    TimerData id1Timer = TimerData.of(""id1"", namespace, timestamp, TimeDomain.EVENT_TIME);

    assertThat(id0Timer, lessThan(id1Timer));
  }
",non-flaky,5
78290,apache_beam,SideInputHandlerTest.testIsEmpty,"  @Test
  public void testIsEmpty() {
    SideInputHandler sideInputHandler =
        new SideInputHandler(ImmutableList.of(view1), InMemoryStateInternals.<Void>forKey(null));

    assertFalse(sideInputHandler.isEmpty());

    // create an empty handler
    SideInputHandler emptySideInputHandler =
        new SideInputHandler(ImmutableList.of(), InMemoryStateInternals.<Void>forKey(null));

    assertTrue(emptySideInputHandler.isEmpty());
  }
",non-flaky,5
78291,apache_beam,SideInputHandlerTest.testContains,"  @Test
  public void testContains() {
    SideInputHandler sideInputHandler =
        new SideInputHandler(ImmutableList.of(view1), InMemoryStateInternals.<Void>forKey(null));

    assertTrue(sideInputHandler.contains(view1));
    assertFalse(sideInputHandler.contains(view2));
  }
",non-flaky,5
78292,apache_beam,SideInputHandlerTest.testIsReady,"  @Test
  public void testIsReady() {
    SideInputHandler sideInputHandler =
        new SideInputHandler(
            ImmutableList.of(view1, view2), InMemoryStateInternals.<Void>forKey(null));

    IntervalWindow firstWindow = new IntervalWindow(new Instant(0), new Instant(WINDOW_MSECS_1));

    IntervalWindow secondWindow = new IntervalWindow(new Instant(0), new Instant(WINDOW_MSECS_2));

    // side input should not yet be ready
    assertFalse(sideInputHandler.isReady(view1, firstWindow));

    // add a value for view1
    sideInputHandler.addSideInputValue(
        view1,
        valuesInWindow(
            materializeValuesFor(View.asIterable(), ""Hello""), new Instant(0), firstWindow));

    // now side input should be ready
    assertTrue(sideInputHandler.isReady(view1, firstWindow));

    // second window input should still not be ready
    assertFalse(sideInputHandler.isReady(view1, secondWindow));
  }
",non-flaky,5
78293,apache_beam,SideInputHandlerTest.testNewInputReplacesPreviousInput,"  @Test
  public void testNewInputReplacesPreviousInput() {
    // new input should completely replace old input
    // the creation of the Iterable that has the side input
    // contents happens upstream. this is also where
    // accumulation/discarding is decided.

    SideInputHandler sideInputHandler =
        new SideInputHandler(ImmutableList.of(view1), InMemoryStateInternals.<Void>forKey(null));

    IntervalWindow window = new IntervalWindow(new Instant(0), new Instant(WINDOW_MSECS_1));

    // add a first value for view1
    sideInputHandler.addSideInputValue(
        view1,
        valuesInWindow(materializeValuesFor(View.asIterable(), ""Hello""), new Instant(0), window));

    assertThat(sideInputHandler.get(view1, window), contains(""Hello""));

    // subsequent values should replace existing values
    sideInputHandler.addSideInputValue(
        view1,
        valuesInWindow(
            materializeValuesFor(View.asIterable(), ""Ciao"", ""Buongiorno""), new Instant(0), window));

    assertThat(sideInputHandler.get(view1, window), contains(""Ciao"", ""Buongiorno""));
  }
",non-flaky,5
78294,apache_beam,SideInputHandlerTest.testMultipleWindows,"  @Test
  public void testMultipleWindows() {
    SideInputHandler sideInputHandler =
        new SideInputHandler(ImmutableList.of(view1), InMemoryStateInternals.<Void>forKey(null));

    // two windows that we'll later use for adding elements/retrieving side input
    IntervalWindow firstWindow = new IntervalWindow(new Instant(0), new Instant(WINDOW_MSECS_1));
    IntervalWindow secondWindow =
        new IntervalWindow(new Instant(1000), new Instant(1000 + WINDOW_MSECS_2));

    // add a first value for view1 in the first window
    sideInputHandler.addSideInputValue(
        view1,
        valuesInWindow(
            materializeValuesFor(View.asIterable(), ""Hello""), new Instant(0), firstWindow));

    assertThat(sideInputHandler.get(view1, firstWindow), contains(""Hello""));

    // add something for second window of view1
    sideInputHandler.addSideInputValue(
        view1,
        valuesInWindow(
            materializeValuesFor(View.asIterable(), ""Arrivederci""), new Instant(0), secondWindow));

    assertThat(sideInputHandler.get(view1, secondWindow), contains(""Arrivederci""));

    // contents for first window should be unaffected
    assertThat(sideInputHandler.get(view1, firstWindow), contains(""Hello""));
  }
",non-flaky,5
78295,apache_beam,SideInputHandlerTest.testMultipleSideInputs,"  @Test
  public void testMultipleSideInputs() {
    SideInputHandler sideInputHandler =
        new SideInputHandler(
            ImmutableList.of(view1, view2), InMemoryStateInternals.<Void>forKey(null));

    // two windows that we'll later use for adding elements/retrieving side input
    IntervalWindow firstWindow = new IntervalWindow(new Instant(0), new Instant(WINDOW_MSECS_1));

    // add value for view1 in the first window
    sideInputHandler.addSideInputValue(
        view1,
        valuesInWindow(
            materializeValuesFor(View.asIterable(), ""Hello""), new Instant(0), firstWindow));

    assertThat(sideInputHandler.get(view1, firstWindow), contains(""Hello""));

    // view2 should not have any data
    assertFalse(sideInputHandler.isReady(view2, firstWindow));

    // also add some data for view2
    sideInputHandler.addSideInputValue(
        view2,
        valuesInWindow(
            materializeValuesFor(View.asIterable(), ""Salut""), new Instant(0), firstWindow));

    assertTrue(sideInputHandler.isReady(view2, firstWindow));
    assertThat(sideInputHandler.get(view2, firstWindow), contains(""Salut""));

    // view1 should not be affected by that
    assertThat(sideInputHandler.get(view1, firstWindow), contains(""Hello""));
  }
",non-flaky,5
78296,apache_beam,LateDataDroppingDoFnRunnerTest.testLateDataFilter,"  @Test
  public void testLateDataFilter() throws Exception {
    MetricsContainerImpl container = new MetricsContainerImpl(""any"");
    MetricsEnvironment.setCurrentContainer(container);
    when(mockTimerInternals.currentInputWatermarkTime()).thenReturn(new Instant(15L));

    LateDataFilter lateDataFilter =
        new LateDataFilter(WindowingStrategy.of(WINDOW_FN), mockTimerInternals);

    Iterable<WindowedValue<Integer>> actual =
        lateDataFilter.filter(
            ""a"",
            ImmutableList.of(
                createDatum(13, 13L),
                createDatum(5, 5L), // late element, earlier than 4L.
                createDatum(16, 16L),
                createDatum(18, 18L)));

    Iterable<WindowedValue<Integer>> expected =
        ImmutableList.of(createDatum(13, 13L), createDatum(16, 16L), createDatum(18, 18L));
    assertThat(expected, containsInAnyOrder(Iterables.toArray(actual, WindowedValue.class)));
    long droppedValues =
        container
            .getCounter(
                MetricName.named(
                    LateDataDroppingDoFnRunner.class,
                    LateDataDroppingDoFnRunner.DROPPED_DUE_TO_LATENESS))
            .getCumulative();
    assertEquals(1, droppedValues);
    // Ensure that reiterating returns the same results and doesn't increment the counter again.
    assertThat(expected, containsInAnyOrder(Iterables.toArray(actual, WindowedValue.class)));
    droppedValues =
        container
            .getCounter(
                MetricName.named(
                    LateDataDroppingDoFnRunner.class,
                    LateDataDroppingDoFnRunner.DROPPED_DUE_TO_LATENESS))
            .getCumulative();
    assertEquals(1, droppedValues);
  }
",non-flaky,5
78297,apache_beam,InMemoryStateInternalsTest.testSameInstance,"    @Test
    public void testSameInstance() {
      assertSameInstance(STRING_VALUE_ADDR);
      assertSameInstance(SUM_INTEGER_ADDR);
      assertSameInstance(STRING_BAG_ADDR);
      assertSameInstance(STRING_SET_ADDR);
      assertSameInstance(STRING_MAP_ADDR);
      assertSameInstance(WATERMARK_EARLIEST_ADDR);
    }
",non-flaky,5
78298,apache_beam,OutputAndTimeBoundedSplittableProcessElementInvokerTest.testInvokeProcessElementOutputBounded,"  @Test
  public void testInvokeProcessElementOutputBounded() throws Exception {
    SplittableProcessElementInvoker<Void, String, OffsetRange, OffsetRangeTracker>.Result res =
        runTest(10000, Duration.ZERO, Integer.MAX_VALUE, Duration.ZERO);
    assertFalse(res.getContinuation().shouldResume());
    OffsetRange residualRange = res.getResidualRestriction();
    // Should process the first 100 elements.
    assertEquals(1000, residualRange.getFrom());
    assertEquals(10000, residualRange.getTo());
  }
",non-flaky,5
78299,apache_beam,OutputAndTimeBoundedSplittableProcessElementInvokerTest.testInvokeProcessElementTimeBounded,"  @Test
  public void testInvokeProcessElementTimeBounded() throws Exception {
    SplittableProcessElementInvoker<Void, String, OffsetRange, OffsetRangeTracker>.Result res =
        runTest(10000, Duration.ZERO, Integer.MAX_VALUE, Duration.millis(100));
    assertFalse(res.getContinuation().shouldResume());
    OffsetRange residualRange = res.getResidualRestriction();
    // Should process ideally around 30 elements - but due to timing flakiness, we can't enforce
    // that precisely. Just test that it's not egregiously off.
    assertThat(residualRange.getFrom(), greaterThan(10L));
    assertThat(residualRange.getFrom(), lessThan(100L));
    assertEquals(10000, residualRange.getTo());
  }
",non-flaky,5
78300,apache_beam,OutputAndTimeBoundedSplittableProcessElementInvokerTest.testInvokeProcessElementTimeBoundedWithStartupDelay,"  @Test
  public void testInvokeProcessElementTimeBoundedWithStartupDelay() throws Exception {
    SplittableProcessElementInvoker<Void, String, OffsetRange, OffsetRangeTracker>.Result res =
        runTest(10000, Duration.standardSeconds(3), Integer.MAX_VALUE, Duration.millis(100));
    assertFalse(res.getContinuation().shouldResume());
    OffsetRange residualRange = res.getResidualRestriction();
    // Same as above, but this time it counts from the time of the first tryClaim() call
    assertThat(residualRange.getFrom(), greaterThan(10L));
    assertThat(residualRange.getFrom(), lessThan(100L));
    assertEquals(10000, residualRange.getTo());
  }
",non-flaky,5
78301,apache_beam,OutputAndTimeBoundedSplittableProcessElementInvokerTest.testInvokeProcessElementVoluntaryReturnStop,"  @Test
  public void testInvokeProcessElementVoluntaryReturnStop() throws Exception {
    SplittableProcessElementInvoker<Void, String, OffsetRange, OffsetRangeTracker>.Result res =
        runTest(5, Duration.ZERO, Integer.MAX_VALUE, Duration.millis(100));
    assertFalse(res.getContinuation().shouldResume());
    assertNull(res.getResidualRestriction());
  }
",non-flaky,5
78302,apache_beam,OutputAndTimeBoundedSplittableProcessElementInvokerTest.testInvokeProcessElementVoluntaryReturnResume,"  @Test
  public void testInvokeProcessElementVoluntaryReturnResume() throws Exception {
    SplittableProcessElementInvoker<Void, String, OffsetRange, OffsetRangeTracker>.Result res =
        runTest(10, Duration.ZERO, 5, Duration.millis(100));
    assertTrue(res.getContinuation().shouldResume());
    assertEquals(new OffsetRange(5, 10), res.getResidualRestriction());
  }
",non-flaky,5
78303,apache_beam,OutputAndTimeBoundedSplittableProcessElementInvokerTest.process,"  @Test
  public void testInvokeProcessElementOutputDisallowedBeforeTryClaim() throws Exception {
    DoFn<Void, String> brokenFn =
        new DoFn<Void, String>() {
          @ProcessElement
          public void process(ProcessContext c, OffsetRangeTracker tracker) {
            c.output(""foo"");
          }
",non-flaky,5
78304,apache_beam,OutputAndTimeBoundedSplittableProcessElementInvokerTest.process,"  @Test
  public void testInvokeProcessElementOutputDisallowedAfterFailedTryClaim() throws Exception {
    DoFn<Void, String> brokenFn =
        new DoFn<Void, String>() {
          @ProcessElement
          public void process(ProcessContext c, OffsetRangeTracker tracker) {
            assertFalse(tracker.tryClaim(6L));
            c.output(""foo"");
          }
",non-flaky,5
78305,apache_beam,InMemoryMultimapSideInputViewTest.testStructuralKeyEquality,"  @Test
  public void testStructuralKeyEquality() {
    MultimapView<byte[], Integer> view =
        InMemoryMultimapSideInputView.fromIterable(
            ByteArrayCoder.of(),
            ImmutableList.of(KV.of(new byte[] {0x00}, 0), KV.of(new byte[] {0x01}, 1)));
    assertEquals(view.get(new byte[] {0x00}), ImmutableList.of(0));
    assertEquals(view.get(new byte[] {0x01}), ImmutableList.of(1));
    assertEquals(view.get(new byte[] {0x02}), ImmutableList.of());
  }
",non-flaky,5
78306,apache_beam,InMemoryMultimapSideInputViewTest.testValueGrouping,"  @Test
  public void testValueGrouping() {
    MultimapView<String, String> view =
        InMemoryMultimapSideInputView.fromIterable(
            StringUtf8Coder.of(),
            ImmutableList.of(KV.of(""A"", ""a1""), KV.of(""A"", ""a2""), KV.of(""B"", ""b1"")));
    assertEquals(view.get(""A""), ImmutableList.of(""a1"", ""a2""));
    assertEquals(view.get(""B""), ImmutableList.of(""b1""));
    assertEquals(view.get(""C""), ImmutableList.of());
  }
",non-flaky,5
78307,apache_beam,SimpleDoFnRunnerTest.testProcessElementExceptionsWrappedAsUserCodeException,"  @Test
  public void testProcessElementExceptionsWrappedAsUserCodeException() {
    ThrowingDoFn fn = new ThrowingDoFn();
    DoFnRunner<String, String> runner =
        new SimpleDoFnRunner<>(
            null,
            fn,
            NullSideInputReader.empty(),
            null,
            null,
            Collections.emptyList(),
            mockStepContext,
            null,
            Collections.emptyMap(),
            WindowingStrategy.of(new GlobalWindows()));

    thrown.expect(UserCodeException.class);
    thrown.expectCause(is(fn.exceptionToThrow));

    runner.processElement(WindowedValue.valueInGlobalWindow(""anyValue""));
  }
",non-flaky,5
78308,apache_beam,SimpleDoFnRunnerTest.testOnTimerExceptionsWrappedAsUserCodeException,"  @Test
  public void testOnTimerExceptionsWrappedAsUserCodeException() {
    ThrowingDoFn fn = new ThrowingDoFn();
    DoFnRunner<String, String> runner =
        new SimpleDoFnRunner<>(
            null,
            fn,
            NullSideInputReader.empty(),
            null,
            null,
            Collections.emptyList(),
            mockStepContext,
            null,
            Collections.emptyMap(),
            WindowingStrategy.of(new GlobalWindows()));

    thrown.expect(UserCodeException.class);
    thrown.expectCause(is(fn.exceptionToThrow));

    runner.onTimer(
        ThrowingDoFn.TIMER_ID, GlobalWindow.INSTANCE, new Instant(0), TimeDomain.EVENT_TIME);
  }
",non-flaky,5
78309,apache_beam,SimpleDoFnRunnerTest.testTimerSet,"  @Test
  public void testTimerSet() {
    WindowFn<?, ?> windowFn = new GlobalWindows();
    DoFnWithTimers<GlobalWindow> fn = new DoFnWithTimers(windowFn.windowCoder());
    DoFnRunner<String, String> runner =
        new SimpleDoFnRunner<>(
            null,
            fn,
            NullSideInputReader.empty(),
            null,
            null,
            Collections.emptyList(),
            mockStepContext,
            null,
            Collections.emptyMap(),
            WindowingStrategy.of(new GlobalWindows()));

    // Setting the timer needs the current time, as it is set relative
    Instant currentTime = new Instant(42);
    when(mockTimerInternals.currentInputWatermarkTime()).thenReturn(currentTime);

    runner.processElement(WindowedValue.valueInGlobalWindow(""anyValue""));

    verify(mockTimerInternals)
        .setTimer(
            StateNamespaces.window(new GlobalWindows().windowCoder(), GlobalWindow.INSTANCE),
            DoFnWithTimers.TIMER_ID,
            currentTime.plus(DoFnWithTimers.TIMER_OFFSET),
            TimeDomain.EVENT_TIME);
  }
",non-flaky,5
78310,apache_beam,SimpleDoFnRunnerTest.testStartBundleExceptionsWrappedAsUserCodeException,"  @Test
  public void testStartBundleExceptionsWrappedAsUserCodeException() {
    ThrowingDoFn fn = new ThrowingDoFn();
    DoFnRunner<String, String> runner =
        new SimpleDoFnRunner<>(
            null,
            fn,
            NullSideInputReader.empty(),
            null,
            null,
            Collections.emptyList(),
            mockStepContext,
            null,
            Collections.emptyMap(),
            WindowingStrategy.of(new GlobalWindows()));

    thrown.expect(UserCodeException.class);
    thrown.expectCause(is(fn.exceptionToThrow));

    runner.startBundle();
  }
",non-flaky,5
78311,apache_beam,SimpleDoFnRunnerTest.testFinishBundleExceptionsWrappedAsUserCodeException,"  @Test
  public void testFinishBundleExceptionsWrappedAsUserCodeException() {
    ThrowingDoFn fn = new ThrowingDoFn();
    DoFnRunner<String, String> runner =
        new SimpleDoFnRunner<>(
            null,
            fn,
            NullSideInputReader.empty(),
            null,
            null,
            Collections.emptyList(),
            mockStepContext,
            null,
            Collections.emptyMap(),
            WindowingStrategy.of(new GlobalWindows()));

    thrown.expect(UserCodeException.class);
    thrown.expectCause(is(fn.exceptionToThrow));

    runner.finishBundle();
  }
",non-flaky,5
78312,apache_beam,SimpleDoFnRunnerTest.testOnTimerCalled,"  @Test
  public void testOnTimerCalled() {
    WindowFn<?, GlobalWindow> windowFn = new GlobalWindows();
    DoFnWithTimers<GlobalWindow> fn = new DoFnWithTimers(windowFn.windowCoder());
    DoFnRunner<String, String> runner =
        new SimpleDoFnRunner<>(
            null,
            fn,
            NullSideInputReader.empty(),
            null,
            null,
            Collections.emptyList(),
            mockStepContext,
            null,
            Collections.emptyMap(),
            WindowingStrategy.of(windowFn));

    Instant currentTime = new Instant(42);
    Duration offset = Duration.millis(37);

    // Mocking is not easily compatible with annotation analysis, so we manually record
    // the method call.
    runner.onTimer(
        DoFnWithTimers.TIMER_ID,
        GlobalWindow.INSTANCE,
        currentTime.plus(offset),
        TimeDomain.EVENT_TIME);

    assertThat(
        fn.onTimerInvocations,
        contains(
            TimerData.of(
                DoFnWithTimers.TIMER_ID,
                StateNamespaces.window(windowFn.windowCoder(), GlobalWindow.INSTANCE),
                currentTime.plus(offset),
                TimeDomain.EVENT_TIME)));
  }
",non-flaky,5
78313,apache_beam,SimpleDoFnRunnerTest.testBackwardsInTimeNoSkew,"  @Test
  public void testBackwardsInTimeNoSkew() {
    SkewingDoFn fn = new SkewingDoFn(Duration.ZERO);
    DoFnRunner<Duration, Duration> runner =
        new SimpleDoFnRunner<>(
            null,
            fn,
            NullSideInputReader.empty(),
            new ListOutputManager(),
            new TupleTag<>(),
            Collections.emptyList(),
            mockStepContext,
            null,
            Collections.emptyMap(),
            WindowingStrategy.of(new GlobalWindows()));

    runner.startBundle();
    // An element output at the current timestamp is fine.
    runner.processElement(
        WindowedValue.timestampedValueInGlobalWindow(Duration.ZERO, new Instant(0)));
    thrown.expect(UserCodeException.class);
    thrown.expectCause(isA(IllegalArgumentException.class));
    thrown.expectMessage(""must be no earlier"");
    thrown.expectMessage(
        String.format(""timestamp of the current input (%s)"", new Instant(0).toString()));
    thrown.expectMessage(
        String.format(
            ""the allowed skew (%s)"", PeriodFormat.getDefault().print(Duration.ZERO.toPeriod())));
    // An element output before (current time - skew) is forbidden
    runner.processElement(
        WindowedValue.timestampedValueInGlobalWindow(Duration.millis(1L), new Instant(0)));
  }
",non-flaky,5
78314,apache_beam,SimpleDoFnRunnerTest.testSkew,"  @Test
  public void testSkew() {
    SkewingDoFn fn = new SkewingDoFn(Duration.standardMinutes(10L));
    DoFnRunner<Duration, Duration> runner =
        new SimpleDoFnRunner<>(
            null,
            fn,
            NullSideInputReader.empty(),
            new ListOutputManager(),
            new TupleTag<>(),
            Collections.emptyList(),
            mockStepContext,
            null,
            Collections.emptyMap(),
            WindowingStrategy.of(new GlobalWindows()));

    runner.startBundle();
    // Outputting between ""now"" and ""now - allowed skew"" succeeds.
    runner.processElement(
        WindowedValue.timestampedValueInGlobalWindow(Duration.standardMinutes(5L), new Instant(0)));
    thrown.expect(UserCodeException.class);
    thrown.expectCause(isA(IllegalArgumentException.class));
    thrown.expectMessage(""must be no earlier"");
    thrown.expectMessage(
        String.format(""timestamp of the current input (%s)"", new Instant(0).toString()));
    thrown.expectMessage(
        String.format(
            ""the allowed skew (%s)"",
            PeriodFormat.getDefault().print(Duration.standardMinutes(10L).toPeriod())));
    // Outputting before ""now - allowed skew"" fails.
    runner.processElement(
        WindowedValue.timestampedValueInGlobalWindow(Duration.standardHours(1L), new Instant(0)));
  }
",non-flaky,5
78315,apache_beam,SimpleDoFnRunnerTest.testInfiniteSkew,"  @Test
  public void testInfiniteSkew() {
    SkewingDoFn fn = new SkewingDoFn(Duration.millis(Long.MAX_VALUE));
    DoFnRunner<Duration, Duration> runner =
        new SimpleDoFnRunner<>(
            null,
            fn,
            NullSideInputReader.empty(),
            new ListOutputManager(),
            new TupleTag<>(),
            Collections.emptyList(),
            mockStepContext,
            null,
            Collections.emptyMap(),
            WindowingStrategy.of(new GlobalWindows()));

    runner.startBundle();
    runner.processElement(
        WindowedValue.timestampedValueInGlobalWindow(Duration.millis(1L), new Instant(0)));
    runner.processElement(
        WindowedValue.timestampedValueInGlobalWindow(
            Duration.millis(1L), BoundedWindow.TIMESTAMP_MIN_VALUE.plus(Duration.millis(1))));
    runner.processElement(
        WindowedValue.timestampedValueInGlobalWindow(
            // This is the maximum amount a timestamp in beam can move (from the maximum timestamp
            // to the minimum timestamp).
            Duration.millis(BoundedWindow.TIMESTAMP_MAX_VALUE.getMillis())
                .minus(Duration.millis(BoundedWindow.TIMESTAMP_MIN_VALUE.getMillis())),
            BoundedWindow.TIMESTAMP_MAX_VALUE));
  }
",non-flaky,5
78316,apache_beam,ReduceFnRunnerTest.testProcessingTimeTimerDoesNotGc,"  @Test
  public void testProcessingTimeTimerDoesNotGc() throws Exception {
    WindowingStrategy<?, IntervalWindow> strategy =
        WindowingStrategy.of((WindowFn<?, IntervalWindow>) FixedWindows.of(Duration.millis(100)))
            .withTimestampCombiner(TimestampCombiner.EARLIEST)
            .withMode(AccumulationMode.ACCUMULATING_FIRED_PANES)
            .withAllowedLateness(Duration.ZERO)
            .withTrigger(
                Repeatedly.forever(
                    AfterProcessingTime.pastFirstElementInPane().plusDelayOf(Duration.millis(10))));

    ReduceFnTester<Integer, Integer, IntervalWindow> tester =
        ReduceFnTester.combining(strategy, Sum.ofIntegers(), VarIntCoder.of());

    tester.advanceProcessingTime(new Instant(5000));
    injectElement(tester, 2); // processing timer @ 5000 + 10; EOW timer @ 100
    injectElement(tester, 5);

    tester.advanceProcessingTime(new Instant(10000));

    tester.assertHasOnlyGlobalAndStateFor(new IntervalWindow(new Instant(0), new Instant(100)));

    assertThat(
        tester.extractOutput(),
        contains(
            isSingleWindowedValue(
                equalTo(7), 2, 0, 100, PaneInfo.createPane(true, false, Timing.EARLY, 0, 0))));
  }
",non-flaky,5
78317,apache_beam,ReduceFnRunnerTest.testOnElementBufferingDiscarding,"  @Test
  public void testOnElementBufferingDiscarding() throws Exception {
    // Test basic execution of a trigger using a non-combining window set and discarding mode.
    MetricsContainerImpl container = new MetricsContainerImpl(""any"");
    MetricsEnvironment.setCurrentContainer(container);
    ReduceFnTester<Integer, Iterable<Integer>, IntervalWindow> tester =
        ReduceFnTester.nonCombining(
            FixedWindows.of(Duration.millis(10)),
            mockTriggerStateMachine,
            AccumulationMode.DISCARDING_FIRED_PANES,
            Duration.millis(100),
            ClosingBehavior.FIRE_IF_NON_EMPTY);

    // Pane of {1, 2}
    injectElement(tester, 1);
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    injectElement(tester, 2);
    assertThat(
        tester.extractOutput(),
        contains(isSingleWindowedValue(containsInAnyOrder(1, 2), 1, 0, 10)));

    // Pane of just 3, and finish
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    triggerShouldFinish(mockTriggerStateMachine);
    injectElement(tester, 3);
    assertThat(
        tester.extractOutput(), contains(isSingleWindowedValue(containsInAnyOrder(3), 3, 0, 10)));
    assertTrue(tester.isMarkedFinished(firstWindow));
    tester.assertHasOnlyGlobalAndFinishedSetsFor(firstWindow);

    // This element shouldn't be seen, because the trigger has finished
    injectElement(tester, 4);

    long droppedElements =
        container
            .getCounter(
                MetricName.named(ReduceFnRunner.class, ReduceFnRunner.DROPPED_DUE_TO_CLOSED_WINDOW))
            .getCumulative();
    assertEquals(1, droppedElements);
  }
",non-flaky,5
78318,apache_beam,ReduceFnRunnerTest.testOnElementBufferingAccumulating,"  @Test
  public void testOnElementBufferingAccumulating() throws Exception {
    // Test basic execution of a trigger using a non-combining window set and accumulating mode.
    ReduceFnTester<Integer, Iterable<Integer>, IntervalWindow> tester =
        ReduceFnTester.nonCombining(
            FixedWindows.of(Duration.millis(10)),
            mockTriggerStateMachine,
            AccumulationMode.ACCUMULATING_FIRED_PANES,
            Duration.millis(100),
            ClosingBehavior.FIRE_IF_NON_EMPTY);

    injectElement(tester, 1);

    // Fires {1, 2}
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    injectElement(tester, 2);

    // Fires {1, 2, 3} because we are in accumulating mode
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    triggerShouldFinish(mockTriggerStateMachine);
    injectElement(tester, 3);

    // This element shouldn't be seen, because the trigger has finished
    injectElement(tester, 4);

    assertThat(
        tester.extractOutput(),
        contains(
            isSingleWindowedValue(containsInAnyOrder(1, 2), 1, 0, 10),
            isSingleWindowedValue(containsInAnyOrder(1, 2, 3), 3, 0, 10)));
    assertTrue(tester.isMarkedFinished(firstWindow));
    tester.assertHasOnlyGlobalAndFinishedSetsFor(firstWindow);
  }
",non-flaky,5
78319,apache_beam,ReduceFnRunnerTest.testSessionEowAndGcTogether,"  @Test
  public void testSessionEowAndGcTogether() throws Exception {
    ReduceFnTester<Integer, Iterable<Integer>, IntervalWindow> tester =
        ReduceFnTester.nonCombining(
            Sessions.withGapDuration(Duration.millis(10)),
            DefaultTriggerStateMachine.of(),
            AccumulationMode.ACCUMULATING_FIRED_PANES,
            Duration.millis(50),
            ClosingBehavior.FIRE_ALWAYS);

    tester.setAutoAdvanceOutputWatermark(true);

    tester.advanceInputWatermark(new Instant(0));
    injectElement(tester, 1);
    tester.advanceInputWatermark(new Instant(100));

    assertThat(
        tester.extractOutput(),
        contains(
            isSingleWindowedValue(
                contains(1), 1, 1, 11, PaneInfo.createPane(true, true, Timing.ON_TIME))));
  }
",non-flaky,5
78320,apache_beam,ReduceFnRunnerTest.testFixedWindowsEowAndGcTogether,"  @Test
  public void testFixedWindowsEowAndGcTogether() throws Exception {
    ReduceFnTester<Integer, Iterable<Integer>, IntervalWindow> tester =
        ReduceFnTester.nonCombining(
            FixedWindows.of(Duration.millis(10)),
            DefaultTriggerStateMachine.of(),
            AccumulationMode.ACCUMULATING_FIRED_PANES,
            Duration.millis(50),
            ClosingBehavior.FIRE_ALWAYS);

    tester.setAutoAdvanceOutputWatermark(true);

    tester.advanceInputWatermark(new Instant(0));
    injectElement(tester, 1);
    tester.advanceInputWatermark(new Instant(100));

    assertThat(
        tester.extractOutput(),
        contains(
            isSingleWindowedValue(
                contains(1), 1, 0, 10, PaneInfo.createPane(true, true, Timing.ON_TIME))));
  }
",non-flaky,5
78321,apache_beam,ReduceFnRunnerTest.testFixedWindowsEowAndGcTogetherFireIfNonEmpty,"  @Test
  public void testFixedWindowsEowAndGcTogetherFireIfNonEmpty() throws Exception {
    ReduceFnTester<Integer, Iterable<Integer>, IntervalWindow> tester =
        ReduceFnTester.nonCombining(
            FixedWindows.of(Duration.millis(10)),
            DefaultTriggerStateMachine.of(),
            AccumulationMode.ACCUMULATING_FIRED_PANES,
            Duration.millis(50),
            ClosingBehavior.FIRE_IF_NON_EMPTY);

    tester.setAutoAdvanceOutputWatermark(true);

    tester.advanceInputWatermark(new Instant(0));
    injectElement(tester, 1);
    tester.advanceInputWatermark(new Instant(100));

    List<WindowedValue<Iterable<Integer>>> output = tester.extractOutput();
    assertThat(
        output,
        contains(
            isSingleWindowedValue(
                contains(1), 1, 0, 10, PaneInfo.createPane(true, true, Timing.ON_TIME))));
  }
",non-flaky,5
78322,apache_beam,ReduceFnRunnerTest.testOnlyOneOnTimePane,"  @Test
  public void testOnlyOneOnTimePane() throws Exception {
    WindowingStrategy<?, IntervalWindow> strategy =
        WindowingStrategy.of((WindowFn<?, IntervalWindow>) FixedWindows.of(Duration.millis(10)))
            .withTrigger(DefaultTrigger.of())
            .withMode(AccumulationMode.ACCUMULATING_FIRED_PANES)
            .withAllowedLateness(Duration.millis(100));

    ReduceFnTester<Integer, Integer, IntervalWindow> tester =
        ReduceFnTester.combining(strategy, Sum.ofIntegers(), VarIntCoder.of());

    tester.advanceInputWatermark(new Instant(0));

    int value1 = 1;
    int value2 = 3;

    // A single element that should be in the ON_TIME output
    tester.injectElements(TimestampedValue.of(value1, new Instant(1)));

    // Should fire ON_TIME
    tester.advanceInputWatermark(new Instant(10));

    // The DefaultTrigger should cause output labeled LATE, even though it does not have to be
    // labeled as such.
    tester.injectElements(TimestampedValue.of(value2, new Instant(3)));

    List<WindowedValue<Integer>> output = tester.extractOutput();
    assertEquals(2, output.size());

    assertThat(output.get(0), isWindowedValue(equalTo(value1)));
    assertThat(output.get(1), isWindowedValue(equalTo(value1 + value2)));

    assertThat(
        output.get(0),
        WindowMatchers.valueWithPaneInfo(PaneInfo.createPane(true, false, Timing.ON_TIME, 0, 0)));
    assertThat(
        output.get(1),
        WindowMatchers.valueWithPaneInfo(PaneInfo.createPane(false, false, Timing.LATE, 1, 1)));
  }
",non-flaky,5
78323,apache_beam,ReduceFnRunnerTest.testOnElementCombiningDiscarding,"  @Test
  public void testOnElementCombiningDiscarding() throws Exception {
    // Test basic execution of a trigger using a non-combining window set and discarding mode.
    WindowingStrategy<?, IntervalWindow> strategy =
        WindowingStrategy.of((WindowFn<?, IntervalWindow>) FixedWindows.of(Duration.millis(10)))
            .withTimestampCombiner(TimestampCombiner.EARLIEST)
            .withMode(AccumulationMode.DISCARDING_FIRED_PANES)
            .withAllowedLateness(Duration.millis(100));

    ReduceFnTester<Integer, Integer, IntervalWindow> tester =
        ReduceFnTester.combining(
            strategy, mockTriggerStateMachine, Sum.ofIntegers(), VarIntCoder.of());

    injectElement(tester, 2);

    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    injectElement(tester, 3);

    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    triggerShouldFinish(mockTriggerStateMachine);
    injectElement(tester, 4);

    // This element shouldn't be seen, because the trigger has finished
    injectElement(tester, 6);

    assertThat(
        tester.extractOutput(),
        contains(
            isSingleWindowedValue(equalTo(5), 2, 0, 10),
            isSingleWindowedValue(equalTo(4), 4, 0, 10)));
    assertTrue(tester.isMarkedFinished(firstWindow));
    tester.assertHasOnlyGlobalAndFinishedSetsFor(firstWindow);
  }
",non-flaky,5
78324,apache_beam,ReduceFnRunnerTest.testLateProcessingTimeTimer,"  @Test
  public void testLateProcessingTimeTimer() throws Exception {
    WindowingStrategy<?, IntervalWindow> strategy =
        WindowingStrategy.of((WindowFn<?, IntervalWindow>) FixedWindows.of(Duration.millis(100)))
            .withTimestampCombiner(TimestampCombiner.EARLIEST)
            .withMode(AccumulationMode.ACCUMULATING_FIRED_PANES)
            .withAllowedLateness(Duration.ZERO)
            .withTrigger(
                Repeatedly.forever(
                    AfterProcessingTime.pastFirstElementInPane().plusDelayOf(Duration.millis(10))));

    ReduceFnTester<Integer, Integer, IntervalWindow> tester =
        ReduceFnTester.combining(strategy, Sum.ofIntegers(), VarIntCoder.of());

    tester.advanceProcessingTime(new Instant(5000));
    injectElement(tester, 2); // processing timer @ 5000 + 10; EOW timer @ 100
    injectElement(tester, 5);

    // After this advancement, the window is expired and only the GC process
    // should be allowed to touch it
    tester.advanceInputWatermarkNoTimers(new Instant(100));

    // This should not output
    tester.advanceProcessingTime(new Instant(6000));

    assertThat(tester.extractOutput(), emptyIterable());
  }
",non-flaky,5
78325,apache_beam,ReduceFnRunnerTest.testCombiningAccumulatingProcessingTime,"  @Test
  public void testCombiningAccumulatingProcessingTime() throws Exception {
    WindowingStrategy<?, IntervalWindow> strategy =
        WindowingStrategy.of((WindowFn<?, IntervalWindow>) FixedWindows.of(Duration.millis(100)))
            .withTimestampCombiner(TimestampCombiner.EARLIEST)
            .withMode(AccumulationMode.ACCUMULATING_FIRED_PANES)
            .withAllowedLateness(Duration.ZERO)
            .withTrigger(
                Repeatedly.forever(
                    AfterProcessingTime.pastFirstElementInPane().plusDelayOf(Duration.millis(10))));

    ReduceFnTester<Integer, Integer, IntervalWindow> tester =
        ReduceFnTester.combining(strategy, Sum.ofIntegers(), VarIntCoder.of());

    tester.advanceProcessingTime(new Instant(5000));
    injectElement(tester, 2); // processing timer @ 5000 + 10; EOW timer @ 100
    injectElement(tester, 5);

    tester.advanceInputWatermarkNoTimers(new Instant(100));
    tester.advanceProcessingTimeNoTimers(new Instant(5010));

    // Fires the GC/EOW timer at the same time as the processing time timer.
    tester.fireTimers(
        new IntervalWindow(new Instant(0), new Instant(100)),
        TimestampedValue.of(TimeDomain.EVENT_TIME, new Instant(100)),
        TimestampedValue.of(TimeDomain.PROCESSING_TIME, new Instant(5010)));

    assertThat(
        tester.extractOutput(),
        contains(
            isSingleWindowedValue(
                equalTo(7), 2, 0, 100, PaneInfo.createPane(true, true, Timing.ON_TIME, 0, 0))));
  }
",non-flaky,5
78326,apache_beam,ReduceFnRunnerTest.element,"  @Test
  public void testFixedWindowEndOfTimeGarbageCollection() throws Exception {
    Duration allowedLateness = Duration.standardDays(365);
    Duration windowSize = Duration.millis(10);
    WindowFn<Object, IntervalWindow> windowFn = FixedWindows.of(windowSize);

    // This timestamp falls into a window where the end of the window is before the end of the
    // global window - the ""end of time"" - yet its expiration time is after.
    final Instant elementTimestamp =
        GlobalWindow.INSTANCE.maxTimestamp().minus(allowedLateness).plus(1);

    IntervalWindow window =
        Iterables.getOnlyElement(
            windowFn.assignWindows(
                windowFn.new AssignContext() {
                  @Override
                  public Object element() {
                    throw new UnsupportedOperationException();
                  }
",non-flaky,5
78327,apache_beam,ReduceFnRunnerTest.testCombiningAccumulatingProcessingTimeSeparateBundles,"  @Test
  public void testCombiningAccumulatingProcessingTimeSeparateBundles() throws Exception {
    WindowingStrategy<?, IntervalWindow> strategy =
        WindowingStrategy.of((WindowFn<?, IntervalWindow>) FixedWindows.of(Duration.millis(100)))
            .withTimestampCombiner(TimestampCombiner.EARLIEST)
            .withMode(AccumulationMode.ACCUMULATING_FIRED_PANES)
            .withAllowedLateness(Duration.ZERO)
            .withTrigger(
                Repeatedly.forever(
                    AfterProcessingTime.pastFirstElementInPane().plusDelayOf(Duration.millis(10))));

    ReduceFnTester<Integer, Integer, IntervalWindow> tester =
        ReduceFnTester.combining(strategy, Sum.ofIntegers(), VarIntCoder.of());

    tester.advanceProcessingTime(new Instant(5000));
    injectElement(tester, 2); // processing timer @ 5000 + 10; EOW timer @ 100
    injectElement(tester, 5);

    tester.advanceInputWatermark(new Instant(100));
    tester.advanceProcessingTime(new Instant(5011));

    assertThat(
        tester.extractOutput(),
        contains(
            isSingleWindowedValue(
                equalTo(7), 2, 0, 100, PaneInfo.createPane(true, true, Timing.ON_TIME, 0, 0))));
  }
",non-flaky,5
78328,apache_beam,ReduceFnRunnerTest.testCombiningAccumulatingEventTime,"  @Test
  public void testCombiningAccumulatingEventTime() throws Exception {
    WindowingStrategy<?, IntervalWindow> strategy =
        WindowingStrategy.of((WindowFn<?, IntervalWindow>) FixedWindows.of(Duration.millis(100)))
            .withTimestampCombiner(TimestampCombiner.EARLIEST)
            .withMode(AccumulationMode.ACCUMULATING_FIRED_PANES)
            .withAllowedLateness(Duration.millis(1))
            .withTrigger(Repeatedly.forever(AfterWatermark.pastEndOfWindow()));

    ReduceFnTester<Integer, Integer, IntervalWindow> tester =
        ReduceFnTester.combining(strategy, Sum.ofIntegers(), VarIntCoder.of());

    injectElement(tester, 2); // processing timer @ 5000 + 10; EOW timer @ 100
    injectElement(tester, 5);

    tester.advanceInputWatermark(new Instant(1000));

    assertThat(
        tester.extractOutput(),
        contains(
            isSingleWindowedValue(
                equalTo(7), 2, 0, 100, PaneInfo.createPane(true, true, Timing.ON_TIME, 0, 0))));
  }
",non-flaky,5
78329,apache_beam,ReduceFnRunnerTest.testOnElementCombiningAccumulating,"  @Test
  public void testOnElementCombiningAccumulating() throws Exception {
    // Test basic execution of a trigger using a non-combining window set and accumulating mode.
    WindowingStrategy<?, IntervalWindow> strategy =
        WindowingStrategy.of((WindowFn<?, IntervalWindow>) FixedWindows.of(Duration.millis(10)))
            .withTimestampCombiner(TimestampCombiner.EARLIEST)
            .withMode(AccumulationMode.ACCUMULATING_FIRED_PANES)
            .withAllowedLateness(Duration.millis(100));

    ReduceFnTester<Integer, Integer, IntervalWindow> tester =
        ReduceFnTester.combining(
            strategy, mockTriggerStateMachine, Sum.ofIntegers(), VarIntCoder.of());

    injectElement(tester, 1);

    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    injectElement(tester, 2);

    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    triggerShouldFinish(mockTriggerStateMachine);
    injectElement(tester, 3);

    // This element shouldn't be seen, because the trigger has finished
    injectElement(tester, 4);

    assertThat(
        tester.extractOutput(),
        contains(
            isSingleWindowedValue(equalTo(3), 1, 0, 10),
            isSingleWindowedValue(equalTo(6), 3, 0, 10)));
    assertTrue(tester.isMarkedFinished(firstWindow));
    tester.assertHasOnlyGlobalAndFinishedSetsFor(firstWindow);
  }
",non-flaky,5
78330,apache_beam,ReduceFnRunnerTest.testOnElementCombiningWithContext,"  @Test
  public void testOnElementCombiningWithContext() throws Exception {
    // Create values at timestamps 0 .. 8, windowed into fixed windows of 2.
    // Side input windowed into fixed windows of 4:
    // main: [ 0 1 ] [ 2 3 ] [ 4 5 ] [ 6 7 ]
    // side: [     100     ] [     104     ]
    // Combine using a CombineFn ""side input + sum(main inputs)"".
    final int firstWindowSideInput = 100;
    final int secondWindowSideInput = 104;
    final Integer expectedValue = firstWindowSideInput;
    WindowingStrategy<?, IntervalWindow> mainInputWindowingStrategy =
        WindowingStrategy.of(FixedWindows.of(Duration.millis(2)))
            .withMode(AccumulationMode.ACCUMULATING_FIRED_PANES);

    WindowMappingFn<?> sideInputWindowMappingFn =
        FixedWindows.of(Duration.millis(4)).getDefaultWindowMappingFn();
    when(mockView.getWindowMappingFn()).thenReturn((WindowMappingFn) sideInputWindowMappingFn);

    TestOptions options = PipelineOptionsFactory.as(TestOptions.class);
    options.setValue(expectedValue);

    when(mockSideInputReader.contains(any(PCollectionView.class))).thenReturn(true);
    when(mockSideInputReader.get(any(PCollectionView.class), any(BoundedWindow.class)))
        .then(
            invocation -> {
              IntervalWindow sideInputWindow = (IntervalWindow) invocation.getArguments()[1];
              long startMs = sideInputWindow.start().getMillis();
              long endMs = sideInputWindow.end().getMillis();
              // Window should have been produced by sideInputWindowingStrategy.
              assertThat(startMs, anyOf(equalTo(0L), equalTo(4L)));
              assertThat(endMs - startMs, equalTo(4L));
              // If startMs == 4 (second window), equal to secondWindowSideInput.
              return firstWindowSideInput + (int) startMs;
            });

    SumAndVerifyContextFn combineFn = new SumAndVerifyContextFn(mockView, expectedValue);
    ReduceFnTester<Integer, Integer, IntervalWindow> tester =
        ReduceFnTester.combining(
            mainInputWindowingStrategy,
            mockTriggerStateMachine,
            combineFn,
            VarIntCoder.of(),
            options,
            mockSideInputReader);

    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    for (int i = 0; i < 8; ++i) {
      injectElement(tester, i);
    }

    assertThat(
        tester.extractOutput(),
        contains(
            isSingleWindowedValue(equalTo(0 + firstWindowSideInput), 1, 0, 2),
            isSingleWindowedValue(equalTo(0 + 1 + firstWindowSideInput), 1, 0, 2),
            isSingleWindowedValue(equalTo(2 + firstWindowSideInput), 3, 2, 4),
            isSingleWindowedValue(equalTo(2 + 3 + firstWindowSideInput), 3, 2, 4),
            isSingleWindowedValue(equalTo(4 + secondWindowSideInput), 5, 4, 6),
            isSingleWindowedValue(equalTo(4 + 5 + secondWindowSideInput), 5, 4, 6),
            isSingleWindowedValue(equalTo(6 + secondWindowSideInput), 7, 6, 8),
            isSingleWindowedValue(equalTo(6 + 7 + secondWindowSideInput), 7, 6, 8)));
  }
",non-flaky,5
78331,apache_beam,ReduceFnRunnerTest.testWatermarkHoldAndLateData,"  @Test
  public void testWatermarkHoldAndLateData() throws Exception {
    MetricsContainerImpl container = new MetricsContainerImpl(""any"");
    MetricsEnvironment.setCurrentContainer(container);
    // Test handling of late data. Specifically, ensure the watermark hold is correct.
    Duration allowedLateness = Duration.millis(10);
    ReduceFnTester<Integer, Iterable<Integer>, IntervalWindow> tester =
        ReduceFnTester.nonCombining(
            FixedWindows.of(Duration.millis(10)),
            mockTriggerStateMachine,
            AccumulationMode.ACCUMULATING_FIRED_PANES,
            allowedLateness,
            ClosingBehavior.FIRE_IF_NON_EMPTY);

    // Input watermark -> null
    assertEquals(null, tester.getWatermarkHold());
    assertEquals(null, tester.getOutputWatermark());

    // All on time data, verify watermark hold.
    IntervalWindow expectedWindow = new IntervalWindow(new Instant(0), new Instant(10));
    injectElement(tester, 1);
    injectElement(tester, 3);
    assertEquals(new Instant(1), tester.getWatermarkHold());
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    injectElement(tester, 2);
    List<WindowedValue<Iterable<Integer>>> output = tester.extractOutput();
    assertThat(
        output,
        contains(
            isSingleWindowedValue(
                containsInAnyOrder(1, 2, 3),
                equalTo(new Instant(1)),
                equalTo((BoundedWindow) expectedWindow))));
    assertThat(
        output.get(0).getPane(), equalTo(PaneInfo.createPane(true, false, Timing.EARLY, 0, -1)));

    // There is no end-of-window hold, but the timer set by the trigger holds the watermark
    assertThat(tester.getWatermarkHold(), nullValue());

    // Nothing dropped.
    long droppedElements =
        container
            .getCounter(
                MetricName.named(ReduceFnRunner.class, ReduceFnRunner.DROPPED_DUE_TO_CLOSED_WINDOW))
            .getCumulative();
    assertEquals(0, droppedElements);

    // Input watermark -> 4, output watermark should advance that far as well
    tester.advanceInputWatermark(new Instant(4));
    assertEquals(new Instant(4), tester.getOutputWatermark());

    // Some late, some on time. Verify that we only hold to the minimum of on-time.
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(false);
    tester.advanceInputWatermark(new Instant(4));
    injectElement(tester, 2);
    injectElement(tester, 3);

    // Late data has arrived behind the _output_ watermark. The ReduceFnRunner sets a GC hold
    // since this data is not permitted to hold up the output watermark.
    assertThat(
        tester.getWatermarkHold(), equalTo(expectedWindow.maxTimestamp().plus(allowedLateness)));

    // Now data just ahead of the output watermark arrives and sets an earlier ""element"" hold
    injectElement(tester, 5);
    assertEquals(new Instant(5), tester.getWatermarkHold());

    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    injectElement(tester, 4);
    output = tester.extractOutput();
    assertThat(
        output,
        contains(
            isSingleWindowedValue(
                containsInAnyOrder(
                    1, 2, 3, // earlier firing
                    2, 3, 4, 5), // new elements
                4, // timestamp
                0, // window start
                10))); // window end
    assertThat(
        output.get(0).getPane(), equalTo(PaneInfo.createPane(false, false, Timing.EARLY, 1, -1)));

    // Since the element hold is cleared, there is no hold remaining
    assertThat(tester.getWatermarkHold(), nullValue());

    // All behind the output watermark -- hold is at GC time (if we imagine the
    // trigger sets a timer for ON_TIME firing, that is actually when they'll be emitted)
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(false);
    tester.advanceInputWatermark(new Instant(8));
    injectElement(tester, 6);
    injectElement(tester, 5);
    assertThat(
        tester.getWatermarkHold(), equalTo(expectedWindow.maxTimestamp().plus(allowedLateness)));

    injectElement(tester, 4);

    // Fire the ON_TIME pane
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);

    // To get an ON_TIME pane, we need the output watermark to be held back a little; this would
    // be done by way of the timers set by the trigger, which are mocked here
    tester.setAutoAdvanceOutputWatermark(false);

    tester.advanceInputWatermark(expectedWindow.maxTimestamp().plus(1));
    tester.fireTimer(expectedWindow, expectedWindow.maxTimestamp(), TimeDomain.EVENT_TIME);

    // Output time is end of the window, because all the new data was late, but the pane
    // is the ON_TIME pane.
    output = tester.extractOutput();
    assertThat(
        output,
        contains(
            isSingleWindowedValue(
                containsInAnyOrder(
                    1, 2, 3, // earlier firing
                    2, 3, 4, 5, // earlier firing
                    4, 5, 6), // new elements
                9, // timestamp
                0, // window start
                10))); // window end
    assertThat(
        output.get(0).getPane(), equalTo(PaneInfo.createPane(false, false, Timing.ON_TIME, 2, 0)));

    tester.setAutoAdvanceOutputWatermark(true);

    // This is ""pending"" at the time the watermark makes it way-late.
    // Because we're about to expire the window, we output it.
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(false);
    injectElement(tester, 8);
    droppedElements =
        container
            .getCounter(
                MetricName.named(ReduceFnRunner.class, ReduceFnRunner.DROPPED_DUE_TO_CLOSED_WINDOW))
            .getCumulative();
    assertEquals(0, droppedElements);

    // Exceed the GC limit, triggering the last pane to be fired
    tester.advanceInputWatermark(new Instant(50));
    output = tester.extractOutput();
    // Output time is still end of the window, because the new data (8) was behind
    // the output watermark.
    assertThat(
        output,
        contains(
            isSingleWindowedValue(
                containsInAnyOrder(
                    1, 2, 3, // earlier firing
                    2, 3, 4, 5, // earlier firing
                    4, 5, 6, // earlier firing
                    8), // new element prior to window becoming expired
                9, // timestamp
                0, // window start
                10))); // window end
    assertThat(
        output.get(0).getPane(), equalTo(PaneInfo.createPane(false, true, Timing.LATE, 3, 1)));
    assertEquals(new Instant(50), tester.getOutputWatermark());
    assertEquals(null, tester.getWatermarkHold());

    // Late timers are ignored
    tester.fireTimer(
        new IntervalWindow(new Instant(0), new Instant(10)),
        new Instant(12),
        TimeDomain.EVENT_TIME);

    // And because we're past the end of window + allowed lateness, everything should be cleaned up.
    assertFalse(tester.isMarkedFinished(firstWindow));
    tester.assertHasOnlyGlobalAndFinishedSetsFor();
  }
",non-flaky,5
91412,strapdata_elassandra,PreBuiltXPackTransportClientTests.testPluginInstalled,"    @Test
    public void testPluginInstalled() {
        try (TransportClient client = new PreBuiltXPackTransportClient(Settings.EMPTY)) {
            Settings settings = client.settings();
            assertEquals(SecurityField.NAME4, NetworkModule.TRANSPORT_TYPE_SETTING.get(settings));
        }
    }
",non-flaky,5
91413,strapdata_elassandra,MonitoringWithWatcherRestIT.cleanExporters,"@TestLogging(""org.elasticsearch.client:TRACE,tracer:TRACE"")
    public void cleanExporters() throws Exception {
        Request request = new Request(""PUT"", ""/_cluster/settings"");
        request.setJsonEntity(Strings.toString(jsonBuilder().startObject()
                .startObject(""transient"")
                    .nullField(""xpack.monitoring.exporters.*"")
                .endObject().endObject()));
        adminClient().performRequest(request);
        adminClient().performRequest(new Request(""DELETE"", ""/.watch*""));
    }
",non-flaky,5
91414,strapdata_elassandra,WatchBackwardsCompatibilityIT.waitForSecuritySetup,"@TestLogging(""org.elasticsearch.client:TRACE"")
    public void waitForSecuritySetup() throws Exception {

        String masterNode = null;
        String catNodesResponse = EntityUtils.toString(
                client().performRequest(""GET"", ""/_cat/nodes?h=id,master"").getEntity(),
                StandardCharsets.UTF_8
        );
        for (String line : catNodesResponse.split(""\n"")) {
            int indexOfStar = line.indexOf('*'); // * in the node's output denotes it is master
            if (indexOfStar != -1) {
                masterNode = line.substring(0, indexOfStar).trim();
                break;
            }
        }
        assertNotNull(masterNode);
        final String masterNodeId = masterNode;

        assertBusy(() -> {
            try {
                Response nodeDetailsResponse = client().performRequest(""GET"", ""/_nodes"");
                ObjectPath path = ObjectPath.createFromResponse(nodeDetailsResponse);
                Map<String, Object> nodes = path.evaluate(""nodes"");
                assertThat(nodes.size(), greaterThanOrEqualTo(2));
                String masterVersion = null;
                for (String key : nodes.keySet()) {
                    // get the ES version number master is on
                    if (key.startsWith(masterNodeId)) {
                        masterVersion = path.evaluate(""nodes."" + key + "".version"");
                        break;
                    }
                }
                assertNotNull(masterVersion);
                final String masterTemplateVersion = masterVersion;

                Response response = client().performRequest(""GET"", ""/_cluster/state/metadata"");
                ObjectPath objectPath = ObjectPath.createFromResponse(response);
                final String mappingsPath = ""metadata.templates.security-index-template.mappings"";
                Map<String, Object> mappings = objectPath.evaluate(mappingsPath);
                assertNotNull(mappings);
                assertThat(mappings.size(), greaterThanOrEqualTo(1));
                for (String key : mappings.keySet()) {
                    String templateVersion = objectPath.evaluate(mappingsPath + ""."" + key + """" +
                            ""._meta.security-version"");
                    final Version mVersion = Version.fromString(masterTemplateVersion);
                    final Version tVersion = Version.fromString(templateVersion);
                    assertEquals(mVersion, tVersion);
                }
            } catch (Exception e) {
                throw new AssertionError(""failed to get cluster state"", e);
            }
        });

        nodes = buildNodeAndVersions();
        logger.info(""Nodes in cluster before test: bwc [{}], new [{}], master [{}]"", nodes.getBWCNodes(), nodes.getNewNodes(),
                nodes.getMaster());

        Map<String, String> params = Collections.singletonMap(""error_trace"", ""true"");
        executeAgainstMasterNode(client -> {
            // create a watch before each test, most of the time this is just overwriting...
            assertOK(client.performRequest(""PUT"", ""/_xpack/watcher/watch/my-watch"", params, entity));
            // just a check to see if we can execute a watch, purely optional
            if (randomBoolean()) {
                assertOK(client.performRequest(""POST"", ""/_xpack/watcher/watch/my-watch/_execute"", params,
                        new StringEntity(""{ \""record_execution\"" : true }"", ContentType.APPLICATION_JSON)));
            }
            if (randomBoolean()) {
                Map<String, String> ignore404Params = MapBuilder.newMapBuilder(params).put(""ignore"", ""404"").immutableMap();
                Response indexExistsResponse = client.performRequest(""HEAD"", ""/.triggered_watches"", ignore404Params);
                if (indexExistsResponse.getStatusLine().getStatusCode() == 404) {
                    logger.info(""Created triggered watches index to ensure it gets upgraded"");
                    client.performRequest(""PUT"", ""/.triggered_watches"");
                }
            }
        });

        // helping debugging output
        executeAgainstMasterNode(client -> {
            Map<String, String> filterPathParams = MapBuilder.newMapBuilder(params)
                    .put(""filter_path"", ""*.template,*.index_patterns"").immutableMap();
            Response r = client.performRequest(""GET"", ""_template/*watch*"", filterPathParams);
            logger.info(""existing watcher templates response [{}]"", EntityUtils.toString(r.getEntity(), StandardCharsets.UTF_8));
        });

        // set logging to debug
//        executeAgainstMasterNode(client -> {
//            StringEntity entity = new StringEntity(""{ \""transient\"" : { \""logger.org.elasticsearch.xpack.watcher\"" : \""TRACE\"" } }"",
//                    ContentType.APPLICATION_JSON);
//            Response response = client.performRequest(""PUT"", ""_cluster/settings"", params, entity);
//            logger.info(""cluster update settings response [{}]"", EntityUtils.toString(response.getEntity(), StandardCharsets.UTF_8));
//        });
    }
",non-flaky,5
91415,strapdata_elassandra,OpenLdapUserSearchSessionFactoryTests.init,"@TestLogging(""org.elasticsearch.xpack.core.ssl.SSLService:TRACE"")
    public void init() throws Exception {
        Path caPath = getDataPath(LDAPCACERT_PATH);
        /*
         * Prior to each test we reinitialize the socket factory with a new SSLService so that we get a new SSLContext.
         * If we re-use a SSLContext, previously connected sessions can get re-established which breaks hostname
         * verification tests since a re-established connection does not perform hostname verification.
         */
        globalSettings = Settings.builder()
            .put(""path.home"", createTempDir())
            .put(""xpack.ssl.certificate_authorities"", caPath)
            .build();
        threadPool = new TestThreadPool(""LdapUserSearchSessionFactoryTests"");
    }
",non-flaky,5
91416,strapdata_elassandra,TribeRestTestCase.compare,"    @TestGroup(enabled = true, sysProperty = ESRestTestCase.TESTS_REST)
            public int compare(RestTestCandidate o1, RestTestCandidate o2) {
                return o1.getTestPath().compareTo(o2.getTestPath());
            }
",non-flaky,5
91417,strapdata_elassandra,SessionFactoryLoadBalancingTests.init,"@TestLogging(""org.elasticsearch.xpack.security.authc.ldap.support:DEBUG"")
    public void init() throws Exception {
        threadPool = new TestThreadPool(""SessionFactoryLoadBalancingTests thread pool"");
    }
",non-flaky,5
91418,strapdata_elassandra,TokenAuthIntegTests.testExpiredTokensDeletedAfterExpiration,"    @TestLogging(""org.elasticsearch.xpack.security.authc:DEBUG"")
    public void testExpiredTokensDeletedAfterExpiration() throws Exception {
        final Client client = client().filterWithHeader(Collections.singletonMap(""Authorization"",
                UsernamePasswordToken.basicAuthHeaderValue(SecuritySettingsSource.TEST_SUPERUSER,
                        SecuritySettingsSourceField.TEST_PASSWORD_SECURE_STRING)));
        SecurityClient securityClient = new SecurityClient(client);
        CreateTokenResponse response = securityClient.prepareCreateToken()
                .setGrantType(""password"")
                .setUsername(SecuritySettingsSource.TEST_USER_NAME)
                .setPassword(new SecureString(SecuritySettingsSourceField.TEST_PASSWORD.toCharArray()))
                .get();

        Instant created = Instant.now();

        InvalidateTokenResponse invalidateResponse = securityClient
                .prepareInvalidateToken(response.getTokenString())
                .setType(InvalidateTokenRequest.Type.ACCESS_TOKEN)
                .get();
        assertTrue(invalidateResponse.isCreated());
        AtomicReference<String> docId = new AtomicReference<>();
        assertBusy(() -> {
            SearchResponse searchResponse = client.prepareSearch(SecurityIndexManager.SECURITY_INDEX_NAME)
                    .setSource(SearchSourceBuilder.searchSource()
                            .query(QueryBuilders.termQuery(""doc_type"", TokenService.INVALIDATED_TOKEN_DOC_TYPE)))
                    .setSize(1)
                    .setTerminateAfter(1)
                    .get();
            assertThat(searchResponse.getHits().getTotalHits(), equalTo(1L));
            docId.set(searchResponse.getHits().getAt(0).getId());
        });

        // hack doc to modify the time to the day before
        Instant dayBefore = created.minus(1L, ChronoUnit.DAYS);
        assertTrue(Instant.now().isAfter(dayBefore));
        client.prepareUpdate(SecurityIndexManager.SECURITY_INDEX_NAME, ""doc"", docId.get())
                .setDoc(""expiration_time"", dayBefore.toEpochMilli())
                .setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE)
                .get();

        AtomicBoolean deleteTriggered = new AtomicBoolean(false);
        assertBusy(() -> {
            if (deleteTriggered.compareAndSet(false, true)) {
                // invalidate a invalid token... doesn't matter that it is bad... we just want this action to trigger the deletion
                try {
                    securityClient.prepareInvalidateToken(""fooobar"")
                            .setType(randomFrom(InvalidateTokenRequest.Type.values()))
                            .execute()
                            .actionGet();
                } catch (ElasticsearchSecurityException e) {
                    assertEquals(""token malformed"", e.getMessage());
                }
            }
            client.admin().indices().prepareRefresh(SecurityIndexManager.SECURITY_INDEX_NAME).get();
            SearchResponse searchResponse = client.prepareSearch(SecurityIndexManager.SECURITY_INDEX_NAME)
                    .setSource(SearchSourceBuilder.searchSource()
                            .query(QueryBuilders.termQuery(""doc_type"", TokenService.INVALIDATED_TOKEN_DOC_TYPE)))
                    .setSize(0)
                    .setTerminateAfter(1)
                    .get();
            assertThat(searchResponse.getHits().getTotalHits(), equalTo(0L));
        }, 30, TimeUnit.SECONDS);
    }
",non-flaky,5
91419,strapdata_elassandra,NativePrivilegeStoreTests.setup,"@TestLogging(""org.elasticsearch.xpack.security.authz.store.NativePrivilegeStore:TRACE"")
    public void setup() {
        requests = new ArrayList<>();
        listener = new AtomicReference<>();
        client = new NoOpClient(getTestName()) {
            @Override
            protected <Request extends ActionRequest,
                Response extends ActionResponse,
                RequestBuilder extends ActionRequestBuilder<Request, Response, RequestBuilder>>
            void doExecute(Action<Request, Response, RequestBuilder> action, Request request, ActionListener<Response> listener) {
                NativePrivilegeStoreTests.this.requests.add(request);
                NativePrivilegeStoreTests.this.listener.set(listener);
            }
        };
        final SecurityIndexManager securityIndex = mock(SecurityIndexManager.class);
        when(securityIndex.freeze()).thenReturn(securityIndex);
        when(securityIndex.indexExists()).thenReturn(true);
        when(securityIndex.isAvailable()).thenReturn(true);
        Mockito.doAnswer(invocationOnMock -> {
            assertThat(invocationOnMock.getArguments().length, equalTo(2));
            assertThat(invocationOnMock.getArguments()[1], instanceOf(Runnable.class));
            ((Runnable) invocationOnMock.getArguments()[1]).run();
            return null;
        }).when(securityIndex).prepareIndexIfNeededThenExecute(any(Consumer.class), any(Runnable.class));
        Mockito.doAnswer(invocationOnMock -> {
            assertThat(invocationOnMock.getArguments().length, equalTo(2));
            assertThat(invocationOnMock.getArguments()[1], instanceOf(Runnable.class));
            ((Runnable) invocationOnMock.getArguments()[1]).run();
            return null;
        }).when(securityIndex).checkIndexVersionThenExecute(any(Consumer.class), any(Runnable.class));
        store = new NativePrivilegeStore(Settings.EMPTY, client, securityIndex);
    }
",non-flaky,5
91420,strapdata_elassandra,TransportHasPrivilegesActionTests.setup,"@TestLogging(""org.elasticsearch.xpack.security.action.user.TransportHasPrivilegesAction:TRACE,"" +
    public void setup() {
        final Settings settings = Settings.builder().build();
        user = new User(randomAlphaOfLengthBetween(4, 12));
        final ThreadPool threadPool = mock(ThreadPool.class);
        final ThreadContext threadContext = new ThreadContext(Settings.EMPTY);
        final TransportService transportService = new TransportService(Settings.EMPTY, mock(Transport.class), null,
            TransportService.NOOP_TRANSPORT_INTERCEPTOR, x -> null, null, Collections.emptySet());

        final Authentication authentication = mock(Authentication.class);
        threadContext.putTransient(AuthenticationField.AUTHENTICATION_KEY, authentication);
        when(threadPool.getThreadContext()).thenReturn(threadContext);

        when(authentication.getUser()).thenReturn(user);

        AuthorizationService authorizationService = mock(AuthorizationService.class);
        Mockito.doAnswer(invocationOnMock -> {
            ActionListener<Role> listener = (ActionListener<Role>) invocationOnMock.getArguments()[1];
            listener.onResponse(role);
            return null;
        }).when(authorizationService).roles(eq(user), any(ActionListener.class));

        applicationPrivileges = new ArrayList<>();
        NativePrivilegeStore privilegeStore = mock(NativePrivilegeStore.class);
        Mockito.doAnswer(inv -> {
            assertThat(inv.getArguments(), arrayWithSize(3));
            ActionListener<List<ApplicationPrivilegeDescriptor>> listener
                = (ActionListener<List<ApplicationPrivilegeDescriptor>>) inv.getArguments()[2];
            logger.info(""Privileges for ({}) are {}"", Arrays.toString(inv.getArguments()), applicationPrivileges);
            listener.onResponse(applicationPrivileges);
            return null;
        }).when(privilegeStore).getPrivileges(any(Collection.class), any(Collection.class), any(ActionListener.class));

        action = new TransportHasPrivilegesAction(settings, threadPool, transportService, mock(ActionFilters.class),
            mock(IndexNameExpressionResolver.class), authorizationService, privilegeStore);
    }
",non-flaky,5
91421,strapdata_elassandra,RemoteIndexAuditTrailStartingTests.transportSSLEnabled,"@TestLogging(""org.elasticsearch.xpack.security.audit.index:TRACE"")
    public boolean transportSSLEnabled() {
        return sslEnabled;
    }
",non-flaky,5
91422,strapdata_elassandra,SSLTrustRestrictionsTests.nodeSettings,"@TestLogging(""org.elasticsearch.xpack.ssl.RestrictedTrustManager:DEBUG"")
    public Settings nodeSettings(int nodeOrdinal) {

        Settings parentSettings = super.nodeSettings(nodeOrdinal);
        Settings.Builder builder = Settings.builder()
                .put(parentSettings.filter((s) -> s.startsWith(""xpack.ssl."") == false))
                .put(nodeSSL);

        restrictionsPath = configPath.resolve(""trust_restrictions.yml"");
        restrictionsTmpPath = configPath.resolve(""trust_restrictions.tmp"");

        writeRestrictions(""*.trusted"");
        builder.put(""xpack.ssl.trust_restrictions.path"", restrictionsPath);
        builder.put(""resource.reload.interval.high"", RESOURCE_RELOAD_MILLIS + ""ms"");

        return builder.build();
    }
",non-flaky,5
91423,strapdata_elassandra,LicensingTests.nodeSettings,"@TestLogging(""org.elasticsearch.cluster.service:TRACE,org.elasticsearch.discovery.zen:TRACE,org.elasticsearch.action.search:TRACE,"" +
    public Settings nodeSettings(int nodeOrdinal) {
        return Settings.builder().put(super.nodeSettings(nodeOrdinal))
                .put(NetworkModule.HTTP_ENABLED.getKey(), true)
            .put(TestZenDiscovery.USE_MOCK_PINGS.getKey(), false)
                .build();
    }
",non-flaky,5
91424,strapdata_elassandra,BasicDistributedJobsIT.testDedicatedMlNode,"    @TestLogging(""org.elasticsearch.xpack.persistent:TRACE,org.elasticsearch.cluster.service:DEBUG,org.elasticsearch.xpack.ml.action:DEBUG"")
    public void testDedicatedMlNode() throws Exception {
        internalCluster().ensureAtMostNumDataNodes(0);
        // start 2 non ml node that will never get a job allocated. (but ml apis are accessible from this node)
        internalCluster().startNode(Settings.builder().put(MachineLearning.ML_ENABLED.getKey(), false));
        internalCluster().startNode(Settings.builder().put(MachineLearning.ML_ENABLED.getKey(), false));
        // start ml node
        if (randomBoolean()) {
            internalCluster().startNode(Settings.builder().put(MachineLearning.ML_ENABLED.getKey(), true));
        } else {
            // the default is based on 'xpack.ml.enabled', which is enabled in base test class.
            internalCluster().startNode();
        }
        ensureStableCluster(3);

        String jobId = ""dedicated-ml-node-job"";
        Job.Builder job = createJob(jobId, new ByteSizeValue(2, ByteSizeUnit.MB));
        PutJobAction.Request putJobRequest = new PutJobAction.Request(job);
        client().execute(PutJobAction.INSTANCE, putJobRequest).actionGet();

        OpenJobAction.Request openJobRequest = new OpenJobAction.Request(job.getId());
        client().execute(OpenJobAction.INSTANCE, openJobRequest).actionGet();
        assertBusy(() -> {
            ClusterState clusterState = client().admin().cluster().prepareState().get().getState();
            PersistentTasksCustomMetaData tasks = clusterState.getMetaData().custom(PersistentTasksCustomMetaData.TYPE);
            PersistentTask<?> task = tasks.getTask(MlTasks.jobTaskId(jobId));
            DiscoveryNode node = clusterState.nodes().resolveNode(task.getExecutorNode());
            assertThat(node.getAttributes(), hasEntry(MachineLearning.ML_ENABLED_NODE_ATTR, ""true""));
            assertThat(node.getAttributes(), hasEntry(MachineLearning.MAX_OPEN_JOBS_NODE_ATTR, ""20""));
            JobTaskState jobTaskState = (JobTaskState) task.getState();
            assertNotNull(jobTaskState);
            assertEquals(JobState.OPENED, jobTaskState.getState());
        });

        logger.info(""stop the only running ml node"");
        internalCluster().stopRandomNode(settings -> settings.getAsBoolean(MachineLearning.ML_ENABLED.getKey(), true));
        ensureStableCluster(2);
        assertBusy(() -> {
            // job should get and remain in a failed state and
            // the status remains to be opened as from ml we didn't had the chance to set the status to failed:
            assertJobTask(jobId, JobState.OPENED, false);
        });

        logger.info(""start ml node"");
        internalCluster().startNode(Settings.builder().put(MachineLearning.ML_ENABLED.getKey(), true));
        ensureStableCluster(3);
        assertBusy(() -> {
            // job should be re-opened:
            assertJobTask(jobId, JobState.OPENED, true);
        });
    }
",non-flaky,5
91425,strapdata_elassandra,MlDistributedFailureIT.testLoseDedicatedMasterNode,"    @TestLogging(""org.elasticsearch.xpack.ml.action:DEBUG,org.elasticsearch.xpack.persistent:TRACE,"" +
    public void testLoseDedicatedMasterNode() throws Exception {
        internalCluster().ensureAtMostNumDataNodes(0);
        logger.info(""Starting dedicated master node..."");
        internalCluster().startNode(Settings.builder()
                .put(""node.master"", true)
                .put(""node.data"", false)
                .put(""node.ml"", false)
                .build());
        logger.info(""Starting ml and data node..."");
        String mlAndDataNode = internalCluster().startNode(Settings.builder()
                .put(""node.master"", false)
                .build());
        ensureStableClusterOnAllNodes(2);
        run(""lose-dedicated-master-node-job"", () -> {
            logger.info(""Stopping dedicated master node"");
            internalCluster().stopRandomNode(settings -> settings.getAsBoolean(""node.master"", false));
            assertBusy(() -> {
                ClusterState state = client(mlAndDataNode).admin().cluster().prepareState()
                        .setLocal(true).get().getState();
                assertNull(state.nodes().getMasterNodeId());
            });
            logger.info(""Restarting dedicated master node"");
            internalCluster().startNode(Settings.builder()
                    .put(""node.master"", true)
                    .put(""node.data"", false)
                    .put(""node.ml"", false)
                    .build());
            ensureStableClusterOnAllNodes(2);
        });
    }
",non-flaky,5
91426,strapdata_elassandra,AutodetectProcessManagerTests.testCanCloseClosingJob,"    @TestLogging(""org.elasticsearch.xpack.ml.job.process.autodetect:DEBUG"")
    public void testCanCloseClosingJob() throws Exception {
        AutodetectCommunicator communicator = mock(AutodetectCommunicator.class);
        AtomicInteger numberOfCommunicatorCloses = new AtomicInteger(0);
        doAnswer(invocationOnMock -> {
            numberOfCommunicatorCloses.incrementAndGet();
            // This increases the chance of the two threads both getting into
            // the middle of the AutodetectProcessManager.close() method
            Thread.yield();
            return null;
        }).when(communicator).close(anyBoolean(), anyString());
        AutodetectProcessManager manager = createManager(communicator);
        assertEquals(0, manager.numberOfOpenJobs());

        JobTask jobTask = mock(JobTask.class);
        when(jobTask.getJobId()).thenReturn(""foo"");
        manager.openJob(jobTask, e -> {});
        manager.processData(jobTask, analysisRegistry, createInputStream(""""), randomFrom(XContentType.values()),
                mock(DataLoadParams.class), (dataCounts1, e) -> {});

        assertEquals(1, manager.numberOfOpenJobs());

        // Close the job in a separate thread
        Thread closeThread = new Thread(() -> manager.closeJob(jobTask, false, ""in separate thread""));
        closeThread.start();
        Thread.yield();

        // Also close the job in the current thread, so that we have two simultaneous close requests
        manager.closeJob(jobTask, false, ""in main test thread"");

        // The 10 second timeout here is usually far in excess of what is required.  In the vast
        // majority of cases the other thread will exit within a few milliseconds.  However, it
        // has been observed that on some VMs the test can fail because the VM stalls at the
        // wrong moment.  A 10 second timeout is on a par with the length of time assertBusy()
        // would wait under these circumstances.
        closeThread.join(10000);
        assertFalse(closeThread.isAlive());

        // Only one of the threads should have called AutodetectCommunicator.close()
        assertEquals(1, numberOfCommunicatorCloses.get());
        assertEquals(0, manager.numberOfOpenJobs());
    }
",non-flaky,5
91427,strapdata_elassandra,MachineLearningLicensingTests.resetLicensing,"@TestLogging(""org.elasticsearch.xpack.ml.action:DEBUG"")
    public void resetLicensing() {
        enableLicensing();

        ensureStableCluster(1);
        ensureYellow();
    }
",non-flaky,5
91428,strapdata_elassandra,HistoryActionConditionTests.testActionConditionWithHardFailures,"@TestLogging(""org.elasticsearch.xpack.watcher:DEBUG,org.elasticsearch.xpack.watcher.WatcherIndexingListener:TRACE"")
    public void testActionConditionWithHardFailures() throws Exception {
        final String id = ""testActionConditionWithHardFailures"";

        final ExecutableCondition scriptConditionFailsHard = mockScriptCondition(""throw new IllegalStateException('failed');"");
        final List<ExecutableCondition> actionConditionsWithFailure =
                Arrays.asList(scriptConditionFailsHard, conditionPasses, InternalAlwaysCondition.INSTANCE);

        Collections.shuffle(actionConditionsWithFailure, random());

        final int failedIndex = actionConditionsWithFailure.indexOf(scriptConditionFailsHard);

        putAndTriggerWatch(id, input, actionConditionsWithFailure.toArray(new Condition[actionConditionsWithFailure.size()]));

        flush();

        assertWatchWithMinimumActionsCount(id, ExecutionState.EXECUTED, 1);

        // only one action should have failed via condition
        final SearchResponse response = searchHistory(SearchSourceBuilder.searchSource().query(termQuery(""watch_id"", id)));
        assertThat(response.getHits().getTotalHits(), is(1L));

        final SearchHit hit = response.getHits().getAt(0);
        final List<Object> actions = getActionsFromHit(hit.getSourceAsMap());

        for (int i = 0; i < actionConditionsWithFailure.size(); ++i) {
            final Map<String, Object> action = (Map<String, Object>)actions.get(i);
            final Map<String, Object> condition = (Map<String, Object>)action.get(""condition"");
            final Map<String, Object> logging = (Map<String, Object>)action.get(""logging"");

            assertThat(action.get(""id""), is(""action"" + i));

            if (i == failedIndex) {
                assertThat(action.get(""status""), is(""condition_failed""));
                assertThat(action.get(""reason""), is(""condition failed. skipping: [expected] failed hard""));
                assertThat(condition, nullValue());
                assertThat(logging, nullValue());
            } else {
                assertThat(condition.get(""type""), is(actionConditionsWithFailure.get(i).type()));

                assertThat(action.get(""status""), is(""success""));
                assertThat(condition.get(""met""), is(true));
                assertThat(action.get(""reason""), nullValue());
                assertThat(logging.get(""logged_text""), is(Integer.toString(i)));
            }
        }
    }
",non-flaky,5
91429,strapdata_elassandra,HistoryTemplateEmailMappingsTests.setUp,"@TestLogging(""org.elasticsearch.xpack.watcher:DEBUG,"" +
    public void setUp() throws Exception {
        super.setUp();
        server = EmailServer.localhost(logger);
    }
",non-flaky,5
91430,strapdata_elassandra,HttpInputIntegrationTests.testHttpInput,"@TestLogging(""org.elasticsearch.xpack.watcher:DEBUG,org.elasticsearch.xpack.watcher.WatcherIndexingListener:TRACE"")
    public void testHttpInput() throws Exception {
        createIndex(""index"");
        client().prepareIndex(""index"", ""type"", ""id"").setSource(""{}"", XContentType.JSON).setRefreshPolicy(IMMEDIATE).get();

        InetSocketAddress address = internalCluster().httpAddresses()[0];
        watcherClient().preparePutWatch(""_name"")
                .setSource(watchBuilder()
                        .trigger(schedule(interval(""5s"")))
                        .input(httpInput(HttpRequestTemplate.builder(address.getHostString(), address.getPort())
                                .path(""/index/_search"")
                                .body(Strings.toString(jsonBuilder().startObject().field(""size"", 1).endObject()))
                                .putHeader(""Content-Type"", new TextTemplate(""application/json""))))
                        .condition(new CompareCondition(""ctx.payload.hits.total"", CompareCondition.Op.EQ, 1L))
                        .addAction(""_id"", loggingAction(""anything"")))
                .get();

        timeWarp().trigger(""_name"");
        refresh();
        assertWatchWithMinimumPerformedActionsCount(""_name"", 1, false);
    }
",non-flaky,5
91431,strapdata_elassandra,BasicWatcherTests.testIndexWatch,"@TestLogging(""org.elasticsearch.xpack.watcher:DEBUG,"" +
    public void testIndexWatch() throws Exception {
        WatcherClient watcherClient = watcherClient();
        createIndex(""idx"");
        // Have a sample document in the index, the watch is going to evaluate
        client().prepareIndex(""idx"", ""type"").setSource(""field"", ""foo"").get();
        refresh();
        WatcherSearchTemplateRequest request = templateRequest(searchSource().query(termQuery(""field"", ""foo"")), ""idx"");
        watcherClient.preparePutWatch(""_name"")
                .setSource(watchBuilder()
                        .trigger(schedule(interval(5, IntervalSchedule.Interval.Unit.SECONDS)))
                        .input(searchInput(request))
                        .condition(new CompareCondition(""ctx.payload.hits.total"", CompareCondition.Op.EQ, 1L))
                        .addAction(""_logger"", loggingAction(""_logging"")
                                .setCategory(""_category"")))
                .get();

        timeWarp().trigger(""_name"");
        assertWatchWithMinimumPerformedActionsCount(""_name"", 1);

        GetWatchResponse getWatchResponse = watcherClient().prepareGetWatch().setId(""_name"").get();
        assertThat(getWatchResponse.isFound(), is(true));
        assertThat(getWatchResponse.getSource(), notNullValue());
    }
",non-flaky,5
91432,strapdata_elassandra,BasicWatcherTests.testModifyWatches,"    @TestLogging(""org.elasticsearch.xpack.watcher:DEBUG"")
    public void testModifyWatches() throws Exception {
        createIndex(""idx"");
        WatcherSearchTemplateRequest searchRequest = templateRequest(searchSource().query(matchAllQuery()), ""idx"");

        WatchSourceBuilder source = watchBuilder()
                .trigger(schedule(interval(""5s"")))
                .input(searchInput(searchRequest))
                .addAction(""_id"", indexAction(""idx"", ""action""));

        watcherClient().preparePutWatch(""_name"")
                .setSource(source.condition(new CompareCondition(""ctx.payload.hits.total"", CompareCondition.Op.EQ, 1L)))
                .get();

        timeWarp().clock().fastForwardSeconds(5);
        timeWarp().trigger(""_name"");
        assertWatchWithMinimumPerformedActionsCount(""_name"", 0, false);

        watcherClient().preparePutWatch(""_name"")
                .setSource(source.condition(new CompareCondition(""ctx.payload.hits.total"", CompareCondition.Op.EQ, 0L)))
                .get();

        timeWarp().clock().fastForwardSeconds(5);
        timeWarp().trigger(""_name"");
        refresh();
        assertWatchWithMinimumPerformedActionsCount(""_name"", 1, false);

        watcherClient().preparePutWatch(""_name"")
                .setSource(source
                        .trigger(schedule(Schedules.cron(""0/1 * * * * ? 2020"")))
                        .condition(new CompareCondition(""ctx.payload.hits.total"", CompareCondition.Op.EQ, 0L)))
                .get();

        timeWarp().clock().fastForwardSeconds(5);
        timeWarp().trigger(""_name"");
        long count = findNumberOfPerformedActions(""_name"");

        timeWarp().clock().fastForwardSeconds(5);
        timeWarp().trigger(""_name"");
        assertThat(count, equalTo(findNumberOfPerformedActions(""_name"")));
    }
",non-flaky,5
91433,strapdata_elassandra,WatchAckTests.indexTestDocument,"@TestLogging(""org.elasticsearch.xpack.watcher:DEBUG"")
    public void indexTestDocument() {
        IndexResponse eventIndexResponse = client().prepareIndex(""events"", ""event"", id)
                .setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE)
                .setSource(""level"", ""error"")
                .get();
        assertEquals(DocWriteResponse.Result.CREATED, eventIndexResponse.getResult());
    }
",non-flaky,5
91434,strapdata_elassandra,TimeThrottleIntegrationTests.testTimeThrottle,"@TestLogging(""org.elasticsearch.xpack.watcher:DEBUG,"" +
    public void testTimeThrottle(){
        String id = randomAlphaOfLength(20);
        PutWatchResponse putWatchResponse = watcherClient().preparePutWatch()
                .setId(id)
                .setSource(watchBuilder()
                        .trigger(schedule(interval(""5s"")))
                        .input(simpleInput())
                        .addAction(""my-logging-action"", loggingAction(""foo""))
                        .defaultThrottlePeriod(TimeValue.timeValueSeconds(30)))
                .get();
        assertThat(putWatchResponse.isCreated(), is(true));

        timeWarp().trigger(id);
        assertHistoryEntryExecuted(id);

        timeWarp().clock().fastForward(TimeValue.timeValueMillis(4000));
        timeWarp().trigger(id);
        assertHistoryEntryThrottled(id);

        timeWarp().clock().fastForwardSeconds(30);
        timeWarp().trigger(id);
        assertHistoryEntryExecuted(id);

        assertTotalHistoryEntries(id, 3);
    }
",non-flaky,5
91435,strapdata_elassandra,ActivateWatchTests.testDeactivateAndActivate,"@TestLogging(""org.elasticsearch.xpack.watcher:DEBUG,org.elasticsearch.xpack.watcher.WatcherIndexingListener:TRACE"")
    public void testDeactivateAndActivate() throws Exception {
        PutWatchResponse putWatchResponse = watcherClient().preparePutWatch()
                .setId(""_id"")
                .setSource(watchBuilder()
                        .trigger(schedule(interval(""1s"")))
                        .input(simpleInput(""foo"", ""bar""))
                        .addAction(""_a1"", indexAction(""actions"", ""action1""))
                        .defaultThrottlePeriod(new TimeValue(0, TimeUnit.SECONDS)))
                .get();

        assertThat(putWatchResponse.isCreated(), is(true));

        GetWatchResponse getWatchResponse = watcherClient().prepareGetWatch(""_id"").get();
        assertThat(getWatchResponse, notNullValue());
        assertThat(getWatchResponse.getStatus().state().isActive(), is(true));

        logger.info(""Waiting for watch to be executed at least once"");
        assertWatchWithMinimumActionsCount(""_id"", ExecutionState.EXECUTED, 1);

        // we now know the watch is executing... lets deactivate it
        ActivateWatchResponse activateWatchResponse = watcherClient().prepareActivateWatch(""_id"", false).get();
        assertThat(activateWatchResponse, notNullValue());
        assertThat(activateWatchResponse.getStatus().state().isActive(), is(false));

        getWatchResponse = watcherClient().prepareGetWatch(""_id"").get();
        assertThat(getWatchResponse, notNullValue());
        assertThat(getWatchResponse.getStatus().state().isActive(), is(false));

        // wait until no watch is executing
        assertBusy(() -> {
            WatcherStatsResponse statsResponse = watcherClient().prepareWatcherStats().setIncludeCurrentWatches(true).get();
            int sum = statsResponse.getNodes().stream().map(WatcherStatsResponse.Node::getSnapshots).mapToInt(List::size).sum();
            assertThat(sum, is(0));
        });

        logger.info(""Ensured no more watches are being executed"");
        refresh();
        long count1 = docCount("".watcher-history*"", ""doc"", matchAllQuery());

        logger.info(""Sleeping for 5 seconds, watch history count [{}]"", count1);
        Thread.sleep(5000);

        refresh();
        long count2 = docCount("".watcher-history*"", ""doc"", matchAllQuery());

        assertThat(count2, is(count1));

        // lets activate it again
        logger.info(""Activating watch again"");

        activateWatchResponse = watcherClient().prepareActivateWatch(""_id"", true).get();
        assertThat(activateWatchResponse, notNullValue());
        assertThat(activateWatchResponse.getStatus().state().isActive(), is(true));

        getWatchResponse = watcherClient().prepareGetWatch(""_id"").get();
        assertThat(getWatchResponse, notNullValue());
        assertThat(getWatchResponse.getStatus().state().isActive(), is(true));

        logger.info(""Sleeping for another five seconds, ensuring that watch is executed"");
        Thread.sleep(5000);
        refresh();
        long count3 = docCount("".watcher-history*"", ""doc"", matchAllQuery());
        assertThat(count3, greaterThan(count1));
    }
",non-flaky,5
91436,strapdata_elassandra,PreBuiltTransportClientTests.testPluginInstalled,"    @Test
    public void testPluginInstalled() {
        try (TransportClient client = new PreBuiltTransportClient(Settings.EMPTY)) {
            Settings settings = client.settings();
            assertEquals(Netty4Plugin.NETTY_TRANSPORT_NAME, NetworkModule.HTTP_DEFAULT_TYPE_SETTING.get(settings));
            assertEquals(Netty4Plugin.NETTY_TRANSPORT_NAME, NetworkModule.TRANSPORT_DEFAULT_TYPE_SETTING.get(settings));
        }
    }
",non-flaky,5
91437,strapdata_elassandra,PreBuiltTransportClientTests.testInstallPluginTwice,"    @Test
    public void testInstallPluginTwice() {
        for (Class<? extends Plugin> plugin :
                Arrays.asList(ParentJoinPlugin.class, ReindexPlugin.class, PercolatorPlugin.class,
                    MustachePlugin.class)) {
            try {
                new PreBuiltTransportClient(Settings.EMPTY, plugin);
                fail(""exception expected"");
            } catch (IllegalArgumentException ex) {
                assertTrue(""Expected message to start with [plugin already exists: ] but was instead ["" + ex.getMessage() + ""]"",
                        ex.getMessage().startsWith(""plugin already exists: ""));
            }
        }
    }
",non-flaky,5
91438,strapdata_elassandra,PackagingTestCase.logTestNameBefore,"@TestMethodProviders({
    public void logTestNameBefore() {
        logger.info(""["" + testNameRule.getMethodName() + ""]: before test"");
    }
",non-flaky,5
91439,strapdata_elassandra,RpmPreservationTestCase.onlyCompatibleDistributions,"@TestCaseOrdering(TestCaseOrdering.AlphabeticOrder.class)
    public void onlyCompatibleDistributions() {
        assumeTrue(""only rpm platforms"", isRPM());
        assumeTrue(""only compatible distributions"", distribution().packaging.compatible);
    }
",non-flaky,5
91440,strapdata_elassandra,ArchiveTestCase.onlyCompatibleDistributions,"@TestCaseOrdering(TestCaseOrdering.AlphabeticOrder.class)
    public void onlyCompatibleDistributions() {
        assumeTrue(""only compatible distributions"", distribution().packaging.compatible);
    }
",non-flaky,5
91441,strapdata_elassandra,PackageTestCase.onlyCompatibleDistributions,"@TestCaseOrdering(TestCaseOrdering.AlphabeticOrder.class)
    public void onlyCompatibleDistributions() {
        assumeTrue(""only compatible distributions"", distribution().packaging.compatible);
    }
",non-flaky,5
91442,strapdata_elassandra,DebPreservationTestCase.onlyCompatibleDistributions,"@TestCaseOrdering(TestCaseOrdering.AlphabeticOrder.class)
    public void onlyCompatibleDistributions() {
        assumeTrue(""only dpkg platforms"", isDPKG());
        assumeTrue(""only compatible distributions"", distribution().packaging.compatible);
    }
",non-flaky,5
91443,strapdata_elassandra,WildflyIT.testTransportClient,"@TestRuleLimitSysouts.Limit(bytes = 14000)
    public void testTransportClient() throws URISyntaxException, IOException {
        try (CloseableHttpClient client = HttpClientBuilder.create().build()) {
            final String str = String.format(
                    Locale.ROOT,
                    ""http://localhost:%d/wildfly-%s%s/transport/employees/1"",
                    Integer.parseInt(System.getProperty(""tests.jboss.http.port"")),
                    Version.CURRENT,
                    Build.CURRENT.isSnapshot() ? ""-SNAPSHOT"" : """");
            final HttpPut put = new HttpPut(new URI(str));
            final String body;
            try (XContentBuilder builder = jsonBuilder()) {
                builder.startObject();
                {
                    builder.field(""first_name"", ""John"");
                    builder.field(""last_name"", ""Smith"");
                    builder.field(""age"", 25);
                    builder.field(""about"", ""I love to go rock climbing"");
                    builder.startArray(""interests"");
                    {
                        builder.value(""sports"");
                        builder.value(""music"");
                    }
                    builder.endArray();
                }
                builder.endObject();
                body = Strings.toString(builder);
            }
            put.setEntity(new StringEntity(body, ContentType.APPLICATION_JSON));
            try (CloseableHttpResponse response = client.execute(put)) {
                int status = response.getStatusLine().getStatusCode();
                assertThat(""expected a 201 response but got: "" + status + "" - body: "" + EntityUtils.toString(response.getEntity()),
                        status, equalTo(201));
            }

            final HttpGet get = new HttpGet(new URI(str));
            try (
                    CloseableHttpResponse response = client.execute(get);
                    XContentParser parser =
                            JsonXContent.jsonXContent.createParser(
                                    new NamedXContentRegistry(ClusterModule.getNamedXWriteables()),
                                    DeprecationHandler.THROW_UNSUPPORTED_OPERATION,
                                    response.getEntity().getContent())) {
                final Map<String, Object> map = parser.map();
                assertThat(map.get(""first_name""), equalTo(""John""));
                assertThat(map.get(""last_name""), equalTo(""Smith""));
                assertThat(map.get(""age""), equalTo(25));
                assertThat(map.get(""about""), equalTo(""I love to go rock climbing""));
                final Object interests = map.get(""interests"");
                assertThat(interests, instanceOf(List.class));
                @SuppressWarnings(""unchecked"") final List<String> interestsAsList = (List<String>) interests;
                assertThat(interestsAsList, containsInAnyOrder(""sports"", ""music""));
            }
        }
    }
",non-flaky,5
91444,strapdata_elassandra,ESIntegTestCase.randomIndexTemplate,"    @TestGroup(enabled = false, sysProperty = ESIntegTestCase.SYSPROP_THIRDPARTY)
    public void randomIndexTemplate() throws IOException {

        // TODO move settings for random directory etc here into the index based randomized settings.
        if (cluster().size() > 0) {
            Settings.Builder randomSettingsBuilder =
                setRandomIndexSettings(random(), Settings.builder());
            if (isInternalCluster()) {
                // this is only used by mock plugins and if the cluster is not internal we just can't set it
                randomSettingsBuilder.put(INDEX_TEST_SEED_SETTING.getKey(), random().nextLong());
            }

            randomSettingsBuilder.put(SETTING_NUMBER_OF_SHARDS, numberOfShards())
                .put(SETTING_NUMBER_OF_REPLICAS, numberOfReplicas());

            // if the test class is annotated with SuppressCodecs(""*""), it means don't use lucene's codec randomization
            // otherwise, use it, it has assertions and so on that can find bugs.
            SuppressCodecs annotation = getClass().getAnnotation(SuppressCodecs.class);
            if (annotation != null && annotation.value().length == 1 && ""*"".equals(annotation.value()[0])) {
                randomSettingsBuilder.put(""index.codec"", randomFrom(CodecService.DEFAULT_CODEC, CodecService.BEST_COMPRESSION_CODEC));
            } else {
                randomSettingsBuilder.put(""index.codec"", CodecService.LUCENE_DEFAULT_CODEC);
            }

            for (String setting : randomSettingsBuilder.keys()) {
                assertThat(""non index. prefix setting set on index template, its a node setting..."", setting, startsWith(""index.""));
            }
            // always default delayed allocation to 0 to make sure we have tests are not delayed
            randomSettingsBuilder.put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), 0);
            if (randomBoolean()) {
                randomSettingsBuilder.put(IndexModule.INDEX_QUERY_CACHE_ENABLED_SETTING.getKey(), randomBoolean());
            }
            PutIndexTemplateRequestBuilder putTemplate = client().admin().indices()
                .preparePutTemplate(""random_index_template"")
                .setPatterns(Collections.singletonList(""*""))
                .setOrder(0)
                .setSettings(randomSettingsBuilder);
            assertAcked(putTemplate.execute().actionGet());
        }
    }
",non-flaky,5
91445,strapdata_elassandra,SuiteScopeClusterIT.testReproducible,"    @Test
    public void testReproducible() throws IOException {
        if (ITER++ == 0) {
            CLUSTER_SEED = cluster().seed();
            for (int i = 0; i < SEQUENCE.length; i++) {
                SEQUENCE[i] = randomLong();
            }
        } else {
            assertEquals(CLUSTER_SEED, Long.valueOf(cluster().seed()));
            for (int i = 0; i < SEQUENCE.length; i++) {
                assertThat(SEQUENCE[i], equalTo(randomLong()));
            }
        }
    }
",non-flaky,5
91446,strapdata_elassandra,LoggingListenerTests.annotatedTestMethod,"        @TestLogging(""xyz:TRACE,foo:WARN,foo.bar:ERROR"")
        public void annotatedTestMethod() {

        }
",non-flaky,5
91447,strapdata_elassandra,LoggingListenerTests.annotatedTestMethod2,"        @TestLogging(""abc:TRACE,xyz:DEBUG"")
        public void annotatedTestMethod2() {

        }
",non-flaky,5
91448,strapdata_elassandra,LoggingListenerTests.invalidMethod,"        @TestLogging(""abc:INFO:WARN"")
        public void invalidMethod() {

        }
",non-flaky,5
91449,strapdata_elassandra,IndexShardIT.testStressMaybeFlushOrRollTranslogGeneration,"    @TestLogging(""org.elasticsearch.index.shard:TRACE,org.elasticsearch.index.engine:TRACE"")
    public void testStressMaybeFlushOrRollTranslogGeneration() throws Exception {
        createIndex(""test"");
        ensureGreen();
        IndicesService indicesService = getInstanceFromNode(IndicesService.class);
        IndexService test = indicesService.indexService(resolveIndex(""test""));
        final IndexShard shard = test.getShardOrNull(0);
        assertFalse(shard.shouldPeriodicallyFlush());
        final boolean flush = randomBoolean();
        final Settings settings;
        if (flush) {
            // size of the operation plus two generations of overhead.
            settings = Settings.builder().put(""index.translog.flush_threshold_size"", ""180b"").build();
        } else {
            // size of the operation plus header and footer
            settings = Settings.builder().put(""index.translog.generation_threshold_size"", ""117b"").build();
        }
        client().admin().indices().prepareUpdateSettings(""test"").setSettings(settings).get();
        client().prepareIndex(""test"", ""test"", ""0"")
                .setSource(""{}"", XContentType.JSON)
                .setRefreshPolicy(randomBoolean() ? IMMEDIATE : NONE)
                .get();
        assertFalse(shard.shouldPeriodicallyFlush());
        final AtomicBoolean running = new AtomicBoolean(true);
        final int numThreads = randomIntBetween(2, 4);
        final Thread[] threads = new Thread[numThreads];
        final CyclicBarrier barrier = new CyclicBarrier(numThreads + 1);
        for (int i = 0; i < threads.length; i++) {
            threads[i] = new Thread(() -> {
                try {
                    barrier.await();
                } catch (final InterruptedException | BrokenBarrierException e) {
                    throw new RuntimeException(e);
                }
                while (running.get()) {
                    shard.afterWriteOperation();
                }
            });
            threads[i].start();
        }
        barrier.await();
        final CheckedRunnable<Exception> check;
        if (flush) {
            final FlushStats initialStats = shard.flushStats();
            client().prepareIndex(""test"", ""test"", ""1"").setSource(""{}"", XContentType.JSON).get();
            check = () -> {
                final FlushStats currentStats = shard.flushStats();
                String msg = String.format(Locale.ROOT, ""flush stats: total=[%d vs %d], periodic=[%d vs %d]"",
                    initialStats.getTotal(), currentStats.getTotal(), initialStats.getPeriodic(), currentStats.getPeriodic());
                assertThat(msg, currentStats.getPeriodic(), equalTo(initialStats.getPeriodic() + 1));
                assertThat(msg, currentStats.getTotal(), equalTo(initialStats.getTotal() + 1));
            };
        } else {
            final long generation = getTranslog(shard).currentFileGeneration();
            client().prepareIndex(""test"", ""test"", ""1"").setSource(""{}"", XContentType.JSON).get();
            check = () -> assertEquals(
                    generation + 1,
                    getTranslog(shard).currentFileGeneration());
        }
        assertBusy(check);
        running.set(false);
        for (int i = 0; i < threads.length; i++) {
            threads[i].join();
        }
        check.run();
    }
",non-flaky,5
91450,strapdata_elassandra,RecoveryDuringReplicationTests.testRecoveryAfterPrimaryPromotion,"    @TestLogging(""org.elasticsearch.index.shard:TRACE,org.elasticsearch.indices.recovery:TRACE"")
    public void testRecoveryAfterPrimaryPromotion() throws Exception {
        try (ReplicationGroup shards = createGroup(2)) {
            shards.startAll();
            int totalDocs = shards.indexDocs(randomInt(10));
            int committedDocs = 0;
            if (randomBoolean()) {
                shards.flush();
                committedDocs = totalDocs;
            }

            final IndexShard oldPrimary = shards.getPrimary();
            final IndexShard newPrimary = shards.getReplicas().get(0);
            final IndexShard replica = shards.getReplicas().get(1);
            if (randomBoolean()) {
                // simulate docs that were inflight when primary failed, these will be rolled back
                final int rollbackDocs = randomIntBetween(1, 5);
                logger.info(""--> indexing {} rollback docs"", rollbackDocs);
                for (int i = 0; i < rollbackDocs; i++) {
                    final IndexRequest indexRequest = new IndexRequest(index.getName(), ""type"", ""rollback_"" + i)
                            .source(""{}"", XContentType.JSON);
                    final BulkShardRequest bulkShardRequest = indexOnPrimary(indexRequest, oldPrimary);
                    indexOnReplica(bulkShardRequest, shards, replica);
                }
                if (randomBoolean()) {
                    oldPrimary.flush(new FlushRequest(index.getName()));
                }
            }

            shards.promoteReplicaToPrimary(newPrimary).get();

            // check that local checkpoint of new primary is properly tracked after primary promotion
            assertThat(newPrimary.getLocalCheckpoint(), equalTo(totalDocs - 1L));
            assertThat(IndexShardTestCase.getReplicationTracker(newPrimary)
                .getTrackedLocalCheckpointForShard(newPrimary.routingEntry().allocationId().getId()).getLocalCheckpoint(),
                equalTo(totalDocs - 1L));

            // index some more
            int moreDocs = shards.indexDocs(randomIntBetween(0, 5));
            totalDocs += moreDocs;

            // As a replica keeps a safe commit, the file-based recovery only happens if the required translog
            // for the sequence based recovery are not fully retained and extra documents were added to the primary.
            boolean expectSeqNoRecovery = (moreDocs == 0 || randomBoolean());
            int uncommittedOpsOnPrimary = 0;
            if (expectSeqNoRecovery == false) {
                IndexMetaData.Builder builder = IndexMetaData.builder(newPrimary.indexSettings().getIndexMetaData());
                builder.settings(Settings.builder().put(newPrimary.indexSettings().getSettings())
                    .put(IndexSettings.INDEX_TRANSLOG_RETENTION_AGE_SETTING.getKey(), ""-1"")
                    .put(IndexSettings.INDEX_TRANSLOG_RETENTION_SIZE_SETTING.getKey(), ""-1"")
                    .put(IndexSettings.INDEX_SOFT_DELETES_RETENTION_OPERATIONS_SETTING.getKey(), 0)
                );
                newPrimary.indexSettings().updateIndexMetaData(builder.build());
                newPrimary.onSettingsChanged();
                // Make sure the global checkpoint on the new primary is persisted properly,
                // otherwise the deletion policy won't trim translog
                assertBusy(() -> {
                    shards.syncGlobalCheckpoint();
                    assertThat(newPrimary.getLastSyncedGlobalCheckpoint(), equalTo(newPrimary.seqNoStats().getMaxSeqNo()));
                });
                newPrimary.flush(new FlushRequest().force(true));
                if (replica.indexSettings().isSoftDeleteEnabled()) {
                    // We need an extra flush to advance the min_retained_seqno on the new primary so ops-based won't happen.
                    // The min_retained_seqno only advances when a merge asks for the retention query.
                    newPrimary.flush(new FlushRequest().force(true));
                }
                uncommittedOpsOnPrimary = shards.indexDocs(randomIntBetween(0, 10));
                totalDocs += uncommittedOpsOnPrimary;
            }

            if (randomBoolean()) {
                uncommittedOpsOnPrimary = 0;
                shards.syncGlobalCheckpoint();
                newPrimary.flush(new FlushRequest());
            }

            oldPrimary.close(""demoted"", false);
            oldPrimary.store().close();

            IndexShard newReplica = shards.addReplicaWithExistingPath(oldPrimary.shardPath(), oldPrimary.routingEntry().currentNodeId());
            shards.recoverReplica(newReplica);

            if (expectSeqNoRecovery) {
                assertThat(newReplica.recoveryState().getIndex().fileDetails(), empty());
                assertThat(newReplica.recoveryState().getTranslog().recoveredOperations(), equalTo(totalDocs - committedDocs));
            } else {
                assertThat(newReplica.recoveryState().getIndex().fileDetails(), not(empty()));
                assertThat(newReplica.recoveryState().getTranslog().recoveredOperations(), equalTo(uncommittedOpsOnPrimary));
            }
            // Make sure that flushing on a recovering shard is ok.
            shards.flush();
            shards.assertAllEqual(totalDocs);
        }
    }
",non-flaky,5
91451,strapdata_elassandra,RecoveryDuringReplicationTests.testResyncAfterPrimaryPromotion,"    @TestLogging(""org.elasticsearch.index.shard:TRACE,org.elasticsearch.action.resync:TRACE"")
    public void testResyncAfterPrimaryPromotion() throws Exception {
        // TODO: check translog trimming functionality once rollback is implemented in Lucene (ES trimming is done)
        Map<String, String> mappings =
            Collections.singletonMap(""type"", ""{ \""type\"": { \""properties\"": { \""f\"": { \""type\"": \""keyword\""} }}}"");
        try (ReplicationGroup shards = new ReplicationGroup(buildIndexMetaData(2, mappings))) {
            shards.startAll();
            int initialDocs = randomInt(10);

            for (int i = 0; i < initialDocs; i++) {
                final IndexRequest indexRequest = new IndexRequest(index.getName(), ""type"", ""initial_doc_"" + i)
                    .source(""{ \""f\"": \""normal\""}"", XContentType.JSON);
                shards.index(indexRequest);
            }

            boolean syncedGlobalCheckPoint = randomBoolean();
            if (syncedGlobalCheckPoint) {
                shards.syncGlobalCheckpoint();
            }

            final IndexShard oldPrimary = shards.getPrimary();
            final IndexShard newPrimary = shards.getReplicas().get(0);
            final IndexShard justReplica = shards.getReplicas().get(1);

            // simulate docs that were inflight when primary failed
            final int extraDocs = randomInt(5);
            logger.info(""--> indexing {} extra docs"", extraDocs);
            for (int i = 0; i < extraDocs; i++) {
                final IndexRequest indexRequest = new IndexRequest(index.getName(), ""type"", ""extra_doc_"" + i)
                    .source(""{ \""f\"": \""normal\""}"", XContentType.JSON);
                final BulkShardRequest bulkShardRequest = indexOnPrimary(indexRequest, oldPrimary);
                indexOnReplica(bulkShardRequest, shards, newPrimary);
            }

            final int extraDocsToBeTrimmed = randomIntBetween(0, 10);
            logger.info(""--> indexing {} extra docs to be trimmed"", extraDocsToBeTrimmed);
            for (int i = 0; i < extraDocsToBeTrimmed; i++) {
                final IndexRequest indexRequest = new IndexRequest(index.getName(), ""type"", ""extra_trimmed_"" + i)
                    .source(""{ \""f\"": \""trimmed\""}"", XContentType.JSON);
                final BulkShardRequest bulkShardRequest = indexOnPrimary(indexRequest, oldPrimary);
                // have to replicate to another replica != newPrimary one - the subject to trim
                indexOnReplica(bulkShardRequest, shards, justReplica);
            }

            logger.info(""--> resyncing replicas seqno_stats primary {} replica {}"", oldPrimary.seqNoStats(), newPrimary.seqNoStats());
            PrimaryReplicaSyncer.ResyncTask task = shards.promoteReplicaToPrimary(newPrimary).get();
            if (syncedGlobalCheckPoint) {
                assertEquals(extraDocs, task.getResyncedOperations());
            } else {
                assertThat(task.getResyncedOperations(), greaterThanOrEqualTo(extraDocs));
            }
            shards.assertAllEqual(initialDocs + extraDocs);
            for (IndexShard replica : shards.getReplicas()) {
                assertThat(replica.getMaxSeqNoOfUpdatesOrDeletes(),
                    greaterThanOrEqualTo(shards.getPrimary().getMaxSeqNoOfUpdatesOrDeletes()));
            }

            // check translog on replica is trimmed
            int translogOperations = 0;
            try(Translog.Snapshot snapshot = getTranslog(justReplica).newSnapshot()) {
                Translog.Operation next;
                while ((next = snapshot.next()) != null) {
                    translogOperations++;
                    assertThat(""unexpected op: "" + next, (int)next.seqNo(), lessThan(initialDocs + extraDocs));
                    assertThat(""unexpected primaryTerm: "" + next.primaryTerm(), next.primaryTerm(),
                        is(oldPrimary.getPendingPrimaryTerm()));
                    final Translog.Source source = next.getSource();
                    assertThat(source.source.utf8ToString(), is(""{ \""f\"": \""normal\""}""));
                }
            }
            assertThat(translogOperations, is(initialDocs + extraDocs));
        }
    }
",non-flaky,5
91452,strapdata_elassandra,RecoveryDuringReplicationTests.indexTranslogOperations,"    @TestLogging(
    public void testWaitForPendingSeqNo() throws Exception {
        IndexMetaData metaData = buildIndexMetaData(1);

        final int pendingDocs = randomIntBetween(1, 5);
        final BlockingEngineFactory primaryEngineFactory = new BlockingEngineFactory();

        try (ReplicationGroup shards = new ReplicationGroup(metaData) {
            @Override
            protected EngineFactory getEngineFactory(ShardRouting routing) {
                if (routing.primary()) {
                    return primaryEngineFactory;
                } else {
                    return new InternalEngineFactory();
                }
            }
        }) {
            shards.startAll();
            int docs = shards.indexDocs(randomIntBetween(1, 10));
            // simulate a background global checkpoint sync at which point we expect the global checkpoint to advance on the replicas
            shards.syncGlobalCheckpoint();
            IndexShard replica = shards.getReplicas().get(0);
            shards.removeReplica(replica);
            closeShards(replica);

            docs += pendingDocs;
            primaryEngineFactory.latchIndexers(pendingDocs);
            CountDownLatch pendingDocsDone = new CountDownLatch(pendingDocs);
            for (int i = 0; i < pendingDocs; i++) {
                final String id = ""pending_"" + i;
                threadPool.generic().submit(() -> {
                    try {
                        shards.index(new IndexRequest(index.getName(), ""type"", id).source(""{}"", XContentType.JSON));
                    } catch (Exception e) {
                        throw new AssertionError(e);
                    } finally {
                        pendingDocsDone.countDown();
                    }
                });
            }

            // wait for the pending ops to ""hang""
            primaryEngineFactory.awaitIndexersLatch();

            primaryEngineFactory.allowIndexing();
            // index some more
            docs += shards.indexDocs(randomInt(5));

            IndexShard newReplica = shards.addReplicaWithExistingPath(replica.shardPath(), replica.routingEntry().currentNodeId());

            CountDownLatch recoveryStart = new CountDownLatch(1);
            AtomicBoolean opsSent = new AtomicBoolean(false);
            final Future<Void> recoveryFuture = shards.asyncRecoverReplica(newReplica, (indexShard, node) -> {
                recoveryStart.countDown();
                return new RecoveryTarget(indexShard, node, recoveryListener, l -> {
                }) {
                    @Override
                    public long indexTranslogOperations(List<Translog.Operation> operations, int totalTranslogOps,
                                                        long maxSeenAutoIdTimestamp, long maxSeqNoOfUpdates) throws IOException {
                        opsSent.set(true);
                        return super.indexTranslogOperations(operations, totalTranslogOps, maxSeenAutoIdTimestamp, maxSeqNoOfUpdates);
                    }
",non-flaky,5
91453,strapdata_elassandra,RecoveryDuringReplicationTests.indexTranslogOperations,"    @TestLogging(
    public void testCheckpointsAndMarkingInSync() throws Exception {
        final IndexMetaData metaData = buildIndexMetaData(0);
        final BlockingEngineFactory replicaEngineFactory = new BlockingEngineFactory();
        try (
                ReplicationGroup shards = new ReplicationGroup(metaData) {
                    @Override
                    protected EngineFactory getEngineFactory(final ShardRouting routing) {
                        if (routing.primary()) {
                            return new InternalEngineFactory();
                        } else {
                            return replicaEngineFactory;
                        }
                    }
                };
                AutoCloseable ignored = replicaEngineFactory // make sure we release indexers before closing
        ) {
            shards.startPrimary();
            final int docs = shards.indexDocs(randomIntBetween(1, 10));
            logger.info(""indexed [{}] docs"", docs);
            final CountDownLatch pendingDocDone = new CountDownLatch(1);
            final CountDownLatch pendingDocActiveWithExtraDocIndexed = new CountDownLatch(1);
            final CountDownLatch phaseTwoStartLatch = new CountDownLatch(1);
            final IndexShard replica = shards.addReplica();
            final Future<Void> recoveryFuture = shards.asyncRecoverReplica(
                    replica,
                    (indexShard, node) -> new RecoveryTarget(indexShard, node, recoveryListener, l -> {}) {
                        @Override
                        public long indexTranslogOperations(final List<Translog.Operation> operations, final int totalTranslogOps,
                                                            final long maxAutoIdTimestamp, long maxSeqNoOfUpdates)
",non-flaky,5
91454,strapdata_elassandra,InternalEngineMergeIT.testMergesHappening,"    @TestLogging(""_root:DEBUG"")
    public void testMergesHappening() throws InterruptedException, IOException, ExecutionException {
        final int numOfShards = randomIntBetween(1, 5);
        // some settings to keep num segments low
        assertAcked(prepareCreate(""test"").setSettings(Settings.builder()
                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, numOfShards)
                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0)
                .build()));
        long id = 0;
        final int rounds = scaledRandomIntBetween(50, 300);
        logger.info(""Starting rounds [{}] "", rounds);
        for (int i = 0; i < rounds; ++i) {
            final int numDocs = scaledRandomIntBetween(100, 1000);
            BulkRequestBuilder request = client().prepareBulk();
            for (int j = 0; j < numDocs; ++j) {
                request.add(Requests.indexRequest(""test"").type(""type1"").id(Long.toString(id++)).source(jsonBuilder().startObject().field(""l"", randomLong()).endObject()));
            }
            BulkResponse response = request.execute().actionGet();
            refresh();
            assertNoFailures(response);
            IndicesStatsResponse stats = client().admin().indices().prepareStats(""test"").setSegments(true).setMerge(true).get();
            logger.info(""index round [{}] - segments {}, total merges {}, current merge {}"", i, stats.getPrimaries().getSegments().getCount(), stats.getPrimaries().getMerge().getTotal(), stats.getPrimaries().getMerge().getCurrent());
        }
        final long upperNumberSegments = 2 * numOfShards * 10;
        awaitBusy(() -> {
            IndicesStatsResponse stats = client().admin().indices().prepareStats().setSegments(true).setMerge(true).get();
            logger.info(""numshards {}, segments {}, total merges {}, current merge {}"", numOfShards, stats.getPrimaries().getSegments().getCount(), stats.getPrimaries().getMerge().getTotal(), stats.getPrimaries().getMerge().getCurrent());
            long current = stats.getPrimaries().getMerge().getCurrent();
            long count = stats.getPrimaries().getSegments().getCount();
            return count < upperNumberSegments && current == 0;
        });
        IndicesStatsResponse stats = client().admin().indices().prepareStats().setSegments(true).setMerge(true).get();
        logger.info(""numshards {}, segments {}, total merges {}, current merge {}"", numOfShards, stats.getPrimaries().getSegments().getCount(), stats.getPrimaries().getMerge().getTotal(), stats.getPrimaries().getMerge().getCurrent());
        long count = stats.getPrimaries().getSegments().getCount();
        assertThat(count, Matchers.lessThanOrEqualTo(upperNumberSegments));
    }
",non-flaky,5
91455,strapdata_elassandra,RecoveryWhileUnderLoadIT.testRecoverWhileUnderLoadAllocateReplicasTest,"@TestLogging(""_root:DEBUG,org.elasticsearch.index.shard:TRACE,org.elasticsearch.cluster.service:TRACE,org.elasticsearch.index.seqno:TRACE,org.elasticsearch.indices.recovery:TRACE"")
    public void testRecoverWhileUnderLoadAllocateReplicasTest() throws Exception {
        logger.info(""--> creating test index ..."");
        int numberOfShards = numberOfShards();
        assertAcked(prepareCreate(""test"", 1, Settings.builder().put(SETTING_NUMBER_OF_SHARDS, numberOfShards).put(SETTING_NUMBER_OF_REPLICAS, 1).put(IndexSettings.INDEX_TRANSLOG_DURABILITY_SETTING.getKey(), Translog.Durability.ASYNC)));

        final int totalNumDocs = scaledRandomIntBetween(200, 10000);
        int waitFor = totalNumDocs / 10;
        int extraDocs = waitFor;
        try (BackgroundIndexer indexer = new BackgroundIndexer(""test"", ""type"", client(), extraDocs)) {
            logger.info(""--> waiting for {} docs to be indexed ..."", waitFor);
            waitForDocs(waitFor, indexer);
            indexer.assertNoFailures();
            logger.info(""--> {} docs indexed"", waitFor);

            extraDocs = totalNumDocs / 10;
            waitFor += extraDocs;
            indexer.continueIndexing(extraDocs);
            logger.info(""--> flushing the index ...."");
            // now flush, just to make sure we have some data in the index, not just translog
            client().admin().indices().prepareFlush().execute().actionGet();

            logger.info(""--> waiting for {} docs to be indexed ..."", waitFor);
            waitForDocs(waitFor, indexer);
            indexer.assertNoFailures();
            logger.info(""--> {} docs indexed"", waitFor);

            extraDocs = totalNumDocs - waitFor;
            indexer.continueIndexing(extraDocs);

            logger.info(""--> allow 2 nodes for index [test] ..."");
            // now start another node, while we index
            allowNodes(""test"", 2);

            logger.info(""--> waiting for GREEN health status ..."");
            // make sure the cluster state is green, and all has been recovered
            assertNoTimeout(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setTimeout(""5m"").setWaitForGreenStatus());

            logger.info(""--> waiting for {} docs to be indexed ..."", totalNumDocs);
            waitForDocs(totalNumDocs, indexer);
            indexer.assertNoFailures();
            logger.info(""--> {} docs indexed"", totalNumDocs);

            logger.info(""--> marking and waiting for indexing threads to stop ..."");
            indexer.stop();
            logger.info(""--> indexing threads stopped"");

            logger.info(""--> refreshing the index"");
            refreshAndAssert();
            logger.info(""--> verifying indexed content"");
            iterateAssertCount(numberOfShards, 10, indexer.getIds());
        }
    }
",non-flaky,5
91456,strapdata_elassandra,RelocationIT.testSimpleRelocationNoIndexing,"@TestLogging(""_root:DEBUG,org.elasticsearch.indices.recovery:TRACE,org.elasticsearch.index.shard.service:TRACE"")
    public void testSimpleRelocationNoIndexing() {
        logger.info(""--> starting [node1] ..."");
        final String node_1 = internalCluster().startNode();

        logger.info(""--> creating test index ..."");
        prepareCreate(""test"", Settings.builder()
                .put(""index.number_of_shards"", 1)
                .put(""index.number_of_replicas"", 0)
        ).get();

        logger.info(""--> index 10 docs"");
        for (int i = 0; i < 10; i++) {
            client().prepareIndex(""test"", ""type"", Integer.toString(i)).setSource(""field"", ""value"" + i).execute().actionGet();
        }
        logger.info(""--> flush so we have an actual index"");
        client().admin().indices().prepareFlush().execute().actionGet();
        logger.info(""--> index more docs so we have something in the translog"");
        for (int i = 10; i < 20; i++) {
            client().prepareIndex(""test"", ""type"", Integer.toString(i)).setSource(""field"", ""value"" + i).execute().actionGet();
        }

        logger.info(""--> verifying count"");
        client().admin().indices().prepareRefresh().execute().actionGet();
        assertThat(client().prepareSearch(""test"").setSize(0).execute().actionGet().getHits().getTotalHits(), equalTo(20L));

        logger.info(""--> start another node"");
        final String node_2 = internalCluster().startNode();
        ClusterHealthResponse clusterHealthResponse = client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForNodes(""2"").execute().actionGet();
        assertThat(clusterHealthResponse.isTimedOut(), equalTo(false));

        logger.info(""--> relocate the shard from node1 to node2"");
        client().admin().cluster().prepareReroute()
                .add(new MoveAllocationCommand(""test"", 0, node_1, node_2))
                .execute().actionGet();

        clusterHealthResponse = client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForNoRelocatingShards(true).setTimeout(ACCEPTABLE_RELOCATION_TIME).execute().actionGet();
        assertThat(clusterHealthResponse.isTimedOut(), equalTo(false));

        logger.info(""--> verifying count again..."");
        client().admin().indices().prepareRefresh().execute().actionGet();
        assertThat(client().prepareSearch(""test"").setSize(0).execute().actionGet().getHits().getTotalHits(), equalTo(20L));
    }
",non-flaky,5
91457,strapdata_elassandra,RelocationIT.testRelocationWhileIndexingRandom,"    @TestLogging(""org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.search:TRACE"")
    public void testRelocationWhileIndexingRandom() throws Exception {
        int numberOfRelocations = scaledRandomIntBetween(1, rarely() ? 10 : 4);
        int numberOfReplicas = randomBoolean() ? 0 : 1;
        int numberOfNodes = numberOfReplicas == 0 ? 2 : 3;

        logger.info(""testRelocationWhileIndexingRandom(numRelocations={}, numberOfReplicas={}, numberOfNodes={})"", numberOfRelocations, numberOfReplicas, numberOfNodes);

        String[] nodes = new String[numberOfNodes];
        logger.info(""--> starting [node1] ..."");
        nodes[0] = internalCluster().startNode();

        logger.info(""--> creating test index ..."");
        prepareCreate(""test"", Settings.builder()
            .put(""index.number_of_shards"", 1)
            .put(""index.number_of_replicas"", numberOfReplicas)
        ).get();


        for (int i = 2; i <= numberOfNodes; i++) {
            logger.info(""--> starting [node{}] ..."", i);
            nodes[i - 1] = internalCluster().startNode();
            if (i != numberOfNodes) {
                ClusterHealthResponse healthResponse = client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID)
                        .setWaitForNodes(Integer.toString(i)).setWaitForGreenStatus().execute().actionGet();
                assertThat(healthResponse.isTimedOut(), equalTo(false));
            }
        }

        int numDocs = scaledRandomIntBetween(200, 2500);
        try (BackgroundIndexer indexer = new BackgroundIndexer(""test"", ""type1"", client(), numDocs)) {
            logger.info(""--> waiting for {} docs to be indexed ..."", numDocs);
            waitForDocs(numDocs, indexer);
            logger.info(""--> {} docs indexed"", numDocs);

            logger.info(""--> starting relocations..."");
            int nodeShiftBased = numberOfReplicas; // if we have replicas shift those
            for (int i = 0; i < numberOfRelocations; i++) {
                int fromNode = (i % 2);
                int toNode = fromNode == 0 ? 1 : 0;
                fromNode += nodeShiftBased;
                toNode += nodeShiftBased;
                numDocs = scaledRandomIntBetween(200, 1000);
                logger.debug(""--> Allow indexer to index [{}] documents"", numDocs);
                indexer.continueIndexing(numDocs);
                logger.info(""--> START relocate the shard from {} to {}"", nodes[fromNode], nodes[toNode]);
                client().admin().cluster().prepareReroute()
                        .add(new MoveAllocationCommand(""test"", 0, nodes[fromNode], nodes[toNode]))
                        .get();
                if (rarely()) {
                    logger.debug(""--> flushing"");
                    client().admin().indices().prepareFlush().get();
                }
                ClusterHealthResponse clusterHealthResponse = client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForNoRelocatingShards(true).setTimeout(ACCEPTABLE_RELOCATION_TIME).execute().actionGet();
                assertThat(clusterHealthResponse.isTimedOut(), equalTo(false));
                indexer.pauseIndexing();
                logger.info(""--> DONE relocate the shard from {} to {}"", fromNode, toNode);
            }
            logger.info(""--> done relocations"");
            logger.info(""--> waiting for indexing threads to stop ..."");
            indexer.stop();
            logger.info(""--> indexing threads stopped"");

            logger.info(""--> refreshing the index"");
            client().admin().indices().prepareRefresh(""test"").execute().actionGet();
            logger.info(""--> searching the index"");
            boolean ranOnce = false;
            for (int i = 0; i < 10; i++) {
                    logger.info(""--> START search test round {}"", i + 1);
                    SearchHits hits = client().prepareSearch(""test"").setQuery(matchAllQuery()).setSize((int) indexer.totalIndexedDocs()).storedFields().execute().actionGet().getHits();
                    ranOnce = true;
                    if (hits.getTotalHits() != indexer.totalIndexedDocs()) {
                        int[] hitIds = new int[(int) indexer.totalIndexedDocs()];
                        for (int hit = 0; hit < indexer.totalIndexedDocs(); hit++) {
                            hitIds[hit] = hit + 1;
                        }
                        IntHashSet set = IntHashSet.from(hitIds);
                        for (SearchHit hit : hits.getHits()) {
                            int id = Integer.parseInt(hit.getId());
                            if (!set.remove(id)) {
                                logger.error(""Extra id [{}]"", id);
                            }
                        }
                        set.forEach((IntProcedure) value -> {
                            logger.error(""Missing id [{}]"", value);
                        });
                    }
                    assertThat(hits.getTotalHits(), equalTo(indexer.totalIndexedDocs()));
                    logger.info(""--> DONE search test round {}"", i + 1);

            }
            if (!ranOnce) {
                fail();
            }
        }
    }
",non-flaky,5
91458,strapdata_elassandra,RelocationIT.indexShardStateChanged,"    @TestLogging(""org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.search:TRACE"")
    public void testRelocationWhileRefreshing() throws Exception {
        int numberOfRelocations = scaledRandomIntBetween(1, rarely() ? 10 : 4);
        int numberOfReplicas = randomBoolean() ? 0 : 1;
        int numberOfNodes = numberOfReplicas == 0 ? 2 : 3;

        logger.info(""testRelocationWhileIndexingRandom(numRelocations={}, numberOfReplicas={}, numberOfNodes={})"", numberOfRelocations, numberOfReplicas, numberOfNodes);

        String[] nodes = new String[numberOfNodes];
        logger.info(""--> starting [node_0] ..."");
        nodes[0] = internalCluster().startNode();

        logger.info(""--> creating test index ..."");
        prepareCreate(
                ""test"",
                Settings.builder()
                        .put(""index.number_of_shards"", 1)
                        .put(""index.number_of_replicas"", numberOfReplicas)
                        .put(""index.refresh_interval"", -1) // we want to control refreshes
                        .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms""))
                .get();

        for (int i = 1; i < numberOfNodes; i++) {
            logger.info(""--> starting [node_{}] ..."", i);
            nodes[i] = internalCluster().startNode();
            if (i != numberOfNodes - 1) {
                ClusterHealthResponse healthResponse = client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID)
                        .setWaitForNodes(Integer.toString(i + 1)).setWaitForGreenStatus().execute().actionGet();
                assertThat(healthResponse.isTimedOut(), equalTo(false));
            }
        }

        final Semaphore postRecoveryShards = new Semaphore(0);
        final IndexEventListener listener = new IndexEventListener() {
            @Override
            public void indexShardStateChanged(IndexShard indexShard, @Nullable IndexShardState previousState, IndexShardState currentState, @Nullable String reason) {
                if (currentState == IndexShardState.POST_RECOVERY) {
                    postRecoveryShards.release();
                }
            }
",non-flaky,5
91459,strapdata_elassandra,RelocationIT.testIndexAndRelocateConcurrently,"    @TestLogging(
    public void testIndexAndRelocateConcurrently() throws ExecutionException, InterruptedException {
        int halfNodes = randomIntBetween(1, 3);
        Settings[] nodeSettings = Stream.concat(
            Stream.generate(() -> Settings.builder().put(""node.attr.color"", ""blue"").build()).limit(halfNodes),
            Stream.generate(() -> Settings.builder().put(""node.attr.color"", ""red"").build()).limit(halfNodes)
            ).toArray(Settings[]::new);
        List<String> nodes = internalCluster().startNodes(nodeSettings);
        String[] blueNodes = nodes.subList(0, halfNodes).stream().toArray(String[]::new);
        String[] redNodes = nodes.subList(halfNodes, nodes.size()).stream().toArray(String[]::new);
        logger.info(""blue nodes: {}"", (Object)blueNodes);
        logger.info(""red nodes: {}"", (Object)redNodes);
        ensureStableCluster(halfNodes * 2);

        final Settings.Builder settings = Settings.builder()
                .put(""index.routing.allocation.exclude.color"", ""blue"")
                .put(indexSettings())
                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(halfNodes - 1))
                .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"");
        assertAcked(prepareCreate(""test"", settings));
        assertAllShardsOnNodes(""test"", redNodes);
        int numDocs = randomIntBetween(100, 150);
        ArrayList<String> ids = new ArrayList<>();
        logger.info("" --> indexing [{}] docs"", numDocs);
        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
        for (int i = 0; i < numDocs; i++) {
            String id = randomRealisticUnicodeOfLength(10) + String.valueOf(i);
            ids.add(id);
            docs[i] = client().prepareIndex(""test"", ""type1"", id).setSource(""field1"", English.intToEnglish(i));
        }
        indexRandom(true, docs);
        SearchResponse countResponse = client().prepareSearch(""test"").get();
        assertHitCount(countResponse, numDocs);

        logger.info("" --> moving index to new nodes"");
        Settings build = Settings.builder().put(""index.routing.allocation.exclude.color"", ""red"")
            .put(""index.routing.allocation.include.color"", ""blue"").build();
        client().admin().indices().prepareUpdateSettings(""test"").setSettings(build).execute().actionGet();

        // index while relocating
        logger.info("" --> indexing [{}] more docs"", numDocs);
        for (int i = 0; i < numDocs; i++) {
            String id = randomRealisticUnicodeOfLength(10) + String.valueOf(numDocs + i);
            ids.add(id);
            docs[i] = client().prepareIndex(""test"", ""type1"", id).setSource(""field1"", English.intToEnglish(numDocs + i));
        }
        indexRandom(true, docs);
        numDocs *= 2;

        logger.info("" --> waiting for relocation to complete"");
        ensureGreen(""test""); // move all shards to the new nodes (it waits on relocation)

        final int numIters = randomIntBetween(10, 20);
        for (int i = 0; i < numIters; i++) {
            logger.info("" --> checking iteration {}"", i);
            SearchResponse afterRelocation = client().prepareSearch().setSize(ids.size()).get();
            assertNoFailures(afterRelocation);
            assertSearchHits(afterRelocation, ids.toArray(new String[ids.size()]));
        }

    }
",non-flaky,5
91460,strapdata_elassandra,SnapshotDisruptionIT.clusterChanged,"@TestLogging(""org.elasticsearch.snapshot:TRACE"")
    public void testDisruptionOnSnapshotInitialization() throws Exception {
        final Settings settings = Settings.builder()
            .put(DEFAULT_SETTINGS)
            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), ""30s"") // wait till cluster state is committed
            .build();
        final String idxName = ""test"";
        configureCluster(settings, 4, null, 2);
        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(3);
        final String dataNode = internalCluster().startDataOnlyNode();
        ensureStableCluster(4);

        createRandomIndex(idxName);

        logger.info(""-->  creating repository"");
        assertAcked(client().admin().cluster().preparePutRepository(""test-repo"")
            .setType(""fs"").setSettings(Settings.builder()
                .put(""location"", randomRepoPath())
                .put(""compress"", randomBoolean())
                .put(""chunk_size"", randomIntBetween(100, 1000), ByteSizeUnit.BYTES)));

        // Writing incompatible snapshot can cause this test to fail due to a race condition in repo initialization
        // by the current master and the former master. It is not causing any issues in real life scenario, but
        // might make this test to fail. We are going to complete initialization of the snapshot to prevent this failures.
        logger.info(""-->  initializing the repository"");
        assertEquals(SnapshotState.SUCCESS, client().admin().cluster().prepareCreateSnapshot(""test-repo"", ""test-snap-1"")
            .setWaitForCompletion(true).setIncludeGlobalState(true).setIndices().get().getSnapshotInfo().state());

        final String masterNode1 = internalCluster().getMasterName();
        Set<String> otherNodes = new HashSet<>();
        otherNodes.addAll(allMasterEligibleNodes);
        otherNodes.remove(masterNode1);
        otherNodes.add(dataNode);

        NetworkDisruption networkDisruption =
            new NetworkDisruption(new NetworkDisruption.TwoPartitions(Collections.singleton(masterNode1), otherNodes),
                new NetworkDisruption.NetworkUnresponsive());
        internalCluster().setDisruptionScheme(networkDisruption);

        ClusterService clusterService = internalCluster().clusterService(masterNode1);
        CountDownLatch disruptionStarted = new CountDownLatch(1);
        clusterService.addListener(new ClusterStateListener() {
            @Override
            public void clusterChanged(ClusterChangedEvent event) {
                SnapshotsInProgress snapshots = event.state().custom(SnapshotsInProgress.TYPE);
                if (snapshots != null && snapshots.entries().size() > 0) {
                    if (snapshots.entries().get(0).state() == SnapshotsInProgress.State.INIT) {
                        // The snapshot started, we can start disruption so the INIT state will arrive to another master node
                        logger.info(""--> starting disruption"");
                        networkDisruption.startDisrupting();
                        clusterService.removeListener(this);
                        disruptionStarted.countDown();
                    }
                }
            }
",non-flaky,5
91461,strapdata_elassandra,DiscoveryDisruptionIT.testIsolatedUnicastNodes,"@TestLogging(""_root:DEBUG,org.elasticsearch.cluster.service:TRACE"")
    public void testIsolatedUnicastNodes() throws Exception {
        List<String> nodes = startCluster(4, -1, new int[]{0});
        // Figure out what is the elected master node
        final String unicastTarget = nodes.get(0);

        Set<String> unicastTargetSide = new HashSet<>();
        unicastTargetSide.add(unicastTarget);

        Set<String> restOfClusterSide = new HashSet<>();
        restOfClusterSide.addAll(nodes);
        restOfClusterSide.remove(unicastTarget);

        // Forcefully clean temporal response lists on all nodes. Otherwise the node in the unicast host list
        // includes all the other nodes that have pinged it and the issue doesn't manifest
        ZenPing zenPing = ((TestZenDiscovery) internalCluster().getInstance(Discovery.class)).getZenPing();
        if (zenPing instanceof UnicastZenPing) {
            ((UnicastZenPing) zenPing).clearTemporalResponses();
        }

        // Simulate a network issue between the unicast target node and the rest of the cluster
        NetworkDisruption networkDisconnect = new NetworkDisruption(new TwoPartitions(unicastTargetSide, restOfClusterSide),
                new NetworkDisconnect());
        setDisruptionScheme(networkDisconnect);
        networkDisconnect.startDisrupting();
        // Wait until elected master has removed that the unlucky node...
        ensureStableCluster(3, nodes.get(1));

        // The isolate master node must report no master, so it starts with pinging
        assertNoMaster(unicastTarget);
        networkDisconnect.stopDisrupting();
        // Wait until the master node sees all 3 nodes again.
        ensureStableCluster(4);
    }
",non-flaky,5
91462,strapdata_elassandra,NodeJoinControllerTests.setUp,"@TestLogging(""org.elasticsearch.discovery.zen:TRACE,org.elasticsearch.cluster.service:TRACE"")
    public void setUp() throws Exception {
        super.setUp();
    }
",non-flaky,5
91463,strapdata_elassandra,ZenDiscoveryIT.testNoShardRelocationsOccurWhenElectedMasterNodeFails,"@TestLogging(""_root:DEBUG"")
    public void testNoShardRelocationsOccurWhenElectedMasterNodeFails() throws Exception {
        Settings defaultSettings = Settings.builder()
                .put(FaultDetection.PING_TIMEOUT_SETTING.getKey(), ""1s"")
                .put(FaultDetection.PING_RETRIES_SETTING.getKey(), ""1"")
                .build();

        Settings masterNodeSettings = Settings.builder()
                .put(Node.NODE_DATA_SETTING.getKey(), false)
                .put(defaultSettings)
                .build();
        internalCluster().startNodes(2, masterNodeSettings);
        Settings dateNodeSettings = Settings.builder()
                .put(Node.NODE_MASTER_SETTING.getKey(), false)
                .put(defaultSettings)
                .build();
        internalCluster().startNodes(2, dateNodeSettings);
        ClusterHealthResponse clusterHealthResponse = client().admin().cluster().prepareHealth()
                .setWaitForEvents(Priority.LANGUID)
                .setWaitForNodes(""4"")
                .setWaitForNoRelocatingShards(true)
                .get();
        assertThat(clusterHealthResponse.isTimedOut(), is(false));

        createIndex(""test"");
        ensureSearchable(""test"");
        RecoveryResponse r = client().admin().indices().prepareRecoveries(""test"").get();
        int numRecoveriesBeforeNewMaster = r.shardRecoveryStates().get(""test"").size();

        final String oldMaster = internalCluster().getMasterName();
        internalCluster().stopCurrentMasterNode();
        assertBusy(() -> {
            String current = internalCluster().getMasterName();
            assertThat(current, notNullValue());
            assertThat(current, not(equalTo(oldMaster)));
        });
        ensureSearchable(""test"");

        r = client().admin().indices().prepareRecoveries(""test"").get();
        int numRecoveriesAfterNewMaster = r.shardRecoveryStates().get(""test"").size();
        assertThat(numRecoveriesAfterNewMaster, equalTo(numRecoveriesBeforeNewMaster));
    }
",non-flaky,5
91464,strapdata_elassandra,PublishClusterStateActionTests.setAsMaster,"@TestLogging(""org.elasticsearch.discovery.zen.publish:TRACE"")
        public MockNode setAsMaster() {
            this.clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .masterNodeId(discoveryNode.getId())).build();
            return this;
        }
",non-flaky,5
91465,strapdata_elassandra,MasterDisruptionIT.testFailWithMinimumMasterNodesConfigured,"@TestLogging(""_root:DEBUG,org.elasticsearch.cluster.service:TRACE"")
    public void testFailWithMinimumMasterNodesConfigured() throws Exception {
        List<String> nodes = startCluster(3);

        // Figure out what is the elected master node
        final String masterNode = internalCluster().getMasterName();
        logger.info(""---> legit elected master node={}"", masterNode);

        // Pick a node that isn't the elected master.
        Set<String> nonMasters = new HashSet<>(nodes);
        nonMasters.remove(masterNode);
        final String unluckyNode = randomFrom(nonMasters.toArray(Strings.EMPTY_ARRAY));


        // Simulate a network issue between the unlucky node and elected master node in both directions.

        NetworkDisruption networkDisconnect = new NetworkDisruption(
                new NetworkDisruption.TwoPartitions(masterNode, unluckyNode),
                new NetworkDisruption.NetworkDisconnect());
        setDisruptionScheme(networkDisconnect);
        networkDisconnect.startDisrupting();

        // Wait until elected master has removed that the unlucky node...
        ensureStableCluster(2, masterNode);

        // The unlucky node must report *no* master node, since it can't connect to master and in fact it should
        // continuously ping until network failures have been resolved. However
        // It may a take a bit before the node detects it has been cut off from the elected master
        assertNoMaster(unluckyNode);

        networkDisconnect.stopDisrupting();

        // Wait until the master node sees all 3 nodes again.
        ensureStableCluster(3);

        // The elected master shouldn't have changed, since the unlucky node never could have elected himself as
        // master since m_m_n of 2 could never be satisfied.
        assertMaster(masterNode, nodes);
    }
",non-flaky,5
91466,strapdata_elassandra,MasterDisruptionIT.execute,"    @TestLogging(""_root:DEBUG,org.elasticsearch.cluster.service:TRACE,org.elasticsearch.test.disruption:TRACE"")
    public void testStaleMasterNotHijackingMajority() throws Exception {
        // 3 node cluster with unicast discovery and minimum_master_nodes set to 2:
        final List<String> nodes = startCluster(3, 2);

        // Save the current master node as old master node, because that node will get frozen
        final String oldMasterNode = internalCluster().getMasterName();
        for (String node : nodes) {
            ensureStableCluster(3, node);
        }
        assertMaster(oldMasterNode, nodes);

        // Simulating a painful gc by suspending all threads for a long time on the current elected master node.
        SingleNodeDisruption masterNodeDisruption = new LongGCDisruption(random(), oldMasterNode);

        // Save the majority side
        final List<String> majoritySide = new ArrayList<>(nodes);
        majoritySide.remove(oldMasterNode);

        // Keeps track of the previous and current master when a master node transition took place on each node on the majority side:
        final Map<String, List<Tuple<String, String>>> masters = Collections.synchronizedMap(new HashMap<String, List<Tuple<String,
                        String>>>());
        for (final String node : majoritySide) {
            masters.put(node, new ArrayList<Tuple<String, String>>());
            internalCluster().getInstance(ClusterService.class, node).addListener(event -> {
                DiscoveryNode previousMaster = event.previousState().nodes().getMasterNode();
                DiscoveryNode currentMaster = event.state().nodes().getMasterNode();
                if (!Objects.equals(previousMaster, currentMaster)) {
                    logger.info(""node {} received new cluster state: {} \n and had previous cluster state: {}"", node, event.state(),
                            event.previousState());
                    String previousMasterNodeName = previousMaster != null ? previousMaster.getName() : null;
                    String currentMasterNodeName = currentMaster != null ? currentMaster.getName() : null;
                    masters.get(node).add(new Tuple<>(previousMasterNodeName, currentMasterNodeName));
                }
            });
        }

        final CountDownLatch oldMasterNodeSteppedDown = new CountDownLatch(1);
        internalCluster().getInstance(ClusterService.class, oldMasterNode).addListener(event -> {
            if (event.state().nodes().getMasterNodeId() == null) {
                oldMasterNodeSteppedDown.countDown();
            }
        });

        internalCluster().setDisruptionScheme(masterNodeDisruption);
        logger.info(""freezing node [{}]"", oldMasterNode);
        masterNodeDisruption.startDisrupting();

        // Wait for the majority side to get stable
        assertDifferentMaster(majoritySide.get(0), oldMasterNode);
        assertDifferentMaster(majoritySide.get(1), oldMasterNode);

        // the test is periodically tripping on the following assertion. To find out which threads are blocking the nodes from making
        // progress we print a stack dump
        boolean failed = true;
        try {
            assertDiscoveryCompleted(majoritySide);
            failed = false;
        } finally {
            if (failed) {
                logger.error(""discovery failed to complete, probably caused by a blocked thread: {}"",
                        new HotThreads().busiestThreads(Integer.MAX_VALUE).ignoreIdleThreads(false).detect());
            }
        }

        // The old master node is frozen, but here we submit a cluster state update task that doesn't get executed,
        // but will be queued and once the old master node un-freezes it gets executed.
        // The old master node will send this update + the cluster state where he is flagged as master to the other
        // nodes that follow the new master. These nodes should ignore this update.
        internalCluster().getInstance(ClusterService.class, oldMasterNode).submitStateUpdateTask(""sneaky-update"", new
                ClusterStateUpdateTask(Priority.IMMEDIATE) {
                    @Override
                    public ClusterState execute(ClusterState currentState) throws Exception {
                        return ClusterState.builder(currentState).build();
                    }
",non-flaky,5
91467,strapdata_elassandra,MasterDisruptionIT.testIsolateMasterAndVerifyClusterStateConsensus,"    @TestLogging(
    public void testIsolateMasterAndVerifyClusterStateConsensus() throws Exception {
        final List<String> nodes = startCluster(3);

        assertAcked(prepareCreate(""test"")
                .setSettings(Settings.builder()
                        .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))
                        .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))
                ));

        ensureGreen();
        String isolatedNode = internalCluster().getMasterName();
        TwoPartitions partitions = isolateNode(isolatedNode);
        NetworkDisruption networkDisruption = addRandomDisruptionType(partitions);
        networkDisruption.startDisrupting();

        String nonIsolatedNode = partitions.getMajoritySide().iterator().next();

        // make sure cluster reforms
        ensureStableCluster(2, nonIsolatedNode);

        // make sure isolated need picks up on things.
        assertNoMaster(isolatedNode, TimeValue.timeValueSeconds(40));

        // restore isolation
        networkDisruption.stopDisrupting();

        for (String node : nodes) {
            ensureStableCluster(3, new TimeValue(DISRUPTION_HEALING_OVERHEAD.millis() + networkDisruption.expectedTimeToHeal().millis()),
                    true, node);
        }

        logger.info(""issue a reroute"");
        // trigger a reroute now, instead of waiting for the background reroute of RerouteService
        assertAcked(client().admin().cluster().prepareReroute());
        // and wait for it to finish and for the cluster to stabilize
        ensureGreen(""test"");

        // verify all cluster states are the same
        // use assert busy to wait for cluster states to be applied (as publish_timeout has low value)
        assertBusy(() -> {
            ClusterState state = null;
            for (String node : nodes) {
                ClusterState nodeState = getNodeClusterState(node);
                if (state == null) {
                    state = nodeState;
                    continue;
                }
                // assert nodes are identical
                try {
                    assertEquals(""unequal versions"", state.version(), nodeState.version());
                    assertEquals(""unequal node count"", state.nodes().getSize(), nodeState.nodes().getSize());
                    assertEquals(""different masters "", state.nodes().getMasterNodeId(), nodeState.nodes().getMasterNodeId());
                    assertEquals(""different meta data version"", state.metaData().version(), nodeState.metaData().version());
                    assertEquals(""different routing"", state.routingTable().toString(), nodeState.routingTable().toString());
                } catch (AssertionError t) {
                    fail(""failed comparing cluster state: "" + t.getMessage() + ""\n"" +
                            ""--- cluster state of node ["" + nodes.get(0) + ""]: ---\n"" + state +
                            ""\n--- cluster state ["" + node + ""]: ---\n"" + nodeState);
                }

            }
        });
    }
",non-flaky,5
91468,strapdata_elassandra,MasterDisruptionIT.testMappingTimeout,"    @TestLogging(
    public void testMappingTimeout() throws Exception {
        startCluster(3);
        createIndex(""test"", Settings.builder()
            .put(""index.number_of_shards"", 1)
            .put(""index.number_of_replicas"", 1)
            .put(""index.routing.allocation.exclude._name"", internalCluster().getMasterName())
        .build());

        // create one field
        index(""test"", ""doc"", ""1"", ""{ \""f\"": 1 }"");

        ensureGreen();

        assertAcked(client().admin().cluster().prepareUpdateSettings().setTransientSettings(
            Settings.builder().put(""indices.mapping.dynamic_timeout"", ""1ms"")));

        ServiceDisruptionScheme disruption = new BlockMasterServiceOnMaster(random());
        setDisruptionScheme(disruption);

        disruption.startDisrupting();

        BulkRequestBuilder bulk = client().prepareBulk();
        bulk.add(client().prepareIndex(""test"", ""doc"", ""2"").setSource(""{ \""f\"": 1 }"", XContentType.JSON));
        bulk.add(client().prepareIndex(""test"", ""doc"", ""3"").setSource(""{ \""g\"": 1 }"", XContentType.JSON));
        bulk.add(client().prepareIndex(""test"", ""doc"", ""4"").setSource(""{ \""f\"": 1 }"", XContentType.JSON));
        BulkResponse bulkResponse = bulk.get();
        assertTrue(bulkResponse.hasFailures());

        disruption.stopDisrupting();

        assertBusy(() -> {
            IndicesStatsResponse stats = client().admin().indices().prepareStats(""test"").clear().get();
            for (ShardStats shardStats : stats.getShards()) {
                assertThat(shardStats.getShardRouting().toString(),
                    shardStats.getSeqNoStats().getGlobalCheckpoint(), equalTo(shardStats.getSeqNoStats().getLocalCheckpoint()));
            }
        });

    }
",non-flaky,5
91469,strapdata_elassandra,ClusterDisruptionIT.testAckedIndexing,"    @TestLogging(""_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE,"" +
    public void testAckedIndexing() throws Exception {

        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5;
        final String timeout = seconds + ""s"";

        final List<String> nodes = startCluster(rarely() ? 5 : 3);

        assertAcked(prepareCreate(""test"")
            .setSettings(Settings.builder()
                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))
                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))
            ));
        ensureGreen();

        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme();
        logger.info(""disruption scheme [{}] added"", disruptionScheme);

        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>(); // id -> node sent.

        final AtomicBoolean stop = new AtomicBoolean(false);
        List<Thread> indexers = new ArrayList<>(nodes.size());
        List<Semaphore> semaphores = new ArrayList<>(nodes.size());
        final AtomicInteger idGenerator = new AtomicInteger(0);
        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>();
        final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>());

        logger.info(""starting indexers"");
        try {
            for (final String node : nodes) {
                final Semaphore semaphore = new Semaphore(0);
                semaphores.add(semaphore);
                final Client client = client(node);
                final String name = ""indexer_"" + indexers.size();
                final int numPrimaries = getNumShards(""test"").numPrimaries;
                Thread thread = new Thread(() -> {
                    while (!stop.get()) {
                        String id = null;
                        try {
                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {
                                continue;
                            }
                            logger.info(""[{}] Acquired semaphore and it has {} permits left"", name, semaphore.availablePermits());
                            try {
                                id = Integer.toString(idGenerator.incrementAndGet());
                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries);
                                logger.trace(""[{}] indexing id [{}] through node [{}] targeting shard [{}]"", name, id, node, shard);
                                IndexResponse response =
                                        client.prepareIndex(""test"", ""type"", id)
                                                .setSource(""{}"", XContentType.JSON)
                                                .setTimeout(timeout)
                                                .get(timeout);
                                assertEquals(DocWriteResponse.Result.CREATED, response.getResult());
                                ackedDocs.put(id, node);
                                logger.trace(""[{}] indexed id [{}] through node [{}], response [{}]"", name, id, node, response);
                            } catch (ElasticsearchException e) {
                                exceptedExceptions.add(e);
                                final String docId = id;
                                logger.trace(() -> new ParameterizedMessage(""[{}] failed id [{}] through node [{}]"", name, docId, node), e);
                            } finally {
                                countDownLatchRef.get().countDown();
                                logger.trace(""[{}] decreased counter : {}"", name, countDownLatchRef.get().getCount());
                            }
                        } catch (InterruptedException e) {
                            // fine - semaphore interrupt
                        } catch (AssertionError | Exception e) {
                            logger.info(() -> new ParameterizedMessage(""unexpected exception in background thread of [{}]"", node), e);
                        }
                    }
                });

                thread.setName(name);
                thread.start();
                indexers.add(thread);
            }

            int docsPerIndexer = randomInt(3);
            logger.info(""indexing {} docs per indexer before partition"", docsPerIndexer);
            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()));
            for (Semaphore semaphore : semaphores) {
                semaphore.release(docsPerIndexer);
            }
            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES));

            for (int iter = 1 + randomInt(2); iter > 0; iter--) {
                logger.info(""starting disruptions & indexing (iteration [{}])"", iter);
                disruptionScheme.startDisrupting();

                docsPerIndexer = 1 + randomInt(5);
                logger.info(""indexing {} docs per indexer during partition"", docsPerIndexer);
                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()));
                Collections.shuffle(semaphores, random());
                for (Semaphore semaphore : semaphores) {
                    assertThat(semaphore.availablePermits(), equalTo(0));
                    semaphore.release(docsPerIndexer);
                }
                logger.info(""waiting for indexing requests to complete"");
                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS));

                logger.info(""stopping disruption"");
                disruptionScheme.stopDisrupting();
                for (String node : internalCluster().getNodeNames()) {
                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +
                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node);
                }
                // in case of a bridge partition, shard allocation can fail ""index.allocation.max_retries"" times if the master
                // is the super-connected node and recovery source and target are on opposite sides of the bridge
                if (disruptionScheme instanceof NetworkDisruption &&
                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {
                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true));
                }
                ensureGreen(""test"");

                logger.info(""validating successful docs"");
                assertBusy(() -> {
                    for (String node : nodes) {
                        try {
                            logger.debug(""validating through node [{}] ([{}] acked docs)"", node, ackedDocs.size());
                            for (String id : ackedDocs.keySet()) {
                                assertTrue(""doc ["" + id + ""] indexed via node ["" + ackedDocs.get(id) + ""] not found"",
                                    client(node).prepareGet(""test"", ""type"", id).setPreference(""_local"").get().isExists());
                            }
                        } catch (AssertionError | NoShardAvailableActionException e) {
                            throw new AssertionError(e.getMessage() + "" (checked via node ["" + node + ""]"", e);
                        }
                    }
                }, 30, TimeUnit.SECONDS);

                logger.info(""done validating (iteration [{}])"", iter);
            }
        } finally {
            if (exceptedExceptions.size() > 0) {
                StringBuilder sb = new StringBuilder();
                for (Exception e : exceptedExceptions) {
                    sb.append(""\n"").append(e.getMessage());
                }
                logger.debug(""Indexing exceptions during disruption: {}"", sb);
            }
            logger.info(""shutting down indexers"");
            stop.set(true);
            for (Thread indexer : indexers) {
                indexer.interrupt();
                indexer.join(60000);
            }
        }
    }
",non-flaky,5
91470,strapdata_elassandra,MasterServiceTests.execute,"    @TestLogging(""org.elasticsearch.cluster.service:TRACE"") // To ensure that we log cluster state events on TRACE level
    public void testClusterStateUpdateLogging() throws Exception {
        MockLogAppender mockAppender = new MockLogAppender();
        mockAppender.start();
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test1"",
                masterService.getClass().getCanonicalName(),
                Level.DEBUG,
                ""*processing [test1]: took [1s] no change in cluster state""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test2"",
                masterService.getClass().getCanonicalName(),
                Level.TRACE,
                ""*failed to execute cluster state update in [2s]*""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test3"",
                masterService.getClass().getCanonicalName(),
                Level.DEBUG,
                ""*processing [test3]: took [3s] done publishing updated cluster state (version: *, uuid: *)""));

        Logger clusterLogger = Loggers.getLogger(masterService.getClass().getPackage().getName());
        Loggers.addAppender(clusterLogger, mockAppender);
        try {
            final CountDownLatch latch = new CountDownLatch(4);
            masterService.currentTimeOverride = System.nanoTime();
            masterService.submitStateUpdateTask(""test1"", new ClusterStateUpdateTask() {
                @Override
                public ClusterState execute(ClusterState currentState) throws Exception {
                    masterService.currentTimeOverride += TimeValue.timeValueSeconds(1).nanos();
                    return currentState;
                }
",non-flaky,5
91471,strapdata_elassandra,MasterServiceTests.execute,"    @TestLogging(""org.elasticsearch.cluster.service:WARN"") // To ensure that we log cluster state events on WARN level
    public void testLongClusterStateUpdateLogging() throws Exception {
        MockLogAppender mockAppender = new MockLogAppender();
        mockAppender.start();
        mockAppender.addExpectation(
            new MockLogAppender.UnseenEventExpectation(
                ""test1 shouldn't see because setting is too low"",
                masterService.getClass().getCanonicalName(),
                Level.WARN,
                ""*cluster state update task [test1] took [*] above the warn threshold of *""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test2"",
                masterService.getClass().getCanonicalName(),
                Level.WARN,
                ""*cluster state update task [test2] took [32s] above the warn threshold of *""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test3"",
                masterService.getClass().getCanonicalName(),
                Level.WARN,
                ""*cluster state update task [test3] took [33s] above the warn threshold of *""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test4"",
                masterService.getClass().getCanonicalName(),
                Level.WARN,
                ""*cluster state update task [test4] took [34s] above the warn threshold of *""));

        Logger clusterLogger = Loggers.getLogger(masterService.getClass().getPackage().getName());
        Loggers.addAppender(clusterLogger, mockAppender);
        try {
            final CountDownLatch latch = new CountDownLatch(5);
            final CountDownLatch processedFirstTask = new CountDownLatch(1);
            masterService.currentTimeOverride = System.nanoTime();
            masterService.submitStateUpdateTask(""test1"", new ClusterStateUpdateTask() {
                @Override
                public ClusterState execute(ClusterState currentState) throws Exception {
                    masterService.currentTimeOverride += TimeValue.timeValueSeconds(1).nanos();
                    return currentState;
                }
",non-flaky,5
91472,strapdata_elassandra,ClusterApplierServiceTests.onSuccess,"    @TestLogging(""org.elasticsearch.cluster.service:TRACE"") // To ensure that we log cluster state events on TRACE level
    public void testClusterStateUpdateLogging() throws Exception {
        MockLogAppender mockAppender = new MockLogAppender();
        mockAppender.start();
        mockAppender.addExpectation(
                new MockLogAppender.SeenEventExpectation(
                        ""test1"",
                        clusterApplierService.getClass().getCanonicalName(),
                        Level.DEBUG,
                        ""*processing [test1]: took [1s] no change in cluster state""));
        mockAppender.addExpectation(
                new MockLogAppender.SeenEventExpectation(
                        ""test2"",
                        clusterApplierService.getClass().getCanonicalName(),
                        Level.TRACE,
                        ""*failed to execute cluster state applier in [2s]*""));

        Logger clusterLogger = Loggers.getLogger(""org.elasticsearch.cluster.service"");
        Loggers.addAppender(clusterLogger, mockAppender);
        try {
            final CountDownLatch latch = new CountDownLatch(3);
            clusterApplierService.currentTimeOverride = System.nanoTime();
            clusterApplierService.runOnApplierThread(""test1"",
                currentState -> clusterApplierService.currentTimeOverride += TimeValue.timeValueSeconds(1).nanos(),
                new ClusterApplyListener() {
                    @Override
                    public void onSuccess(String source) {
                        latch.countDown();
                    }
",non-flaky,5
91473,strapdata_elassandra,ClusterApplierServiceTests.onSuccess,"    @TestLogging(""org.elasticsearch.cluster.service:WARN"") // To ensure that we log cluster state events on WARN level
    public void testLongClusterStateUpdateLogging() throws Exception {
        MockLogAppender mockAppender = new MockLogAppender();
        mockAppender.start();
        mockAppender.addExpectation(
                new MockLogAppender.UnseenEventExpectation(
                        ""test1 shouldn't see because setting is too low"",
                        clusterApplierService.getClass().getCanonicalName(),
                        Level.WARN,
                        ""*cluster state applier task [test1] took [*] above the warn threshold of *""));
        mockAppender.addExpectation(
                new MockLogAppender.SeenEventExpectation(
                        ""test2"",
                        clusterApplierService.getClass().getCanonicalName(),
                        Level.WARN,
                        ""*cluster state applier task [test2] took [32s] above the warn threshold of *""));
        mockAppender.addExpectation(
                new MockLogAppender.SeenEventExpectation(
                        ""test4"",
                        clusterApplierService.getClass().getCanonicalName(),
                        Level.WARN,
                        ""*cluster state applier task [test3] took [34s] above the warn threshold of *""));

        Logger clusterLogger = Loggers.getLogger(""org.elasticsearch.cluster.service"");
        Loggers.addAppender(clusterLogger, mockAppender);
        try {
            final CountDownLatch latch = new CountDownLatch(4);
            final CountDownLatch processedFirstTask = new CountDownLatch(1);
            clusterApplierService.currentTimeOverride = System.nanoTime();
            clusterApplierService.runOnApplierThread(""test1"",
                currentState -> clusterApplierService.currentTimeOverride += TimeValue.timeValueSeconds(1).nanos(),
                new ClusterApplyListener() {
                    @Override
                    public void onSuccess(String source) {
                        latch.countDown();
                        processedFirstTask.countDown();
                    }
",non-flaky,5
91474,strapdata_elassandra,ClusterServiceIT.execute,"    @TestLogging(""_root:debug,org.elasticsearch.action.admin.cluster.tasks:trace"")
    public void testPendingUpdateTask() throws Exception {
        String node_0 = internalCluster().startNode();
        internalCluster().startCoordinatingOnlyNode(Settings.EMPTY);

        final ClusterService clusterService = internalCluster().getInstance(ClusterService.class, node_0);
        final CountDownLatch block1 = new CountDownLatch(1);
        final CountDownLatch invoked1 = new CountDownLatch(1);
        clusterService.submitStateUpdateTask(""1"", new ClusterStateUpdateTask() {
            @Override
            public ClusterState execute(ClusterState currentState) {
                invoked1.countDown();
                try {
                    block1.await();
                } catch (InterruptedException e) {
                    fail();
                }
                return currentState;
            }
",non-flaky,5
91475,strapdata_elassandra,SpecificMasterNodesIT.testSimpleOnlyMasterNodeElection,"@TestLogging(""_root:DEBUG,org.elasticsearch.action.admin.cluster.state:TRACE"")
    public void testSimpleOnlyMasterNodeElection() throws IOException {
        logger.info(""--> start data node / non master node"");
        internalCluster().startNode(Settings.builder().put(Node.NODE_DATA_SETTING.getKey(), true).put(Node.NODE_MASTER_SETTING.getKey(), false)
            .put(""discovery.initial_state_timeout"", ""1s""));
        try {
            assertThat(client().admin().cluster().prepareState().setMasterNodeTimeout(""100ms"").execute().actionGet().getState().nodes().getMasterNodeId(), nullValue());
            fail(""should not be able to find master"");
        } catch (MasterNotDiscoveredException e) {
            // all is well, no master elected
        }
        logger.info(""--> start master node"");
        final String masterNodeName = internalCluster().startNode(Settings.builder().put(Node.NODE_DATA_SETTING.getKey(), false).put(Node.NODE_MASTER_SETTING.getKey(), true));
        assertThat(internalCluster().nonMasterClient().admin().cluster().prepareState().execute().actionGet().getState().nodes().getMasterNode().getName(), equalTo(masterNodeName));
        assertThat(internalCluster().masterClient().admin().cluster().prepareState().execute().actionGet().getState().nodes().getMasterNode().getName(), equalTo(masterNodeName));

        logger.info(""--> stop master node"");
        internalCluster().stopCurrentMasterNode();

        try {
            assertThat(client().admin().cluster().prepareState().setMasterNodeTimeout(""100ms"").execute().actionGet().getState().nodes().getMasterNodeId(), nullValue());
            fail(""should not be able to find master"");
        } catch (MasterNotDiscoveredException e) {
            // all is well, no master elected
        }

        logger.info(""--> start master node"");
        final String nextMasterEligibleNodeName = internalCluster().startNode(Settings.builder().put(Node.NODE_DATA_SETTING.getKey(), false).put(Node.NODE_MASTER_SETTING.getKey(), true));
        assertThat(internalCluster().nonMasterClient().admin().cluster().prepareState().execute().actionGet().getState().nodes().getMasterNode().getName(), equalTo(nextMasterEligibleNodeName));
        assertThat(internalCluster().masterClient().admin().cluster().prepareState().execute().actionGet().getState().nodes().getMasterNode().getName(), equalTo(nextMasterEligibleNodeName));
    }
",non-flaky,5
91476,strapdata_elassandra,MinimumMasterNodesIT.testSimpleMinimumMasterNodes,"@TestLogging(""_root:DEBUG,org.elasticsearch.cluster.service:TRACE,org.elasticsearch.discovery.zen:TRACE"")
    public void testSimpleMinimumMasterNodes() throws Exception {

        Settings settings = Settings.builder()
                .put(""discovery.zen.minimum_master_nodes"", 2)
                .put(ZenDiscovery.PING_TIMEOUT_SETTING.getKey(), ""200ms"")
                .put(""discovery.initial_state_timeout"", ""500ms"")
                .build();

        logger.info(""--> start first node"");
        internalCluster().startNode(settings);

        logger.info(""--> should be blocked, no master..."");
        ClusterState state = client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();
        assertThat(state.blocks().hasGlobalBlock(DiscoverySettings.NO_MASTER_BLOCK_ID), equalTo(true));
        assertThat(state.nodes().getSize(), equalTo(1)); // verify that we still see the local node in the cluster state

        logger.info(""--> start second node, cluster should be formed"");
        internalCluster().startNode(settings);

        ClusterHealthResponse clusterHealthResponse = client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForNodes(""2"").execute().actionGet();
        assertThat(clusterHealthResponse.isTimedOut(), equalTo(false));

        state = client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();
        assertThat(state.blocks().hasGlobalBlock(DiscoverySettings.NO_MASTER_BLOCK_ID), equalTo(false));
        state = client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();
        assertThat(state.blocks().hasGlobalBlock(DiscoverySettings.NO_MASTER_BLOCK_ID), equalTo(false));

        state = client().admin().cluster().prepareState().execute().actionGet().getState();
        assertThat(state.nodes().getSize(), equalTo(2));
        assertThat(state.metaData().indices().containsKey(""test""), equalTo(false));

        createIndex(""test"");
        NumShards numShards = getNumShards(""test"");
        logger.info(""--> indexing some data"");
        for (int i = 0; i < 100; i++) {
            client().prepareIndex(""test"", ""type1"", Integer.toString(i)).setSource(""field"", ""value"").execute().actionGet();
        }
        // make sure that all shards recovered before trying to flush
        assertThat(client().admin().cluster().prepareHealth(""test"").setWaitForActiveShards(numShards.totalNumShards).execute().actionGet().getActiveShards(), equalTo(numShards.totalNumShards));
        // flush for simpler debugging
        flushAndRefresh();

        logger.info(""--> verify we the data back"");
        for (int i = 0; i < 10; i++) {
            assertThat(client().prepareSearch().setSize(0).setQuery(QueryBuilders.matchAllQuery()).execute().actionGet().getHits().getTotalHits(), equalTo(100L));
        }

        internalCluster().stopCurrentMasterNode();
        awaitBusy(() -> {
            ClusterState clusterState = client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();
            return clusterState.blocks().hasGlobalBlock(DiscoverySettings.NO_MASTER_BLOCK_ID);
        });
        state = client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();
        assertThat(state.blocks().hasGlobalBlock(DiscoverySettings.NO_MASTER_BLOCK_ID), equalTo(true));
        // verify that both nodes are still in the cluster state but there is no master
        assertThat(state.nodes().getSize(), equalTo(2));
        assertThat(state.nodes().getMasterNode(), equalTo(null));

        logger.info(""--> starting the previous master node again..."");
        internalCluster().startNode(settings);

        clusterHealthResponse = client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForYellowStatus().setWaitForNodes(""2"").execute().actionGet();
        assertThat(clusterHealthResponse.isTimedOut(), equalTo(false));

        state = client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();
        assertThat(state.blocks().hasGlobalBlock(DiscoverySettings.NO_MASTER_BLOCK_ID), equalTo(false));
        state = client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();
        assertThat(state.blocks().hasGlobalBlock(DiscoverySettings.NO_MASTER_BLOCK_ID), equalTo(false));

        state = client().admin().cluster().prepareState().execute().actionGet().getState();
        assertThat(state.nodes().getSize(), equalTo(2));
        assertThat(state.metaData().indices().containsKey(""test""), equalTo(true));

        ensureGreen();

        logger.info(""--> verify we the data back after cluster reform"");
        for (int i = 0; i < 10; i++) {
            assertHitCount(client().prepareSearch().setSize(0).setQuery(QueryBuilders.matchAllQuery()).execute().actionGet(), 100);
        }

        internalCluster().stopRandomNonMasterNode();
        assertBusy(() -> {
            ClusterState state1 = client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();
            assertThat(state1.blocks().hasGlobalBlock(DiscoverySettings.NO_MASTER_BLOCK_ID), equalTo(true));
        });

        logger.info(""--> starting the previous master node again..."");
        internalCluster().startNode(settings);

        ensureGreen();
        clusterHealthResponse = client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForNodes(""2"").setWaitForGreenStatus().execute().actionGet();
        assertThat(clusterHealthResponse.isTimedOut(), equalTo(false));

        state = client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();
        assertThat(state.blocks().hasGlobalBlock(DiscoverySettings.NO_MASTER_BLOCK_ID), equalTo(false));
        state = client().admin().cluster().prepareState().setLocal(true).execute().actionGet().getState();
        assertThat(state.blocks().hasGlobalBlock(DiscoverySettings.NO_MASTER_BLOCK_ID), equalTo(false));

        state = client().admin().cluster().prepareState().execute().actionGet().getState();
        assertThat(state.nodes().getSize(), equalTo(2));
        assertThat(state.metaData().indices().containsKey(""test""), equalTo(true));

        logger.info(""Running Cluster Health"");
        ensureGreen();

        logger.info(""--> verify we the data back"");
        for (int i = 0; i < 10; i++) {
            assertHitCount(client().prepareSearch().setSize(0).setQuery(QueryBuilders.matchAllQuery()).execute().actionGet(), 100);
        }
    }
",non-flaky,5
91477,strapdata_elassandra,PrimaryAllocationIT.testPrimaryReplicaResyncFailed,"    @TestLogging(""_root:DEBUG, org.elasticsearch.cluster.routing.allocation:TRACE, org.elasticsearch.cluster.action.shard:TRACE,"" +
    public void testPrimaryReplicaResyncFailed() throws Exception {
        String master = internalCluster().startMasterOnlyNode(Settings.EMPTY);
        final int numberOfReplicas = between(2, 3);
        final String oldPrimary = internalCluster().startDataOnlyNode();
        assertAcked(
            prepareCreate(""test"", Settings.builder().put(indexSettings())
                .put(SETTING_NUMBER_OF_SHARDS, 1)
                .put(SETTING_NUMBER_OF_REPLICAS, numberOfReplicas)));
        final ShardId shardId = new ShardId(clusterService().state().metaData().index(""test"").getIndex(), 0);
        final Set<String> replicaNodes = new HashSet<>(internalCluster().startDataOnlyNodes(numberOfReplicas));
        ensureGreen();
        assertAcked(
            client(master).admin().cluster().prepareUpdateSettings()
                .setTransientSettings(Settings.builder().put(""cluster.routing.allocation.enable"", ""none"")).get());
        logger.info(""--> Indexing with gap in seqno to ensure that some operations will be replayed in resync"");
        long numDocs = scaledRandomIntBetween(5, 50);
        for (int i = 0; i < numDocs; i++) {
            IndexResponse indexResult = index(""test"", ""doc"", Long.toString(i));
            assertThat(indexResult.getShardInfo().getSuccessful(), equalTo(numberOfReplicas + 1));
        }
        final IndexShard oldPrimaryShard = internalCluster().getInstance(IndicesService.class, oldPrimary).getShardOrNull(shardId);
        EngineTestCase.generateNewSeqNo(IndexShardTestCase.getEngine(oldPrimaryShard)); // Make gap in seqno.
        long moreDocs = scaledRandomIntBetween(1, 10);
        for (int i = 0; i < moreDocs; i++) {
            IndexResponse indexResult = index(""test"", ""doc"", Long.toString(numDocs + i));
            assertThat(indexResult.getShardInfo().getSuccessful(), equalTo(numberOfReplicas + 1));
        }
        final Set<String> replicasSide1 = Sets.newHashSet(randomSubsetOf(between(1, numberOfReplicas - 1), replicaNodes));
        final Set<String> replicasSide2 = Sets.difference(replicaNodes, replicasSide1);
        NetworkDisruption partition = new NetworkDisruption(new TwoPartitions(replicasSide1, replicasSide2), new NetworkDisconnect());
        internalCluster().setDisruptionScheme(partition);
        logger.info(""--> isolating some replicas during primary-replica resync"");
        partition.startDisrupting();
        internalCluster().stopRandomNode(InternalTestCluster.nameFilter(oldPrimary));
        // Checks that we fails replicas in one side but not mark them as stale.
        assertBusy(() -> {
            ClusterState state = client(master).admin().cluster().prepareState().get().getState();
            final IndexShardRoutingTable shardRoutingTable = state.routingTable().shardRoutingTable(shardId);
            final String newPrimaryNode = state.getRoutingNodes().node(shardRoutingTable.primary.currentNodeId()).node().getName();
            assertThat(newPrimaryNode, not(equalTo(oldPrimary)));
            Set<String> selectedPartition = replicasSide1.contains(newPrimaryNode) ? replicasSide1 : replicasSide2;
            assertThat(shardRoutingTable.activeShards(), hasSize(selectedPartition.size()));
            for (ShardRouting activeShard : shardRoutingTable.activeShards()) {
                assertThat(state.getRoutingNodes().node(activeShard.currentNodeId()).node().getName(), isIn(selectedPartition));
            }
            assertThat(state.metaData().index(""test"").inSyncAllocationIds(shardId.id()), hasSize(numberOfReplicas + 1));
        }, 1, TimeUnit.MINUTES);
        assertAcked(
            client(master).admin().cluster().prepareUpdateSettings()
                .setTransientSettings(Settings.builder().put(""cluster.routing.allocation.enable"", ""all"")).get());
        partition.stopDisrupting();
        partition.ensureHealthy(internalCluster());
        logger.info(""--> stop disrupting network and re-enable allocation"");
        assertBusy(() -> {
            ClusterState state = client(master).admin().cluster().prepareState().get().getState();
            assertThat(state.routingTable().shardRoutingTable(shardId).activeShards(), hasSize(numberOfReplicas));
            assertThat(state.metaData().index(""test"").inSyncAllocationIds(shardId.id()), hasSize(numberOfReplicas + 1));
            for (String node : replicaNodes) {
                IndexShard shard = internalCluster().getInstance(IndicesService.class, node).getShardOrNull(shardId);
                assertThat(shard.getLocalCheckpoint(), equalTo(numDocs + moreDocs));
            }
        }, 30, TimeUnit.SECONDS);
        internalCluster().assertConsistentHistoryBetweenTranslogAndLuceneIndex();
    }
",non-flaky,5
91478,strapdata_elassandra,PersistentTasksExecutorFullRestartIT.testFullClusterRestart,"    @TestLogging(""org.elasticsearch.persistent:TRACE,org.elasticsearch.cluster.service:DEBUG"")
    public void testFullClusterRestart() throws Exception {
        PersistentTasksService service = internalCluster().getInstance(PersistentTasksService.class);
        int numberOfTasks = randomIntBetween(1, 10);
        String[] taskIds = new String[numberOfTasks];
        List<PlainActionFuture<PersistentTask<TestParams>>> futures = new ArrayList<>(numberOfTasks);

        for (int i = 0; i < numberOfTasks; i++) {
            PlainActionFuture<PersistentTask<TestParams>> future = new PlainActionFuture<>();
            futures.add(future);
            taskIds[i] = UUIDs.base64UUID();
            service.sendStartRequest(taskIds[i], TestPersistentTasksExecutor.NAME, new TestParams(""Blah""), future);
        }

        for (int i = 0; i < numberOfTasks; i++) {
            assertThat(futures.get(i).get().getId(), equalTo(taskIds[i]));
        }

        PersistentTasksCustomMetaData tasksInProgress = internalCluster().clusterService().state().getMetaData()
                .custom(PersistentTasksCustomMetaData.TYPE);
        assertThat(tasksInProgress.tasks().size(), equalTo(numberOfTasks));

        // Make sure that at least one of the tasks is running
        assertBusy(() -> {
            // Wait for the task to start
            assertThat(client().admin().cluster().prepareListTasks().setActions(TestPersistentTasksExecutor.NAME + ""[c]"").get()
                    .getTasks().size(), greaterThan(0));
        });

        // Restart cluster
        internalCluster().fullRestart();
        ensureYellow();

        tasksInProgress = internalCluster().clusterService().state().getMetaData().custom(PersistentTasksCustomMetaData.TYPE);
        assertThat(tasksInProgress.tasks().size(), equalTo(numberOfTasks));
        // Check that cluster state is correct
        for (int i = 0; i < numberOfTasks; i++) {
            PersistentTask<?> task = tasksInProgress.getTask(taskIds[i]);
            assertNotNull(task);
        }

        logger.info(""Waiting for {} tasks to start"", numberOfTasks);
        assertBusy(() -> {
            // Wait for all tasks to start
            assertThat(client().admin().cluster().prepareListTasks().setActions(TestPersistentTasksExecutor.NAME + ""[c]"").get()
                            .getTasks().size(), equalTo(numberOfTasks));
        });

        logger.info(""Complete all tasks"");
        // Complete the running task and make sure it finishes properly
        assertThat(new TestPersistentTasksPlugin.TestTasksRequestBuilder(client()).setOperation(""finish"").get().getTasks().size(),
                equalTo(numberOfTasks));

        assertBusy(() -> {
            // Make sure the task is removed from the cluster state
            assertThat(((PersistentTasksCustomMetaData) internalCluster().clusterService().state().getMetaData()
                    .custom(PersistentTasksCustomMetaData.TYPE)).tasks(), empty());
        });

    }
",non-flaky,5
91479,strapdata_elassandra,SearchWhileCreatingIndexIT.testIndexCausesIndexCreation,"@TestLogging(""_root:DEBUG"")
    public void testIndexCausesIndexCreation() throws Exception {
        searchWhileCreatingIndex(false, 1); // 1 replica in our default...
    }
",non-flaky,5
91480,strapdata_elassandra,SharedClusterSnapshotRestoreIT.testReadonlyRepository,"    @TestLogging(""_root:DEBUG"")  // this fails every now and then: https://github.com/elastic/elasticsearch/issues/18121 but without
    public void testReadonlyRepository() throws Exception {
        Client client = client();
        logger.info(""-->  creating repository"");
        Path repositoryLocation = randomRepoPath();
        assertAcked(client.admin().cluster().preparePutRepository(""test-repo"")
                .setType(""fs"").setSettings(Settings.builder()
                        .put(""location"", repositoryLocation)
                        .put(""compress"", randomBoolean())
                        .put(""chunk_size"", randomIntBetween(100, 1000), ByteSizeUnit.BYTES)));

        createIndex(""test-idx"");
        ensureGreen();

        logger.info(""--> indexing some data"");
        for (int i = 0; i < 100; i++) {
            index(""test-idx"", ""_doc"", Integer.toString(i), ""foo"", ""bar"" + i);
        }
        refresh();

        logger.info(""--> snapshot"");
        CreateSnapshotResponse createSnapshotResponse = client.admin().cluster().prepareCreateSnapshot(""test-repo"", ""test-snap"").setWaitForCompletion(true).setIndices(""test-idx"").get();
        assertThat(createSnapshotResponse.getSnapshotInfo().successfulShards(), greaterThan(0));
        assertThat(createSnapshotResponse.getSnapshotInfo().successfulShards(), equalTo(createSnapshotResponse.getSnapshotInfo().totalShards()));

        assertThat(client.admin().cluster().prepareGetSnapshots(""test-repo"").setSnapshots(""test-snap"").get().getSnapshots().get(0).state(), equalTo(SnapshotState.SUCCESS));

        logger.info(""--> delete index"");
        cluster().wipeIndices(""test-idx"");

        logger.info(""--> create read-only URL repository"");
        assertAcked(client.admin().cluster().preparePutRepository(""readonly-repo"")
                .setType(""fs"").setSettings(Settings.builder()
                        .put(""location"", repositoryLocation)
                        .put(""compress"", randomBoolean())
                        .put(""readonly"", true)
                        .put(""chunk_size"", randomIntBetween(100, 1000), ByteSizeUnit.BYTES)));
        logger.info(""--> restore index after deletion"");
        RestoreSnapshotResponse restoreSnapshotResponse = client.admin().cluster().prepareRestoreSnapshot(""readonly-repo"", ""test-snap"").setWaitForCompletion(true).setIndices(""test-idx"").execute().actionGet();
        assertThat(restoreSnapshotResponse.getRestoreInfo().totalShards(), greaterThan(0));

        assertThat(client.prepareSearch(""test-idx"").setSize(0).get().getHits().getTotalHits(), equalTo(100L));

        logger.info(""--> list available shapshots"");
        GetSnapshotsResponse getSnapshotsResponse = client.admin().cluster().prepareGetSnapshots(""readonly-repo"").get();
        assertThat(getSnapshotsResponse.getSnapshots(), notNullValue());
        assertThat(getSnapshotsResponse.getSnapshots().size(), equalTo(1));

        logger.info(""--> try deleting snapshot"");
        assertThrows(client.admin().cluster().prepareDeleteSnapshot(""readonly-repo"", ""test-snap""), RepositoryException.class, ""cannot delete snapshot from a readonly repository"");

        logger.info(""--> try making another snapshot"");
        assertThrows(client.admin().cluster().prepareCreateSnapshot(""readonly-repo"", ""test-snap-2"").setWaitForCompletion(true).setIndices(""test-idx""), RepositoryException.class, ""cannot create snapshot in a readonly repository"");
    }
",non-flaky,5
91481,strapdata_elassandra,SharedClusterSnapshotRestoreIT.testAbortedSnapshotDuringInitDoesNotStart,"    @TestLogging(""org.elasticsearch.snapshots:TRACE"")
    public void testAbortedSnapshotDuringInitDoesNotStart() throws Exception {
        final Client client = client();

        // Blocks on initialization
        assertAcked(client.admin().cluster().preparePutRepository(""repository"")
            .setType(""mock"").setSettings(Settings.builder()
                .put(""location"", randomRepoPath())
                .put(""block_on_init"", true)
            ));

        createIndex(""test-idx"");
        final int nbDocs = scaledRandomIntBetween(100, 500);
        for (int i = 0; i < nbDocs; i++) {
            index(""test-idx"", ""_doc"", Integer.toString(i), ""foo"", ""bar"" + i);
        }
        flushAndRefresh(""test-idx"");
        assertThat(client.prepareSearch(""test-idx"").setSize(0).get().getHits().getTotalHits(), equalTo((long) nbDocs));

        // Create a snapshot
        client.admin().cluster().prepareCreateSnapshot(""repository"", ""snap"").execute();
        waitForBlock(internalCluster().getMasterName(), ""repository"", TimeValue.timeValueMinutes(1));
        boolean blocked = true;

        // Snapshot is initializing (and is blocked at this stage)
        SnapshotsStatusResponse snapshotsStatus = client.admin().cluster().prepareSnapshotStatus(""repository"").setSnapshots(""snap"").get();
        assertThat(snapshotsStatus.getSnapshots().iterator().next().getState(), equalTo(State.INIT));

        final List<State> states = new CopyOnWriteArrayList<>();
        final ClusterStateListener listener = event -> {
            SnapshotsInProgress snapshotsInProgress = event.state().custom(SnapshotsInProgress.TYPE);
            for (SnapshotsInProgress.Entry entry : snapshotsInProgress.entries()) {
                if (""snap"".equals(entry.snapshot().getSnapshotId().getName())) {
                    states.add(entry.state());
                }
            }
        };

        try {
            // Record the upcoming states of the snapshot on all nodes
            internalCluster().getInstances(ClusterService.class).forEach(clusterService -> clusterService.addListener(listener));

            // Delete the snapshot while it is being initialized
            ActionFuture<AcknowledgedResponse> delete = client.admin().cluster().prepareDeleteSnapshot(""repository"", ""snap"").execute();

            // The deletion must set the snapshot in the ABORTED state
            assertBusy(() -> {
                SnapshotsStatusResponse status = client.admin().cluster().prepareSnapshotStatus(""repository"").setSnapshots(""snap"").get();
                assertThat(status.getSnapshots().iterator().next().getState(), equalTo(State.ABORTED));
            });

            // Now unblock the repository
            unblockNode(""repository"", internalCluster().getMasterName());
            blocked = false;

            assertAcked(delete.get());
            expectThrows(SnapshotMissingException.class, () ->
                client.admin().cluster().prepareGetSnapshots(""repository"").setSnapshots(""snap"").get());

            assertFalse(""Expecting snapshot state to be updated"", states.isEmpty());
            assertFalse(""Expecting snapshot to be aborted and not started at all"", states.contains(State.STARTED));
        } finally {
            internalCluster().getInstances(ClusterService.class).forEach(clusterService -> clusterService.removeListener(listener));
            if (blocked) {
                unblockNode(""repository"", internalCluster().getMasterName());
            }
        }
    }
",non-flaky,5
91482,strapdata_elassandra,QueueResizingEsThreadPoolExecutorTests.testAutoQueueSizingWithMax,"    @TestLogging(""org.elasticsearch.common.util.concurrent:DEBUG"")
    public void testAutoQueueSizingWithMax() throws Exception {
        ThreadContext context = new ThreadContext(Settings.EMPTY);
        ResizableBlockingQueue<Runnable> queue =
                new ResizableBlockingQueue<>(ConcurrentCollections.<Runnable>newBlockingQueue(),
                        5000);

        int threads = randomIntBetween(1, 5);
        int measureWindow = randomIntBetween(10, 100);
        int max = randomIntBetween(5010, 5024);
        logger.info(""--> auto-queue with a measurement window of {} tasks"", measureWindow);
        QueueResizingEsThreadPoolExecutor executor =
                new QueueResizingEsThreadPoolExecutor(
                        ""test-threadpool"", threads, threads, 1000,
                        TimeUnit.MILLISECONDS, queue, 10, max, fastWrapper(), measureWindow, TimeValue.timeValueMillis(1),
                        EsExecutors.daemonThreadFactory(""queuetest""), new EsAbortPolicy(), context);
        executor.prestartAllCoreThreads();
        logger.info(""--> executor: {}"", executor);

        // Execute a task multiple times that takes 1ms
        executeTask(executor, measureWindow * 3);

        // The queue capacity should increase, but no higher than the maximum
        assertBusy(() -> {
            assertThat(queue.capacity(), equalTo(max));
        });
        executor.shutdown();
        executor.awaitTermination(10, TimeUnit.SECONDS);
        context.close();
    }
",non-flaky,5
91483,strapdata_elassandra,IndexActionIT.testAutoGenerateIdNoDuplicates,"    @TestLogging(""_root:DEBUG,org.elasticsearch.index.shard.IndexShard:TRACE,org.elasticsearch.action.search:TRACE"")
    public void testAutoGenerateIdNoDuplicates() throws Exception {
        int numberOfIterations = scaledRandomIntBetween(10, 50);
        for (int i = 0; i < numberOfIterations; i++) {
            Exception firstError = null;
            createIndex(""test"");
            int numOfDocs = randomIntBetween(10, 100);
            logger.info(""indexing [{}] docs"", numOfDocs);
            List<IndexRequestBuilder> builders = new ArrayList<>(numOfDocs);
            for (int j = 0; j < numOfDocs; j++) {
                builders.add(client().prepareIndex(""test"", ""type"").setSource(""field"", ""value_"" + j));
            }
            indexRandom(true, builders);
            logger.info(""verifying indexed content"");
            int numOfChecks = randomIntBetween(8, 12);
            for (int j = 0; j < numOfChecks; j++) {
                try {
                    logger.debug(""running search with all types"");
                    SearchResponse response = client().prepareSearch(""test"").get();
                    if (response.getHits().getTotalHits() != numOfDocs) {
                        final String message = ""Count is "" + response.getHits().getTotalHits() + "" but "" + numOfDocs + "" was expected. ""
                            + ElasticsearchAssertions.formatShardStatus(response);
                        logger.error(""{}. search response: \n{}"", message, response);
                        fail(message);
                    }
                } catch (Exception e) {
                    logger.error(""search for all docs types failed"", e);
                    if (firstError == null) {
                        firstError = e;
                    }
                }
                try {
                    logger.debug(""running search with a specific type"");
                    SearchResponse response = client().prepareSearch(""test"").setTypes(""type"").get();
                    if (response.getHits().getTotalHits() != numOfDocs) {
                        final String message = ""Count is "" + response.getHits().getTotalHits() + "" but "" + numOfDocs + "" was expected. ""
                            + ElasticsearchAssertions.formatShardStatus(response);
                        logger.error(""{}. search response: \n{}"", message, response);
                        fail(message);
                    }
                } catch (Exception e) {
                    logger.error(""search for all docs of a specific type failed"", e);
                    if (firstError == null) {
                        firstError = e;
                    }
                }
            }
            if (firstError != null) {
                fail(firstError.getMessage());
            }
            internalCluster().wipeIndices(""test"");
        }
    }
",non-flaky,5
91484,strapdata_elassandra,IndexingMasterFailoverIT.run,"    @TestLogging(""_root:DEBUG"")
    public void testMasterFailoverDuringIndexingWithMappingChanges() throws Throwable {
        logger.info(""--> start 4 nodes, 3 master, 1 data"");

        final Settings sharedSettings = Settings.builder()
                .put(FaultDetection.PING_TIMEOUT_SETTING.getKey(), ""1s"") // for hitting simulated network failures quickly
                .put(FaultDetection.PING_RETRIES_SETTING.getKey(), ""1"") // for hitting simulated network failures quickly
                .put(""discovery.zen.join_timeout"", ""10s"")  // still long to induce failures but to long so test won't time out
                .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), ""1s"") // <-- for hitting simulated network failures quickly
                .put(ElectMasterService.DISCOVERY_ZEN_MINIMUM_MASTER_NODES_SETTING.getKey(), 2)
                .build();

        internalCluster().startMasterOnlyNodes(3, sharedSettings);

        String dataNode = internalCluster().startDataOnlyNode(sharedSettings);

        logger.info(""--> wait for all nodes to join the cluster"");
        ensureStableCluster(4);

        // We index data with mapping changes into cluster and have master failover at same time
        client().admin().indices().prepareCreate(""myindex"")
                .setSettings(Settings.builder().put(""index.number_of_shards"", 1).put(""index.number_of_replicas"", 0))
                .get();
        ensureGreen(""myindex"");

        final CyclicBarrier barrier = new CyclicBarrier(2);

        Thread indexingThread = new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    barrier.await();
                } catch (InterruptedException e) {
                    logger.warn(""Barrier interrupted"", e);
                    return;
                } catch (BrokenBarrierException e) {
                    logger.warn(""Broken barrier"", e);
                    return;
                }
                for (int i = 0; i < 10; i++) {
                    // index data with mapping changes
                    IndexResponse response = client(dataNode).prepareIndex(""myindex"", ""mytype"").setSource(""field_"" + i, ""val"").get();
                    assertEquals(DocWriteResponse.Result.CREATED, response.getResult());
                }
            }
",non-flaky,5
91485,strapdata_elassandra,IndicesShardStoreRequestIT.testEmpty,"@TestLogging(""_root:DEBUG,org.elasticsearch.action.admin.indices.shards:TRACE,org.elasticsearch.cluster.service:TRACE"")
    public void testEmpty() {
        ensureGreen();
        IndicesShardStoresResponse rsp = client().admin().indices().prepareShardStores().get();
        assertThat(rsp.getStoreStatuses().size(), equalTo(0));
    }
",non-flaky,5
91486,strapdata_elassandra,RemoteClusterConnectionTests.run,"    @TestLogging(""_root:DEBUG, org.elasticsearch.transport:TRACE"")
    public void testCloseWhileConcurrentlyConnecting() throws IOException, InterruptedException, BrokenBarrierException {
        List<DiscoveryNode> knownNodes = new CopyOnWriteArrayList<>();
        try (MockTransportService seedTransport = startTransport(""seed_node"", knownNodes, Version.CURRENT);
             MockTransportService seedTransport1 = startTransport(""seed_node_1"", knownNodes, Version.CURRENT);
             MockTransportService discoverableTransport = startTransport(""discoverable_node"", knownNodes, Version.CURRENT)) {
            DiscoveryNode seedNode = seedTransport.getLocalDiscoNode();
            DiscoveryNode seedNode1 = seedTransport1.getLocalDiscoNode();
            knownNodes.add(seedTransport.getLocalDiscoNode());
            knownNodes.add(discoverableTransport.getLocalDiscoNode());
            knownNodes.add(seedTransport1.getLocalDiscoNode());
            Collections.shuffle(knownNodes, random());
            List<Supplier<DiscoveryNode>> seedNodes = Arrays.asList(() -> seedNode1, () -> seedNode);
            Collections.shuffle(seedNodes, random());

            try (MockTransportService service = MockTransportService.createNewService(Settings.EMPTY, Version.CURRENT, threadPool, null)) {
                service.start();
                service.acceptIncomingRequests();
                try (RemoteClusterConnection connection = new RemoteClusterConnection(Settings.EMPTY, ""test-cluster"",
                    seedNodes, service, service.getConnectionManager(), Integer.MAX_VALUE, n -> true)) {
                    int numThreads = randomIntBetween(4, 10);
                    Thread[] threads = new Thread[numThreads];
                    CyclicBarrier barrier = new CyclicBarrier(numThreads + 1);
                    for (int i = 0; i < threads.length; i++) {
                        final int numConnectionAttempts = randomIntBetween(10, 100);
                        threads[i] = new Thread() {
                            @Override
                            public void run() {
                                try {
                                    barrier.await();
                                    CountDownLatch latch = new CountDownLatch(numConnectionAttempts);
                                    for (int i = 0; i < numConnectionAttempts; i++) {
                                        AtomicReference<Exception> executed = new AtomicReference<>();
                                        ActionListener<Void> listener = ActionListener.wrap(
                                            x -> {
                                                if (executed.compareAndSet(null, new RuntimeException())) {
                                                    latch.countDown();
                                                } else {
                                                    throw new AssertionError(""shit's been called twice"", executed.get());
                                                }
                                            },
                                            x -> {
                                                if (executed.compareAndSet(null, x)) {
                                                    latch.countDown();
                                                } else {
                                                    final String message = x.getMessage();
                                                    if ((executed.get().getClass() == x.getClass()
                                                        && ""operation was cancelled reason [connect handler is closed]"".equals(message)
                                                        && message.equals(executed.get().getMessage())) == false) {
                                                        // we do cancel the operation and that means that if timing allows it, the caller
                                                        // of a blocking call as well as the handler will get the exception from the
                                                        // ExecutionCancelledException concurrently. unless that is the case we fail
                                                        // if we get called more than once!
                                                        AssertionError assertionError = new AssertionError(""shit's been called twice"", x);
                                                        assertionError.addSuppressed(executed.get());
                                                        throw assertionError;
                                                    }
                                                }
                                                if (x instanceof RejectedExecutionException || x instanceof AlreadyClosedException
                                                    || x instanceof CancellableThreads.ExecutionCancelledException) {
                                                    // that's fine
                                                } else {
                                                    throw new AssertionError(x);
                                                }
                                            });
                                        try {
                                            connection.updateSeedNodes(null, seedNodes, listener);
                                        } catch (Exception e) {
                                            // it's ok if we're shutting down
                                            assertThat(e.getMessage(), containsString(""threadcontext is already closed""));
                                            latch.countDown();
                                        }
                                    }
                                    latch.await();
                                } catch (Exception ex) {
                                    throw new AssertionError(ex);
                                }
                            }
",non-flaky,5
91487,strapdata_elassandra,IndexPrimaryRelocationIT.run,"    @TestLogging(""_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.index.shard:TRACE,org.elasticsearch.cluster.service:TRACE"")
    public void testPrimaryRelocationWhileIndexing() throws Exception {
        internalCluster().ensureAtLeastNumDataNodes(randomIntBetween(2, 3));
        client().admin().indices().prepareCreate(""test"")
            .setSettings(Settings.builder().put(""index.number_of_shards"", 1).put(""index.number_of_replicas"", 0))
            .addMapping(""type"", ""field"", ""type=text"")
            .get();
        ensureGreen(""test"");
        AtomicInteger numAutoGenDocs = new AtomicInteger();
        final AtomicBoolean finished = new AtomicBoolean(false);
        Thread indexingThread = new Thread() {
            @Override
            public void run() {
                while (finished.get() == false) {
                    IndexResponse indexResponse = client().prepareIndex(""test"", ""type"", ""id"").setSource(""field"", ""value"").get();
                    assertEquals(DocWriteResponse.Result.CREATED, indexResponse.getResult());
                    DeleteResponse deleteResponse = client().prepareDelete(""test"", ""type"", ""id"").get();
                    assertEquals(DocWriteResponse.Result.DELETED, deleteResponse.getResult());
                    client().prepareIndex(""test"", ""type"").setSource(""auto"", true).get();
                    numAutoGenDocs.incrementAndGet();
                }
            }
",non-flaky,5
91488,strapdata_elassandra,IndexRecoveryIT.testRerouteRecovery,"    @TestLogging(
    public void testRerouteRecovery() throws Exception {
        logger.info(""--> start node A"");
        final String nodeA = internalCluster().startNode();

        logger.info(""--> create index on node: {}"", nodeA);
        ByteSizeValue shardSize = createAndPopulateIndex(INDEX_NAME, 1, SHARD_COUNT, REPLICA_COUNT).getShards()[0].getStats().getStore().size();

        logger.info(""--> start node B"");
        final String nodeB = internalCluster().startNode();

        ensureGreen();

        logger.info(""--> slowing down recoveries"");
        slowDownRecovery(shardSize);

        logger.info(""--> move shard from: {} to: {}"", nodeA, nodeB);
        client().admin().cluster().prepareReroute()
                .add(new MoveAllocationCommand(INDEX_NAME, 0, nodeA, nodeB))
                .execute().actionGet().getState();

        logger.info(""--> waiting for recovery to start both on source and target"");
        final Index index = resolveIndex(INDEX_NAME);
        assertBusy(() -> {
            IndicesService indicesService = internalCluster().getInstance(IndicesService.class, nodeA);
            assertThat(indicesService.indexServiceSafe(index).getShard(0).recoveryStats().currentAsSource(),
                    equalTo(1));
            indicesService = internalCluster().getInstance(IndicesService.class, nodeB);
            assertThat(indicesService.indexServiceSafe(index).getShard(0).recoveryStats().currentAsTarget(),
                    equalTo(1));
        });

        logger.info(""--> request recoveries"");
        RecoveryResponse response = client().admin().indices().prepareRecoveries(INDEX_NAME).execute().actionGet();

        List<RecoveryState> recoveryStates = response.shardRecoveryStates().get(INDEX_NAME);
        List<RecoveryState> nodeARecoveryStates = findRecoveriesForTargetNode(nodeA, recoveryStates);
        assertThat(nodeARecoveryStates.size(), equalTo(1));
        List<RecoveryState> nodeBRecoveryStates = findRecoveriesForTargetNode(nodeB, recoveryStates);
        assertThat(nodeBRecoveryStates.size(), equalTo(1));

        assertRecoveryState(nodeARecoveryStates.get(0), 0, RecoverySource.EmptyStoreRecoverySource.INSTANCE, true, Stage.DONE, null, nodeA);
        validateIndexRecoveryState(nodeARecoveryStates.get(0).getIndex());

        assertOnGoingRecoveryState(nodeBRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, true, nodeA, nodeB);
        validateIndexRecoveryState(nodeBRecoveryStates.get(0).getIndex());

        logger.info(""--> request node recovery stats"");
        NodesStatsResponse statsResponse = client().admin().cluster().prepareNodesStats().clear().setIndices(new CommonStatsFlags(CommonStatsFlags.Flag.Recovery)).get();
        long nodeAThrottling = Long.MAX_VALUE;
        long nodeBThrottling = Long.MAX_VALUE;
        for (NodeStats nodeStats : statsResponse.getNodes()) {
            final RecoveryStats recoveryStats = nodeStats.getIndices().getRecoveryStats();
            if (nodeStats.getNode().getName().equals(nodeA)) {
                assertThat(""node A should have ongoing recovery as source"", recoveryStats.currentAsSource(), equalTo(1));
                assertThat(""node A should not have ongoing recovery as target"", recoveryStats.currentAsTarget(), equalTo(0));
                nodeAThrottling = recoveryStats.throttleTime().millis();
            }
            if (nodeStats.getNode().getName().equals(nodeB)) {
                assertThat(""node B should not have ongoing recovery as source"", recoveryStats.currentAsSource(), equalTo(0));
                assertThat(""node B should have ongoing recovery as target"", recoveryStats.currentAsTarget(), equalTo(1));
                nodeBThrottling = recoveryStats.throttleTime().millis();
            }
        }

        logger.info(""--> checking throttling increases"");
        final long finalNodeAThrottling = nodeAThrottling;
        final long finalNodeBThrottling = nodeBThrottling;
        assertBusy(() -> {
            NodesStatsResponse statsResponse1 = client().admin().cluster().prepareNodesStats().clear().setIndices(new CommonStatsFlags(CommonStatsFlags.Flag.Recovery)).get();
            assertThat(statsResponse1.getNodes(), hasSize(2));
            for (NodeStats nodeStats : statsResponse1.getNodes()) {
                final RecoveryStats recoveryStats = nodeStats.getIndices().getRecoveryStats();
                if (nodeStats.getNode().getName().equals(nodeA)) {
                    assertThat(""node A throttling should increase"", recoveryStats.throttleTime().millis(), greaterThan(finalNodeAThrottling));
                }
                if (nodeStats.getNode().getName().equals(nodeB)) {
                    assertThat(""node B throttling should increase"", recoveryStats.throttleTime().millis(), greaterThan(finalNodeBThrottling));
                }
            }
        });


        logger.info(""--> speeding up recoveries"");
        restoreRecoverySpeed();

        // wait for it to be finished
        ensureGreen();

        response = client().admin().indices().prepareRecoveries(INDEX_NAME).execute().actionGet();

        recoveryStates = response.shardRecoveryStates().get(INDEX_NAME);
        assertThat(recoveryStates.size(), equalTo(1));

        assertRecoveryState(recoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, true, Stage.DONE, nodeA, nodeB);
        validateIndexRecoveryState(recoveryStates.get(0).getIndex());
        Consumer<String> assertNodeHasThrottleTimeAndNoRecoveries = nodeName ->  {
            NodesStatsResponse nodesStatsResponse = client().admin().cluster().prepareNodesStats().setNodesIds(nodeName)
                .clear().setIndices(new CommonStatsFlags(CommonStatsFlags.Flag.Recovery)).get();
            assertThat(nodesStatsResponse.getNodes(), hasSize(1));
            NodeStats nodeStats = nodesStatsResponse.getNodes().get(0);
            final RecoveryStats recoveryStats = nodeStats.getIndices().getRecoveryStats();
            assertThat(recoveryStats.currentAsSource(), equalTo(0));
            assertThat(recoveryStats.currentAsTarget(), equalTo(0));
            assertThat(nodeName + "" throttling should be >0"", recoveryStats.throttleTime().millis(), greaterThan(0L));
        };
        // we have to use assertBusy as recovery counters are decremented only when the last reference to the RecoveryTarget
        // is decremented, which may happen after the recovery was done.
        assertBusy(() -> assertNodeHasThrottleTimeAndNoRecoveries.accept(nodeA));
        assertBusy(() -> assertNodeHasThrottleTimeAndNoRecoveries.accept(nodeB));

        logger.info(""--> bump replica count"");
        client().admin().indices().prepareUpdateSettings(INDEX_NAME)
                .setSettings(Settings.builder().put(""number_of_replicas"", 1)).execute().actionGet();
        ensureGreen();

        assertBusy(() -> assertNodeHasThrottleTimeAndNoRecoveries.accept(nodeA));
        assertBusy(() -> assertNodeHasThrottleTimeAndNoRecoveries.accept(nodeB));

        logger.info(""--> start node C"");
        String nodeC = internalCluster().startNode();
        assertFalse(client().admin().cluster().prepareHealth().setWaitForNodes(""3"").get().isTimedOut());

        logger.info(""--> slowing down recoveries"");
        slowDownRecovery(shardSize);

        logger.info(""--> move replica shard from: {} to: {}"", nodeA, nodeC);
        client().admin().cluster().prepareReroute()
                .add(new MoveAllocationCommand(INDEX_NAME, 0, nodeA, nodeC))
                .execute().actionGet().getState();

        response = client().admin().indices().prepareRecoveries(INDEX_NAME).execute().actionGet();
        recoveryStates = response.shardRecoveryStates().get(INDEX_NAME);

        nodeARecoveryStates = findRecoveriesForTargetNode(nodeA, recoveryStates);
        assertThat(nodeARecoveryStates.size(), equalTo(1));
        nodeBRecoveryStates = findRecoveriesForTargetNode(nodeB, recoveryStates);
        assertThat(nodeBRecoveryStates.size(), equalTo(1));
        List<RecoveryState> nodeCRecoveryStates = findRecoveriesForTargetNode(nodeC, recoveryStates);
        assertThat(nodeCRecoveryStates.size(), equalTo(1));

        assertRecoveryState(nodeARecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, false, Stage.DONE, nodeB, nodeA);
        validateIndexRecoveryState(nodeARecoveryStates.get(0).getIndex());

        assertRecoveryState(nodeBRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, true, Stage.DONE, nodeA, nodeB);
        validateIndexRecoveryState(nodeBRecoveryStates.get(0).getIndex());

        // relocations of replicas are marked as REPLICA and the source node is the node holding the primary (B)
        assertOnGoingRecoveryState(nodeCRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, false, nodeB, nodeC);
        validateIndexRecoveryState(nodeCRecoveryStates.get(0).getIndex());

        if (randomBoolean()) {
            // shutdown node with relocation source of replica shard and check if recovery continues
            internalCluster().stopRandomNode(InternalTestCluster.nameFilter(nodeA));
            ensureStableCluster(2);

            response = client().admin().indices().prepareRecoveries(INDEX_NAME).execute().actionGet();
            recoveryStates = response.shardRecoveryStates().get(INDEX_NAME);

            nodeARecoveryStates = findRecoveriesForTargetNode(nodeA, recoveryStates);
            assertThat(nodeARecoveryStates.size(), equalTo(0));
            nodeBRecoveryStates = findRecoveriesForTargetNode(nodeB, recoveryStates);
            assertThat(nodeBRecoveryStates.size(), equalTo(1));
            nodeCRecoveryStates = findRecoveriesForTargetNode(nodeC, recoveryStates);
            assertThat(nodeCRecoveryStates.size(), equalTo(1));

            assertRecoveryState(nodeBRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, true, Stage.DONE, nodeA, nodeB);
            validateIndexRecoveryState(nodeBRecoveryStates.get(0).getIndex());

            assertOnGoingRecoveryState(nodeCRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, false, nodeB, nodeC);
            validateIndexRecoveryState(nodeCRecoveryStates.get(0).getIndex());
        }

        logger.info(""--> speeding up recoveries"");
        restoreRecoverySpeed();
        ensureGreen();

        response = client().admin().indices().prepareRecoveries(INDEX_NAME).execute().actionGet();
        recoveryStates = response.shardRecoveryStates().get(INDEX_NAME);

        nodeARecoveryStates = findRecoveriesForTargetNode(nodeA, recoveryStates);
        assertThat(nodeARecoveryStates.size(), equalTo(0));
        nodeBRecoveryStates = findRecoveriesForTargetNode(nodeB, recoveryStates);
        assertThat(nodeBRecoveryStates.size(), equalTo(1));
        nodeCRecoveryStates = findRecoveriesForTargetNode(nodeC, recoveryStates);
        assertThat(nodeCRecoveryStates.size(), equalTo(1));

        assertRecoveryState(nodeBRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, true, Stage.DONE, nodeA, nodeB);
        validateIndexRecoveryState(nodeBRecoveryStates.get(0).getIndex());

        // relocations of replicas are marked as REPLICA and the source node is the node holding the primary (B)
        assertRecoveryState(nodeCRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, false, Stage.DONE, nodeB, nodeC);
        validateIndexRecoveryState(nodeCRecoveryStates.get(0).getIndex());
    }
",non-flaky,5
91489,strapdata_elassandra,IndexRecoveryIT.sendRequest,"    @TestLogging(""_root:DEBUG,org.elasticsearch.indices.recovery:TRACE"")
    public void testDisconnectsDuringRecovery() throws Exception {
        boolean primaryRelocation = randomBoolean();
        final String indexName = ""test"";
        final Settings nodeSettings = Settings.builder()
            .put(RecoverySettings.INDICES_RECOVERY_RETRY_DELAY_NETWORK_SETTING.getKey(), TimeValue.timeValueMillis(randomIntBetween(0, 100)))
            .build();
        TimeValue disconnectAfterDelay = TimeValue.timeValueMillis(randomIntBetween(0, 100));
        // start a master node
        String masterNodeName = internalCluster().startMasterOnlyNode(nodeSettings);

        final String blueNodeName = internalCluster().startNode(Settings.builder().put(""node.attr.color"", ""blue"").put(nodeSettings).build());
        final String redNodeName = internalCluster().startNode(Settings.builder().put(""node.attr.color"", ""red"").put(nodeSettings).build());

        client().admin().indices().prepareCreate(indexName)
            .setSettings(
                Settings.builder()
                    .put(IndexMetaData.INDEX_ROUTING_INCLUDE_GROUP_SETTING.getKey() + ""color"", ""blue"")
                    .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)
                    .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0)
            ).get();

        List<IndexRequestBuilder> requests = new ArrayList<>();
        int numDocs = scaledRandomIntBetween(25, 250);
        for (int i = 0; i < numDocs; i++) {
            requests.add(client().prepareIndex(indexName, ""type"").setSource(""{}"", XContentType.JSON));
        }
        indexRandom(true, requests);
        ensureSearchable(indexName);
        assertHitCount(client().prepareSearch(indexName).get(), numDocs);

        MockTransportService masterTransportService = (MockTransportService) internalCluster().getInstance(TransportService.class, masterNodeName);
        MockTransportService blueMockTransportService = (MockTransportService) internalCluster().getInstance(TransportService.class, blueNodeName);
        MockTransportService redMockTransportService = (MockTransportService) internalCluster().getInstance(TransportService.class, redNodeName);

        redMockTransportService.addSendBehavior(blueMockTransportService, new StubbableTransport.SendRequestBehavior() {
            private final AtomicInteger count = new AtomicInteger();

            @Override
            public void sendRequest(Transport.Connection connection, long requestId, String action, TransportRequest request,
                                    TransportRequestOptions options) throws IOException {
                logger.info(""--> sending request {} on {}"", action, connection.getNode());
                if (PeerRecoverySourceService.Actions.START_RECOVERY.equals(action) && count.incrementAndGet() == 1) {
                    // ensures that it's considered as valid recovery attempt by source
                    try {
                        awaitBusy(() -> client(blueNodeName).admin().cluster().prepareState().setLocal(true).get()
                            .getState().getRoutingTable().index(""test"").shard(0).getAllInitializingShards().isEmpty() == false);
                    } catch (InterruptedException e) {
                        throw new RuntimeException(e);
                    }
                    connection.sendRequest(requestId, action, request, options);
                    try {
                        Thread.sleep(disconnectAfterDelay.millis());
                    } catch (InterruptedException e) {
                        throw new RuntimeException(e);
                    }
                    throw new ConnectTransportException(connection.getNode(), ""DISCONNECT: simulation disconnect after successfully sending "" + action + "" request"");
                } else {
                    connection.sendRequest(requestId, action, request, options);
                }
            }
",non-flaky,5
91490,strapdata_elassandra,RareClusterStateIT.execute,"@TestLogging(""_root:DEBUG"")
    public void testAssignmentWithJustAddedNodes() throws Exception {
        internalCluster().startNode();
        final String index = ""index"";
        prepareCreate(index).setSettings(Settings.builder().put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)
            .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0)).get();
        ensureGreen(index);

        // close to have some unassigned started shards shards..
        client().admin().indices().prepareClose(index).get();


        final String masterName = internalCluster().getMasterName();
        final ClusterService clusterService = internalCluster().clusterService(masterName);
        final AllocationService allocationService = internalCluster().getInstance(AllocationService.class, masterName);
        clusterService.submitStateUpdateTask(""test-inject-node-and-reroute"", new ClusterStateUpdateTask() {
            @Override
            public ClusterState execute(ClusterState currentState) throws Exception {
                // inject a node
                ClusterState.Builder builder = ClusterState.builder(currentState);
                builder.nodes(DiscoveryNodes.builder(currentState.nodes()).add(new DiscoveryNode(""_non_existent"",
                        buildNewFakeTransportAddress(), emptyMap(), emptySet(), Version.CURRENT)));

                // open index
                final IndexMetaData indexMetaData = IndexMetaData.builder(currentState.metaData().index(index)).state(IndexMetaData.State.OPEN).build();

                builder.metaData(MetaData.builder(currentState.metaData()).put(indexMetaData, true));
                builder.blocks(ClusterBlocks.builder().blocks(currentState.blocks()).removeIndexBlocks(index));
                ClusterState updatedState = builder.build();

                RoutingTable.Builder routingTable = RoutingTable.builder(updatedState.routingTable());
                routingTable.addAsRecovery(updatedState.metaData().index(index));
                updatedState = ClusterState.builder(updatedState).routingTable(routingTable.build()).build();

                return allocationService.reroute(updatedState, ""reroute"");

            }
",non-flaky,5
91491,strapdata_elassandra,UpdateByQueryBasicTests.testBasics,"@TestLogging(""org.elasticsearch.index.reindex:TRACE,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.search.SearchService:TRACE"")
    public void testBasics() throws Exception {
        indexRandom(true, client().prepareIndex(""test"", ""test"", ""1"").setSource(""foo"", ""a""),
                client().prepareIndex(""test"", ""test"", ""2"").setSource(""foo"", ""a""),
                client().prepareIndex(""test"", ""test"", ""3"").setSource(""foo"", ""b""),
                client().prepareIndex(""test"", ""test"", ""4"").setSource(""foo"", ""c""));
        assertHitCount(client().prepareSearch(""test"").setTypes(""test"").setSize(0).get(), 4);
        assertEquals(1, client().prepareGet(""test"", ""test"", ""1"").get().getVersion());
        assertEquals(1, client().prepareGet(""test"", ""test"", ""4"").get().getVersion());

        // Reindex all the docs
        assertThat(updateByQuery().source(""test"").refresh(true).get(), matcher().updated(4));
        assertEquals(2, client().prepareGet(""test"", ""test"", ""1"").get().getVersion());
        assertEquals(2, client().prepareGet(""test"", ""test"", ""4"").get().getVersion());

        // Now none of them
        assertThat(updateByQuery().source(""test"").filter(termQuery(""foo"", ""no_match"")).refresh(true).get(), matcher().updated(0));
        assertEquals(2, client().prepareGet(""test"", ""test"", ""1"").get().getVersion());
        assertEquals(2, client().prepareGet(""test"", ""test"", ""4"").get().getVersion());

        // Now half of them
        assertThat(updateByQuery().source(""test"").filter(termQuery(""foo"", ""a"")).refresh(true).get(), matcher().updated(2));
        assertEquals(3, client().prepareGet(""test"", ""test"", ""1"").get().getVersion());
        assertEquals(3, client().prepareGet(""test"", ""test"", ""2"").get().getVersion());
        assertEquals(2, client().prepareGet(""test"", ""test"", ""3"").get().getVersion());
        assertEquals(2, client().prepareGet(""test"", ""test"", ""4"").get().getVersion());

        // Limit with size
        UpdateByQueryRequestBuilder request = updateByQuery().source(""test"").size(3).refresh(true);
        request.source().addSort(""foo.keyword"", SortOrder.ASC);
        assertThat(request.get(), matcher().updated(3));
        // Only the first three documents are updated because of sort
        assertEquals(4, client().prepareGet(""test"", ""test"", ""1"").get().getVersion());
        assertEquals(4, client().prepareGet(""test"", ""test"", ""2"").get().getVersion());
        assertEquals(3, client().prepareGet(""test"", ""test"", ""3"").get().getVersion());
        assertEquals(2, client().prepareGet(""test"", ""test"", ""4"").get().getVersion());
    }
",non-flaky,5
91492,strapdata_elassandra,ReindexFailureTests.testFailuresCauseAbortDefault,"@TestLogging(""_root:DEBUG"")
    public void testFailuresCauseAbortDefault() throws Exception {
        /*
         * Create the destination index such that the copy will cause a mapping
         * conflict on every request.
         */
        indexRandom(true,
                client().prepareIndex(""dest"", ""test"", ""test"").setSource(""test"", 10) /* Its a string in the source! */);

        indexDocs(100);

        ReindexRequestBuilder copy = reindex().source(""source"").destination(""dest"");
        /*
         * Set the search size to something very small to cause there to be
         * multiple batches for this request so we can assert that we abort on
         * the first batch.
         */
        copy.source().setSize(1);

        BulkByScrollResponse response = copy.get();
        assertThat(response, matcher()
                .batches(1)
                .failures(both(greaterThan(0)).and(lessThanOrEqualTo(maximumNumberOfShards()))));
        for (Failure failure: response.getBulkFailures()) {
            assertThat(failure.getMessage(), containsString(""IllegalArgumentException[For input string: \""words words\""]""));
        }
    }
",non-flaky,5
91493,strapdata_elassandra,CancelTests.clearAllowedOperations,"@TestLogging(""org.elasticsearch.index.reindex:DEBUG,org.elasticsearch.action.bulk:DEBUG"")
    public void clearAllowedOperations() {
        ALLOWED_OPERATIONS.drainPermits();
    }
",non-flaky,5
92592,FasterXML_jackson-databind,TestTypeFactoryWithClassLoader.testUsesCorrectClassLoaderWhenThreadClassLoaderIsNull,"  @Test
  public void testUsesCorrectClassLoaderWhenThreadClassLoaderIsNull() throws ClassNotFoundException {
	Thread.currentThread().setContextClassLoader(null);
	TypeFactory spySut = spy(mapper.getTypeFactory().withModifier(typeModifier).withClassLoader(classLoader));
	Class<?> clazz = spySut.findClass(aClassName);
	verify(spySut).getClassLoader();
	verify(spySut).classForName(any(String.class), any(Boolean.class), eq(classLoader));
	Assert.assertNotNull(clazz);
	Assert.assertEquals(classLoader, spySut.getClassLoader());
	Assert.assertEquals(typeModifier,spySut._modifiers[0]);
	Assert.assertEquals(null, Thread.currentThread().getContextClassLoader());
  }
",non-flaky,5
92593,FasterXML_jackson-databind,TestTypeFactoryWithClassLoader.testUsesCorrectClassLoaderWhenThreadClassLoaderIsNotNull,"  @Test
public void testUsesCorrectClassLoaderWhenThreadClassLoaderIsNotNull() throws ClassNotFoundException {
	TypeFactory spySut = spy(mapper.getTypeFactory().withModifier(typeModifier).withClassLoader(classLoader));
	Class<?> clazz = spySut.findClass(aClassName);
	verify(spySut).getClassLoader();
	verify(spySut).classForName(any(String.class), any(Boolean.class), eq(classLoader));
	Assert.assertNotNull(clazz);
	Assert.assertEquals(classLoader, spySut.getClassLoader());
	Assert.assertEquals(typeModifier,spySut._modifiers[0]);
}
",non-flaky,5
92594,FasterXML_jackson-databind,TestTypeFactoryWithClassLoader.testCallingOnlyWithModifierGivesExpectedResults,"@Test
public void testCallingOnlyWithModifierGivesExpectedResults(){
	TypeFactory sut = mapper.getTypeFactory().withModifier(typeModifier);
	Assert.assertNull(sut.getClassLoader());
	Assert.assertEquals(typeModifier,sut._modifiers[0]);
}
",non-flaky,5
92595,FasterXML_jackson-databind,TestTypeFactoryWithClassLoader.testCallingOnlyWithClassLoaderGivesExpectedResults,"@Test
public void testCallingOnlyWithClassLoaderGivesExpectedResults(){
	TypeFactory sut = mapper.getTypeFactory().withClassLoader(classLoader);
	Assert.assertNotNull(sut.getClassLoader());
	Assert.assertArrayEquals(null,sut._modifiers);
}
",non-flaky,5
92596,FasterXML_jackson-databind,TestTypeFactoryWithClassLoader.testDefaultTypeFactoryNotAffectedByWithConstructors,"@Test
public void testDefaultTypeFactoryNotAffectedByWithConstructors() {
	TypeFactory sut = mapper.getTypeFactory().withModifier(typeModifier).withClassLoader(classLoader);
	Assert.assertEquals(classLoader, sut.getClassLoader());
	Assert.assertEquals(typeModifier,sut._modifiers[0]);
	Assert.assertNull(mapper.getTypeFactory().getClassLoader());
	Assert.assertArrayEquals(null,mapper.getTypeFactory()._modifiers);
}
",non-flaky,5
92597,FasterXML_jackson-databind,TestTypeFactoryWithClassLoader.testSetsTheCorrectClassLoderIfUsingWithModifierFollowedByWithClassLoader,"@Test
public void testSetsTheCorrectClassLoderIfUsingWithModifierFollowedByWithClassLoader() {
	TypeFactory sut = mapper.getTypeFactory().withModifier(typeModifier).withClassLoader(classLoader);
	Assert.assertNotNull(sut.getClassLoader());
}
",non-flaky,5
92598,FasterXML_jackson-databind,TestTypeFactoryWithClassLoader.testSetsTheCorrectClassLoderIfUsingWithClassLoaderFollowedByWithModifier,"@Test
public void testSetsTheCorrectClassLoderIfUsingWithClassLoaderFollowedByWithModifier() {
	TypeFactory sut = mapper.getTypeFactory().withClassLoader(classLoader).withModifier(typeModifier);
	Assert.assertNotNull(sut.getClassLoader());
}
",non-flaky,5
92599,FasterXML_jackson-databind,TestTypeFactoryWithClassLoader.testThreadContextClassLoaderIsUsedIfNotUsingWithClassLoader,"@Test
public void testThreadContextClassLoaderIsUsedIfNotUsingWithClassLoader() throws ClassNotFoundException {
	TypeFactory spySut = spy(mapper.getTypeFactory());
	Assert.assertNull(spySut.getClassLoader());
	Class<?> clazz = spySut.findClass(aClassName);
	Assert.assertNotNull(clazz);
	verify(spySut).classForName(any(String.class), any(Boolean.class), eq(threadClassLoader));
}
",non-flaky,5
92600,FasterXML_jackson-databind,TestTypeFactoryWithClassLoader.testUsesFallBackClassLoaderIfNoThreadClassLoaderAndNoWithClassLoader,"@Test
public void testUsesFallBackClassLoaderIfNoThreadClassLoaderAndNoWithClassLoader() throws ClassNotFoundException {
	Thread.currentThread().setContextClassLoader(null);
	TypeFactory spySut = spy(mapper.getTypeFactory());
	Assert.assertNull(spySut.getClassLoader());
	Assert.assertArrayEquals(null,spySut._modifiers);
	Class<?> clazz = spySut.findClass(aClassName);
	Assert.assertNotNull(clazz);
	verify(spySut).classForName(any(String.class));
}
",non-flaky,5
92601,FasterXML_jackson-databind,ImmutablesTypeSerializationTest.testImmutablesSimpleDeserialization,"    @Test
    public void testImmutablesSimpleDeserialization() throws IOException {
        Account expected = ImmutableAccount.builder()
                .id(1L)
                .name(""foo"")
                .build();
        Account actual = MAPPER.readValue(""{\""id\"": 1,\""name\"":\""foo\""}"", Account.class);
        assertEquals(expected, actual);
    }
",non-flaky,5
92602,FasterXML_jackson-databind,ImmutablesTypeSerializationTest.testImmutablesSimpleRoundTrip,"    @Test
    public void testImmutablesSimpleRoundTrip() throws IOException {
        Account original = ImmutableAccount.builder()
                .id(1L)
                .name(""foo"")
                .build();
        String json = MAPPER.writeValueAsString(original);
        Account deserialized = MAPPER.readValue(json, Account.class);
        assertEquals(original, deserialized);
    }
",non-flaky,5
92603,FasterXML_jackson-databind,ImmutablesTypeSerializationTest.testImmutablesSimpleGenericDeserialization,"    @Test
    public void testImmutablesSimpleGenericDeserialization() throws IOException {
        Key<Account> expected = ImmutableKey.<Account>builder()
                .id(ImmutableAccount.builder()
                        .id(1L)
                        .name(""foo"")
                        .build())
                .build();
        Key<Account> actual = MAPPER.readValue(
                ""{\""id\"":{\""id\"": 1,\""name\"":\""foo\""}}"",
                new TypeReference<Key<Account>>() {});
        assertEquals(expected, actual);
    }
",non-flaky,5
92604,FasterXML_jackson-databind,ImmutablesTypeSerializationTest.testImmutablesSimpleGenericRoundTrip,"    @Test
    public void testImmutablesSimpleGenericRoundTrip() throws IOException {
        Key<Account> original = ImmutableKey.<Account>builder()
                .id(ImmutableAccount.builder()
                        .id(1L)
                        .name(""foo"")
                        .build())
                .build();
        String json = MAPPER.writeValueAsString(original);
        Key<Account> deserialized = MAPPER.readValue(json, new TypeReference<Key<Account>>() {});
        assertEquals(original, deserialized);
    }
",non-flaky,5
92605,FasterXML_jackson-databind,ImmutablesTypeSerializationTest.testImmutablesMultipleTypeParametersDeserialization,"    @Test
    public void testImmutablesMultipleTypeParametersDeserialization() throws IOException {
        Entry<Key<Account>, Account> expected = ImmutableEntry.<Key<Account>, Account>builder()
                .key(ImmutableKey.<Account>builder()
                        .id(ImmutableAccount.builder()
                                .id(1L)
                                .name(""foo"")
                                .build())
                        .build())
                .value(ImmutableAccount.builder()
                        .id(2L)
                        .name(""bar"")
                        .build())
                .build();
        Entry<Key<Account>, Account> actual = MAPPER.readValue(
                ""{\""key\"":{\""id\"":{\""id\"": 1,\""name\"":\""foo\""}},\""value\"":{\""id\"":2,\""name\"":\""bar\""}}"",
                new TypeReference<Entry<Key<Account>, Account>>() {});
        assertEquals(expected, actual);
    }
",non-flaky,5
92606,FasterXML_jackson-databind,ImmutablesTypeSerializationTest.testImmutablesMultipleTypeParametersRoundTrip,"    @Test
    public void testImmutablesMultipleTypeParametersRoundTrip() throws IOException {
        Entry<Key<Account>, Account> original = ImmutableEntry.<Key<Account>, Account>builder()
                .key(ImmutableKey.<Account>builder()
                        .id(ImmutableAccount.builder()
                                .id(1L)
                                .name(""foo"")
                                .build())
                        .build())
                .value(ImmutableAccount.builder()
                        .id(2L)
                        .name(""bar"")
                        .build())
                .build();
        String json = MAPPER.writeValueAsString(original);
        Entry<Key<Account>, Account> deserialized = MAPPER.readValue(
                json, new TypeReference<Entry<Key<Account>, Account>>() {});
        assertEquals(original, deserialized);
    }
",non-flaky,5
92607,FasterXML_jackson-databind,ObjectReaderValueOfWithValueTypeTest.testValueOfStringWithValueType,"    @Test
    public void testValueOfStringWithValueType() throws IOException {
        when(objectReader.readValue((String) any())).thenReturn(pojo);
        when(objectReader.forType((Class<?>) any())).thenReturn(objectReader);
        when(objectReader.readValue((String) any(), (Class<?>) any())).thenCallRealMethod();

        String source = """";
        POJO result = objectReader.readValue(source, POJO.class);

        assertEquals(result, pojo);
        verify(objectReader).forType(POJO.class);
        verify(objectReader).readValue(source);
    }
",non-flaky,5
92608,FasterXML_jackson-databind,ObjectReaderValueOfWithValueTypeTest.testValueOfByteArrayWithValueType,"    @Test
    public void testValueOfByteArrayWithValueType() throws IOException {
        when(objectReader.forType((Class<?>) any())).thenReturn(objectReader);
        when(objectReader.readValue((byte[]) any())).thenReturn(pojo);
        when(objectReader.readValue((byte[]) any(), (Class<?>) any())).thenCallRealMethod();

        byte[] source = ""{}"".getBytes();
        POJO result = objectReader.readValue(source, POJO.class);

        assertEquals(result, pojo);
        verify(objectReader).forType(POJO.class);
        verify(objectReader).readValue(source);
    }
",non-flaky,5
92609,FasterXML_jackson-databind,ObjectReaderValueOfWithValueTypeTest.testValueOfDataInputWithValueType,"    @Test
    public void testValueOfDataInputWithValueType() throws IOException {
        when(objectReader.forType((Class<?>) any())).thenReturn(objectReader);
        when(objectReader.readValue((DataInput) any())).thenReturn(pojo);
        when(objectReader.readValue((DataInput) any(), (Class<?>) any())).thenCallRealMethod();

        DataInput source = new DataInputStream(new ByteArrayInputStream(""{}"".getBytes()));
        POJO result = objectReader.readValue(source, POJO.class);

        assertEquals(result, pojo);
        verify(objectReader).forType(POJO.class);
        verify(objectReader).readValue(source);
    }
",non-flaky,5
92610,FasterXML_jackson-databind,ObjectReaderValueOfWithValueTypeTest.testValueOfFileWithValueType,"    @Test
    public void testValueOfFileWithValueType() throws IOException {
        when(objectReader.forType((Class<?>) any())).thenReturn(objectReader);
        when(objectReader.readValue((File) any())).thenReturn(pojo);
        when(objectReader.readValue((File) any(), (Class<?>) any())).thenCallRealMethod();

        File source = new File(""unknownpath"");
        POJO result = objectReader.readValue(source, POJO.class);

        assertEquals(result, pojo);
        verify(objectReader).forType(POJO.class);
        verify(objectReader).readValue(source);
    }
",non-flaky,5
92611,FasterXML_jackson-databind,ObjectReaderValueOfWithValueTypeTest.testValueOfInputStreamWithValueType,"    @Test
    public void testValueOfInputStreamWithValueType() throws IOException {
        when(objectReader.forType((Class<?>) any())).thenReturn(objectReader);
        when(objectReader.readValue((InputStream) any())).thenReturn(pojo);
        when(objectReader.readValue((InputStream) any(), (Class<?>) any())).thenCallRealMethod();

        InputStream source = new ByteArrayInputStream(""{}"".getBytes());
        POJO result = objectReader.readValue(source, POJO.class);

        assertEquals(result, pojo);
        verify(objectReader).forType(POJO.class);
        verify(objectReader).readValue(source);
    }
",non-flaky,5
92612,FasterXML_jackson-databind,ObjectReaderValueOfWithValueTypeTest.testValueOfJsonNodeWithValueType,"    @Test
    public void testValueOfJsonNodeWithValueType() throws IOException {
        when(objectReader.forType((Class<?>) any())).thenReturn(objectReader);
        when(objectReader.readValue((JsonNode) any())).thenReturn(pojo);
        when(objectReader.readValue((JsonNode) any(), (Class<?>) any())).thenCallRealMethod();

        JsonNode source = new TextNode(""{}"");
        POJO result = objectReader.readValue(source, POJO.class);

        assertEquals(result, pojo);
        verify(objectReader).forType(POJO.class);
        verify(objectReader).readValue(source);
    }
",non-flaky,5
92613,FasterXML_jackson-databind,ObjectReaderValueOfWithValueTypeTest.testValueOfReaderWithValueType,"    @Test
    public void testValueOfReaderWithValueType() throws IOException {
        when(objectReader.forType((Class<?>) any())).thenReturn(objectReader);
        when(objectReader.readValue((Reader) any())).thenReturn(pojo);
        when(objectReader.readValue((Reader) any(), (Class<?>) any())).thenCallRealMethod();

        Reader source = new StringReader(""{}"");
        POJO result = objectReader.readValue(source, POJO.class);

        assertEquals(result, pojo);
        verify(objectReader).forType(POJO.class);
        verify(objectReader).readValue(source);
    }
",non-flaky,5
92614,FasterXML_jackson-databind,ObjectReaderValueOfWithValueTypeTest.testValueOfURLWithValueType,"    @Test
    public void testValueOfURLWithValueType() throws IOException {
        when(objectReader.forType((Class<?>) any())).thenReturn(objectReader);
        when(objectReader.readValue((URL) any())).thenReturn(pojo);
        when(objectReader.readValue((URL) any(), (Class<?>) any())).thenCallRealMethod();

        URL source = new URL(""http://www.test.com"");
        POJO result = objectReader.readValue(source, POJO.class);

        assertEquals(result, pojo);
        verify(objectReader).forType(POJO.class);
        verify(objectReader).readValue(source);
    }
",non-flaky,5
92615,FasterXML_jackson-databind,TestPropertyCreatorSubtypesExternalPropertyMissingProperty.testDeserializationPresent,"    @Test
    public void testDeserializationPresent() throws Exception {
        checkOrangeBox(BOX_READER_PASS);
        checkAppleBox(BOX_READER_PASS);

        checkOrangeBox(BOX_READER_FAIL);
        checkAppleBox(BOX_READER_FAIL);
    }
",non-flaky,5
92616,FasterXML_jackson-databind,TestPropertyCreatorSubtypesExternalPropertyMissingProperty.testDeserializationNull,"    @Test
    public void testDeserializationNull() throws Exception {
        checkOrangeBoxNull(BOX_READER_PASS, orangeBoxNullJson);
        checkAppleBoxNull(BOX_READER_PASS, appleBoxNullJson);

        checkOrangeBoxNull(BOX_READER_FAIL, orangeBoxNullJson);
        checkAppleBoxNull(BOX_READER_FAIL, appleBoxNullJson);
    }
",non-flaky,5
92617,FasterXML_jackson-databind,TestPropertyCreatorSubtypesExternalPropertyMissingProperty.testDeserializationEmpty,"    @Test
    public void testDeserializationEmpty() throws Exception {
        checkOrangeBoxEmpty(BOX_READER_PASS, orangeBoxEmptyJson);
        checkAppleBoxEmpty(BOX_READER_PASS, appleBoxEmptyJson);

        checkOrangeBoxEmpty(BOX_READER_FAIL, orangeBoxEmptyJson);
        checkAppleBoxEmpty(BOX_READER_FAIL, appleBoxEmptyJson);
    }
",non-flaky,5
92618,FasterXML_jackson-databind,TestPropertyCreatorSubtypesExternalPropertyMissingProperty.testDeserializationMissing,"    @Test
    public void testDeserializationMissing() throws Exception {
        checkOrangeBoxNull(BOX_READER_PASS, orangeBoxMissingJson);
        checkAppleBoxNull(BOX_READER_PASS, appleBoxMissingJson);

        checkBoxException(BOX_READER_FAIL, orangeBoxMissingJson);
        checkBoxException(BOX_READER_FAIL, appleBoxMissingJson);
    }
",non-flaky,5
92619,FasterXML_jackson-databind,TestSubtypesExternalPropertyMissingProperty.testDeserializationPresent,"    @Test
    public void testDeserializationPresent() throws Exception {
        ObjectReader r = READER.without(DeserializationFeature.FAIL_ON_MISSING_EXTERNAL_TYPE_ID_PROPERTY);
        checkOrangeBox(r);
        checkAppleBox(r);

        r = READER.with(DeserializationFeature.FAIL_ON_MISSING_EXTERNAL_TYPE_ID_PROPERTY);
        checkOrangeBox(r);
        checkAppleBox(r);
    }
",non-flaky,5
92620,FasterXML_jackson-databind,TestSubtypesExternalPropertyMissingProperty.testDeserializationNull,"    @Test
    public void testDeserializationNull() throws Exception {
        ObjectReader r = READER.without(DeserializationFeature.FAIL_ON_MISSING_EXTERNAL_TYPE_ID_PROPERTY);
        checkOrangeBoxNull(r, orangeBoxNullJson);
        checkAppleBoxNull(r, appleBoxNullJson);

        r = READER.with(DeserializationFeature.FAIL_ON_MISSING_EXTERNAL_TYPE_ID_PROPERTY);
        checkOrangeBoxNull(r, orangeBoxNullJson);
        checkAppleBoxNull(r, appleBoxNullJson);
    }
",non-flaky,5
92621,FasterXML_jackson-databind,TestSubtypesExternalPropertyMissingProperty.testDeserializationEmpty,"    @Test
    public void testDeserializationEmpty() throws Exception {
        ObjectReader r = READER.without(DeserializationFeature.FAIL_ON_MISSING_EXTERNAL_TYPE_ID_PROPERTY);
        checkOrangeBoxEmpty(r, orangeBoxEmptyJson);
        checkAppleBoxEmpty(r, appleBoxEmptyJson);

        r = READER.with(DeserializationFeature.FAIL_ON_MISSING_EXTERNAL_TYPE_ID_PROPERTY);
        checkOrangeBoxEmpty(r, orangeBoxEmptyJson);
        checkAppleBoxEmpty(r, appleBoxEmptyJson);
    }
",non-flaky,5
92622,FasterXML_jackson-databind,TestSubtypesExternalPropertyMissingProperty.testDeserializationMissing,"    @Test
    public void testDeserializationMissing() throws Exception {
        ObjectReader r = READER.without(DeserializationFeature.FAIL_ON_MISSING_EXTERNAL_TYPE_ID_PROPERTY);
        checkOrangeBoxNull(r, orangeBoxMissingJson);
        checkAppleBoxNull(r, appleBoxMissingJson);

        r = READER.with(DeserializationFeature.FAIL_ON_MISSING_EXTERNAL_TYPE_ID_PROPERTY);
        checkBoxDatabindException(r, orangeBoxMissingJson);
        checkBoxDatabindException(r, appleBoxMissingJson);
    }
",non-flaky,5
92623,FasterXML_jackson-databind,TestSubtypesExternalPropertyMissingProperty.testDeserializationMissingRequired,"    @Test
    public void testDeserializationMissingRequired() throws Exception {
        ObjectReader r = READER.without(DeserializationFeature.FAIL_ON_MISSING_EXTERNAL_TYPE_ID_PROPERTY);
        checkReqBoxDatabindException(r, orangeBoxMissingJson);
        checkReqBoxDatabindException(r, appleBoxMissingJson);

        r = READER.with(DeserializationFeature.FAIL_ON_MISSING_EXTERNAL_TYPE_ID_PROPERTY);
        checkReqBoxDatabindException(r, orangeBoxMissingJson);
        checkReqBoxDatabindException(r, appleBoxMissingJson);
    }
",non-flaky,5
94601,square_okhttp,UrlConnectionCacheTest.gzip,"  @Test public void testGoldenCacheResponse() throws Exception {
  public Buffer gzip(String data) throws IOException {
    Buffer result = new Buffer();
    BufferedSink sink = Okio.buffer(new GzipSink(result));
    sink.writeUtf8(data);
    sink.close();
    return result;
  }
",non-flaky,5
94602,square_okhttp,OkUrlFactoryTest.setInstanceFollowRedirectsFalse,"  @Test
  public void setInstanceFollowRedirectsFalse() throws Exception {
    server.enqueue(new MockResponse()
        .setResponseCode(302)
        .addHeader(""Location: /b"")
        .setBody(""A""));
    server.enqueue(new MockResponse()
        .setBody(""B""));

    HttpURLConnection connection = factory.open(server.url(""/a"").url());
    connection.setInstanceFollowRedirects(false);
    assertResponseBody(connection, ""A"");
    assertResponseCode(connection, 302);
  }
",non-flaky,5
94603,square_okhttp,OkUrlFactoryTest.checkURLPermitted,"  @Test
  public void testURLFilter() throws Exception {
    server.enqueue(new MockResponse()
        .setBody(""B""));
    final URL blockedURL = server.url(""/a"").url();
    factory.setUrlFilter(new URLFilter() {
      @Override
      public void checkURLPermitted(URL url) throws IOException {
        if (blockedURL.equals(url)) {
          throw new IOException(""Blocked"");
        }
      }
",non-flaky,5
94604,square_okhttp,OkUrlFactoryTest.checkURLPermitted,"  @Test
  public void testURLFilterRedirect() throws Exception {
    MockWebServer cleartextServer = new MockWebServer();
    cleartextServer.enqueue(new MockResponse()
        .setBody(""Blocked!""));
    final URL blockedURL = cleartextServer.url(""/"").url();

    SslClient contextBuilder = SslClient.localhost();
    server.useHttps(contextBuilder.socketFactory, false);
    factory.setClient(factory.client().newBuilder()
        .sslSocketFactory(contextBuilder.socketFactory, contextBuilder.trustManager)
        .followSslRedirects(true)
        .build());
    factory.setUrlFilter(new URLFilter() {
      @Override
      public void checkURLPermitted(URL url) throws IOException {
        if (blockedURL.equals(url)) {
          throw new IOException(""Blocked"");
        }
      }
",non-flaky,5
94605,square_okhttp,URLEncodingTest.get,"  @Test @Ignore public void lenientUrlToUriNul() throws Exception {
      @Override public Response get(Request request) throws IOException {
        uriReference.set(request.url().uri());
        throw new UnsupportedOperationException();
      }
",non-flaky,5
94606,square_okhttp,CookiesTest.testNetscapeResponse,"  @Test
  public void testNetscapeResponse() throws Exception {
    CookieManager cookieManager = new CookieManager(null, ACCEPT_ORIGINAL_SERVER);
    client = client.newBuilder()
        .cookieJar(new JavaNetCookieJar(cookieManager))
        .build();
    MockWebServer server = new MockWebServer();
    server.start();

    HttpUrl urlWithIpAddress = urlWithIpAddress(server, ""/path/foo"");
    server.enqueue(new MockResponse().addHeader(""Set-Cookie: a=android; ""
        + ""expires=Fri, 31-Dec-9999 23:59:59 GMT; ""
        + ""path=/path; ""
        + ""domain="" + urlWithIpAddress.host() + ""; ""
        + ""secure""));
    get(urlWithIpAddress);

    List<HttpCookie> cookies = cookieManager.getCookieStore().getCookies();
    assertEquals(1, cookies.size());
    HttpCookie cookie = cookies.get(0);
    assertEquals(""a"", cookie.getName());
    assertEquals(""android"", cookie.getValue());
    assertEquals(null, cookie.getComment());
    assertEquals(null, cookie.getCommentURL());
    assertEquals(false, cookie.getDiscard());
    assertTrue(cookie.getMaxAge() > 100000000000L);
    assertEquals(""/path"", cookie.getPath());
    assertEquals(true, cookie.getSecure());
    assertEquals(0, cookie.getVersion());
  }
",non-flaky,5
94607,square_okhttp,CookiesTest.put,"  @Test public void cookieHandlerLikeAndroid() throws Exception {
      @Override public void put(URI uri, Map<String, List<String>> map) throws IOException {
      }
",non-flaky,5
94608,square_okhttp,CacheTest.assertCookies,"  @Test public void getHeadersRetainsCached200LevelWarnings() throws Exception {
  public void assertCookies(HttpUrl url, String... expectedCookies) throws Exception {
    List<String> actualCookies = new ArrayList<>();
    for (HttpCookie cookie : cookieManager.getCookieStore().get(url.uri())) {
      actualCookies.add(cookie.toString());
    }
    assertEquals(Arrays.asList(expectedCookies), actualCookies);
  }
",non-flaky,5
94609,square_okhttp,CacheTest.intercept,"  @Test public void networkInterceptorInvokedForConditionalGet() throws Exception {
          @Override public Response intercept(Chain chain) throws IOException {
            ifNoneMatch.compareAndSet(null, chain.request().header(""If-None-Match""));
            return chain.proceed(chain.request());
          }
",non-flaky,5
94610,square_okhttp,CacheTest.intercept,"  @Test public void networkInterceptorNotInvokedForFullyCached() throws Exception {
          @Override public Response intercept(Chain chain) throws IOException {
            throw new AssertionError();
          }
",non-flaky,5
94611,square_okhttp,CacheTest.gzip,"  @Test public void etagConditionCanBeNonAscii() throws Exception {
  public Buffer gzip(String data) throws IOException {
    Buffer result = new Buffer();
    BufferedSink sink = Okio.buffer(new GzipSink(result));
    sink.writeUtf8(data);
    sink.close();
    return result;
  }
",non-flaky,5
94612,square_okhttp,MultipartBodyTest.contentType,"  @Test public void streamingPartHasNoLength() throws Exception {
      @Override public MediaType contentType() {
        return null;
      }
",non-flaky,5
94613,square_okhttp,URLConnectionTest.createSocket,"  @Test public void contentDisagreesWithContentLengthHeaderBodyTooShort() throws IOException {
  public void testConnectViaSocketFactory(boolean useHttps) throws IOException {
    SocketFactory uselessSocketFactory = new SocketFactory() {
      public Socket createSocket() {
        throw new IllegalArgumentException(""useless"");
      }
",non-flaky,5
94614,square_okhttp,URLConnectionTest.select,"  @Test public void redirectWithProxySelector() throws Exception {
          @Override public List<Proxy> select(URI uri) {
            proxySelectionRequests.add(uri);
            MockWebServer proxyServer = (uri.getPort() == server.getPort())
                ? server
                : server2;
            return Arrays.asList(proxyServer.toProxyAddress());
          }
",non-flaky,5
94615,square_okhttp,URLConnectionTest.intercept,"  @Test public void interceptorsNotInvoked() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        throw new AssertionError();
      }
",non-flaky,5
94616,square_okhttp,URLConnectionTest.lookup,"  @Test public void unexpectedExceptionSync() throws Exception {
          @Override public List<InetAddress> lookup(String hostname) {
            throw new RuntimeException(""boom!"");
          }
",non-flaky,5
94617,square_okhttp,URLConnectionTest.lookup,"  @Test public void unexpectedExceptionAsync() throws Exception {
          @Override public List<InetAddress> lookup(String hostname) {
            throw new RuntimeException(""boom!"");
          }
",non-flaky,5
94618,square_okhttp,URLConnectionTest.gzip,"  @Test public void callsNotManagedByDispatcher() throws Exception {
  public Buffer gzip(String data) throws IOException {
    Buffer result = new Buffer();
    BufferedSink gzipSink = Okio.buffer(new GzipSink(result));
    gzipSink.writeUtf8(data);
    gzipSink.close();
    return result;
  }
",non-flaky,5
94619,square_okhttp,InterceptorTest.intercept,"  @Test public void applicationInterceptorsCanShortCircuitResponses() throws Exception {
          @Override public Response intercept(Chain chain) throws IOException {
            return interceptorResponse;
          }
",non-flaky,5
94620,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsCannotShortCircuitResponses() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        return new Response.Builder()
            .request(chain.request())
            .protocol(Protocol.HTTP_1_1)
            .code(200)
            .message(""Intercepted!"")
            .body(ResponseBody.create(MediaType.parse(""text/plain; charset=utf-8""), ""abc""))
            .build();
      }
",non-flaky,5
94621,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsCannotCallProceedMultipleTimes() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        chain.proceed(chain.request());
        return chain.proceed(chain.request());
      }
",non-flaky,5
94622,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsCannotChangeServerAddress() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Address address = chain.connection().route().address();
        String sameHost = address.url().host();
        int differentPort = address.url().port() + 1;
        return chain.proceed(chain.request().newBuilder()
            .url(HttpUrl.parse(""http://"" + sameHost + "":"" + differentPort + ""/""))
            .build());
      }
",non-flaky,5
94623,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsHaveConnectionAccess() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Connection connection = chain.connection();
        assertNotNull(connection);
        return chain.proceed(chain.request());
      }
",non-flaky,5
94624,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsObserveNetworkHeaders() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        // The network request has everything: User-Agent, Host, Accept-Encoding.
        Request networkRequest = chain.request();
        assertNotNull(networkRequest.header(""User-Agent""));
        assertEquals(server.getHostName() + "":"" + server.getPort(),
            networkRequest.header(""Host""));
        assertNotNull(networkRequest.header(""Accept-Encoding""));

        // The network response also has everything, including the raw gzipped content.
        Response networkResponse = chain.proceed(networkRequest);
        assertEquals(""gzip"", networkResponse.header(""Content-Encoding""));
        return networkResponse;
      }
",non-flaky,5
94625,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsCanChangeRequestMethodFromGetToPost() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Request originalRequest = chain.request();
        MediaType mediaType = MediaType.parse(""text/plain"");
        RequestBody body = RequestBody.create(mediaType, ""abc"");
        return chain.proceed(originalRequest.newBuilder()
            .method(""POST"", body)
            .header(""Content-Type"", mediaType.toString())
            .header(""Content-Length"", Long.toString(body.contentLength()))
            .build());
      }
",non-flaky,5
94626,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsRewriteRequestToServer() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Request originalRequest = chain.request();
        return chain.proceed(originalRequest.newBuilder()
            .method(""POST"", uppercase(originalRequest.body()))
            .addHeader(""OkHttp-Intercepted"", ""yep"")
            .build());
      }
",non-flaky,5
94627,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorsRewriteResponseFromServer() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Response originalResponse = chain.proceed(chain.request());
        return originalResponse.newBuilder()
            .body(uppercase(originalResponse.body()))
            .addHeader(""OkHttp-Intercepted"", ""yep"")
            .build();
      }
",non-flaky,5
94628,square_okhttp,InterceptorTest.intercept,"  @Test public void multipleNetworkInterceptors() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Request originalRequest = chain.request();
        Response originalResponse = chain.proceed(originalRequest.newBuilder()
            .addHeader(""Request-Interceptor"", ""Android"") // 1. Added first.
            .build());
        return originalResponse.newBuilder()
            .addHeader(""Response-Interceptor"", ""Donut"") // 4. Added last.
            .build();
      }
",non-flaky,5
94629,square_okhttp,InterceptorTest.intercept,"  @Test public void asyncNetworkInterceptors() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Response originalResponse = chain.proceed(chain.request());
        return originalResponse.newBuilder()
            .addHeader(""OkHttp-Intercepted"", ""yep"")
            .build();
      }
",non-flaky,5
94630,square_okhttp,InterceptorTest.intercept,"  @Test public void applicationInterceptorsCanMakeMultipleRequestsToServer() throws Exception {
          @Override public Response intercept(Chain chain) throws IOException {
            Response response1 = chain.proceed(chain.request());
            response1.body().close();
            return chain.proceed(chain.request());
          }
",non-flaky,5
94631,square_okhttp,InterceptorTest.intercept,"  @Test public void interceptorMakesAnUnrelatedRequest() throws Exception {
          @Override public Response intercept(Chain chain) throws IOException {
            if (chain.request().url().encodedPath().equals(""/b"")) {
              Request requestA = new Request.Builder()
                  .url(server.url(""/a""))
                  .build();
              Response responseA = client.newCall(requestA).execute();
              assertEquals(""a"", responseA.body().string());
            }

            return chain.proceed(chain.request());
          }
",non-flaky,5
94632,square_okhttp,InterceptorTest.intercept,"  @Test public void interceptorMakesAnUnrelatedAsyncRequest() throws Exception {
          @Override public Response intercept(Chain chain) throws IOException {
            if (chain.request().url().encodedPath().equals(""/b"")) {
              Request requestA = new Request.Builder()
                  .url(server.url(""/a""))
                  .build();

              try {
                RecordingCallback callbackA = new RecordingCallback();
                client.newCall(requestA).enqueue(callbackA);
                callbackA.await(requestA.url()).assertBody(""a"");
              } catch (Exception e) {
                throw new RuntimeException(e);
              }
            }

            return chain.proceed(chain.request());
          }
",non-flaky,5
94633,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorThrowsRuntimeExceptionSynchronous() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        throw new RuntimeException(""boom!"");
      }
",non-flaky,5
94634,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorModifiedRequestIsReturned() throws IOException {
      @Override public Response intercept(Chain chain) throws IOException {
        return chain.proceed(chain.request().newBuilder()
            .header(""User-Agent"", ""intercepted request"")
            .build());
      }
",non-flaky,5
94635,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorThrowsRuntimeExceptionAsynchronous() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        throw new RuntimeException(""boom!"");
      }
",non-flaky,5
94636,square_okhttp,InterceptorTest.intercept,"  @Test public void applicationInterceptorReturnsNull() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        chain.proceed(chain.request());
        return null;
      }
",non-flaky,5
94637,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorReturnsNull() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        chain.proceed(chain.request());
        return null;
      }
",non-flaky,5
94638,square_okhttp,InterceptorTest.intercept,"  @Test public void networkInterceptorReturnsConnectionOnEmptyBody() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Response response = chain.proceed(chain.request());
        assertNotNull(chain.connection());
        return response;
      }
",non-flaky,5
94639,square_okhttp,ResponseTest.close,"  @Test public void eachPeakIsIndependent() throws Exception {
      @Override public void close() throws IOException {
        closed = true;
      }
",non-flaky,5
94640,square_okhttp,SocksProxyTest.select,"  @Test public void proxySelector() throws Exception {
      @Override public List<Proxy> select(URI uri) {
        return Collections.singletonList(socksProxy.proxy());
      }
",non-flaky,5
94641,square_okhttp,DispatcherTest.intercept,"  @Test public void synchronousCallAccessors() throws Exception {
              @Override public Response intercept(Chain chain) throws IOException {
                try {
                  ready.countDown();
                  waiting.await();
                } catch (InterruptedException e) {
                  throw new AssertionError();
                }
                throw new IOException();
              }
",non-flaky,5
94642,square_okhttp,DispatcherTest.run,"  @Test public void idleCallbackInvokedWhenIdle() throws InterruptedException {
      @Override public void run() {
        idle.set(true);
      }
",non-flaky,5
94643,square_okhttp,OkHttpClientTest.intercept,"  @Test public void clonedInterceptorsListsAreIndependent() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        return chain.proceed(chain.request());
      }
",non-flaky,5
94644,square_okhttp,ConnectionReuseTest.intercept,"  @Test public void connectionsAreNotReusedIfNetworkInterceptorInterferes() throws Exception {
      @Override public Response intercept(Chain chain) throws IOException {
        Response response = chain.proceed(chain.request());
        return response.newBuilder()
            .body(ResponseBody.create(null, ""unrelated response body!""))
            .build();
      }
",non-flaky,5
94645,square_okhttp,ConnectionSpecSelectorTest.nonRetryableIOException,"  @Test
  public void nonRetryableIOException() throws Exception {
    ConnectionSpecSelector connectionSpecSelector =
        createConnectionSpecSelector(ConnectionSpec.MODERN_TLS, ConnectionSpec.COMPATIBLE_TLS);
    SSLSocket socket = createSocketWithEnabledProtocols(TlsVersion.TLS_1_1, TlsVersion.TLS_1_0);
    connectionSpecSelector.configureSecureSocket(socket);

    boolean retry = connectionSpecSelector.connectionFailed(
        new IOException(""Non-handshake exception""));
    assertFalse(retry);
    socket.close();
  }
",non-flaky,5
94646,square_okhttp,ConnectionSpecSelectorTest.nonRetryableSSLHandshakeException,"  @Test
  public void nonRetryableSSLHandshakeException() throws Exception {
    ConnectionSpecSelector connectionSpecSelector =
        createConnectionSpecSelector(ConnectionSpec.MODERN_TLS, ConnectionSpec.COMPATIBLE_TLS);
    SSLSocket socket = createSocketWithEnabledProtocols(TlsVersion.TLS_1_1, TlsVersion.TLS_1_0);
    connectionSpecSelector.configureSecureSocket(socket);

    SSLHandshakeException trustIssueException =
        new SSLHandshakeException(""Certificate handshake exception"");
    trustIssueException.initCause(new CertificateException());
    boolean retry = connectionSpecSelector.connectionFailed(trustIssueException);
    assertFalse(retry);
    socket.close();
  }
",non-flaky,5
94647,square_okhttp,ConnectionSpecSelectorTest.retryableSSLHandshakeException,"  @Test
  public void retryableSSLHandshakeException() throws Exception {
    ConnectionSpecSelector connectionSpecSelector =
        createConnectionSpecSelector(ConnectionSpec.MODERN_TLS, ConnectionSpec.COMPATIBLE_TLS);
    SSLSocket socket = createSocketWithEnabledProtocols(TlsVersion.TLS_1_1, TlsVersion.TLS_1_0);
    connectionSpecSelector.configureSecureSocket(socket);

    boolean retry = connectionSpecSelector.connectionFailed(RETRYABLE_EXCEPTION);
    assertTrue(retry);
    socket.close();
  }
",non-flaky,5
94648,square_okhttp,ConnectionSpecSelectorTest.someFallbacksSupported,"  @Test
  public void someFallbacksSupported() throws Exception {
    ConnectionSpec sslV3 =
        new ConnectionSpec.Builder(ConnectionSpec.MODERN_TLS)
            .tlsVersions(TlsVersion.SSL_3_0)
            .build();

    ConnectionSpecSelector connectionSpecSelector = createConnectionSpecSelector(
        ConnectionSpec.MODERN_TLS, ConnectionSpec.COMPATIBLE_TLS, sslV3);

    TlsVersion[] enabledSocketTlsVersions = {TlsVersion.TLS_1_1, TlsVersion.TLS_1_0};
    SSLSocket socket = createSocketWithEnabledProtocols(enabledSocketTlsVersions);

    // MODERN_TLS is used here.
    connectionSpecSelector.configureSecureSocket(socket);
    assertEnabledProtocols(socket, TlsVersion.TLS_1_1, TlsVersion.TLS_1_0);

    boolean retry = connectionSpecSelector.connectionFailed(RETRYABLE_EXCEPTION);
    assertTrue(retry);
    socket.close();

    // COMPATIBLE_TLS is used here.
    socket = createSocketWithEnabledProtocols(enabledSocketTlsVersions);
    connectionSpecSelector.configureSecureSocket(socket);
    assertEnabledProtocols(socket, TlsVersion.TLS_1_0);

    retry = connectionSpecSelector.connectionFailed(RETRYABLE_EXCEPTION);
    assertFalse(retry);
    socket.close();

    // sslV3 is not used because SSLv3 is not enabled on the socket.
  }
",non-flaky,5
94649,square_okhttp,RouteSelectorTest.select,"  @Test public void proxySelectorReturnsNull() throws Exception {
      @Override public List<Proxy> select(URI uri) {
        assertEquals(uriHost, uri.getHost());
        return null;
      }
",non-flaky,5
94650,square_okhttp,RelayTest.call,"  @Test public void racingReaders() throws Exception {
      @Override public ByteString call() throws Exception {
        Buffer buffer = new Buffer();
        while (source.read(buffer, 16384) != -1) {
        }
        source.close();
        return buffer.readByteString();
      }
",non-flaky,5
94651,square_okhttp,Jdk9PlatformTest.buildsWhenJdk9,"  @Test
  public void buildsWhenJdk9() {
    assumeTrue(getPlatform().equals(""jdk9""));

    assertNotNull(Jdk9Platform.buildIfSupported());
  }
",non-flaky,5
94652,square_okhttp,Jdk9PlatformTest.findsAlpnMethods,"  @Test
  public void findsAlpnMethods() {
    assumeTrue(getPlatform().equals(""jdk9""));

    Jdk9Platform platform = Jdk9Platform.buildIfSupported();

    assertEquals(""getApplicationProtocol"", platform.getProtocolMethod.getName());
    assertEquals(""setApplicationProtocols"", platform.setProtocolMethod.getName());
  }
",non-flaky,5
94653,square_okhttp,JdkWithJettyBootPlatformTest.testBuildsWithJettyBoot,"  @Test
  public void testBuildsWithJettyBoot() {
    assumeTrue(getPlatform().equals(""jdk-with-jetty-boot""));

    assertNotNull(JdkWithJettyBootPlatform.buildIfSupported());
  }
",non-flaky,5
94654,square_okhttp,OptionalMethodTest.isSupported,"  @Test
  public void isSupported() throws Exception {
    {
      BaseClass base = new BaseClass();
      assertTrue(STRING_METHOD_RETURNS_ANY.isSupported(base));
      assertTrue(STRING_METHOD_RETURNS_STRING.isSupported(base));
      assertFalse(STRING_METHOD_RETURNS_INT.isSupported(base));
      assertTrue(VOID_METHOD_RETURNS_ANY.isSupported(base));
      assertTrue(VOID_METHOD_RETURNS_VOID.isSupported(base));
      assertFalse(SUBCLASS_METHOD_RETURNS_ANY.isSupported(base));
      assertFalse(SUBCLASS_METHOD_RETURNS_STRING.isSupported(base));
      assertFalse(SUBCLASS_METHOD_RETURNS_INT.isSupported(base));
      assertFalse(METHOD_WITH_ARGS_WRONG_PARAMS.isSupported(base));
      assertFalse(METHOD_WITH_ARGS_CORRECT_PARAMS.isSupported(base));
    }
    {
      SubClass1 subClass1 = new SubClass1();
      assertTrue(STRING_METHOD_RETURNS_ANY.isSupported(subClass1));
      assertTrue(STRING_METHOD_RETURNS_STRING.isSupported(subClass1));
      assertFalse(STRING_METHOD_RETURNS_INT.isSupported(subClass1));
      assertTrue(VOID_METHOD_RETURNS_ANY.isSupported(subClass1));
      assertTrue(VOID_METHOD_RETURNS_VOID.isSupported(subClass1));
      assertTrue(SUBCLASS_METHOD_RETURNS_ANY.isSupported(subClass1));
      assertTrue(SUBCLASS_METHOD_RETURNS_STRING.isSupported(subClass1));
      assertFalse(SUBCLASS_METHOD_RETURNS_INT.isSupported(subClass1));
      assertFalse(METHOD_WITH_ARGS_WRONG_PARAMS.isSupported(subClass1));
      assertTrue(METHOD_WITH_ARGS_CORRECT_PARAMS.isSupported(subClass1));
    }
    {
      SubClass2 subClass2 = new SubClass2();
      assertTrue(STRING_METHOD_RETURNS_ANY.isSupported(subClass2));
      assertTrue(STRING_METHOD_RETURNS_STRING.isSupported(subClass2));
      assertFalse(STRING_METHOD_RETURNS_INT.isSupported(subClass2));
      assertTrue(VOID_METHOD_RETURNS_ANY.isSupported(subClass2));
      assertTrue(VOID_METHOD_RETURNS_VOID.isSupported(subClass2));
      assertTrue(SUBCLASS_METHOD_RETURNS_ANY.isSupported(subClass2));
      assertFalse(SUBCLASS_METHOD_RETURNS_STRING.isSupported(subClass2));
      assertTrue(SUBCLASS_METHOD_RETURNS_INT.isSupported(subClass2));
      assertFalse(METHOD_WITH_ARGS_WRONG_PARAMS.isSupported(subClass2));
      assertTrue(METHOD_WITH_ARGS_CORRECT_PARAMS.isSupported(subClass2));
    }
  }
",non-flaky,5
94655,square_okhttp,OptionalMethodTest.invoke,"  @Test
  public void invoke() throws Exception {
    {
      BaseClass base = new BaseClass();
      assertEquals(""string"", STRING_METHOD_RETURNS_STRING.invoke(base));
      assertEquals(""string"", STRING_METHOD_RETURNS_ANY.invoke(base));
      assertErrorOnInvoke(STRING_METHOD_RETURNS_INT, base);
      assertNull(VOID_METHOD_RETURNS_ANY.invoke(base));
      assertNull(VOID_METHOD_RETURNS_VOID.invoke(base));
      assertErrorOnInvoke(SUBCLASS_METHOD_RETURNS_ANY, base);
      assertErrorOnInvoke(SUBCLASS_METHOD_RETURNS_STRING, base);
      assertErrorOnInvoke(SUBCLASS_METHOD_RETURNS_INT, base);
      assertErrorOnInvoke(METHOD_WITH_ARGS_WRONG_PARAMS, base);
      assertErrorOnInvoke(METHOD_WITH_ARGS_CORRECT_PARAMS, base);
    }
    {
      SubClass1 subClass1 = new SubClass1();
      assertEquals(""string"", STRING_METHOD_RETURNS_STRING.invoke(subClass1));
      assertEquals(""string"", STRING_METHOD_RETURNS_ANY.invoke(subClass1));
      assertErrorOnInvoke(STRING_METHOD_RETURNS_INT, subClass1);
      assertNull(VOID_METHOD_RETURNS_ANY.invoke(subClass1));
      assertNull(VOID_METHOD_RETURNS_VOID.invoke(subClass1));
      assertEquals(""subclassMethod1"", SUBCLASS_METHOD_RETURNS_ANY.invoke(subClass1));
      assertEquals(""subclassMethod1"", SUBCLASS_METHOD_RETURNS_STRING.invoke(subClass1));
      assertErrorOnInvoke(SUBCLASS_METHOD_RETURNS_INT, subClass1);
      assertErrorOnInvoke(METHOD_WITH_ARGS_WRONG_PARAMS, subClass1);
      assertEquals(""arg"", METHOD_WITH_ARGS_CORRECT_PARAMS.invoke(subClass1, ""arg""));
    }

    {
      SubClass2 subClass2 = new SubClass2();
      assertEquals(""string"", STRING_METHOD_RETURNS_STRING.invoke(subClass2));
      assertEquals(""string"", STRING_METHOD_RETURNS_ANY.invoke(subClass2));
      assertErrorOnInvoke(STRING_METHOD_RETURNS_INT, subClass2);
      assertNull(VOID_METHOD_RETURNS_ANY.invoke(subClass2));
      assertNull(VOID_METHOD_RETURNS_VOID.invoke(subClass2));
      assertEquals(1234, SUBCLASS_METHOD_RETURNS_ANY.invoke(subClass2));
      assertErrorOnInvoke(SUBCLASS_METHOD_RETURNS_STRING, subClass2);
      assertEquals(1234, SUBCLASS_METHOD_RETURNS_INT.invoke(subClass2));
      assertErrorOnInvoke(METHOD_WITH_ARGS_WRONG_PARAMS, subClass2);
      assertEquals(""arg"", METHOD_WITH_ARGS_CORRECT_PARAMS.invoke(subClass2, ""arg""));
    }
  }
",non-flaky,5
94656,square_okhttp,OptionalMethodTest.invokeBadArgs,"  @Test
  public void invokeBadArgs() throws Exception {
    SubClass1 subClass1 = new SubClass1();
    assertIllegalArgumentExceptionOnInvoke(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1); // no args
    assertIllegalArgumentExceptionOnInvoke(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1, 123);
    assertIllegalArgumentExceptionOnInvoke(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1, true);
    assertIllegalArgumentExceptionOnInvoke(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1,
        new Object());
    assertIllegalArgumentExceptionOnInvoke(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1, ""one"",
        ""two"");
  }
",non-flaky,5
94657,square_okhttp,OptionalMethodTest.invokeWithException,"  @Test
  public void invokeWithException() throws Exception {
    SubClass2 subClass2 = new SubClass2();
    try {
      THROWS_EXCEPTION.invoke(subClass2);
    } catch (InvocationTargetException expected) {
      assertTrue(expected.getTargetException() instanceof IOException);
    }

    try {
      THROWS_RUNTIME_EXCEPTION.invoke(subClass2);
    } catch (InvocationTargetException expected) {
      assertTrue(expected.getTargetException() instanceof NumberFormatException);
    }
  }
",non-flaky,5
94658,square_okhttp,OptionalMethodTest.invokeNonPublic,"  @Test
  public void invokeNonPublic() throws Exception {
    SubClass2 subClass2 = new SubClass2();
    assertFalse(NON_PUBLIC.isSupported(subClass2));
    assertErrorOnInvoke(NON_PUBLIC, subClass2);
  }
",non-flaky,5
94659,square_okhttp,OptionalMethodTest.invokeOptional,"  @Test
  public void invokeOptional() throws Exception {
    {
      BaseClass base = new BaseClass();
      assertEquals(""string"", STRING_METHOD_RETURNS_STRING.invokeOptional(base));
      assertEquals(""string"", STRING_METHOD_RETURNS_ANY.invokeOptional(base));
      assertNull(STRING_METHOD_RETURNS_INT.invokeOptional(base));
      assertNull(VOID_METHOD_RETURNS_ANY.invokeOptional(base));
      assertNull(VOID_METHOD_RETURNS_VOID.invokeOptional(base));
      assertNull(SUBCLASS_METHOD_RETURNS_ANY.invokeOptional(base));
      assertNull(SUBCLASS_METHOD_RETURNS_STRING.invokeOptional(base));
      assertNull(SUBCLASS_METHOD_RETURNS_INT.invokeOptional(base));
      assertNull(METHOD_WITH_ARGS_WRONG_PARAMS.invokeOptional(base));
      assertNull(METHOD_WITH_ARGS_CORRECT_PARAMS.invokeOptional(base));
    }
    {
      SubClass1 subClass1 = new SubClass1();
      assertEquals(""string"", STRING_METHOD_RETURNS_STRING.invokeOptional(subClass1));
      assertEquals(""string"", STRING_METHOD_RETURNS_ANY.invokeOptional(subClass1));
      assertNull(STRING_METHOD_RETURNS_INT.invokeOptional(subClass1));
      assertNull(VOID_METHOD_RETURNS_ANY.invokeOptional(subClass1));
      assertNull(VOID_METHOD_RETURNS_VOID.invokeOptional(subClass1));
      assertEquals(""subclassMethod1"", SUBCLASS_METHOD_RETURNS_ANY.invokeOptional(subClass1));
      assertEquals(""subclassMethod1"", SUBCLASS_METHOD_RETURNS_STRING.invokeOptional(subClass1));
      assertNull(SUBCLASS_METHOD_RETURNS_INT.invokeOptional(subClass1));
      assertNull(METHOD_WITH_ARGS_WRONG_PARAMS.invokeOptional(subClass1));
      assertEquals(""arg"", METHOD_WITH_ARGS_CORRECT_PARAMS.invokeOptional(subClass1, ""arg""));
    }

    {
      SubClass2 subClass2 = new SubClass2();
      assertEquals(""string"", STRING_METHOD_RETURNS_STRING.invokeOptional(subClass2));
      assertEquals(""string"", STRING_METHOD_RETURNS_ANY.invokeOptional(subClass2));
      assertNull(STRING_METHOD_RETURNS_INT.invokeOptional(subClass2));
      assertNull(VOID_METHOD_RETURNS_ANY.invokeOptional(subClass2));
      assertNull(VOID_METHOD_RETURNS_VOID.invokeOptional(subClass2));
      assertEquals(1234, SUBCLASS_METHOD_RETURNS_ANY.invokeOptional(subClass2));
      assertNull(SUBCLASS_METHOD_RETURNS_STRING.invokeOptional(subClass2));
      assertEquals(1234, SUBCLASS_METHOD_RETURNS_INT.invokeOptional(subClass2));
      assertNull(METHOD_WITH_ARGS_WRONG_PARAMS.invokeOptional(subClass2));
      assertEquals(""arg"", METHOD_WITH_ARGS_CORRECT_PARAMS.invokeOptional(subClass2, ""arg""));
    }
  }
",non-flaky,5
94660,square_okhttp,OptionalMethodTest.invokeOptionalBadArgs,"  @Test
  public void invokeOptionalBadArgs() throws Exception {
    SubClass1 subClass1 = new SubClass1();
    assertIllegalArgumentExceptionOnInvokeOptional(METHOD_WITH_ARGS_CORRECT_PARAMS,
        subClass1); // no args
    assertIllegalArgumentExceptionOnInvokeOptional(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1, 123);
    assertIllegalArgumentExceptionOnInvokeOptional(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1,
        true);
    assertIllegalArgumentExceptionOnInvokeOptional(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1,
        new Object());
    assertIllegalArgumentExceptionOnInvokeOptional(METHOD_WITH_ARGS_CORRECT_PARAMS, subClass1,
        ""one"", ""two"");
  }
",non-flaky,5
94661,square_okhttp,OptionalMethodTest.invokeOptionalWithException,"  @Test
  public void invokeOptionalWithException() throws Exception {
    SubClass2 subClass2 = new SubClass2();
    try {
      THROWS_EXCEPTION.invokeOptional(subClass2);
    } catch (InvocationTargetException expected) {
      assertTrue(expected.getTargetException() instanceof IOException);
    }

    try {
      THROWS_RUNTIME_EXCEPTION.invokeOptional(subClass2);
    } catch (InvocationTargetException expected) {
      assertTrue(expected.getTargetException() instanceof NumberFormatException);
    }
  }
",non-flaky,5
94662,square_okhttp,OptionalMethodTest.invokeOptionalNonPublic,"  @Test
  public void invokeOptionalNonPublic() throws Exception {
    SubClass2 subClass2 = new SubClass2();
    assertFalse(NON_PUBLIC.isSupported(subClass2));
    assertErrorOnInvokeOptional(NON_PUBLIC, subClass2);
  }
",non-flaky,5
94663,square_okhttp,Http2Test.headers,"  @Test public void onlyOneLiteralHeadersFrame() throws IOException {
      @Override public void headers(boolean inFinished, int streamId,
          int associatedStreamId, List<Header> headerBlock) {
        assertTrue(inFinished);
        assertEquals(expectedStreamId, streamId);
        assertEquals(-1, associatedStreamId);
        assertEquals(sentHeaders, headerBlock);
      }
",non-flaky,5
94664,square_okhttp,Http2Test.priority,"  @Test public void headersWithPriority() throws IOException {
      @Override public void priority(int streamId, int streamDependency, int weight,
          boolean exclusive) {
        assertEquals(0, streamDependency);
        assertEquals(256, weight);
        assertFalse(exclusive);
      }
",non-flaky,5
94665,square_okhttp,Http2Test.headers,"  @Test public void headersFrameThenContinuation() throws IOException {
      @Override public void headers(boolean inFinished, int streamId,
          int associatedStreamId, List<Header> headerBlock) {
        assertFalse(inFinished);
        assertEquals(expectedStreamId, streamId);
        assertEquals(-1, associatedStreamId);
        assertEquals(sentHeaders, headerBlock);
      }
",non-flaky,5
94666,square_okhttp,Http2Test.pushPromise,"  @Test public void pushPromise() throws IOException {
      public void pushPromise(int streamId, int promisedStreamId, List<Header> headerBlock) {
        assertEquals(expectedStreamId, streamId);
        assertEquals(expectedPromisedStreamId, promisedStreamId);
        assertEquals(pushPromise, headerBlock);
      }
",non-flaky,5
94667,square_okhttp,Http2Test.pushPromise,"  @Test public void pushPromiseThenContinuation() throws IOException {
      public void pushPromise(int streamId, int promisedStreamId, List<Header> headerBlock) {
        assertEquals(expectedStreamId, streamId);
        assertEquals(expectedPromisedStreamId, promisedStreamId);
        assertEquals(pushPromise, headerBlock);
      }
",non-flaky,5
94668,square_okhttp,Http2Test.rstStream,"  @Test public void readRstStreamFrame() throws IOException {
      @Override public void rstStream(int streamId, ErrorCode errorCode) {
        assertEquals(expectedStreamId, streamId);
        assertEquals(ErrorCode.PROTOCOL_ERROR, errorCode);
      }
",non-flaky,5
94669,square_okhttp,Http2Test.settings,"  @Test public void readSettingsFrame() throws IOException {
      @Override public void settings(boolean clearPrevious, Settings settings) {
        assertFalse(clearPrevious); // No clearPrevious in HTTP/2.
        assertEquals(reducedTableSizeBytes, settings.getHeaderTableSize());
        assertEquals(false, settings.getEnablePush(true));
      }
",non-flaky,5
94670,square_okhttp,Http2Test.settings,"  @Test public void readSettingsFrameUnknownSettingId() throws IOException {
      @Override public void settings(boolean clearPrevious, Settings settings) {
        settingValue.set(settings.get(7));
      }
",non-flaky,5
94671,square_okhttp,Http2Test.ping,"  @Test public void pingRoundTrip() throws IOException {
      @Override public void ping(boolean ack, int payload1, int payload2) {
        assertTrue(ack);
        assertEquals(expectedPayload1, payload1);
        assertEquals(expectedPayload2, payload2);
      }
",non-flaky,5
94672,square_okhttp,Http2Test.data,"  @Test public void maxLengthDataFrame() throws IOException {
      @Override public void data(boolean inFinished, int streamId, BufferedSource source,
          int length) throws IOException {
        assertFalse(inFinished);
        assertEquals(expectedStreamId, streamId);
        assertEquals(Http2.INITIAL_MAX_FRAME_SIZE, length);
        ByteString data = source.readByteString(length);
        for (byte b : data.toByteArray()) {
          assertEquals(2, b);
        }
      }
",non-flaky,5
94673,square_okhttp,Http2Test.windowUpdate,"  @Test public void windowUpdateRoundTrip() throws IOException {
      @Override public void windowUpdate(int streamId, long windowSizeIncrement) {
        assertEquals(expectedStreamId, streamId);
        assertEquals(expectedWindowSizeIncrement, windowSizeIncrement);
      }
",non-flaky,5
94674,square_okhttp,Http2Test.goAway,"  @Test public void goAwayWithoutDebugDataRoundTrip() throws IOException {
      @Override public void goAway(
          int lastGoodStreamId, ErrorCode errorCode, ByteString debugData) {
        assertEquals(expectedStreamId, lastGoodStreamId);
        assertEquals(expectedError, errorCode);
        assertEquals(0, debugData.size());
      }
",non-flaky,5
94675,square_okhttp,Http2Test.goAway,"  @Test public void goAwayWithDebugDataRoundTrip() throws IOException {
      @Override public void goAway(
          int lastGoodStreamId, ErrorCode errorCode, ByteString debugData) {
        assertEquals(0, lastGoodStreamId);
        assertEquals(expectedError, errorCode);
        assertEquals(expectedData, debugData);
      }
",non-flaky,5
94676,square_okhttp,Http2Test.headers,"  @Test public void streamIdHasReservedBit() throws IOException {
      @Override public void headers(boolean inFinished, int streamId,
          int associatedStreamId, List<Header> headerBlock) {
        assertFalse(inFinished);
        assertEquals(expectedStreamId, streamId);
        assertEquals(-1, associatedStreamId);
        assertEquals(headerEntries(""foo"", ""barrr"", ""baz"", ""qux""), headerBlock);
      }
",non-flaky,5
94677,square_okhttp,Http2ConnectionTest.onStream,"  @Test public void serverSendsSettingsToClient() throws Exception {
      @Override public void onStream(Http2Stream stream) throws IOException {
        throw new AssertionError();
      }
",non-flaky,5
94678,square_okhttp,Http2ConnectionTest.onRequest,"  @Test public void blockedStreamDoesntStarveNewStream() throws Exception {
    @Override public boolean onRequest(int streamId, List<Header> requestHeaders) {
      return false;
    }
",non-flaky,5
94679,square_okhttp,DisconnectTest.run,"  @Test public void interruptReadingResponseBody() throws Exception {
      @Override public void run() {
        try {
          sleep(delayMillis);
          connection.disconnect();
        } catch (InterruptedException e) {
          throw new RuntimeException(e);
        }
      }
",non-flaky,5
94680,square_okhttp,ThreadInterruptTest.run,"  @Test public void interruptReadingResponseBody() throws Exception {
      @Override public void run() {
        try {
          sleep(delayMillis);
          toInterrupt.interrupt();
        } catch (InterruptedException e) {
          throw new RuntimeException(e);
        }
      }
",non-flaky,5
94681,square_okhttp,ClientAuthTest.buildClient,"  @Test public void invalidClientAuthFails() throws Throwable {
  public OkHttpClient buildClient(HeldCertificate cert, HeldCertificate... chain) {
    SslClient.Builder sslClientBuilder = new SslClient.Builder()
        .addTrustedCertificate(serverRootCa.certificate);

    if (cert != null) {
      sslClientBuilder.certificateChain(cert, chain);
    }

    SslClient sslClient = sslClientBuilder.build();
    return new OkHttpClient.Builder()
        .sslSocketFactory(sslClient.socketFactory, sslClient.trustManager)
        .build();
  }
",non-flaky,5
94682,square_okhttp,DiskLruCacheTest.writeFile,"  @Test public void abortAfterDetach() throws Exception {
  public void writeFile(File file, String content) throws Exception {
    BufferedSink sink = Okio.buffer(fileSystem.sink(file));
    sink.writeUtf8(content);
    sink.close();
  }
",non-flaky,5
94683,square_okhttp,HttpResponseCacheTest.get,"  @Test public void getInstalledWithWrongTypeInstalled() {
      public CacheResponse get(URI uri, String requestMethod,
          Map<String, List<String>> requestHeaders) {
        return null;
      }
",non-flaky,5
94684,square_okhttp,CacheAdapterTest.get,"  @Test public void get_httpGet() throws Exception {
      @Override public CacheResponse get(
          URI uri, String method, Map<String, List<String>> headers) throws IOException {
        try {
          assertEquals(toUri(serverUrl), uri);
          assertEquals(""GET"", method);
          assertTrue(""Arbitrary standard header not present"", headers.containsKey(""User-Agent""));
          assertEquals(Collections.singletonList(""value1""), headers.get(""key1""));
          return null;
        } catch (Throwable t) {
          throw new IOException(""unexpected cache failure"", t);
        }
      }
",non-flaky,5
94685,square_okhttp,CacheAdapterTest.get,"  @Test public void get_httpsGet() throws Exception {
      @Override public CacheResponse get(URI uri, String method, Map<String, List<String>> headers)
          throws IOException {
        try {
          assertEquals(""https"", uri.getScheme());
          assertEquals(toUri(serverUrl), uri);
          assertEquals(""GET"", method);
          assertTrue(""Arbitrary standard header not present"", headers.containsKey(""User-Agent""));
          assertEquals(Collections.singletonList(""value1""), headers.get(""key1""));
          return null;
        } catch (Throwable t) {
          throw new IOException(""unexpected cache failure"", t);
        }
      }
",non-flaky,5
94686,square_okhttp,CacheAdapterTest.put,"  @Test public void put_httpGet() throws Exception {
      @Override public CacheRequest put(URI uri, URLConnection connection) throws IOException {
        try {
          assertTrue(connection instanceof HttpURLConnection);
          assertFalse(connection instanceof HttpsURLConnection);

          assertEquals(response.length, connection.getContentLength());

          HttpURLConnection httpUrlConnection = (HttpURLConnection) connection;
          assertEquals(""GET"", httpUrlConnection.getRequestMethod());
          assertTrue(httpUrlConnection.getDoInput());
          assertFalse(httpUrlConnection.getDoOutput());

          assertEquals(""Fantastic"", httpUrlConnection.getResponseMessage());
          assertEquals(toUri(serverUrl), uri);
          assertEquals(serverUrl, connection.getURL());
          assertEquals(""value"", connection.getRequestProperty(""key""));

          // Check retrieval by string key.
          assertEquals(statusLine, httpUrlConnection.getHeaderField(null));
          assertEquals(""c"", httpUrlConnection.getHeaderField(""A""));
          // The RI and OkHttp supports case-insensitive matching for this method.
          assertEquals(""c"", httpUrlConnection.getHeaderField(""a""));
          return null;
        } catch (Throwable t) {
          throw new IOException(""unexpected cache failure"", t);
        }
      }
",non-flaky,5
94687,square_okhttp,CacheAdapterTest.put,"  @Test public void put_httpPost() throws Exception {
      @Override public CacheRequest put(URI uri, URLConnection connection) throws IOException {
        try {
          assertTrue(connection instanceof HttpURLConnection);
          assertFalse(connection instanceof HttpsURLConnection);

          assertEquals(0, connection.getContentLength());

          HttpURLConnection httpUrlConnection = (HttpURLConnection) connection;
          assertEquals(""POST"", httpUrlConnection.getRequestMethod());
          assertTrue(httpUrlConnection.getDoInput());
          assertTrue(httpUrlConnection.getDoOutput());

          assertEquals(""Fantastic"", httpUrlConnection.getResponseMessage());
          assertEquals(toUri(serverUrl), uri);
          assertEquals(serverUrl, connection.getURL());
          assertEquals(""value"", connection.getRequestProperty(""key""));

          // Check retrieval by string key.
          assertEquals(statusLine, httpUrlConnection.getHeaderField(null));
          assertEquals(""c"", httpUrlConnection.getHeaderField(""A""));
          // The RI and OkHttp supports case-insensitive matching for this method.
          assertEquals(""c"", httpUrlConnection.getHeaderField(""a""));
          return null;
        } catch (Throwable t) {
          throw new IOException(""unexpected cache failure"", t);
        }
      }
",non-flaky,5
94688,square_okhttp,CacheAdapterTest.put,"  @Test public void put_httpsGet() throws Exception {
      @Override public CacheRequest put(URI uri, URLConnection connection) throws IOException {
        try {
          assertTrue(connection instanceof HttpsURLConnection);
          assertEquals(toUri(serverUrl), uri);
          assertEquals(serverUrl, connection.getURL());

          HttpsURLConnection cacheHttpsUrlConnection = (HttpsURLConnection) connection;
          HttpsURLConnection realHttpsUrlConnection =
              (HttpsURLConnection) CacheAdapterTest.this.connection;
          assertEquals(realHttpsUrlConnection.getCipherSuite(),
              cacheHttpsUrlConnection.getCipherSuite());
          assertEquals(realHttpsUrlConnection.getPeerPrincipal(),
              cacheHttpsUrlConnection.getPeerPrincipal());
          assertArrayEquals(realHttpsUrlConnection.getLocalCertificates(),
              cacheHttpsUrlConnection.getLocalCertificates());
          assertArrayEquals(realHttpsUrlConnection.getServerCertificates(),
              cacheHttpsUrlConnection.getServerCertificates());
          assertEquals(realHttpsUrlConnection.getLocalPrincipal(),
              cacheHttpsUrlConnection.getLocalPrincipal());
          return null;
        } catch (Throwable t) {
          throw new IOException(""unexpected cache failure"", t);
        }
      }
",non-flaky,5
94689,square_okhttp,ResponseCacheTest.assertCookies,"  @Test public void getHeadersRetainsCached200LevelWarnings() throws Exception {
  public void assertCookies(URL url, String... expectedCookies) throws Exception {
    List<String> actualCookies = new ArrayList<>();
    for (HttpCookie cookie : cookieManager.getCookieStore().get(url.toURI())) {
      actualCookies.add(cookie.toString());
    }
    assertEquals(Arrays.asList(expectedCookies), actualCookies);
  }
",non-flaky,5
94690,square_okhttp,ResponseCacheTest.gzip,"  @Test public void emptyResponseHeaderNameFromCacheIsLenient() throws Exception {
  public Buffer gzip(String data) throws IOException {
    Buffer result = new Buffer();
    BufferedSink sink = Okio.buffer(new GzipSink(result));
    sink.writeUtf8(data);
    sink.close();
    return result;
  }
",non-flaky,5
94691,square_okhttp,ResponseCacheTest.put,"  @Test public void responseCacheCallbackApis() throws Exception {
      @Override public CacheRequest put(URI uri, URLConnection connection) throws IOException {
        HttpURLConnection httpURLConnection = (HttpURLConnection) connection;
        assertEquals(server.url(""/"").url(), uri.toURL());
        assertEquals(200, httpURLConnection.getResponseCode());
        InputStream is = httpURLConnection.getInputStream();
        try {
          is.read();
          fail();
        } catch (UnsupportedOperationException expected) {
        }
        assertEquals(""5"", connection.getHeaderField(""Content-Length""));
        assertEquals(""text/plain"", connection.getHeaderField(""Content-Type""));
        assertEquals(""ijk"", connection.getHeaderField(""fgh""));
        cacheCount.incrementAndGet();
        return null;
      }
",non-flaky,5
94692,square_okhttp,ResponseCacheTest.abort,"  @Test public void responseCacheReturnsNullOutputStream() throws Exception {
      @Override public CacheRequest put(URI uri, URLConnection connection) {
        return new CacheRequest() {
          @Override public void abort() {
            aborted.set(true);
          }
",non-flaky,5
94693,square_okhttp,ResponseCacheTest.get,"  @Test public void responseCacheReturnsNullStatusLine() throws Exception {
      public CacheResponse get(URI uri, String requestMethod,
          Map<String, List<String>> requestHeaders)
",non-flaky,5
94694,square_okhttp,ResponseCacheTest.get,"  @Test public void responseCacheRequestHeaders() throws IOException, URISyntaxException {
      @Override public CacheResponse get(URI uri, String requestMethod,
          Map<String, List<String>> requestHeaders) throws IOException {
        requestHeadersRef.set(requestHeaders);
        return null;
      }
",non-flaky,5
94695,square_okhttp,JavaApiConverterTest.getBody,"  @Test public void createOkResponseForCacheGet() throws Exception {
      @Override public InputStream getBody() throws IOException {
        return new ByteArrayInputStream(""HelloWorld"".getBytes(StandardCharsets.UTF_8));
      }
",non-flaky,5
94696,square_okhttp,JavaApiConverterTest.getBody,"  @Test public void createOkResponseForCacheGet_withMissingStatusLine() throws Exception {
      @Override public InputStream getBody() throws IOException {
        return null; // Should never be called
      }
",non-flaky,5
94697,square_okhttp,JavaApiConverterTest.getBody,"  @Test public void createOkResponseForCacheGet_secure() throws Exception {
      @Override public InputStream getBody() throws IOException {
        return new ByteArrayInputStream(""HelloWorld"".getBytes(StandardCharsets.UTF_8));
      }
",non-flaky,5
94698,square_okhttp,JavaApiConverterTest.contentType,"  @Test public void extractStatusLine() throws Exception {
      @Override public MediaType contentType() {
        return MediaType.parse(""text/plain; charset=utf-8"");
      }
",non-flaky,5
94699,square_okhttp,RealWebSocketTest.contentType,"  @Test public void streamingMessage() throws IOException {
      @Override public MediaType contentType() {
        return TEXT;
      }
",non-flaky,5
94700,square_okhttp,RealWebSocketTest.contentType,"  @Test public void streamingMessageCanInterleavePing() throws IOException, InterruptedException {
      @Override public MediaType contentType() {
        return TEXT;
      }
",non-flaky,5
98337,Kong_unirest-java,MockClientInterceptorIssueTest.setup,"    @BeforeEach
    public void setup() {
        this.unirestInstance = Unirest.spawnInstance();
        this.unirestInstance.config().interceptor(interceptor);
    }
",non-flaky,5
98338,Kong_unirest-java,ExpectedResponseTest.writeValue,"    @Test
        public String writeValue(Object value) {
            return ""derp"";
        }
",non-flaky,5
98339,Kong_unirest-java,AssertTest.expectAnyPath,"    @Test
    public void expectAnyPath(){
        client.expect(HttpMethod.GET)
                .thenReturn(""woh"");

        Unirest.get(path).asEmpty();

        client.verifyAll();
    }
",non-flaky,5
98340,Kong_unirest-java,ApacheBehaviorTest.setTimeoutsAndCustomClient,"    @Test
    public void setTimeoutsAndCustomClient() {
        try {
            Unirest.config().connectTimeout(1000).socketTimeout(2000);
        } catch (Exception e) {
            fail();
        }

        try {
            Unirest.config().asyncClient(HttpAsyncClientBuilder.create().build());
        } catch (Exception e) {
            fail();
        }

        try {
            Unirest.config().asyncClient(HttpAsyncClientBuilder.create().build());
            Unirest.config().connectTimeout(1000).socketTimeout(2000);
            fail();
        } catch (Exception e) {
            // Ok
        }

        try {
            Unirest.config().httpClient(HttpClientBuilder.create().build());
            Unirest.config().connectTimeout(1000).socketTimeout(2000);
            fail();
        } catch (Exception e) {
            // Ok
        }
    }
",non-flaky,5
98341,Kong_unirest-java,ApacheInterceptorTest.process,"    @Test
        public void process(org.apache.http.HttpRequest httpRequest, org.apache.http.protocol.HttpContext httpContext) throws HttpException, IOException {
            httpRequest.addHeader(""x-custom"", ""foo"");
        }
",non-flaky,5
98342,Kong_unirest-java,ApacheClientTest.setUp,"    @BeforeEach
    public void setUp() {
        super.setUp();
    }
",non-flaky,5
98343,Kong_unirest-java,ApacheClientTest.tearDown,"    @AfterEach
    public void tearDown() {
        super.tearDown();
        requestConfigUsed = false;
    }
",non-flaky,5
98344,Kong_unirest-java,CacheManagerTest.getClient,"    @Test
        public Object getClient() {
            return null;
        }
",non-flaky,5
98345,Kong_unirest-java,UriFormatterTest.testMangler_encoding,"    @Test
    public void testMangler_encoding() {
        assertLinkSurvives(""http://localhost/test%2Fthis"");
    }
",non-flaky,5
98346,Kong_unirest-java,UriFormatterTest.testMangler_fragment,"    @Test
    public void testMangler_fragment() {
        assertLinkSurvives(""http://localhost/test?a=b#fragment"");
    }
",non-flaky,5
98347,Kong_unirest-java,UriFormatterTest.basicBoringUri,"    @Test
    public void basicBoringUri() {
        assertLinkSurvives(""http://localhost/test?a=b"");
    }
",non-flaky,5
98348,Kong_unirest-java,UriFormatterTest.semicolonsAsParam,"    @Test
    public void semicolonsAsParam() {
        assertLinkSurvives(""http://localhost/test?a=b;foo=bar"");
    }
",non-flaky,5
98349,Kong_unirest-java,UriFormatterTest.utf8Chars,"    @Test
    public void utf8Chars(){
        assertLinkSurvives(""http://localhost/test?foo="");
    }
",non-flaky,5
98350,Kong_unirest-java,ClientFactoryTest.before,"    @AfterEach
    public void before(){
        Unirest.shutDown(true);
    }
",non-flaky,5
98351,Kong_unirest-java,JSONArrayTest.toString,"    @Test
        public String toString(){
            return ""Hello World"";
        }
",non-flaky,5
98352,Kong_unirest-java,JsonObjectMapperTest.getDate,"    @Test
        public Date getDate() {
            return date;
        }
",non-flaky,5
98353,Kong_unirest-java,ConsumerTest.tearDown,"    @AfterEach
    public void tearDown() {
        super.tearDown();
        asyncDone = false;
        status = 0;
        File file = test.toFile();
        if(file.exists()){
            file.delete();
        }
    }
",non-flaky,5
98354,Kong_unirest-java,AsObjectTest.writeValue,"    @Test
        public String writeValue(Object value) {
            writeWasCalled = true;
            return new Gson().toJson(value);
        }
",non-flaky,5
98355,Kong_unirest-java,ShutDownHooksTest.setUp,"    @Override @BeforeEach
    public void setUp() {
        super.setUp();
        clearUnirestHooks();
    }
",non-flaky,5
98356,Kong_unirest-java,AsGenericTypeTest.getSomeTees,"    @Test
        public T getSomeTees() {
            return someTees;
        }
",non-flaky,5
98357,Kong_unirest-java,CallbackFutureTest.completed,"    @Test @Disabled
                        public void completed(HttpResponse<JsonNode> response) {
                            throw new UnirestException(""Failure!"");
                        }
",non-flaky,5
98358,Kong_unirest-java,CallbackFutureTest.completed,"    @Test @Disabled
                    public void completed(HttpResponse<JsonNode> response) {
                        throw new UnirestException(""Failure!"");
                    }
",non-flaky,5
98359,Kong_unirest-java,DownloadProgressTest.setUp,"    @BeforeEach
    public void setUp() {
        super.setUp();
        this.monitor = new TestMonitor();
    }
",non-flaky,5
98360,Kong_unirest-java,PostRequestHandlersTest.tearDown,"    @AfterEach
    public void tearDown() {
        super.tearDown();
        captured = null;
    }
",non-flaky,5
98361,Kong_unirest-java,PostRequestHandlersTest.accept,"    @Test
        public void accept(HttpResponse<?> httpResponse) {

            this.httpResponse = httpResponse;
        }
",non-flaky,5
98362,Kong_unirest-java,AsFileTest.tearDown,"    @Override @AfterEach
    public void tearDown() {
        try {
            Files.delete(test);
        } catch (Exception ignored) { }
    }
",non-flaky,5
98363,Kong_unirest-java,CachingAlternativeTest.invalidate,"    @Test
        public void invalidate() {
            regular.invalidateAll();
            async.invalidateAll();
        }
",non-flaky,5
98364,Kong_unirest-java,ProxyTest.tearDown,"    @AfterEach
    public void tearDown() {
        super.tearDown();
        Unirest.shutDown(true);
        JankyProxy.shutdown();
    }
",non-flaky,5
98365,Kong_unirest-java,InterceptorTest.setUp,"    @BeforeEach
    public void setUp() {
        super.setUp();
        interceptor = new UniInterceptor(""x-custom"", ""foo"");
    }
",non-flaky,5
98366,Kong_unirest-java,InterceptorTest.onRequest,"    @Test
            public void onRequest(HttpRequest<?> request, Config config) {
                request.getBody().ifPresent(b ->
                        b.multiParts().forEach(part ->
                                values.add(part.toString())));
            }
",non-flaky,5
98367,Kong_unirest-java,CustomObjectMapperTest.setUp,"    @BeforeEach
    public void setUp() {
        super.setUp();
        customOm = Mockito.spy(JsonObjectMapper.class);
    }
",non-flaky,5
98368,Kong_unirest-java,UploadProgressTest.setUp,"    @Override @BeforeEach
    public void setUp() {
        super.setUp();
        this.monitor = new TestMonitor();
    }
",non-flaky,5
104610,apache_pinot,AggregateMetricsClusterIntegrationTest.testQueries,"  @Test
  public void testQueries()
      throws Exception {
    String sql = ""SELECT SUM(AirTime), SUM(ArrDelay) FROM mytable"";
    testSqlQuery(sql, Collections.singletonList(sql));
    sql = ""SELECT SUM(AirTime), DaysSinceEpoch FROM mytable GROUP BY DaysSinceEpoch ORDER BY SUM(AirTime) DESC"";
    testSqlQuery(sql, Collections.singletonList(sql));
    sql = ""SELECT Origin, SUM(ArrDelay) FROM mytable WHERE Carrier = 'AA' GROUP BY Origin ORDER BY Origin"";
    testSqlQuery(sql, Collections.singletonList(sql));
  }
",non-flaky,5
104611,apache_pinot,SegmentPartitionLLCRealtimeClusterIntegrationTest.testPartitionMetadata,"  @Test
  public void testPartitionMetadata() {
    int[] numSegmentsForPartition = new int[2];
    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(getTableName());
    List<SegmentZKMetadata> segmentsZKMetadata = _helixResourceManager.getSegmentsZKMetadata(realtimeTableName);
    for (SegmentZKMetadata segmentZKMetadata : segmentsZKMetadata) {
      SegmentPartitionMetadata segmentPartitionMetadata = segmentZKMetadata.getPartitionMetadata();
      assertNotNull(segmentPartitionMetadata);
      Map<String, ColumnPartitionMetadata> columnPartitionMetadataMap =
          segmentPartitionMetadata.getColumnPartitionMap();
      assertEquals(columnPartitionMetadataMap.size(), 1);
      ColumnPartitionMetadata columnPartitionMetadata = columnPartitionMetadataMap.get(PARTITION_COLUMN);
      assertNotNull(columnPartitionMetadata);
      assertTrue(columnPartitionMetadata.getFunctionName().equalsIgnoreCase(""murmur""));
      assertEquals(columnPartitionMetadata.getNumPartitions(), 2);
      int partitionGroupId = new LLCSegmentName(segmentZKMetadata.getSegmentName()).getPartitionGroupId();
      assertEquals(columnPartitionMetadata.getPartitions(), Collections.singleton(partitionGroupId));
      numSegmentsForPartition[partitionGroupId]++;
    }

    // There should be 2 segments for partition 0, 2 segments for partition 1
    assertEquals(numSegmentsForPartition[0], 2);
    assertEquals(numSegmentsForPartition[1], 2);
  }
",non-flaky,5
104612,apache_pinot,SegmentPartitionLLCRealtimeClusterIntegrationTest.testPartitionRouting,"  @Test(dependsOnMethods = ""testPartitionMetadata"")
  public void testPartitionRouting()
      throws Exception {
    // Query partition 0
    {
      String query = ""SELECT COUNT(*) FROM mytable WHERE DestState = 'CA'"";
      JsonNode response = postQuery(query);

      String queryToCompare = ""SELECT COUNT(*) FROM mytable WHERE DestState BETWEEN 'CA' AND 'CA'"";
      JsonNode responseToCompare = postQuery(queryToCompare);

      // Should only query the segments for partition 0
      assertEquals(response.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), 2);
      assertEquals(responseToCompare.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), 4);

      assertEquals(response.get(""aggregationResults"").get(0).get(""value"").asInt(),
          responseToCompare.get(""aggregationResults"").get(0).get(""value"").asInt());
    }

    // Query partition 1
    {
      String query = ""SELECT COUNT(*) FROM mytable WHERE DestState = 'FL'"";
      JsonNode response = postQuery(query);

      String queryToCompare = ""SELECT COUNT(*) FROM mytable WHERE DestState BETWEEN 'FL' AND 'FL'"";
      JsonNode responseToCompare = postQuery(queryToCompare);

      // Should only query the segments for partition 1
      assertEquals(response.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), 2);
      assertEquals(responseToCompare.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), 4);

      assertEquals(response.get(""aggregationResults"").get(0).get(""value"").asInt(),
          responseToCompare.get(""aggregationResults"").get(0).get(""value"").asInt());
    }
  }
",non-flaky,5
104613,apache_pinot,SegmentPartitionLLCRealtimeClusterIntegrationTest.testNonPartitionedStream,"  @Test(dependsOnMethods = ""testPartitionRouting"")
  public void testNonPartitionedStream()
      throws Exception {
    // Push the second Avro file into Kafka without partitioning
    _partitionColumn = null;
    pushAvroIntoKafka(Collections.singletonList(_avroFiles.get(1)));

    // Wait for all documents loaded
    _countStarResult += NUM_DOCS_IN_SECOND_AVRO_FILE;
    waitForAllDocsLoaded(600_000L);

    // Check partition metadata
    int[] numSegmentsForPartition = new int[2];
    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(getTableName());
    List<SegmentZKMetadata> segmentsZKMetadata = _helixResourceManager.getSegmentsZKMetadata(realtimeTableName);
    for (SegmentZKMetadata segmentZKMetadata : segmentsZKMetadata) {
      SegmentPartitionMetadata segmentPartitionMetadata = segmentZKMetadata.getPartitionMetadata();
      assertNotNull(segmentPartitionMetadata);
      Map<String, ColumnPartitionMetadata> columnPartitionMetadataMap =
          segmentPartitionMetadata.getColumnPartitionMap();
      assertEquals(columnPartitionMetadataMap.size(), 1);
      ColumnPartitionMetadata columnPartitionMetadata = columnPartitionMetadataMap.get(PARTITION_COLUMN);
      assertNotNull(columnPartitionMetadata);
      assertTrue(columnPartitionMetadata.getFunctionName().equalsIgnoreCase(""murmur""));
      assertEquals(columnPartitionMetadata.getNumPartitions(), 2);
      int partitionGroupId = new LLCSegmentName(segmentZKMetadata.getSegmentName()).getPartitionGroupId();
      numSegmentsForPartition[partitionGroupId]++;

      if (segmentZKMetadata.getStatus() == Status.IN_PROGRESS) {
        // For consuming segment, the partition metadata should only contain the stream partition
        assertEquals(columnPartitionMetadata.getPartitions(), Collections.singleton(partitionGroupId));
      } else {
        LLCSegmentName llcSegmentName = new LLCSegmentName(segmentZKMetadata.getSegmentName());
        int sequenceNumber = llcSegmentName.getSequenceNumber();
        if (sequenceNumber == 0) {
          // The partition metadata for the first completed segment should only contain the stream partition
          assertEquals(columnPartitionMetadata.getPartitions(), Collections.singleton(partitionGroupId));
        } else {
          // The partition metadata for the new completed segments should contain both partitions
          assertEquals(columnPartitionMetadata.getPartitions(), new HashSet<>(Arrays.asList(0, 1)));
        }
      }
    }

    // There should be 4 segments for partition 0, 4 segments for partition 1
    assertEquals(numSegmentsForPartition[0], 4);
    assertEquals(numSegmentsForPartition[1], 4);

    // Check partition routing
    int numSegments = segmentsZKMetadata.size();

    // Query partition 0
    {
      String query = ""SELECT COUNT(*) FROM mytable WHERE DestState = 'CA'"";
      JsonNode response = postQuery(query);

      String queryToCompare = ""SELECT COUNT(*) FROM mytable WHERE DestState BETWEEN 'CA' AND 'CA'"";
      JsonNode responseToCompare = postQuery(queryToCompare);

      // Should skip the first completed segments and the consuming segment for partition 1
      assertEquals(response.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments - 2);
      assertEquals(responseToCompare.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments);

      // The result won't match because the consuming segment for partition 1 is pruned out
    }

    // Query partition 1
    {
      String query = ""SELECT COUNT(*) FROM mytable WHERE DestState = 'FL'"";
      JsonNode response = postQuery(query);

      String queryToCompare = ""SELECT COUNT(*) FROM mytable WHERE DestState BETWEEN 'FL' AND 'FL'"";
      JsonNode responseToCompare = postQuery(queryToCompare);

      // Should skip the first completed segments and the consuming segment for partition 0
      assertEquals(response.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments - 2);
      assertEquals(responseToCompare.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments);

      // The result won't match because the consuming segment for partition 0 is pruned out
    }

    // Push the third Avro file into Kafka with partitioning
    _partitionColumn = PARTITION_COLUMN;
    pushAvroIntoKafka(Collections.singletonList(_avroFiles.get(2)));

    // Wait for all documents loaded
    _countStarResult += NUM_DOCS_IN_THIRD_AVRO_FILE;
    waitForAllDocsLoaded(600_000L);

    // Check partition metadata
    numSegmentsForPartition = new int[2];
    segmentsZKMetadata = _helixResourceManager.getSegmentsZKMetadata(realtimeTableName);
    for (SegmentZKMetadata segmentZKMetadata : segmentsZKMetadata) {
      SegmentPartitionMetadata segmentPartitionMetadata = segmentZKMetadata.getPartitionMetadata();
      assertNotNull(segmentPartitionMetadata);
      Map<String, ColumnPartitionMetadata> columnPartitionMetadataMap =
          segmentPartitionMetadata.getColumnPartitionMap();
      assertEquals(columnPartitionMetadataMap.size(), 1);
      ColumnPartitionMetadata columnPartitionMetadata = columnPartitionMetadataMap.get(PARTITION_COLUMN);
      assertNotNull(columnPartitionMetadata);
      assertTrue(columnPartitionMetadata.getFunctionName().equalsIgnoreCase(""murmur""));
      assertEquals(columnPartitionMetadata.getNumPartitions(), 2);
      int partitionGroupId = new LLCSegmentName(segmentZKMetadata.getSegmentName()).getPartitionGroupId();
      numSegmentsForPartition[partitionGroupId]++;

      if (segmentZKMetadata.getStatus() == Status.IN_PROGRESS) {
        // For consuming segment, the partition metadata should only contain the stream partition
        assertEquals(columnPartitionMetadata.getPartitions(), Collections.singleton(partitionGroupId));
      } else {
        // The partition metadata for the new completed segments should only contain the stream partition
        LLCSegmentName llcSegmentName = new LLCSegmentName(segmentZKMetadata.getSegmentName());
        int sequenceNumber = llcSegmentName.getSequenceNumber();
        if (sequenceNumber == 0 || sequenceNumber >= 4) {
          // The partition metadata for the first and new completed segments should only contain the stream partition
          assertEquals(columnPartitionMetadata.getPartitions(), Collections.singleton(partitionGroupId));
        } else {
          // The partition metadata for the completed segments containing records from the second Avro file should
          // contain both partitions
          assertEquals(columnPartitionMetadata.getPartitions(), new HashSet<>(Arrays.asList(0, 1)));
        }
      }
    }

    // There should be 6 segments for partition 0, 6 segments for partition 1
    assertEquals(numSegmentsForPartition[0], 6);
    assertEquals(numSegmentsForPartition[1], 6);

    // Check partition routing
    numSegments = segmentsZKMetadata.size();

    // Query partition 0
    {
      String query = ""SELECT COUNT(*) FROM mytable WHERE DestState = 'CA'"";
      JsonNode response = postQuery(query);

      String queryToCompare = ""SELECT COUNT(*) FROM mytable WHERE DestState BETWEEN 'CA' AND 'CA'"";
      JsonNode responseToCompare = postQuery(queryToCompare);

      // Should skip 2 completed segments and the consuming segment for partition 1
      assertEquals(response.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments - 3);
      assertEquals(responseToCompare.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments);

      // The result should match again after all the segments with the non-partitioning records are committed
      assertEquals(response.get(""aggregationResults"").get(0).get(""value"").asInt(),
          responseToCompare.get(""aggregationResults"").get(0).get(""value"").asInt());
    }

    // Query partition 1
    {
      String query = ""SELECT COUNT(*) FROM mytable WHERE DestState = 'FL'"";
      JsonNode response = postQuery(query);

      String queryToCompare = ""SELECT COUNT(*) FROM mytable WHERE DestState BETWEEN 'FL' AND 'FL'"";
      JsonNode responseToCompare = postQuery(queryToCompare);

      // Should skip 2 completed segments and the consuming segment for partition 0
      assertEquals(response.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments - 3);
      assertEquals(responseToCompare.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments);

      // The result should match again after all the segments with the non-partitioning records are committed
      assertEquals(response.get(""aggregationResults"").get(0).get(""value"").asInt(),
          responseToCompare.get(""aggregationResults"").get(0).get(""value"").asInt());
    }
  }
",non-flaky,5
104614,apache_pinot,NullHandlingIntegrationTest.testTotalCount,"  @Test
  public void testTotalCount()
      throws Exception {
    String query = ""SELECT count(*) FROM "" + getTableName();
    testQuery(query, Collections.singletonList(query));
  }
",non-flaky,5
104615,apache_pinot,NullHandlingIntegrationTest.testCountWithNullDescription,"  @Test
  public void testCountWithNullDescription()
      throws Exception {
    String query = ""SELECT count(*) FROM "" + getTableName() + "" where description IS NOT NULL"";
    testQuery(query, Collections.singletonList(query));
  }
",non-flaky,5
104616,apache_pinot,NullHandlingIntegrationTest.testCountWithNullDescriptionAndSalary,"  @Test
  public void testCountWithNullDescriptionAndSalary()
      throws Exception {
    String query = ""SELECT count(*) FROM "" + getTableName() + "" where description IS NOT NULL AND salary IS NOT NULL"";
    testQuery(query, Collections.singletonList(query));
  }
",non-flaky,5
104617,apache_pinot,ChaosMonkeyIntegrationTest.testShortZookeeperFreeze,"  @Test(enabled = false)
  public void testShortZookeeperFreeze()
      throws Exception {
    testFreezeZookeeper(10000L);
  }
",non-flaky,5
104618,apache_pinot,ChaosMonkeyIntegrationTest.testLongZookeeperFreeze,"  @Test(enabled = false)
  public void testLongZookeeperFreeze()
      throws Exception {
    testFreezeZookeeper(60000L);
  }
",non-flaky,5
104619,apache_pinot,RealtimeClusterIntegrationTest.testQueriesFromQueryFile,"  @Test
  public void testQueriesFromQueryFile()
      throws Exception {
    super.testQueriesFromQueryFile();
  }
",non-flaky,5
104620,apache_pinot,RealtimeClusterIntegrationTest.testGeneratedQueriesWithMultiValues,"  @Test
  public void testGeneratedQueriesWithMultiValues()
      throws Exception {
    super.testGeneratedQueriesWithMultiValues();
  }
",non-flaky,5
104621,apache_pinot,RealtimeClusterIntegrationTest.testDictionaryBasedQueries,"  @Test
  public void testDictionaryBasedQueries()
      throws Exception {

    // Dictionary columns
    // int
    testDictionaryBasedFunctions(""NASDelay"");

    // long
    testDictionaryBasedFunctions(""AirlineID"");

    // double
    testDictionaryBasedFunctions(""ArrDelayMinutes"");

    // float
    testDictionaryBasedFunctions(""DepDelayMinutes"");

    // Non Dictionary columns
    // int
    testDictionaryBasedFunctions(""ActualElapsedTime"");

    // double
    testDictionaryBasedFunctions(""DepDelay"");

    // float
    testDictionaryBasedFunctions(""ArrDelay"");
  }
",non-flaky,5
104622,apache_pinot,RealtimeClusterIntegrationTest.testQueryExceptions,"  @Test
  public void testQueryExceptions()
      throws Exception {
    super.testQueryExceptions();
  }
",non-flaky,5
104623,apache_pinot,RealtimeClusterIntegrationTest.testInstanceShutdown,"  @Test
  public void testInstanceShutdown()
      throws Exception {
    super.testInstanceShutdown();
  }
",non-flaky,5
104624,apache_pinot,RealtimeClusterIntegrationTest.testHardcodedSqlQueries,"  @Test
  public void testHardcodedSqlQueries()
      throws Exception {
    super.testHardcodedSqlQueries();
  }
",non-flaky,5
104625,apache_pinot,RealtimeClusterIntegrationTest.testSqlQueriesFromQueryFile,"  @Test
  public void testSqlQueriesFromQueryFile()
      throws Exception {
    super.testSqlQueriesFromQueryFile();
  }
",non-flaky,5
104626,apache_pinot,MergeRollupMinionClusterIntegrationTest.testSingleLevelConcat,"  @Test
  public void testSingleLevelConcat()
      throws Exception {
    // The original segments are time partitioned by month:
    // segmentName (totalDocs)
    // myTable1_16071_16101_3 (9746)
    // myTable1_16102_16129_4 (8690)
    // myTable1_16130_16159_5 (9621)
    // myTable1_16160_16189_6 (9454)
    // myTable1_16190_16220_7 (10329)
    // myTable1_16221_16250_8 (10468)
    // myTable1_16251_16281_9 (10499)
    // myTable1_16282_16312_10 (10196)
    // myTable1_16313_16342_11 (9136)
    // myTable1_16343_16373_0 (9292)
    // myTable1_16374_16404_1 (8736)
    // myTable1_16405_16435_2 (9378)

    // Expected merge tasks and result segments:
    // 1.
    //    {myTable1_16071_16101_3}
    //      -> {merged_100days_T1_0_myTable1_16071_16099_0, merged_100days_T1_0_myTable1_16100_16101_1}
    // 2.
    //    {merged_100days_T1_0_myTable1_16100_16101_1, myTable1_16102_16129_4, myTable1_16130_16159_5}
    //      -> {merged_100days_T2_0_myTable1_16100_???_0(15000), merged_100days_T2_0_myTable1_???_16159_1}
    //    {myTable1_16160_16189_6, myTable1_16190_16220_7}
    //      -> {merged_100days_T2_1_myTable1_16160_16199_0, merged_100days_T2_1_myTable1_16200_16220_1}
    // 3.
    //    {merged_100days_T2_1_myTable1_16200_16220_1, myTable1_16221_16250_8}
    //      -> {merged_100days_T3_0_myTable1_16200_???_0(15000), merged_100days_T3_0_myTable1_???_16250_1}
    //    {myTable1_16251_16281_9, myTable1_16282_16312_10}
    //      -> {merged_100days_T3_1_myTable1_16251_???_0(15000), merged_100days_T3_1_myTable1_???_16299_1,
    //      merged_100days_T3_1_myTable1_16300_16312_2}
    // 4.
    //    {merged_100days_T3_1_myTable1_16300_16312_2, myTable1_16313_16342_11, myTable1_16343_16373_0}
    //      -> {merged_100days_T4_0_myTable1_16300_???_0(15000), merged_100days_T4_0_myTable1_???_16373_1}
    //    {myTable1_16374_16404_1}
    //      -> {merged_100days_T4_1_16374_16399_0, merged_100days_T4_1_16400_16404_1}
    // 5.
    //    {merged_100days_T4_1_16400_16404_1, myTable1_16405_16435_2}
    //      -> {merged_100days_T5_0_myTable1_16400_16435_0}

    String sqlQuery = ""SELECT count(*) FROM myTable1""; // 115545 rows for the test table
    JsonNode expectedJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    int[] expectedNumSubTasks = {1, 2, 2, 2, 1};
    int[] expectedNumSegmentsQueried = {13, 12, 13, 13, 12};
    long expectedWatermark = 16000 * 86_400_000L;
    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(SINGLE_LEVEL_CONCAT_TEST_TABLE);
    int numTasks = 0;
    for (String tasks = _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE);
        tasks != null; tasks =
        _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE), numTasks++) {
      assertEquals(_helixTaskResourceManager.getTaskConfigs(tasks).size(), expectedNumSubTasks[numTasks]);
      assertTrue(_helixTaskResourceManager.getTaskQueues()
          .contains(PinotHelixTaskResourceManager.getHelixJobQueueName(MinionConstants.MergeRollupTask.TASK_TYPE)));
      // Will not schedule task if there's incomplete task
      assertNull(
          _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.RealtimeToOfflineSegmentsTask.TASK_TYPE));
      waitForTaskToComplete();

      // Check watermark
      MergeRollupTaskMetadata minionTaskMetadata = MergeRollupTaskMetadata
          .fromZNRecord(_taskManager.getClusterInfoAccessor().getMinionMergeRollupTaskZNRecord(offlineTableName));
      assertNotNull(minionTaskMetadata);
      assertEquals((long) minionTaskMetadata.getWatermarkMap().get(""100days""), expectedWatermark);
      expectedWatermark += 100 * 86_400_000L;

      // Check metadata of merged segments
      for (SegmentZKMetadata metadata : _pinotHelixResourceManager.getSegmentsZKMetadata(offlineTableName)) {
        if (metadata.getSegmentName().startsWith(""merged"")) {
          // Check merged segment zk metadata
          assertNotNull(metadata.getCustomMap());
          assertEquals(""100days"",
              metadata.getCustomMap().get(MinionConstants.MergeRollupTask.SEGMENT_ZK_METADATA_MERGE_LEVEL_KEY));
          // Check merged segments are time partitioned
          assertEquals(metadata.getEndTimeMs() / (86_400_000L * 100), metadata.getStartTimeMs() / (86_400_000L * 100));
        }
      }

      // Check num total doc of merged segments are the same as the original segments
      JsonNode actualJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
      SqlResultComparator.areEqual(actualJson, expectedJson, sqlQuery);
      // Check query routing
      int numSegmentsQueried = actualJson.get(""numSegmentsQueried"").asInt();
      assertEquals(numSegmentsQueried, expectedNumSegmentsQueried[numTasks]);
    }
    // Check total tasks
    assertEquals(numTasks, 5);

    assertTrue(_controllerStarter.getControllerMetrics()
        .containsGauge(""mergeRollupTaskDelayInNumBuckets.myTable1_OFFLINE.100days""));

    // Drop the table
    dropOfflineTable(SINGLE_LEVEL_CONCAT_TEST_TABLE);

    // Check if the task metadata is cleaned up on table deletion
    verifyTableDelete(offlineTableName);
  }
",non-flaky,5
104627,apache_pinot,MergeRollupMinionClusterIntegrationTest.testSingleLevelRollup,"  @Test
  public void testSingleLevelRollup()
      throws Exception {
    // The original segments are time partitioned by month:
    // segmentName (totalDocs)
    // myTable2_16071_16101_3_1, myTable2_16071_16101_3_2 (9746)
    // myTable2_16102_16129_4_1, myTable2_16102_16129_4_2 (8690)
    // myTable2_16130_16159_5_1, myTable2_16130_16159_5_2 (9621)
    // myTable2_16160_16189_6_1, myTable2_16160_16189_6_2 (9454)
    // myTable2_16190_16220_7_1, myTable2_16190_16220_7_2 (10329)
    // myTable2_16221_16250_8_1, myTable2_16221_16250_8_2 (10468)
    // myTable2_16251_16281_9_1, myTable2_16251_16281_9_2 (10499)
    // myTable2_16282_16312_10_1, myTable2_16282_16312_10_2 (10196)
    // myTable2_16313_16342_11_1, myTable2_16313_16342_11_2 (9136)
    // myTable2_16343_16373_0_1, myTable2_16343_16373_0_2 (9292)
    // myTable2_16374_16404_1_1, myTable2_16374_16404_1_2 (8736)
    // myTable2_16405_16435_2_1, myTable2_16405_16435_2_2 (9378)

    // Expected merge tasks and result segments:
    // 1.
    //    {myTable2_16071_16101_3_1, myTable2_16071_16101_3_2, myTable2_16102_16129_4_1, myTable2_16102_16129_4_2,
    //     myTable2_16130_16159_5_1, myTable2_16130_16159_5_2, myTable2_16160_16189_6_1, myTable2_16160_16189_6_2
    //     myTable2_16190_16220_7}
    //      -> {merged_150days_T1_0_myTable2_16065_16198_0, merged_150days_T1_0_myTable2_16205_16219_1}
    // 2.
    //    {merged_150days_T1_0_myTable2_16205_16219_1, myTable2_16221_16250_8_1, myTable2_16221_16250_8_2,
    //     myTable2_16251_16281_9_1, myTable2_16251_16281_9_2, myTable2_16282_16312_10_1
    //     myTable2_16282_16312_10_2, myTable2_16313_16342_11_1, myTable2_16313_16342_11_2,
    //     myTable2_16343_16373_0_1, myTable2_16343_16373_0_2}
    //      -> {merged_150days_1628644088146_0_myTable2_16205_16345_0,
    //          merged_150days_1628644088146_0_myTable2_16352_16373_1}
    // 3.
    //    {merged_150days_1628644088146_0_myTable2_16352_16373_1, myTable2_16374_16404_1_1, myTable2_16374_16404_1_2
    //     myTable2_16405_16435_2_1, myTable2_16405_16435_2_2}
    //      -> {merged_150days_1628644105127_0_myTable2_16352_16429_0}

    String sqlQuery = ""SELECT count(*) FROM myTable2""; // 115545 rows for the test table
    JsonNode expectedJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    int[] expectedNumSegmentsQueried = {16, 7, 3};
    long expectedWatermark = 16050 * 86_400_000L;
    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(SINGLE_LEVEL_ROLLUP_TEST_TABLE);
    int numTasks = 0;
    for (String tasks = _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE);
        tasks != null; tasks =
        _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE), numTasks++) {
      assertEquals(_helixTaskResourceManager.getTaskConfigs(tasks).size(), 1);
      assertTrue(_helixTaskResourceManager.getTaskQueues()
          .contains(PinotHelixTaskResourceManager.getHelixJobQueueName(MinionConstants.MergeRollupTask.TASK_TYPE)));
      // Will not schedule task if there's incomplete task
      assertNull(
          _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.RealtimeToOfflineSegmentsTask.TASK_TYPE));
      waitForTaskToComplete();

      // Check watermark
      MergeRollupTaskMetadata minionTaskMetadata = MergeRollupTaskMetadata
          .fromZNRecord(_taskManager.getClusterInfoAccessor().getMinionMergeRollupTaskZNRecord(offlineTableName));
      assertNotNull(minionTaskMetadata);
      assertEquals((long) minionTaskMetadata.getWatermarkMap().get(""150days""), expectedWatermark);
      expectedWatermark += 150 * 86_400_000L;

      // Check metadata of merged segments
      for (SegmentZKMetadata metadata : _pinotHelixResourceManager.getSegmentsZKMetadata(offlineTableName)) {
        if (metadata.getSegmentName().startsWith(""merged"")) {
          // Check merged segment zk metadata
          assertNotNull(metadata.getCustomMap());
          assertEquals(""150days"",
              metadata.getCustomMap().get(MinionConstants.MergeRollupTask.SEGMENT_ZK_METADATA_MERGE_LEVEL_KEY));
          // Check merged segments are time partitioned
          assertEquals(metadata.getEndTimeMs() / (86_400_000L * 150), metadata.getStartTimeMs() / (86_400_000L * 150));
        }
      }

      // Check total doc of merged segments are less than the original segments
      JsonNode actualJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
      assertTrue(
          actualJson.get(""resultTable"").get(""rows"").get(0).get(0).asInt() < expectedJson.get(""resultTable"").get(""rows"")
              .get(0).get(0).asInt());
      // Check query routing
      int numSegmentsQueried = actualJson.get(""numSegmentsQueried"").asInt();
      assertEquals(numSegmentsQueried, expectedNumSegmentsQueried[numTasks]);
    }

    // Check total doc is half of the original after all merge tasks are finished
    JsonNode actualJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    assertEquals(actualJson.get(""resultTable"").get(""rows"").get(0).get(0).asInt(),
        expectedJson.get(""resultTable"").get(""rows"").get(0).get(0).asInt() / 2);
    // Check time column is rounded
    JsonNode responseJson =
        postSqlQuery(""SELECT count(*), DaysSinceEpoch FROM myTable2 GROUP BY DaysSinceEpoch ORDER BY DaysSinceEpoch"");
    for (int i = 0; i < responseJson.get(""resultTable"").get(""rows"").size(); i++) {
      int daysSinceEpoch = responseJson.get(""resultTable"").get(""rows"").get(i).get(1).asInt();
      assertTrue(daysSinceEpoch % 7 == 0);
    }
    // Check total tasks
    assertEquals(numTasks, 3);

    assertTrue(_controllerStarter.getControllerMetrics()
        .containsGauge(""mergeRollupTaskDelayInNumBuckets.myTable2_OFFLINE.150days""));
  }
",non-flaky,5
104628,apache_pinot,MergeRollupMinionClusterIntegrationTest.testMultiLevelConcat,"  @Test
  public void testMultiLevelConcat()
      throws Exception {
    // The original segments are time partitioned by month:
    // segmentName (totalDocs)
    // myTable3_16071_16101_3 (9746)
    // myTable3_16102_16129_4 (8690)
    // myTable3_16130_16159_5 (9621)
    // myTable3_16160_16189_6 (9454)
    // myTable3_16190_16220_7 (10329)
    // myTable3_16221_16250_8 (10468)
    // myTable3_16251_16281_9 (10499)
    // myTable3_16282_16312_10 (10196)
    // myTable3_16313_16342_11 (9136)
    // myTable3_16343_16373_0 (9292)
    // myTable3_16374_16404_1 (8736)
    // myTable3_16405_16435_2 (9378)

    // Expected merge tasks and results:
    // 1.
    //    45days: {myTable3_16071_16101_3, myTable3_16102_16129_4}
    //      -> {merged_45days_T1_0_myTable3_16071_16109_0, merged_45days_T1_0_myTable3_16110_16129_1}
    //    watermark: {45days: 16065, 90days: null}
    // 2.
    //    45days: {merged_45days_T1_0_myTable3_16110_16129_1, myTable3_16130_16159_5}
    //      -> {merged_45days_T2_0_myTable3_16110_16154_0, merged_45days_T2_0_myTable3_16155_16159_1}
    //    90days: {merged_45days_T1_0_myTable3_16071_16109_0}
    //      -> {merged_90days_T2_0_myTable3_16071_16109_0}
    //    watermark: {45days: 16110, 90days: 16020}
    // 3.
    //    45days: {merged_45days_T2_0_myTable3_16155_16159_1, myTable3_16160_16189_6, myTable3_16190_16220_7}
    //      -> {merged_45days_T3_0_myTable3_16155_16199_0, merged_45days_T3_0_myTable3_16200_16220_1}
    //    watermark: {45days: 16155, 90days: 16020}
    // 4.
    //    45days: {merged_45days_T3_-_myTable3_16200_16220_1, myTable3_16221_16250_8}
    //      -> {merged_45days_T4_0_myTable3_16200_16244_0, merged_45days_T4_0_myTable3_16245_16250_1}
    //    90days: {merged_45days_T2_0_myTable3_16110_16154_0, merged_45days_T3_0_myTable3_16155_16199_0}
    //      -> {merged_90days_T4_0_myTable3_16110_16199_0}
    //    watermark: {45days: 16200, 90days: 16110}
    // 5.
    //    45days: {merged_45days_T4_0_myTable3_16245_16250_1, myTable3_16251_16281_9, myTable3_16282_16312_10}
    //      -> {merged_45days_T5_0_myTable3_16245_16289_0, merged_45days_T5_0_myTable3_16290_16312_1}
    //    watermark: {45days: 16245, 90days: 16110}
    // 6.
    //    45days: {merged_45days_T5_0_myTable3_16290_16312_1, myTable3_16313_16342_11}
    //      -> {merged_45days_T6_0_myTable3_16290_16334_0, merged_45days_T6_0_myTable3_16335_16342_1}
    //    90days: {merged_45days_T4_0_myTable3_16200_16244_0, merged_45days_T5_0_myTable3_16245_16289_0}
    //      -> {merged_90days_T6_0_myTable3_16200_16289_0}
    //    watermark: {45days: 16290, 90days: 16200}
    // 7.
    //    45days: {merged_45days_T6_0_myTable3_16335_16342_1, myTable_16343_16373_0, myTable_16374_16404_1}
    //      -> {merged_45days_T7_0_myTable3_16335_16379_0, merged_45days_T7_0_myTable3_16380_16404_1}
    //    watermark: {45days: 16335, 90days: 16200}
    // 8.
    //    45days: {merged_45days_T7_0_myTable3_16380_16404_1, myTable3_16405_16435_2}
    //      -> {merged_45days_T8_0_myTable3_16380_16424_0, merged_45days_T8_1_myTable3_16425_16435_1}
    //    90days: {merged_45days_T6_0_myTable3_16290_16334_0, merged_45days_T7_0_myTable3_16335_16379_0}
    //      -> {merged_90days_T8_0_myTable3_16290_16379_0}
    //    watermark: {45days:16380, 90days: 16290}
    // 9.
    //    45days: no segment left, not scheduling
    //    90days: [16380, 16470) is not a valid merge window because windowEndTime > 45days watermark, not scheduling

    String sqlQuery = ""SELECT count(*) FROM myTable3""; // 115545 rows for the test table
    JsonNode expectedJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    int[] expectedNumSubTasks = {1, 2, 1, 2, 1, 2, 1, 2, 1};
    int[] expectedNumSegmentsQueried = {12, 12, 11, 10, 9, 8, 7, 6, 5};
    Long[] expectedWatermarks45Days = {16065L, 16110L, 16155L, 16200L, 16245L, 16290L, 16335L, 16380L};
    Long[] expectedWatermarks90Days = {null, 16020L, 16020L, 16110L, 16110L, 16200L, 16200L, 16290L};
    for (int i = 0; i < expectedWatermarks45Days.length; i++) {
      expectedWatermarks45Days[i] *= 86_400_000L;
    }
    for (int i = 1; i < expectedWatermarks90Days.length; i++) {
      expectedWatermarks90Days[i] *= 86_400_000L;
    }

    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(MULTI_LEVEL_CONCAT_TEST_TABLE);
    int numTasks = 0;
    for (String tasks = _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE);
        tasks != null; tasks =
        _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE), numTasks++) {
      assertEquals(_helixTaskResourceManager.getTaskConfigs(tasks).size(), expectedNumSubTasks[numTasks]);
      assertTrue(_helixTaskResourceManager.getTaskQueues()
          .contains(PinotHelixTaskResourceManager.getHelixJobQueueName(MinionConstants.MergeRollupTask.TASK_TYPE)));
      // Will not schedule task if there's incomplete task
      assertNull(
          _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.RealtimeToOfflineSegmentsTask.TASK_TYPE));
      waitForTaskToComplete();

      // Check watermark
      MergeRollupTaskMetadata minionTaskMetadata = MergeRollupTaskMetadata
          .fromZNRecord(_taskManager.getClusterInfoAccessor().getMinionMergeRollupTaskZNRecord(offlineTableName));
      assertNotNull(minionTaskMetadata);
      assertEquals(minionTaskMetadata.getWatermarkMap().get(""45days""), expectedWatermarks45Days[numTasks]);
      assertEquals(minionTaskMetadata.getWatermarkMap().get(""90days""), expectedWatermarks90Days[numTasks]);

      // Check metadata of merged segments
      for (SegmentZKMetadata metadata : _pinotHelixResourceManager.getSegmentsZKMetadata(offlineTableName)) {
        if (metadata.getSegmentName().startsWith(""merged"")) {
          // Check merged segment zk metadata
          assertNotNull(metadata.getCustomMap());
          if (metadata.getSegmentName().startsWith(""merged_45days"")) {
            assertEquals(""45days"",
                metadata.getCustomMap().get(MinionConstants.MergeRollupTask.SEGMENT_ZK_METADATA_MERGE_LEVEL_KEY));
            assertEquals(metadata.getEndTimeMs() / (86_400_000L * 45), metadata.getStartTimeMs() / (86_400_000L * 45));
          }
          if (metadata.getSegmentName().startsWith(""merged_90days"")) {
            assertEquals(""90days"",
                metadata.getCustomMap().get(MinionConstants.MergeRollupTask.SEGMENT_ZK_METADATA_MERGE_LEVEL_KEY));
            assertEquals(metadata.getEndTimeMs() / (86_400_000L * 90), metadata.getStartTimeMs() / (86_400_000L * 90));
          }
        }
      }

      // Check total doc of merged segments are the same as the original segments
      JsonNode actualJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
      SqlResultComparator.areEqual(actualJson, expectedJson, sqlQuery);
      // Check query routing
      int numSegmentsQueried = actualJson.get(""numSegmentsQueried"").asInt();
      assertEquals(numSegmentsQueried, expectedNumSegmentsQueried[numTasks]);
    }
    // Check total tasks
    assertEquals(numTasks, 8);

    assertTrue(_controllerStarter.getControllerMetrics()
        .containsGauge(""mergeRollupTaskDelayInNumBuckets.myTable3_OFFLINE.45days""));
    assertTrue(_controllerStarter.getControllerMetrics()
        .containsGauge(""mergeRollupTaskDelayInNumBuckets.myTable3_OFFLINE.90days""));
  }
",non-flaky,5
104629,apache_pinot,OfflineClusterIntegrationTest.testInstancesStarted,"  @Test
  public void testInstancesStarted() {
    assertEquals(_serviceStatusCallbacks.size(), getNumBrokers() + getNumServers());
    for (ServiceStatus.ServiceStatusCallback serviceStatusCallback : _serviceStatusCallbacks) {
      assertEquals(serviceStatusCallback.getServiceStatus(), ServiceStatus.Status.GOOD);
    }
  }
",non-flaky,5
104630,apache_pinot,OfflineClusterIntegrationTest.testInvalidTableConfig,"  @Test
  public void testInvalidTableConfig() {
    TableConfig tableConfig = new TableConfigBuilder(TableType.OFFLINE).setTableName(""badTable"").build();
    ObjectNode tableConfigJson = (ObjectNode) tableConfig.toJsonNode();
    // Remove a mandatory field
    tableConfigJson.remove(TableConfig.VALIDATION_CONFIG_KEY);
    try {
      sendPostRequest(_controllerRequestURLBuilder.forTableCreate(), tableConfigJson.toString());
      fail();
    } catch (IOException e) {
      // Should get response code 400 (BAD_REQUEST)
      assertTrue(e.getMessage().startsWith(""Server returned HTTP response code: 400""));
    }
  }
",non-flaky,5
104631,apache_pinot,OfflineClusterIntegrationTest.testRefreshTableConfigAndQueryTimeout,"  @Test
  public void testRefreshTableConfigAndQueryTimeout()
      throws Exception {
    // Set timeout as 5ms so that query will timeout
    TableConfig tableConfig = getOfflineTableConfig();
    tableConfig.setQueryConfig(new QueryConfig(5L));
    updateTableConfig(tableConfig);

    // Wait for at most 1 minute for broker to receive and process the table config refresh message
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_TIMEOUT_QUERY);
        JsonNode exceptions = queryResponse.get(""exceptions"");
        if (exceptions.isEmpty()) {
          return false;
        }
        int errorCode = exceptions.get(0).get(""errorCode"").asInt();
        if (errorCode == QueryException.BROKER_TIMEOUT_ERROR_CODE) {
          // Timed out on broker side
          return true;
        }
        if (errorCode == QueryException.SERVER_NOT_RESPONDING_ERROR_CODE) {
          // Timed out on server side
          int numServersQueried = queryResponse.get(""numServersQueried"").asInt();
          int numServersResponded = queryResponse.get(""numServersResponded"").asInt();
          int numDocsScanned = queryResponse.get(""numDocsScanned"").asInt();
          return numServersQueried == getNumServers() && numServersResponded == 0 && numDocsScanned == 0;
        }
        return false;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 60_000L, ""Failed to refresh table config"");

    // Remove timeout so that query will finish
    tableConfig.setQueryConfig(null);
    updateTableConfig(tableConfig);

    // Wait for at most 1 minute for broker to receive and process the table config refresh message
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_TIMEOUT_QUERY);
        JsonNode exceptions = queryResponse.get(""exceptions"");
        if (!exceptions.isEmpty()) {
          return false;
        }
        int numServersQueried = queryResponse.get(""numServersQueried"").asInt();
        int numServersResponded = queryResponse.get(""numServersResponded"").asInt();
        int numDocsScanned = queryResponse.get(""numDocsScanned"").asInt();
        return numServersQueried == getNumServers() && numServersResponded == getNumServers()
            && numDocsScanned == getCountStarResult();
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 60_000L, ""Failed to refresh table config"");
  }
",non-flaky,5
104632,apache_pinot,OfflineClusterIntegrationTest.testUploadSameSegments,"  @Test
  public void testUploadSameSegments()
      throws Exception {
    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(getTableName());
    SegmentZKMetadata segmentZKMetadata = _helixResourceManager.getSegmentsZKMetadata(offlineTableName).get(0);
    String segmentName = segmentZKMetadata.getSegmentName();
    long crc = segmentZKMetadata.getCrc();
    // Creation time is when the segment gets created
    long creationTime = segmentZKMetadata.getCreationTime();
    // Push time is when the segment gets first pushed (new segment)
    long pushTime = segmentZKMetadata.getPushTime();
    // Refresh time is when the segment gets refreshed (existing segment)
    long refreshTime = segmentZKMetadata.getRefreshTime();

    uploadSegments(offlineTableName, _tarDir);
    for (SegmentZKMetadata segmentZKMetadataAfterUpload : _helixResourceManager
        .getSegmentsZKMetadata(offlineTableName)) {
      // Only check one segment
      if (segmentZKMetadataAfterUpload.getSegmentName().equals(segmentName)) {
        assertEquals(segmentZKMetadataAfterUpload.getCrc(), crc);
        assertEquals(segmentZKMetadataAfterUpload.getCreationTime(), creationTime);
        assertEquals(segmentZKMetadataAfterUpload.getPushTime(), pushTime);
        // Refresh time should change
        assertTrue(segmentZKMetadataAfterUpload.getRefreshTime() > refreshTime);
        return;
      }
    }
  }
",non-flaky,5
104633,apache_pinot,OfflineClusterIntegrationTest.testUploadSegmentRefreshOnly,"  @Test
  public void testUploadSegmentRefreshOnly()
      throws Exception {
    TableConfig segmentUploadTestTableConfig =
        new TableConfigBuilder(TableType.OFFLINE).setTableName(SEGMENT_UPLOAD_TEST_TABLE).setSchemaName(getSchemaName())
            .setTimeColumnName(getTimeColumnName()).setSortedColumn(getSortedColumn())
            .setInvertedIndexColumns(getInvertedIndexColumns()).setNoDictionaryColumns(getNoDictionaryColumns())
            .setRangeIndexColumns(getRangeIndexColumns()).setBloomFilterColumns(getBloomFilterColumns())
            .setFieldConfigList(getFieldConfigs()).setNumReplicas(getNumReplicas())
            .setSegmentVersion(getSegmentVersion())
            .setLoadMode(getLoadMode()).setTaskConfig(getTaskConfig()).setBrokerTenant(getBrokerTenant())
            .setServerTenant(getServerTenant()).setIngestionConfig(getIngestionConfig())
            .setNullHandlingEnabled(getNullHandlingEnabled()).build();
    addTableConfig(segmentUploadTestTableConfig);
    String offlineTableName = segmentUploadTestTableConfig.getTableName();
    File[] segmentTarFiles = _tarDir.listFiles();
    assertNotNull(segmentTarFiles);
    int numSegments = segmentTarFiles.length;
    assertTrue(numSegments > 0);
    List<Header> headers = new ArrayList<>();
    headers.add(new BasicHeader(FileUploadDownloadClient.CustomHeaders.REFRESH_ONLY, ""true""));
    List<NameValuePair> parameters = new ArrayList<>();
    NameValuePair tableNameParameter = new BasicNameValuePair(FileUploadDownloadClient.QueryParameters.TABLE_NAME,
        TableNameBuilder.extractRawTableName(offlineTableName));
    parameters.add(tableNameParameter);

    URI uploadSegmentHttpURI = FileUploadDownloadClient.getUploadSegmentHttpURI(LOCAL_HOST, _controllerPort);
    try (FileUploadDownloadClient fileUploadDownloadClient = new FileUploadDownloadClient()) {
      // Refresh non-existing segment
      File segmentTarFile = segmentTarFiles[0];
      try {
        fileUploadDownloadClient
            .uploadSegment(uploadSegmentHttpURI, segmentTarFile.getName(), segmentTarFile, headers, parameters,
                FileUploadDownloadClient.DEFAULT_SOCKET_TIMEOUT_MS);
        fail();
      } catch (HttpErrorStatusException e) {
        assertEquals(e.getStatusCode(), HttpStatus.SC_GONE);
        assertTrue(_helixResourceManager.getSegmentsZKMetadata(SEGMENT_UPLOAD_TEST_TABLE).isEmpty());
      }

      // Upload segment
      SimpleHttpResponse response = fileUploadDownloadClient
          .uploadSegment(uploadSegmentHttpURI, segmentTarFile.getName(), segmentTarFile, null, parameters,
              FileUploadDownloadClient.DEFAULT_SOCKET_TIMEOUT_MS);
      assertEquals(response.getStatusCode(), HttpStatus.SC_OK);
      System.out.println(response.getResponse());
      List<SegmentZKMetadata> segmentsZKMetadata = _helixResourceManager.getSegmentsZKMetadata(offlineTableName);
      assertEquals(segmentsZKMetadata.size(), 1);

      // Refresh existing segment
      response = fileUploadDownloadClient
          .uploadSegment(uploadSegmentHttpURI, segmentTarFile.getName(), segmentTarFile, headers, parameters,
              FileUploadDownloadClient.DEFAULT_SOCKET_TIMEOUT_MS);
      assertEquals(response.getStatusCode(), HttpStatus.SC_OK);
      segmentsZKMetadata = _helixResourceManager.getSegmentsZKMetadata(offlineTableName);
      assertEquals(segmentsZKMetadata.size(), 1);
      assertNotEquals(segmentsZKMetadata.get(0).getRefreshTime(), Long.MIN_VALUE);
    }
    dropOfflineTable(SEGMENT_UPLOAD_TEST_TABLE);
  }
",non-flaky,5
104634,apache_pinot,OfflineClusterIntegrationTest.testInvertedIndexTriggering,"  @Test(dependsOnMethods = ""testRangeIndexTriggering"")
  public void testInvertedIndexTriggering()
      throws Exception {
    long numTotalDocs = getCountStarResult();

    // Without index on DivActualElapsedTime, all docs are scanned at filtering stage.
    assertEquals(postQuery(TEST_UPDATED_INVERTED_INDEX_QUERY).get(""numEntriesScannedInFilter"").asLong(), numTotalDocs);

    addInvertedIndex();
    long tableSizeWithNewIndex = getTableSize(getTableName());

    // Update table config to remove the new inverted index, and
    // reload table to clean the new inverted indices physically.
    TableConfig tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setInvertedIndexColumns(getInvertedIndexColumns());
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_INVERTED_INDEX_QUERY);
        // Total docs should not change during reload, but num entries scanned
        // gets back to total number of documents as the index is removed.
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numEntriesScannedInFilter"").asLong() == numTotalDocs;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to cleanup obsolete index"");
    assertEquals(getTableSize(getTableName()), _tableSizeAfterRemovingIndex);

    // Add the inverted index back to test index removal via force download.
    addInvertedIndex();
    long tableSizeAfterAddingIndexAgain = getTableSize(getTableName());
    assertEquals(tableSizeAfterAddingIndexAgain, tableSizeWithNewIndex);

    // Update table config to remove the new inverted index.
    tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setInvertedIndexColumns(getInvertedIndexColumns());
    updateTableConfig(tableConfig);

    // Force to download a single segment, and disk usage should drop a bit.
    SegmentZKMetadata segmentZKMetadata =
        _helixResourceManager.getSegmentsZKMetadata(TableNameBuilder.OFFLINE.tableNameWithType(getTableName())).get(0);
    String segmentName = segmentZKMetadata.getSegmentName();
    reloadOfflineSegment(getTableName(), segmentName, true);
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_INVERTED_INDEX_QUERY);
        // Total docs should not change during reload
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return getTableSize(getTableName()) < tableSizeAfterAddingIndexAgain;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to clean up obsolete index in segment"");

    // Force to download the whole table and expect disk usage drops further.
    reloadOfflineTable(getTableName(), true);
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_INVERTED_INDEX_QUERY);
        // Total docs should not change during reload, but num entries scanned
        // gets back to total number of documents as the index is removed.
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numEntriesScannedInFilter"").asLong() == numTotalDocs;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to cleanup obsolete index in table"");
    // With force download, the table size gets back to the initial value.
    assertEquals(getTableSize(getTableName()), DISK_SIZE_IN_BYTES);
  }
",non-flaky,5
104635,apache_pinot,OfflineClusterIntegrationTest.testTimeFunc,"  @Test
  public void testTimeFunc()
      throws Exception {
    String sqlQuery = ""SELECT toDateTime(now(), 'yyyy-MM-dd z'), toDateTime(ago('PT1H'), 'yyyy-MM-dd z') FROM mytable"";
    JsonNode response = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    String todayStr = response.get(""resultTable"").get(""rows"").get(0).get(0).asText();
    String expectedTodayStr =
        Instant.now().atZone(ZoneId.of(""UTC"")).format(DateTimeFormatter.ofPattern(""yyyy-MM-dd z""));
    assertEquals(todayStr, expectedTodayStr);

    String oneHourAgoTodayStr = response.get(""resultTable"").get(""rows"").get(0).get(1).asText();
    String expectedOneHourAgoTodayStr = Instant.now().minus(Duration.parse(""PT1H"")).atZone(ZoneId.of(""UTC""))
        .format(DateTimeFormatter.ofPattern(""yyyy-MM-dd z""));
    assertEquals(oneHourAgoTodayStr, expectedOneHourAgoTodayStr);
  }
",non-flaky,5
104636,apache_pinot,OfflineClusterIntegrationTest.testLiteralOnlyFunc,"  @Test
  public void testLiteralOnlyFunc()
      throws Exception {
    long currentTsMin = System.currentTimeMillis();
    long oneHourAgoTsMin = currentTsMin - ONE_HOUR_IN_MS;
    String sqlQuery =
        ""SELECT 1, now() as currentTs, ago('PT1H') as oneHourAgoTs, 'abc', toDateTime(now(), 'yyyy-MM-dd z') as ""
            + ""today, now(), ago('PT1H')"";
    JsonNode response = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    long currentTsMax = System.currentTimeMillis();
    long oneHourAgoTsMax = currentTsMax - ONE_HOUR_IN_MS;

    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(0).asText(), ""1"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(1).asText(), ""currentTs"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(2).asText(), ""oneHourAgoTs"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(3).asText(), ""abc"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(4).asText(), ""today"");
    String nowColumnName = response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(5).asText();
    String oneHourAgoColumnName = response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(6).asText();
    assertTrue(Long.parseLong(nowColumnName) > currentTsMin);
    assertTrue(Long.parseLong(nowColumnName) < currentTsMax);
    assertTrue(Long.parseLong(oneHourAgoColumnName) > oneHourAgoTsMin);
    assertTrue(Long.parseLong(oneHourAgoColumnName) < oneHourAgoTsMax);

    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(0).asText(), ""LONG"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(1).asText(), ""LONG"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(2).asText(), ""LONG"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(3).asText(), ""STRING"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(4).asText(), ""STRING"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(5).asText(), ""LONG"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(6).asText(), ""LONG"");

    int first = response.get(""resultTable"").get(""rows"").get(0).get(0).asInt();
    long second = response.get(""resultTable"").get(""rows"").get(0).get(1).asLong();
    long third = response.get(""resultTable"").get(""rows"").get(0).get(2).asLong();
    String fourth = response.get(""resultTable"").get(""rows"").get(0).get(3).asText();
    assertEquals(first, 1);
    assertTrue(second > currentTsMin);
    assertTrue(second < currentTsMax);
    assertTrue(third > oneHourAgoTsMin);
    assertTrue(third < oneHourAgoTsMax);
    assertEquals(fourth, ""abc"");
    String todayStr = response.get(""resultTable"").get(""rows"").get(0).get(4).asText();
    String expectedTodayStr =
        Instant.now().atZone(ZoneId.of(""UTC"")).format(DateTimeFormatter.ofPattern(""yyyy-MM-dd z""));
    assertEquals(todayStr, expectedTodayStr);
    long nowValue = response.get(""resultTable"").get(""rows"").get(0).get(5).asLong();
    assertEquals(nowValue, Long.parseLong(nowColumnName));
    long oneHourAgoValue = response.get(""resultTable"").get(""rows"").get(0).get(6).asLong();
    assertEquals(oneHourAgoValue, Long.parseLong(oneHourAgoColumnName));
  }
",non-flaky,5
104637,apache_pinot,OfflineClusterIntegrationTest.testRangeIndexTriggering,"  @Test(dependsOnMethods = ""testBloomFilterTriggering"")
  public void testRangeIndexTriggering()
      throws Exception {
    long numTotalDocs = getCountStarResult();
    assertEquals(postQuery(TEST_UPDATED_RANGE_INDEX_QUERY).get(""numEntriesScannedInFilter"").asLong(), numTotalDocs);

    // Update table config and trigger reload
    TableConfig tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setRangeIndexColumns(UPDATED_RANGE_INDEX_COLUMNS);
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_RANGE_INDEX_QUERY);
        // Total docs should not change during reload
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numEntriesScannedInFilter"").asLong() < numTotalDocs;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to generate range index"");

    // Update table config to remove the new range index, and
    // reload table to clean the new range index physically.
    tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setRangeIndexColumns(getRangeIndexColumns());
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_RANGE_INDEX_QUERY);
        // Total docs should not change during reload, but num entries scanned
        // gets back to total number of documents as the index is removed.
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numEntriesScannedInFilter"").asLong() == numTotalDocs;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to cleanup obsolete index"");

    assertEquals(getTableSize(getTableName()), _tableSizeAfterRemovingIndex);
  }
",non-flaky,5
104638,apache_pinot,OfflineClusterIntegrationTest.testBloomFilterTriggering,"  @Test(dependsOnMethods = ""testDefaultColumns"")
  public void testBloomFilterTriggering()
      throws Exception {
    long numTotalDocs = getCountStarResult();
    assertEquals(postQuery(TEST_UPDATED_BLOOM_FILTER_QUERY).get(""numSegmentsProcessed"").asLong(), NUM_SEGMENTS);

    // Update table config and trigger reload
    TableConfig tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setBloomFilterColumns(UPDATED_BLOOM_FILTER_COLUMNS);
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_BLOOM_FILTER_QUERY);
        // Total docs should not change during reload
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numSegmentsProcessed"").asLong() == 0L;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to generate bloom filter"");

    // Update table config to remove the new bloom filter, and
    // reload table to clean the new bloom filter physically.
    tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setBloomFilterColumns(getBloomFilterColumns());
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_BLOOM_FILTER_QUERY);
        // Total docs should not change during reload, but num entries scanned
        // gets back to total number of documents as bloom filter is removed.
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numSegmentsProcessed"").asLong() == NUM_SEGMENTS;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to cleanup obsolete index"");
    assertEquals(getTableSize(getTableName()), _tableSizeAfterRemovingIndex);
  }
",non-flaky,5
104639,apache_pinot,OfflineClusterIntegrationTest.testServerErrorWithBrokerTimeout,"  @Test
  public void testServerErrorWithBrokerTimeout()
      throws Exception {
    // Set query timeout
    long queryTimeout = 5000;
    TableConfig tableConfig = getOfflineTableConfig();
    tableConfig.setQueryConfig(new QueryConfig(queryTimeout));
    updateTableConfig(tableConfig);

    long startTime = System.currentTimeMillis();
    // The query below will fail execution due to JSON_MATCH on column without json index
    JsonNode queryResponse = postSqlQuery(""SELECT count(*) FROM mytable WHERE JSON_MATCH(Dest, '$=123')"");

    assertTrue(System.currentTimeMillis() - startTime < queryTimeout);
    assertTrue(queryResponse.get(""exceptions"").get(0).get(""message"").toString().startsWith(""\""QueryExecutionError""));

    // Remove timeout
    tableConfig.setQueryConfig(null);
    updateTableConfig(tableConfig);
  }
",non-flaky,5
104640,apache_pinot,OfflineClusterIntegrationTest.testStarTreeTriggering,"  @Test
  public void testStarTreeTriggering()
      throws Exception {
    long numTotalDocs = getCountStarResult();
    long tableSizeWithDefaultIndex = getTableSize(getTableName());

    // Test the first query
    JsonNode firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
    int firstQueryResult = firstQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt();
    assertEquals(firstQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    // Initially 'numDocsScanned' should be the same as 'COUNT(*)' result
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), firstQueryResult);

    // Update table config and trigger reload
    TableConfig tableConfig = getOfflineTableConfig();
    IndexingConfig indexingConfig = tableConfig.getIndexingConfig();
    indexingConfig.setStarTreeIndexConfigs(Collections.singletonList(STAR_TREE_INDEX_CONFIG_1));
    indexingConfig.setEnableDynamicStarTreeCreation(true);
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());

    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
        // Result should not change during reload
        assertEquals(queryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), firstQueryResult);
        // Total docs should not change during reload
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        // With star-tree, 'numDocsScanned' should be the same as number of segments (1 per segment)
        return queryResponse.get(""numDocsScanned"").asInt() == NUM_SEGMENTS;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to add first star-tree index"");

    // Reload again should have no effect
    reloadOfflineTable(getTableName());
    firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
    assertEquals(firstQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), firstQueryResult);
    assertEquals(firstQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), NUM_SEGMENTS);

    // Should be able to use the star-tree with an additional match-all predicate on another dimension
    firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1 + "" AND DaysSinceEpoch > 16070"");
    assertEquals(firstQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), firstQueryResult);
    assertEquals(firstQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), NUM_SEGMENTS);

    // Test the second query
    JsonNode secondQueryResponse = postQuery(TEST_STAR_TREE_QUERY_2);
    int secondQueryResult = secondQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt();
    assertEquals(secondQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    // Initially 'numDocsScanned' should be the same as 'COUNT(*)' result
    assertEquals(secondQueryResponse.get(""numDocsScanned"").asInt(), secondQueryResult);

    // Update table config with a different star-tree index config and trigger reload
    indexingConfig.setStarTreeIndexConfigs(Collections.singletonList(STAR_TREE_INDEX_CONFIG_2));
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());

    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_STAR_TREE_QUERY_2);
        // Result should not change during reload
        assertEquals(queryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), secondQueryResult);
        // Total docs should not change during reload
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        // With star-tree, 'numDocsScanned' should be the same as number of segments (1 per segment)
        return queryResponse.get(""numDocsScanned"").asInt() == NUM_SEGMENTS;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to change to second star-tree index"");

    // First query should not be able to use the star-tree
    firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), firstQueryResult);

    // Reload again should have no effect
    reloadOfflineTable(getTableName());
    firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
    assertEquals(firstQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), firstQueryResult);
    assertEquals(firstQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), firstQueryResult);
    secondQueryResponse = postQuery(TEST_STAR_TREE_QUERY_2);
    assertEquals(secondQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), secondQueryResult);
    assertEquals(secondQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(secondQueryResponse.get(""numDocsScanned"").asInt(), NUM_SEGMENTS);

    // Should be able to use the star-tree with an additional match-all predicate on another dimension
    secondQueryResponse = postQuery(TEST_STAR_TREE_QUERY_2 + "" AND DaysSinceEpoch > 16070"");
    assertEquals(secondQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), secondQueryResult);
    assertEquals(secondQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(secondQueryResponse.get(""numDocsScanned"").asInt(), NUM_SEGMENTS);

    // Remove the star-tree index config and trigger reload
    indexingConfig.setStarTreeIndexConfigs(null);
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());

    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_STAR_TREE_QUERY_2);
        // Result should not change during reload
        assertEquals(queryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), secondQueryResult);
        // Total docs should not change during reload
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        // Without star-tree, 'numDocsScanned' should be the same as the 'COUNT(*)' result
        return queryResponse.get(""numDocsScanned"").asInt() == secondQueryResult;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to remove star-tree index"");
    assertEquals(getTableSize(getTableName()), tableSizeWithDefaultIndex);

    // First query should not be able to use the star-tree
    firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), firstQueryResult);

    // Reload again should have no effect
    reloadOfflineTable(getTableName());
    firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
    assertEquals(firstQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), firstQueryResult);
    assertEquals(firstQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), firstQueryResult);
    secondQueryResponse = postQuery(TEST_STAR_TREE_QUERY_2);
    assertEquals(secondQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), secondQueryResult);
    assertEquals(secondQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(secondQueryResponse.get(""numDocsScanned"").asInt(), secondQueryResult);
  }
",non-flaky,5
104641,apache_pinot,OfflineClusterIntegrationTest.testDefaultColumns,"  @Test(dependsOnMethods = ""testAggregateMetadataAPI"")
  public void testDefaultColumns()
      throws Exception {
    long numTotalDocs = getCountStarResult();

    reloadWithExtraColumns();
    JsonNode queryResponse = postQuery(SELECT_STAR_QUERY);
    assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(queryResponse.get(""selectionResults"").get(""columns"").size(), 91);

    testNewAddedColumns();

    reloadWithMissingColumns();
    queryResponse = postQuery(SELECT_STAR_QUERY);
    assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(queryResponse.get(""selectionResults"").get(""columns"").size(), 75);

    reloadWithRegularColumns();
    queryResponse = postQuery(SELECT_STAR_QUERY);
    assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(queryResponse.get(""selectionResults"").get(""columns"").size(), 79);

    _tableSizeAfterRemovingIndex = getTableSize(getTableName());
  }
",non-flaky,5
104642,apache_pinot,OfflineClusterIntegrationTest.testBrokerResponseMetadata,"  @Test
  public void testBrokerResponseMetadata()
      throws Exception {
    super.testBrokerResponseMetadata();
  }
",non-flaky,5
104643,apache_pinot,OfflineClusterIntegrationTest.testGroupByUDF,"  @Test
  public void testGroupByUDF()
      throws Exception {
    String pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY timeConvert(DaysSinceEpoch,'DAYS','SECONDS')"";
    JsonNode response = postQuery(pqlQuery);
    JsonNode groupByResult = response.get(""aggregationResults"").get(0);
    JsonNode groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 605.0);
    assertEquals(groupByEntry.get(""group"").get(0).asInt(), 16138 * 24 * 3600);
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""timeconvert(DaysSinceEpoch,'DAYS','SECONDS')"");

    pqlQuery =
        ""SELECT COUNT(*) FROM mytable GROUP BY dateTimeConvert(DaysSinceEpoch,'1:DAYS:EPOCH','1:HOURS:EPOCH',""
            + ""'1:HOURS')"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 605.0);
    assertEquals(groupByEntry.get(""group"").get(0).asInt(), 16138 * 24);
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(),
        ""datetimeconvert(DaysSinceEpoch,'1:DAYS:EPOCH','1:HOURS:EPOCH','1:HOURS')"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY add(DaysSinceEpoch,DaysSinceEpoch,15)"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 605.0);
    assertEquals(groupByEntry.get(""group"").get(0).asDouble(), 16138.0 + 16138 + 15);
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""add(DaysSinceEpoch,DaysSinceEpoch,'15')"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY sub(DaysSinceEpoch,25)"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 605.0);
    assertEquals(groupByEntry.get(""group"").get(0).asDouble(), 16138.0 - 25);
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""sub(DaysSinceEpoch,'25')"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY mult(DaysSinceEpoch,24,3600)"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 605.0);
    assertEquals(groupByEntry.get(""group"").get(0).asDouble(), 16138.0 * 24 * 3600);
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""mult(DaysSinceEpoch,'24','3600')"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY div(DaysSinceEpoch,2)"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 605.0);
    assertEquals(groupByEntry.get(""group"").get(0).asDouble(), 16138.0 / 2);
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""div(DaysSinceEpoch,'2')"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY arrayLength(DivAirports)"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 115545.0);
    assertEquals(groupByEntry.get(""group"").get(0).asText(), ""5"");
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""arraylength(DivAirports)"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY arrayLength(valueIn(DivAirports,'DFW','ORD'))"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 114895.0);
    assertEquals(groupByEntry.get(""group"").get(0).asText(), ""0"");
    groupByEntry = groupByResult.get(""groupByResult"").get(1);
    assertEquals(groupByEntry.get(""value"").asDouble(), 648.0);
    assertEquals(groupByEntry.get(""group"").get(0).asText(), ""1"");
    groupByEntry = groupByResult.get(""groupByResult"").get(2);
    assertEquals(groupByEntry.get(""value"").asDouble(), 2.0);
    assertEquals(groupByEntry.get(""group"").get(0).asText(), ""2"");
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""arraylength(valuein(DivAirports,'DFW','ORD'))"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY valueIn(DivAirports,'DFW','ORD')"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 336.0);
    assertEquals(groupByEntry.get(""group"").get(0).asText(), ""ORD"");
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""valuein(DivAirports,'DFW','ORD')"");

    pqlQuery = ""SELECT MAX(timeConvert(DaysSinceEpoch,'DAYS','SECONDS')) FROM mytable"";
    response = postQuery(pqlQuery);
    JsonNode aggregationResult = response.get(""aggregationResults"").get(0);
    assertEquals(aggregationResult.get(""function"").asText(), ""max_timeconvert(DaysSinceEpoch,'DAYS','SECONDS')"");
    assertEquals(aggregationResult.get(""value"").asDouble(), 16435.0 * 24 * 3600);

    pqlQuery = ""SELECT MIN(div(DaysSinceEpoch,2)) FROM mytable"";
    response = postQuery(pqlQuery);
    aggregationResult = response.get(""aggregationResults"").get(0);
    assertEquals(aggregationResult.get(""function"").asText(), ""min_div(DaysSinceEpoch,'2')"");
    assertEquals(aggregationResult.get(""value"").asDouble(), 16071.0 / 2);
  }
",non-flaky,5
104644,apache_pinot,OfflineClusterIntegrationTest.testAggregationUDF,"  @Test
  public void testAggregationUDF()
      throws Exception {

    String pqlQuery = ""SELECT MAX(timeConvert(DaysSinceEpoch,'DAYS','SECONDS')) FROM mytable"";
    JsonNode response = postQuery(pqlQuery);
    JsonNode aggregationResult = response.get(""aggregationResults"").get(0);
    assertEquals(aggregationResult.get(""function"").asText(), ""max_timeconvert(DaysSinceEpoch,'DAYS','SECONDS')"");
    assertEquals(aggregationResult.get(""value"").asDouble(), 16435.0 * 24 * 3600);

    pqlQuery = ""SELECT MIN(div(DaysSinceEpoch,2)) FROM mytable"";
    response = postQuery(pqlQuery);
    aggregationResult = response.get(""aggregationResults"").get(0);
    assertEquals(aggregationResult.get(""function"").asText(), ""min_div(DaysSinceEpoch,'2')"");
    assertEquals(aggregationResult.get(""value"").asDouble(), 16071.0 / 2);
  }
",non-flaky,5
104645,apache_pinot,OfflineClusterIntegrationTest.testSelectionUDF,"  @Test
  public void testSelectionUDF()
      throws Exception {
    String pqlQuery = ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable"";
    JsonNode response = postQuery(pqlQuery);
    ArrayNode selectionResults = (ArrayNode) response.get(""selectionResults"").get(""results"");
    assertNotNull(selectionResults);
    assertFalse(selectionResults.isEmpty());
    for (int i = 0; i < selectionResults.size(); i++) {
      long daysSinceEpoch = selectionResults.get(i).get(0).asLong();
      long secondsSinceEpoch = selectionResults.get(i).get(1).asLong();
      assertEquals(daysSinceEpoch * 24 * 60 * 60, secondsSinceEpoch);
    }

    pqlQuery =
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by DaysSinceEpoch ""
            + ""limit 10000"";
    response = postQuery(pqlQuery);
    selectionResults = (ArrayNode) response.get(""selectionResults"").get(""results"");
    assertNotNull(selectionResults);
    assertFalse(selectionResults.isEmpty());
    long prevValue = -1;
    for (int i = 0; i < selectionResults.size(); i++) {
      long daysSinceEpoch = selectionResults.get(i).get(0).asLong();
      long secondsSinceEpoch = selectionResults.get(i).get(1).asLong();
      assertEquals(daysSinceEpoch * 24 * 60 * 60, secondsSinceEpoch);
      assertTrue(daysSinceEpoch >= prevValue);
      prevValue = daysSinceEpoch;
    }

    pqlQuery =
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by timeConvert""
            + ""(DaysSinceEpoch,'DAYS','SECONDS') DESC limit 10000"";
    response = postQuery(pqlQuery);
    selectionResults = (ArrayNode) response.get(""selectionResults"").get(""results"");
    assertNotNull(selectionResults);
    assertFalse(selectionResults.isEmpty());
    prevValue = Long.MAX_VALUE;
    for (int i = 0; i < selectionResults.size(); i++) {
      long daysSinceEpoch = selectionResults.get(i).get(0).asLong();
      long secondsSinceEpoch = selectionResults.get(i).get(1).asLong();
      assertEquals(daysSinceEpoch * 24 * 60 * 60, secondsSinceEpoch);
      assertTrue(secondsSinceEpoch <= prevValue);
      prevValue = secondsSinceEpoch;
    }
  }
",non-flaky,5
104646,apache_pinot,OfflineClusterIntegrationTest.testFilterUDF,"  @Test
  public void testFilterUDF()
      throws Exception {
    int daysSinceEpoch = 16138;
    long secondsSinceEpoch = 16138 * 24 * 60 * 60;

    String pqlQuery;
    pqlQuery = ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch = "" + daysSinceEpoch;
    long expectedResult = postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong();

    pqlQuery = ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch;
    assertEquals(postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResult);

    pqlQuery = ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch = "" + daysSinceEpoch
        + "" OR timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch;
    assertEquals(postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResult);

    pqlQuery = ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch = "" + daysSinceEpoch
        + "" AND timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch;
    assertEquals(postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResult);

    pqlQuery =
        ""SELECT count(*) FROM mytable WHERE DIV(timeConvert(DaysSinceEpoch,'DAYS','SECONDS'),1) = "" + secondsSinceEpoch;
    assertEquals(postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResult);

    pqlQuery = String
        .format(""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','SECONDS') IN (%d, %d)"",
            secondsSinceEpoch - 100, secondsSinceEpoch);
    assertEquals(postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResult);

    pqlQuery = String
        .format(""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','SECONDS') BETWEEN %d AND %d"",
            secondsSinceEpoch - 100, secondsSinceEpoch);
    assertEquals(postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResult);
  }
",non-flaky,5
104647,apache_pinot,OfflineClusterIntegrationTest.testCaseStatementInSelection,"  @Test
  public void testCaseStatementInSelection()
      throws Exception {
    List<String> origins = Arrays
        .asList(""ATL"", ""ORD"", ""DFW"", ""DEN"", ""LAX"", ""IAH"", ""SFO"", ""PHX"", ""LAS"", ""EWR"", ""MCO"", ""BOS"", ""SLC"", ""SEA"", ""MSP"",
            ""CLT"", ""LGA"", ""DTW"", ""JFK"", ""BWI"");
    StringBuilder caseStatementBuilder = new StringBuilder(""CASE "");
    for (int i = 0; i < origins.size(); i++) {
      // WHEN origin = 'ATL' THEN 1
      // WHEN origin = 'ORD' THEN 2
      // WHEN origin = 'DFW' THEN 3
      // ....
      caseStatementBuilder.append(String.format(""WHEN origin = '%s' THEN %d "", origins.get(i), i + 1));
    }
    caseStatementBuilder.append(""ELSE 0 END"");
    String sqlQuery = ""SELECT origin, "" + caseStatementBuilder + "" AS origin_code FROM mytable LIMIT 1000"";
    JsonNode response = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    JsonNode rows = response.get(""resultTable"").get(""rows"");
    assertEquals(response.get(""exceptions"").size(), 0);
    for (int i = 0; i < rows.size(); i++) {
      String origin = rows.get(i).get(0).asText();
      int originCode = rows.get(i).get(1).asInt();
      if (originCode > 0) {
        assertEquals(origin, origins.get(originCode - 1));
      } else {
        assertFalse(origins.contains(origin));
      }
    }
  }
",non-flaky,5
104648,apache_pinot,OfflineClusterIntegrationTest.testCaseStatementInSelectionWithTransformFunctionInThen,"  @Test
  public void testCaseStatementInSelectionWithTransformFunctionInThen()
      throws Exception {
    String sqlQuery =
        ""SELECT ArrDelay, CASE WHEN ArrDelay > 0 THEN ArrDelay WHEN ArrDelay < 0 THEN ArrDelay * -1 ELSE 0 END AS ""
            + ""ArrTimeDiff FROM mytable LIMIT 1000"";
    JsonNode response = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    JsonNode rows = response.get(""resultTable"").get(""rows"");
    assertEquals(response.get(""exceptions"").size(), 0);
    for (int i = 0; i < rows.size(); i++) {
      int arrDelay = rows.get(i).get(0).asInt();
      int arrDelayDiff = rows.get(i).get(1).asInt();
      if (arrDelay > 0) {
        assertEquals(arrDelay, arrDelayDiff);
      } else {
        assertEquals(arrDelay, arrDelayDiff * -1);
      }
    }
  }
",non-flaky,5
104649,apache_pinot,OfflineClusterIntegrationTest.testCaseStatementWithLogicalTransformFunction,"  @Test
  public void testCaseStatementWithLogicalTransformFunction()
      throws Exception {
    String sqlQuery = ""SELECT ArrDelay"" + "", CASE WHEN ArrDelay > 50 OR ArrDelay < 10 THEN 10 ELSE 0 END""
        + "", CASE WHEN ArrDelay < 50 AND ArrDelay >= 10 THEN 10 ELSE 0 END"" + "" FROM mytable LIMIT 1000"";
    JsonNode response = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    JsonNode rows = response.get(""resultTable"").get(""rows"");
    assertEquals(response.get(""exceptions"").size(), 0);
    for (int i = 0; i < rows.size(); i++) {
      int row0 = rows.get(i).get(0).asInt();
      int row1 = rows.get(i).get(1).asInt();
      int row2 = rows.get(i).get(2).asInt();
      if (row0 > 50 || row0 < 10) {
        assertEquals(row1, 10);
      } else {
        assertEquals(row1, 0);
      }
      if (row0 < 50 && row0 >= 10) {
        assertEquals(row2, 10);
      } else {
        assertEquals(row2, 0);
      }
    }
  }
",non-flaky,5
104650,apache_pinot,OfflineClusterIntegrationTest.testCaseStatementWithInAggregation,"  @Test
  public void testCaseStatementWithInAggregation()
      throws Exception {
    testCountVsCaseQuery(""origin = 'ATL'"");
    testCountVsCaseQuery(""origin <> 'ATL'"");

    testCountVsCaseQuery(""DaysSinceEpoch > 16312"");
    testCountVsCaseQuery(""DaysSinceEpoch >= 16312"");
    testCountVsCaseQuery(""DaysSinceEpoch < 16312"");
    testCountVsCaseQuery(""DaysSinceEpoch <= 16312"");
    testCountVsCaseQuery(""DaysSinceEpoch = 16312"");
    testCountVsCaseQuery(""DaysSinceEpoch <> 16312"");
  }
",non-flaky,5
104651,apache_pinot,OfflineClusterIntegrationTest.testFilterWithInvertedIndexUDF,"  @Test
  public void testFilterWithInvertedIndexUDF()
      throws Exception {
    int daysSinceEpoch = 16138;
    long secondsSinceEpoch = 16138 * 24 * 60 * 60;

    String[] origins = new String[]{
        ""ATL"", ""ORD"", ""DFW"", ""DEN"", ""LAX"", ""IAH"", ""SFO"", ""PHX"", ""LAS"", ""EWR"", ""MCO"", ""BOS"", ""SLC"", ""SEA"", ""MSP"", ""CLT"",
        ""LGA"", ""DTW"", ""JFK"", ""BWI""
    };
    String pqlQuery;
    for (String origin : origins) {
      pqlQuery =
          ""SELECT count(*) FROM mytable WHERE Origin = \"""" + origin + ""\"" AND DaysSinceEpoch = "" + daysSinceEpoch;
      JsonNode response1 = postQuery(pqlQuery);
      pqlQuery = ""SELECT count(*) FROM mytable WHERE Origin = \"""" + origin
          + ""\"" AND timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch;
      JsonNode response2 = postQuery(pqlQuery);
      double val1 = response1.get(""aggregationResults"").get(0).get(""value"").asDouble();
      double val2 = response2.get(""aggregationResults"").get(0).get(""value"").asDouble();
      assertEquals(val1, val2);
    }
  }
",non-flaky,5
104652,apache_pinot,OfflineClusterIntegrationTest.testQueryWithRepeatedColumns,"  @Test
  public void testQueryWithRepeatedColumns()
      throws Exception {
    //test repeated columns in selection query
    String query = ""SELECT ArrTime, ArrTime FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));

    //test repeated columns in selection query with order by
    query = ""SELECT ArrTime, ArrTime FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL' order by ArrTime"";
    testQuery(query, Collections.singletonList(query));

    //test repeated columns in agg query
    query = ""SELECT count(*), count(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL'"";
    testQuery(query, Arrays.asList(""SELECT count(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL'"",
        ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL'""));

    //test repeated columns in agg group by query
    query =
        ""SELECT ArrTime, ArrTime, count(*), count(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL' ""
            + ""group by ArrTime, ArrTime"";
    testQuery(query, Arrays.asList(
        ""SELECT ArrTime, ArrTime, count(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL' group by ""
            + ""ArrTime, ArrTime"",
        ""SELECT ArrTime, ArrTime, count(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL' group by ""
            + ""ArrTime, ArrTime""));
  }
",non-flaky,5
104653,apache_pinot,OfflineClusterIntegrationTest.testQueryWithOrderby,"  @Test
  public void testQueryWithOrderby()
      throws Exception {
    //test repeated columns in selection query
    String query = ""SELECT ArrTime, Carrier, DaysSinceEpoch FROM mytable ORDER BY DaysSinceEpoch DESC"";
    testQuery(query, Collections.singletonList(query));

    //test repeated columns in selection query
    query = ""SELECT ArrTime, DaysSinceEpoch, Carrier FROM mytable ORDER BY Carrier DESC"";
    testQuery(query, Collections.singletonList(query));

    //test repeated columns in selection query
    query = ""SELECT ArrTime, DaysSinceEpoch, Carrier FROM mytable ORDER BY Carrier DESC, ArrTime DESC"";
    testQuery(query, Collections.singletonList(query));
  }
",non-flaky,5
104654,apache_pinot,OfflineClusterIntegrationTest.testQueryWithAlias,"  @Test
  public void testQueryWithAlias()
      throws Exception {
    {
      //test same alias name with column name
      String query =
          ""SELECT ArrTime AS ArrTime, Carrier AS Carrier, DaysSinceEpoch AS DaysSinceEpoch FROM mytable ORDER BY ""
              + ""DaysSinceEpoch DESC"";
      testSqlQuery(query, Collections.singletonList(query));

      query =
          ""SELECT ArrTime AS ArrTime, DaysSinceEpoch AS DaysSinceEpoch, Carrier AS Carrier FROM mytable ORDER BY ""
              + ""Carrier DESC"";
      testSqlQuery(query, Collections.singletonList(query));

      query =
          ""SELECT ArrTime AS ArrTime, DaysSinceEpoch AS DaysSinceEpoch, Carrier AS Carrier FROM mytable ORDER BY ""
              + ""Carrier DESC, ArrTime DESC"";
      testSqlQuery(query, Collections.singletonList(query));
    }
    {
      //test single alias
      String query = ""SELECT ArrTime, Carrier AS CarrierName, DaysSinceEpoch FROM mytable ORDER BY DaysSinceEpoch DESC"";
      testSqlQuery(query, Collections.singletonList(query));

      query = ""SELECT count(*) AS cnt, max(ArrTime) as maxArrTime FROM mytable"";
      testSqlQuery(query, Collections.singletonList(query));

      query = ""SELECT count(*) AS cnt, Carrier AS CarrierName FROM mytable GROUP BY CarrierName ORDER BY cnt"";
      testSqlQuery(query, Collections.singletonList(query));
    }
    {
      //test multiple alias
      String query =
          ""SELECT ArrTime, Carrier, Carrier AS CarrierName1, Carrier AS CarrierName2, DaysSinceEpoch FROM mytable ""
              + ""ORDER BY DaysSinceEpoch DESC"";
      testSqlQuery(query, Collections.singletonList(query));

      query = ""SELECT count(*) AS cnt, max(ArrTime) as maxArrTime1, max(ArrTime) as maxArrTime2 FROM mytable"";
      testSqlQuery(query, Collections.singletonList(query));

      query =
          ""SELECT count(*), count(*) AS cnt1, count(*) AS cnt2, Carrier AS CarrierName FROM mytable GROUP BY ""
              + ""CarrierName ORDER BY cnt2"";
      testSqlQuery(query, Collections.singletonList(query));
    }
  }
",non-flaky,5
104655,apache_pinot,OfflineClusterIntegrationTest.testDistinctQuery,"  @Test
  public void testDistinctQuery()
      throws Exception {
    // by default 10 rows will be returned, so use high limit
    String pql = ""SELECT DISTINCT(Carrier) FROM mytable LIMIT 1000000"";
    String sql = ""SELECT DISTINCT Carrier FROM mytable"";
    testQuery(pql, Collections.singletonList(sql));
    pql = ""SELECT DISTINCT Carrier FROM mytable LIMIT 1000000"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT DISTINCT(Carrier, DestAirportID) FROM mytable LIMIT 1000000"";
    sql = ""SELECT DISTINCT Carrier, DestAirportID FROM mytable"";
    testQuery(pql, Collections.singletonList(sql));
    pql = ""SELECT DISTINCT Carrier, DestAirportID FROM mytable LIMIT 1000000"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT DISTINCT(Carrier, DestAirportID, DestStateName) FROM mytable LIMIT 1000000"";
    sql = ""SELECT DISTINCT Carrier, DestAirportID, DestStateName FROM mytable"";
    testQuery(pql, Collections.singletonList(sql));
    pql = ""SELECT DISTINCT Carrier, DestAirportID, DestStateName FROM mytable LIMIT 1000000"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT DISTINCT(Carrier, DestAirportID, DestCityName) FROM mytable LIMIT 1000000"";
    sql = ""SELECT DISTINCT Carrier, DestAirportID, DestCityName FROM mytable"";
    testQuery(pql, Collections.singletonList(sql));
    pql = ""SELECT DISTINCT Carrier, DestAirportID, DestCityName FROM mytable LIMIT 1000000"";
    testSqlQuery(pql, Collections.singletonList(sql));
  }
",non-flaky,5
104656,apache_pinot,OfflineClusterIntegrationTest.testNonAggregationGroupByQuery,"  @Test
  public void testNonAggregationGroupByQuery()
      throws Exception {
    // by default 10 rows will be returned, so use high limit
    String pql = ""SELECT Carrier FROM mytable GROUP BY Carrier LIMIT 1000000"";
    String sql = ""SELECT Carrier FROM mytable GROUP BY Carrier"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT Carrier, DestAirportID FROM mytable GROUP BY Carrier, DestAirportID LIMIT 1000000"";
    sql = ""SELECT Carrier, DestAirportID FROM mytable GROUP BY Carrier, DestAirportID"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql =
        ""SELECT Carrier, DestAirportID, DestStateName FROM mytable GROUP BY Carrier, DestAirportID, DestStateName ""
            + ""LIMIT 1000000"";
    sql = ""SELECT Carrier, DestAirportID, DestStateName FROM mytable GROUP BY Carrier, DestAirportID, DestStateName"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql =
        ""SELECT Carrier, DestAirportID, DestCityName FROM mytable GROUP BY Carrier, DestAirportID, DestCityName LIMIT""
            + "" 1000000"";
    sql = ""SELECT Carrier, DestAirportID, DestCityName FROM mytable GROUP BY Carrier, DestAirportID, DestCityName"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT ArrTime-DepTime FROM mytable GROUP BY ArrTime, DepTime LIMIT 1000000"";
    sql = ""SELECT ArrTime-DepTime FROM mytable GROUP BY ArrTime, DepTime"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT ArrTime-DepTime,ArrTime/3,DepTime*2 FROM mytable GROUP BY ArrTime, DepTime LIMIT 1000000"";
    sql = ""SELECT ArrTime-DepTime,ArrTime/3,DepTime*2 FROM mytable GROUP BY ArrTime, DepTime"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT ArrTime+DepTime FROM mytable GROUP BY ArrTime + DepTime LIMIT 1000000"";
    sql = ""SELECT ArrTime+DepTime FROM mytable GROUP BY ArrTime + DepTime"";
    testSqlQuery(pql, Collections.singletonList(sql));
  }
",non-flaky,5
104657,apache_pinot,OfflineClusterIntegrationTest.testCaseInsensitivity,"  @Test
  public void testCaseInsensitivity() {
    int daysSinceEpoch = 16138;
    int hoursSinceEpoch = 16138 * 24;
    int secondsSinceEpoch = 16138 * 24 * 60 * 60;
    List<String> baseQueries = Arrays.asList(""SELECT * FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by DaysSinceEpoch ""
            + ""limit 10000"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by timeConvert""
            + ""(DaysSinceEpoch,'DAYS','SECONDS') DESC limit 10000"",
        ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch = "" + daysSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','HOURS') = "" + hoursSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch,
        ""SELECT MAX(timeConvert(DaysSinceEpoch,'DAYS','SECONDS')) FROM mytable"",
        ""SELECT COUNT(*) FROM mytable GROUP BY dateTimeConvert(DaysSinceEpoch,'1:DAYS:EPOCH','1:HOURS:EPOCH',""
            + ""'1:HOURS')"");
    List<String> queries = new ArrayList<>();
    baseQueries.forEach(q -> queries.add(q.replace(""mytable"", ""MYTABLE"").replace(""DaysSinceEpoch"", ""DAYSSinceEpOch"")));
    baseQueries
        .forEach(q -> queries.add(q.replace(""mytable"", ""MYDB.MYTABLE"").replace(""DaysSinceEpoch"", ""DAYSSinceEpOch"")));

    for (String query : queries) {
      try {
        JsonNode response = postQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""PQL: "" + query + "" failed"");

        response = postSqlQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""SQL: "" + query + "" failed"");
      } catch (Exception e) {
        // Fail the test when exception caught
        throw new RuntimeException(""Got Exceptions from query - "" + query);
      }
    }
  }
",non-flaky,5
104658,apache_pinot,OfflineClusterIntegrationTest.testColumnNameContainsTableName,"  @Test
  public void testColumnNameContainsTableName() {
    int daysSinceEpoch = 16138;
    int hoursSinceEpoch = 16138 * 24;
    int secondsSinceEpoch = 16138 * 24 * 60 * 60;
    List<String> baseQueries = Arrays.asList(""SELECT * FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by DaysSinceEpoch ""
            + ""limit 10000"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by timeConvert""
            + ""(DaysSinceEpoch,'DAYS','SECONDS') DESC limit 10000"",
        ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch = "" + daysSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','HOURS') = "" + hoursSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch,
        ""SELECT MAX(timeConvert(DaysSinceEpoch,'DAYS','SECONDS')) FROM mytable"",
        ""SELECT COUNT(*) FROM mytable GROUP BY dateTimeConvert(DaysSinceEpoch,'1:DAYS:EPOCH','1:HOURS:EPOCH',""
            + ""'1:HOURS')"");
    List<String> queries = new ArrayList<>();
    baseQueries.forEach(q -> queries.add(q.replace(""DaysSinceEpoch"", ""mytable.DAYSSinceEpOch"")));
    baseQueries.forEach(q -> queries.add(q.replace(""DaysSinceEpoch"", ""mytable.DAYSSinceEpOch"")));

    for (String query : queries) {
      try {
        JsonNode response = postQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""PQL: "" + query + "" failed"");

        response = postSqlQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""SQL: "" + query + "" failed"");
      } catch (Exception e) {
        // Fail the test when exception caught
        throw new RuntimeException(""Got Exceptions from query - "" + query);
      }
    }
  }
",non-flaky,5
104659,apache_pinot,OfflineClusterIntegrationTest.testCaseInsensitivityWithColumnNameContainsTableName,"  @Test
  public void testCaseInsensitivityWithColumnNameContainsTableName() {
    int daysSinceEpoch = 16138;
    int hoursSinceEpoch = 16138 * 24;
    int secondsSinceEpoch = 16138 * 24 * 60 * 60;
    List<String> baseQueries = Arrays.asList(""SELECT * FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by DaysSinceEpoch ""
            + ""limit 10000"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by timeConvert""
            + ""(DaysSinceEpoch,'DAYS','SECONDS') DESC limit 10000"",
        ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch = "" + daysSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','HOURS') = "" + hoursSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch,
        ""SELECT MAX(timeConvert(DaysSinceEpoch,'DAYS','SECONDS')) FROM mytable"",
        ""SELECT COUNT(*) FROM mytable GROUP BY dateTimeConvert(DaysSinceEpoch,'1:DAYS:EPOCH','1:HOURS:EPOCH',""
            + ""'1:HOURS')"");
    List<String> queries = new ArrayList<>();
    baseQueries
        .forEach(q -> queries.add(q.replace(""mytable"", ""MYTABLE"").replace(""DaysSinceEpoch"", ""MYTABLE.DAYSSinceEpOch"")));
    baseQueries.forEach(
        q -> queries.add(q.replace(""mytable"", ""MYDB.MYTABLE"").replace(""DaysSinceEpoch"", ""MYTABLE.DAYSSinceEpOch"")));

    for (String query : queries) {
      try {
        JsonNode response = postQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""PQL: "" + query + "" failed"");

        response = postSqlQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""SQL: "" + query + "" failed"");
      } catch (Exception e) {
        // Fail the test when exception caught
        throw new RuntimeException(""Got Exceptions from query - "" + query);
      }
    }
  }
",non-flaky,5
104660,apache_pinot,OfflineClusterIntegrationTest.testQuerySourceWithDatabaseName,"  @Test
  public void testQuerySourceWithDatabaseName()
      throws Exception {
    // by default 10 rows will be returned, so use high limit
    String pql = ""SELECT DISTINCT(Carrier) FROM mytable LIMIT 1000000"";
    String sql = ""SELECT DISTINCT Carrier FROM mytable"";
    testQuery(pql, Collections.singletonList(sql));
    pql = ""SELECT DISTINCT Carrier FROM db.mytable LIMIT 1000000"";
    testSqlQuery(pql, Collections.singletonList(sql));
  }
",non-flaky,5
104661,apache_pinot,OfflineClusterIntegrationTest.testDistinctCountHll,"  @Test
  public void testDistinctCountHll()
      throws Exception {
    String query;

    // The Accurate value is 6538.
    query = ""SELECT distinctCount(FlightNum) FROM mytable "";
    assertEquals(postQuery(query).get(""aggregationResults"").get(0).get(""value"").asLong(), 6538);
    assertEquals(postSqlQuery(query, _brokerBaseApiUrl).get(""resultTable"").get(""rows"").get(0).get(0).asLong(), 6538);

    // Expected distinctCountHll with different log2m value from 2 to 19. The Accurate value is 6538.
    long[] expectedResults = new long[]{
        3504, 6347, 8877, 9729, 9046, 7672, 7538, 6993, 6649, 6651, 6553, 6525, 6459, 6523, 6532, 6544, 6538, 6539
    };

    for (int i = 2; i < 20; i++) {
      query = String.format(""SELECT distinctCountHLL(FlightNum, %d) FROM mytable "", i);
      assertEquals(postQuery(query).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResults[i - 2]);
      assertEquals(postSqlQuery(query, _brokerBaseApiUrl).get(""resultTable"").get(""rows"").get(0).get(0).asLong(),
          expectedResults[i - 2]);
    }

    // Default HLL is set as log2m=12
    query = ""SELECT distinctCountHLL(FlightNum) FROM mytable "";
    assertEquals(postQuery(query).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResults[10]);
    assertEquals(postSqlQuery(query, _brokerBaseApiUrl).get(""resultTable"").get(""rows"").get(0).get(0).asLong(),
        expectedResults[10]);
  }
",non-flaky,5
104662,apache_pinot,OfflineClusterIntegrationTest.testAggregationFunctionsWithUnderscore,"  @Test
  public void testAggregationFunctionsWithUnderscore()
      throws Exception {
    String query;

    // The Accurate value is 6538.
    query = ""SELECT distinct_count(FlightNum) FROM mytable "";
    assertEquals(postQuery(query).get(""aggregationResults"").get(0).get(""value"").asLong(), 6538);
    assertEquals(postSqlQuery(query, _brokerBaseApiUrl).get(""resultTable"").get(""rows"").get(0).get(0).asLong(), 6538);

    // The Accurate value is 6538.
    query = ""SELECT c_o_u_n_t(FlightNum) FROM mytable "";
    assertEquals(postQuery(query).get(""aggregationResults"").get(0).get(""value"").asLong(), 115545);
    assertEquals(postSqlQuery(query, _brokerBaseApiUrl).get(""resultTable"").get(""rows"").get(0).get(0).asLong(), 115545);
  }
",non-flaky,5
104663,apache_pinot,OfflineClusterIntegrationTest.testGrpcQueryServer,"  @Test
  public void testGrpcQueryServer()
      throws Exception {
    GrpcQueryClient queryClient = new GrpcQueryClient(""localhost"", CommonConstants.Server.DEFAULT_GRPC_PORT);
    String sql = ""SELECT * FROM mytable_OFFLINE LIMIT 1000000"";
    BrokerRequest brokerRequest = new Pql2Compiler().compileToBrokerRequest(sql);
    List<String> segments = _helixResourceManager.getSegmentsFor(""mytable_OFFLINE"");

    GrpcRequestBuilder requestBuilder = new GrpcRequestBuilder().setSegments(segments);
    testNonStreamingRequest(queryClient.submit(requestBuilder.setSql(sql).build()));
    testNonStreamingRequest(queryClient.submit(requestBuilder.setBrokerRequest(brokerRequest).build()));

    requestBuilder.setEnableStreaming(true);
    testStreamingRequest(queryClient.submit(requestBuilder.setSql(sql).build()));
    testStreamingRequest(queryClient.submit(requestBuilder.setBrokerRequest(brokerRequest).build()));
  }
",non-flaky,5
104664,apache_pinot,OfflineClusterIntegrationTest.testHardcodedServerPartitionedSqlQueries,"  @Test
  public void testHardcodedServerPartitionedSqlQueries()
      throws Exception {
    super.testHardcodedServerPartitionedSqlQueries();
  }
",non-flaky,5
104665,apache_pinot,OfflineClusterIntegrationTest.testAggregateMetadataAPI,"  @Test
  public void testAggregateMetadataAPI()
      throws IOException {
    JsonNode oneColumnResponse = JsonUtils
        .stringToJsonNode(sendGetRequest(_controllerBaseApiUrl + ""/tables/mytable/metadata?columns=DestCityMarketID""));
    assertEquals(oneColumnResponse.get(DISK_SIZE_IN_BYTES_KEY).asInt(), DISK_SIZE_IN_BYTES);
    assertEquals(oneColumnResponse.get(NUM_SEGMENTS_KEY).asInt(), NUM_SEGMENTS);
    assertEquals(oneColumnResponse.get(NUM_ROWS_KEY).asInt(), NUM_ROWS);
    assertEquals(oneColumnResponse.get(COLUMN_LENGTH_MAP_KEY).size(), 1);
    assertEquals(oneColumnResponse.get(COLUMN_CARDINALITY_MAP_KEY).size(), 1);

    JsonNode threeColumnsResponse = JsonUtils.stringToJsonNode(sendGetRequest(_controllerBaseApiUrl
        + ""/tables/mytable/metadata?columns=DivActualElapsedTime&columns=CRSElapsedTime&columns=OriginStateName""));
    assertEquals(threeColumnsResponse.get(DISK_SIZE_IN_BYTES_KEY).asInt(), DISK_SIZE_IN_BYTES);
    assertEquals(threeColumnsResponse.get(NUM_SEGMENTS_KEY).asInt(), NUM_SEGMENTS);
    assertEquals(threeColumnsResponse.get(NUM_ROWS_KEY).asInt(), NUM_ROWS);
    assertEquals(threeColumnsResponse.get(COLUMN_LENGTH_MAP_KEY).size(), 3);
    assertEquals(threeColumnsResponse.get(COLUMN_CARDINALITY_MAP_KEY).size(), 3);

    JsonNode zeroColumnResponse =
        JsonUtils.stringToJsonNode(sendGetRequest(_controllerBaseApiUrl + ""/tables/mytable/metadata""));
    assertEquals(zeroColumnResponse.get(DISK_SIZE_IN_BYTES_KEY).asInt(), DISK_SIZE_IN_BYTES);
    assertEquals(zeroColumnResponse.get(NUM_SEGMENTS_KEY).asInt(), NUM_SEGMENTS);
    assertEquals(zeroColumnResponse.get(NUM_ROWS_KEY).asInt(), NUM_ROWS);
    assertEquals(zeroColumnResponse.get(COLUMN_LENGTH_MAP_KEY).size(), 0);
    assertEquals(zeroColumnResponse.get(COLUMN_CARDINALITY_MAP_KEY).size(), 0);

    JsonNode allColumnResponse =
        JsonUtils.stringToJsonNode(sendGetRequest(_controllerBaseApiUrl + ""/tables/mytable/metadata?columns=*""));
    assertEquals(allColumnResponse.get(DISK_SIZE_IN_BYTES_KEY).asInt(), DISK_SIZE_IN_BYTES);
    assertEquals(allColumnResponse.get(NUM_SEGMENTS_KEY).asInt(), NUM_SEGMENTS);
    assertEquals(allColumnResponse.get(NUM_ROWS_KEY).asInt(), NUM_ROWS);
    assertEquals(allColumnResponse.get(COLUMN_LENGTH_MAP_KEY).size(), 82);
    assertEquals(allColumnResponse.get(COLUMN_CARDINALITY_MAP_KEY).size(), 82);

    allColumnResponse = JsonUtils.stringToJsonNode(sendGetRequest(
        _controllerBaseApiUrl + ""/tables/mytable/metadata?columns=CRSElapsedTime&columns=*&columns=OriginStateName""));
    assertEquals(allColumnResponse.get(DISK_SIZE_IN_BYTES_KEY).asInt(), DISK_SIZE_IN_BYTES);
    assertEquals(allColumnResponse.get(NUM_SEGMENTS_KEY).asInt(), NUM_SEGMENTS);
    assertEquals(allColumnResponse.get(NUM_ROWS_KEY).asInt(), NUM_ROWS);
    assertEquals(allColumnResponse.get(COLUMN_LENGTH_MAP_KEY).size(), 82);
    assertEquals(allColumnResponse.get(COLUMN_CARDINALITY_MAP_KEY).size(), 82);
  }
",non-flaky,5
104666,apache_pinot,RealtimeKinesisIntegrationTest.testRecords,"  @Test
  public void testRecords()
      throws Exception {
    Assert.assertNotEquals(_totalRecordsPushedInStream, 0);

    ResultSet pinotResultSet = getPinotConnection()
        .execute(new Request(""sql"", ""SELECT * FROM "" + getTableName() + "" ORDER BY Origin LIMIT 10000""))
        .getResultSet(0);

    Assert.assertNotEquals(pinotResultSet.getRowCount(), 0);

    Statement h2statement =
        _h2Connection.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY, java.sql.ResultSet.CONCUR_READ_ONLY);
    h2statement.execute(""SELECT * FROM "" + getTableName() + "" ORDER BY Origin"");
    java.sql.ResultSet h2ResultSet = h2statement.getResultSet();

    Assert.assertFalse(h2ResultSet.isLast());

    h2ResultSet.beforeFirst();
    int row = 0;
    Map<String, Integer> columnToIndex = new HashMap<>();
    for (int i = 0; i < _h2FieldNameAndTypes.size(); i++) {
      columnToIndex.put(pinotResultSet.getColumnName(i), i);
    }

    while (h2ResultSet.next()) {

      for (String fieldNameAndDatatype : _h2FieldNameAndTypes) {
        String[] fieldNameAndDatatypeList = fieldNameAndDatatype.split("" "");
        String fieldName = fieldNameAndDatatypeList[0];
        String h2DataType = fieldNameAndDatatypeList[1];
        switch (h2DataType) {
          case ""int"": {
            int expectedValue = h2ResultSet.getInt(fieldName);
            int actualValue = pinotResultSet.getInt(row, columnToIndex.get(fieldName));
            Assert.assertEquals(expectedValue, actualValue);
            break;
          }
          case ""varchar(128)"": {
            String expectedValue = h2ResultSet.getString(fieldName);
            String actualValue = pinotResultSet.getString(row, columnToIndex.get(fieldName));
            Assert.assertEquals(expectedValue, actualValue);
            break;
          }
          default:
            break;
        }
      }

      row++;

      if (row >= pinotResultSet.getRowCount()) {
        int cnt = 0;
        while (h2ResultSet.next()) {
          cnt++;
        }
        Assert.assertEquals(cnt, 0);
        break;
      }
    }
  }
",non-flaky,5
104667,apache_pinot,RealtimeKinesisIntegrationTest.testCountRecords,"  @Test
  public void testCountRecords() {
    long count =
        getPinotConnection().execute(new Request(""sql"", ""SELECT COUNT(*) FROM "" + getTableName())).getResultSet(0)
            .getLong(0);

    Assert.assertEquals(count, _totalRecordsPushedInStream);
  }
",non-flaky,5
104668,apache_pinot,StarTreeClusterIntegrationTest.testGeneratedQueries,"  @Test
  public void testGeneratedQueries()
      throws Exception {
    for (int i = 0; i < NUM_QUERIES_TO_GENERATE; i += 2) {
      testStarQuery(_starTree1QueryGenerator.nextQuery());
      testStarQuery(_starTree2QueryGenerator.nextQuery());
    }
  }
",non-flaky,5
104669,apache_pinot,StarTreeClusterIntegrationTest.testPredicateOnMetrics,"  @Test
  public void testPredicateOnMetrics()
      throws Exception {
    String starQuery;

    // Query containing predicate on one metric only
    starQuery = ""SELECT SUM(DepDelayMinutes) FROM myStarTable WHERE DepDelay > 0"";
    testStarQuery(starQuery);
    starQuery = ""SELECT SUM(DepDelayMinutes) FROM myStarTable WHERE DepDelay BETWEEN 0 and 10000"";
    testStarQuery(starQuery);

    // Query containing predicate on multiple metrics
    starQuery = ""SELECT SUM(DepDelayMinutes) FROM myStarTable WHERE DepDelay > 0 AND ArrDelay > 0"";
    testStarQuery(starQuery);

    // Query containing predicate on multiple metrics and dimensions
    starQuery =
        ""SELECT SUM(DepDelayMinutes) FROM myStarTable WHERE DepDelay > 0 AND ArrDelay > 0 AND OriginStateName = ""
            + ""'Massachusetts'"";
    testStarQuery(starQuery);
  }
",non-flaky,5
104670,apache_pinot,LuceneRealtimeClusterIntegrationTest.testTextSearchCountQuery,"  @Test
  public void testTextSearchCountQuery()
      throws Exception {
    // Keep posting queries until all records are consumed
    long previousResult = 0;
    while (getCurrentCountStarResult() < NUM_RECORDS) {
      long result = getTextColumnQueryResult();
      assertTrue(result >= previousResult);
      previousResult = result;
      Thread.sleep(100);
    }

    //Lucene index on consuming segments to update the latest records
    TestUtils.waitForCondition(aVoid -> {
      try {
        return getTextColumnQueryResult() == NUM_MATCHING_RECORDS;
      } catch (Exception e) {
        fail(""Caught exception while getting text column query result"");
        return false;
      }
    }, 10_000L, ""Failed to reach expected number of matching records"");
  }
",non-flaky,5
104671,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testRealtimeToOfflineSegmentsTask,"  @Test
  public void testRealtimeToOfflineSegmentsTask()
      throws IOException {
    List<SegmentZKMetadata> segmentsZKMetadata = _pinotHelixResourceManager.getSegmentsZKMetadata(_offlineTableName);
    Assert.assertTrue(segmentsZKMetadata.isEmpty());

    long expectedWatermark = _dataSmallestTimeMs + 86400000;
    int numOfflineSegments = 0;
    for (int i = 0; i < 3; i++) {
      // Schedule task
      Assert.assertNotNull(_taskManager.scheduleTasks().get(MinionConstants.RealtimeToOfflineSegmentsTask.TASK_TYPE));
      Assert.assertTrue(_helixTaskResourceManager.getTaskQueues().contains(
          PinotHelixTaskResourceManager.getHelixJobQueueName(MinionConstants.RealtimeToOfflineSegmentsTask.TASK_TYPE)));
      // Should not generate more tasks
      Assert.assertNull(_taskManager.scheduleTasks().get(MinionConstants.RealtimeToOfflineSegmentsTask.TASK_TYPE));

      // Wait at most 600 seconds for all tasks COMPLETED
      waitForTaskToComplete(expectedWatermark);
      // check segment is in offline
      segmentsZKMetadata = _pinotHelixResourceManager.getSegmentsZKMetadata(_offlineTableName);
      numOfflineSegments++;
      Assert.assertEquals(segmentsZKMetadata.size(), numOfflineSegments);
      long expectedOfflineSegmentTimeMs = expectedWatermark - 86400000;
      Assert.assertEquals(segmentsZKMetadata.get(i).getStartTimeMs(), expectedOfflineSegmentTimeMs);
      Assert.assertEquals(segmentsZKMetadata.get(i).getEndTimeMs(), expectedOfflineSegmentTimeMs);

      expectedWatermark += 86400000;
    }
    testHardcodedSqlQueries();

    // Delete the table
    dropRealtimeTable(_realtimeTableName);

    // Check if the metadata is cleaned up on table deletion
    verifyTableDelete(_realtimeTableName);
  }
",non-flaky,5
104672,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testSegmentListApi,"  @Test(enabled = false)
  public void testSegmentListApi() {
  }
",non-flaky,5
104673,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testBrokerDebugOutput,"  @Test(enabled = false)
  public void testBrokerDebugOutput() {
  }
",non-flaky,5
104674,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testBrokerDebugRoutingTableSQL,"  @Test(enabled = false)
  public void testBrokerDebugRoutingTableSQL() {
  }
",non-flaky,5
104675,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testBrokerResponseMetadata,"  @Test(enabled = false)
  public void testBrokerResponseMetadata() {
  }
",non-flaky,5
104676,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testDictionaryBasedQueries,"  @Test(enabled = false)
  public void testDictionaryBasedQueries() {
  }
",non-flaky,5
104677,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testGeneratedQueriesWithMultiValues,"  @Test(enabled = false)
  public void testGeneratedQueriesWithMultiValues() {
  }
",non-flaky,5
104678,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testGeneratedQueriesWithoutMultiValues,"  @Test(enabled = false)
  public void testGeneratedQueriesWithoutMultiValues() {
  }
",non-flaky,5
104679,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testHardcodedQueries,"  @Test(enabled = false)
  public void testHardcodedQueries() {
  }
",non-flaky,5
104680,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testHardcodedSqlQueries,"  @Test(enabled = false)
  public void testHardcodedSqlQueries() {
  }
",non-flaky,5
104681,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testInstanceShutdown,"  @Test(enabled = false)
  public void testInstanceShutdown() {
  }
",non-flaky,5
104682,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testQueriesFromQueryFile,"  @Test(enabled = false)
  public void testQueriesFromQueryFile() {
  }
",non-flaky,5
104683,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testQueryExceptions,"  @Test(enabled = false)
  public void testQueryExceptions() {
  }
",non-flaky,5
104684,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testReload,"  @Test(enabled = false)
  public void testReload(boolean includeOfflineTable) {
  }
",non-flaky,5
104685,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testSqlQueriesFromQueryFile,"  @Test(enabled = false)
  public void testSqlQueriesFromQueryFile() {
  }
",non-flaky,5
104686,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testVirtualColumnQueries,"  @Test(enabled = false)
  public void testVirtualColumnQueries() {
  }
",non-flaky,5
104687,apache_pinot,MapTypeClusterIntegrationTest.testJsonPathQueries,"  @Test
  public void testJsonPathQueries()
      throws Exception {
    // Selection only
    String query = ""SELECT stringKeyMapStr FROM "" + getTableName();
    JsonNode pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(selectionResults.get(i).get(0).textValue(), String.format(""{\""k1\"":%d,\""k2\"":100%d}"", i, i));
    }
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k1', 'INT') FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), i);
    }
    query = ""SELECT jsonExtractScalar(intKeyMapStr, '$.95', 'INT') FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), i);
    }

    // Selection order-by
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k2', 'INT') FROM "" + getTableName()
        + "" ORDER BY jsonExtractScalar(stringKeyMapStr, '$.k1', 'INT')"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), NUM_DOCS + i);
    }
    query = ""SELECT jsonExtractScalar(intKeyMapStr, '$.717', 'INT') FROM "" + getTableName()
        + "" ORDER BY jsonExtractScalar(intKeyMapStr, '$.95', 'INT')"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), NUM_DOCS + i);
    }

    // Aggregation only
    query = ""SELECT MAX(jsonExtractScalar(stringKeyMapStr, '$.k1', 'INT')) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode aggregationResult = pinotResponse.get(""aggregationResults"").get(0).get(""value"");
    assertEquals((int) Double.parseDouble(aggregationResult.textValue()), NUM_DOCS - 1);
    query = ""SELECT MAX(jsonExtractScalar(intKeyMapStr, '$.95', 'INT')) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    aggregationResult = pinotResponse.get(""aggregationResults"").get(0).get(""value"");
    assertEquals((int) Double.parseDouble(aggregationResult.textValue()), NUM_DOCS - 1);

    // Aggregation group-by
    query = ""SELECT MIN(jsonExtractScalar(stringKeyMapStr, '$.k2', 'INT')) FROM "" + getTableName()
        + "" GROUP BY jsonExtractScalar(stringKeyMapStr, '$.k1', 'INT')"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode groupByResults = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    assertEquals(groupByResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      JsonNode groupByResult = groupByResults.get(i);
      assertEquals(Integer.parseInt(groupByResult.get(""group"").get(0).asText()), i);
      assertEquals((int) Double.parseDouble(groupByResult.get(""value"").asText()), NUM_DOCS + i);
    }
    query = ""SELECT MIN(jsonExtractScalar(intKeyMapStr, '$.717', 'INT')) FROM "" + getTableName()
        + "" GROUP BY jsonExtractScalar(intKeyMapStr, '$.95', 'INT')"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    groupByResults = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    assertEquals(groupByResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      JsonNode groupByResult = groupByResults.get(i);
      assertEquals(Integer.parseInt(groupByResult.get(""group"").get(0).asText()), i);
      assertEquals((int) Double.parseDouble(groupByResult.get(""value"").asText()), NUM_DOCS + i);
    }

    // Filter
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k2', 'INT') FROM "" + getTableName()
        + "" WHERE jsonExtractScalar(stringKeyMapStr, '$.k1', 'INT') = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 1);
    assertEquals(Integer.parseInt(selectionResults.get(0).get(0).textValue()), NUM_DOCS + 25);
    query = ""SELECT jsonExtractScalar(intKeyMapStr, '$.717', 'INT') FROM "" + getTableName()
        + "" WHERE jsonExtractScalar(intKeyMapStr, '$.95', 'INT') = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 1);
    assertEquals(Integer.parseInt(selectionResults.get(0).get(0).textValue()), NUM_DOCS + 25);

    // Filter on non-existing key
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k2', 'INT') FROM "" + getTableName()
        + "" WHERE jsonExtractScalar(stringKeyMapStr, '$.k3', 'INT_ARRAY') = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
    query = ""SELECT jsonExtractScalar(intKeyMapStr, '$.717', 'INT') FROM "" + getTableName()
        + "" WHERE jsonExtractScalar(intKeyMapStr, '$.123', 'INT_ARRAY') = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);

    // Select non-existing key (illegal query)
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k3', 'INT') FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertNotEquals(pinotResponse.get(""exceptions"").size(), 0);
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.123', 'INT') FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertNotEquals(pinotResponse.get(""exceptions"").size(), 0);

    // Select non-existing key with default value
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k3', 'INT', '0') FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.123', 'INT', '0') FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);

    // Select non-existing key with proper filter
    query = ""SELECT jsonExtractScalar(intKeyMapStr, '$.123', 'INT') FROM "" + getTableName()
        + "" WHERE jsonExtractKey(intKeyMapStr, '$.*') = \""$['123']\"""";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k3', 'INT') FROM "" + getTableName()
        + "" WHERE jsonExtractKey(stringKeyMapStr, '$.*') = \""$['k3']\"""";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
  }
",non-flaky,5
104688,apache_pinot,MapTypeClusterIntegrationTest.testQueries,"  @Test
  public void testQueries()
      throws Exception {
    // Selection only
    String query = ""SELECT mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES) FROM "" + getTableName();
    JsonNode pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), i);
    }
    query = ""SELECT mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), i);
    }

    // Selection order-by
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k2', stringKeyMap__VALUES) FROM "" + getTableName()
        + "" ORDER BY mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES)"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), NUM_DOCS + i);
    }
    query = ""SELECT mapValue(intKeyMap__KEYS, 717, intKeyMap__VALUES) FROM "" + getTableName()
        + "" ORDER BY mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES)"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), NUM_DOCS + i);
    }

    // Aggregation only
    query = ""SELECT MAX(mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES)) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode aggregationResult = pinotResponse.get(""aggregationResults"").get(0).get(""value"");
    assertEquals((int) Double.parseDouble(aggregationResult.textValue()), NUM_DOCS - 1);
    query = ""SELECT MAX(mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES)) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    aggregationResult = pinotResponse.get(""aggregationResults"").get(0).get(""value"");
    assertEquals((int) Double.parseDouble(aggregationResult.textValue()), NUM_DOCS - 1);

    // Aggregation group-by
    query = ""SELECT MIN(mapValue(stringKeyMap__KEYS, 'k2', stringKeyMap__VALUES)) FROM "" + getTableName()
        + "" GROUP BY mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES)"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode groupByResults = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    assertEquals(groupByResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      JsonNode groupByResult = groupByResults.get(i);
      assertEquals(Integer.parseInt(groupByResult.get(""group"").get(0).asText()), i);
      assertEquals((int) Double.parseDouble(groupByResult.get(""value"").asText()), NUM_DOCS + i);
    }
    query = ""SELECT MIN(mapValue(intKeyMap__KEYS, 717, intKeyMap__VALUES)) FROM "" + getTableName()
        + "" GROUP BY mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES)"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    groupByResults = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    assertEquals(groupByResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      JsonNode groupByResult = groupByResults.get(i);
      assertEquals(Integer.parseInt(groupByResult.get(""group"").get(0).asText()), i);
      assertEquals((int) Double.parseDouble(groupByResult.get(""value"").asText()), NUM_DOCS + i);
    }

    // Filter
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k2', stringKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES) = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 1);
    assertEquals(Integer.parseInt(selectionResults.get(0).get(0).textValue()), NUM_DOCS + 25);
    query = ""SELECT mapValue(intKeyMap__KEYS, 717, intKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES) = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 1);
    assertEquals(Integer.parseInt(selectionResults.get(0).get(0).textValue()), NUM_DOCS + 25);

    // Filter on non-existing key
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k2', stringKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE mapValue(stringKeyMap__KEYS, 'k3', stringKeyMap__VALUES) = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
    query = ""SELECT mapValue(intKeyMap__KEYS, 717, intKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE mapValue(intKeyMap__KEYS, 123, intKeyMap__VALUES) = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);

    // Select non-existing key (illegal query)
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k3', stringKeyMap__VALUES) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertNotEquals(pinotResponse.get(""exceptions"").size(), 0);
    query = ""SELECT mapValue(stringKeyMap__KEYS, 123, stringKeyMap__VALUES) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertNotEquals(pinotResponse.get(""exceptions"").size(), 0);

    // Select non-existing key with proper filter
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k3', stringKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE stringKeyMap__KEYS = 'k3'"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
    query = ""SELECT mapValue(intKeyMap__KEYS, 123, intKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE stringKeyMap__KEYS = 123"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
  }
",non-flaky,5
104689,apache_pinot,UpsertTableSegmentUploadIntegrationTest.testSegmentAssignment,"  @Test
  public void testSegmentAssignment()
      throws Exception {
    IdealState idealState = HelixHelper.getTableIdealState(_helixManager, TABLE_NAME_WITH_TYPE);
    Assert.assertEquals(getCurrentCountStarResult(), getCountStarResult());
    verifyTableIdealStates(idealState);
    // Wait 3 seconds to let the realtime validation thread to run.
    Thread.sleep(3000);
    // Verify the result again.
    Assert.assertEquals(getCurrentCountStarResult(), getCountStarResult());
    verifyTableIdealStates(idealState);
  }
",non-flaky,5
104690,apache_pinot,BasicAuthTlsRealtimeIntegrationTest.testSegmentUploadDownload,"  @Test
  public void testSegmentUploadDownload()
      throws Exception {
    final Request query = new Request(""sql"", ""SELECT count(*) FROM "" + getTableName());

    ResultSetGroup resultBeforeOffline = getPinotConnection().execute(query);
    Assert.assertTrue(resultBeforeOffline.getResultSet(0).getLong(0) > 0);

    // schedule offline segment generation
    Assert.assertNotNull(_controllerStarter.getTaskManager().scheduleTasks());

    // wait for offline segments
    JsonNode offlineSegments = TestUtils.waitForResult(() -> {
      JsonNode segmentSets = JsonUtils.stringToJsonNode(
          sendGetRequest(_controllerRequestURLBuilder.forSegmentListAPI(getTableName()), AUTH_HEADER));
      JsonNode currentOfflineSegments =
          new IntRange(0, segmentSets.size()).stream().map(segmentSets::get).filter(s -> s.has(""OFFLINE""))
              .map(s -> s.get(""OFFLINE"")).findFirst().get();
      Assert.assertFalse(currentOfflineSegments.isEmpty());
      return currentOfflineSegments;
    }, 30000);

    // Verify constant row count
    ResultSetGroup resultAfterOffline = getPinotConnection().execute(query);
    Assert.assertEquals(resultBeforeOffline.getResultSet(0).getLong(0), resultAfterOffline.getResultSet(0).getLong(0));

    // download and sanity-check size of offline segment(s)
    for (int i = 0; i < offlineSegments.size(); i++) {
      String segment = offlineSegments.get(i).asText();
      Assert.assertTrue(
          sendGetRequest(_controllerRequestURLBuilder.forSegmentDownload(getTableName(), segment), AUTH_HEADER).length()
              > 200000); // download segment
    }
  }
",non-flaky,5
104691,apache_pinot,ConvertToRawIndexMinionClusterIntegrationTest.testConvertToRawIndexTask,"  @Test
  public void testConvertToRawIndexTask()
      throws Exception {
    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(getTableName());

    File testDataDir = new File(CommonConstants.Server.DEFAULT_INSTANCE_DATA_DIR + ""-0"", offlineTableName);
    if (!testDataDir.isDirectory()) {
      testDataDir = new File(CommonConstants.Server.DEFAULT_INSTANCE_DATA_DIR + ""-1"", offlineTableName);
    }
    Assert.assertTrue(testDataDir.isDirectory());
    File tableDataDir = testDataDir;

    // Check that all columns have dictionary
    File[] indexDirs = tableDataDir.listFiles();
    Assert.assertNotNull(indexDirs);
    for (File indexDir : indexDirs) {
      SegmentMetadata segmentMetadata = new SegmentMetadataImpl(indexDir);
      for (String columnName : segmentMetadata.getSchema().getColumnNames()) {
        Assert.assertTrue(segmentMetadata.getColumnMetadataFor(columnName).hasDictionary());
      }
    }

    // Should create the task queues and generate a ConvertToRawIndexTask task with 5 child tasks
    Assert.assertNotNull(_taskManager.scheduleTasks().get(ConvertToRawIndexTask.TASK_TYPE));
    Assert.assertTrue(_helixTaskResourceManager.getTaskQueues()
        .contains(PinotHelixTaskResourceManager.getHelixJobQueueName(ConvertToRawIndexTask.TASK_TYPE)));

    // Should generate one more ConvertToRawIndexTask task with 3 child tasks
    Assert.assertNotNull(_taskManager.scheduleTasks().get(ConvertToRawIndexTask.TASK_TYPE));

    // Should not generate more tasks
    Assert.assertNull(_taskManager.scheduleTasks().get(ConvertToRawIndexTask.TASK_TYPE));

    // Wait at most 600 seconds for all tasks COMPLETED and new segments refreshed
    TestUtils.waitForCondition(input -> {
      // Check task state
      for (TaskState taskState : _helixTaskResourceManager.getTaskStates(ConvertToRawIndexTask.TASK_TYPE).values()) {
        if (taskState != TaskState.COMPLETED) {
          return false;
        }
      }

      // Check segment ZK metadata
      for (SegmentZKMetadata segmentZKMetadata : _helixResourceManager.getSegmentsZKMetadata(offlineTableName)) {
        Map<String, String> customMap = segmentZKMetadata.getCustomMap();
        if (customMap == null || customMap.size() != 1 || !customMap
            .containsKey(ConvertToRawIndexTask.TASK_TYPE + MinionConstants.TASK_TIME_SUFFIX)) {
          return false;
        }
      }

      // Check segment metadata
      File[] indexDirs1 = tableDataDir.listFiles();
      Assert.assertNotNull(indexDirs1);
      for (File indexDir : indexDirs1) {
        SegmentMetadata segmentMetadata;

        // Segment metadata file might not exist if the segment is refreshing
        try {
          segmentMetadata = new SegmentMetadataImpl(indexDir);
        } catch (Exception e) {
          return false;
        }

        // The columns in COLUMNS_TO_CONVERT should have raw index
        List<String> rawIndexColumns = Arrays.asList(StringUtils.split(COLUMNS_TO_CONVERT, ','));
        for (String columnName : segmentMetadata.getSchema().getColumnNames()) {
          if (rawIndexColumns.contains(columnName)) {
            if (segmentMetadata.getColumnMetadataFor(columnName).hasDictionary()) {
              return false;
            }
          } else {
            if (!segmentMetadata.getColumnMetadataFor(columnName).hasDictionary()) {
              return false;
            }
          }
        }
      }

      return true;
    }, 600_000L, ""Failed to get all tasks COMPLETED and new segments refreshed"");
  }
",non-flaky,5
104692,apache_pinot,ConvertToRawIndexMinionClusterIntegrationTest.testPinotHelixResourceManagerAPIs,"  @Test
  public void testPinotHelixResourceManagerAPIs() {
    // Instance APIs
    Assert.assertEquals(_helixResourceManager.getAllInstances().size(), 5);
    Assert.assertEquals(_helixResourceManager.getOnlineInstanceList().size(), 5);
    Assert.assertEquals(_helixResourceManager.getOnlineUnTaggedBrokerInstanceList().size(), 0);
    Assert.assertEquals(_helixResourceManager.getOnlineUnTaggedServerInstanceList().size(), 0);

    // Table APIs
    String rawTableName = getTableName();
    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(rawTableName);
    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(rawTableName);
    List<String> tableNames = _helixResourceManager.getAllTables();
    Assert.assertEquals(tableNames.size(), 2);
    Assert.assertTrue(tableNames.contains(offlineTableName));
    Assert.assertTrue(tableNames.contains(realtimeTableName));
    Assert.assertEquals(_helixResourceManager.getAllRawTables(), Collections.singletonList(rawTableName));
    Assert.assertEquals(_helixResourceManager.getAllRealtimeTables(), Collections.singletonList(realtimeTableName));

    // Tenant APIs
    Assert.assertEquals(_helixResourceManager.getAllBrokerTenantNames(), Collections.singleton(""TestTenant""));
    Assert.assertEquals(_helixResourceManager.getAllServerTenantNames(), Collections.singleton(""TestTenant""));
  }
",non-flaky,5
104693,apache_pinot,BaseClusterIntegrationTestSet.testHardcodedQueries," * <p>To enable the test, override it and add @Test annotation.
  public void testHardcodedQueries()
      throws Exception {
    // Here are some sample queries.
    String query;
    query = ""SELECT COUNT(*) FROM mytable WHERE DaysSinceEpoch = 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));
    query = ""SELECT COUNT(*) FROM mytable WHERE DaysSinceEpoch <> 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));
    query = ""SELECT COUNT(*) FROM mytable WHERE DaysSinceEpoch > 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));
    query = ""SELECT COUNT(*) FROM mytable WHERE DaysSinceEpoch >= 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));
    query = ""SELECT COUNT(*) FROM mytable WHERE DaysSinceEpoch < 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));
    query = ""SELECT COUNT(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));
    query = ""SELECT MAX(ArrTime), MIN(ArrTime) FROM mytable WHERE DaysSinceEpoch >= 16312"";
    testQuery(query, Arrays.asList(""SELECT MAX(ArrTime) FROM mytable WHERE DaysSinceEpoch >= 15312"",
        ""SELECT MIN(ArrTime) FROM mytable WHERE DaysSinceEpoch >= 15312""));
    query =
        ""SELECT SUM(TotalAddGTime) FROM mytable WHERE DivArrDelay NOT IN (67, 260) AND Carrier IN ('F9', 'B6') OR ""
            + ""DepTime BETWEEN 2144 AND 1926"";
    testQuery(query, Collections.singletonList(query));
  }
",non-flaky,5
104694,apache_pinot,LLCRealtimeClusterIntegrationTest.testConsumerDirectoryExists,"  @Test
  public void testConsumerDirectoryExists() {
    File consumerDirectory = new File(CONSUMER_DIRECTORY, ""mytable_REALTIME"");
    assertEquals(consumerDirectory.exists(), _isConsumerDirConfigured,
        ""The off heap consumer directory does not exist"");
  }
",non-flaky,5
104695,apache_pinot,LLCRealtimeClusterIntegrationTest.testSegmentFlushSize,"  @Test
  public void testSegmentFlushSize() {
    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(getTableName());
    List<SegmentZKMetadata> segmentsZKMetadata =
        ZKMetadataProvider.getSegmentsZKMetadata(_propertyStore, realtimeTableName);
    for (SegmentZKMetadata segmentZKMetadata : segmentsZKMetadata) {
      assertEquals(segmentZKMetadata.getSizeThresholdToFlushSegment(),
          getRealtimeSegmentFlushSize() / getNumKafkaPartitions());
    }
  }
",non-flaky,5
104696,apache_pinot,LLCRealtimeClusterIntegrationTest.testInvertedIndexTriggering,"  @Test
  public void testInvertedIndexTriggering()
      throws Exception {
    long numTotalDocs = getCountStarResult();

    JsonNode queryResponse = postQuery(TEST_UPDATED_INVERTED_INDEX_QUERY);
    assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertTrue(queryResponse.get(""numEntriesScannedInFilter"").asLong() > 0L);

    TableConfig tableConfig = getRealtimeTableConfig();
    tableConfig.getIndexingConfig().setInvertedIndexColumns(UPDATED_INVERTED_INDEX_COLUMNS);
    updateTableConfig(tableConfig);
    reloadRealtimeTable(getTableName());

    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse1 = postQuery(TEST_UPDATED_INVERTED_INDEX_QUERY);
        // Total docs should not change during reload
        assertEquals(queryResponse1.get(""totalDocs"").asLong(), numTotalDocs);
        assertEquals(queryResponse1.get(""numConsumingSegmentsQueried"").asLong(), 2);
        assertTrue(queryResponse1.get(""minConsumingFreshnessTimeMs"").asLong() > _startTime);
        assertTrue(queryResponse1.get(""minConsumingFreshnessTimeMs"").asLong() < System.currentTimeMillis());
        return queryResponse1.get(""numEntriesScannedInFilter"").asLong() == 0;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to generate inverted index"");
  }
",non-flaky,5
104697,apache_pinot,LLCRealtimeClusterIntegrationTest.testAddHLCTableShouldFail,"  @Test(expectedExceptions = IOException.class)
  public void testAddHLCTableShouldFail()
      throws IOException {
    TableConfig tableConfig = new TableConfigBuilder(TableType.REALTIME).setTableName(""testTable"")
        .setStreamConfigs(Collections.singletonMap(""stream.kafka.consumer.type"", ""HIGHLEVEL"")).build();
    sendPostRequest(_controllerRequestURLBuilder.forTableCreate(), tableConfig.toJsonString());
  }
",non-flaky,5
104698,apache_pinot,LLCRealtimeClusterIntegrationTest.testReload,"  @Test
  public void testReload()
      throws Exception {
    testReload(false);
  }
",non-flaky,5
104699,apache_pinot,LLCRealtimeClusterIntegrationTest.testHardcodedServerPartitionedSqlQueries,"  @Test
  public void testHardcodedServerPartitionedSqlQueries()
      throws Exception {
    super.testHardcodedServerPartitionedSqlQueries();
  }
",non-flaky,5
104700,apache_pinot,SegmentWriterUploaderIntegrationTest.testFileBasedSegmentWriterAndDefaultUploader,"  @Test
  public void testFileBasedSegmentWriterAndDefaultUploader()
      throws Exception {

    TableConfig offlineTableConfig = createOfflineTableConfig();
    addTableConfig(offlineTableConfig);

    SegmentWriter segmentWriter = new FileBasedSegmentWriter();
    segmentWriter.init(offlineTableConfig, _schema);
    SegmentUploader segmentUploader = new SegmentUploaderDefault();
    segmentUploader.init(offlineTableConfig);

    GenericRow reuse = new GenericRow();
    long totalDocs = 0;
    for (int i = 0; i < 3; i++) {
      AvroRecordReader avroRecordReader = new AvroRecordReader();
      avroRecordReader.init(_avroFiles.get(i), null, null);

      long numDocsInSegment = 0;
      while (avroRecordReader.hasNext()) {
        avroRecordReader.next(reuse);
        segmentWriter.collect(reuse);
        numDocsInSegment++;
        totalDocs++;
      }
      // flush to segment
      URI segmentTarURI = segmentWriter.flush();
      // upload
      segmentUploader.uploadSegment(segmentTarURI, null);

      // check num segments
      Assert.assertEquals(getNumSegments(), i + 1);
      // check numDocs in latest segment
      Assert.assertEquals(getNumDocsInLatestSegment(), numDocsInSegment);
      // check totalDocs in query
      checkTotalDocsInQuery(totalDocs);
    }
    segmentWriter.close();

    dropAllSegments(_tableNameWithType, TableType.OFFLINE);
    checkNumSegments(0);

    // upload all together using dir
    segmentUploader.uploadSegmentsFromDir(_tarDir.toURI(), null);
    // check num segments
    Assert.assertEquals(getNumSegments(), 3);
    // check totalDocs in query
    checkTotalDocsInQuery(totalDocs);

    dropOfflineTable(_tableNameWithType);
  }
",non-flaky,5
104701,apache_pinot,BasicAuthRealtimeIntegrationTest.testSegmentUploadDownload,"  @Test
  public void testSegmentUploadDownload()
      throws Exception {
    final Request query = new Request(""sql"", ""SELECT count(*) FROM "" + getTableName());

    ResultSetGroup resultBeforeOffline = getPinotConnection().execute(query);
    Assert.assertTrue(resultBeforeOffline.getResultSet(0).getLong(0) > 0);

    // schedule offline segment generation
    Assert.assertNotNull(_controllerStarter.getTaskManager().scheduleTasks());

    // wait for offline segments
    JsonNode offlineSegments = TestUtils.waitForResult(() -> {
      JsonNode segmentSets = JsonUtils.stringToJsonNode(
          sendGetRequest(_controllerRequestURLBuilder.forSegmentListAPI(getTableName()), AUTH_HEADER));
      JsonNode currentOfflineSegments =
          new IntRange(0, segmentSets.size()).stream().map(segmentSets::get).filter(s -> s.has(""OFFLINE""))
              .map(s -> s.get(""OFFLINE"")).findFirst().get();
      Assert.assertFalse(currentOfflineSegments.isEmpty());
      return currentOfflineSegments;
    }, 30000);

    // Verify constant row count
    ResultSetGroup resultAfterOffline = getPinotConnection().execute(query);
    Assert.assertEquals(resultBeforeOffline.getResultSet(0).getLong(0), resultAfterOffline.getResultSet(0).getLong(0));

    // download and sanity-check size of offline segment(s)
    for (int i = 0; i < offlineSegments.size(); i++) {
      String segment = offlineSegments.get(i).asText();
      Assert.assertTrue(
          sendGetRequest(_controllerRequestURLBuilder.forSegmentDownload(getTableName(), segment), AUTH_HEADER).length()
              > 200000); // download segment
    }
  }
",non-flaky,5
104702,apache_pinot,ServerStarterIntegrationTest.testDefaultServerConf,"  @Test
  public void testDefaultServerConf()
      throws Exception {
    String expectedHost = NetUtils.getHostAddress();
    String expectedInstanceId = PREFIX_OF_SERVER_INSTANCE + expectedHost + ""_"" + DEFAULT_SERVER_NETTY_PORT;

    verifyInstanceConfig(new PinotConfiguration(), expectedInstanceId, expectedHost, DEFAULT_SERVER_NETTY_PORT);
  }
",non-flaky,5
104703,apache_pinot,ServerStarterIntegrationTest.testSetInstanceIdToHostname,"  @Test
  public void testSetInstanceIdToHostname()
      throws Exception {
    String expectedHost = NetUtils.getHostnameOrAddress();
    String expectedInstanceId = PREFIX_OF_SERVER_INSTANCE + expectedHost + ""_"" + DEFAULT_SERVER_NETTY_PORT;

    Map<String, Object> properties = new HashMap<>();
    properties.put(SET_INSTANCE_ID_TO_HOSTNAME_KEY, true);

    verifyInstanceConfig(new PinotConfiguration(properties), expectedInstanceId, expectedHost,
        DEFAULT_SERVER_NETTY_PORT);
  }
",non-flaky,5
104704,apache_pinot,ServerStarterIntegrationTest.testCustomInstanceId,"  @Test
  public void testCustomInstanceId()
      throws Exception {
    Map<String, Object> properties = new HashMap<>();
    properties.put(CONFIG_OF_INSTANCE_ID, CUSTOM_INSTANCE_ID);

    verifyInstanceConfig(new PinotConfiguration(properties), CUSTOM_INSTANCE_ID, NetUtils.getHostAddress(),
        DEFAULT_SERVER_NETTY_PORT);
  }
",non-flaky,5
104705,apache_pinot,ServerStarterIntegrationTest.testCustomHost,"  @Test
  public void testCustomHost()
      throws Exception {
    String expectedInstanceId = PREFIX_OF_SERVER_INSTANCE + CUSTOM_HOST + ""_"" + DEFAULT_SERVER_NETTY_PORT;

    Map<String, Object> properties = new HashMap<>();
    properties.put(KEY_OF_SERVER_NETTY_HOST, CUSTOM_HOST);

    verifyInstanceConfig(new PinotConfiguration(properties), expectedInstanceId, CUSTOM_HOST,
        DEFAULT_SERVER_NETTY_PORT);
  }
",non-flaky,5
104706,apache_pinot,ServerStarterIntegrationTest.testCustomPort,"  @Test
  public void testCustomPort()
      throws Exception {
    String expectedHost = NetUtils.getHostAddress();
    String expectedInstanceId = PREFIX_OF_SERVER_INSTANCE + expectedHost + ""_"" + CUSTOM_PORT;

    Map<String, Object> properties = new HashMap<>();
    properties.put(KEY_OF_SERVER_NETTY_PORT, CUSTOM_PORT);

    verifyInstanceConfig(new PinotConfiguration(properties), expectedInstanceId, expectedHost, CUSTOM_PORT);
  }
",non-flaky,5
104707,apache_pinot,ServerStarterIntegrationTest.testAllCustomServerConf,"  @Test
  public void testAllCustomServerConf()
      throws Exception {
    Map<String, Object> properties = new HashMap<>();
    properties.put(CONFIG_OF_INSTANCE_ID, CUSTOM_INSTANCE_ID);
    properties.put(KEY_OF_SERVER_NETTY_HOST, CUSTOM_HOST);
    properties.put(KEY_OF_SERVER_NETTY_PORT, CUSTOM_PORT);
    verifyInstanceConfig(new PinotConfiguration(properties), CUSTOM_INSTANCE_ID, CUSTOM_HOST, CUSTOM_PORT);
  }
",non-flaky,5
104708,apache_pinot,JsonPathClusterIntegrationTest.testPqlQueries,"  @Test
  public void testPqlQueries()
      throws Exception {

    //Selection Query
    String pqlQuery = ""Select "" + MY_MAP_STR_FIELD_NAME + "" from "" + DEFAULT_TABLE_NAME;
    JsonNode pinotResponse = postQuery(pqlQuery);
    ArrayNode selectionResults = (ArrayNode) pinotResponse.get(""selectionResults"").get(""results"");
    Assert.assertNotNull(selectionResults);
    Assert.assertFalse(selectionResults.isEmpty());
    for (int i = 0; i < selectionResults.size(); i++) {
      String value = selectionResults.get(i).get(0).textValue();
      Assert.assertTrue(value.indexOf(""-k1-"") > 0);
    }

    //Filter Query
    pqlQuery = ""Select jsonExtractScalar(myMapStr,'$.k1','STRING') from "" + DEFAULT_TABLE_NAME
        + ""  where jsonExtractScalar(myMapStr,'$.k1','STRING') = 'value-k1-0'"";
    pinotResponse = postQuery(pqlQuery);
    selectionResults = (ArrayNode) pinotResponse.get(""selectionResults"").get(""results"");
    Assert.assertNotNull(selectionResults);
    Assert.assertFalse(selectionResults.isEmpty());
    for (int i = 0; i < selectionResults.size(); i++) {
      String value = selectionResults.get(i).get(0).textValue();
      Assert.assertEquals(value, ""value-k1-0"");
    }
    pqlQuery =
        ""Select "" + MY_MAP_STR_K1_FIELD_NAME + "" from "" + DEFAULT_TABLE_NAME + ""  where "" + MY_MAP_STR_K1_FIELD_NAME
            + "" = 'value-k1-0'"";
    pinotResponse = postQuery(pqlQuery);
    selectionResults = (ArrayNode) pinotResponse.get(""selectionResults"").get(""results"");
    Assert.assertNotNull(selectionResults);
    Assert.assertFalse(selectionResults.isEmpty());
    for (int i = 0; i < selectionResults.size(); i++) {
      String value = selectionResults.get(i).get(0).textValue();
      Assert.assertEquals(value, ""value-k1-0"");
    }

    //selection order by
    pqlQuery = ""Select jsonExtractScalar(myMapStr,'$.k1','STRING') from "" + DEFAULT_TABLE_NAME
        + "" order by jsonExtractScalar(myMapStr,'$.k1','STRING')"";
    pinotResponse = postQuery(pqlQuery);
    selectionResults = (ArrayNode) pinotResponse.get(""selectionResults"").get(""results"");
    Assert.assertNotNull(selectionResults);
    Assert.assertFalse(selectionResults.isEmpty());
    for (int i = 0; i < selectionResults.size(); i++) {
      String value = selectionResults.get(i).get(0).textValue();
      Assert.assertTrue(value.indexOf(""-k1-"") > 0);
    }
    pqlQuery =
        ""Select "" + MY_MAP_STR_K1_FIELD_NAME + "" from "" + DEFAULT_TABLE_NAME + "" order by "" + MY_MAP_STR_K1_FIELD_NAME;
    pinotResponse = postQuery(pqlQuery);
    selectionResults = (ArrayNode) pinotResponse.get(""selectionResults"").get(""results"");
    Assert.assertNotNull(selectionResults);
    Assert.assertFalse(selectionResults.isEmpty());
    for (int i = 0; i < selectionResults.size(); i++) {
      String value = selectionResults.get(i).get(0).textValue();
      Assert.assertTrue(value.indexOf(""-k1-"") > 0);
    }

    //Group By Query
    pqlQuery = ""Select count(*) from "" + DEFAULT_TABLE_NAME + "" group by jsonExtractScalar(myMapStr,'$.k1','STRING')"";
    pinotResponse = postQuery(pqlQuery);
    Assert.assertNotNull(pinotResponse.get(""aggregationResults""));
    JsonNode groupByResult = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    Assert.assertNotNull(groupByResult);
    Assert.assertTrue(groupByResult.isArray());
    Assert.assertFalse(groupByResult.isEmpty());

    pqlQuery = ""Select count(*) from "" + DEFAULT_TABLE_NAME + "" group by "" + MY_MAP_STR_K1_FIELD_NAME;
    pinotResponse = postQuery(pqlQuery);
    Assert.assertNotNull(pinotResponse.get(""aggregationResults""));
    groupByResult = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    Assert.assertNotNull(groupByResult);
    Assert.assertTrue(groupByResult.isArray());
    Assert.assertFalse(groupByResult.isEmpty());
  }
",non-flaky,5
104709,apache_pinot,JsonPathClusterIntegrationTest.testSqlQueries,"  @Test
  public void testSqlQueries()
      throws Exception {
    //Selection Query
    String sqlQuery = ""Select myMapStr from "" + DEFAULT_TABLE_NAME;
    JsonNode pinotResponse = postSqlQuery(sqlQuery);
    ArrayNode rows = (ArrayNode) pinotResponse.get(""resultTable"").get(""rows"");
    Assert.assertNotNull(rows);
    Assert.assertFalse(rows.isEmpty());
    for (int i = 0; i < rows.size(); i++) {
      String value = rows.get(i).get(0).textValue();
      Assert.assertTrue(value.indexOf(""-k1-"") > 0);
    }

    //Filter Query
    sqlQuery = ""Select jsonExtractScalar(myMapStr,'$.k1','STRING') from "" + DEFAULT_TABLE_NAME
        + ""  where jsonExtractScalar(myMapStr,'$.k1','STRING') = 'value-k1-0'"";
    pinotResponse = postSqlQuery(sqlQuery);
    rows = (ArrayNode) pinotResponse.get(""resultTable"").get(""rows"");
    Assert.assertNotNull(rows);
    Assert.assertFalse(rows.isEmpty());
    for (int i = 0; i < rows.size(); i++) {
      String value = rows.get(i).get(0).textValue();
      Assert.assertEquals(value, ""value-k1-0"");
    }

    //selection order by
    sqlQuery = ""Select jsonExtractScalar(myMapStr,'$.k1','STRING') from "" + DEFAULT_TABLE_NAME
        + "" order by jsonExtractScalar(myMapStr,'$.k1','STRING')"";
    pinotResponse = postSqlQuery(sqlQuery);
    rows = (ArrayNode) pinotResponse.get(""resultTable"").get(""rows"");
    Assert.assertNotNull(rows);
    Assert.assertFalse(rows.isEmpty());
    for (int i = 0; i < rows.size(); i++) {
      String value = rows.get(i).get(0).textValue();
      Assert.assertTrue(value.indexOf(""-k1-"") > 0);
    }

    //Group By Query
    sqlQuery = ""Select jsonExtractScalar(myMapStr,'$.k1','STRING'), count(*) from "" + DEFAULT_TABLE_NAME
        + "" group by jsonExtractScalar(myMapStr,'$.k1','STRING')"";
    pinotResponse = postSqlQuery(sqlQuery);
    Assert.assertNotNull(pinotResponse.get(""resultTable""));
    rows = (ArrayNode) pinotResponse.get(""resultTable"").get(""rows"");
    for (int i = 0; i < rows.size(); i++) {
      String value = rows.get(i).get(0).textValue();
      Assert.assertTrue(value.indexOf(""-k1-"") > 0);
    }
  }
",non-flaky,5
113698,salesforce_reactive-grpc,GradleProofTest.gradleProof,"    @Test
    public void gradleProof() throws Exception {
        GradleProof proof = new GradleProof();
        try {
            proof.startServer();
            String result = proof.doClient(""World"");
            assertEquals(""Hello World"", result);
        } finally {
            proof.stopServer();
        }
    }
",non-flaky,5
113699,salesforce_reactive-grpc,ExampleInstrumentedTest.useAppContext,"    @Test
    public void useAppContext() {
        // Context of the app under test.
        Context appContext = InstrumentationRegistry.getTargetContext();

        assertEquals(""demo.client.android"", appContext.getPackageName());
    }
",non-flaky,5
113700,salesforce_reactive-grpc,ExampleUnitTest.addition_isCorrect,"    @Test
    public void addition_isCorrect() {
        assertEquals(4, 2 + 2);
    }
",non-flaky,5
113701,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.clientCanCancelServerStreamExplicitly,"    @Test
    public void clientCanCancelServerStreamExplicitly() throws InterruptedException {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        AtomicInteger lastNumberConsumed = new AtomicInteger(Integer.MAX_VALUE);
        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());
        Flux<NumberProto.Number> test = Mono.just(Empty.getDefaultInstance()).as(stub::responsePressure)
                .doOnNext(number -> {lastNumberConsumed.set(number.getNumber(0)); System.out.println(""C: "" + number.getNumber(0));})
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""));

        Disposable subscription = test.publish().connect();

        Thread.sleep(1000);
        subscription.dispose();
        Thread.sleep(1000);

        // Cancellation may or may not deliver the last generated message due to delays in the gRPC processing thread
        assertThat(Math.abs(lastNumberConsumed.get() - svc.getLastNumberProduced())).isLessThanOrEqualTo(3);
        assertThat(svc.wasCanceled()).isTrue();
    }
",non-flaky,5
113702,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.clientCanCancelServerStreamImplicitly,"    @Test
    public void clientCanCancelServerStreamImplicitly() throws InterruptedException {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());
        Flux<NumberProto.Number> test = Mono.just(Empty.getDefaultInstance()).as(stub::responsePressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""))
                .take(10);

        Disposable subscription = test.publish().connect();

        Thread.sleep(1000);

        assertThat(svc.wasCanceled()).isTrue();
    }
",non-flaky,5
113703,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamImplicitly,"    @Test
    public void serverCanCancelClientStreamImplicitly() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        svc.setExplicitCancel(false);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flux<NumberProto.Number> request = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delayElements(Duration.ofMillis(SEQUENCE_DELAY_MILLIS))
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(x -> {
                    requestDidProduce.set(true);
                    System.out.println(""Produced: "" + x.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        Mono<NumberProto.Number> observer = request.as(stub::requestPressure)
                .doOnSuccess(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()));

        StepVerifier.create(observer)
                .expectNext(protoNum(9))
                .verifyComplete();

        await().atMost(org.awaitility.Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();
    }
",non-flaky,5
113704,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamExplicitly,"    @Test
    public void serverCanCancelClientStreamExplicitly() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        svc.setExplicitCancel(true);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flux<NumberProto.Number> request = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delayElements(Duration.ofMillis(SEQUENCE_DELAY_MILLIS))
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(n -> {
                    requestDidProduce.set(true);
                    System.out.println(""P: "" + n.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        Mono<NumberProto.Number> observer = request.as(stub::requestPressure)
                .doOnSuccess(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()));

        StepVerifier.create(observer)
                .expectNext(protoNum(-1))
                .verifyComplete();

        await().atMost(org.awaitility.Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();
    }
",non-flaky,5
113705,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamImplicitlyBidi,"    @Test
    public void serverCanCancelClientStreamImplicitlyBidi() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        svc.setExplicitCancel(false);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flux<NumberProto.Number> request = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delayElements(Duration.ofMillis(SEQUENCE_DELAY_MILLIS))
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(x -> {
                    requestDidProduce.set(true);
                    System.out.println(""Produced: "" + x.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        Flux<NumberProto.Number> observer = request.compose(stub::twoWayPressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()));

        StepVerifier.create(observer)
                .expectNext(protoNum(9))
                .verifyComplete();

        await().atMost(org.awaitility.Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();
    }
",non-flaky,5
113706,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamExplicitlyBidi,"    @Test
    public void serverCanCancelClientStreamExplicitlyBidi() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        svc.setExplicitCancel(true);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flux<NumberProto.Number> request = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delayElements(Duration.ofMillis(SEQUENCE_DELAY_MILLIS))
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(n -> {
                    requestDidProduce.set(true);
                    System.out.println(""P: "" + n.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        Flux<NumberProto.Number> observer = request.compose(stub::twoWayPressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()));

        StepVerifier.create(observer)
                .expectNext(protoNum(-1))
                .verifyComplete();

        await().atMost(org.awaitility.Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();
    }
",non-flaky,5
113707,salesforce_reactive-grpc,ServerErrorIntegrationTest.oneToOne,"    @Test
    public void oneToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloResponse> resp = Mono.just(HelloRequest.getDefaultInstance()).compose(stub::sayHello);

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
",non-flaky,5
113708,salesforce_reactive-grpc,ServerErrorIntegrationTest.oneToMany,"    @Test
    public void oneToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloResponse> resp = Mono.just(HelloRequest.getDefaultInstance()).as(stub::sayHelloRespStream);
        Flux<HelloResponse> test = resp
                .doOnNext(System.out::println)
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""));

        StepVerifier.create(test)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
",non-flaky,5
113709,salesforce_reactive-grpc,ServerErrorIntegrationTest.manyToOne,"    @Test
    public void manyToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloResponse> resp = Flux.just(HelloRequest.getDefaultInstance()).as(stub::sayHelloReqStream);
        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
",non-flaky,5
113710,salesforce_reactive-grpc,ServerErrorIntegrationTest.manyToMany,"    @Test
    public void manyToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloResponse> resp = Flux.just(HelloRequest.getDefaultInstance()).compose(stub::sayHelloBothStream);
        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
",non-flaky,5
113711,salesforce_reactive-grpc,BackpressureIntegrationTest.clientToServerBackpressure,"    @Test
    public void clientToServerBackpressure() {
        serverRule.getServiceRegistry().addService(new TestService());

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        Flux<NumberProto.Number> reactorRequest = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .doOnNext(i -> System.out.println(i + "" --> ""))
                .doOnNext(i -> updateNumberOfWaits(lastValueTime, numberOfWaits))
                .map(BackpressureIntegrationTest::protoNum);

        Mono<NumberProto.Number> reactorResponse = reactorRequest.as(stub::requestPressure);

        StepVerifier.create(reactorResponse)
                .expectNextMatches(v -> v.getNumber(0) == NUMBER_OF_STREAM_ELEMENTS - 1)
                .expectComplete()
                .verify(Duration.ofSeconds(5));

        assertThat(numberOfWaits.get()).isEqualTo(1);
    }
",non-flaky,5
113712,salesforce_reactive-grpc,BackpressureIntegrationTest.serverToClientBackpressure,"    @Test
    public void serverToClientBackpressure() {
        serverRule.getServiceRegistry().addService(new TestService());

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        Mono<Empty> reactorRequest = Mono.just(Empty.getDefaultInstance());

        Flux<NumberProto.Number> reactorResponse = reactorRequest.as(stub::responsePressure)
                .doOnNext(n -> System.out.println(n.getNumber(0) + ""  <--""))
                .doOnNext(n -> waitIfValuesAreEqual(n.getNumber(0), 3));

        StepVerifier.create(reactorResponse)
                .expectNextCount(NUMBER_OF_STREAM_ELEMENTS)
                .expectComplete()
                .verify(Duration.ofSeconds(5));

        assertThat(numberOfWaits.get()).isEqualTo(1);
    }
",non-flaky,5
113713,salesforce_reactive-grpc,BackpressureIntegrationTest.bidiResponseBackpressure,"    @Test
    public void bidiResponseBackpressure() {
        serverRule.getServiceRegistry().addService(new TestService());

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        Flux<NumberProto.Number> reactorRequest = Flux.empty();

        Flux<NumberProto.Number> reactorResponse = reactorRequest.compose(stub::twoWayResponsePressure)
                .doOnNext(n -> System.out.println(n.getNumber(0) + ""  <--""))
                .doOnNext(n -> waitIfValuesAreEqual(n.getNumber(0), 3));

        StepVerifier.create(reactorResponse)
                .expectNextCount(NUMBER_OF_STREAM_ELEMENTS)
                .expectComplete()
                .verify(Duration.ofSeconds(5));

        assertThat(numberOfWaits.get()).isEqualTo(1);
    }
",non-flaky,5
113714,salesforce_reactive-grpc,BackpressureIntegrationTest.bidiRequestBackpressure,"    @Test
    public void bidiRequestBackpressure() {
        serverRule.getServiceRegistry().addService(new TestService());

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        Flux<NumberProto.Number> reactorRequest = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .doOnNext(i -> System.out.println(i + "" --> ""))
                .doOnNext(i -> updateNumberOfWaits(lastValueTime, numberOfWaits))
                .map(BackpressureIntegrationTest::protoNum);

        Flux<NumberProto.Number> reactorResponse = reactorRequest.compose(stub::twoWayRequestPressure);

        StepVerifier.create(reactorResponse)
                .expectNextMatches(v -> v.getNumber(0) == NUMBER_OF_STREAM_ELEMENTS - 1)
                .expectComplete()
                .verify(Duration.ofSeconds(5));

        assertThat(numberOfWaits.get()).isEqualTo(1);
    }
",non-flaky,5
113715,salesforce_reactive-grpc,ServerErrorUpstreamCancellationIntegrationTest.serverErrorSignalsUpstreamCancellationManyToOne,"    @Test
    public void serverErrorSignalsUpstreamCancellationManyToOne() {
        serverRule.getServiceRegistry().addService(new ExplodeAfterFiveService());
        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        AtomicBoolean upstreamCancel = new AtomicBoolean(false);

        Mono<NumberProto.Number> observer = Flux.range(0, Integer.MAX_VALUE)
                .map(this::protoNum)
                .doOnCancel(() -> upstreamCancel.set(true))
                .as(stub::requestPressure)
                .doOnError(System.out::println)
                .doOnSuccess(i -> System.out.println(i.getNumber(0)));

        StepVerifier.create(observer)
                .verifyError(StatusRuntimeException.class);

        assertThat(upstreamCancel.get()).isTrue();
    }
",non-flaky,5
113716,salesforce_reactive-grpc,ServerErrorUpstreamCancellationIntegrationTest.serverErrorSignalsUpstreamCancellationBidi,"    @Test
    public void serverErrorSignalsUpstreamCancellationBidi() {
        serverRule.getServiceRegistry().addService(new ExplodeAfterFiveService());
        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        AtomicBoolean upstreamCancel = new AtomicBoolean(false);

        Flux<NumberProto.Number> subscriber = Flux.range(0, Integer.MAX_VALUE)
                .map(this::protoNum)
                .doOnCancel(() -> upstreamCancel.set(true))
                .compose(stub::twoWayPressure)
                .doOnNext(i -> System.out.println(i.getNumber(0)));

        StepVerifier.create(subscriber)
                .verifyError(StatusRuntimeException.class);
        assertThat(upstreamCancel.get()).isTrue();
    }
",non-flaky,5
113717,salesforce_reactive-grpc,UnexpectedServerErrorIntegrationTest.oneToOne,"    @Test
    public void oneToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloResponse> resp = Mono.just(HelloRequest.getDefaultInstance()).compose(stub::sayHello);

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus().getCode() == Status.Code.INTERNAL);
    }
",non-flaky,5
113718,salesforce_reactive-grpc,UnexpectedServerErrorIntegrationTest.oneToMany,"    @Test
    public void oneToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloResponse> resp = Mono.just(HelloRequest.getDefaultInstance()).as(stub::sayHelloRespStream);
        Flux<HelloResponse> test = resp
                .doOnNext(System.out::println)
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""));

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus().getCode() == Status.Code.INTERNAL);
    }
",non-flaky,5
113719,salesforce_reactive-grpc,UnexpectedServerErrorIntegrationTest.manyToOne,"    @Test
    public void manyToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(HelloRequest.getDefaultInstance());
        Mono<HelloResponse> resp = req.as(stub::sayHelloReqStream);

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus().getCode() == Status.Code.INTERNAL);
    }
",non-flaky,5
113720,salesforce_reactive-grpc,UnexpectedServerErrorIntegrationTest.manyToMany,"    @Test
    public void manyToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(HelloRequest.getDefaultInstance());
        Flux<HelloResponse> resp = req.compose(stub::sayHelloBothStream);

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus().getCode() == Status.Code.INTERNAL);
    }
",non-flaky,5
113721,salesforce_reactive-grpc,ClientThreadIntegrationTest.oneToOne,"    @Test
    public void oneToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloRequest> req = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Mono<HelloResponse> resp = req.compose(stub::sayHello);

        AtomicReference<String> clientThreadName = new AtomicReference<>();

        StepVerifier
                .create(resp
                        .map(HelloResponse::getMessage)
                        .doOnSuccess(x -> clientThreadName.set(Thread.currentThread().getName())))
                .expectNext(""Hello reactorjava"")
                .verifyComplete();

        assertThat(clientThreadName.get()).isEqualTo(""TheGrpcClient"");
        assertThat(serverThreadName.get()).isEqualTo(""TheGrpcServer"");
    }
",non-flaky,5
113722,salesforce_reactive-grpc,ClientThreadIntegrationTest.manyToMany,"    @Test
    public void manyToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build(),
                HelloRequest.newBuilder().setName(""d"").build(),
                HelloRequest.newBuilder().setName(""e"").build());

        Flux<HelloResponse> resp = req.compose(stub::sayHelloBothStream);

        AtomicReference<String> clientThreadName = new AtomicReference<>();

        StepVerifier
                .create(resp
                        .map(HelloResponse::getMessage)
                        .doOnNext(x -> clientThreadName.set(Thread.currentThread().getName())))
                .expectNext(""Hello a and b"", ""Hello c and d"", ""Hello e"")
                .verifyComplete();

        assertThat(clientThreadName.get()).isEqualTo(""TheGrpcClient"");
        assertThat(serverThreadName.get()).isEqualTo(""TheGrpcServer"");
    }
",non-flaky,5
113723,salesforce_reactive-grpc,UnimplementedMethodIntegrationTest.unimplementedMethodShouldFail,"    @Test
    public void unimplementedMethodShouldFail() {
        GreeterGrpc.GreeterBlockingStub stub = GreeterGrpc.newBlockingStub(channel);

        assertThatThrownBy(() -> stub.sayHello(HelloRequest.newBuilder().setName(""World"").build()))
                .isInstanceOf(StatusRuntimeException.class)
                .hasMessageContaining(""UNIMPLEMENTED"");
    }
",non-flaky,5
113724,salesforce_reactive-grpc,AbstractStubTest.getChannelWorks,"    @Test
    public void getChannelWorks() {
        ManagedChannel channel = serverRule.getChannel();
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);

        assertThat(stub.getChannel()).isEqualTo(channel);
    }
",non-flaky,5
113725,salesforce_reactive-grpc,AbstractStubTest.settingCallOptionsWorks,"    @Test
    public void settingCallOptionsWorks() {
        ManagedChannel channel = serverRule.getChannel();
        Deadline deadline = Deadline.after(42, TimeUnit.SECONDS);

        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel).withDeadline(deadline);

        assertThat(stub.getCallOptions().getDeadline()).isEqualTo(deadline);
    }
",non-flaky,5
113726,salesforce_reactive-grpc,StandardClientReactiveServerInteropTest.oneToOne,"    @Test
    public void oneToOne() {
        AtomicBoolean called = new AtomicBoolean(false);
        GreeterGrpc.GreeterStub stub = GreeterGrpc.newStub(channel);

        HelloRequest request = HelloRequest.newBuilder().setName(""World"").build();
        stub.sayHello(request, new LambdaStreamObserver<>(
                response -> {
                    assertThat(response.getMessage()).isEqualTo(""Hello World"");
                    called.set(true);
                }
        ));

        await().atMost(1, TimeUnit.SECONDS).untilTrue(called);
    }
",non-flaky,5
113727,salesforce_reactive-grpc,StandardClientReactiveServerInteropTest.oneToMany,"    @Test
    public void oneToMany() {
        AtomicInteger called = new AtomicInteger(0);
        GreeterGrpc.GreeterStub stub = GreeterGrpc.newStub(channel);

        HelloRequest request = HelloRequest.newBuilder().setName(""World"").build();
        stub.sayHelloRespStream(request, new LambdaStreamObserver<>(
                response -> {
                    assertThat(response.getMessage()).isIn(""Hello World"", ""Hi World"", ""Greetings World"");
                    called.incrementAndGet();
                }
        ));

        await().atMost(1, TimeUnit.SECONDS).untilAtomic(called, equalTo(3));
    }
",non-flaky,5
113728,salesforce_reactive-grpc,StandardClientReactiveServerInteropTest.manyToOne,"    @Test
    public void manyToOne() {
        AtomicBoolean called = new AtomicBoolean(false);
        GreeterGrpc.GreeterStub stub = GreeterGrpc.newStub(channel);

        StreamObserver<HelloRequest> requestStream = stub.sayHelloReqStream(new LambdaStreamObserver<>(
                response -> {
                    assertThat(response.getMessage()).isEqualTo(""Hello A and B and C"");
                    called.set(true);
                }
        ));

        requestStream.onNext(HelloRequest.newBuilder().setName(""A"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""B"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""C"").build());
        requestStream.onCompleted();

        await().atMost(1, TimeUnit.SECONDS).untilTrue(called);
    }
",non-flaky,5
113729,salesforce_reactive-grpc,StandardClientReactiveServerInteropTest.manyToMany,"    @Test
    public void manyToMany() {
        AtomicInteger called = new AtomicInteger(0);
        GreeterGrpc.GreeterStub stub = GreeterGrpc.newStub(channel);

        StreamObserver<HelloRequest> requestStream = stub.sayHelloBothStream(new LambdaStreamObserver<>(
                response -> {
                    assertThat(response.getMessage()).isIn(""Hello A and B"", ""Hello C and D"");
                    called.incrementAndGet();
                }
        ));

        requestStream.onNext(HelloRequest.newBuilder().setName(""A"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""B"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""C"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""D"").build());
        requestStream.onCompleted();

        await().atMost(1, TimeUnit.SECONDS).untilAtomic(called, equalTo(2));
    }
",non-flaky,5
113730,salesforce_reactive-grpc,EndToEndIntegrationTest.oneToOne,"    @Test
    public void oneToOne() throws IOException {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloRequest> req = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Mono<HelloResponse> resp = req.compose(stub::sayHello);

        StepVerifier.create(resp.map(HelloResponse::getMessage))
                .expectNext(""Hello reactorjava"")
                .verifyComplete();
    }
",non-flaky,5
113731,salesforce_reactive-grpc,EndToEndIntegrationTest.oneToMany,"    @Test
    public void oneToMany() throws IOException {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloRequest> req = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Flux<HelloResponse> resp = req.as(stub::sayHelloRespStream);

        StepVerifier.create(resp.map(HelloResponse::getMessage))
                .expectNext(""Hello reactorjava"", ""Hi reactorjava"", ""Greetings reactorjava"")
                .verifyComplete();
    }
",non-flaky,5
113732,salesforce_reactive-grpc,EndToEndIntegrationTest.manyToOne,"    @Test
    public void manyToOne() throws Exception {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build());

        Mono<HelloResponse> resp = req.as(stub::sayHelloReqStream);

        StepVerifier.create(resp.map(HelloResponse::getMessage))
                .expectNext(""Hello a and b and c"")
                .verifyComplete();
    }
",non-flaky,5
113733,salesforce_reactive-grpc,EndToEndIntegrationTest.manyToMany,"    @Test
    public void manyToMany() throws Exception {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build(),
                HelloRequest.newBuilder().setName(""d"").build(),
                HelloRequest.newBuilder().setName(""e"").build());

        Flux<HelloResponse> resp = req.compose(stub::sayHelloBothStream);

        StepVerifier.create(resp.map(HelloResponse::getMessage))
                .expectNext(""Hello a and b"", ""Hello c and d"", ""Hello e"")
                .verifyComplete();
    }
",non-flaky,5
113734,salesforce_reactive-grpc,ConcurrentRequestIntegrationTest.fourKindsOfRequestAtOnce,"    @Test
    public void fourKindsOfRequestAtOnce() throws Exception {
        StepVerifier.setDefaultTimeout(Duration.ofSeconds(3));

        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);

        // == MAKE REQUESTS ==
        // One to One
        Mono<HelloRequest> req1 = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Mono<HelloResponse> resp1 = req1.compose(stub::sayHello);

        // One to Many
        Mono<HelloRequest> req2 = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Flux<HelloResponse> resp2 = req2.as(stub::sayHelloRespStream);

        // Many to One
        Flux<HelloRequest> req3 = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build());

        Mono<HelloResponse> resp3 = req3.as(stub::sayHelloReqStream);

        // Many to Many
        Flux<HelloRequest> req4 = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build(),
                HelloRequest.newBuilder().setName(""d"").build(),
                HelloRequest.newBuilder().setName(""e"").build());

        Flux<HelloResponse> resp4 = req4.compose(stub::sayHelloBothStream);

        // == VERIFY RESPONSES ==
        ListeningExecutorService executorService = MoreExecutors.listeningDecorator(Executors.newCachedThreadPool());

        // Run all four verifications in parallel
        try {
            // One to One
            ListenableFuture<Boolean> oneToOne = executorService.submit(() -> {
                StepVerifier.create(resp1.map(HelloResponse::getMessage))
                        .expectNext(""Hello reactorjava"")
                        .verifyComplete();
                return true;
            });

            // One to Many
            ListenableFuture<Boolean> oneToMany = executorService.submit(() -> {
                StepVerifier.create(resp2.map(HelloResponse::getMessage))
                        .expectNext(""Hello reactorjava"", ""Hi reactorjava"", ""Greetings reactorjava"")
                        .verifyComplete();
                return true;
            });

            // Many to One
            ListenableFuture<Boolean> manyToOne = executorService.submit(() -> {
                StepVerifier.create(resp3.map(HelloResponse::getMessage))
                        .expectNext(""Hello a and b and c"")
                        .verifyComplete();
                return true;
            });

            // Many to Many
            ListenableFuture<Boolean> manyToMany = executorService.submit(() -> {
                StepVerifier.create(resp4.map(HelloResponse::getMessage))
                        .expectNext(""Hello a and b"", ""Hello c and d"", ""Hello e"")
                        .verifyComplete();
                return true;
            });

            ListenableFuture<List<Boolean>> allFutures = Futures.allAsList(Lists.newArrayList(oneToOne, oneToMany, manyToOne, manyToMany));
            // Block for response
            List<Boolean> results = allFutures.get(3, TimeUnit.SECONDS);
            assertThat(results).containsExactly(true, true, true, true);

        } finally {
            executorService.shutdown();
        }
    }
",non-flaky,5
113735,salesforce_reactive-grpc,ReactiveClientStandardServerInteropTest.oneToOne,"    @Test
    public void oneToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<String> reactorRequest = Mono.just(""World"");
        Mono<String> reactorResponse = reactorRequest.map(this::toRequest).compose(stub::sayHello).map(this::fromResponse);

        StepVerifier.create(reactorResponse)
                .expectNext(""Hello World"")
                .verifyComplete();
    }
",non-flaky,5
113736,salesforce_reactive-grpc,ReactiveClientStandardServerInteropTest.oneToMany,"    @Test
    public void oneToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<String> reactorRequest = Mono.just(""World"");
        Flux<String> reactorResponse = reactorRequest.map(this::toRequest).as(stub::sayHelloRespStream).map(this::fromResponse);

        StepVerifier.create(reactorResponse)
                .expectNext(""Hello World"", ""Hi World"", ""Greetings World"")
                .verifyComplete();
    }
",non-flaky,5
113737,salesforce_reactive-grpc,ReactiveClientStandardServerInteropTest.manyToOne,"    @Test
    public void manyToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<String> reactorRequest = Flux.just(""A"", ""B"", ""C"");
        Mono<String> reactorResponse = reactorRequest.map(this::toRequest).as(stub::sayHelloReqStream).map(this::fromResponse);

        StepVerifier.create(reactorResponse)
                .expectNext(""Hello A and B and C"")
                .verifyComplete();
    }
",non-flaky,5
113738,salesforce_reactive-grpc,ReactiveClientStandardServerInteropTest.manyToMany,"    @Test
    public void manyToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<String> reactorRequest = Flux.just(""A"", ""B"", ""C"", ""D"");
        Flux<String> reactorResponse = reactorRequest.map(this::toRequest).compose(stub::sayHelloBothStream).map(this::fromResponse);

        StepVerifier.create(reactorResponse)
                .expectNext(""Hello A and B"", ""Hello C and D"")
                .verifyComplete();
    }
",non-flaky,5
113739,salesforce_reactive-grpc,ContextPropagationIntegrationTest.ClientSendsContext,"    @Test
    public void ClientSendsContext() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Context.current()
                .withValue(ctxKey, ""ClientSendsContext"")
                .run(() -> StepVerifier.create(worldReq.compose(stub::sayHello).map(HelloResponse::getMessage))
                        .expectNext(""Hello World"")
                        .verifyComplete());

        assertThat(clientInterceptor.getSendMessageCtxValue()).isEqualTo(""ClientSendsContext"");
    }
",non-flaky,5
113740,salesforce_reactive-grpc,ContextPropagationIntegrationTest.ClientGetsContext,"    @Test
    public void ClientGetsContext() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);

        Mono<HelloResponse> test = worldReq.compose(stub::sayHello)
                .doOnSuccess(resp -> {
                    Context ctx = Context.current();
                    assertThat(ctxKey.get(ctx)).isEqualTo(""ClientGetsContext"");
                });

        StepVerifier.create(test.map(HelloResponse::getMessage))
                .expectNext(""Hello World"")
                .verifyComplete();
    }
",non-flaky,5
113741,salesforce_reactive-grpc,ContextPropagationIntegrationTest.ServerAcceptsContext,"    @Test
    public void ServerAcceptsContext() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);

        StepVerifier.create(worldReq.compose(stub::sayHello).map(HelloResponse::getMessage))
                .expectNext(""Hello World"")
                .verifyComplete();
        assertThat(svc.getReceivedCtxValue()).isEqualTo(""ServerAcceptsContext"");
    }
",non-flaky,5
113742,salesforce_reactive-grpc,UnaryZeroMessageResponseIntegrationTest.zeroMessageResponseOneToOne,"    @Test
    public void zeroMessageResponseOneToOne() {
        serverRule.getServiceRegistry().addService(new MissingUnaryResponseService());

        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(serverRule.getChannel());
        Mono<HelloRequest> req = Mono.just(HelloRequest.newBuilder().setName(""reactor"").build());
        Mono<HelloResponse> resp = req.compose(stub::sayHello);

        StepVerifier.create(resp).verifyErrorMatches(t ->
                t instanceof StatusRuntimeException &&
                ((StatusRuntimeException) t).getStatus().getCode() == Status.Code.CANCELLED);
    }
",non-flaky,5
113743,salesforce_reactive-grpc,UnaryZeroMessageResponseIntegrationTest.zeroMessageResponseManyToOne,"    @Test
    public void zeroMessageResponseManyToOne() {
        serverRule.getServiceRegistry().addService(new MissingUnaryResponseService());

        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(serverRule.getChannel());
        Flux<HelloRequest> req = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build());

        Mono<HelloResponse> resp = req.as(stub::sayHelloReqStream);

        StepVerifier.create(resp).verifyErrorMatches(t ->
                t instanceof StatusRuntimeException &&
                ((StatusRuntimeException) t).getStatus().getCode() == Status.Code.CANCELLED);
    }
",non-flaky,5
113744,salesforce_reactive-grpc,ReactorGrpcPublisherManyToManyVerificationTest.createPublisher,"@Test(timeOut = 3000)
    public Publisher<Message> createPublisher(long elements) {
        ReactorTckGrpc.ReactorTckStub stub = ReactorTckGrpc.newReactorStub(channel);
        Flux<Message> request = Flux.range(0, (int)elements).map(this::toMessage);
        Publisher<Message> publisher = stub.manyToMany(request).publishOn(Schedulers.immediate());

        return publisher;
    }
",non-flaky,5
113745,salesforce_reactive-grpc,ReactorGrpcPublisherManyToOneVerificationTest.maxElementsFromPublisher,"@Test(timeOut = 3000)
    public long maxElementsFromPublisher() {
        return 1;
    }
",non-flaky,5
113746,salesforce_reactive-grpc,ReactorGrpcPublisherOneToOneVerificationTest.maxElementsFromPublisher,"@Test(timeOut = 3000)
    public long maxElementsFromPublisher() {
        return 1;
    }
",non-flaky,5
113747,salesforce_reactive-grpc,ReactorGrpcPublisherOneToManyVerificationTest.createPublisher,"@Test(timeOut = 3000)
    public Publisher<Message> createPublisher(long elements) {
        ReactorTckGrpc.ReactorTckStub stub = ReactorTckGrpc.newReactorStub(channel);
        Mono<Message> request = Mono.just(toMessage((int) elements));
        Publisher<Message> publisher = stub.oneToMany(request).publishOn(Schedulers.immediate());

        return publisher;
    }
",non-flaky,5
113748,salesforce_reactive-grpc,ReactorGrpcSubscriberWhiteboxVerificationTest.triggerRequest,"@Test(timeOut = 3000)
    public Subscriber<Message> createSubscriber(WhiteboxSubscriberProbe<Message> probe) {
        return new ReactivePublisherBackpressureOnReadyHandlerClient<Message>(new StubServerCallStreamObserver()) {
            @Override
            public void onSubscribe(final Subscription s) {
                super.onSubscribe(s);

                // register a successful Subscription, and create a Puppet,
                // for the WhiteboxVerification to be able to drive its tests:
                probe.registerOnSubscribe(new SubscriberPuppet() {

                    @Override
                    public void triggerRequest(long elements) {
                        s.request(elements);
                    }
",non-flaky,5
113749,salesforce_reactive-grpc,SubscribeOnlyOnceTest.subscribeOnlyOnceLifterErrorsWhenMultipleSubscribe,"    @Test
    public void subscribeOnlyOnceLifterErrorsWhenMultipleSubscribe() throws Exception {
        SubscribeOnlyOnceLifter<Object> op = new SubscribeOnlyOnceLifter<>();
        CoreSubscriber<Object> innerSub = mock(CoreSubscriber.class);
        Subscription subscription = mock(Subscription.class);

        CoreSubscriber<Object> outerSub = op.apply(null, innerSub);

        outerSub.onSubscribe(subscription);
        assertThatThrownBy(() -> outerSub.onSubscribe(subscription))
                .isInstanceOf(NullPointerException.class)
                .hasMessageContaining(""cannot directly subscribe to a gRPC service multiple times"");

        verify(innerSub, times(1)).onSubscribe(subscription);
    }
",non-flaky,5
113750,salesforce_reactive-grpc,BackpressureChunkingTest.chunkOperatorCorrectlyChunks,"    @Test
    public void chunkOperatorCorrectlyChunks() {
        final List<Long> requests = new ArrayList<>();
        int chunkSize = ReactiveBackpressureChunker.DEFAULT_CHUNK_SIZE;

        Flux<Integer> chunked = Flux.range(0, chunkSize + 4)
                .doOnRequest(requests::add)
                .transform(Operators.lift(new BackpressureChunkingLifter<Integer>()));

        StepVerifier.create(chunked)
                .expectNext(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19)
                .verifyComplete();

        assertThat(requests).containsExactly((long) chunkSize, (long) chunkSize);
    }
",non-flaky,5
113751,salesforce_reactive-grpc,ReactorConsumerStreamObserverTest.rxConsumerIsSet,"    @Test
    public void rxConsumerIsSet() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        ReactorConsumerStreamObserver rxObs = new ReactorConsumerStreamObserver();

        rxObs.beforeStart(obs);

        assertThat(rxObs.getRxConsumer()).isNotNull();
    }
",non-flaky,5
113752,salesforce_reactive-grpc,ReactorConsumerStreamObserverTest.onNextDelegates,"    @Test
    public void onNextDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        ReactorConsumerStreamObserver rxObs = new ReactorConsumerStreamObserver();
        Subscriber<Object> sub = mock(Subscriber.class);

        rxObs.beforeStart(obs);
        rxObs.getRxConsumer().subscribe(sub);

        Object obj = new Object();
        StepVerifier.create(rxObs.getRxConsumer())
                .then(() -> rxObs.onNext(obj))
                .expectNext(obj)
                .then(rxObs::onCompleted)
                .expectComplete()
                .verify(Duration.ofSeconds(3));
    }
",non-flaky,5
113753,salesforce_reactive-grpc,ReactorConsumerStreamObserverTest.onErrorDelegates,"    @Test
    public void onErrorDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        ReactorConsumerStreamObserver rxObs = new ReactorConsumerStreamObserver();
        Subscriber<Object> sub = mock(Subscriber.class);

        rxObs.beforeStart(obs);
        rxObs.getRxConsumer().subscribe(sub);

        Throwable obj = new Exception(""test error"");
        StepVerifier.create(rxObs.getRxConsumer())
                .then(() -> rxObs.onError(obj))
                .expectErrorMessage(""test error"")
                .verify(Duration.ofSeconds(3));
    }
",non-flaky,5
113754,salesforce_reactive-grpc,GrpcRetryTest.noRetryMakesErrorFlowabable,"    @Test
    public void noRetryMakesErrorFlowabable() {
        Flux<Integer> test = newThreeErrorFlux()
                .as(flux -> flux);

        StepVerifier.create(test)
                .expectErrorMessage(""Not yet!"")
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113755,salesforce_reactive-grpc,GrpcRetryTest.noRetryMakesErrorSingle,"    @Test
    public void noRetryMakesErrorSingle() {
        Mono<Integer> test = newThreeErrorMono()
                .as(mono -> mono);

        StepVerifier.create(test)
                .expectErrorMessage(""Not yet!"")
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113756,salesforce_reactive-grpc,GrpcRetryTest.oneToManyRetryWhen,"    @Test
    public void oneToManyRetryWhen() {
        Flux<Integer> test = newThreeErrorMono()
                .<Flux<Integer>>as(GrpcRetry.OneToMany.retryWhen(Mono::flux, Retry.any().retryMax(4)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113757,salesforce_reactive-grpc,GrpcRetryTest.oneToManyRetryImmediately,"    @Test
    public void oneToManyRetryImmediately() {
        Flux<Integer> test = newThreeErrorMono()
                .<Flux<Integer>>as(GrpcRetry.OneToMany.retryImmediately(Mono::flux));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113758,salesforce_reactive-grpc,GrpcRetryTest.oneToManyRetryAfter,"    @Test
    public void oneToManyRetryAfter() {
        Flux<Integer> test = newThreeErrorMono()
                .<Flux<Integer>>as(GrpcRetry.OneToMany.retryAfter(Mono::flux, Duration.ofMillis(10)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113759,salesforce_reactive-grpc,GrpcRetryTest.manyToManyRetryWhen,"    @Test
    public void manyToManyRetryWhen() {
        Flux<Integer> test = newThreeErrorFlux()
                .<Integer>compose(GrpcRetry.ManyToMany.retryWhen(Function.identity(), Retry.any().retryMax(4)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113760,salesforce_reactive-grpc,GrpcRetryTest.manyToManyRetryImmediately,"    @Test
    public void manyToManyRetryImmediately() {
        Flux<Integer> test = newThreeErrorFlux()
                .<Integer>compose(GrpcRetry.ManyToMany.retryImmediately(Function.identity()));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113761,salesforce_reactive-grpc,GrpcRetryTest.manyToManyRetryAfter,"    @Test
    public void manyToManyRetryAfter() {
        Flux<Integer> test = newThreeErrorFlux()
                .<Integer>compose(GrpcRetry.ManyToMany.retryAfter(Function.identity(), Duration.ofMillis(10)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113762,salesforce_reactive-grpc,GrpcRetryTest.manyToOneRetryWhen,"    @Test
    public void manyToOneRetryWhen() {
        Mono<Integer> test = newThreeErrorFlux()
                .<Mono<Integer>>as(GrpcRetry.ManyToOne.retryWhen(Flux::single, Retry.any().retryMax(4)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113763,salesforce_reactive-grpc,GrpcRetryTest.manyToOneRetryImmediately,"    @Test
    public void manyToOneRetryImmediately() {
        Mono<Integer> test = newThreeErrorFlux()
                .<Mono<Integer>>as(GrpcRetry.ManyToOne.retryImmediately(Flux::single));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113764,salesforce_reactive-grpc,GrpcRetryTest.manyToOneRetryAfter,"    @Test
    public void manyToOneRetryAfter() {
        Mono<Integer> test = newThreeErrorFlux()
                .<Mono<Integer>>as(GrpcRetry.ManyToOne.retryAfter(Flux::single, Duration.ofMillis(10)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
",non-flaky,5
113765,salesforce_reactive-grpc,ReactiveStreamObserverPublisherServerTest.onNextDelegates,"    @Test
    public void onNextDelegates() {
        ServerCallStreamObserver<Object> obs = mock(ServerCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherServer<Object> pub = new ReactiveStreamObserverPublisherServer<Object>(obs);
        pub.subscribe(sub);

        Object obj = new Object();

        pub.onNext(obj);
        verify(sub).onNext(obj);
    }
",non-flaky,5
113766,salesforce_reactive-grpc,ReactiveStreamObserverPublisherServerTest.onErrorDelegates,"    @Test
    public void onErrorDelegates() {
        ServerCallStreamObserver<Object> obs = mock(ServerCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherServer<Object> pub = new ReactiveStreamObserverPublisherServer<Object>(obs);
        pub.subscribe(sub);

        Throwable obj = new Exception();

        pub.onError(obj);
        verify(sub).onError(obj);
    }
",non-flaky,5
113767,salesforce_reactive-grpc,ReactiveStreamObserverPublisherServerTest.onCompletedDelegates,"    @Test
    public void onCompletedDelegates() {
        ServerCallStreamObserver<Object> obs = mock(ServerCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherServer<Object> pub = new ReactiveStreamObserverPublisherServer<Object>(obs);
        pub.subscribe(sub);

        pub.onCompleted();
        verify(sub).onComplete();
    }
",non-flaky,5
113768,salesforce_reactive-grpc,ReactiveStreamObserverPublisherServerTest.answer,"    @Test
    public void requestDelegates() {
        ServerCallStreamObserver<Object> obs = mock(ServerCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        final AtomicReference<Subscription> subscription = new AtomicReference<Subscription>();
        doAnswer(new Answer() {
            @Override
            public Object answer(InvocationOnMock invocationOnMock) {
                subscription.set((Subscription) invocationOnMock.getArguments()[0]);
                return null;
            }
",non-flaky,5
113769,salesforce_reactive-grpc,ReactiveStreamObserverPublisherClientTest.onNextDelegates,"    @Test
    public void onNextDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherClient<Object> pub = new ReactiveStreamObserverPublisherClient<Object>(obs);
        pub.subscribe(sub);

        Object obj = new Object();

        pub.onNext(obj);
        verify(sub).onNext(obj);
    }
",non-flaky,5
113770,salesforce_reactive-grpc,ReactiveStreamObserverPublisherClientTest.onErrorDelegates,"    @Test
    public void onErrorDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherClient<Object> pub = new ReactiveStreamObserverPublisherClient<Object>(obs);
        pub.subscribe(sub);

        Throwable obj = new Exception();

        pub.onError(obj);
        verify(sub).onError(obj);
    }
",non-flaky,5
113771,salesforce_reactive-grpc,ReactiveStreamObserverPublisherClientTest.onCompletedDelegates,"    @Test
    public void onCompletedDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherClient<Object> pub = new ReactiveStreamObserverPublisherClient<Object>(obs);
        pub.subscribe(sub);

        pub.onCompleted();
        verify(sub).onComplete();
    }
",non-flaky,5
113772,salesforce_reactive-grpc,ReactiveStreamObserverPublisherClientTest.answer,"    @Test
    public void requestDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        final AtomicReference<Subscription> subscription = new AtomicReference<Subscription>();
        doAnswer(new Answer() {
            @Override
            public Object answer(InvocationOnMock invocationOnMock) {
                subscription.set((Subscription) invocationOnMock.getArguments()[0]);
                return null;
            }
",non-flaky,5
113773,salesforce_reactive-grpc,CancellableStreamObserverTest.run,"    @Test
    public void statusExceptionTriggersHandler() {
        ClientResponseObserver<Object, Object> delegate = mock(ClientResponseObserver.class);
        final AtomicBoolean called = new AtomicBoolean(false);

        CancellableStreamObserver<Object, Object> observer = new CancellableStreamObserver<Object, Object>(delegate, new Runnable() {
            @Override
            public void run() {
                called.set(true);
            }
",non-flaky,5
113774,salesforce_reactive-grpc,CancellableStreamObserverTest.run,"    @Test
    public void statusRuntimeExceptionTriggersHandler() {
        ClientResponseObserver<Object, Object> delegate = mock(ClientResponseObserver.class);
        final AtomicBoolean called = new AtomicBoolean(false);

        CancellableStreamObserver<Object, Object> observer = new CancellableStreamObserver<Object, Object>(delegate, new Runnable() {
            @Override
            public void run() {
                called.set(true);
            }
",non-flaky,5
113775,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.applySubscribes,"    @Test
    public void applySubscribes() {
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(16);

        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        assertThat(chunkSubscriber).isNotNull();

        chunkSubscriber.onSubscribe(upstreamSubscription);
        assertThat(downstreamSubscriber.upstreamSubscription).isNotNull();
    }
",non-flaky,5
113776,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.requestOneGetsAChunk,"    @Test
    public void requestOneGetsAChunk() {
        int chunkSize = 16;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.request(1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
    }
",non-flaky,5
113777,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.requestOneSupplyOneDoesntRequestAnother,"    @Test
    public void requestOneSupplyOneDoesntRequestAnother() {
        int chunkSize = 16;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.request(1);
        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(chunkSize);
    }
",non-flaky,5
113778,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.requestManyGetsAChunkFirst,"    @Test
    public void requestManyGetsAChunkFirst() {
        int chunkSize = 16;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.request(256);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
    }
",non-flaky,5
113779,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.requestManyChunksRequestsAsSatisfiedAndStopsWhenComplete,"    @Test
    public void requestManyChunksRequestsAsSatisfiedAndStopsWhenComplete() {
        int chunkSize = 3;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.request(9);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(chunkSize);

        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(3);
        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(3);
        send(chunkSubscriber, 1);
        // Chunk satisfied, request next chunk
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(6);

        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(6);
        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(6);
        send(chunkSubscriber, 1);
        // Chunk satisfied, request next chunk
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(9);

        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(9);
        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(9);
        send(chunkSubscriber, 1);
        // Requested satisfied, do not request any more
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(9);
    }
",non-flaky,5
113780,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.completePropagatesDown,"    @Test
    public void completePropagatesDown() {
        int chunkSize = 3;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        chunkSubscriber.onComplete();
        assertThat(downstreamSubscriber.isComplete).isTrue();
    }
",non-flaky,5
113781,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.errorPropagatesDown,"    @Test
    public void errorPropagatesDown() {
        int chunkSize = 3;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        Throwable t = new Throwable();
        chunkSubscriber.onError(t);
        assertThat(downstreamSubscriber.lastThrowable).isEqualTo(t);
    }
",non-flaky,5
113782,salesforce_reactive-grpc,ReactiveBackpressureChunkerTest.cancelPropagatesUp,"    @Test
    public void cancelPropagatesUp() {
        int chunkSize = 3;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.cancel();
        assertThat(upstreamSubscription.isCancelled).isTrue();
    }
",non-flaky,5
113783,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.runPrimesThePump,"    @Test
    public void runPrimesThePump() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        when(obs.isReady()).thenReturn(true);
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);

        handler.onSubscribe(sub);

        handler.run();
        verify(sub).request(1);
    }
",non-flaky,5
113784,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.onNextKeepsPumpRunning,"    @Test
    public void onNextKeepsPumpRunning() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        when(obs.isReady()).thenReturn(true);

        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);

        handler.onSubscribe(sub);

        Object obj = new Object();
        handler.onNext(obj);

        verify(obs).onNext(obj);
        verify(sub).request(1);
    }
",non-flaky,5
113785,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.onNextStopsPump,"    @Test
    public void onNextStopsPump() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        when(obs.isReady()).thenReturn(false);

        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);

        handler.onSubscribe(sub);

        Object obj = new Object();
        handler.onNext(obj);

        verify(obs).onNext(obj);
        verify(sub, never()).request(1);
    }
",non-flaky,5
113786,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.exceptionInOnNextCancelsUpstreamSubscription,"    @Test
    public void exceptionInOnNextCancelsUpstreamSubscription() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        doThrow(new IllegalStateException(""won't be propagated to handler caller"")).when(obs).onNext(any());
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);
        handler.onSubscribe(sub);
        
        handler.onNext(new Object());
        verify(obs).cancel(anyString(), any(Throwable.class));
        verify(obs).onError(any(Throwable.class));
    }
",non-flaky,5
113787,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.exceptionInOnOnErrorCancelsUpstreamSubscription,"    @Test
    public void exceptionInOnOnErrorCancelsUpstreamSubscription() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        doThrow(new IllegalStateException(""won't be propagated to handler caller"")).when(obs).onError(any(Throwable.class));
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);
        handler.onSubscribe(sub);
        
        handler.onError(new RuntimeException());
        verify(obs).cancel(anyString(), any(Throwable.class));
    }
",non-flaky,5
113788,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.exceptionInOnCompleteCancelsUpstreamSubscription,"    @Test
    public void exceptionInOnCompleteCancelsUpstreamSubscription() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        doThrow(new IllegalStateException(""won't be propagated to handler caller"")).when(obs).onCompleted();
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);
        handler.onSubscribe(sub);
        
        handler.onComplete();
        verify(obs).cancel(anyString(), any(Throwable.class));
        verify(obs).onError(any(Throwable.class));
    }
",non-flaky,5
113789,salesforce_reactive-grpc,ReactivePublisherBackpressureOnReadyHandlerTest.onSubscribeCancelsSecondSubscription,"    @Test
    public void onSubscribeCancelsSecondSubscription() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub1 = mock(Subscription.class);
        Subscription sub2 = mock(Subscription.class);

        handler.onSubscribe(sub1);
        handler.onSubscribe(sub2);
        
        verify(sub2).cancel();
    }
",non-flaky,5
113790,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.clientCanCancelServerStreamExplicitly,"    @Test
    public void clientCanCancelServerStreamExplicitly() throws InterruptedException {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());
        TestSubscriber<NumberProto.Number> subscription = Single.just(Empty.getDefaultInstance())
                .as(stub::responsePressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""))
                .test();

        Thread.sleep(250);
        subscription.dispose();
        Thread.sleep(250);

        subscription.awaitTerminalEvent(3, TimeUnit.SECONDS);
        // Cancellation may or may not deliver the last generated message due to delays in the gRPC processing thread
        assertThat(Math.abs(subscription.valueCount() - svc.getLastNumberProduced())).isLessThanOrEqualTo(3);
        assertThat(svc.wasCanceled()).isTrue();

        errorRule.verifyNoError();
    }
",non-flaky,5
113791,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.clientCanCancelServerStreamImplicitly,"    @Test
    public void clientCanCancelServerStreamImplicitly() throws InterruptedException {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());
        TestSubscriber<NumberProto.Number> subscription =  Single.just(Empty.getDefaultInstance())
                .as(stub::responsePressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""))
                .take(10)
                .test();

        // Consume some work
        Thread.sleep(TimeUnit.SECONDS.toMillis(1));
        subscription.dispose();

        subscription.awaitTerminalEvent(3, TimeUnit.SECONDS);
        subscription.assertValueCount(10);
        subscription.assertTerminated();
        assertThat(svc.wasCanceled()).isTrue();

        errorRule.verifyNoError();
    }
",non-flaky,5
113792,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamImplicitly,"    @Test
    public void serverCanCancelClientStreamImplicitly() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        svc.setExplicitCancel(false);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flowable<NumberProto.Number> request = Flowable
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delay(10, TimeUnit.MILLISECONDS)
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(x -> {
                    requestDidProduce.set(true);
                    System.out.println(""Produced: "" + x.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        TestObserver<NumberProto.Number> observer = request
                .as(stub::requestPressure)
                .doOnSuccess(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .test();

        observer.awaitTerminalEvent(3, TimeUnit.SECONDS);
        observer.assertComplete();
        observer.assertTerminated();

        await().atMost(Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();

        errorRule.verifyNoError();
    }
",non-flaky,5
113793,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamExplicitly,"    @Test
    public void serverCanCancelClientStreamExplicitly() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        svc.setExplicitCancel(true);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flowable<NumberProto.Number> request = Flowable
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delay(10, TimeUnit.MILLISECONDS)
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(n -> {
                    requestDidProduce.set(true);
                    System.out.println(""P: "" + n.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        TestObserver<NumberProto.Number> observer = request
                .as(stub::requestPressure)
                .doOnSuccess(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .test();

        observer.awaitTerminalEvent();
        observer.assertComplete();
        observer.assertTerminated();

        await().atMost(Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();

        errorRule.verifyNoError();
    }
",non-flaky,5
113794,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamImplicitlyBidi,"    @Test
    public void serverCanCancelClientStreamImplicitlyBidi() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        svc.setExplicitCancel(false);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flowable<NumberProto.Number> request = Flowable
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delay(10, TimeUnit.MILLISECONDS)
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(x -> {
                    requestDidProduce.set(true);
                    System.out.println(""Produced: "" + x.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        TestSubscriber<NumberProto.Number> observer = request
                .compose(stub::twoWayPressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .test();

        observer.awaitTerminalEvent(3, TimeUnit.SECONDS);
        observer.assertTerminated();
        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();

        errorRule.verifyNoError();
    }
",non-flaky,5
113795,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.serverCanCancelClientStreamExplicitlyBidi,"    @Test
    public void serverCanCancelClientStreamExplicitlyBidi() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        svc.setExplicitCancel(true);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flowable<NumberProto.Number> request = Flowable
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delay(10, TimeUnit.MILLISECONDS)
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(n -> {
                    requestDidProduce.set(true);
                    System.out.println(""P: "" + n.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        TestSubscriber<NumberProto.Number> observer = request
                .compose(stub::twoWayPressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .test();

        observer.awaitTerminalEvent();
        observer.assertTerminated();
        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();

        errorRule.verifyNoError();
    }
",non-flaky,5
113796,salesforce_reactive-grpc,CancellationPropagationIntegrationTest.prematureResponseStreamDisposalShouldNotThrowUnhandledException,"    @Test
    public void prematureResponseStreamDisposalShouldNotThrowUnhandledException() throws Exception {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        // slowly process the response stream
        Disposable subscription = stub.responsePressure(Empty.getDefaultInstance()).subscribe(n -> {
            Thread.sleep(1000);
        });

        subscription.dispose();

        Thread.sleep(200);
        errorRule.verifyNoError();
    }
",non-flaky,5
113797,salesforce_reactive-grpc,ServerErrorIntegrationTest.oneToOne,"    @Test
    public void oneToOne() {
        RxGreeterGrpc.RxGreeterStub stub = RxGreeterGrpc.newRxStub(channel);
        Single<HelloResponse> resp = Single.just(HelloRequest.getDefaultInstance()).compose(stub::sayHello);
        TestObserver<HelloResponse> test = resp.test();

        test.awaitTerminalEvent(3, TimeUnit.SECONDS);
        test.assertError(t -> t instanceof StatusRuntimeException);
        test.assertError(t -> ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
",non-flaky,5
114034,aws_aws-sdk-java-v2,__handlerClassName__Test.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        ${handlerClassName} function = new ${handlerClassName}();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
114035,aws_aws-sdk-java-v2,MyDynamoDbStreamsFunctionTest.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        MyDynamoDbStreamsFunction function = new MyDynamoDbStreamsFunction();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
114036,aws_aws-sdk-java-v2,AppTest.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        App function = new App();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
114037,aws_aws-sdk-java-v2,MyNettyFunctionTest.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        MyNettyFunction function = new MyNettyFunction();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
114038,aws_aws-sdk-java-v2,MyWafRegionalFunctionTest.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        MyWafRegionalFunction function = new MyWafRegionalFunction();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
114039,aws_aws-sdk-java-v2,MyApacheFunctionTest.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        MyApacheFunction function = new MyApacheFunction();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
114040,aws_aws-sdk-java-v2,UpdateItemWithResponseIntegrationTest.updateItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull,"    @Test
    public void updateItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull() {
        Record record = new Record().setId(1).setId2(10);
        UpdateItemEnhancedRequest<Record> request = UpdateItemEnhancedRequest.builder(Record.class)
                                                                          .item(record)
                                                                          .build();

        UpdateItemEnhancedResponse<Record> response = mappedTable.updateItemWithResponse(request);

        assertThat(response.itemCollectionMetrics()).isNull();
    }
",non-flaky,5
114041,aws_aws-sdk-java-v2,UpdateItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Record record = new Record().setId(1).setId2(10);
        UpdateItemEnhancedRequest<Record> request = UpdateItemEnhancedRequest.builder(Record.class)
                                                                             .item(record)
                                                                             .returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE)
                                                                             .build();

        UpdateItemEnhancedResponse<Record> response = mappedTable.updateItemWithResponse(request);

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
114042,aws_aws-sdk-java-v2,PutItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull() {
        Record record = new Record().setId(1).setId2(10);
        PutItemEnhancedRequest<Record> request = PutItemEnhancedRequest.builder(Record.class)
                                                                       .item(record)
                                                                       .build();

        PutItemEnhancedResponse<Record> response = mappedTable.putItemWithResponse(request);

        assertThat(response.itemCollectionMetrics()).isNull();
    }
",non-flaky,5
114043,aws_aws-sdk-java-v2,PutItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Record record = new Record().setId(1).setId2(10);
        PutItemEnhancedRequest<Record> request = PutItemEnhancedRequest.builder(Record.class)
                                                                       .item(record)
                                                                       .returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE)
                                                                       .build();

        PutItemEnhancedResponse<Record> response = mappedTable.putItemWithResponse(request);

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
114044,aws_aws-sdk-java-v2,AsyncUpdateItemWithResponseIntegrationTest.updateItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull,"    @Test
    public void updateItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull() {
        Record record = new Record().setId(1).setId2(10);
        UpdateItemEnhancedRequest<Record> request = UpdateItemEnhancedRequest.builder(Record.class)
                                                                          .item(record)
                                                                          .build();

        UpdateItemEnhancedResponse<Record> response = mappedTable.updateItemWithResponse(request).join();

        assertThat(response.itemCollectionMetrics()).isNull();
    }
",non-flaky,5
114045,aws_aws-sdk-java-v2,AsyncUpdateItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Record record = new Record().setId(1).setId2(10);
        UpdateItemEnhancedRequest<Record> request = UpdateItemEnhancedRequest.builder(Record.class)
                                                                             .item(record)
                                                                             .returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE)
                                                                             .build();

        UpdateItemEnhancedResponse<Record> response = mappedTable.updateItemWithResponse(request).join();

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
114046,aws_aws-sdk-java-v2,DeleteItemWithResponseIntegrationTest.deleteItem_returnConsumedCapacity_unset_consumedCapacityNull,"    @Test
    public void deleteItem_returnConsumedCapacity_unset_consumedCapacityNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response = mappedTable.deleteItemWithResponse(r -> r.key(key));

        assertThat(response.consumedCapacity()).isNull();
    }
",non-flaky,5
114047,aws_aws-sdk-java-v2,DeleteItemWithResponseIntegrationTest.deleteItem_returnConsumedCapacity_set_consumedCapacityNotNull,"    @Test
    public void deleteItem_returnConsumedCapacity_set_consumedCapacityNotNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response =
            mappedTable.deleteItemWithResponse(r -> r.key(key).returnConsumedCapacity(ReturnConsumedCapacity.TOTAL));

        assertThat(response.consumedCapacity()).isNotNull();
    }
",non-flaky,5
114048,aws_aws-sdk-java-v2,DeleteItemWithResponseIntegrationTest.delete_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void delete_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response =
            mappedTable.deleteItemWithResponse(r -> r.key(key).returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE));

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
114049,aws_aws-sdk-java-v2,AsyncDeleteItemWithResponseIntegrationTest.deleteItem_returnConsumedCapacity_unset_consumedCapacityNull,"    @Test
    public void deleteItem_returnConsumedCapacity_unset_consumedCapacityNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response = mappedTable.deleteItemWithResponse(r -> r.key(key)).join();

        assertThat(response.consumedCapacity()).isNull();
    }
",non-flaky,5
114050,aws_aws-sdk-java-v2,AsyncDeleteItemWithResponseIntegrationTest.deleteItem_returnConsumedCapacity_set_consumedCapacityNotNull,"    @Test
    public void deleteItem_returnConsumedCapacity_set_consumedCapacityNotNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response =
            mappedTable.deleteItemWithResponse(r -> r.key(key).returnConsumedCapacity(ReturnConsumedCapacity.TOTAL)).join();

        assertThat(response.consumedCapacity()).isNotNull();
    }
",non-flaky,5
114051,aws_aws-sdk-java-v2,AsyncDeleteItemWithResponseIntegrationTest.delete_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void delete_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response =
            mappedTable.deleteItemWithResponse(r -> r.key(key).returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE))
                       .join();

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
114052,aws_aws-sdk-java-v2,AsyncPutItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull() {
        Record record = new Record().setId(1).setId2(10);
        PutItemEnhancedRequest<Record> request = PutItemEnhancedRequest.builder(Record.class)
                                                                       .item(record)
                                                                       .build();

        PutItemEnhancedResponse<Record> response = mappedTable.putItemWithResponse(request).join();

        assertThat(response.itemCollectionMetrics()).isNull();
    }
",non-flaky,5
114053,aws_aws-sdk-java-v2,AsyncPutItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Record record = new Record().setId(1).setId2(10);
        PutItemEnhancedRequest<Record> request = PutItemEnhancedRequest.builder(Record.class)
                                                                       .item(record)
                                                                       .returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE)
                                                                       .build();

        PutItemEnhancedResponse<Record> response = mappedTable.putItemWithResponse(request).join();

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
114054,aws_aws-sdk-java-v2,EnhancedTypeTest.anonymousCreationCapturesComplexTypeArguments,"    @Test
    public void anonymousCreationCapturesComplexTypeArguments() {
        EnhancedType<Map<String, List<List<String>>>> enhancedType = new EnhancedType<Map<String, List<List<String>>>>(){};
        assertThat(enhancedType.rawClass()).isEqualTo(Map.class);
        assertThat(enhancedType.rawClassParameters().get(0).rawClass()).isEqualTo(String.class);
        assertThat(enhancedType.rawClassParameters().get(1).rawClass()).isEqualTo(List.class);
        assertThat(enhancedType.rawClassParameters().get(1).rawClassParameters().get(0).rawClass()).isEqualTo(List.class);
        assertThat(enhancedType.rawClassParameters().get(1).rawClassParameters().get(0).rawClassParameters().get(0).rawClass())
            .isEqualTo(String.class);
    }
",non-flaky,5
114055,aws_aws-sdk-java-v2,EnhancedTypeTest.customTypesWork,"    @Test
    public void customTypesWork() {
        EnhancedType<EnhancedTypeTest> enhancedType = new EnhancedType<EnhancedTypeTest>(){};
        assertThat(enhancedType.rawClass()).isEqualTo(EnhancedTypeTest.class);
    }
",non-flaky,5
114056,aws_aws-sdk-java-v2,EnhancedTypeTest.nonStaticInnerTypesWork,"    @Test
    public void nonStaticInnerTypesWork() {
        EnhancedType<InnerType> enhancedType = new EnhancedType<InnerType>(){};
        assertThat(enhancedType.rawClass()).isEqualTo(InnerType.class);
    }
",non-flaky,5
114057,aws_aws-sdk-java-v2,EnhancedTypeTest.staticInnerTypesWork,"    @Test
    public void staticInnerTypesWork() {
        EnhancedType<InnerStaticType> enhancedType = new EnhancedType<InnerStaticType>(){};
        assertThat(enhancedType.rawClass()).isEqualTo(InnerStaticType.class);
    }
",non-flaky,5
114058,aws_aws-sdk-java-v2,EnhancedTypeTest.helperCreationMethodsWork,"    @Test
    public void helperCreationMethodsWork() {
        assertThat(EnhancedType.of(String.class).rawClass()).isEqualTo(String.class);

        assertThat(EnhancedType.listOf(String.class)).satisfies(v -> {
            assertThat(v.rawClass()).isEqualTo(List.class);
            assertThat(v.rawClassParameters()).hasSize(1);
            assertThat(v.rawClassParameters().get(0).rawClass()).isEqualTo(String.class);
        });

        assertThat(EnhancedType.mapOf(String.class, Integer.class)).satisfies(v -> {
            assertThat(v.rawClass()).isEqualTo(Map.class);
            assertThat(v.rawClassParameters()).hasSize(2);
            assertThat(v.rawClassParameters().get(0).rawClass()).isEqualTo(String.class);
            assertThat(v.rawClassParameters().get(1).rawClass()).isEqualTo(Integer.class);
        });
    }
",non-flaky,5
114059,aws_aws-sdk-java-v2,EnhancedTypeTest.equalityIsBasedOnInnerEquality,"    @Test
    public void equalityIsBasedOnInnerEquality() {
        verifyEquals(EnhancedType.of(String.class), EnhancedType.of(String.class));
        verifyNotEquals(EnhancedType.of(String.class), EnhancedType.of(Integer.class));

        verifyEquals(new EnhancedType<Map<String, List<String>>>(){}, new EnhancedType<Map<String, List<String>>>(){});
        verifyNotEquals(new EnhancedType<Map<String, List<String>>>(){}, new EnhancedType<Map<String,
            List<Integer>>>(){});

        TableSchema<String> tableSchema = StaticTableSchema.builder(String.class).build();

        verifyNotEquals(EnhancedType.documentOf(String.class,
                                             tableSchema,
                                             b -> b.ignoreNulls(false)), EnhancedType.documentOf(String.class,
                                                                                                 tableSchema,
                                                                                                 b -> b.ignoreNulls(true)));
        verifyEquals(EnhancedType.documentOf(String.class,
                                                tableSchema,
                                                b -> b.ignoreNulls(false).preserveEmptyObject(true)),
                        EnhancedType.documentOf(String.class,
                                                tableSchema,
                                                b -> b.ignoreNulls(false).preserveEmptyObject(true)));
    }
",non-flaky,5
114060,aws_aws-sdk-java-v2,EnhancedTypeTest.dequeOf_ReturnsRawClassOfDeque_WhenSpecifyingClass,"    @Test
    public void dequeOf_ReturnsRawClassOfDeque_WhenSpecifyingClass() {
        EnhancedType<Deque<String>> type = EnhancedType.dequeOf(String.class);

        assertThat(type.rawClass()).isEqualTo(Deque.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114061,aws_aws-sdk-java-v2,EnhancedTypeTest.dequeOf_ReturnsRawClassOfDeque_WhenSpecifyingEnhancedType,"    @Test
    public void dequeOf_ReturnsRawClassOfDeque_WhenSpecifyingEnhancedType() {
        EnhancedType<Deque<String>> type = EnhancedType.dequeOf(EnhancedType.of(String.class));

        assertThat(type.rawClass()).isEqualTo(Deque.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114062,aws_aws-sdk-java-v2,EnhancedTypeTest.sortedSetOf_ReturnsRawClassOfDeque_WhenSpecifyingClass,"    @Test
    public void sortedSetOf_ReturnsRawClassOfDeque_WhenSpecifyingClass() {
        EnhancedType<SortedSet<String>> type = EnhancedType.sortedSetOf(String.class);

        assertThat(type.rawClass()).isEqualTo(SortedSet.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114063,aws_aws-sdk-java-v2,EnhancedTypeTest.sortedSetOf_ReturnsRawClassOfDeque_WhenSpecifyingEnhancedType,"    @Test
    public void sortedSetOf_ReturnsRawClassOfDeque_WhenSpecifyingEnhancedType() {
        EnhancedType<SortedSet<String>> type = EnhancedType.sortedSetOf(EnhancedType.of(String.class));

        assertThat(type.rawClass()).isEqualTo(SortedSet.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114064,aws_aws-sdk-java-v2,EnhancedTypeTest.navigableSetOf_ReturnsRawClassOfNavigableSet_WhenSpecifyingClass,"    @Test
    public void navigableSetOf_ReturnsRawClassOfNavigableSet_WhenSpecifyingClass() {
        EnhancedType<NavigableSet<String>> type = EnhancedType.navigableSetOf(String.class);

        assertThat(type.rawClass()).isEqualTo(NavigableSet.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114065,aws_aws-sdk-java-v2,EnhancedTypeTest.navigableSetOf_ReturnsRawClassOfNavigableSet_WhenSpecifyingEnhancedType,"    @Test
    public void navigableSetOf_ReturnsRawClassOfNavigableSet_WhenSpecifyingEnhancedType() {
        EnhancedType<NavigableSet<String>> type = EnhancedType.navigableSetOf(EnhancedType.of(String.class));

        assertThat(type.rawClass()).isEqualTo(NavigableSet.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114066,aws_aws-sdk-java-v2,EnhancedTypeTest.collectionOf_ReturnsRawClassOfCollection_WhenSpecifyingClass,"    @Test
    public void collectionOf_ReturnsRawClassOfCollection_WhenSpecifyingClass() {
        EnhancedType<Collection<String>> type = EnhancedType.collectionOf(String.class);

        assertThat(type.rawClass()).isEqualTo(Collection.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114067,aws_aws-sdk-java-v2,EnhancedTypeTest.collectionOf_ReturnsRawClassOfCollection_WhenSpecifyingEnhancedType,"    @Test
    public void collectionOf_ReturnsRawClassOfCollection_WhenSpecifyingEnhancedType() {
        EnhancedType<Collection<String>> type = EnhancedType.collectionOf(EnhancedType.of(String.class));

        assertThat(type.rawClass()).isEqualTo(Collection.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114068,aws_aws-sdk-java-v2,EnhancedTypeTest.sortedMapOf_ReturnsRawClassOfSortedMap_WhenSpecifyingClass,"    @Test
    public void sortedMapOf_ReturnsRawClassOfSortedMap_WhenSpecifyingClass() {
        EnhancedType<SortedMap<String, Integer>> type = EnhancedType.sortedMapOf(String.class, Integer.class);

        assertThat(type.rawClass()).isEqualTo(SortedMap.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class), EnhancedType.of(Integer.class));
    }
",non-flaky,5
114069,aws_aws-sdk-java-v2,EnhancedTypeTest.sortedMapOf_ReturnsRawClassOfSortedMap_WhenSpecifyingEnhancedType,"    @Test
    public void sortedMapOf_ReturnsRawClassOfSortedMap_WhenSpecifyingEnhancedType() {
        EnhancedType<SortedMap<String, Integer>> type =
            EnhancedType.sortedMapOf(EnhancedType.of(String.class), EnhancedType.of(Integer.class));

        assertThat(type.rawClass()).isEqualTo(SortedMap.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class), EnhancedType.of(Integer.class));
    }
",non-flaky,5
114070,aws_aws-sdk-java-v2,EnhancedTypeTest.concurrentMapOf_ReturnsRawClassOfConcurrentMap_WhenSpecifyingClass,"    @Test
    public void concurrentMapOf_ReturnsRawClassOfConcurrentMap_WhenSpecifyingClass() {
        EnhancedType<ConcurrentMap<String, Integer>> type = EnhancedType.concurrentMapOf(String.class, Integer.class);

        assertThat(type.rawClass()).isEqualTo(ConcurrentMap.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class), EnhancedType.of(Integer.class));
    }
",non-flaky,5
114071,aws_aws-sdk-java-v2,EnhancedTypeTest.concurrentMapOf_ReturnsRawClassOfConcurrentMap_WhenSpecifyingEnhancedType,"    @Test
    public void concurrentMapOf_ReturnsRawClassOfConcurrentMap_WhenSpecifyingEnhancedType() {
        EnhancedType<ConcurrentMap<String, Integer>> type =
            EnhancedType.concurrentMapOf(EnhancedType.of(String.class), EnhancedType.of(Integer.class));

        assertThat(type.rawClass()).isEqualTo(ConcurrentMap.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class), EnhancedType.of(Integer.class));
    }
",non-flaky,5
114072,aws_aws-sdk-java-v2,EnhancedTypeTest.navigableMapOf_ReturnsRawClassOfNavigableMap_WhenSpecifyingClass,"    @Test
    public void navigableMapOf_ReturnsRawClassOfNavigableMap_WhenSpecifyingClass() {
        EnhancedType<NavigableMap<String, Integer>> type = EnhancedType.navigableMapOf(String.class, Integer.class);

        assertThat(type.rawClass()).isEqualTo(NavigableMap.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class), EnhancedType.of(Integer.class));
    }
",non-flaky,5
114073,aws_aws-sdk-java-v2,EnhancedTypeTest.navigableMapOf_ReturnsRawClassOfNavigableMap_WhenSpecifyingEnhancedType,"    @Test
    public void navigableMapOf_ReturnsRawClassOfNavigableMap_WhenSpecifyingEnhancedType() {
        EnhancedType<NavigableMap<String, Integer>> type =
            EnhancedType.navigableMapOf(EnhancedType.of(String.class), EnhancedType.of(Integer.class));

        assertThat(type.rawClass()).isEqualTo(NavigableMap.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class), EnhancedType.of(Integer.class));
    }
",non-flaky,5
114074,aws_aws-sdk-java-v2,EnhancedTypeTest.documentOf_toString_doesNotRaiseNPE,"    @Test
    public void documentOf_toString_doesNotRaiseNPE() {
        TableSchema<String> tableSchema = StaticTableSchema.builder(String.class).build();
        EnhancedType<String> type = EnhancedType.documentOf(String.class, tableSchema);
        assertThatCode(() -> type.toString()).doesNotThrowAnyException();
    }
",non-flaky,5
114075,aws_aws-sdk-java-v2,EnhancedTypeTest.documentOf_withEnhancedTypeConfiguration,"    @Test
    public void documentOf_withEnhancedTypeConfiguration() {
        TableSchema<String> tableSchema = StaticTableSchema.builder(String.class).build();
        EnhancedType<String> type = EnhancedType.documentOf(String.class, tableSchema, b -> b.preserveEmptyObject(true));
        assertThat(type.documentConfiguration()).isPresent();
        assertThat(type.documentConfiguration().get().preserveEmptyObject()).isTrue();
    }
",non-flaky,5
114076,aws_aws-sdk-java-v2,ExpressionTest.join_correctlyWrapsExpressions,"    @Test
    public void join_correctlyWrapsExpressions() {
        Expression expression1 = Expression.builder().expression(""one"").build();
        Expression expression2 = Expression.builder().expression(""two"").build();
        Expression expression3 = Expression.builder().expression(""three"").build();

        Expression coalescedExpression = Expression.join(Expression.join(expression1, expression2, "" AND ""),
                                                         expression3, "" AND "");

        String expectedExpression = ""((one) AND (two)) AND (three)"";
        assertThat(coalescedExpression.expression(), is(expectedExpression));
    }
",non-flaky,5
114077,aws_aws-sdk-java-v2,ExpressionTest.joinExpressions_correctlyJoins,"    @Test
    public void joinExpressions_correctlyJoins() {
        String result = Expression.joinExpressions(""one"", ""two"", "" AND "");
        assertThat(result, is(""(one) AND (two)""));
    }
",non-flaky,5
114078,aws_aws-sdk-java-v2,ExpressionTest.joinNames_correctlyJoins,"    @Test
    public void joinNames_correctlyJoins() {
        Map<String, String> names1 = new HashMap<>();
        names1.put(""one"", ""1"");
        names1.put(""two"", ""2"");
        Map<String, String> names2 = new HashMap<>();
        names2.put(""three"", ""3"");
        names2.put(""four"", ""4"");

        Map<String, String> result = Expression.joinNames(names1, names2);

        assertThat(result.size(), is(4));
        assertThat(result, hasEntry(""one"", ""1""));
        assertThat(result, hasEntry(""two"", ""2""));
        assertThat(result, hasEntry(""three"", ""3""));
        assertThat(result, hasEntry(""four"", ""4""));
    }
",non-flaky,5
114079,aws_aws-sdk-java-v2,ExpressionTest.joinNames_correctlyJoinsEmpty,"    @Test
    public void joinNames_correctlyJoinsEmpty() {
        Map<String, String> names1 = new HashMap<>();
        names1.put(""one"", ""1"");
        names1.put(""two"", ""2"");
        Map<String, String> names2 = new HashMap<>();
        names2.put(""three"", ""3"");
        names2.put(""four"", ""4"");

        Map<String, String> result = Expression.joinNames(names1, null);
        assertThat(result.size(), is(2));
        assertThat(result, hasEntry(""one"", ""1""));
        assertThat(result, hasEntry(""two"", ""2""));

        result = Expression.joinNames(null, names2);
        assertThat(result.size(), is(2));
        assertThat(result, hasEntry(""three"", ""3""));
        assertThat(result, hasEntry(""four"", ""4""));

        result = Expression.joinNames(names1, Collections.emptyMap());
        assertThat(result.size(), is(2));
        assertThat(result, hasEntry(""one"", ""1""));
        assertThat(result, hasEntry(""two"", ""2""));

        result = Expression.joinNames(Collections.emptyMap(), names2);
        assertThat(result.size(), is(2));
        assertThat(result, hasEntry(""three"", ""3""));
        assertThat(result, hasEntry(""four"", ""4""));
    }
",non-flaky,5
114080,aws_aws-sdk-java-v2,ExpressionTest.joinNames_conflictingKey,"    @Test
    public void joinNames_conflictingKey() {
        Map<String, String> names1 = new HashMap<>();
        names1.put(""one"", ""1"");
        names1.put(""two"", ""2"");
        Map<String, String> names2 = new HashMap<>();
        names2.put(""three"", ""3"");
        names2.put(""two"", ""4"");

        exception.expect(IllegalArgumentException.class);
        exception.expectMessage(""two"");
        Expression.joinNames(names1, names2);
    }
",non-flaky,5
114081,aws_aws-sdk-java-v2,ExpressionTest.joinValues_correctlyJoins,"    @Test
    public void joinValues_correctlyJoins() {
        Map<String, AttributeValue> values1 = new HashMap<>();
        values1.put(""one"", EnhancedAttributeValue.fromString(""1"").toAttributeValue());
        values1.put(""two"", EnhancedAttributeValue.fromString(""2"").toAttributeValue());
        Map<String, AttributeValue> values2 = new HashMap<>();
        values2.put(""three"", EnhancedAttributeValue.fromString(""3"").toAttributeValue());
        values2.put(""four"", EnhancedAttributeValue.fromString(""4"").toAttributeValue());

        Map<String, AttributeValue> result = Expression.joinValues(values1, values2);

        assertThat(result.size(), is(4));
        assertThat(result, hasEntry(""one"", EnhancedAttributeValue.fromString(""1"").toAttributeValue()));
        assertThat(result, hasEntry(""two"", EnhancedAttributeValue.fromString(""2"").toAttributeValue()));
        assertThat(result, hasEntry(""three"", EnhancedAttributeValue.fromString(""3"").toAttributeValue()));
        assertThat(result, hasEntry(""four"", EnhancedAttributeValue.fromString(""4"").toAttributeValue()));
    }
",non-flaky,5
114082,aws_aws-sdk-java-v2,ExpressionTest.joinValues_conflictingKey,"    @Test
    public void joinValues_conflictingKey() {
        Map<String, AttributeValue> values1 = new HashMap<>();
        values1.put(""one"", EnhancedAttributeValue.fromString(""1"").toAttributeValue());
        values1.put(""two"", EnhancedAttributeValue.fromString(""2"").toAttributeValue());
        Map<String, AttributeValue> values2 = new HashMap<>();
        values2.put(""three"", EnhancedAttributeValue.fromString(""3"").toAttributeValue());
        values2.put(""two"", EnhancedAttributeValue.fromString(""4"").toAttributeValue());

        exception.expect(IllegalArgumentException.class);
        exception.expectMessage(""two"");
        Expression.joinValues(values1, values2);
    }
",non-flaky,5
114083,aws_aws-sdk-java-v2,KeyTest.getKeyMap,"    @Test
    public void getKeyMap() {
        Map<String, AttributeValue> expectedResult = new HashMap<>();
        expectedResult.put(""gsi_id"", AttributeValue.builder().s(""id123"").build());
        expectedResult.put(""gsi_sort"", AttributeValue.builder().s(""id456"").build());
        assertThat(key.keyMap(FakeItemWithIndices.getTableSchema(), ""gsi_1""), is(expectedResult));
    }
",non-flaky,5
114084,aws_aws-sdk-java-v2,KeyTest.getPrimaryKeyMap,"    @Test
    public void getPrimaryKeyMap() {
        Map<String, AttributeValue> expectedResult = new HashMap<>();
        expectedResult.put(""id"", AttributeValue.builder().s(""id123"").build());
        expectedResult.put(""sort"", AttributeValue.builder().s(""id456"").build());
        assertThat(key.primaryKeyMap(FakeItemWithIndices.getTableSchema()), is(expectedResult));
    }
",non-flaky,5
114085,aws_aws-sdk-java-v2,KeyTest.getPartitionKeyValue,"    @Test
    public void getPartitionKeyValue() {
        assertThat(key.partitionKeyValue(),
                   is(AttributeValue.builder().s(""id123"").build()));
    }
",non-flaky,5
114086,aws_aws-sdk-java-v2,KeyTest.getSortKeyValue,"    @Test
    public void getSortKeyValue() {
        assertThat(key.sortKeyValue(), is(Optional.of(AttributeValue.builder().s(""id456"").build())));
    }
",non-flaky,5
114087,aws_aws-sdk-java-v2,KeyTest.getKeyMap_partitionOnly,"    @Test
    public void getKeyMap_partitionOnly() {
        Map<String, AttributeValue> expectedResult = new HashMap<>();
        expectedResult.put(""gsi_id"", AttributeValue.builder().s(""id123"").build());
        assertThat(partitionOnlyKey.keyMap(FakeItemWithIndices.getTableSchema(), ""gsi_1""), is(expectedResult));
    }
",non-flaky,5
114088,aws_aws-sdk-java-v2,KeyTest.getPrimaryKeyMap_partitionOnly,"    @Test
    public void getPrimaryKeyMap_partitionOnly() {
        Map<String, AttributeValue> expectedResult = new HashMap<>();
        expectedResult.put(""id"", AttributeValue.builder().s(""id123"").build());
        assertThat(partitionOnlyKey.primaryKeyMap(FakeItemWithIndices.getTableSchema()), is(expectedResult));
    }
",non-flaky,5
114089,aws_aws-sdk-java-v2,KeyTest.getPartitionKeyValue_partitionOnly,"    @Test
    public void getPartitionKeyValue_partitionOnly() {
        assertThat(partitionOnlyKey.partitionKeyValue(),
                   is(AttributeValue.builder().s(""id123"").build()));
    }
",non-flaky,5
114090,aws_aws-sdk-java-v2,KeyTest.getSortKeyValue_partitionOnly,"    @Test
    public void getSortKeyValue_partitionOnly() {
        assertThat(partitionOnlyKey.sortKeyValue(), is(Optional.empty()));
    }
",non-flaky,5
114091,aws_aws-sdk-java-v2,KeyTest.numericKeys_convertsToCorrectAttributeValue,"    @Test
    public void numericKeys_convertsToCorrectAttributeValue() {
        Key key = Key.builder().partitionValue(123).sortValue(45.6).build();

        assertThat(key.partitionKeyValue(), is(AttributeValue.builder().n(""123"").build()));
        assertThat(key.sortKeyValue(), is(Optional.of(AttributeValue.builder().n(""45.6"").build())));
    }
",non-flaky,5
114092,aws_aws-sdk-java-v2,KeyTest.stringKeys_convertsToCorrectAttributeValue,"    @Test
    public void stringKeys_convertsToCorrectAttributeValue() {
        Key key = Key.builder().partitionValue(""one"").sortValue(""two"").build();

        assertThat(key.partitionKeyValue(), is(AttributeValue.builder().s(""one"").build()));
        assertThat(key.sortKeyValue(), is(Optional.of(AttributeValue.builder().s(""two"").build())));
    }
",non-flaky,5
114093,aws_aws-sdk-java-v2,KeyTest.binaryKeys_convertsToCorrectAttributeValue,"    @Test
    public void binaryKeys_convertsToCorrectAttributeValue() {
        SdkBytes partition = SdkBytes.fromString(""one"", StandardCharsets.UTF_8);
        SdkBytes sort = SdkBytes.fromString(""two"", StandardCharsets.UTF_8);

        Key key = Key.builder().partitionValue(partition).sortValue(sort).build();

        assertThat(key.partitionKeyValue(), is(AttributeValue.builder().b(partition).build()));
        assertThat(key.sortKeyValue(), is(Optional.of(AttributeValue.builder().b(sort).build())));
    }
",non-flaky,5
114094,aws_aws-sdk-java-v2,KeyTest.toBuilder,"    @Test
    public void toBuilder() {
        Key keyClone = key.toBuilder().build();

        assertThat(key, is(equalTo(keyClone)));
    }
",non-flaky,5
114095,aws_aws-sdk-java-v2,KeyTest.nullPartitionKey_shouldThrowException,"    @Test
    public void nullPartitionKey_shouldThrowException() {
        AttributeValue attributeValue = null;
        assertThatThrownBy(() ->  Key.builder().partitionValue(attributeValue).build())
         .isInstanceOf(IllegalArgumentException.class).hasMessageContaining(""partitionValue should not be null"");

        assertThatThrownBy(() ->  Key.builder().partitionValue(AttributeValue.builder().nul(true).build()).build())
            .isInstanceOf(IllegalArgumentException.class).hasMessageContaining(""partitionValue should not be null"");
    }
",non-flaky,5
114096,aws_aws-sdk-java-v2,TableSchemaTest.builder_constructsStaticTableSchemaBuilder,"    @Test
    public void builder_constructsStaticTableSchemaBuilder() {
        StaticTableSchema.Builder<FakeItem> builder = TableSchema.builder(FakeItem.class);
        assertThat(builder).isNotNull();
    }
",non-flaky,5
114097,aws_aws-sdk-java-v2,TableSchemaTest.fromBean_constructsBeanTableSchema,"    @Test
    public void fromBean_constructsBeanTableSchema() {
        BeanTableSchema<SimpleBean> beanBeanTableSchema = TableSchema.fromBean(SimpleBean.class);
        assertThat(beanBeanTableSchema).isNotNull();
    }
",non-flaky,5
114098,aws_aws-sdk-java-v2,TableSchemaTest.fromImmutable_constructsImmutableTableSchema,"    @Test
    public void fromImmutable_constructsImmutableTableSchema() {
        ImmutableTableSchema<SimpleImmutable> immutableTableSchema =
            TableSchema.fromImmutableClass(SimpleImmutable.class);

        assertThat(immutableTableSchema).isNotNull();
    }
",non-flaky,5
114099,aws_aws-sdk-java-v2,TableSchemaTest.fromClass_constructsBeanTableSchema,"    @Test
    public void fromClass_constructsBeanTableSchema() {
        TableSchema<SimpleBean> tableSchema = TableSchema.fromClass(SimpleBean.class);
        assertThat(tableSchema).isInstanceOf(BeanTableSchema.class);
    }
",non-flaky,5
114100,aws_aws-sdk-java-v2,TableSchemaTest.fromClass_constructsImmutableTableSchema,"    @Test
    public void fromClass_constructsImmutableTableSchema() {
        TableSchema<SimpleImmutable> tableSchema = TableSchema.fromClass(SimpleImmutable.class);
        assertThat(tableSchema).isInstanceOf(ImmutableTableSchema.class);
    }
",non-flaky,5
114101,aws_aws-sdk-java-v2,TableSchemaTest.fromClass_invalidClassThrowsException,"    @Test
    public void fromClass_invalidClassThrowsException() {
        exception.expect(IllegalArgumentException.class);
        exception.expectMessage(""InvalidBean"");
        TableSchema.fromClass(InvalidBean.class);
    }
",non-flaky,5
114102,aws_aws-sdk-java-v2,EnhancedTypeDocumentationConfigurationTest.defaultBuilder_defaultToFalse,"    @Test
    public void defaultBuilder_defaultToFalse() {
        EnhancedTypeDocumentConfiguration configuration =
            EnhancedTypeDocumentConfiguration.builder().build();
        assertThat(configuration.ignoreNulls()).isFalse();
        assertThat(configuration.preserveEmptyObject()).isFalse();
    }
",non-flaky,5
114103,aws_aws-sdk-java-v2,EnhancedTypeDocumentationConfigurationTest.equalsHashCode,"    @Test
    public void equalsHashCode() {
        EnhancedTypeDocumentConfiguration configuration =
            EnhancedTypeDocumentConfiguration.builder()
                                             .preserveEmptyObject(true)
                                             .ignoreNulls(false)
                                             .build();

        EnhancedTypeDocumentConfiguration another =
            EnhancedTypeDocumentConfiguration.builder()
                                             .preserveEmptyObject(true)
                                             .ignoreNulls(false)
                                             .build();

        EnhancedTypeDocumentConfiguration different =
            EnhancedTypeDocumentConfiguration.builder()
                                             .preserveEmptyObject(false)
                                             .ignoreNulls(true)
                                             .build();

        assertThat(configuration).isEqualTo(another);
        assertThat(configuration.hashCode()).isEqualTo(another.hashCode());
        assertThat(configuration).isNotEqualTo(different);
        assertThat(configuration.hashCode()).isNotEqualTo(different.hashCode());
    }
",non-flaky,5
114104,aws_aws-sdk-java-v2,TypeConvertingVisitorTest.defaultConvertersThrowExceptions,"    @Test
    public void defaultConvertersThrowExceptions() {
        assertThat(DefaultVisitor.INSTANCE.convert(EnhancedAttributeValue.nullValue())).isEqualTo(null);

        assertDefaultConversionFails(EnhancedAttributeValue.fromString(""foo""));
        assertDefaultConversionFails(EnhancedAttributeValue.fromNumber(""1""));
        assertDefaultConversionFails(EnhancedAttributeValue.fromBoolean(true));
        assertDefaultConversionFails(EnhancedAttributeValue.fromBytes(SdkBytes.fromUtf8String("""")));
        assertDefaultConversionFails(EnhancedAttributeValue.fromSetOfStrings(Collections.emptyList()));
        assertDefaultConversionFails(EnhancedAttributeValue.fromSetOfNumbers(Collections.emptyList()));
        assertDefaultConversionFails(EnhancedAttributeValue.fromSetOfBytes(Collections.emptyList()));
        assertDefaultConversionFails(EnhancedAttributeValue.fromListOfAttributeValues(Collections.emptyList()));
        assertDefaultConversionFails(EnhancedAttributeValue.fromMap(Collections.emptyMap()));
    }
",non-flaky,5
114105,aws_aws-sdk-java-v2,OptionalAttributeConvertersTest.optionalDoubleConverterWorksCorrectly,"    @Test
    public void optionalDoubleConverterWorksCorrectly() {
        OptionalDoubleAttributeConverter converter = OptionalDoubleAttributeConverter.create();

        assertThat(transformFrom(converter, OptionalDouble.empty())).isEqualTo(nullValue().toAttributeValue());
        assertThat(transformFrom(converter, OptionalDouble.of(-Double.MAX_VALUE))).isEqualTo(fromNumber(""-1.7976931348623157E308"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalDouble.of(-Double.MIN_VALUE))).isEqualTo(fromNumber(""-4.9E-324"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalDouble.of(0.0))).isEqualTo(fromNumber(""0.0"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalDouble.of(Double.MIN_VALUE))).isEqualTo(fromNumber(""4.9E-324"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalDouble.of(Double.MAX_VALUE))).isEqualTo(fromNumber(""1.7976931348623157E308"").toAttributeValue());

        assertThat(transformTo(converter, nullValue().toAttributeValue())).isEmpty();
        assertThat(transformTo(converter, fromNumber(""-1.7976931348623157E308""))).hasValue(-Double.MAX_VALUE);
        assertThat(transformTo(converter, fromNumber(""-4.9E-324""))).hasValue(-Double.MIN_VALUE);
        assertThat(transformTo(converter, fromNumber(""0.0""))).hasValue(0.0);
        assertThat(transformTo(converter, fromNumber(""4.9E-324""))).hasValue(Double.MIN_VALUE);
        assertThat(transformTo(converter, fromNumber(""1.7976931348623157E308""))).hasValue(Double.MAX_VALUE);
    }
",non-flaky,5
114106,aws_aws-sdk-java-v2,OptionalAttributeConvertersTest.optionalIntConverterWorksCorrectly,"    @Test
    public void optionalIntConverterWorksCorrectly() {
        OptionalIntAttributeConverter converter = OptionalIntAttributeConverter.create();

        assertThat(transformFrom(converter, OptionalInt.empty())).isEqualTo(nullValue().toAttributeValue());
        assertThat(transformFrom(converter, OptionalInt.of(Integer.MIN_VALUE))).isEqualTo(fromNumber(""-2147483648"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalInt.of(0))).isEqualTo(fromNumber(""0"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalInt.of(Integer.MAX_VALUE))).isEqualTo(fromNumber(""2147483647"").toAttributeValue());

        assertThat(transformTo(converter, nullValue().toAttributeValue())).isEmpty();
        assertThat(transformTo(converter, fromNumber(""-2147483648""))).hasValue(Integer.MIN_VALUE);
        assertThat(transformTo(converter, fromNumber(""0""))).hasValue(0);
        assertThat(transformTo(converter, fromNumber(""2147483647""))).hasValue(Integer.MAX_VALUE);
    }
",non-flaky,5
114107,aws_aws-sdk-java-v2,OptionalAttributeConvertersTest.optionalLongConverterWorksCorrectly,"    @Test
    public void optionalLongConverterWorksCorrectly() {
        OptionalLongAttributeConverter converter = OptionalLongAttributeConverter.create();

        assertThat(transformFrom(converter, OptionalLong.empty())).isEqualTo(nullValue().toAttributeValue());
        assertThat(transformFrom(converter, OptionalLong.of(Long.MIN_VALUE))).isEqualTo(fromNumber(""-9223372036854775808"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalLong.of(0))).isEqualTo(fromNumber(""0"").toAttributeValue());
        assertThat(transformFrom(converter, OptionalLong.of(Long.MAX_VALUE))).isEqualTo(fromNumber(""9223372036854775807"").toAttributeValue());

        assertThat(transformTo(converter, nullValue().toAttributeValue())).isEmpty();
        assertThat(transformTo(converter, fromNumber(""-9223372036854775808""))).hasValue(Long.MIN_VALUE);
        assertThat(transformTo(converter, fromNumber(""0""))).hasValue(0);
        assertThat(transformTo(converter, fromNumber(""9223372036854775807""))).hasValue(Long.MAX_VALUE);
    }
",non-flaky,5
114108,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterMinTest,"    @Test
    public void InstantAsStringAttributeConverterMinTest() {
        verifyTransform(Instant.MIN, ""-1000000000-01-01T00:00:00Z"");
    }
",non-flaky,5
114109,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterEpochMinusOneMilliTest,"    @Test
    public void InstantAsStringAttributeConverterEpochMinusOneMilliTest() {
        verifyTransform(Instant.EPOCH.minusMillis(1), ""1969-12-31T23:59:59.999Z"");
    }
",non-flaky,5
114110,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterEpochTest,"    @Test
    public void InstantAsStringAttributeConverterEpochTest() {
        verifyTransform(Instant.EPOCH, ""1970-01-01T00:00:00Z"");
    }
",non-flaky,5
114111,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterEpochPlusOneMilliTest,"    @Test
    public void InstantAsStringAttributeConverterEpochPlusOneMilliTest() {
        verifyTransform(Instant.EPOCH.plusMillis(1), ""1970-01-01T00:00:00.001Z"");
    }
",non-flaky,5
114112,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterMaxTest,"    @Test
    public void InstantAsStringAttributeConverterMaxTest() {
        verifyTransform(Instant.MAX, ""+1000000000-12-31T23:59:59.999999999Z"");
    }
",non-flaky,5
114113,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterExceedLowerBoundTest,"    @Test
    public void InstantAsStringAttributeConverterExceedLowerBoundTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""-1000000001-12-31T23:59:59.999999999Z"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114114,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterInvalidFormatTest,"    @Test
    public void InstantAsStringAttributeConverterInvalidFormatTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""X"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114115,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterExceedHigherBoundTest,"    @Test
    public void InstantAsStringAttributeConverterExceedHigherBoundTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""+1000000001-01-01T00:00:00Z"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114116,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterNotAcceptLocalDateTimeTest,"    @Test
    public void InstantAsStringAttributeConverterNotAcceptLocalDateTimeTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""1988-05-21T00:12:00.000000001"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114117,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterNotAcceptOffsetTimeTest,"    @Test
    public void InstantAsStringAttributeConverterNotAcceptOffsetTimeTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""1988-05-21T00:12:00+01:00"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114118,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterNotAcceptZonedTimeTest,"    @Test
    public void InstantAsStringAttributeConverterNotAcceptZonedTimeTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""1988-05-21T00:12:00+01:00[Europe/Paris]"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114119,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterNotAcceptLocalDateTest,"    @Test
    public void InstantAsStringAttributeConverterNotAcceptLocalDateTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""1988-05-21"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114120,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterNotAcceptLocalTimeTest,"    @Test
    public void InstantAsStringAttributeConverterNotAcceptLocalTimeTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""00:12:00.000000001"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114121,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterNotAcceptMonthDayTest,"    @Test
    public void InstantAsStringAttributeConverterNotAcceptMonthDayTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""05-21"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114122,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterMinTest,"    @Test
    public void localDateTimeAttributeConverterMinTest() {
        verifyTransform(LocalDateTime.MIN, ""-999999999-01-01T00:00"");
    }
",non-flaky,5
114123,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterNormalTest,"    @Test
    public void localDateTimeAttributeConverterNormalTest() {
        verifyTransform(LocalDateTime.of(0, 1, 1, 0, 0, 0, 0), ""0000-01-01T00:00"");
    }
",non-flaky,5
114124,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterMaxTest,"    @Test
    public void localDateTimeAttributeConverterMaxTest() {
        verifyTransform(LocalDateTime.MAX, ""+999999999-12-31T23:59:59.999999999"");
    }
",non-flaky,5
114125,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterLowerBoundTest,"    @Test
    public void localDateTimeAttributeConverterLowerBoundTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""-9999999999-01-01T00:00"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114126,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterHigherBoundTest,"    @Test
    public void localDateTimeAttributeConverterHigherBoundTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""9999999999-12-31T00:00:00"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114127,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterExceedHigherBoundTest,"    @Test
    public void localDateTimeAttributeConverterExceedHigherBoundTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""9999999999-12-32T00:00:00"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114128,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterInvalidNanoSecondsTest,"    @Test
    public void localDateTimeAttributeConverterInvalidNanoSecondsTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""0-01-01T00:00:00.9999999999"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114129,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterNotAcceptInstantTest,"    @Test
    public void localDateTimeAttributeConverterNotAcceptInstantTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""1988-05-21T00:12:00.000000001Z"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114130,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterNotAcceptOffsetTimeTest,"    @Test
    public void localDateTimeAttributeConverterNotAcceptOffsetTimeTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""1988-05-21T00:12:00+01:00"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114131,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterNotAcceptZonedTimeTest,"    @Test
    public void localDateTimeAttributeConverterNotAcceptZonedTimeTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""1988-05-21T00:12:00+01:00[Europe/Paris]"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114132,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterNotAcceptLocalTimeTest,"    @Test
    public void localDateTimeAttributeConverterNotAcceptLocalTimeTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""00:12:00.000000001"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
114133,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterNotAcceptMonthDayTest,"    @Test
    public void localDateTimeAttributeConverterNotAcceptMonthDayTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""05-21"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
118685,netty_netty,XmlDecoderTest.shouldDecodeRequestWithSimpleXml,"    @Test
    public void shouldDecodeRequestWithSimpleXml() {
        Object temp;

        write(XML1);

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlDocumentStart.class));
        assertThat(((XmlDocumentStart) temp).version(), is(""1.0""));
        assertThat(((XmlDocumentStart) temp).encoding(), is(""UTF-8""));
        assertThat(((XmlDocumentStart) temp).standalone(), is(false));
        assertThat(((XmlDocumentStart) temp).encodingScheme(), is(nullValue()));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlDTD.class));
        assertThat(((XmlDTD) temp).text(), is(""employee.dtd""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlProcessingInstruction.class));
        assertThat(((XmlProcessingInstruction) temp).target(), is(""xml-stylesheet""));
        assertThat(((XmlProcessingInstruction) temp).data(), is(""type=\""text/css\"" href=\""netty.css\""""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlProcessingInstruction.class));
        assertThat(((XmlProcessingInstruction) temp).target(), is(""xml-test""));
        assertThat(((XmlProcessingInstruction) temp).data(), is(""""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementStart.class));
        assertThat(((XmlElementStart) temp).name(), is(""employee""));
        assertThat(((XmlElementStart) temp).prefix(), is(""""));
        assertThat(((XmlElementStart) temp).namespace(), is(""""));
        assertThat(((XmlElementStart) temp).attributes().size(), is(0));
        assertThat(((XmlElementStart) temp).namespaces().size(), is(1));
        assertThat(((XmlElementStart) temp).namespaces().get(0).prefix(), is(""nettya""));
        assertThat(((XmlElementStart) temp).namespaces().get(0).uri(), is(""http://netty.io/netty/a""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementStart.class));
        assertThat(((XmlElementStart) temp).name(), is(""id""));
        assertThat(((XmlElementStart) temp).prefix(), is(""nettya""));
        assertThat(((XmlElementStart) temp).namespace(), is(""http://netty.io/netty/a""));
        assertThat(((XmlElementStart) temp).attributes().size(), is(0));
        assertThat(((XmlElementStart) temp).namespaces().size(), is(0));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlEntityReference.class));
        assertThat(((XmlEntityReference) temp).name(), is(""plusmn""));
        assertThat(((XmlEntityReference) temp).text(), is(""""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlCharacters.class));
        assertThat(((XmlCharacters) temp).data(), is(""1""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementEnd.class));
        assertThat(((XmlElementEnd) temp).name(), is(""id""));
        assertThat(((XmlElementEnd) temp).prefix(), is(""nettya""));
        assertThat(((XmlElementEnd) temp).namespace(), is(""http://netty.io/netty/a""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlCharacters.class));
        assertThat(((XmlCharacters) temp).data(), is(""\n""));

        temp = channel.readInbound();
        assertThat(temp, nullValue());

        write(XML2);

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementStart.class));
        assertThat(((XmlElementStart) temp).name(), is(""name""));
        assertThat(((XmlElementStart) temp).prefix(), is(""""));
        assertThat(((XmlElementStart) temp).namespace(), is(""""));
        assertThat(((XmlElementStart) temp).attributes().size(), is(1));
        assertThat(((XmlElementStart) temp).attributes().get(0).name(), is(""type""));
        assertThat(((XmlElementStart) temp).attributes().get(0).value(), is(""given""));
        assertThat(((XmlElementStart) temp).attributes().get(0).prefix(), is(""""));
        assertThat(((XmlElementStart) temp).attributes().get(0).namespace(), is(""""));
        assertThat(((XmlElementStart) temp).namespaces().size(), is(0));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlCharacters.class));
        assertThat(((XmlCharacters) temp).data(), is(""Alba""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementEnd.class));
        assertThat(((XmlElementEnd) temp).name(), is(""name""));
        assertThat(((XmlElementEnd) temp).prefix(), is(""""));
        assertThat(((XmlElementEnd) temp).namespace(), is(""""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlCdata.class));
        assertThat(((XmlCdata) temp).data(), is("" <some data &gt;/> ""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlCharacters.class));
        assertThat(((XmlCharacters) temp).data(), is(""   ""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlComment.class));
        assertThat(((XmlComment) temp).data(), is("" namespaced ""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementStart.class));
        assertThat(((XmlElementStart) temp).name(), is(""salary""));
        assertThat(((XmlElementStart) temp).prefix(), is(""nettyb""));
        assertThat(((XmlElementStart) temp).namespace(), is(""http://netty.io/netty/b""));
        assertThat(((XmlElementStart) temp).attributes().size(), is(1));
        assertThat(((XmlElementStart) temp).attributes().get(0).name(), is(""period""));
        assertThat(((XmlElementStart) temp).attributes().get(0).value(), is(""weekly""));
        assertThat(((XmlElementStart) temp).attributes().get(0).prefix(), is(""nettyb""));
        assertThat(((XmlElementStart) temp).attributes().get(0).namespace(), is(""http://netty.io/netty/b""));
        assertThat(((XmlElementStart) temp).namespaces().size(), is(1));
        assertThat(((XmlElementStart) temp).namespaces().get(0).prefix(), is(""nettyb""));
        assertThat(((XmlElementStart) temp).namespaces().get(0).uri(), is(""http://netty.io/netty/b""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlCharacters.class));
        assertThat(((XmlCharacters) temp).data(), is(""100""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementEnd.class));
        assertThat(((XmlElementEnd) temp).name(), is(""salary""));
        assertThat(((XmlElementEnd) temp).prefix(), is(""nettyb""));
        assertThat(((XmlElementEnd) temp).namespace(), is(""http://netty.io/netty/b""));
        assertThat(((XmlElementEnd) temp).namespaces().size(), is(1));
        assertThat(((XmlElementEnd) temp).namespaces().get(0).prefix(), is(""nettyb""));
        assertThat(((XmlElementEnd) temp).namespaces().get(0).uri(), is(""http://netty.io/netty/b""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementStart.class));
        assertThat(((XmlElementStart) temp).name(), is(""last""));
        assertThat(((XmlElementStart) temp).prefix(), is(""""));
        assertThat(((XmlElementStart) temp).namespace(), is(""""));
        assertThat(((XmlElementStart) temp).attributes().size(), is(0));
        assertThat(((XmlElementStart) temp).namespaces().size(), is(0));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementEnd.class));
        assertThat(((XmlElementEnd) temp).name(), is(""last""));
        assertThat(((XmlElementEnd) temp).prefix(), is(""""));
        assertThat(((XmlElementEnd) temp).namespace(), is(""""));
        assertThat(((XmlElementEnd) temp).namespaces().size(), is(0));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementEnd.class));
        assertThat(((XmlElementEnd) temp).name(), is(""employee""));
        assertThat(((XmlElementEnd) temp).prefix(), is(""""));
        assertThat(((XmlElementEnd) temp).namespace(), is(""""));
        assertThat(((XmlElementEnd) temp).namespaces().size(), is(1));
        assertThat(((XmlElementEnd) temp).namespaces().get(0).prefix(), is(""nettya""));
        assertThat(((XmlElementEnd) temp).namespaces().get(0).uri(), is(""http://netty.io/netty/a""));

        temp = channel.readInbound();
        assertThat(temp, nullValue());
    }
",non-flaky,5
118686,netty_netty,XmlDecoderTest.shouldDecodeXmlHeader,"    @Test
    public void shouldDecodeXmlHeader() {
        Object temp;

        write(XML3);

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlDocumentStart.class));
        assertThat(((XmlDocumentStart) temp).version(), is(""1.1""));
        assertThat(((XmlDocumentStart) temp).encoding(), is(""UTF-8""));
        assertThat(((XmlDocumentStart) temp).standalone(), is(true));
        assertThat(((XmlDocumentStart) temp).encodingScheme(), is(""UTF-8""));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementStart.class));
        assertThat(((XmlElementStart) temp).name(), is(""netty""));
        assertThat(((XmlElementStart) temp).prefix(), is(""""));
        assertThat(((XmlElementStart) temp).namespace(), is(""""));
        assertThat(((XmlElementStart) temp).attributes().size(), is(0));
        assertThat(((XmlElementStart) temp).namespaces().size(), is(0));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementEnd.class));
        assertThat(((XmlElementEnd) temp).name(), is(""netty""));
        assertThat(((XmlElementEnd) temp).prefix(), is(""""));
        assertThat(((XmlElementEnd) temp).namespace(), is(""""));
        assertThat(((XmlElementEnd) temp).namespaces().size(), is(0));

        temp = channel.readInbound();
        assertThat(temp, nullValue());
    }
",non-flaky,5
118687,netty_netty,XmlDecoderTest.shouldDecodeWithoutHeader,"    @Test
    public void shouldDecodeWithoutHeader() {
        Object temp;

        write(XML4);

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlDocumentStart.class));
        assertThat(((XmlDocumentStart) temp).version(), is(nullValue()));
        assertThat(((XmlDocumentStart) temp).encoding(), is(""UTF-8""));
        assertThat(((XmlDocumentStart) temp).standalone(), is(false));
        assertThat(((XmlDocumentStart) temp).encodingScheme(), is(nullValue()));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementStart.class));
        assertThat(((XmlElementStart) temp).name(), is(""netty""));
        assertThat(((XmlElementStart) temp).prefix(), is(""""));
        assertThat(((XmlElementStart) temp).namespace(), is(""""));
        assertThat(((XmlElementStart) temp).attributes().size(), is(0));
        assertThat(((XmlElementStart) temp).namespaces().size(), is(0));

        temp = channel.readInbound();
        assertThat(temp, instanceOf(XmlElementEnd.class));
        assertThat(((XmlElementEnd) temp).name(), is(""netty""));
        assertThat(((XmlElementEnd) temp).prefix(), is(""""));
        assertThat(((XmlElementEnd) temp).namespace(), is(""""));
        assertThat(((XmlElementEnd) temp).namespaces().size(), is(0));

        temp = channel.readInbound();
        assertThat(temp, nullValue());
    }
",non-flaky,5
118688,netty_netty,SmtpCommandTest.getCommandFromCache,"    @Test
    public void getCommandFromCache() {
        assertSame(SmtpCommand.DATA, SmtpCommand.valueOf(""DATA""));
        assertSame(SmtpCommand.EHLO, SmtpCommand.valueOf(""EHLO""));
        assertNotSame(SmtpCommand.EHLO, SmtpCommand.valueOf(""ehlo""));
    }
",non-flaky,5
118689,netty_netty,SmtpCommandTest.equalsIgnoreCase,"    @Test
    public void equalsIgnoreCase() {
        assertEquals(SmtpCommand.MAIL, SmtpCommand.valueOf(""mail""));
        assertEquals(SmtpCommand.valueOf(""test""), SmtpCommand.valueOf(""TEST""));
    }
",non-flaky,5
118690,netty_netty,SmtpCommandTest.isContentExpected,"    @Test
    public void isContentExpected() {
        assertTrue(SmtpCommand.valueOf(""DATA"").isContentExpected());
        assertTrue(SmtpCommand.valueOf(""data"").isContentExpected());

        assertFalse(SmtpCommand.HELO.isContentExpected());
        assertFalse(SmtpCommand.HELP.isContentExpected());
        assertFalse(SmtpCommand.valueOf(""DATA2"").isContentExpected());
    }
",non-flaky,5
118691,netty_netty,SmtpRequestEncoderTest.testEncodeEhlo,"    @Test
    public void testEncodeEhlo() {
        testEncode(SmtpRequests.ehlo(""localhost""), ""EHLO localhost\r\n"");
    }
",non-flaky,5
118692,netty_netty,SmtpRequestEncoderTest.testEncodeHelo,"    @Test
    public void testEncodeHelo() {
        testEncode(SmtpRequests.helo(""localhost""), ""HELO localhost\r\n"");
    }
",non-flaky,5
118693,netty_netty,SmtpRequestEncoderTest.testEncodeMail,"    @Test
    public void testEncodeMail() {
        testEncode(SmtpRequests.mail(""me@netty.io""), ""MAIL FROM:<me@netty.io>\r\n"");
    }
",non-flaky,5
118694,netty_netty,SmtpRequestEncoderTest.testEncodeMailNullSender,"    @Test
    public void testEncodeMailNullSender() {
        testEncode(SmtpRequests.mail(null), ""MAIL FROM:<>\r\n"");
    }
",non-flaky,5
118695,netty_netty,SmtpRequestEncoderTest.testEncodeRcpt,"    @Test
    public void testEncodeRcpt() {
        testEncode(SmtpRequests.rcpt(""me@netty.io""), ""RCPT TO:<me@netty.io>\r\n"");
    }
",non-flaky,5
118696,netty_netty,SmtpRequestEncoderTest.testEncodeNoop,"    @Test
    public void testEncodeNoop() {
        testEncode(SmtpRequests.noop(), ""NOOP\r\n"");
    }
",non-flaky,5
118697,netty_netty,SmtpRequestEncoderTest.testEncodeRset,"    @Test
    public void testEncodeRset() {
        testEncode(SmtpRequests.rset(), ""RSET\r\n"");
    }
",non-flaky,5
118698,netty_netty,SmtpRequestEncoderTest.testEncodeHelp,"    @Test
    public void testEncodeHelp() {
        testEncode(SmtpRequests.help(null), ""HELP\r\n"");
    }
",non-flaky,5
118699,netty_netty,SmtpRequestEncoderTest.testEncodeHelpWithArg,"    @Test
    public void testEncodeHelpWithArg() {
        testEncode(SmtpRequests.help(""MAIL""), ""HELP MAIL\r\n"");
    }
",non-flaky,5
118700,netty_netty,SmtpRequestEncoderTest.testEncodeData,"    @Test
    public void testEncodeData() {
        testEncode(SmtpRequests.data(), ""DATA\r\n"");
    }
",non-flaky,5
118701,netty_netty,SmtpRequestEncoderTest.testEncodeDataAndContent,"    @Test
    public void testEncodeDataAndContent() {
        EmbeddedChannel channel = new EmbeddedChannel(new SmtpRequestEncoder());
        assertTrue(channel.writeOutbound(SmtpRequests.data()));
        assertTrue(channel.writeOutbound(
                new DefaultSmtpContent(Unpooled.copiedBuffer(""Subject: Test\r\n\r\n"", CharsetUtil.US_ASCII))));
        assertTrue(channel.writeOutbound(
                new DefaultLastSmtpContent(Unpooled.copiedBuffer(""Test\r\n"", CharsetUtil.US_ASCII))));
        assertTrue(channel.finish());

        assertEquals(""DATA\r\nSubject: Test\r\n\r\nTest\r\n.\r\n"", getWrittenString(channel));
    }
",non-flaky,5
118702,netty_netty,SmtpRequestEncoderTest.testThrowsIfContentExpected,"    @Test(expected = EncoderException.class)
    public void testThrowsIfContentExpected() {
        EmbeddedChannel channel = new EmbeddedChannel(new SmtpRequestEncoder());
        try {
            assertTrue(channel.writeOutbound(SmtpRequests.data()));
            channel.writeOutbound(SmtpRequests.noop());
        } finally {
            channel.finishAndReleaseAll();
        }
    }
",non-flaky,5
118703,netty_netty,SmtpRequestEncoderTest.testRsetClearsContentExpectedFlag,"    @Test
    public void testRsetClearsContentExpectedFlag() {
        EmbeddedChannel channel = new EmbeddedChannel(new SmtpRequestEncoder());

        assertTrue(channel.writeOutbound(SmtpRequests.data()));
        assertTrue(channel.writeOutbound(SmtpRequests.rset()));
        assertTrue(channel.writeOutbound(SmtpRequests.noop()));
        assertTrue(channel.finish());

        assertEquals(""DATA\r\nRSET\r\nNOOP\r\n"", getWrittenString(channel));
    }
",non-flaky,5
118704,netty_netty,SmtpResponseDecoderTest.testDecodeOneLineResponse,"    @Test
    public void testDecodeOneLineResponse() {
        EmbeddedChannel channel = newChannel();
        assertTrue(channel.writeInbound(newBuffer(""200 Ok\r\n"")));
        assertTrue(channel.finish());

        SmtpResponse response = channel.readInbound();
        assertEquals(200, response.code());
        List<CharSequence> sequences = response.details();
        assertEquals(1, sequences.size());

        assertEquals(""Ok"", sequences.get(0).toString());
        assertNull(channel.readInbound());
    }
",non-flaky,5
118705,netty_netty,SmtpResponseDecoderTest.testDecodeOneLineResponseNoDetails,"    @Test
    public void testDecodeOneLineResponseNoDetails() {
        EmbeddedChannel channel = newChannel();
        assertTrue(channel.writeInbound(newBuffer(""250 \r\n"")));
        assertTrue(channel.finish());

        SmtpResponse response = channel.readInbound();
        assertEquals(250, response.code());
        List<CharSequence> sequences = response.details();
        assertEquals(0, sequences.size());
    }
",non-flaky,5
118706,netty_netty,SmtpResponseDecoderTest.testDecodeOneLineResponseChunked,"    @Test
    public void testDecodeOneLineResponseChunked() {
        EmbeddedChannel channel = newChannel();
        assertFalse(channel.writeInbound(newBuffer(""200 Ok"")));
        assertTrue(channel.writeInbound(newBuffer(""\r\n"")));
        assertTrue(channel.finish());

        SmtpResponse response = channel.readInbound();
        assertEquals(200, response.code());
        List<CharSequence> sequences = response.details();
        assertEquals(1, sequences.size());

        assertEquals(""Ok"", sequences.get(0).toString());
        assertNull(channel.readInbound());
    }
",non-flaky,5
118707,netty_netty,SmtpResponseDecoderTest.testDecodeTwoLineResponse,"    @Test
    public void testDecodeTwoLineResponse() {
        EmbeddedChannel channel = newChannel();
        assertTrue(channel.writeInbound(newBuffer(""200-Hello\r\n200 Ok\r\n"")));
        assertTrue(channel.finish());

        SmtpResponse response = channel.readInbound();
        assertEquals(200, response.code());
        List<CharSequence> sequences = response.details();
        assertEquals(2, sequences.size());

        assertEquals(""Hello"", sequences.get(0).toString());
        assertEquals(""Ok"", sequences.get(1).toString());
        assertNull(channel.readInbound());
    }
",non-flaky,5
118708,netty_netty,SmtpResponseDecoderTest.testDecodeTwoLineResponseChunked,"    @Test
    public void testDecodeTwoLineResponseChunked() {
        EmbeddedChannel channel = newChannel();
        assertFalse(channel.writeInbound(newBuffer(""200-"")));
        assertFalse(channel.writeInbound(newBuffer(""Hello\r\n2"")));
        assertFalse(channel.writeInbound(newBuffer(""00 Ok"")));
        assertTrue(channel.writeInbound(newBuffer(""\r\n"")));
        assertTrue(channel.finish());

        SmtpResponse response = channel.readInbound();
        assertEquals(200, response.code());
        List<CharSequence> sequences = response.details();
        assertEquals(2, sequences.size());

        assertEquals(""Hello"", sequences.get(0).toString());
        assertEquals(""Ok"", sequences.get(1).toString());
        assertNull(channel.readInbound());
    }
",non-flaky,5
118709,netty_netty,SmtpResponseDecoderTest.testDecodeInvalidSeparator,"    @Test(expected = DecoderException.class)
    public void testDecodeInvalidSeparator() {
        EmbeddedChannel channel = newChannel();
        assertTrue(channel.writeInbound(newBuffer(""200:Ok\r\n"")));
    }
",non-flaky,5
118710,netty_netty,SmtpResponseDecoderTest.testDecodeInvalidCode,"    @Test(expected = DecoderException.class)
    public void testDecodeInvalidCode() {
        EmbeddedChannel channel = newChannel();
        assertTrue(channel.writeInbound(newBuffer(""xyz Ok\r\n"")));
    }
",non-flaky,5
118711,netty_netty,SmtpResponseDecoderTest.testDecodeInvalidLine,"    @Test(expected = DecoderException.class)
    public void testDecodeInvalidLine() {
        EmbeddedChannel channel = newChannel();
        assertTrue(channel.writeInbound(newBuffer(""Ok\r\n"")));
    }
",non-flaky,5
118712,netty_netty,UnixChannelUtilTest.testPooledAllocatorIsBufferCopyNeededForWrite,"    @Test
    public void testPooledAllocatorIsBufferCopyNeededForWrite() {
        testIsBufferCopyNeededForWrite(PooledByteBufAllocator.DEFAULT);
    }
",non-flaky,5
118713,netty_netty,UnixChannelUtilTest.testUnPooledAllocatorIsBufferCopyNeededForWrite,"    @Test
    public void testUnPooledAllocatorIsBufferCopyNeededForWrite() {
        testIsBufferCopyNeededForWrite(UnpooledByteBufAllocator.DEFAULT);
    }
",non-flaky,5
118714,netty_netty,SocketTest.testKeepAlive,"    @Test
    public void testKeepAlive() throws Exception {
        assertFalse(socket.isKeepAlive());
        socket.setKeepAlive(true);
        assertTrue(socket.isKeepAlive());
    }
",non-flaky,5
118715,netty_netty,SocketTest.testTcpNoDelay,"    @Test
    public void testTcpNoDelay() throws Exception {
        assertFalse(socket.isTcpNoDelay());
        socket.setTcpNoDelay(true);
        assertTrue(socket.isTcpNoDelay());
    }
",non-flaky,5
118716,netty_netty,SocketTest.testReceivedBufferSize,"    @Test
    public void testReceivedBufferSize() throws Exception {
        int size = socket.getReceiveBufferSize();
        int newSize = 65535;
        assertTrue(size > 0);
        socket.setReceiveBufferSize(newSize);
        // Linux usually set it to double what is specified
        assertTrue(newSize <= socket.getReceiveBufferSize());
    }
",non-flaky,5
118717,netty_netty,SocketTest.testSendBufferSize,"    @Test
    public void testSendBufferSize() throws Exception {
        int size = socket.getSendBufferSize();
        int newSize = 65535;
        assertTrue(size > 0);
        socket.setSendBufferSize(newSize);
        // Linux usually set it to double what is specified
        assertTrue(newSize <= socket.getSendBufferSize());
    }
",non-flaky,5
118718,netty_netty,SocketTest.testSoLinger,"    @Test
    public void testSoLinger() throws Exception {
        assertEquals(-1, socket.getSoLinger());
        socket.setSoLinger(10);
        assertEquals(10, socket.getSoLinger());
    }
",non-flaky,5
118719,netty_netty,SocketTest.testDoubleCloseDoesNotThrow,"    @Test
    public void testDoubleCloseDoesNotThrow() throws IOException {
        Socket socket = Socket.newSocketStream();
        socket.close();
        socket.close();
    }
",non-flaky,5
118720,netty_netty,SocketTest.testTrafficClass,"    @Test
    public void testTrafficClass() throws IOException {
        // IPTOS_THROUGHPUT
        final int value = 0x08;
        socket.setTrafficClass(value);
        assertEquals(value, socket.getTrafficClass());
    }
",non-flaky,5
118721,netty_netty,DetectPeerCloseWithoutReadTest.clientCloseWithoutServerReadIsDetectedNoExtraReadRequested,"    @Test(timeout = 10000)
    public void clientCloseWithoutServerReadIsDetectedNoExtraReadRequested() throws InterruptedException {
        clientCloseWithoutServerReadIsDetected0(false);
    }
",non-flaky,5
118722,netty_netty,DetectPeerCloseWithoutReadTest.clientCloseWithoutServerReadIsDetectedExtraReadRequested,"    @Test(timeout = 10000)
    public void clientCloseWithoutServerReadIsDetectedExtraReadRequested() throws InterruptedException {
        clientCloseWithoutServerReadIsDetected0(true);
    }
",non-flaky,5
118723,netty_netty,DetectPeerCloseWithoutReadTest.serverCloseWithoutClientReadIsDetectedNoExtraReadRequested,"    @Test(timeout = 10000)
    public void serverCloseWithoutClientReadIsDetectedNoExtraReadRequested() throws InterruptedException {
        serverCloseWithoutClientReadIsDetected0(false);
    }
",non-flaky,5
118724,netty_netty,DetectPeerCloseWithoutReadTest.serverCloseWithoutClientReadIsDetectedExtraReadRequested,"    @Test(timeout = 10000)
    public void serverCloseWithoutClientReadIsDetectedExtraReadRequested() throws InterruptedException {
        serverCloseWithoutClientReadIsDetected0(true);
    }
",non-flaky,5
118725,netty_netty,BigEndianCompositeByteBufTest.testInternalNioBufferAfterRelease,"    @Test(expected = UnsupportedOperationException.class)
    public void testInternalNioBufferAfterRelease() {
        super.testInternalNioBufferAfterRelease();
    }
",non-flaky,5
118726,netty_netty,ByteProcessorTest.testForward,"    @Test
    public void testForward() {
        final ByteBuf buf =
                Unpooled.copiedBuffer(""abc\r\n\ndef\r\rghi\n\njkl\0\0mno  \t\tx"", CharsetUtil.ISO_8859_1);
        final int length = buf.readableBytes();

        assertEquals(3,  buf.forEachByte(0,  length, ByteProcessor.FIND_CRLF));
        assertEquals(6,  buf.forEachByte(3,  length - 3, ByteProcessor.FIND_NON_CRLF));
        assertEquals(9,  buf.forEachByte(6,  length - 6, ByteProcessor.FIND_CR));
        assertEquals(11, buf.forEachByte(9,  length - 9, ByteProcessor.FIND_NON_CR));
        assertEquals(14, buf.forEachByte(11, length - 11, ByteProcessor.FIND_LF));
        assertEquals(16, buf.forEachByte(14, length - 14, ByteProcessor.FIND_NON_LF));
        assertEquals(19, buf.forEachByte(16, length - 16, ByteProcessor.FIND_NUL));
        assertEquals(21, buf.forEachByte(19, length - 19, ByteProcessor.FIND_NON_NUL));
        assertEquals(24, buf.forEachByte(19, length - 19, ByteProcessor.FIND_ASCII_SPACE));
        assertEquals(24, buf.forEachByte(21, length - 21, ByteProcessor.FIND_LINEAR_WHITESPACE));
        assertEquals(28, buf.forEachByte(24, length - 24, ByteProcessor.FIND_NON_LINEAR_WHITESPACE));
        assertEquals(-1, buf.forEachByte(28, length - 28, ByteProcessor.FIND_LINEAR_WHITESPACE));

        buf.release();
    }
",non-flaky,5
118727,netty_netty,ByteProcessorTest.testBackward,"    @Test
    public void testBackward() {
        final ByteBuf buf =
                Unpooled.copiedBuffer(""abc\r\n\ndef\r\rghi\n\njkl\0\0mno  \t\tx"", CharsetUtil.ISO_8859_1);
        final int length = buf.readableBytes();

        assertEquals(27, buf.forEachByteDesc(0, length, ByteProcessor.FIND_LINEAR_WHITESPACE));
        assertEquals(25, buf.forEachByteDesc(0, length, ByteProcessor.FIND_ASCII_SPACE));
        assertEquals(23, buf.forEachByteDesc(0, 28, ByteProcessor.FIND_NON_LINEAR_WHITESPACE));
        assertEquals(20, buf.forEachByteDesc(0, 24, ByteProcessor.FIND_NUL));
        assertEquals(18, buf.forEachByteDesc(0, 21, ByteProcessor.FIND_NON_NUL));
        assertEquals(15, buf.forEachByteDesc(0, 19, ByteProcessor.FIND_LF));
        assertEquals(13, buf.forEachByteDesc(0, 16, ByteProcessor.FIND_NON_LF));
        assertEquals(10, buf.forEachByteDesc(0, 14, ByteProcessor.FIND_CR));
        assertEquals(8,  buf.forEachByteDesc(0, 11, ByteProcessor.FIND_NON_CR));
        assertEquals(5,  buf.forEachByteDesc(0, 9, ByteProcessor.FIND_CRLF));
        assertEquals(2,  buf.forEachByteDesc(0, 6, ByteProcessor.FIND_NON_CRLF));
        assertEquals(-1, buf.forEachByteDesc(0, 3, ByteProcessor.FIND_CRLF));

        buf.release();
    }
",non-flaky,5
118728,netty_netty,BigEndianHeapByteBufTest.shouldNotAllowNullInConstructor1,"    @Test(expected = NullPointerException.class)
    public void shouldNotAllowNullInConstructor1() {
        new UnpooledHeapByteBuf(null, new byte[1], 0);
    }
",non-flaky,5
118729,netty_netty,BigEndianHeapByteBufTest.shouldNotAllowNullInConstructor2,"    @Test(expected = NullPointerException.class)
    public void shouldNotAllowNullInConstructor2() {
        new UnpooledHeapByteBuf(UnpooledByteBufAllocator.DEFAULT, null, 0);
    }
",non-flaky,5
118730,netty_netty,EmptyByteBufTest.testIsWritable,"    @Test
    public void testIsWritable() {
        EmptyByteBuf empty = new EmptyByteBuf(UnpooledByteBufAllocator.DEFAULT);
        assertFalse(empty.isWritable());
        assertFalse(empty.isWritable(1));
    }
",non-flaky,5
118731,netty_netty,EmptyByteBufTest.testWriteEmptyByteBuf,"    @Test
    public void testWriteEmptyByteBuf() {
        EmptyByteBuf empty = new EmptyByteBuf(UnpooledByteBufAllocator.DEFAULT);
        empty.writeBytes(Unpooled.EMPTY_BUFFER); // Ok
        ByteBuf nonEmpty = UnpooledByteBufAllocator.DEFAULT.buffer().writeBoolean(false);
        try {
            empty.writeBytes(nonEmpty);
            fail();
        } catch (IndexOutOfBoundsException ignored) {
            // Ignore.
        } finally {
            nonEmpty.release();
        }
    }
",non-flaky,5
118732,netty_netty,EmptyByteBufTest.testIsReadable,"    @Test
    public void testIsReadable() {
        EmptyByteBuf empty = new EmptyByteBuf(UnpooledByteBufAllocator.DEFAULT);
        assertFalse(empty.isReadable());
        assertFalse(empty.isReadable(1));
    }
",non-flaky,5
118733,netty_netty,EmptyByteBufTest.testArray,"    @Test
    public void testArray() {
        EmptyByteBuf empty = new EmptyByteBuf(UnpooledByteBufAllocator.DEFAULT);
        assertThat(empty.hasArray(), is(true));
        assertThat(empty.array().length, is(0));
        assertThat(empty.arrayOffset(), is(0));
    }
",non-flaky,5
118734,netty_netty,EmptyByteBufTest.testNioBuffer,"    @Test
    public void testNioBuffer() {
        EmptyByteBuf empty = new EmptyByteBuf(UnpooledByteBufAllocator.DEFAULT);
        assertThat(empty.nioBufferCount(), is(1));
        assertThat(empty.nioBuffer().position(), is(0));
        assertThat(empty.nioBuffer().limit(), is(0));
        assertThat(empty.nioBuffer(), is(sameInstance(empty.nioBuffer())));
        assertThat(empty.nioBuffer(), is(sameInstance(empty.internalNioBuffer(empty.readerIndex(), 0))));
    }
",non-flaky,5
118735,netty_netty,EmptyByteBufTest.testMemoryAddress,"    @Test
    public void testMemoryAddress() {
        EmptyByteBuf empty = new EmptyByteBuf(UnpooledByteBufAllocator.DEFAULT);
        if (empty.hasMemoryAddress()) {
            assertThat(empty.memoryAddress(), is(not(0L)));
        } else {
            try {
                empty.memoryAddress();
                fail();
            } catch (UnsupportedOperationException ignored) {
                // Ignore.
            }
        }
    }
",non-flaky,5
118736,netty_netty,EmptyByteBufTest.consistentEqualsAndHashCodeWithAbstractBytebuf,"    @Test
    public void consistentEqualsAndHashCodeWithAbstractBytebuf() {
        ByteBuf empty = new EmptyByteBuf(UnpooledByteBufAllocator.DEFAULT);
        ByteBuf emptyAbstract = new UnpooledHeapByteBuf(UnpooledByteBufAllocator.DEFAULT, 0, 0);
        assertEquals(emptyAbstract, empty);
        assertEquals(emptyAbstract.hashCode(), empty.hashCode());
        assertEquals(EmptyByteBuf.EMPTY_BYTE_BUF_HASH_CODE, empty.hashCode());
        assertTrue(emptyAbstract.release());
        assertFalse(empty.release());
    }
",non-flaky,5
118737,netty_netty,ByteBufUtilTest.decodeRandomHexBytesWithEvenLength,"    @Test
    public void decodeRandomHexBytesWithEvenLength() {
        decodeRandomHexBytes(256);
    }
",non-flaky,5
118738,netty_netty,ByteBufUtilTest.decodeRandomHexBytesWithOddLength,"    @Test
    public void decodeRandomHexBytesWithOddLength() {
        decodeRandomHexBytes(257);
    }
",non-flaky,5
118739,netty_netty,ByteBufUtilTest.decodeHexDumpWithOddLength,"    @Test(expected = IllegalArgumentException.class)
    public void decodeHexDumpWithOddLength() {
        ByteBufUtil.decodeHexDump(""abc"");
    }
",non-flaky,5
118740,netty_netty,ByteBufUtilTest.decodeHexDumpWithInvalidChar,"    @Test(expected = IllegalArgumentException.class)
    public void decodeHexDumpWithInvalidChar() {
        ByteBufUtil.decodeHexDump(""fg"");
    }
",non-flaky,5
118741,netty_netty,ByteBufUtilTest.equalsBufferSubsections,"    @Test
    public void equalsBufferSubsections() {
        byte[] b1 = new byte[128];
        byte[] b2 = new byte[256];
        Random rand = new Random();
        rand.nextBytes(b1);
        rand.nextBytes(b2);
        final int iB1 = b1.length / 2;
        final int iB2 = iB1 + b1.length;
        final int length = b1.length - iB1;
        System.arraycopy(b1, iB1, b2, iB2, length);
        assertTrue(ByteBufUtil.equals(Unpooled.wrappedBuffer(b1), iB1, Unpooled.wrappedBuffer(b2), iB2, length));
    }
",non-flaky,5
118742,netty_netty,ByteBufUtilTest.notEqualsBufferSubsections,"    @Test
    public void notEqualsBufferSubsections() {
        byte[] b1 = new byte[50];
        byte[] b2 = new byte[256];
        Random rand = new Random();
        rand.nextBytes(b1);
        rand.nextBytes(b2);
        final int iB1 = b1.length / 2;
        final int iB2 = iB1 + b1.length;
        final int length = b1.length - iB1;
        System.arraycopy(b1, iB1, b2, iB2, length);
        // Randomly pick an index in the range that will be compared and make the value at that index differ between
        // the 2 arrays.
        int diffIndex = random(rand, iB1, iB1 + length - 1);
        ++b1[diffIndex];
        assertFalse(ByteBufUtil.equals(Unpooled.wrappedBuffer(b1), iB1, Unpooled.wrappedBuffer(b2), iB2, length));
    }
",non-flaky,5
118743,netty_netty,ByteBufUtilTest.notEqualsBufferOverflow,"    @Test
    public void notEqualsBufferOverflow() {
        byte[] b1 = new byte[8];
        byte[] b2 = new byte[16];
        Random rand = new Random();
        rand.nextBytes(b1);
        rand.nextBytes(b2);
        final int iB1 = b1.length / 2;
        final int iB2 = iB1 + b1.length;
        final int length = b1.length - iB1;
        System.arraycopy(b1, iB1, b2, iB2, length - 1);
        assertFalse(ByteBufUtil.equals(Unpooled.wrappedBuffer(b1), iB1, Unpooled.wrappedBuffer(b2), iB2,
                Math.max(b1.length, b2.length) * 2));
    }
",non-flaky,5
118744,netty_netty,ByteBufUtilTest.notEqualsBufferUnderflow,"    @Test (expected = IllegalArgumentException.class)
    public void notEqualsBufferUnderflow() {
        byte[] b1 = new byte[8];
        byte[] b2 = new byte[16];
        Random rand = new Random();
        rand.nextBytes(b1);
        rand.nextBytes(b2);
        final int iB1 = b1.length / 2;
        final int iB2 = iB1 + b1.length;
        final int length = b1.length - iB1;
        System.arraycopy(b1, iB1, b2, iB2, length - 1);
        assertFalse(ByteBufUtil.equals(Unpooled.wrappedBuffer(b1), iB1, Unpooled.wrappedBuffer(b2), iB2,
                -1));
    }
",non-flaky,5
118745,netty_netty,ByteBufUtilTest.writeShortBE,"    @Test
    public void writeShortBE() {
        int expected = 0x1234;

        ByteBuf buf = Unpooled.buffer(2).order(ByteOrder.BIG_ENDIAN);
        ByteBufUtil.writeShortBE(buf, expected);
        assertEquals(expected, buf.readShort());
        buf.resetReaderIndex();
        assertEquals(ByteBufUtil.swapShort((short) expected), buf.readShortLE());
        buf.release();

        buf = Unpooled.buffer(2).order(ByteOrder.LITTLE_ENDIAN);
        ByteBufUtil.writeShortBE(buf, expected);
        assertEquals((short) expected, buf.readShortLE());
        buf.resetReaderIndex();
        assertEquals(ByteBufUtil.swapShort((short) expected), buf.readShort());
        buf.release();
    }
",non-flaky,5
118746,netty_netty,ByteBufUtilTest.setShortBE,"    @Test
    public void setShortBE() {
        int shortValue = 0x1234;

        ByteBuf buf = Unpooled.wrappedBuffer(new byte[2]).order(ByteOrder.BIG_ENDIAN);
        ByteBufUtil.setShortBE(buf, 0, shortValue);
        assertEquals(shortValue, buf.readShort());
        buf.resetReaderIndex();
        assertEquals(ByteBufUtil.swapShort((short) shortValue), buf.readShortLE());
        buf.release();

        buf = Unpooled.wrappedBuffer(new byte[2]).order(ByteOrder.LITTLE_ENDIAN);
        ByteBufUtil.setShortBE(buf, 0, shortValue);
        assertEquals((short) shortValue, buf.readShortLE());
        buf.resetReaderIndex();
        assertEquals(ByteBufUtil.swapShort((short) shortValue), buf.readShort());
        buf.release();
    }
",non-flaky,5
118747,netty_netty,ByteBufUtilTest.writeMediumBE,"    @Test
    public void writeMediumBE() {
        int mediumValue = 0x123456;

        ByteBuf buf = Unpooled.buffer(4).order(ByteOrder.BIG_ENDIAN);
        ByteBufUtil.writeMediumBE(buf, mediumValue);
        assertEquals(mediumValue, buf.readMedium());
        buf.resetReaderIndex();
        assertEquals(ByteBufUtil.swapMedium(mediumValue), buf.readMediumLE());
        buf.release();

        buf = Unpooled.buffer(4).order(ByteOrder.LITTLE_ENDIAN);
        ByteBufUtil.writeMediumBE(buf, mediumValue);
        assertEquals(mediumValue, buf.readMediumLE());
        buf.resetReaderIndex();
        assertEquals(ByteBufUtil.swapMedium(mediumValue), buf.readMedium());
        buf.release();
    }
",non-flaky,5
118748,netty_netty,ByteBufUtilTest.testWriteUsAscii,"    @Test
    public void testWriteUsAscii() {
        String usAscii = ""NettyRocks"";
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(usAscii.getBytes(CharsetUtil.US_ASCII));
        ByteBuf buf2 = Unpooled.buffer(16);
        ByteBufUtil.writeAscii(buf2, usAscii);

        assertEquals(buf, buf2);

        buf.release();
        buf2.release();
    }
",non-flaky,5
118749,netty_netty,ByteBufUtilTest.testWriteUsAsciiSwapped,"    @Test
    public void testWriteUsAsciiSwapped() {
        String usAscii = ""NettyRocks"";
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(usAscii.getBytes(CharsetUtil.US_ASCII));
        SwappedByteBuf buf2 = new SwappedByteBuf(Unpooled.buffer(16));
        ByteBufUtil.writeAscii(buf2, usAscii);

        assertEquals(buf, buf2);

        buf.release();
        buf2.release();
    }
",non-flaky,5
118750,netty_netty,ByteBufUtilTest.testWriteUsAsciiWrapped,"    @Test
    public void testWriteUsAsciiWrapped() {
        String usAscii = ""NettyRocks"";
        ByteBuf buf = unreleasableBuffer(Unpooled.buffer(16));
        assertWrapped(buf);
        buf.writeBytes(usAscii.getBytes(CharsetUtil.US_ASCII));
        ByteBuf buf2 = unreleasableBuffer(Unpooled.buffer(16));
        assertWrapped(buf2);
        ByteBufUtil.writeAscii(buf2, usAscii);

        assertEquals(buf, buf2);

        buf.unwrap().release();
        buf2.unwrap().release();
    }
",non-flaky,5
118751,netty_netty,ByteBufUtilTest.testWriteUsAsciiComposite,"    @Test
    public void testWriteUsAsciiComposite() {
        String usAscii = ""NettyRocks"";
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(usAscii.getBytes(CharsetUtil.US_ASCII));
        ByteBuf buf2 = Unpooled.compositeBuffer().addComponent(
                Unpooled.buffer(8)).addComponent(Unpooled.buffer(24));
        // write some byte so we start writing with an offset.
        buf2.writeByte(1);
        ByteBufUtil.writeAscii(buf2, usAscii);

        // Skip the previously written byte.
        assertEquals(buf, buf2.skipBytes(1));

        buf.release();
        buf2.release();
    }
",non-flaky,5
118752,netty_netty,ByteBufUtilTest.testWriteUsAsciiCompositeWrapped,"    @Test
    public void testWriteUsAsciiCompositeWrapped() {
        String usAscii = ""NettyRocks"";
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(usAscii.getBytes(CharsetUtil.US_ASCII));
        ByteBuf buf2 = new WrappedCompositeByteBuf(Unpooled.compositeBuffer().addComponent(
                Unpooled.buffer(8)).addComponent(Unpooled.buffer(24)));
        // write some byte so we start writing with an offset.
        buf2.writeByte(1);
        ByteBufUtil.writeAscii(buf2, usAscii);

        // Skip the previously written byte.
        assertEquals(buf, buf2.skipBytes(1));

        buf.release();
        buf2.release();
    }
",non-flaky,5
118753,netty_netty,ByteBufUtilTest.testWriteUtf8,"    @Test
    public void testWriteUtf8() {
        String usAscii = ""Some UTF-8 like "";
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(usAscii.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = Unpooled.buffer(16);
        ByteBufUtil.writeUtf8(buf2, usAscii);

        assertEquals(buf, buf2);

        buf.release();
        buf2.release();
    }
",non-flaky,5
118754,netty_netty,ByteBufUtilTest.testWriteUtf8Composite,"    @Test
    public void testWriteUtf8Composite() {
        String utf8 = ""Some UTF-8 like "";
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(utf8.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = Unpooled.compositeBuffer().addComponent(
                Unpooled.buffer(8)).addComponent(Unpooled.buffer(24));
        // write some byte so we start writing with an offset.
        buf2.writeByte(1);
        ByteBufUtil.writeUtf8(buf2, utf8);

        // Skip the previously written byte.
        assertEquals(buf, buf2.skipBytes(1));

        buf.release();
        buf2.release();
    }
",non-flaky,5
118755,netty_netty,ByteBufUtilTest.testWriteUtf8CompositeWrapped,"    @Test
    public void testWriteUtf8CompositeWrapped() {
        String utf8 = ""Some UTF-8 like "";
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(utf8.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = new WrappedCompositeByteBuf(Unpooled.compositeBuffer().addComponent(
                Unpooled.buffer(8)).addComponent(Unpooled.buffer(24)));
        // write some byte so we start writing with an offset.
        buf2.writeByte(1);
        ByteBufUtil.writeUtf8(buf2, utf8);

        // Skip the previously written byte.
        assertEquals(buf, buf2.skipBytes(1));

        buf.release();
        buf2.release();
    }
",non-flaky,5
118756,netty_netty,ByteBufUtilTest.testWriteUtf8Surrogates,"    @Test
    public void testWriteUtf8Surrogates() {
        // leading surrogate + trailing surrogate
        String surrogateString = new StringBuilder(2)
                                .append('a')
                                .append('\uD800')
                                .append('\uDC00')
                                .append('b')
                                .toString();
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(surrogateString.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = Unpooled.buffer(16);
        ByteBufUtil.writeUtf8(buf2, surrogateString);

        assertEquals(buf, buf2);
        assertEquals(buf.readableBytes(), ByteBufUtil.utf8Bytes(surrogateString));

        buf.release();
        buf2.release();
    }
",non-flaky,5
118757,netty_netty,ByteBufUtilTest.testWriteUtf8InvalidOnlyTrailingSurrogate,"    @Test
    public void testWriteUtf8InvalidOnlyTrailingSurrogate() {
        String surrogateString = new StringBuilder(2)
                                .append('a')
                                .append('\uDC00')
                                .append('b')
                                .toString();
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(surrogateString.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = Unpooled.buffer(16);
        ByteBufUtil.writeUtf8(buf2, surrogateString);

        assertEquals(buf, buf2);
        assertEquals(buf.readableBytes(), ByteBufUtil.utf8Bytes(surrogateString));

        buf.release();
        buf2.release();
    }
",non-flaky,5
118758,netty_netty,ByteBufUtilTest.testWriteUtf8InvalidOnlyLeadingSurrogate,"    @Test
    public void testWriteUtf8InvalidOnlyLeadingSurrogate() {
        String surrogateString = new StringBuilder(2)
                                .append('a')
                                .append('\uD800')
                                .append('b')
                                .toString();
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(surrogateString.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = Unpooled.buffer(16);
        ByteBufUtil.writeUtf8(buf2, surrogateString);

        assertEquals(buf, buf2);
        assertEquals(buf.readableBytes(), ByteBufUtil.utf8Bytes(surrogateString));

        buf.release();
        buf2.release();
    }
",non-flaky,5
118759,netty_netty,ByteBufUtilTest.testWriteUtf8InvalidSurrogatesSwitched,"    @Test
    public void testWriteUtf8InvalidSurrogatesSwitched() {
        String surrogateString = new StringBuilder(2)
                                .append('a')
                                .append('\uDC00')
                                .append('\uD800')
                                .append('b')
                                .toString();
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(surrogateString.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = Unpooled.buffer(16);
        ByteBufUtil.writeUtf8(buf2, surrogateString);

        assertEquals(buf, buf2);
        assertEquals(buf.readableBytes(), ByteBufUtil.utf8Bytes(surrogateString));

        buf.release();
        buf2.release();
    }
",non-flaky,5
118760,netty_netty,ByteBufUtilTest.testWriteUtf8InvalidTwoLeadingSurrogates,"    @Test
    public void testWriteUtf8InvalidTwoLeadingSurrogates() {
        String surrogateString = new StringBuilder(2)
                                .append('a')
                                .append('\uD800')
                                .append('\uD800')
                                .append('b')
                                .toString();
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(surrogateString.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = Unpooled.buffer(16);
        ByteBufUtil.writeUtf8(buf2, surrogateString);

        assertEquals(buf, buf2);
        assertEquals(buf.readableBytes(), ByteBufUtil.utf8Bytes(surrogateString));
        buf.release();
        buf2.release();
    }
",non-flaky,5
118761,netty_netty,ByteBufUtilTest.testWriteUtf8InvalidTwoTrailingSurrogates,"    @Test
    public void testWriteUtf8InvalidTwoTrailingSurrogates() {
        String surrogateString = new StringBuilder(2)
                                .append('a')
                                .append('\uDC00')
                                .append('\uDC00')
                                .append('b')
                                .toString();
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(surrogateString.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = Unpooled.buffer(16);
        ByteBufUtil.writeUtf8(buf2, surrogateString);

        assertEquals(buf, buf2);
        assertEquals(buf.readableBytes(), ByteBufUtil.utf8Bytes(surrogateString));

        buf.release();
        buf2.release();
    }
",non-flaky,5
118762,netty_netty,ByteBufUtilTest.testWriteUtf8InvalidEndOnLeadingSurrogate,"    @Test
    public void testWriteUtf8InvalidEndOnLeadingSurrogate() {
        String surrogateString = new StringBuilder(2)
                                .append('\uD800')
                                .toString();
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(surrogateString.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = Unpooled.buffer(16);
        ByteBufUtil.writeUtf8(buf2, surrogateString);

        assertEquals(buf, buf2);
        assertEquals(buf.readableBytes(), ByteBufUtil.utf8Bytes(surrogateString));

        buf.release();
        buf2.release();
    }
",non-flaky,5
118763,netty_netty,ByteBufUtilTest.testWriteUtf8InvalidEndOnTrailingSurrogate,"    @Test
    public void testWriteUtf8InvalidEndOnTrailingSurrogate() {
        String surrogateString = new StringBuilder(2)
                                .append('\uDC00')
                                .toString();
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(surrogateString.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = Unpooled.buffer(16);
        ByteBufUtil.writeUtf8(buf2, surrogateString);

        assertEquals(buf, buf2);
        assertEquals(buf.readableBytes(), ByteBufUtil.utf8Bytes(surrogateString));

        buf.release();
        buf2.release();
    }
",non-flaky,5
118764,netty_netty,ByteBufUtilTest.testWriteUsAsciiString,"    @Test
    public void testWriteUsAsciiString() {
        AsciiString usAscii = new AsciiString(""NettyRocks"");
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(usAscii.toString().getBytes(CharsetUtil.US_ASCII));
        ByteBuf buf2 = Unpooled.buffer(16);
        ByteBufUtil.writeAscii(buf2, usAscii);

        assertEquals(buf, buf2);

        buf.release();
        buf2.release();
    }
",non-flaky,5
118765,netty_netty,ByteBufUtilTest.testWriteUtf8Wrapped,"    @Test
    public void testWriteUtf8Wrapped() {
        String usAscii = ""Some UTF-8 like "";
        ByteBuf buf = unreleasableBuffer(Unpooled.buffer(16));
        assertWrapped(buf);
        buf.writeBytes(usAscii.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = unreleasableBuffer(Unpooled.buffer(16));
        assertWrapped(buf2);
        ByteBufUtil.writeUtf8(buf2, usAscii);

        assertEquals(buf, buf2);

        buf.release();
        buf2.release();
    }
",non-flaky,5
118766,netty_netty,ByteBufUtilTest.testDecodeUsAscii,"    @Test
    public void testDecodeUsAscii() {
        testDecodeString(""This is a test"", CharsetUtil.US_ASCII);
    }
",non-flaky,5
118767,netty_netty,ByteBufUtilTest.testDecodeUtf8,"    @Test
    public void testDecodeUtf8() {
        testDecodeString(""Some UTF-8 like "", CharsetUtil.UTF_8);
    }
",non-flaky,5
118768,netty_netty,ByteBufUtilTest.testToStringDoesNotThrowIndexOutOfBounds,"    @Test
    public void testToStringDoesNotThrowIndexOutOfBounds() {
        CompositeByteBuf buffer = Unpooled.compositeBuffer();
        try {
            byte[] bytes = ""1234"".getBytes(CharsetUtil.UTF_8);
            buffer.addComponent(Unpooled.buffer(bytes.length).writeBytes(bytes));
            buffer.addComponent(Unpooled.buffer(bytes.length).writeBytes(bytes));
            assertEquals(""1234"", buffer.toString(bytes.length, bytes.length, CharsetUtil.UTF_8));
        } finally {
            buffer.release();
        }
    }
",non-flaky,5
118769,netty_netty,ByteBufUtilTest.testIsTextWithUtf8,"    @Test
    public void testIsTextWithUtf8() {
        byte[][] validUtf8Bytes = {
                ""netty"".getBytes(CharsetUtil.UTF_8),
                {(byte) 0x24},
                {(byte) 0xC2, (byte) 0xA2},
                {(byte) 0xE2, (byte) 0x82, (byte) 0xAC},
                {(byte) 0xF0, (byte) 0x90, (byte) 0x8D, (byte) 0x88},
                {(byte) 0x24,
                        (byte) 0xC2, (byte) 0xA2,
                        (byte) 0xE2, (byte) 0x82, (byte) 0xAC,
                        (byte) 0xF0, (byte) 0x90, (byte) 0x8D, (byte) 0x88} // multiple characters
        };
        for (byte[] bytes : validUtf8Bytes) {
            assertIsText(bytes, true, CharsetUtil.UTF_8);
        }
        byte[][] invalidUtf8Bytes = {
                {(byte) 0x80},
                {(byte) 0xF0, (byte) 0x82, (byte) 0x82, (byte) 0xAC}, // Overlong encodings
                {(byte) 0xC2},                                        // not enough bytes
                {(byte) 0xE2, (byte) 0x82},                           // not enough bytes
                {(byte) 0xF0, (byte) 0x90, (byte) 0x8D},              // not enough bytes
                {(byte) 0xC2, (byte) 0xC0},                           // not correct bytes
                {(byte) 0xE2, (byte) 0x82, (byte) 0xC0},              // not correct bytes
                {(byte) 0xF0, (byte) 0x90, (byte) 0x8D, (byte) 0xC0}, // not correct bytes
                {(byte) 0xC1, (byte) 0x80},                           // out of lower bound
                {(byte) 0xE0, (byte) 0x80, (byte) 0x80},              // out of lower bound
                {(byte) 0xED, (byte) 0xAF, (byte) 0x80}               // out of upper bound
        };
        for (byte[] bytes : invalidUtf8Bytes) {
            assertIsText(bytes, false, CharsetUtil.UTF_8);
        }
    }
",non-flaky,5
118770,netty_netty,ByteBufUtilTest.testIsTextWithoutOptimization,"    @Test
    public void testIsTextWithoutOptimization() {
        byte[] validBytes = {(byte) 0x01, (byte) 0xD8, (byte) 0x37, (byte) 0xDC};
        byte[] invalidBytes = {(byte) 0x01, (byte) 0xD8};

        assertIsText(validBytes, true, CharsetUtil.UTF_16LE);
        assertIsText(invalidBytes, false, CharsetUtil.UTF_16LE);
    }
",non-flaky,5
118771,netty_netty,ByteBufUtilTest.testIsTextWithAscii,"    @Test
    public void testIsTextWithAscii() {
        byte[] validBytes = {(byte) 0x00, (byte) 0x01, (byte) 0x37, (byte) 0x7F};
        byte[] invalidBytes = {(byte) 0x80, (byte) 0xFF};

        assertIsText(validBytes, true, CharsetUtil.US_ASCII);
        assertIsText(invalidBytes, false, CharsetUtil.US_ASCII);
    }
",non-flaky,5
118772,netty_netty,ByteBufUtilTest.testIsTextWithInvalidIndexAndLength,"    @Test
    public void testIsTextWithInvalidIndexAndLength() {
        ByteBuf buffer = Unpooled.buffer();
        try {
            buffer.writeBytes(new byte[4]);
            int[][] validIndexLengthPairs = {
                    {4, 0},
                    {0, 4},
                    {1, 3},
            };
            for (int[] pair : validIndexLengthPairs) {
                assertTrue(ByteBufUtil.isText(buffer, pair[0], pair[1], CharsetUtil.US_ASCII));
            }
            int[][] invalidIndexLengthPairs = {
                    {4, 1},
                    {-1, 2},
                    {3, -1},
                    {3, -2},
                    {5, 0},
                    {1, 5},
            };
            for (int[] pair : invalidIndexLengthPairs) {
                try {
                    ByteBufUtil.isText(buffer, pair[0], pair[1], CharsetUtil.US_ASCII);
                    fail(""Expected IndexOutOfBoundsException"");
                } catch (IndexOutOfBoundsException e) {
                    // expected
                }
            }
        } finally {
            buffer.release();
        }
    }
",non-flaky,5
118773,netty_netty,ByteBufUtilTest.testUtf8Bytes,"    @Test
    public void testUtf8Bytes() {
        final String s = ""Some UTF-8 like "";
        checkUtf8Bytes(s);
    }
",non-flaky,5
118774,netty_netty,ByteBufUtilTest.testUtf8BytesWithSurrogates,"    @Test
    public void testUtf8BytesWithSurrogates() {
        final String s = ""a\uD800\uDC00b"";
        checkUtf8Bytes(s);
    }
",non-flaky,5
118775,netty_netty,ByteBufUtilTest.testUtf8BytesWithNonSurrogates3Bytes,"    @Test
    public void testUtf8BytesWithNonSurrogates3Bytes() {
        final String s = ""a\uE000b"";
        checkUtf8Bytes(s);
    }
",non-flaky,5
118776,netty_netty,ByteBufUtilTest.testUtf8BytesWithNonSurrogatesNonAscii,"    @Test
    public void testUtf8BytesWithNonSurrogatesNonAscii() {
        final char nonAscii = (char) 0x81;
        final String s = ""a"" + nonAscii + ""b"";
        checkUtf8Bytes(s);
    }
",non-flaky,5
118777,netty_netty,ByteBufUtilTest.run,"    @Test
    public void testIsTextMultiThreaded() throws Throwable {
        final ByteBuf buffer = Unpooled.copiedBuffer(""Hello, World!"", CharsetUtil.ISO_8859_1);

        try {
            final AtomicInteger counter = new AtomicInteger(60000);
            final AtomicReference<Throwable> errorRef = new AtomicReference<Throwable>();
            List<Thread> threads = new ArrayList<Thread>();
            for (int i = 0; i < 10; i++) {
                Thread thread = new Thread(new Runnable() {
                    @Override
                    public void run() {
                        try {
                            while (errorRef.get() == null && counter.decrementAndGet() > 0) {
                                assertTrue(ByteBufUtil.isText(buffer, CharsetUtil.ISO_8859_1));
                            }
                        } catch (Throwable cause) {
                            errorRef.compareAndSet(null, cause);
                        }
                    }
",non-flaky,5
118778,netty_netty,AbstractReferenceCountedByteBufTest.testRetainOverflow,"    @Test(expected = IllegalReferenceCountException.class)
    public void testRetainOverflow() {
        AbstractReferenceCountedByteBuf referenceCounted = newReferenceCounted();
        referenceCounted.setRefCnt(Integer.MAX_VALUE);
        assertEquals(Integer.MAX_VALUE, referenceCounted.refCnt());
        referenceCounted.retain();
    }
",non-flaky,5
118779,netty_netty,AbstractReferenceCountedByteBufTest.testRetainOverflow2,"    @Test(expected = IllegalReferenceCountException.class)
    public void testRetainOverflow2() {
        AbstractReferenceCountedByteBuf referenceCounted = newReferenceCounted();
        assertEquals(1, referenceCounted.refCnt());
        referenceCounted.retain(Integer.MAX_VALUE);
    }
",non-flaky,5
118780,netty_netty,AbstractReferenceCountedByteBufTest.testReleaseOverflow,"    @Test(expected = IllegalReferenceCountException.class)
    public void testReleaseOverflow() {
        AbstractReferenceCountedByteBuf referenceCounted = newReferenceCounted();
        referenceCounted.setRefCnt(0);
        assertEquals(0, referenceCounted.refCnt());
        referenceCounted.release(Integer.MAX_VALUE);
    }
",non-flaky,5
118781,netty_netty,AbstractReferenceCountedByteBufTest.testReleaseErrorMessage,"    @Test
    public void testReleaseErrorMessage() {
        AbstractReferenceCountedByteBuf referenceCounted = newReferenceCounted();
        assertTrue(referenceCounted.release());
        try {
            referenceCounted.release(1);
            fail(""IllegalReferenceCountException didn't occur"");
        } catch (IllegalReferenceCountException e) {
            assertEquals(""refCnt: 0, decrement: 1"", e.getMessage());
        }
    }
",non-flaky,5
118782,netty_netty,AbstractReferenceCountedByteBufTest.testRetainResurrect,"    @Test(expected = IllegalReferenceCountException.class)
    public void testRetainResurrect() {
        AbstractReferenceCountedByteBuf referenceCounted = newReferenceCounted();
        assertTrue(referenceCounted.release());
        assertEquals(0, referenceCounted.refCnt());
        referenceCounted.retain();
    }
",non-flaky,5
118783,netty_netty,AbstractReferenceCountedByteBufTest.testRetainResurrect2,"    @Test(expected = IllegalReferenceCountException.class)
    public void testRetainResurrect2() {
        AbstractReferenceCountedByteBuf referenceCounted = newReferenceCounted();
        assertTrue(referenceCounted.release());
        assertEquals(0, referenceCounted.refCnt());
        referenceCounted.retain(2);
    }
",non-flaky,5
118784,netty_netty,ReadOnlyByteBufferBufTest.testCopyDirect,"    @Test
    public void testCopyDirect() {
        testCopy(true);
    }
",non-flaky,5
122541,vespa-engine_vespa,SystemCtlTest.enable,"    @Test
    public void enable() {
        terminal.expectCommand(""systemctl --quiet is-enabled docker 2>&1"", 1, """")
                .expectCommand(""systemctl enable docker 2>&1"")
                .expectCommand(""systemctl --quiet is-enabled docker 2>&1"");

        SystemCtl.SystemCtlEnable enableDockerService = new SystemCtl(terminal).enable(""docker"");
        assertTrue(enableDockerService.converge(taskContext));
        assertFalse(""Already converged"", enableDockerService.converge(taskContext));
    }
",non-flaky,5
122542,vespa-engine_vespa,SystemCtlTest.enableCommandFailure,"    @Test
    public void enableCommandFailure() {
        terminal.expectCommand(""systemctl --quiet is-enabled docker 2>&1"", 1, """")
                .expectCommand(""systemctl enable docker 2>&1"", 1, ""error enabling service"");
        SystemCtl.SystemCtlEnable enableDockerService = new SystemCtl(terminal).enable(""docker"");
        try {
            enableDockerService.converge(taskContext);
            fail();
        } catch (ChildProcessFailureException e) {
            // success
        }
    }
",non-flaky,5
122543,vespa-engine_vespa,SystemCtlTest.start,"    @Test
    public void start() {
        terminal.expectCommand(
                        ""systemctl show docker 2>&1"",
                        0,
                        ""a=b\n"" +
                                ""ActiveState=failed\n"" +
                                ""bar=zoo\n"")
                .expectCommand(""systemctl start docker 2>&1"", 0, """");

        SystemCtl.SystemCtlStart startDockerService = new SystemCtl(terminal).start(""docker"");
        assertTrue(startDockerService.converge(taskContext));
    }
",non-flaky,5
122544,vespa-engine_vespa,SystemCtlTest.startIsNoop,"    @Test
    public void startIsNoop() {
        terminal.expectCommand(
                        ""systemctl show docker 2>&1"",
                        0,
                        ""a=b\n"" +
                                ""ActiveState=active\n"" +
                                ""bar=zoo\n"")
                .expectCommand(""systemctl start docker 2>&1"", 0, """");

        SystemCtl.SystemCtlStart startDockerService = new SystemCtl(terminal).start(""docker"");
        assertFalse(startDockerService.converge(taskContext));
    }
",non-flaky,5
122545,vespa-engine_vespa,SystemCtlTest.startCommandFailre,"    @Test
    public void startCommandFailre() {
        terminal.expectCommand(""systemctl show docker 2>&1"", 1, ""error"");
        SystemCtl.SystemCtlStart startDockerService = new SystemCtl(terminal).start(""docker"");
        try {
            startDockerService.converge(taskContext);
            fail();
        } catch (ChildProcessFailureException e) {
            // success
        }
    }
",non-flaky,5
122546,vespa-engine_vespa,SystemCtlTest.disable,"    @Test
    public void disable() {
        terminal.expectCommand(""systemctl --quiet is-enabled docker 2>&1"")
                .expectCommand(""systemctl disable docker 2>&1"")
                .expectCommand(""systemctl --quiet is-enabled docker 2>&1"", 1, """");

        assertTrue(new SystemCtl(terminal).disable(""docker"").converge(taskContext));
        assertFalse(""Already converged"", new SystemCtl(terminal).disable(""docker"").converge(taskContext));
    }
",non-flaky,5
122547,vespa-engine_vespa,SystemCtlTest.stop,"    @Test
    public void stop() {
        terminal.expectCommand(
                        ""systemctl show docker 2>&1"",
                        0,
                        ""a=b\n"" +
                                ""ActiveState=active\n"" +
                                ""bar=zoo\n"")
                .expectCommand(""systemctl stop docker 2>&1"", 0, """");

        assertTrue(new SystemCtl(terminal).stop(""docker"").converge(taskContext));
    }
",non-flaky,5
122548,vespa-engine_vespa,SystemCtlTest.restart,"    @Test
    public void restart() {
        terminal.expectCommand(""systemctl restart docker 2>&1"", 0, """");
        assertTrue(new SystemCtl(terminal).restart(""docker"").converge(taskContext));
    }
",non-flaky,5
122549,vespa-engine_vespa,SystemCtlTest.testUnitExists,"    @Test
    public void testUnitExists() {
        SystemCtl systemCtl = new SystemCtl(terminal);

        terminal.expectCommand(""systemctl list-unit-files foo.service 2>&1"", 0,
                ""UNIT FILE STATE\n"" +
                        ""\n"" +
                        ""0 unit files listed.\n"");
        assertFalse(systemCtl.serviceExists(taskContext, ""foo""));

        terminal.expectCommand(""systemctl list-unit-files foo.service 2>&1"", 0,
                ""UNIT FILE           STATE  \n"" +
                        ""foo.service enabled\n"" +
                        ""\n"" +
                        ""1 unit files listed.\n"");
        assertTrue(systemCtl.serviceExists(taskContext, ""foo""));

        terminal.expectCommand(""systemctl list-unit-files foo.service 2>&1"", 0, ""garbage"");
        try {
            systemCtl.serviceExists(taskContext, ""foo"");
            fail();
        } catch (Exception e) {
            assertThat(e.getMessage(), containsString(""garbage""));
        }
    }
",non-flaky,5
122550,vespa-engine_vespa,SystemCtlTest.withSudo,"    @Test
    public void withSudo() {
        SystemCtl systemCtl = new SystemCtl(terminal).withSudo();
        terminal.expectCommand(""sudo systemctl restart docker 2>&1"", 0, """");
        assertTrue(systemCtl.restart(""docker"").converge(taskContext));
    }
",non-flaky,5
122551,vespa-engine_vespa,SystemCtlTesterTest.return_expectations,"    @Test
    public void return_expectations() {
        assertSystemCtlMethod(sct -> sct.expectEnable(unit), sc -> sc.enable(unit).converge(context));
        assertSystemCtlMethod(sct -> sct.expectDisable(unit), sc -> sc.disable(unit).converge(context));
        assertSystemCtlMethod(sct -> sct.expectStart(unit), sc -> sc.start(unit).converge(context));
        assertSystemCtlMethod(sct -> sct.expectStop(unit), sc -> sc.stop(unit).converge(context));
        assertSystemCtlMethod(sct -> sct.expectServiceExists(unit), sc -> sc.serviceExists(context, unit));
        assertSystemCtlMethod(sct -> sct.expectIsActive(unit), sc -> sc.isActive(context, unit));
    }
",non-flaky,5
122552,vespa-engine_vespa,SystemCtlTesterTest.void_tests,"    @Test
    public void void_tests() {
        systemCtl.expectRestart(unit);
        systemCtl.restart(unit).converge(context);
        terminal.verifyAllCommandsExecuted();

        systemCtl.expectDaemonReload();
        systemCtl.daemonReload(context);
        terminal.verifyAllCommandsExecuted();
    }
",non-flaky,5
122553,vespa-engine_vespa,ProcessFactoryImplTest.testSpawn,"    @Test
    public void testSpawn() {
        CommandLine commandLine = mock(CommandLine.class);
        when(commandLine.getArguments()).thenReturn(List.of(""program""));
        when(commandLine.getRedirectStderrToStdoutInsteadOfDiscard()).thenReturn(true);
        when(commandLine.programName()).thenReturn(""program"");
        Path outputPath;
        try (ChildProcess2Impl child = processFactory.spawn(commandLine)) {
            outputPath = child.getOutputPath();
            assertTrue(Files.exists(outputPath));
            assertEquals(""rw-------"", new UnixPath(outputPath).getPermissions());
            ArgumentCaptor<ProcessBuilder> processBuilderCaptor =
                    ArgumentCaptor.forClass(ProcessBuilder.class);
            verify(starter).start(processBuilderCaptor.capture());
            ProcessBuilder processBuilder = processBuilderCaptor.getValue();
            assertTrue(processBuilder.redirectErrorStream());
            ProcessBuilder.Redirect redirect = processBuilder.redirectOutput();
            assertEquals(ProcessBuilder.Redirect.Type.WRITE, redirect.type());
            assertEquals(outputPath.toFile(), redirect.file());
        }

        assertFalse(Files.exists(outputPath));
    }
",non-flaky,5
122554,vespa-engine_vespa,ProcessFactoryImplTest.close,"    @Test
    public void testSpawnWithPersistentOutputFile() {

        class TemporaryFile implements AutoCloseable {
            private final Path path;
            private TemporaryFile() {
                String outputFileName = ProcessFactoryImplTest.class.getSimpleName() + ""-temporary-test-file.out"";
                FileAttribute<Set<PosixFilePermission>> fileAttribute = PosixFilePermissions.asFileAttribute(
                        PosixFilePermissions.fromString(""rw-------""));
                path = uncheck(() -> Files.createTempFile(outputFileName, "".out"", fileAttribute));
            }
            @Override public void close() { uncheck(() -> Files.deleteIfExists(path)); }
        }

        try (TemporaryFile outputPath = new TemporaryFile()) {
",non-flaky,5
122555,vespa-engine_vespa,CommandLineTest.testStrings,"    @Test
    public void testStrings() {
        terminal.expectCommand(
                ""/bin/bash \""with space\"" \""speci&l\"" \""\"" \""double\\\""quote\"" 2>&1"",
                0,
                """");
        commandLine.add(""/bin/bash"", ""with space"", ""speci&l"", """", ""double\""quote"").execute();
        assertEquals(""bash"", commandLine.programName());
    }
",non-flaky,5
122556,vespa-engine_vespa,CommandLineTest.testBasicExecute,"    @Test
    public void testBasicExecute() {
        terminal.expectCommand(""foo bar 2>&1"", 0, ""line1\nline2\n\n"");
        CommandResult result = commandLine.add(""foo"", ""bar"").execute();
        assertEquals(0, result.getExitCode());
        assertEquals(""line1\nline2"", result.getOutput());
        assertEquals(""line1\nline2\n\n"", result.getUntrimmedOutput());
        assertEquals(List.of(""line1"", ""line2""), result.getOutputLines());
        assertEquals(1, context.getSystemModificationLog().size());
        assertEquals(""Executing command: foo bar 2>&1"", context.getSystemModificationLog().get(0));

        List<CommandLine> commandLines = terminal.getTestProcessFactory().getMutableCommandLines();
        assertEquals(1, commandLines.size());
        assertTrue(commandLine == commandLines.get(0));

        int lines = result.map(r -> r.getOutputLines().size());
        assertEquals(2, lines);
    }
",non-flaky,5
122557,vespa-engine_vespa,CommandLineTest.verifyDefaults,"    @Test
    public void verifyDefaults() {
        assertEquals(CommandLine.DEFAULT_TIMEOUT, commandLine.getTimeout());
        assertEquals(CommandLine.DEFAULT_MAX_OUTPUT_BYTES, commandLine.getMaxOutputBytes());
        assertEquals(CommandLine.DEFAULT_SIGTERM_GRACE_PERIOD, commandLine.getSigTermGracePeriod());
        assertEquals(CommandLine.DEFAULT_SIGKILL_GRACE_PERIOD, commandLine.getSigKillGracePeriod());
        assertEquals(0, commandLine.getArguments().size());
        assertEquals(Optional.empty(), commandLine.getOutputFile());
        assertEquals(StandardCharsets.UTF_8, commandLine.getOutputEncoding());
        assertTrue(commandLine.getRedirectStderrToStdoutInsteadOfDiscard());
        Predicate<Integer> defaultExitCodePredicate = commandLine.getSuccessfulExitCodePredicate();
        assertTrue(defaultExitCodePredicate.test(0));
        assertFalse(defaultExitCodePredicate.test(1));
    }
",non-flaky,5
122558,vespa-engine_vespa,CommandLineTest.executeSilently,"    @Test
    public void executeSilently() {
        terminal.ignoreCommand("""");
        commandLine.add(""foo"", ""bar"").executeSilently();
        assertEquals(0, context.getSystemModificationLog().size());
        commandLine.recordSilentExecutionAsSystemModification();
        assertEquals(1, context.getSystemModificationLog().size());
        assertEquals(""Executed command: foo bar 2>&1"", context.getSystemModificationLog().get(0));
    }
",non-flaky,5
122559,vespa-engine_vespa,CommandLineTest.processFactorySpawnFails,"    @Test(expected = NegativeArraySizeException.class)
    public void processFactorySpawnFails() {
        terminal.interceptCommand(
                        commandLine.toString(),
                        command -> { throw new NegativeArraySizeException(); });
        commandLine.add(""foo"").execute();
    }
",non-flaky,5
122560,vespa-engine_vespa,CommandLineTest.waitingForTerminationExceptionStillClosesChild,"    @Test
    public void waitingForTerminationExceptionStillClosesChild() {
        TestChildProcess2 child = new TestChildProcess2(0, """");
        child.throwInWaitForTermination(new NegativeArraySizeException());
        terminal.interceptCommand(commandLine.toString(), command -> child);
        assertFalse(child.closeCalled());
        try {
            commandLine.add(""foo"").execute();
            fail();
        } catch (NegativeArraySizeException e) {
            // OK
        }

        assertTrue(child.closeCalled());
    }
",non-flaky,5
122561,vespa-engine_vespa,CommandLineTest.programFails,"    @Test
    public void programFails() {
        terminal.expectCommand(""foo 2>&1"", 1, """");
        try {
            commandLine.add(""foo"").execute();
            fail();
        } catch (ChildProcessFailureException e) {
            assertEquals(
                    ""Command 'foo 2>&1' terminated with exit code 1: stdout/stderr: ''"",
                    e.getMessage());
        }
    }
",non-flaky,5
122562,vespa-engine_vespa,CommandLineTest.mapException,"    @Test
    public void mapException() {
        terminal.ignoreCommand(""output"");
        CommandResult result = terminal.newCommandLine(context).add(""program"").execute();
        IllegalArgumentException exception = new IllegalArgumentException(""foo"");
        try {
            result.mapOutput(output -> { throw exception; });
            fail();
        } catch (UnexpectedOutputException e) {
            assertEquals(""Command 'program 2>&1' output was not of the expected format: "" +
                    ""Failed to map output: stdout/stderr: 'output'"", e.getMessage());
            assertTrue(e.getCause() == exception);
        }
    }
",non-flaky,5
122563,vespa-engine_vespa,CommandLineTest.testMapEachLine,"    @Test
    public void testMapEachLine() {
        assertEquals(
                1 + 2 + 3,
                terminal.ignoreCommand(""1\n2\n3\n"")
                        .newCommandLine(context)
                        .add(""foo"")
                        .execute()
                        .mapEachLine(Integer::valueOf)
                        .stream()
                        .mapToInt(i -> i)
                        .sum());
    }
",non-flaky,5
122564,vespa-engine_vespa,CommandLineTest.addTokensWithMultipleWhiteSpaces,"    @Test
    public void addTokensWithMultipleWhiteSpaces() {
        terminal.expectCommand(""iptables -L 2>&1"");
        commandLine.addTokens(""iptables  -L"").execute();

        terminal.verifyAllCommandsExecuted();
    }
",non-flaky,5
122565,vespa-engine_vespa,CommandLineTest.addTokensWithSpecialCharacters,"    @Test
    public void addTokensWithSpecialCharacters() {
        terminal.expectCommand(""find . ! -name hei 2>&1"");
        commandLine.addTokens(""find . ! -name hei"").execute();

        terminal.verifyAllCommandsExecuted();
    }
",non-flaky,5
122566,vespa-engine_vespa,ChildProcess2ImplTest.testSuccess,"    @Test
    public void testSuccess() throws Exception {
        when(commandLine.getTimeout()).thenReturn(Duration.ofHours(1));
        when(commandLine.getMaxOutputBytes()).thenReturn(10L);
        when(commandLine.getOutputEncoding()).thenReturn(StandardCharsets.UTF_8);
        when(commandLine.getSigTermGracePeriod()).thenReturn(Duration.ofMinutes(2));
        when(commandLine.getSigKillGracePeriod()).thenReturn(Duration.ofMinutes(3));
        when(commandLine.toString()).thenReturn(""program arg"");

        when(timer.currentTime()).thenReturn(
                Instant.ofEpochMilli(1),
                Instant.ofEpochMilli(2));

        when(processApi.waitFor(anyLong(), any())).thenReturn(true);

        try (ChildProcess2Impl child =
                     new ChildProcess2Impl(commandLine, processApi, temporaryFile, timer)) {
            child.waitForTermination();
        }
    }
",non-flaky,5
122567,vespa-engine_vespa,ChildProcess2ImplTest.testTimeout,"    @Test
    public void testTimeout() throws Exception {
        when(commandLine.getTimeout()).thenReturn(Duration.ofSeconds(1));
        when(commandLine.getMaxOutputBytes()).thenReturn(10L);
        when(commandLine.getOutputEncoding()).thenReturn(StandardCharsets.UTF_8);
        when(commandLine.getSigTermGracePeriod()).thenReturn(Duration.ofMinutes(2));
        when(commandLine.getSigKillGracePeriod()).thenReturn(Duration.ofMinutes(3));
        when(commandLine.toString()).thenReturn(""program arg"");

        when(timer.currentTime()).thenReturn(
                Instant.ofEpochSecond(0),
                Instant.ofEpochSecond(2));

        when(processApi.waitFor(anyLong(), any())).thenReturn(true);

        try (ChildProcess2Impl child =
                     new ChildProcess2Impl(commandLine, processApi, temporaryFile, timer)) {
            try {
                child.waitForTermination();
                fail();
            } catch (TimeoutChildProcessException e) {
                assertEquals(
                        ""Command 'program arg' timed out after PT1S: stdout/stderr: ''"",
                        e.getMessage());
            }
        }
    }
",non-flaky,5
122568,vespa-engine_vespa,ChildProcess2ImplTest.testMaxOutputBytes,"    @Test
    public void testMaxOutputBytes() throws Exception {
        when(commandLine.getTimeout()).thenReturn(Duration.ofSeconds(1));
        when(commandLine.getMaxOutputBytes()).thenReturn(10L);
        when(commandLine.getOutputEncoding()).thenReturn(StandardCharsets.UTF_8);
        when(commandLine.getSigTermGracePeriod()).thenReturn(Duration.ofMinutes(2));
        when(commandLine.getSigKillGracePeriod()).thenReturn(Duration.ofMinutes(3));
        when(commandLine.toString()).thenReturn(""program arg"");

        when(timer.currentTime()).thenReturn(
                Instant.ofEpochMilli(0),
                Instant.ofEpochMilli(1));

        when(processApi.waitFor(anyLong(), any())).thenReturn(true);

        Files.write(temporaryFile, ""1234567890123"".getBytes(StandardCharsets.UTF_8));

        try (ChildProcess2Impl child =
                     new ChildProcess2Impl(commandLine, processApi, temporaryFile, timer)) {
            try {
                child.waitForTermination();
                fail();
            } catch (LargeOutputChildProcessException e) {
                assertEquals(
                        ""Command 'program arg' output more than 13 bytes: stdout/stderr: '1234567890123'"",
                        e.getMessage());
            }
        }
    }
",non-flaky,5
122569,vespa-engine_vespa,ChildProcess2ImplTest.testUnkillable,"    @Test
    public void testUnkillable() throws Exception {
        when(commandLine.getTimeout()).thenReturn(Duration.ofSeconds(1));
        when(commandLine.getMaxOutputBytes()).thenReturn(10L);
        when(commandLine.getOutputEncoding()).thenReturn(StandardCharsets.UTF_8);
        when(commandLine.getSigTermGracePeriod()).thenReturn(Duration.ofMinutes(2));
        when(commandLine.getSigKillGracePeriod()).thenReturn(Duration.ofMinutes(3));
        when(commandLine.toString()).thenReturn(""program arg"");

        when(timer.currentTime()).thenReturn(
                Instant.ofEpochMilli(0),
                Instant.ofEpochMilli(1));

        when(processApi.waitFor(anyLong(), any())).thenReturn(false);

        Files.write(temporaryFile, ""1234567890123"".getBytes(StandardCharsets.UTF_8));

        try (ChildProcess2Impl child =
                     new ChildProcess2Impl(commandLine, processApi, temporaryFile, timer)) {
            try {
                child.waitForTermination();
                fail();
            } catch (UnkillableChildProcessException e) {
                assertEquals(
                        ""Command 'program arg' did not terminate even after SIGTERM, +PT2M, SIGKILL, and +PT3M: stdout/stderr: '1234567890123'"",
                        e.getMessage());
            }
        }
    }
",non-flaky,5
122570,vespa-engine_vespa,DiskSizeTest.bytes_to_display_count_test,"    @Test
    public void bytes_to_display_count_test() {
        assertEquals(""-1 bytes"", DiskSize.of(-1).asString());
        assertEquals(""123 bytes"", DiskSize.of(123).asString());
        assertEquals(""1 kB"", DiskSize.of(1_000).asString());
        assertEquals(""15 MB"", DiskSize.of(15_000_000).asString());
        assertEquals(""123 GB"", DiskSize.of(123_456_789_012L).asString());
        assertEquals(""988 TB"", DiskSize.of(987_654_321_098_765L).asString());
        assertEquals(""987.7 TB"", DiskSize.of(987_654_321_098_765L).asString(1));
        assertEquals(""987.65 TB"", DiskSize.of(987_654_321_098_765L).asString(2));
        assertEquals(""2 PB"", DiskSize.of(2_000_000_000_000_000L).asString());
        assertEquals(""9 EB"", DiskSize.of(Long.MAX_VALUE).asString());
    }
",non-flaky,5
122571,vespa-engine_vespa,MakeDirectoryTest.newDirectory,"    @Test
    public void newDirectory() {
        verifySystemModifications(
                ""Creating directory "" + path,
                ""Changing owner of /parent/dir from user to test-owner"",
                ""Changing group of /parent/dir from group to test-group"");

        owner = ""new-owner"";
        verifySystemModifications(""Changing owner of /parent/dir from test-owner to new-owner"");

        group = ""new-group"";
        verifySystemModifications(""Changing group of /parent/dir from test-group to new-group"");

        permissions = ""--x---r--"";
        verifySystemModifications(""Changing permissions of /parent/dir from rwxr----x to --x---r--"");
    }
",non-flaky,5
122572,vespa-engine_vespa,MakeDirectoryTest.exceptionIfMissingParent,"    @Test
    public void exceptionIfMissingParent() {
        String path = ""/parent/dir"";
        MakeDirectory makeDirectory = new MakeDirectory(fileSystem.getPath(path));

        try {
            makeDirectory.converge(context);
        } catch (UncheckedIOException e) {
            if (e.getCause() instanceof NoSuchFileException) {
                return;
            }
            throw e;
        }
        fail();
    }
",non-flaky,5
122573,vespa-engine_vespa,MakeDirectoryTest.okIfParentExists,"    @Test
    public void okIfParentExists() {
        String path = ""/dir"";
        MakeDirectory makeDirectory = new MakeDirectory(fileSystem.getPath(path));
        assertTrue(makeDirectory.converge(context));
        assertTrue(Files.isDirectory(fileSystem.getPath(path)));

        MakeDirectory makeDirectory2 = new MakeDirectory(fileSystem.getPath(path));
        assertFalse(makeDirectory2.converge(context));
    }
",non-flaky,5
122574,vespa-engine_vespa,StoredBooleanTest.storedBoolean,"    @Test
    public void storedBoolean() {
        assertFalse(storedBoolean.value());
        storedBoolean.set(context);
        assertTrue(storedBoolean.value());
        storedBoolean.clear(context);
        assertFalse(storedBoolean.value());
    }
",non-flaky,5
122575,vespa-engine_vespa,StoredBooleanTest.testCompatibility,"    @Test
    public void testCompatibility() throws IOException {
        StoredInteger storedInteger = new StoredInteger(path);
        assertFalse(storedBoolean.value());

        storedInteger.write(context, 1);
        assertTrue(storedBoolean.value());

        storedInteger.write(context, 2);
        assertTrue(storedBoolean.value());

        storedInteger.write(context, 0);
        assertFalse(storedBoolean.value());

        Files.delete(path);
        assertFalse(storedBoolean.value());
    }
",non-flaky,5
122576,vespa-engine_vespa,FileSnapshotTest.fileDoesNotExist,"    @Test
    public void fileDoesNotExist() {
        assertFalse(fileSnapshot.exists());
        assertFalse(fileSnapshot.attributes().isPresent());
        assertFalse(fileSnapshot.content().isPresent());
        assertEquals(path.toPath(), fileSnapshot.path());
    }
",non-flaky,5
122577,vespa-engine_vespa,FileSnapshotTest.directory,"    @Test
    public void directory() {
        path.createParents().createDirectory();
        fileSnapshot = fileSnapshot.snapshot();
        assertTrue(fileSnapshot.exists());
        assertTrue(fileSnapshot.attributes().isPresent());
        assertTrue(fileSnapshot.attributes().get().isDirectory());
    }
",non-flaky,5
122578,vespa-engine_vespa,FileSnapshotTest.regularFile,"    @Test
    public void regularFile() {
        path.createParents().writeUtf8File(""file content"");
        fileSnapshot = fileSnapshot.snapshot();
        assertTrue(fileSnapshot.exists());
        assertTrue(fileSnapshot.attributes().isPresent());
        assertTrue(fileSnapshot.attributes().get().isRegularFile());
        assertTrue(fileSnapshot.utf8Content().isPresent());
        assertEquals(""file content"", fileSnapshot.utf8Content().get());

        FileSnapshot newFileSnapshot = fileSnapshot.snapshot();
        assertSame(fileSnapshot, newFileSnapshot);
    }
",non-flaky,5
122579,vespa-engine_vespa,FileSnapshotTest.fileRemoval,"    @Test
    public void fileRemoval() {
        path.createParents().writeUtf8File(""file content"");
        fileSnapshot = fileSnapshot.snapshot();
        assertTrue(fileSnapshot.exists());
        path.deleteIfExists();
        fileSnapshot = fileSnapshot.snapshot();
        assertFalse(fileSnapshot.exists());
    }
",non-flaky,5
122580,vespa-engine_vespa,EditorTest.testEdit,"    @Test
    public void testEdit() {
        path.writeUtf8File(joinLines(""first"", ""second"", ""third""));

        LineEditor lineEditor = mock(LineEditor.class);
        when(lineEditor.edit(any())).thenReturn(
                LineEdit.none(), // don't edit the first line
                LineEdit.remove(), // remove the second
                LineEdit.replaceWith(""replacement"")); // replace the third

        Editor editor = new Editor(path.toPath(), lineEditor);
        TaskContext context = mock(TaskContext.class);

        assertTrue(editor.converge(context));

        verify(lineEditor, times(3)).edit(any());

        // Verify the system modification message
        ArgumentCaptor<String> modificationMessage = ArgumentCaptor.forClass(String.class);
        verify(context).recordSystemModification(any(), modificationMessage.capture());
        assertEquals(
                ""Patching file /file:\n-second\n-third\n+replacement\n"",
                modificationMessage.getValue());

        // Verify the new contents of the file:
        assertEquals(joinLines(""first"", ""replacement""), path.readUtf8File());
    }
",non-flaky,5
122581,vespa-engine_vespa,EditorTest.testInsert,"    @Test
    public void testInsert() {
        path.writeUtf8File(joinLines(""second"", ""eight"", ""fifth"", ""seventh""));

        LineEditor lineEditor = mock(LineEditor.class);
        when(lineEditor.edit(any())).thenReturn(
                LineEdit.insertBefore(""first""), // insert first, and keep the second line
                LineEdit.replaceWith(""third"", ""fourth""), // remove eight, and replace with third and fourth instead
                LineEdit.none(), // Keep fifth
                LineEdit.insert(List.of(""sixth""), // insert sixth before seventh
                        List.of(""eight""))); // add eight after seventh

        Editor editor = new Editor(path.toPath(), lineEditor);
        TaskContext context = mock(TaskContext.class);

        assertTrue(editor.converge(context));

        // Verify the system modification message
        ArgumentCaptor<String> modificationMessage = ArgumentCaptor.forClass(String.class);
        verify(context).recordSystemModification(any(), modificationMessage.capture());
        assertEquals(
                ""Patching file /file:\n"" +
                        ""+first\n"" +
                        ""-eight\n"" +
                        ""+third\n"" +
                        ""+fourth\n"" +
                        ""+sixth\n"" +
                        ""+eight\n"",
                modificationMessage.getValue());

        // Verify the new contents of the file:
        assertEquals(joinLines(""first"", ""second"", ""third"", ""fourth"", ""fifth"", ""sixth"", ""seventh"", ""eight""),
                path.readUtf8File());
    }
",non-flaky,5
122582,vespa-engine_vespa,EditorTest.noop,"    @Test
    public void noop() {
        path.writeUtf8File(""line\n"");

        LineEditor lineEditor = mock(LineEditor.class);
        when(lineEditor.edit(any())).thenReturn(LineEdit.none());

        Editor editor = new Editor(path.toPath(), lineEditor);
        TaskContext context = mock(TaskContext.class);

        assertFalse(editor.converge(context));

        verify(lineEditor, times(1)).edit(any());

        // Verify the system modification message
        verify(context, times(0)).recordSystemModification(any(), any());

        // Verify same contents
        assertEquals(""line\n"", path.readUtf8File());
    }
",non-flaky,5
122583,vespa-engine_vespa,EditorTest.testMissingFile,"    @Test
    public void testMissingFile() {
        LineEditor lineEditor = mock(LineEditor.class);
        when(lineEditor.onComplete()).thenReturn(List.of(""line""));

        TaskContext context = mock(TaskContext.class);
        var editor = new Editor(path.toPath(), lineEditor);
        editor.converge(context);

        assertEquals(""line\n"", path.readUtf8File());
    }
",non-flaky,5
122584,vespa-engine_vespa,FileSyncTest.trivial,"    @Test
    public void trivial() {
        assertConvergence(""Creating file /dir/file.txt"",
                ""Changing owner of /dir/file.txt from user to owner"",
                ""Changing group of /dir/file.txt from group to group1"",
                ""Changing permissions of /dir/file.txt from rw-r--r-- to rw-r-xr--"");

        content = ""new-content"";
        assertConvergence(""Patching file /dir/file.txt"");

        owner = ""new-owner"";
        assertConvergence(""Changing owner of /dir/file.txt from owner to "" +
                        owner);

        group = ""new-group1"";
        assertConvergence(""Changing group of /dir/file.txt from group1 to new-group1"");

        permissions = ""rwxr--rwx"";
        assertConvergence(""Changing permissions of /dir/file.txt from rw-r-xr-- to "" +
                permissions);
    }
",non-flaky,5
122585,vespa-engine_vespa,FileFinderTest.all_files_non_recursive,"        @Test
        public void all_files_non_recursive() {
            assertFileHelper(FileFinder.files(testRoot())
                            .maxDepth(1),

                    of(""file-1.json"", ""test.json"", ""test.txt""),
                    of(""test"", ""test/file.txt"", ""test/data.json"", ""test/subdir-1"", ""test/subdir-1/test"", ""test/subdir-2""));
        }
",non-flaky,5
122586,vespa-engine_vespa,FileFinderTest.all_files_recursive,"        @Test
        public void all_files_recursive() {
            assertFileHelper(FileFinder.files(testRoot()),

                    of(""file-1.json"", ""test.json"", ""test.txt"", ""test/file.txt"", ""test/data.json"", ""test/subdir-1/test""),
                    of(""test"", ""test/subdir-1"", ""test/subdir-2""));
        }
",non-flaky,5
122587,vespa-engine_vespa,FileFinderTest.all_files_recursive_with_prune_relative,"        @Test
        public void all_files_recursive_with_prune_relative() {
            assertFileHelper(FileFinder.files(testRoot()).prune(fileSystem.getPath(""test"")),

                    of(""file-1.json"", ""test.json"", ""test.txt""),
                    of(""test"", ""test/file.txt"", ""test/data.json"", ""test/subdir-1"", ""test/subdir-1/test"", ""test/subdir-2""));
        }
",non-flaky,5
122588,vespa-engine_vespa,FileFinderTest.all_files_recursive_with_prune_absolute,"        @Test
        public void all_files_recursive_with_prune_absolute() {
            assertFileHelper(FileFinder.files(testRoot()).prune(testRoot().resolve(""test/subdir-1"")),

                    of(""file-1.json"", ""test.json"", ""test.txt"", ""test/file.txt"", ""test/data.json""),
                    of(""test"", ""test/subdir-1"", ""test/subdir-1/test"", ""test/subdir-2""));
        }
",non-flaky,5
122589,vespa-engine_vespa,FileFinderTest.throws_if_prune_path_not_under_base_path,"        @Test(expected = IllegalArgumentException.class)
        public void throws_if_prune_path_not_under_base_path() {
            FileFinder.files(Paths.get(""/some/path"")).prune(Paths.get(""/other/path""));
        }
",non-flaky,5
122590,vespa-engine_vespa,FileFinderTest.with_file_filter_recursive,"        @Test
        public void with_file_filter_recursive() {
            assertFileHelper(FileFinder.files(testRoot())
                            .match(FileFinder.nameEndsWith("".json"")),

                    of(""file-1.json"", ""test.json"", ""test/data.json""),
                    of(""test.txt"", ""test"", ""test/file.txt"", ""test/subdir-1"", ""test/subdir-1/test"", ""test/subdir-2""));
        }
",non-flaky,5
122591,vespa-engine_vespa,FileFinderTest.all_files_limited_depth,"        @Test
        public void all_files_limited_depth() {
            assertFileHelper(FileFinder.files(testRoot())
                            .maxDepth(2),

                    of(""test.txt"", ""file-1.json"", ""test.json"", ""test/file.txt"", ""test/data.json""),
                    of(""test"", ""test/subdir-1"", ""test/subdir-1/test"", ""test/subdir-2""));
        }
",non-flaky,5
122592,vespa-engine_vespa,FileFinderTest.directory_with_filter,"        @Test
        public void directory_with_filter() {
            assertFileHelper(FileFinder.directories(testRoot())
                            .match(FileFinder.nameStartsWith(""subdir""))
                            .maxDepth(2),

                    of(""test/subdir-1"", ""test/subdir-2""),
                    of(""file-1.json"", ""test.json"", ""test.txt"", ""test"", ""test/file.txt"", ""test/data.json""));
        }
",non-flaky,5
122593,vespa-engine_vespa,FileFinderTest.match_file_and_directory_with_same_name,"        @Test
        public void match_file_and_directory_with_same_name() {
            assertFileHelper(FileFinder.from(testRoot())
                            .match(FileFinder.nameEndsWith(""test"")),

                    of(""test"", ""test/subdir-1/test""),
                    of(""file-1.json"", ""test.json"", ""test.txt""));
        }
",non-flaky,5
122594,vespa-engine_vespa,FileFinderTest.all_contents,"        @Test
        public void all_contents() {
            assertFileHelper(FileFinder.from(testRoot())
                            .maxDepth(1),

                    of(""file-1.json"", ""test.json"", ""test.txt"", ""test""),
                    of());

            assertTrue(Files.exists(testRoot()));
        }
",non-flaky,5
122595,vespa-engine_vespa,FileFinderTest.age_filter_test,"        @Test
        public void age_filter_test() {
            Path path = Paths.get(""/my/fake/path"");
            when(attributes.lastModifiedTime()).thenReturn(FileTime.from(Instant.now().minus(Duration.ofHours(1))));
            FileFinder.FileAttributes fileAttributes = new FileFinder.FileAttributes(path, attributes);

            assertFalse(FileFinder.olderThan(Duration.ofMinutes(61)).test(fileAttributes));
            assertTrue(FileFinder.olderThan(Duration.ofMinutes(59)).test(fileAttributes));

            assertTrue(FileFinder.youngerThan(Duration.ofMinutes(61)).test(fileAttributes));
            assertFalse(FileFinder.youngerThan(Duration.ofMinutes(59)).test(fileAttributes));
        }
",non-flaky,5
122596,vespa-engine_vespa,FileFinderTest.size_filters,"        @Test
        public void size_filters() {
            Path path = Paths.get(""/my/fake/path"");
            when(attributes.size()).thenReturn(100L);
            FileFinder.FileAttributes fileAttributes = new FileFinder.FileAttributes(path, attributes);

            assertFalse(FileFinder.largerThan(101).test(fileAttributes));
            assertTrue(FileFinder.largerThan(99).test(fileAttributes));

            assertTrue(FileFinder.smallerThan(101).test(fileAttributes));
            assertFalse(FileFinder.smallerThan(99).test(fileAttributes));
        }
",non-flaky,5
122597,vespa-engine_vespa,FileFinderTest.filename_filters,"        @Test
        public void filename_filters() {
            Path path = Paths.get(""/my/fake/path/some-12352-file.json"");
            FileFinder.FileAttributes fileAttributes = new FileFinder.FileAttributes(path, attributes);

            assertTrue(FileFinder.nameStartsWith(""some-"").test(fileAttributes));
            assertFalse(FileFinder.nameStartsWith(""som-"").test(fileAttributes));

            assertTrue(FileFinder.nameEndsWith("".json"").test(fileAttributes));
            assertFalse(FileFinder.nameEndsWith(""file"").test(fileAttributes));

            assertTrue(FileFinder.nameMatches(Pattern.compile(""some-[0-9]+-file.json"")).test(fileAttributes));
            assertTrue(FileFinder.nameMatches(Pattern.compile(""^some-[0-9]+-file.json$"")).test(fileAttributes));
            assertFalse(FileFinder.nameMatches(Pattern.compile(""some-[0-9]-file.json"")).test(fileAttributes));
        }
",non-flaky,5
122598,vespa-engine_vespa,TemplarTest.test,"    @Test
    public void test() {
        Templar templar = new Templar(""x y <%= foo %>, some other <%=bar%> text"");
        templar.set(""foo"", ""fidelity"")
                .set(""bar"", ""halimov"")
                .set(""not"", ""used"");

        assertEquals(""x y fidelity, some other halimov text"", templar.resolve());
    }
",non-flaky,5
122599,vespa-engine_vespa,FileWriterTest.testWrite,"    @Test
    public void testWrite() {
        final String content = ""content"";
        final String permissions = ""rwxr-xr-x"";
        final String owner = ""owner"";
        final String group = ""group"";

        Path path = fileSystem.getPath(""/opt/vespa/tmp/file.txt"");
        FileWriter writer = new FileWriter(path, () -> content)
                .withPermissions(permissions)
                .withOwner(owner)
                .withGroup(group)
                .onlyIfFileDoesNotAlreadyExist();
        assertTrue(writer.converge(context));
        verify(context, times(1)).recordSystemModification(any(), eq(""Creating file "" + path));

        UnixPath unixPath = new UnixPath(path);
        assertEquals(content, unixPath.readUtf8File());
        assertEquals(permissions, unixPath.getPermissions());
        assertEquals(owner, unixPath.getOwner());
        assertEquals(group, unixPath.getGroup());
        Instant fileTime = unixPath.getLastModifiedTime();

        // Second time is a no-op.
        assertFalse(writer.converge(context));
        assertEquals(fileTime, unixPath.getLastModifiedTime());
    }
",non-flaky,5
122600,vespa-engine_vespa,FileWriterTest.testAtomicWrite,"    @Test
    public void testAtomicWrite() {
        FileWriter writer = new FileWriter(fileSystem.getPath(""/foo/bar""))
                .atomicWrite(true);

        assertTrue(writer.converge(context, ""content""));

        verify(context).recordSystemModification(any(), eq(""Creating file /foo/bar""));
        assertEquals(""content"", new UnixPath(writer.path()).readUtf8File());
    }
",non-flaky,5
122601,vespa-engine_vespa,FileDeleterTest.deleteExisting,"    @Test
    public void deleteExisting() {
        assertFalse(deleter.converge(context));
        path.createParents().writeUtf8File(""bar"");
        assertTrue(deleter.converge(context));
        assertFalse(deleter.converge(context));
    }
",non-flaky,5
122602,vespa-engine_vespa,TemplateTest.basic,"    @Test
    public void basic() {
        FileSystem fileSystem = TestFileSystem.create();
        Path templatePath = fileSystem.getPath(""/example.vm"");
        String templateContent = ""a $x, $y b"";
        new UnixPath(templatePath).writeUtf8File(templateContent);

        Path toPath = fileSystem.getPath(""/example"");
        TaskContext taskContext = mock(TaskContext.class);
        boolean converged = Template.at(templatePath)
                .set(""x"", ""foo"")
                .set(""y"", ""bar"")
                .getFileWriterTo(toPath)
                .converge(taskContext);

        assertTrue(converged);

        String actualContent = new UnixPath(toPath).readUtf8File();
        assertEquals(""a foo, bar b"", actualContent);
    }
",non-flaky,5
122603,vespa-engine_vespa,FileContentCacheTest.get,"    @Test
    public void get() {
        when(unixPath.readBytes()).thenReturn(content);
        assertArrayEquals(content, cache.get(Instant.ofEpochMilli(0)));
        verify(unixPath, times(1)).readBytes();
        verifyNoMoreInteractions(unixPath);

        // cache hit
        assertArrayEquals(content, cache.get(Instant.ofEpochMilli(0)));
        verify(unixPath, times(1)).readBytes();
        verifyNoMoreInteractions(unixPath);

        // cache miss
        when(unixPath.readBytes()).thenReturn(newContent);
        assertArrayEquals(newContent, cache.get(Instant.ofEpochMilli(1)));
        verify(unixPath, times(1 + 1)).readBytes();
        verifyNoMoreInteractions(unixPath);

        // cache hit both at times 0 and 1
        assertArrayEquals(newContent, cache.get(Instant.ofEpochMilli(0)));
        verify(unixPath, times(1 + 1)).readBytes();
        verifyNoMoreInteractions(unixPath);
        assertArrayEquals(newContent, cache.get(Instant.ofEpochMilli(1)));
        verify(unixPath, times(1 + 1)).readBytes();
        verifyNoMoreInteractions(unixPath);
    }
",non-flaky,5
122604,vespa-engine_vespa,FileContentCacheTest.updateWith,"    @Test
    public void updateWith() {
        cache.updateWith(content, Instant.ofEpochMilli(2));
        assertArrayEquals(content, cache.get(Instant.ofEpochMilli(2)));
        verifyNoMoreInteractions(unixPath);

        cache.updateWith(newContent, Instant.ofEpochMilli(4));
        assertArrayEquals(newContent, cache.get(Instant.ofEpochMilli(4)));
        verifyNoMoreInteractions(unixPath);
    }
",non-flaky,5
122605,vespa-engine_vespa,UnixPathTest.createParents,"    @Test
    public void createParents() {
        Path parentDirectory = fs.getPath(""/a/b/c"");
        Path filePath = parentDirectory.resolve(""bar"");
        UnixPath path = new UnixPath(filePath);

        assertFalse(Files.exists(fs.getPath(""/a"")));
        path.createParents();
        assertTrue(Files.exists(parentDirectory));
    }
",non-flaky,5
122606,vespa-engine_vespa,UnixPathTest.utf8File,"    @Test
    public void utf8File() {
        String original = ""foo\nbar\n"";
        UnixPath path = new UnixPath(fs.getPath(""example.txt""));
        path.writeUtf8File(original);
        String fromFile = path.readUtf8File();
        assertEquals(original, fromFile);
    }
",non-flaky,5
122607,vespa-engine_vespa,UnixPathTest.permissions,"    @Test
    public void permissions() {
        String expectedPermissions = ""rwxr-x---"";
        UnixPath path = new UnixPath(fs.getPath(""file.txt""));
        path.writeUtf8File(""foo"");
        path.setPermissions(expectedPermissions);
        assertEquals(expectedPermissions, path.getPermissions());
    }
",non-flaky,5
122608,vespa-engine_vespa,UnixPathTest.badPermissionsString,"    @Test(expected = IllegalArgumentException.class)
    public void badPermissionsString() {
        new UnixPath(fs.getPath(""file.txt"")).setPermissions(""abcdefghi"");
    }
",non-flaky,5
122609,vespa-engine_vespa,UnixPathTest.owner,"    @Test
    public void owner() {
        Path path = fs.getPath(""file.txt"");
        UnixPath unixPath = new UnixPath(path);
        unixPath.writeUtf8File(""foo"");

        unixPath.setOwner(""owner"");
        assertEquals(""owner"", unixPath.getOwner());

        unixPath.setGroup(""group"");
        assertEquals(""group"", unixPath.getGroup());
    }
",non-flaky,5
122610,vespa-engine_vespa,UnixPathTest.createDirectoryWithPermissions,"    @Test
    public void createDirectoryWithPermissions() {
        Path path = fs.getPath(""dir"");
        UnixPath unixPath = new UnixPath(path);
        String permissions = ""rwxr-xr--"";
        unixPath.createDirectory(permissions);
        assertTrue(unixPath.isDirectory());
        assertEquals(permissions, unixPath.getPermissions());
    }
",non-flaky,5
122611,vespa-engine_vespa,UnixPathTest.createSymbolicLink,"    @Test
    public void createSymbolicLink() {
        String original = ""foo\nbar\n"";
        UnixPath path = new UnixPath(fs.getPath(""example.txt""));
        path.writeUtf8File(original);
        String fromFile = path.readUtf8File();
        assertEquals(original, fromFile);

        UnixPath link = path.createSymbolicLink(fs.getPath(""link-to-example.txt""));
        assertEquals(original, link.readUtf8File());
    }
",non-flaky,5
122612,vespa-engine_vespa,UnixPathTest.readBytesIfExists,"    @Test
    public void readBytesIfExists() {
        UnixPath path = new UnixPath(fs.getPath(""example.txt""));
        assertFalse(path.readBytesIfExists().isPresent());
        path.writeBytes(new byte[]{42});
        assertArrayEquals(new byte[]{42}, path.readBytesIfExists().get());
    }
",non-flaky,5
122613,vespa-engine_vespa,UnixPathTest.deleteRecursively,"    @Test
    public void deleteRecursively() throws Exception {
        // Create the following file tree:
        //
        // /dir1
        //  |--- dir2
        //      |--- file1
        // /link1 -> /dir1/dir2
        //
        var dir1 = fs.getPath(""/dir1"");
        var dir2 = dir1.resolve(""dir2"");
        var file1 = dir2.resolve(""file1"");
        Files.createDirectories(dir2);
        Files.writeString(file1, ""file1"");
        var link1 = Files.createSymbolicLink(fs.getPath(""/link1""), dir2);

        new UnixPath(link1).deleteRecursively();
        assertTrue(""Deleting "" + link1 + "" recursively does not remove "" + dir2, Files.exists(dir2));
        assertTrue(""Deleting "" + link1 + "" recursively does not remove "" + file1, Files.exists(file1));

        new UnixPath(dir1).deleteRecursively();
        assertFalse(dir1 + "" deleted recursively"", Files.exists(file1));
        assertFalse(dir1 + "" deleted recursively"", Files.exists(dir2));
        assertFalse(dir1 + "" deleted recursively"", Files.exists(dir1));
    }
",non-flaky,5
122614,vespa-engine_vespa,UnixPathTest.atomicWrite,"    @Test
    public void atomicWrite() {
        var path = new UnixPath(fs.getPath(""/dir/foo""));
        path.createParents();
        path.writeUtf8File(""bar"");
        path.atomicWriteUt8(""bar v2"");
        assertEquals(""bar v2"", path.readUtf8File());
    }
",non-flaky,5
122615,vespa-engine_vespa,UnixPathTest.testParentAndFilename,"    @Test
    public void testParentAndFilename() {
        var absolutePath = new UnixPath(""/foo/bar"");
        assertEquals(""/foo"", absolutePath.getParent().toString());
        assertEquals(""bar"", absolutePath.getFilename());

        var pathWithoutSlash = new UnixPath(""foo"");
        assertRuntimeException(IllegalStateException.class, ""Path has no parent directory: 'foo'"", () -> pathWithoutSlash.getParent());
        assertEquals(""foo"", pathWithoutSlash.getFilename());

        var pathWithSlash = new UnixPath(""/foo"");
        assertEquals(""/"", pathWithSlash.getParent().toString());
        assertEquals(""foo"", pathWithSlash.getFilename());

        assertRuntimeException(IllegalStateException.class, ""Path has no parent directory: '/'"", () -> new UnixPath(""/"").getParent());
        assertRuntimeException(IllegalStateException.class, ""Path has no filename: '/'"", () -> new UnixPath(""/"").getFilename());
    }
",non-flaky,5
122616,vespa-engine_vespa,FileAttributesCacheTest.exists,"    @Test
    public void exists() {
        UnixPath unixPath = mock(UnixPath.class);
        FileAttributesCache cache = new FileAttributesCache(unixPath);

        when(unixPath.getAttributesIfExists()).thenReturn(Optional.empty());
        assertFalse(cache.get().isPresent());
        verify(unixPath, times(1)).getAttributesIfExists();
        verifyNoMoreInteractions(unixPath);

        FileAttributes attributes = mock(FileAttributes.class);
        when(unixPath.getAttributesIfExists()).thenReturn(Optional.of(attributes));
        assertTrue(cache.get().isPresent());
        verify(unixPath, times(1 + 1)).getAttributesIfExists();
        verifyNoMoreInteractions(unixPath);

        assertEquals(attributes, cache.getOrThrow());
        verifyNoMoreInteractions(unixPath);
    }
",non-flaky,5
122617,vespa-engine_vespa,StringEditorTest.testBasics,"    @Test
    public void testBasics() {
        assertCursor(0, 0, """");

        cursor.write(""hello"");
        assertCursor(0, 5, ""hello"");

        cursor.write(""one\ntwo"");
        assertCursor(1, 3, ""helloone\ntwo"");

        cursor.deleteAll();
        assertCursor(0, 0, """");

        cursor.moveForward();
        assertCursor(0, 0, """");

        cursor.writeLine(""foo"");
        assertCursor(1, 0, ""foo\n"");

        cursor.writeLines(""one"", ""two"");
        assertCursor(3, 0, ""foo\none\ntwo\n"");

        cursor.deleteBackward();
        assertCursor(2, 3, ""foo\none\ntwo"");

        cursor.deleteBackward(2);
        assertCursor(2, 1, ""foo\none\nt"");

        Mark mark = cursor.createMark();

        cursor.moveToStartOfPreviousLine().moveBackward(2);
        assertCursor(0, 2, ""foo\none\nt"");

        assertEquals(""o\none\nt"", cursor.getTextTo(mark));

        cursor.deleteTo(mark);
        assertCursor(0, 2, ""fo"");

        cursor.deleteBackward(2);
        assertCursor(0, 0, """");

        cursor.writeLines(""one"", ""two"", ""three"").moveToStartOfBuffer();
        assertCursor(0, 0, ""one\ntwo\nthree\n"");

        Pattern pattern = Pattern.compile(""t(.)"");
        Optional<Match> match = cursor.moveForwardToEndOfMatch(pattern);
        assertCursor(1, 2, ""one\ntwo\nthree\n"");
        assertTrue(match.isPresent());
        assertEquals(""tw"", match.get().match());
        assertEquals("""", match.get().prefix());
        assertEquals(""o"", match.get().suffix());
        assertEquals(new Position(1, 0), match.get().startOfMatch());
        assertEquals(new Position(1, 2), match.get().endOfMatch());
        assertEquals(1, match.get().groupCount());
        assertEquals(""w"", match.get().group(1));

        match = cursor.moveForwardToEndOfMatch(pattern);
        assertCursor(2, 2, ""one\ntwo\nthree\n"");
        assertTrue(match.isPresent());
        assertEquals(""th"", match.get().match());
        assertEquals(1, match.get().groupCount());
        assertEquals(""h"", match.get().group(1));

        match = cursor.moveForwardToEndOfMatch(pattern);
        assertCursor(2, 2, ""one\ntwo\nthree\n"");
        assertFalse(match.isPresent());

        assertTrue(cursor.skipBackward(""h""));
        assertCursor(2, 1, ""one\ntwo\nthree\n"");
        assertFalse(cursor.skipBackward(""x""));

        assertTrue(cursor.skipForward(""hre""));
        assertCursor(2, 4, ""one\ntwo\nthree\n"");
        assertFalse(cursor.skipForward(""x""));

        try {
            cursor.moveTo(mark);
            fail();
        } catch (IllegalArgumentException e) {
            // expected
        }

        mark = cursor.createMark();
        cursor.moveToStartOfBuffer();
        assertEquals(new Position(0, 0), cursor.getPosition());
        cursor.moveTo(mark);
        assertEquals(new Position(2, 4), cursor.getPosition());

        cursor.moveTo(1, 2);
        assertCursor(1, 2, ""one\ntwo\nthree\n"");

        cursor.deleteSuffix();
        assertCursor(1, 2, ""one\ntw\nthree\n"");

        cursor.deletePrefix();
        assertCursor(1, 0, ""one\n\nthree\n"");

        cursor.deleteLine();
        assertCursor(1, 0, ""one\nthree\n"");

        cursor.deleteLine();
        assertCursor(1, 0, ""one\n"");

        cursor.deleteLine();
        assertCursor(1, 0, ""one\n"");

        cursor.moveToStartOfBuffer().moveForward().writeNewlineAfter();
        assertCursor(0, 1, ""o\nne\n"");

        cursor.deleteAll().writeLines(""one"", ""two"", ""three"", ""four"");
        cursor.moveToStartOfBuffer().moveToStartOfNextLine();
        assertCursor(1, 0, ""one\ntwo\nthree\nfour\n"");
        Pattern pattern2 = Pattern.compile(""(o)(.)?"");
        int count = cursor.replaceMatches(pattern2, m -> {
            String prefix = m.group(2) == null ? """" : m.group(2);
            return prefix + m.match() + m.group(1);
        });
        assertCursor(3, 5, ""one\ntwoo\nthree\nfuouor\n"");
        assertEquals(2, count);

        cursor.moveToStartOfBuffer().moveToEndOfLine();
        Pattern pattern3 = Pattern.compile(""o"");
        count = cursor.replaceMatches(pattern3, m -> ""a"");
        assertEquals(4, count);
        assertCursor(3, 5, ""one\ntwaa\nthree\nfuauar\n"");
    }
",non-flaky,5
122618,vespa-engine_vespa,TextBufferImplTest.testWrite,"    @Test
    public void testWrite() {
        assertEquals("""", textBuffer.getString());
        assertWrite(2, 0, ""foo\nbar\n"",
                0, 0, ""foo\nbar\n"");

        assertWrite(1, 6, ""fofirst\nsecondo\nbar\n"",
                0, 2, ""first\nsecond"");

        assertWrite(3, 1, ""fofirst\nsecondo\nbar\na"",
                3, 0, ""a"");
        assertWrite(4, 0, ""fofirst\nsecondo\nbar\na\n"",
                3, 1, ""\n"");
    }
",non-flaky,5
122619,vespa-engine_vespa,TextBufferImplTest.testDelete,"    @Test
    public void testDelete() {
        write(0, 0, ""foo\nbar\nzoo\n"");
        delete(0, 2, 2, 1);
        assertEquals(""fooo\n"", textBuffer.getString());

        delete(0, 4, 1, 0);
        assertEquals(""fooo"", textBuffer.getString());

        delete(0, 0, 0, 4);
        assertEquals("""", textBuffer.getString());

        delete(0, 0, 0, 0);
        assertEquals("""", textBuffer.getString());
    }
",non-flaky,5
122620,vespa-engine_vespa,IPAddressesTest.choose_sitelocal_ipv4_over_public,"    @Test
    public void choose_sitelocal_ipv4_over_public() {
        mock.addAddress(""localhost"", ""38.3.4.2"")
                .addAddress(""localhost"", ""10.0.2.2"")
                .addAddress(""localhost"", ""fe80::1"")
                .addAddress(""localhost"", ""2001::1"");

        assertEquals(InetAddresses.forString(""10.0.2.2""), mock.getIPv4Address(""localhost"").get());
    }
",non-flaky,5
122621,vespa-engine_vespa,IPAddressesTest.choose_ipv6_public_over_local,"    @Test
    public void choose_ipv6_public_over_local() {
        mock.addAddress(""localhost"", ""38.3.4.2"")
                .addAddress(""localhost"", ""10.0.2.2"")
                .addAddress(""localhost"", ""fe80::1"")
                .addAddress(""localhost"", ""2001::1"");

        assertEquals(InetAddresses.forString(""2001::1""), mock.getIPv6Address(""localhost"").get());
    }
",non-flaky,5
122622,vespa-engine_vespa,IPAddressesTest.throws_when_multiple_ipv6_addresses,"    @Test(expected = RuntimeException.class)
    public void throws_when_multiple_ipv6_addresses() {
        mock.addAddress(""localhost"", ""2001::1"")
                .addAddress(""localhost"", ""2001::2"");
        mock.getIPv6Address(""localhost"");
    }
",non-flaky,5
122623,vespa-engine_vespa,IPAddressesTest.throws_when_multiple_private_ipv4_addresses,"    @Test(expected = RuntimeException.class)
    public void throws_when_multiple_private_ipv4_addresses() {
        mock.addAddress(""localhost"", ""38.3.4.2"")
                .addAddress(""localhost"", ""10.0.2.2"")
                .addAddress(""localhost"", ""10.0.2.3"");
        mock.getIPv4Address(""localhost"");
    }
",non-flaky,5
122624,vespa-engine_vespa,IPAddressesTest.translator_with_valid_parameters,"    @Test
    public void translator_with_valid_parameters() {

        // Test simplest possible address
        Inet6Address original = (Inet6Address) InetAddresses.forString(""2001:db8::1"");
        Inet6Address prefix = (Inet6Address) InetAddresses.forString(""fd00::"");
        InetAddress translated = IPAddresses.prefixTranslate(original, prefix, 8);
        assertEquals(""fd00:0:0:0:0:0:0:1"", translated.getHostAddress());


        // Test an actual aws address we use
        original = (Inet6Address) InetAddresses.forString(""2600:1f16:f34:5300:ccc6:1703:b7c2:369d"");
        translated = IPAddresses.prefixTranslate(original, prefix, 8);
        assertEquals(""fd00:0:0:0:ccc6:1703:b7c2:369d"", translated.getHostAddress());

        // Test different subnet size
        translated = IPAddresses.prefixTranslate(original, prefix, 6);
        assertEquals(""fd00:0:0:5300:ccc6:1703:b7c2:369d"", translated.getHostAddress());
    }
",non-flaky,5
122625,vespa-engine_vespa,DefaultEnvWriterTest.default_env_is_correctly_rewritten,"    @Test
    public void default_env_is_correctly_rewritten() throws IOException {
        Path tempFile = temporaryFolder.newFile().toPath();
        Files.copy(EXAMPLE_FILE, tempFile, REPLACE_EXISTING);

        DefaultEnvWriter writer = new DefaultEnvWriter();
        writer.addOverride(""VESPA_HOSTNAME"", ""my-new-hostname"");
        writer.addFallback(""VESPA_CONFIGSERVER"", ""new-fallback-configserver"");
        writer.addOverride(""VESPA_TLS_CONFIG_FILE"", ""/override/path/to/config.file"");

        boolean modified = writer.updateFile(context, tempFile);

        assertTrue(modified);
        assertEquals(Files.readString(EXPECTED_RESULT_FILE), Files.readString(tempFile));
        verify(context, times(1)).log(any(Logger.class), any(String.class));

        modified = writer.updateFile(context, tempFile);
        assertFalse(modified);
        assertEquals(Files.readString(EXPECTED_RESULT_FILE), Files.readString(tempFile));
        verify(context, times(1)).log(any(Logger.class), any(String.class));
    }
",non-flaky,5
122626,vespa-engine_vespa,DefaultEnvWriterTest.generates_default_env_content,"    @Test
    public void generates_default_env_content() throws IOException {
        DefaultEnvWriter writer = new DefaultEnvWriter();
        writer.addOverride(""VESPA_HOSTNAME"", ""my-new-hostname"");
        writer.addFallback(""VESPA_CONFIGSERVER"", ""new-fallback-configserver"");
        writer.addOverride(""VESPA_TLS_CONFIG_FILE"", ""/override/path/to/config.file"");
        writer.addUnset(""VESPA_LEGACY_OPTION"");
        String generatedContent = writer.generateContent();
        assertEquals(Files.readString(EXPECTED_RESULT_FILE), generatedContent);
    }
",non-flaky,5
122627,vespa-engine_vespa,YumTesterTest.generic_yum_methods,"    @Test
    public void generic_yum_methods() {
        assertYumMethod(yum -> yum.expectInstall(packages).withEnableRepo(repos),
                yum -> yum.install(List.of(packages)).enableRepo(repos).converge(context));

        assertYumMethod(yum -> yum.expectUpdate(packages).withEnableRepo(repos),
                yum -> yum.upgrade(List.of(packages)).enableRepo(repos).converge(context));

        assertYumMethod(yum -> yum.expectRemove(packages).withEnableRepo(repos),
                yum -> yum.remove(List.of(packages)).enableRepo(repos).converge(context));

        assertYumMethod(yum -> yum.expectInstallFixedVersion(minimalPackage.toName()).withEnableRepo(repos),
                yum -> yum.installFixedVersion(minimalPackage).enableRepo(repos).converge(context));
    }
",non-flaky,5
122628,vespa-engine_vespa,YumTesterTest.expect_query_installed,"    @Test
    public void expect_query_installed() {
        Stream.of(minimalPackage, fullPackage, null).forEach(pkg -> {
            yum.expectQueryInstalled(packages[0]).andReturn(pkg);
            assertEquals(Optional.ofNullable(pkg), yum.queryInstalled(context, packages[0]));
            terminal.verifyAllCommandsExecuted();
        });
    }
",non-flaky,5
122629,vespa-engine_vespa,YumPackageNameTest.testBuilder,"    @Test
    public void testBuilder() {
        YumPackageName yumPackage = new YumPackageName.Builder(""docker"")
                .setEpoch(""2"")
                .setVersion(""1.12.6"")
                .setRelease(""71.git3e8e77d.el7.centos.1"")
                .setArchitecture(""x86_64"")
                .build();
        assertEquals(""2:docker-1.12.6-71.git3e8e77d.el7.centos.1.x86_64"", yumPackage.toName());
    }
",non-flaky,5
122630,vespa-engine_vespa,YumPackageNameTest.testAllValidFormats,"    @Test
    public void testAllValidFormats() {
        // name
        verifyPackageName(
                ""docker-engine-selinux"",
                null,
                ""docker-engine-selinux"",
                null,
                null,
                null,
                ""docker-engine-selinux"",
                null);

        // name.arch
        verifyPackageName(
                ""docker-engine-selinux.x86_64"",
                null,
                ""docker-engine-selinux"",
                null,
                null,
                ""x86_64"",
                ""docker-engine-selinux.x86_64"",
                null);

        // name-ver-rel
        verifyPackageName(""docker-engine-selinux-1.12.6-1.el7"",
                null,
                ""docker-engine-selinux"",
                ""1.12.6"",
                ""1.el7"",
                null,
                ""docker-engine-selinux-1.12.6-1.el7"",
                ""0:docker-engine-selinux-1.12.6-1.el7.*"");

        // name-ver-rel.arch
        verifyPackageName(""docker-engine-selinux-1.12.6-1.el7.x86_64"",
                null,
                ""docker-engine-selinux"",
                ""1.12.6"",
                ""1.el7"",
                ""x86_64"",
                ""docker-engine-selinux-1.12.6-1.el7.x86_64"",
                ""0:docker-engine-selinux-1.12.6-1.el7.*"");

        // name-epoch:ver-rel.arch
        verifyPackageName(
                ""docker-2:1.12.6-71.git3e8e77d.el7.centos.1.x86_64"",
                ""2"",
                ""docker"",
                ""1.12.6"",
                ""71.git3e8e77d.el7.centos.1"",
                ""x86_64"",
                ""2:docker-1.12.6-71.git3e8e77d.el7.centos.1.x86_64"",
                ""2:docker-1.12.6-71.git3e8e77d.el7.centos.1.*"");

        // epoch:name-ver-rel.arch
        verifyPackageName(
                ""2:docker-1.12.6-71.git3e8e77d.el7.centos.1.x86_64"",
                ""2"",
                ""docker"",
                ""1.12.6"",
                ""71.git3e8e77d.el7.centos.1"",
                ""x86_64"",
                ""2:docker-1.12.6-71.git3e8e77d.el7.centos.1.x86_64"",
                ""2:docker-1.12.6-71.git3e8e77d.el7.centos.1.*"");
    }
",non-flaky,5
122631,vespa-engine_vespa,YumPackageNameTest.testArchitectures,"    @Test
    public void testArchitectures() {
        assertEquals(""x86_64"", YumPackageName.fromString(""docker.x86_64"").getArchitecture().get());
        assertEquals(""i686"", YumPackageName.fromString(""docker.i686"").getArchitecture().get());
        assertEquals(""noarch"", YumPackageName.fromString(""docker.noarch"").getArchitecture().get());
    }
",non-flaky,5
122632,vespa-engine_vespa,YumPackageNameTest.unrecognizedArchitectureGetsGobbledUp,"    @Test
    public void unrecognizedArchitectureGetsGobbledUp() {
        YumPackageName packageName = YumPackageName.fromString(""docker-engine-selinux-1.12.6-1.el7.i486"");
        // This is not a great feature - please use YumPackageName.Builder instead.
        assertEquals(""1.el7.i486"", packageName.getRelease().get());
    }
",non-flaky,5
122633,vespa-engine_vespa,YumPackageNameTest.failParsingOfPackageNameWithEpochAndArchitecture,"    @Test
    public void failParsingOfPackageNameWithEpochAndArchitecture() {
        try {
            YumPackageName.fromString(""epoch:docker-engine-selinux-1.12.6-1.el7.x86_64"");
            fail();
        } catch (IllegalArgumentException e) {
            assertThat(e.getMessage(), containsStringIgnoringCase(""epoch""));
        }
    }
",non-flaky,5
122634,vespa-engine_vespa,YumPackageNameTest.testSubset,"    @Test
    public void testSubset() {
        YumPackageName yumPackage = new YumPackageName.Builder(""docker"")
                .setVersion(""1.12.6"")
                .build();

        assertTrue(yumPackage.isSubsetOf(yumPackage));
        assertTrue(yumPackage.isSubsetOf(new YumPackageName.Builder(""docker"")
                .setVersion(""1.12.6"")
                .setEpoch(""2"")
                .setRelease(""71.git3e8e77d.el7.centos.1"")
                .setArchitecture(""x86_64"")
                .build()));
        assertFalse(yumPackage.isSubsetOf(new YumPackageName.Builder(""docker"")
                .setVersion(""1.13.1"")
                .build()));
    }
",non-flaky,5
122635,vespa-engine_vespa,YumTest.testQueryInstalledNevra,"    @Test
    public void testQueryInstalledNevra() {
        terminal.expectCommand(
                ""rpm -q docker --queryformat \""%{NAME}\\\\n%{EPOCH}\\\\n%{VERSION}\\\\n%{RELEASE}\\\\n%{ARCH}\"" 2>&1"",
                0,
                ""docker\n2\n1.13.1\n74.git6e3bb8e.el7.centos\nx86_64"");

        Optional<YumPackageName> installed = yum.queryInstalled(taskContext, ""docker"");

        assertTrue(installed.isPresent());
        assertEquals(""docker"", installed.get().getName());
        assertEquals(""2"", installed.get().getEpoch().get());
        assertEquals(""1.13.1"", installed.get().getVersion().get());
        assertEquals(""74.git6e3bb8e.el7.centos"", installed.get().getRelease().get());
        assertEquals(""x86_64"", installed.get().getArchitecture().get());
    }
",non-flaky,5
122636,vespa-engine_vespa,YumTest.testQueryInstalledPartial,"    @Test
    public void testQueryInstalledPartial() {
        terminal.expectCommand(
                ""rpm -q vespa-node-admin --queryformat \""%{NAME}\\\\n%{EPOCH}\\\\n%{VERSION}\\\\n%{RELEASE}\\\\n%{ARCH}\"" 2>&1"",
                0,
                ""vespa-node-admin\n(none)\n6.283.62\n1.el7\nnoarch"");

        Optional<YumPackageName> installed = yum.queryInstalled(taskContext, ""vespa-node-admin"");

        assertTrue(installed.isPresent());
        assertEquals(""vespa-node-admin"", installed.get().getName());
        assertFalse(installed.get().getEpoch().isPresent());
        assertEquals(""6.283.62"", installed.get().getVersion().get());
        assertEquals(""1.el7"", installed.get().getRelease().get());
        assertEquals(""noarch"", installed.get().getArchitecture().get());
    }
",non-flaky,5
122637,vespa-engine_vespa,YumTest.testQueryNotInstalled,"    @Test
    public void testQueryNotInstalled() {
        terminal.expectCommand(
                ""rpm -q fake-package --queryformat \""%{NAME}\\\\n%{EPOCH}\\\\n%{VERSION}\\\\n%{RELEASE}\\\\n%{ARCH}\"" 2>&1"",
                1,
                ""package fake-package is not installed"");

        Optional<YumPackageName> installed = yum.queryInstalled(taskContext, ""fake-package"");

        assertFalse(installed.isPresent());
    }
",non-flaky,5
122638,vespa-engine_vespa,YumTest.testAlreadyInstalled,"    @Test
    public void testAlreadyInstalled() {
        terminal.expectCommand(
                ""yum install --assumeyes --enablerepo=repo1 --enablerepo=repo2 --setopt skip_missing_names_on_install=False package-1 package-2 2>&1"",
                0,
                ""foobar\nNothing to do\n"");

        assertFalse(yum
                .install(""package-1"", ""package-2"")
                .enableRepo(""repo1"", ""repo2"")
                .converge(taskContext));
    }
",non-flaky,5
122639,vespa-engine_vespa,YumTest.testAlreadyUpgraded,"    @Test
    public void testAlreadyUpgraded() {
        terminal.expectCommand(
                ""yum upgrade --assumeyes --setopt skip_missing_names_on_update=False package-1 package-2 2>&1"",
                0,
                ""foobar\nNo packages marked for update\n"");

        assertFalse(yum
                .upgrade(""package-1"", ""package-2"")
                .converge(taskContext));
    }
",non-flaky,5
122640,vespa-engine_vespa,YumTest.testAlreadyRemoved,"    @Test
    public void testAlreadyRemoved() {
        terminal.expectCommand(
                ""yum remove --assumeyes package-1 package-2 2>&1"",
                0,
                ""foobar\nNo Packages marked for removal\n"");

        assertFalse(yum
                .remove(""package-1"", ""package-2"")
                .converge(taskContext));
    }
",non-flaky,5
133899,cdancy_jenkins-rest,PluginManagerApiLiveTest.testGetPlugins,"    @Test
    public void testGetPlugins() {
        final Plugins plugins = api().plugins(3, null);
        assertNotNull(plugins);
        assertTrue(plugins.errors().isEmpty());
        assertFalse(plugins.plugins().isEmpty());
        assertNotNull(plugins.plugins().get(0).shortName());
    }
",non-flaky,5
133900,cdancy_jenkins-rest,PluginManagerApiLiveTest.testInstallNecessaryPlugins,"    @Test
    public void testInstallNecessaryPlugins() {
        final RequestStatus status = api().installNecessaryPlugins(""artifactory@2.2.1"");
        assertNotNull(status);
        assertTrue(status.value());
        assertTrue(status.errors().isEmpty());
    }
",non-flaky,5
133901,cdancy_jenkins-rest,StatisticsApiMockTest.testOverallLoad,"@Test(groups = ""unit"", testName = ""StatisticsApiMockTest"")
    public void testOverallLoad() throws Exception {
        MockWebServer server = mockWebServer();

        server.enqueue(new MockResponse().setBody(payloadFromResource(""/overall-load.json"")).setResponseCode(200));
        JenkinsApi jenkinsApi = api(server.getUrl(""/""));
        StatisticsApi api = jenkinsApi.statisticsApi();
        try {
            OverallLoad load = api.overallLoad();
            assertNotNull(load);
            assertSent(server, ""GET"", ""/overallLoad/api/json"");
        } finally {
            jenkinsApi.close();
            server.shutdown();
        }
    }
",non-flaky,5
133902,cdancy_jenkins-rest,CrumbIssuerApiMockTest.testGetSystemInfo,"@Test(groups = ""unit"", testName = ""CrumbIssuerApiMockTest"")
    public void testGetSystemInfo() throws Exception {
        MockWebServer server = mockWebServer();

        final String value = ""04a1109fc2db171362c966ebe9fc87f0"";
        server.enqueue(new MockResponse().setBody(""Jenkins-Crumb:"" + value).setResponseCode(200));
        JenkinsApi jenkinsApi = api(server.getUrl(""/""));
        CrumbIssuerApi api = jenkinsApi.crumbIssuerApi();
        try {
            final Crumb instance = api.crumb();
            assertNotNull(instance);
            assertTrue(instance.value().equals(value));
            assertSentAccept(server, ""GET"", ""/crumbIssuer/api/xml?xpath=concat%28//crumbRequestField,%22%3A%22,//crumb%29"", MediaType.TEXT_PLAIN);
        } finally {
            jenkinsApi.close();
            server.shutdown();
        }
    }
",non-flaky,5
133903,cdancy_jenkins-rest,ConfigurationAsCodeApiLiveTest.testCascCheck,"    @Test
    public void testCascCheck() {
        String config = payloadFromResource(""/casc.yml"");
        RequestStatus success = api().check(config);
        assertTrue(success.value());
    }
",non-flaky,5
133904,cdancy_jenkins-rest,ConfigurationAsCodeApiLiveTest.testCascApply,"    @Test
    public void testCascApply() {
        String config = payloadFromResource(""/casc.yml"");
        RequestStatus success = api().apply(config);
        assertTrue(success.value());
    }
",non-flaky,5
133905,cdancy_jenkins-rest,ConfigurationAsCodeApiLiveTest.testBadCascCheck,"    @Test
    public void testBadCascCheck() {
        String config = payloadFromResource(""/casc-bad.yml"");
        RequestStatus success = api().check(config);
        assertFalse(success.value());
    }
",non-flaky,5
133906,cdancy_jenkins-rest,ConfigurationAsCodeApiLiveTest.testBadCascApply,"    @Test
    public void testBadCascApply() {
        String config = payloadFromResource(""/casc-bad.yml"");
        RequestStatus success = api().apply(config);
        assertFalse(success.value());
    }
",non-flaky,5
133907,cdancy_jenkins-rest,SystemApiLiveTest.testGetSystemInfo,"    @Test
    public void testGetSystemInfo() {
        final SystemInfo version = api().systemInfo();
        assertNotNull(version);
        assertTrue(version.jenkinsVersion() != null);
    }
",non-flaky,5
133908,cdancy_jenkins-rest,SystemApiLiveTest.testQuietDown,"    @Test
    public void testQuietDown() {
        RequestStatus success = api().quietDown();
        assertNotNull(success);
        assertTrue(success.value());
    }
",non-flaky,5
133909,cdancy_jenkins-rest,SystemApiLiveTest.testAlreadyQuietDown,"    @Test(dependsOnMethods = ""testQuietDown"")
    public void testAlreadyQuietDown() {
        RequestStatus success = api().quietDown();
        assertNotNull(success);
        assertTrue(success.value());
    }
",non-flaky,5
133910,cdancy_jenkins-rest,SystemApiLiveTest.testCancelQuietDown,"    @Test(dependsOnMethods = ""testAlreadyQuietDown"")
    public void testCancelQuietDown() {
        RequestStatus success = api().cancelQuietDown();
        assertNotNull(success);
        assertTrue(success.value());
    }
",non-flaky,5
133911,cdancy_jenkins-rest,SystemApiLiveTest.testAlreadyCanceledQuietDown,"    @Test(dependsOnMethods = ""testCancelQuietDown"")
    public void testAlreadyCanceledQuietDown() {
        RequestStatus success = api().cancelQuietDown();
        assertNotNull(success);
        assertTrue(success.value());
    }
",non-flaky,5
133912,cdancy_jenkins-rest,PluginManagerApiMockTest.testGetPlugins,"@Test(groups = ""unit"", testName = ""PluginManagerApiMockTest"")
    public void testGetPlugins() throws Exception {
        final MockWebServer server = mockWebServer();
        server.enqueue(new MockResponse().setBody(payloadFromResource(""/plugins.json"")).setResponseCode(200));
        
        final JenkinsApi jenkinsApi = api(server.getUrl(""/""));
        final PluginManagerApi api = jenkinsApi.pluginManagerApi();
        try {
            final Plugins plugins = api.plugins(3, null);
            assertNotNull(plugins);
            assertTrue(plugins.errors().isEmpty());
            assertFalse(plugins.plugins().isEmpty());
            assertNotNull(plugins.plugins().get(0).shortName());
            final Map<String, Object> queryParams = Maps.newHashMap();
            queryParams.put(""depth"", 3);
            assertSent(server, ""GET"", ""/pluginManager/api/json"", queryParams);
        } finally {
            jenkinsApi.close();
            server.shutdown();
        }
    }
",non-flaky,5
133913,cdancy_jenkins-rest,QueueApiLiveTest.init,"@Test(groups = ""live"", testName = ""QueueApiLiveTest"", singleThreaded = true)
    public void init() {
        String config = payloadFromResource(""/freestyle-project-sleep-task.xml"");
        RequestStatus success = api.jobsApi().create(null,""QueueTest"", config);
        assertTrue(success.value());

        config = payloadFromResource(""/freestyle-project.xml"");
        success = api.jobsApi().create(null,""QueueTestSingleParam"", config);
        assertTrue(success.value());

        config = payloadFromResource(""/freestyle-project-sleep-task-multiple-params.xml"");
        success = api.jobsApi().create(null,""QueueTestMultipleParams"", config);
        assertTrue(success.value());
    }
",non-flaky,5
133914,cdancy_jenkins-rest,QueueApiLiveTest.testGetQueue,"    @Test
    public void testGetQueue() {
        IntegerResponse job1 = api.jobsApi().build(null, ""QueueTest"");
        assertNotNull(job1);
        assertTrue(job1.errors().size() == 0);
        IntegerResponse job2 = api.jobsApi().build(null, ""QueueTest"");
        assertNotNull(job2);
        assertTrue(job2.errors().size() == 0);
        List<QueueItem> queueItems = api().queue();
        assertTrue(queueItems.size() > 0);
        boolean foundLastKickedJob = false;
        for (QueueItem item : queueItems) {
            if (item.id() == job2.value()) {
                foundLastKickedJob = true;
                break;
            }
        }
        assertTrue(foundLastKickedJob);
    }
",non-flaky,5
133915,cdancy_jenkins-rest,QueueApiLiveTest.testGetPendingQueueItem,"    @Test
    public void testGetPendingQueueItem() {
        IntegerResponse job1 = api.jobsApi().build(null,""QueueTest"");
        assertNotNull(job1);
        assertTrue(job1.errors().size() == 0);
        IntegerResponse job2 = api.jobsApi().build(null,""QueueTest"");
        assertNotNull(job2);
        assertTrue(job2.errors().size() == 0);

        // job2 is queue after job1, so while job1 runs, job2 is pending in the queue
        QueueItem queueItem = api().queueItem(job2.value());
        assertFalse(queueItem.cancelled());
        assertNotNull(queueItem.why());
        assertNull(queueItem.executable());
    }
",non-flaky,5
133916,cdancy_jenkins-rest,QueueApiLiveTest.testGetRunningQueueItem,"    @Test
    public void testGetRunningQueueItem() throws InterruptedException {
        IntegerResponse job1 = api.jobsApi().build(null,""QueueTest"");
        assertNotNull(job1);
        assertTrue(job1.errors().size() == 0);
        IntegerResponse job2 = api.jobsApi().build(null,""QueueTest"");
        assertNotNull(job2);
        assertTrue(job2.errors().size() == 0);

        // job1 runs first, so we get its queueItem
        QueueItem queueItem = getRunningQueueItem(job1.value());

        // If null, it means the queueItem has been cancelled, which would not be normal in this test
        assertNotNull(queueItem);
        assertFalse(queueItem.cancelled());

        //  We exepect this build to run, consequently:
        //  * the why field should now be null
        //  * the executable field should NOT be null
        //  * the build number should be set to an integer
        //  * the url for the build should be set to a string
        assertNull(queueItem.why());
        assertNotNull(queueItem.executable());
    }
",non-flaky,5
133917,cdancy_jenkins-rest,QueueApiLiveTest.testQueueItemSingleParameters,"    @Test
    public void testQueueItemSingleParameters() throws InterruptedException {
        Map<String, List<String>> params = new HashMap<>();
        params.put(""SomeKey"", Lists.newArrayList(""SomeVeryNewValue1""));
        IntegerResponse job1 = api.jobsApi().buildWithParameters(null,""QueueTestSingleParam"", params);
        assertNotNull(job1);
        assertTrue(job1.value() > 0);
        assertTrue(job1.errors().size() == 0);

        // Jenkins will reject two consecutive build requests when the build parameter values are the same
        // So we must set some different parameter values
        params = new HashMap<>();
        params.put(""SomeKey"", Lists.newArrayList(""SomeVeryNewValue2""));
        IntegerResponse job2 = api.jobsApi().buildWithParameters(null,""QueueTestSingleParam"", params);
        assertNotNull(job2);
        assertTrue(job2.value() > 0);
        assertTrue(job2.errors().size() == 0);

        QueueItem queueItem = getRunningQueueItem(job1.value());
        assertNotNull(queueItem);
        assertFalse(queueItem.cancelled());

        Map <String, String> map = Maps.newHashMap();
        map.put(""SomeKey"", ""SomeVeryNewValue1"");
        assertEquals(queueItem.params(), map);
    }
",non-flaky,5
133918,cdancy_jenkins-rest,QueueApiLiveTest.testQueueItemMultipleParameters,"    @Test
    public void testQueueItemMultipleParameters() throws InterruptedException {
        Map<String, List<String>> params = new HashMap<>();
        params.put(""SomeKey1"", Lists.newArrayList(""SomeVeryNewValue1""));
        IntegerResponse job1 = api.jobsApi().buildWithParameters(null, ""QueueTestMultipleParams"",params);
        assertNotNull(job1);
        assertTrue(job1.value() > 0);
        assertTrue(job1.errors().size() == 0);

        // Jenkins will reject two consecutive build requests when the build parameter values are the same
        // So we must set some different parameter values
        params = new HashMap<>();
        params.put(""SomeKey1"", Lists.newArrayList(""SomeVeryNewValue2""));
        IntegerResponse job2 = api.jobsApi().buildWithParameters(null, ""QueueTestMultipleParams"", params);
        assertNotNull(job2);
        assertTrue(job2.value() > 0);
        assertTrue(job2.errors().size() == 0);

        QueueItem queueItem = getRunningQueueItem(job1.value());
        assertNotNull(queueItem);
        assertFalse(queueItem.cancelled());

        Map <String, String> map = Maps.newHashMap();
        map.put(""SomeKey1"", ""SomeVeryNewValue1"");
        map.put(""SomeKey2"", ""SomeValue2"");
        map.put(""SomeKey3"", ""SomeValue3"");
        assertEquals(queueItem.params(), map);
    }
",non-flaky,5
133919,cdancy_jenkins-rest,QueueApiLiveTest.testQueueItemEmptyParameterValue,"    @Test
    public void testQueueItemEmptyParameterValue() throws InterruptedException {
        Map<String, List<String>> params = new HashMap<>();
        params.put(""SomeKey1"", Lists.newArrayList(""""));
        IntegerResponse job1 = api.jobsApi().buildWithParameters(null, ""QueueTestMultipleParams"",params);
        assertNotNull(job1);
        assertTrue(job1.value() > 0);
        assertTrue(job1.errors().size() == 0);

        QueueItem queueItem = getRunningQueueItem(job1.value());
        assertNotNull(queueItem);

        Map <String, String> map = Maps.newHashMap();
        map.put(""SomeKey1"", """");
        map.put(""SomeKey2"", ""SomeValue2"");
        map.put(""SomeKey3"", ""SomeValue3"");
        assertEquals(queueItem.params(), map);
    }
",non-flaky,5
133920,cdancy_jenkins-rest,QueueApiLiveTest.testGetCancelledQueueItem,"    @Test
    public void testGetCancelledQueueItem() throws InterruptedException {
        IntegerResponse job1 = api.jobsApi().build(null,""QueueTest"");
        assertNotNull(job1);
        assertTrue(job1.errors().size() == 0);
        IntegerResponse job2 = api.jobsApi().build(null, ""QueueTest"");
        assertNotNull(job2);
        assertTrue(job2.errors().size() == 0);

        RequestStatus success = api().cancel(job2.value());
        assertNotNull(success);
        assertTrue(success.value());
        assertTrue(success.errors().isEmpty());

        QueueItem queueItem = api().queueItem(job2.value());
        assertTrue(queueItem.cancelled());
        assertNull(queueItem.why());
        assertNull(queueItem.executable());
    }
",non-flaky,5
133921,cdancy_jenkins-rest,QueueApiLiveTest.testCancelNonExistentQueueItem,"    @Test
    public void testCancelNonExistentQueueItem() throws InterruptedException {
        RequestStatus success = api().cancel(123456789);
        assertNotNull(success);
        assertTrue(success.value());
        assertTrue(success.errors().isEmpty());
    }
",non-flaky,5
133922,cdancy_jenkins-rest,CrumbIssuerApiLiveTest.testGetCrumb,"    @Test
    public void testGetCrumb() {
        final Crumb crumb = api().crumb();
        assertNotNull(crumb);
        assertNotNull(crumb.value());
        assertTrue(crumb.errors().isEmpty());
    }
",non-flaky,5
133923,cdancy_jenkins-rest,SystemApiMockTest.testGetSystemInfo,"@Test(groups = ""unit"", testName = ""SystemApiMockTest"")
    public void testGetSystemInfo() throws Exception {
        MockWebServer server = mockWebServer();

        server.enqueue(
            new MockResponse().setHeader(""X-Hudson"", ""1.395"").setHeader(""X-Jenkins"", JenkinsApiMetadata.BUILD_VERSION)
                .setHeader(""X-Jenkins-Session"", ""cc323b8d"").setHeader(""X-Hudson-CLI-Port"", ""50000"")
                .setHeader(""X-Jenkins-CLI-Port"", ""50000"").setHeader(""X-Jenkins-CLI2-Port"", ""50000"")
                .setHeader(""X-Instance-Identity"", ""fdsa"").setHeader(""X-SSH-Endpoint"", ""127.0.1.1:46126"")
                .setHeader(""Server"", ""Jetty(winstone-2.9)"").setResponseCode(200));
        JenkinsApi jenkinsApi = api(server.getUrl(""/""));
        SystemApi api = jenkinsApi.systemApi();
        try {
            final SystemInfo version = api.systemInfo();
            assertNotNull(version);
            assertTrue(version.jenkinsVersion().equalsIgnoreCase(JenkinsApiMetadata.BUILD_VERSION));
            assertSent(server, ""HEAD"", ""/"");
        } finally {
            jenkinsApi.close();
            server.shutdown();
        }
    }
",non-flaky,5
133924,cdancy_jenkins-rest,JobsApiMockTest.testGetInnerFolderJobList,"@Test(groups = ""unit"", testName = ""JobsApiMockTest"")
    public void testGetInnerFolderJobList() throws Exception {
        MockWebServer server = mockWebServer();

        String body = payloadFromResource(""/jobsInJenkinsFolder.json"");
        server.enqueue(new MockResponse().setBody(body).setResponseCode(200));
        JenkinsApi jenkinsApi = api(server.url(""/"").url());
        JobsApi api = jenkinsApi.jobsApi();
        try {
            JobList output = api.jobList(""Folder1/Folder 2"");
            assertNotNull(output);
            assertNotNull(output.jobs());
            assertEquals(output.jobs().size(), 1);
            assertEquals(output.jobs().get(0), Job.create(""hudson.model.FreeStyleProject"", ""Test Project"", ""http://localhost:8080/job/username"", null));
            assertSent(server, ""GET"", ""/job/Folder1/job/Folder%202/api/json"");
        } finally {
            jenkinsApi.close();
            server.shutdown();
        }
    }
",non-flaky,5
133925,cdancy_jenkins-rest,StatisticsApiLiveTest.testOverallLoad,"    @Test
    public void testOverallLoad() {
        OverallLoad load = api().overallLoad();
        assertNotNull(load);
    }
",non-flaky,5
133926,cdancy_jenkins-rest,ConfigurationAsCodeApiMockTest.testCascCheck,"@Test(groups = ""unit"", testName = ""ConfigurationAsCodeApiMockTest"")
    public void testCascCheck() throws Exception {
        MockWebServer server = mockWebServer();

        server.enqueue(new MockResponse().setResponseCode(200));
        JenkinsApi jenkinsApi = api(server.url(""/"").url());
        ConfigurationAsCodeApi api = jenkinsApi.configurationAsCodeApi();
        try {
            RequestStatus requestStatus = api.check(""random"");
            assertNotNull(requestStatus);
            assertTrue(requestStatus.value());
            assertEquals(requestStatus.errors().size(), 0);
        } finally {
            jenkinsApi.close();
            server.shutdown();
        }
    }
",non-flaky,5
133927,cdancy_jenkins-rest,QueueApiMockTest.testGetQueue,"@Test(groups = ""unit"", testName = ""QueueApiMockTest"")
    public void testGetQueue() throws Exception {
        MockWebServer server = mockWebServer();
        String body = payloadFromResource(""/queue.json"");
        server.enqueue(new MockResponse().setBody(body).setResponseCode(200));
        JenkinsApi jenkinsApi = api(server.getUrl(""/""));
        QueueApi api = jenkinsApi.queueApi();
        try {
            List<QueueItem> output = api.queue();
            assertTrue(output.size() == 2);
            assertSent(server, ""GET"", ""/queue/api/json"");
        } finally {
            jenkinsApi.close();
            server.shutdown();
        }
    }
",non-flaky,5
133928,cdancy_jenkins-rest,BaseJenkinsApiLiveTest.payloadFromResource,"@Test(groups = ""live"")
    public String payloadFromResource(String resource) {
        try {
            return new String(toStringAndClose(getClass().getResourceAsStream(resource)).getBytes(Charsets.UTF_8));
        } catch (IOException e) {
            throw Throwables.propagate(e);
        }
    }
",non-flaky,5
133929,cdancy_jenkins-rest,JenkinsApiMetadataTest.testEtcdApiRegistered,"@Test(groups = ""unit"", testName = ""JenkinsApiMetadataTest"")
   public void testEtcdApiRegistered() {
      ApiMetadata api = Apis.withId(""jenkins"");

      assertNotNull(api);
      assertTrue(api instanceof JenkinsApiMetadata);
      assertEquals(api.getId(), ""jenkins"");
   }
",non-flaky,5
156375,apache_commons-lang,ClassPathUtilsTest.testConstructor,"    @Test
    public void testConstructor() {
        assertNotNull(new ClassPathUtils());
        final Constructor<?>[] cons = ClassPathUtils.class.getDeclaredConstructors();
        assertEquals(1, cons.length);
        assertTrue(Modifier.isPublic(cons[0].getModifiers()));
        assertTrue(Modifier.isPublic(ClassPathUtils.class.getModifiers()));
        assertFalse(Modifier.isFinal(ClassPathUtils.class.getModifiers()));
    }
",non-flaky,5
156376,apache_commons-lang,ClassPathUtilsTest.testToFullyQualifiedNameNullClassString,"    @Test
    public void testToFullyQualifiedNameNullClassString() {
        assertThrows(NullPointerException.class,
                () -> ClassPathUtils.toFullyQualifiedName((Class<?>) null, ""Test.properties""));
    }
",non-flaky,5
156377,apache_commons-lang,ClassPathUtilsTest.testToFullyQualifiedNameClassNull,"    @Test
    public void testToFullyQualifiedNameClassNull() {
        assertThrows(NullPointerException.class, () -> ClassPathUtils.toFullyQualifiedName(ClassPathUtils.class, null));
    }
",non-flaky,5
156378,apache_commons-lang,ClassPathUtilsTest.testToFullyQualifiedNameClassString,"    @Test
    public void testToFullyQualifiedNameClassString() {
        final String expected = ""org.apache.commons.lang3.Test.properties"";
        final String actual = ClassPathUtils.toFullyQualifiedName(ClassPathUtils.class, ""Test.properties"");

        assertEquals(expected, actual);
    }
",non-flaky,5
156379,apache_commons-lang,ClassPathUtilsTest.testToFullyQualifiedNameNullPackageString,"    @Test
    public void testToFullyQualifiedNameNullPackageString() {
        assertThrows(NullPointerException.class,
                () -> ClassPathUtils.toFullyQualifiedName((Package) null, ""Test.properties""));
    }
",non-flaky,5
156380,apache_commons-lang,ClassPathUtilsTest.testToFullyQualifiedNamePackageNull,"    @Test
    public void testToFullyQualifiedNamePackageNull() {
        assertThrows(NullPointerException.class,
                () -> ClassPathUtils.toFullyQualifiedName(ClassPathUtils.class.getPackage(), null));
    }
",non-flaky,5
156381,apache_commons-lang,ClassPathUtilsTest.testToFullyQualifiedNamePackageString,"    @Test
    public void testToFullyQualifiedNamePackageString() {
        final String expected = ""org.apache.commons.lang3.Test.properties"";
        final String actual = ClassPathUtils.toFullyQualifiedName(ClassPathUtils.class.getPackage(), ""Test.properties"");

        assertEquals(expected, actual);
    }
",non-flaky,5
156382,apache_commons-lang,ClassPathUtilsTest.testToFullyQualifiedPathClassNullString,"    @Test
    public void testToFullyQualifiedPathClassNullString() {
        assertThrows(NullPointerException.class,
                () -> ClassPathUtils.toFullyQualifiedPath((Class<?>) null, ""Test.properties""));
    }
",non-flaky,5
156383,apache_commons-lang,ClassPathUtilsTest.testToFullyQualifiedPathClassNull,"    @Test
    public void testToFullyQualifiedPathClassNull() {
        assertThrows(NullPointerException.class, () -> ClassPathUtils.toFullyQualifiedPath(ClassPathUtils.class, null));
    }
",non-flaky,5
156384,apache_commons-lang,ClassPathUtilsTest.testToFullyQualifiedPathClass,"    @Test
    public void testToFullyQualifiedPathClass() {
        final String expected = ""org/apache/commons/lang3/Test.properties"";
        final String actual = ClassPathUtils.toFullyQualifiedPath(ClassPathUtils.class, ""Test.properties"");

        assertEquals(expected, actual);
    }
",non-flaky,5
156385,apache_commons-lang,ClassPathUtilsTest.testToFullyQualifiedPathPackageNullString,"    @Test
    public void testToFullyQualifiedPathPackageNullString() {
        assertThrows(NullPointerException.class,
                () -> ClassPathUtils.toFullyQualifiedPath((Package) null, ""Test.properties""));
    }
",non-flaky,5
156386,apache_commons-lang,ClassPathUtilsTest.testToFullyQualifiedPathPackageNull,"    @Test
    public void testToFullyQualifiedPathPackageNull() {
        assertThrows(NullPointerException.class,
                () -> ClassPathUtils.toFullyQualifiedPath(ClassPathUtils.class.getPackage(), null));
    }
",non-flaky,5
156387,apache_commons-lang,ClassPathUtilsTest.testToFullyQualifiedPathPackage,"    @Test
    public void testToFullyQualifiedPathPackage() {
        final String expected = ""org/apache/commons/lang3/Test.properties"";
        final String actual = ClassPathUtils.toFullyQualifiedPath(ClassPathUtils.class.getPackage(), ""Test.properties"");

        assertEquals(expected, actual);
    }
",non-flaky,5
156388,apache_commons-lang,StringUtilsEmptyBlankTest.testIsEmpty,"    @Test
    public void testIsEmpty() {
        assertTrue(StringUtils.isEmpty(null));
        assertTrue(StringUtils.isEmpty(""""));
        assertFalse(StringUtils.isEmpty("" ""));
        assertFalse(StringUtils.isEmpty(""foo""));
        assertFalse(StringUtils.isEmpty(""  foo  ""));
    }
",non-flaky,5
156389,apache_commons-lang,StringUtilsEmptyBlankTest.testIsNotEmpty,"    @Test
    public void testIsNotEmpty() {
        assertFalse(StringUtils.isNotEmpty(null));
        assertFalse(StringUtils.isNotEmpty(""""));
        assertTrue(StringUtils.isNotEmpty("" ""));
        assertTrue(StringUtils.isNotEmpty(""foo""));
        assertTrue(StringUtils.isNotEmpty(""  foo  ""));
    }
",non-flaky,5
156390,apache_commons-lang,StringUtilsEmptyBlankTest.testIsAnyEmpty,"    @Test
    public void testIsAnyEmpty() {
        assertTrue(StringUtils.isAnyEmpty((String) null));
        assertFalse(StringUtils.isAnyEmpty((String[]) null));
        assertTrue(StringUtils.isAnyEmpty(null, ""foo""));
        assertTrue(StringUtils.isAnyEmpty("""", ""bar""));
        assertTrue(StringUtils.isAnyEmpty(""bob"", """"));
        assertTrue(StringUtils.isAnyEmpty(""  bob  "", null));
        assertFalse(StringUtils.isAnyEmpty("" "", ""bar""));
        assertFalse(StringUtils.isAnyEmpty(""foo"", ""bar""));
    }
",non-flaky,5
156391,apache_commons-lang,StringUtilsEmptyBlankTest.testIsNoneEmpty,"    @Test
    public void testIsNoneEmpty() {
        assertFalse(StringUtils.isNoneEmpty((String) null));
        assertTrue(StringUtils.isNoneEmpty((String[]) null));
        assertFalse(StringUtils.isNoneEmpty(null, ""foo""));
        assertFalse(StringUtils.isNoneEmpty("""", ""bar""));
        assertFalse(StringUtils.isNoneEmpty(""bob"", """"));
        assertFalse(StringUtils.isNoneEmpty(""  bob  "", null));
        assertTrue(StringUtils.isNoneEmpty("" "", ""bar""));
        assertTrue(StringUtils.isNoneEmpty(""foo"", ""bar""));
    }
",non-flaky,5
156392,apache_commons-lang,StringUtilsEmptyBlankTest.testIsAllEmpty,"    @Test
    public void testIsAllEmpty() {
        assertTrue(StringUtils.isAllEmpty());
        assertTrue(StringUtils.isAllEmpty(new String[]{}));
        assertTrue(StringUtils.isAllEmpty((String) null));
        assertTrue(StringUtils.isAllEmpty((String[]) null));
        assertFalse(StringUtils.isAllEmpty(null, ""foo""));
        assertFalse(StringUtils.isAllEmpty("""", ""bar""));
        assertFalse(StringUtils.isAllEmpty(""bob"", """"));
        assertFalse(StringUtils.isAllEmpty(""  bob  "", null));
        assertFalse(StringUtils.isAllEmpty("" "", ""bar""));
        assertFalse(StringUtils.isAllEmpty(""foo"", ""bar""));
        assertTrue(StringUtils.isAllEmpty("""", null));
    }
",non-flaky,5
156393,apache_commons-lang,StringUtilsEmptyBlankTest.testIsBlank,"    @Test
    public void testIsBlank() {
        assertTrue(StringUtils.isBlank(null));
        assertTrue(StringUtils.isBlank(""""));
        assertTrue(StringUtils.isBlank(StringUtilsTest.WHITESPACE));
        assertFalse(StringUtils.isBlank(""foo""));
        assertFalse(StringUtils.isBlank(""  foo  ""));
    }
",non-flaky,5
156394,apache_commons-lang,StringUtilsEmptyBlankTest.testIsNotBlank,"    @Test
    public void testIsNotBlank() {
        assertFalse(StringUtils.isNotBlank(null));
        assertFalse(StringUtils.isNotBlank(""""));
        assertFalse(StringUtils.isNotBlank(StringUtilsTest.WHITESPACE));
        assertTrue(StringUtils.isNotBlank(""foo""));
        assertTrue(StringUtils.isNotBlank(""  foo  ""));
    }
",non-flaky,5
156395,apache_commons-lang,StringUtilsEmptyBlankTest.testIsAnyBlank,"    @Test
    public void testIsAnyBlank() {
        assertTrue(StringUtils.isAnyBlank((String) null));
        assertFalse(StringUtils.isAnyBlank((String[]) null));
        assertTrue(StringUtils.isAnyBlank(null, ""foo""));
        assertTrue(StringUtils.isAnyBlank(null, null));
        assertTrue(StringUtils.isAnyBlank("""", ""bar""));
        assertTrue(StringUtils.isAnyBlank(""bob"", """"));
        assertTrue(StringUtils.isAnyBlank(""  bob  "", null));
        assertTrue(StringUtils.isAnyBlank("" "", ""bar""));
        assertFalse(StringUtils.isAnyBlank(""foo"", ""bar""));
    }
",non-flaky,5
156396,apache_commons-lang,StringUtilsEmptyBlankTest.testIsNoneBlank,"    @Test
    public void testIsNoneBlank() {
        assertFalse(StringUtils.isNoneBlank((String) null));
        assertTrue(StringUtils.isNoneBlank((String[]) null));
        assertFalse(StringUtils.isNoneBlank(null, ""foo""));
        assertFalse(StringUtils.isNoneBlank(null, null));
        assertFalse(StringUtils.isNoneBlank("""", ""bar""));
        assertFalse(StringUtils.isNoneBlank(""bob"", """"));
        assertFalse(StringUtils.isNoneBlank(""  bob  "", null));
        assertFalse(StringUtils.isNoneBlank("" "", ""bar""));
        assertTrue(StringUtils.isNoneBlank(""foo"", ""bar""));
    }
",non-flaky,5
156397,apache_commons-lang,StringUtilsEmptyBlankTest.testIsAllBlank,"    @Test
    public void testIsAllBlank() {
        assertTrue(StringUtils.isAllBlank((String) null));
        assertTrue(StringUtils.isAllBlank((String[]) null));
        assertTrue(StringUtils.isAllBlank(null, null));
        assertTrue(StringUtils.isAllBlank(null, "" ""));
        assertFalse(StringUtils.isAllBlank(null, ""foo""));
        assertFalse(StringUtils.isAllBlank("""", ""bar""));
        assertFalse(StringUtils.isAllBlank(""bob"", """"));
        assertFalse(StringUtils.isAllBlank(""  bob  "", null));
        assertFalse(StringUtils.isAllBlank("" "", ""bar""));
        assertFalse(StringUtils.isAllBlank(""foo"", ""bar""));
    }
",non-flaky,5
156398,apache_commons-lang,StringUtilsEmptyBlankTest.testFirstNonBlank,"    @Test
    public void testFirstNonBlank() {
        assertNull(StringUtils.firstNonBlank());
        assertNull(StringUtils.firstNonBlank((String[]) null));
        assertNull(StringUtils.firstNonBlank(null, null, null));
        assertNull(StringUtils.firstNonBlank(null, """", "" ""));
        assertNull(StringUtils.firstNonBlank(null, null, "" ""));
        assertEquals(""zz"", StringUtils.firstNonBlank(null, ""zz""));
        assertEquals(""abc"", StringUtils.firstNonBlank(""abc""));
        assertEquals(""xyz"", StringUtils.firstNonBlank(null, ""xyz""));
        assertEquals(""xyz"", StringUtils.firstNonBlank(null, ""xyz"", ""abc""));
    }
",non-flaky,5
156399,apache_commons-lang,StringUtilsEmptyBlankTest.testFirstNonEmpty,"    @Test
    public void testFirstNonEmpty() {
        assertNull(StringUtils.firstNonEmpty());
        assertNull(StringUtils.firstNonEmpty((String[]) null));
        assertNull(StringUtils.firstNonEmpty(null, null, null));
        assertEquals("" "", StringUtils.firstNonEmpty(null, """", "" ""));
        assertNull(StringUtils.firstNonEmpty(null, null, """"));
        assertEquals(""zz"", StringUtils.firstNonEmpty(null, ""zz""));
        assertEquals(""abc"", StringUtils.firstNonEmpty(""abc""));
        assertEquals(""xyz"", StringUtils.firstNonEmpty(null, ""xyz""));
        assertEquals(""xyz"", StringUtils.firstNonEmpty(null, ""xyz"", ""abc""));
    }
",non-flaky,5
156400,apache_commons-lang,FastDateFormatTest.test_getInstance,"    @Test
    public void test_getInstance() {
        final FastDateFormat format1 = FastDateFormat.getInstance();
        final FastDateFormat format2 = FastDateFormat.getInstance();
        assertSame(format1, format2);
    }
",non-flaky,5
156401,apache_commons-lang,FastDateFormatTest.test_getInstance_String,"    @Test
    public void test_getInstance_String() {
        final FastDateFormat format1 = FastDateFormat.getInstance(""MM/DD/yyyy"");
        final FastDateFormat format2 = FastDateFormat.getInstance(""MM-DD-yyyy"");
        final FastDateFormat format3 = FastDateFormat.getInstance(""MM-DD-yyyy"");

        assertNotSame(format1, format2);
        assertSame(format2, format3);
        assertEquals(""MM/DD/yyyy"", format1.getPattern());
        assertEquals(TimeZone.getDefault(), format1.getTimeZone());
        assertEquals(TimeZone.getDefault(), format2.getTimeZone());
    }
",non-flaky,5
156402,apache_commons-lang,FastDateFormatTest.test_getInstance_String_TimeZone,"    @Test
    public void test_getInstance_String_TimeZone() {

        final FastDateFormat format1 = FastDateFormat.getInstance(""MM/DD/yyyy"",
                TimeZone.getTimeZone(""Atlantic/Reykjavik""));
        final FastDateFormat format2 = FastDateFormat.getInstance(""MM/DD/yyyy"");
        final FastDateFormat format3 = FastDateFormat.getInstance(""MM/DD/yyyy"", TimeZone.getDefault());
        final FastDateFormat format4 = FastDateFormat.getInstance(""MM/DD/yyyy"", TimeZone.getDefault());
        final FastDateFormat format5 = FastDateFormat.getInstance(""MM-DD-yyyy"", TimeZone.getDefault());
        final FastDateFormat format6 = FastDateFormat.getInstance(""MM-DD-yyyy"");

        assertNotSame(format1, format2);
        assertEquals(TimeZone.getTimeZone(""Atlantic/Reykjavik""), format1.getTimeZone());
        assertEquals(TimeZone.getDefault(), format2.getTimeZone());
        assertSame(format3, format4);
        assertNotSame(format3, format5);
        assertNotSame(format4, format6);
    }
",non-flaky,5
156403,apache_commons-lang,FastDateFormatTest.test_getInstance_String_Locale,"    @Test
    public void test_getInstance_String_Locale() {
        final FastDateFormat format1 = FastDateFormat.getInstance(""MM/DD/yyyy"", Locale.GERMANY);
        final FastDateFormat format2 = FastDateFormat.getInstance(""MM/DD/yyyy"");
        final FastDateFormat format3 = FastDateFormat.getInstance(""MM/DD/yyyy"", Locale.GERMANY);

        assertNotSame(format1, format2);
        assertSame(format1, format3);
        assertEquals(Locale.GERMANY, format1.getLocale());
    }
",non-flaky,5
156404,apache_commons-lang,FastDateFormatTest.test_changeDefault_Locale_DateInstance,"    @Test
    public void test_changeDefault_Locale_DateInstance() {
        final FastDateFormat format1 = FastDateFormat.getDateInstance(FastDateFormat.FULL, Locale.GERMANY);
        final FastDateFormat format2 = FastDateFormat.getDateInstance(FastDateFormat.FULL);
        Locale.setDefault(Locale.GERMANY);
        final FastDateFormat format3 = FastDateFormat.getDateInstance(FastDateFormat.FULL);

        assertSame(Locale.GERMANY, format1.getLocale());
        assertEquals(Locale.US, format2.getLocale());
        assertSame(Locale.GERMANY, format3.getLocale());
        assertNotSame(format1, format2);
        assertNotSame(format2, format3);
    }
",non-flaky,5
156405,apache_commons-lang,FastDateFormatTest.test_changeDefault_Locale_DateTimeInstance,"    @Test
    public void test_changeDefault_Locale_DateTimeInstance() {
        final FastDateFormat format1 = FastDateFormat.getDateTimeInstance(FastDateFormat.FULL, FastDateFormat.FULL, Locale.GERMANY);
        final FastDateFormat format2 = FastDateFormat.getDateTimeInstance(FastDateFormat.FULL, FastDateFormat.FULL);
        Locale.setDefault(Locale.GERMANY);
        final FastDateFormat format3 = FastDateFormat.getDateTimeInstance(FastDateFormat.FULL, FastDateFormat.FULL);

        assertSame(Locale.GERMANY, format1.getLocale());
        assertEquals(Locale.US, format2.getLocale());
        assertSame(Locale.GERMANY, format3.getLocale());
        assertNotSame(format1, format2);
        assertNotSame(format2, format3);
    }
",non-flaky,5
156406,apache_commons-lang,FastDateFormatTest.test_getInstance_String_TimeZone_Locale,"    @Test
    public void test_getInstance_String_TimeZone_Locale() {
        final FastDateFormat format1 = FastDateFormat.getInstance(""MM/DD/yyyy"",
                TimeZone.getTimeZone(""Atlantic/Reykjavik""), Locale.GERMANY);
        final FastDateFormat format2 = FastDateFormat.getInstance(""MM/DD/yyyy"", Locale.GERMANY);
        final FastDateFormat format3 = FastDateFormat.getInstance(""MM/DD/yyyy"",
                TimeZone.getDefault(), Locale.GERMANY);

        assertNotSame(format1, format2);
        assertEquals(TimeZone.getTimeZone(""Atlantic/Reykjavik""), format1.getTimeZone());
        assertEquals(TimeZone.getDefault(), format2.getTimeZone());
        assertEquals(TimeZone.getDefault(), format3.getTimeZone());
        assertEquals(Locale.GERMANY, format1.getLocale());
        assertEquals(Locale.GERMANY, format2.getLocale());
        assertEquals(Locale.GERMANY, format3.getLocale());
    }
",non-flaky,5
156407,apache_commons-lang,FastDateFormatTest.testCheckDefaults,"    @Test
    public void testCheckDefaults() {
        final FastDateFormat format = FastDateFormat.getInstance();
        final FastDateFormat medium = FastDateFormat.getDateTimeInstance(FastDateFormat.SHORT, FastDateFormat.SHORT);
        assertEquals(medium, format);

        final SimpleDateFormat sdf = new SimpleDateFormat();
        assertEquals(sdf.toPattern(), format.getPattern());

        assertEquals(Locale.getDefault(), format.getLocale());
        assertEquals(TimeZone.getDefault(), format.getTimeZone());
    }
",non-flaky,5
156408,apache_commons-lang,FastDateFormatTest.testCheckDifferingStyles,"    @Test
    public void testCheckDifferingStyles() {
        final FastDateFormat shortShort = FastDateFormat.getDateTimeInstance(FastDateFormat.SHORT, FastDateFormat.SHORT, Locale.US);
        final FastDateFormat shortLong = FastDateFormat.getDateTimeInstance(FastDateFormat.SHORT, FastDateFormat.LONG, Locale.US);
        final FastDateFormat longShort = FastDateFormat.getDateTimeInstance(FastDateFormat.LONG, FastDateFormat.SHORT, Locale.US);
        final FastDateFormat longLong = FastDateFormat.getDateTimeInstance(FastDateFormat.LONG, FastDateFormat.LONG, Locale.US);

        assertNotEquals(shortShort, shortLong);
        assertNotEquals(shortShort, longShort);
        assertNotEquals(shortShort, longLong);
        assertNotEquals(shortLong, longShort);
        assertNotEquals(shortLong, longLong);
        assertNotEquals(longShort, longLong);
    }
",non-flaky,5
156409,apache_commons-lang,FastDateFormatTest.testDateDefaults,"    @Test
    public void testDateDefaults() {
        assertEquals(FastDateFormat.getDateInstance(FastDateFormat.LONG, Locale.CANADA),
                FastDateFormat.getDateInstance(FastDateFormat.LONG, TimeZone.getDefault(), Locale.CANADA));

        assertEquals(FastDateFormat.getDateInstance(FastDateFormat.LONG, TimeZone.getTimeZone(""America/New_York"")),
                FastDateFormat.getDateInstance(FastDateFormat.LONG, TimeZone.getTimeZone(""America/New_York""), Locale.getDefault()));

        assertEquals(FastDateFormat.getDateInstance(FastDateFormat.LONG),
                FastDateFormat.getDateInstance(FastDateFormat.LONG, TimeZone.getDefault(), Locale.getDefault()));
    }
",non-flaky,5
156410,apache_commons-lang,FastDateFormatTest.testTimeDefaults,"    @Test
    public void testTimeDefaults() {
        assertEquals(FastDateFormat.getTimeInstance(FastDateFormat.LONG, Locale.CANADA),
                FastDateFormat.getTimeInstance(FastDateFormat.LONG, TimeZone.getDefault(), Locale.CANADA));

        assertEquals(FastDateFormat.getTimeInstance(FastDateFormat.LONG, TimeZone.getTimeZone(""America/New_York"")),
                FastDateFormat.getTimeInstance(FastDateFormat.LONG, TimeZone.getTimeZone(""America/New_York""), Locale.getDefault()));

        assertEquals(FastDateFormat.getTimeInstance(FastDateFormat.LONG),
                FastDateFormat.getTimeInstance(FastDateFormat.LONG, TimeZone.getDefault(), Locale.getDefault()));
    }
",non-flaky,5
156411,apache_commons-lang,FastDateFormatTest.testTimeDateDefaults,"    @Test
    public void testTimeDateDefaults() {
        assertEquals(FastDateFormat.getDateTimeInstance(FastDateFormat.LONG, FastDateFormat.MEDIUM, Locale.CANADA),
                FastDateFormat.getDateTimeInstance(FastDateFormat.LONG, FastDateFormat.MEDIUM, TimeZone.getDefault(), Locale.CANADA));

        assertEquals(FastDateFormat.getDateTimeInstance(FastDateFormat.LONG, FastDateFormat.MEDIUM, TimeZone.getTimeZone(""America/New_York"")),
                FastDateFormat.getDateTimeInstance(FastDateFormat.LONG, FastDateFormat.MEDIUM, TimeZone.getTimeZone(""America/New_York""), Locale.getDefault()));

        assertEquals(FastDateFormat.getDateTimeInstance(FastDateFormat.LONG, FastDateFormat.MEDIUM),
                FastDateFormat.getDateTimeInstance(FastDateFormat.LONG, FastDateFormat.MEDIUM, TimeZone.getDefault(), Locale.getDefault()));
    }
",non-flaky,5
156412,apache_commons-lang,FastDateFormatTest.format,"    @Test
    public void testParseSync() throws InterruptedException {
        final String pattern = ""yyyy-MM-dd'T'HH:mm:ss.SSS"";
        final SimpleDateFormat inner = new SimpleDateFormat(pattern);
        final Format sdf= new Format() {
            private static final long serialVersionUID = 1L;

            @Override
            public StringBuffer format(final Object obj,
                    final StringBuffer toAppendTo,
",non-flaky,5
156413,apache_commons-lang,FastDateFormatTest.testLANG_954,"    @Test
    public void testLANG_954() {
        final String pattern = ""yyyy-MM-dd'T'"";
        FastDateFormat.getInstance(pattern);
    }
",non-flaky,5
156414,apache_commons-lang,FastDateFormatTest.testLANG_1152,"    @Test
    public void testLANG_1152() {
        final TimeZone utc = FastTimeZone.getGmtTimeZone();
        final Date date = new Date(Long.MAX_VALUE);

        String dateAsString = FastDateFormat.getInstance(""yyyy-MM-dd"", utc, Locale.US).format(date);
        assertEquals(""292278994-08-17"", dateAsString);

        dateAsString = FastDateFormat.getInstance(""dd/MM/yyyy"", utc, Locale.US).format(date);
        assertEquals(""17/08/292278994"", dateAsString);
    }
",non-flaky,5
156415,apache_commons-lang,FastDateFormatTest.testLANG_1267,"    @Test
    public void testLANG_1267() {
        FastDateFormat.getInstance(""yyyy-MM-dd'T'HH:mm:ss.SSSXXX"");
    }
",non-flaky,5
156416,apache_commons-lang,GmtTimeZoneTest.hoursOutOfRange,"    @Test
    public void hoursOutOfRange() {
        assertThrows(IllegalArgumentException.class, () -> new GmtTimeZone(false, 24, 0));
    }
",non-flaky,5
156417,apache_commons-lang,GmtTimeZoneTest.hoursInRange,"    @Test
    public void hoursInRange() {
        assertEquals(23 * 60 * 60 * 1000, new GmtTimeZone(false, 23, 0).getRawOffset());
    }
",non-flaky,5
156418,apache_commons-lang,GmtTimeZoneTest.minutesOutOfRange,"    @Test
    public void minutesOutOfRange() {
        assertThrows(IllegalArgumentException.class, () -> new GmtTimeZone(false, 0, 60));
    }
",non-flaky,5
156419,apache_commons-lang,GmtTimeZoneTest.minutesInRange,"    @Test
    public void minutesInRange() {
        assertEquals(59 * 60 * 1000, new GmtTimeZone(false, 0, 59).getRawOffset());
    }
",non-flaky,5
156420,apache_commons-lang,GmtTimeZoneTest.getOffset,"    @Test
    public void getOffset() {
        assertEquals(0, new GmtTimeZone(false, 0, 0).getOffset(234304));
    }
",non-flaky,5
156421,apache_commons-lang,GmtTimeZoneTest.setRawOffset,"    @Test
    public void setRawOffset() {
        assertThrows(UnsupportedOperationException.class, () -> new GmtTimeZone(false, 0, 0).setRawOffset(0));
    }
",non-flaky,5
156422,apache_commons-lang,GmtTimeZoneTest.getRawOffset,"    @Test
    public void getRawOffset() {
        assertEquals(0, new GmtTimeZone(false, 0, 0).getRawOffset());
    }
",non-flaky,5
156423,apache_commons-lang,GmtTimeZoneTest.getID,"    @Test
    public void getID() {
        assertEquals(""GMT+00:00"", new GmtTimeZone(false, 0, 0).getID());
        assertEquals(""GMT+01:02"", new GmtTimeZone(false, 1, 2).getID());
        assertEquals(""GMT+11:22"", new GmtTimeZone(false, 11, 22).getID());
        assertEquals(""GMT-01:02"", new GmtTimeZone(true, 1, 2).getID());
        assertEquals(""GMT-11:22"", new GmtTimeZone(true, 11, 22).getID());
    }
",non-flaky,5
156424,apache_commons-lang,GmtTimeZoneTest.useDaylightTime,"    @Test
    public void useDaylightTime() {
        assertFalse(new GmtTimeZone(false, 0, 0).useDaylightTime());
    }
",non-flaky,5
156425,apache_commons-lang,GmtTimeZoneTest.inDaylightTime,"    @Test
    public void inDaylightTime() {
        assertFalse(new GmtTimeZone(false, 0, 0).useDaylightTime());
    }
",non-flaky,5
156426,apache_commons-lang,GmtTimeZoneTest.testToString,"    @Test
    public void testToString() {
        assertEquals(""[GmtTimeZone id=\""GMT-12:00\"",offset=-43200000]"",
            new GmtTimeZone(true, 12, 0).toString());
    }
",non-flaky,5
156427,apache_commons-lang,GmtTimeZoneTest.testGetOffset,"    @Test
    public void testGetOffset() {
        assertEquals(-(6 * 60 + 30) * 60 * 1000,
            new GmtTimeZone(true, 6, 30).getOffset(1, 1, 1, 1, 1, 1));
    }
",non-flaky,5
156428,apache_commons-lang,DateUtilsFragmentTest.setUp,"    @BeforeEach
    public void setUp() {
        aCalendar = Calendar.getInstance();
        aCalendar.set(2005, months, days, hours, minutes, seconds);
        aCalendar.set(Calendar.MILLISECOND, millis);
        aDate = aCalendar.getTime();
    }
",non-flaky,5
156429,apache_commons-lang,DateUtilsFragmentTest.testNullDate,"    @Test
    public void testNullDate() {
        assertThrows(
                IllegalArgumentException.class,
                () -> DateUtils.getFragmentInMilliseconds((Date) null, Calendar.MILLISECOND));

        assertThrows(
                IllegalArgumentException.class,
                () -> DateUtils.getFragmentInSeconds((Date) null, Calendar.MILLISECOND));

        assertThrows(
                IllegalArgumentException.class,
                () -> DateUtils.getFragmentInMinutes((Date) null, Calendar.MILLISECOND));

        assertThrows(
                IllegalArgumentException.class,
                () -> DateUtils.getFragmentInHours((Date) null, Calendar.MILLISECOND));

        assertThrows(
                IllegalArgumentException.class,
                () -> DateUtils.getFragmentInDays((Date) null, Calendar.MILLISECOND));
    }
",non-flaky,5
156430,apache_commons-lang,DateUtilsFragmentTest.testNullCalendar,"    @Test
    public void testNullCalendar() {
        assertThrows(
                IllegalArgumentException.class,
                () -> DateUtils.getFragmentInMilliseconds((Calendar) null, Calendar.MILLISECOND));

        assertThrows(
                IllegalArgumentException.class,
                () -> DateUtils.getFragmentInSeconds((Calendar) null, Calendar.MILLISECOND));

        assertThrows(
                IllegalArgumentException.class,
                () -> DateUtils.getFragmentInMinutes((Calendar) null, Calendar.MILLISECOND));

        assertThrows(
                IllegalArgumentException.class,
                () -> DateUtils.getFragmentInHours((Calendar) null, Calendar.MILLISECOND));

        assertThrows(
                IllegalArgumentException.class,
                () -> DateUtils.getFragmentInDays((Calendar) null, Calendar.MILLISECOND));
    }
",non-flaky,5
156431,apache_commons-lang,DateUtilsFragmentTest.testInvalidFragmentWithDate,"    @Test
    public void testInvalidFragmentWithDate() {
        assertThrows(IllegalArgumentException.class, () -> DateUtils.getFragmentInMilliseconds(aDate, 0));
        assertThrows(IllegalArgumentException.class, () -> DateUtils.getFragmentInSeconds(aDate, 0));
        assertThrows(IllegalArgumentException.class, () -> DateUtils.getFragmentInMinutes(aDate, 0));
        assertThrows(IllegalArgumentException.class, () -> DateUtils.getFragmentInHours(aDate, 0));
        assertThrows(IllegalArgumentException.class, () -> DateUtils.getFragmentInDays(aDate, 0));
    }
",non-flaky,5
156432,apache_commons-lang,DateUtilsFragmentTest.testInvalidFragmentWithCalendar,"    @Test
    public void testInvalidFragmentWithCalendar() {
        assertThrows(IllegalArgumentException.class, () -> DateUtils.getFragmentInMilliseconds(aCalendar, 0));
        assertThrows(IllegalArgumentException.class, () -> DateUtils.getFragmentInSeconds(aCalendar, 0));
        assertThrows(IllegalArgumentException.class, () -> DateUtils.getFragmentInMinutes(aCalendar, 0));
        assertThrows(IllegalArgumentException.class, () -> DateUtils.getFragmentInHours(aCalendar, 0));
        assertThrows(IllegalArgumentException.class, () -> DateUtils.getFragmentInDays(aCalendar, 0));
    }
",non-flaky,5
156433,apache_commons-lang,DateUtilsFragmentTest.testMillisecondFragmentInLargerUnitWithDate,"    @Test
    public void testMillisecondFragmentInLargerUnitWithDate() {
        assertEquals(0, DateUtils.getFragmentInMilliseconds(aDate, Calendar.MILLISECOND));
        assertEquals(0, DateUtils.getFragmentInSeconds(aDate, Calendar.MILLISECOND));
        assertEquals(0, DateUtils.getFragmentInMinutes(aDate, Calendar.MILLISECOND));
        assertEquals(0, DateUtils.getFragmentInHours(aDate, Calendar.MILLISECOND));
        assertEquals(0, DateUtils.getFragmentInDays(aDate, Calendar.MILLISECOND));
    }
",non-flaky,5
156434,apache_commons-lang,DateUtilsFragmentTest.testMillisecondFragmentInLargerUnitWithCalendar,"    @Test
    public void testMillisecondFragmentInLargerUnitWithCalendar() {
        assertEquals(0, DateUtils.getFragmentInMilliseconds(aCalendar, Calendar.MILLISECOND));
        assertEquals(0, DateUtils.getFragmentInSeconds(aCalendar, Calendar.MILLISECOND));
        assertEquals(0, DateUtils.getFragmentInMinutes(aCalendar, Calendar.MILLISECOND));
        assertEquals(0, DateUtils.getFragmentInHours(aCalendar, Calendar.MILLISECOND));
        assertEquals(0, DateUtils.getFragmentInDays(aCalendar, Calendar.MILLISECOND));
    }
",non-flaky,5
156435,apache_commons-lang,DateUtilsFragmentTest.testSecondFragmentInLargerUnitWithDate,"    @Test
    public void testSecondFragmentInLargerUnitWithDate() {
        assertEquals(0, DateUtils.getFragmentInSeconds(aDate, Calendar.SECOND));
        assertEquals(0, DateUtils.getFragmentInMinutes(aDate, Calendar.SECOND));
        assertEquals(0, DateUtils.getFragmentInHours(aDate, Calendar.SECOND));
        assertEquals(0, DateUtils.getFragmentInDays(aDate, Calendar.SECOND));
    }
",non-flaky,5
156436,apache_commons-lang,DateUtilsFragmentTest.testSecondFragmentInLargerUnitWithCalendar,"    @Test
    public void testSecondFragmentInLargerUnitWithCalendar() {
        assertEquals(0, DateUtils.getFragmentInSeconds(aCalendar, Calendar.SECOND));
        assertEquals(0, DateUtils.getFragmentInMinutes(aCalendar, Calendar.SECOND));
        assertEquals(0, DateUtils.getFragmentInHours(aCalendar, Calendar.SECOND));
        assertEquals(0, DateUtils.getFragmentInDays(aCalendar, Calendar.SECOND));
    }
",non-flaky,5
156437,apache_commons-lang,DateUtilsFragmentTest.testMinuteFragmentInLargerUnitWithDate,"    @Test
    public void testMinuteFragmentInLargerUnitWithDate() {
        assertEquals(0, DateUtils.getFragmentInMinutes(aDate, Calendar.MINUTE));
        assertEquals(0, DateUtils.getFragmentInHours(aDate, Calendar.MINUTE));
        assertEquals(0, DateUtils.getFragmentInDays(aDate, Calendar.MINUTE));
    }
",non-flaky,5
156438,apache_commons-lang,DateUtilsFragmentTest.testMinuteFragmentInLargerUnitWithCalendar,"    @Test
    public void testMinuteFragmentInLargerUnitWithCalendar() {
        assertEquals(0, DateUtils.getFragmentInMinutes(aCalendar, Calendar.MINUTE));
        assertEquals(0, DateUtils.getFragmentInHours(aCalendar, Calendar.MINUTE));
        assertEquals(0, DateUtils.getFragmentInDays(aCalendar, Calendar.MINUTE));
    }
",non-flaky,5
156439,apache_commons-lang,DateUtilsFragmentTest.testHourOfDayFragmentInLargerUnitWithDate,"    @Test
    public void testHourOfDayFragmentInLargerUnitWithDate() {
        assertEquals(0, DateUtils.getFragmentInHours(aDate, Calendar.HOUR_OF_DAY));
        assertEquals(0, DateUtils.getFragmentInDays(aDate, Calendar.HOUR_OF_DAY));
    }
",non-flaky,5
156440,apache_commons-lang,DateUtilsFragmentTest.testHourOfDayFragmentInLargerUnitWithCalendar,"    @Test
    public void testHourOfDayFragmentInLargerUnitWithCalendar() {
        assertEquals(0, DateUtils.getFragmentInHours(aCalendar, Calendar.HOUR_OF_DAY));
        assertEquals(0, DateUtils.getFragmentInDays(aCalendar, Calendar.HOUR_OF_DAY));
    }
",non-flaky,5
156441,apache_commons-lang,DateUtilsFragmentTest.testDayOfYearFragmentInLargerUnitWithDate,"    @Test
    public void testDayOfYearFragmentInLargerUnitWithDate() {
        assertEquals(0, DateUtils.getFragmentInDays(aDate, Calendar.DAY_OF_YEAR));
    }
",non-flaky,5
156442,apache_commons-lang,DateUtilsFragmentTest.testDayOfYearFragmentInLargerUnitWithCalendar,"    @Test
    public void testDayOfYearFragmentInLargerUnitWithCalendar() {
        assertEquals(0, DateUtils.getFragmentInDays(aCalendar, Calendar.DAY_OF_YEAR));
    }
",non-flaky,5
156443,apache_commons-lang,DateUtilsFragmentTest.testDateFragmentInLargerUnitWithDate,"    @Test
    public void testDateFragmentInLargerUnitWithDate() {
        assertEquals(0, DateUtils.getFragmentInDays(aDate, Calendar.DATE));
    }
",non-flaky,5
156444,apache_commons-lang,DateUtilsFragmentTest.testDateFragmentInLargerUnitWithCalendar,"    @Test
    public void testDateFragmentInLargerUnitWithCalendar() {
        assertEquals(0, DateUtils.getFragmentInDays(aCalendar, Calendar.DATE));
    }
",non-flaky,5
156445,apache_commons-lang,DateUtilsFragmentTest.testMillisecondsOfSecondWithDate,"    @Test
    public void testMillisecondsOfSecondWithDate() {
        final long testResult = DateUtils.getFragmentInMilliseconds(aDate, Calendar.SECOND);
        assertEquals(millis, testResult);
    }
",non-flaky,5
156446,apache_commons-lang,DateUtilsFragmentTest.testMillisecondsOfSecondWithCalendar,"    @Test
    public void testMillisecondsOfSecondWithCalendar() {
        final long testResult = DateUtils.getFragmentInMilliseconds(aCalendar, Calendar.SECOND);
        assertEquals(millis, testResult);
        assertEquals(aCalendar.get(Calendar.MILLISECOND), testResult);
    }
",non-flaky,5
156447,apache_commons-lang,DateUtilsFragmentTest.testMillisecondsOfMinuteWithDate,"    @Test
    public void testMillisecondsOfMinuteWithDate() {
        final long testResult = DateUtils.getFragmentInMilliseconds(aDate, Calendar.MINUTE);
        assertEquals(millis + (seconds * DateUtils.MILLIS_PER_SECOND), testResult);
    }
",non-flaky,5
156448,apache_commons-lang,DateUtilsFragmentTest.testMillisecondsOfMinuteWithCalender,"    @Test
    public void testMillisecondsOfMinuteWithCalender() {
        final long testResult = DateUtils.getFragmentInMilliseconds(aCalendar, Calendar.MINUTE);
        assertEquals(millis + (seconds * DateUtils.MILLIS_PER_SECOND), testResult);
    }
",non-flaky,5
156449,apache_commons-lang,DateUtilsFragmentTest.testSecondsofMinuteWithDate,"    @Test
    public void testSecondsofMinuteWithDate() {
        final long testResult = DateUtils.getFragmentInSeconds(aDate, Calendar.MINUTE);
        assertEquals(seconds, testResult);
    }
",non-flaky,5
156450,apache_commons-lang,DateUtilsFragmentTest.testSecondsofMinuteWithCalendar,"    @Test
    public void testSecondsofMinuteWithCalendar() {
        final long testResult = DateUtils.getFragmentInSeconds(aCalendar, Calendar.MINUTE);
        assertEquals(seconds, testResult);
        assertEquals(aCalendar.get(Calendar.SECOND), testResult);
    }
",non-flaky,5
156451,apache_commons-lang,DateUtilsFragmentTest.testMillisecondsOfHourWithDate,"    @Test
    public void testMillisecondsOfHourWithDate() {
        final long testResult = DateUtils.getFragmentInMilliseconds(aDate, Calendar.HOUR_OF_DAY);
        assertEquals(millis + (seconds * DateUtils.MILLIS_PER_SECOND) + (minutes * DateUtils.MILLIS_PER_MINUTE), testResult);
    }
",non-flaky,5
156452,apache_commons-lang,DateUtilsFragmentTest.testMillisecondsOfHourWithCalendar,"    @Test
    public void testMillisecondsOfHourWithCalendar() {
        final long testResult = DateUtils.getFragmentInMilliseconds(aCalendar, Calendar.HOUR_OF_DAY);
        assertEquals(millis + (seconds * DateUtils.MILLIS_PER_SECOND) + (minutes * DateUtils.MILLIS_PER_MINUTE), testResult);
    }
",non-flaky,5
156453,apache_commons-lang,DateUtilsFragmentTest.testSecondsofHourWithDate,"    @Test
    public void testSecondsofHourWithDate() {
        final long testResult = DateUtils.getFragmentInSeconds(aDate, Calendar.HOUR_OF_DAY);
        assertEquals(
                seconds
                        + (minutes
                                * DateUtils.MILLIS_PER_MINUTE / DateUtils.MILLIS_PER_SECOND),
                testResult);
    }
",non-flaky,5
156454,apache_commons-lang,DateUtilsFragmentTest.testSecondsofHourWithCalendar,"    @Test
    public void testSecondsofHourWithCalendar() {
        final long testResult = DateUtils.getFragmentInSeconds(aCalendar, Calendar.HOUR_OF_DAY);
        assertEquals(
                seconds
                        + (minutes
                                * DateUtils.MILLIS_PER_MINUTE / DateUtils.MILLIS_PER_SECOND),
                testResult);
    }
",non-flaky,5
156455,apache_commons-lang,DateUtilsFragmentTest.testMinutesOfHourWithDate,"    @Test
    public void testMinutesOfHourWithDate() {
        final long testResult = DateUtils.getFragmentInMinutes(aDate, Calendar.HOUR_OF_DAY);
        assertEquals(minutes, testResult);
    }
",non-flaky,5
156456,apache_commons-lang,DateUtilsFragmentTest.testMinutesOfHourWithCalendar,"    @Test
    public void testMinutesOfHourWithCalendar() {
        final long testResult = DateUtils.getFragmentInMinutes(aCalendar, Calendar.HOUR_OF_DAY);
        assertEquals(minutes, testResult);
    }
",non-flaky,5
156457,apache_commons-lang,DateUtilsFragmentTest.testMillisecondsOfDayWithDate,"    @Test
    public void testMillisecondsOfDayWithDate() {
        long testresult = DateUtils.getFragmentInMilliseconds(aDate, Calendar.DATE);
        final long expectedValue = millis + (seconds * DateUtils.MILLIS_PER_SECOND) + (minutes * DateUtils.MILLIS_PER_MINUTE) + (hours * DateUtils.MILLIS_PER_HOUR);
        assertEquals(expectedValue, testresult);
        testresult = DateUtils.getFragmentInMilliseconds(aDate, Calendar.DAY_OF_YEAR);
        assertEquals(expectedValue, testresult);
    }
",non-flaky,5
156458,apache_commons-lang,DateUtilsFragmentTest.testMillisecondsOfDayWithCalendar,"    @Test
    public void testMillisecondsOfDayWithCalendar() {
        long testresult = DateUtils.getFragmentInMilliseconds(aCalendar, Calendar.DATE);
        final long expectedValue = millis + (seconds * DateUtils.MILLIS_PER_SECOND) + (minutes * DateUtils.MILLIS_PER_MINUTE) + (hours * DateUtils.MILLIS_PER_HOUR);
        assertEquals(expectedValue, testresult);
        testresult = DateUtils.getFragmentInMilliseconds(aCalendar, Calendar.DAY_OF_YEAR);
        assertEquals(expectedValue, testresult);
    }
",non-flaky,5
156459,apache_commons-lang,DateUtilsFragmentTest.testSecondsOfDayWithDate,"    @Test
    public void testSecondsOfDayWithDate() {
        long testresult = DateUtils.getFragmentInSeconds(aDate, Calendar.DATE);
        final long expectedValue = seconds + ((minutes * DateUtils.MILLIS_PER_MINUTE) + (hours * DateUtils.MILLIS_PER_HOUR))/ DateUtils.MILLIS_PER_SECOND;
        assertEquals(expectedValue, testresult);
        testresult = DateUtils.getFragmentInSeconds(aDate, Calendar.DAY_OF_YEAR);
        assertEquals(expectedValue, testresult);
    }
",non-flaky,5
156460,apache_commons-lang,DateUtilsFragmentTest.testSecondsOfDayWithCalendar,"    @Test
    public void testSecondsOfDayWithCalendar() {
        long testresult = DateUtils.getFragmentInSeconds(aCalendar, Calendar.DATE);
        final long expectedValue = seconds + ((minutes * DateUtils.MILLIS_PER_MINUTE) + (hours * DateUtils.MILLIS_PER_HOUR))/ DateUtils.MILLIS_PER_SECOND;
        assertEquals(expectedValue, testresult);
        testresult = DateUtils.getFragmentInSeconds(aCalendar, Calendar.DAY_OF_YEAR);
        assertEquals(expectedValue, testresult);
    }
",non-flaky,5
156461,apache_commons-lang,DateUtilsFragmentTest.testMinutesOfDayWithDate,"    @Test
    public void testMinutesOfDayWithDate() {
        long testResult = DateUtils.getFragmentInMinutes(aDate, Calendar.DATE);
        final long expectedValue = minutes + ((hours * DateUtils.MILLIS_PER_HOUR))/ DateUtils.MILLIS_PER_MINUTE;
        assertEquals(expectedValue, testResult);
        testResult = DateUtils.getFragmentInMinutes(aDate, Calendar.DAY_OF_YEAR);
        assertEquals(expectedValue, testResult);
    }
",non-flaky,5
156462,apache_commons-lang,DateUtilsFragmentTest.testMinutesOfDayWithCalendar,"    @Test
    public void testMinutesOfDayWithCalendar() {
        long testResult = DateUtils.getFragmentInMinutes(aCalendar, Calendar.DATE);
        final long expectedValue = minutes + ((hours * DateUtils.MILLIS_PER_HOUR))/ DateUtils.MILLIS_PER_MINUTE;
        assertEquals(expectedValue, testResult);
        testResult = DateUtils.getFragmentInMinutes(aCalendar, Calendar.DAY_OF_YEAR);
        assertEquals(expectedValue, testResult);
    }
",non-flaky,5
156463,apache_commons-lang,DateUtilsFragmentTest.testHoursOfDayWithDate,"    @Test
    public void testHoursOfDayWithDate() {
        long testResult = DateUtils.getFragmentInHours(aDate, Calendar.DATE);
        final long expectedValue = hours;
        assertEquals(expectedValue, testResult);
        testResult = DateUtils.getFragmentInHours(aDate, Calendar.DAY_OF_YEAR);
        assertEquals(expectedValue, testResult);
    }
",non-flaky,5
156464,apache_commons-lang,DateUtilsFragmentTest.testHoursOfDayWithCalendar,"    @Test
    public void testHoursOfDayWithCalendar() {
        long testResult = DateUtils.getFragmentInHours(aCalendar, Calendar.DATE);
        final long expectedValue = hours;
        assertEquals(expectedValue, testResult);
        testResult = DateUtils.getFragmentInHours(aCalendar, Calendar.DAY_OF_YEAR);
        assertEquals(expectedValue, testResult);
    }
",non-flaky,5
156465,apache_commons-lang,DateUtilsFragmentTest.testMillisecondsOfMonthWithDate,"    @Test
    public void testMillisecondsOfMonthWithDate() {
        final long testResult = DateUtils.getFragmentInMilliseconds(aDate, Calendar.MONTH);
        assertEquals(millis + (seconds * DateUtils.MILLIS_PER_SECOND) + (minutes * DateUtils.MILLIS_PER_MINUTE)
                                + (hours * DateUtils.MILLIS_PER_HOUR) + ((days - 1) * DateUtils.MILLIS_PER_DAY),
                testResult);
    }
",non-flaky,5
156466,apache_commons-lang,DateUtilsFragmentTest.testMillisecondsOfMonthWithCalendar,"    @Test
    public void testMillisecondsOfMonthWithCalendar() {
        final long testResult = DateUtils.getFragmentInMilliseconds(aCalendar, Calendar.MONTH);
        assertEquals(millis + (seconds * DateUtils.MILLIS_PER_SECOND) + (minutes * DateUtils.MILLIS_PER_MINUTE)
                + (hours * DateUtils.MILLIS_PER_HOUR) + ((days - 1) * DateUtils.MILLIS_PER_DAY),
testResult);
    }
",non-flaky,5
156467,apache_commons-lang,DateUtilsFragmentTest.testSecondsOfMonthWithDate,"    @Test
    public void testSecondsOfMonthWithDate() {
        final long testResult = DateUtils.getFragmentInSeconds(aDate, Calendar.MONTH);
        assertEquals(
                seconds
                        + ((minutes * DateUtils.MILLIS_PER_MINUTE)
                                + (hours * DateUtils.MILLIS_PER_HOUR) + ((days - 1) * DateUtils.MILLIS_PER_DAY))
                        / DateUtils.MILLIS_PER_SECOND,
                testResult);
    }
",non-flaky,5
156468,apache_commons-lang,DateUtilsFragmentTest.testSecondsOfMonthWithCalendar,"    @Test
    public void testSecondsOfMonthWithCalendar() {
        final long testResult = DateUtils.getFragmentInSeconds(aCalendar, Calendar.MONTH);
        assertEquals(
                seconds
                        + ((minutes * DateUtils.MILLIS_PER_MINUTE)
                                + (hours * DateUtils.MILLIS_PER_HOUR) + ((days - 1) * DateUtils.MILLIS_PER_DAY))
                        / DateUtils.MILLIS_PER_SECOND,
                testResult);
    }
",non-flaky,5
156469,apache_commons-lang,DateUtilsFragmentTest.testMinutesOfMonthWithDate,"    @Test
    public void testMinutesOfMonthWithDate() {
        final long testResult = DateUtils.getFragmentInMinutes(aDate, Calendar.MONTH);
        assertEquals(minutes
                                + ((hours * DateUtils.MILLIS_PER_HOUR) + ((days - 1) * DateUtils.MILLIS_PER_DAY))
                        / DateUtils.MILLIS_PER_MINUTE,
                testResult);
    }
",non-flaky,5
156470,apache_commons-lang,DateUtilsFragmentTest.testMinutesOfMonthWithCalendar,"    @Test
    public void testMinutesOfMonthWithCalendar() {
        final long testResult = DateUtils.getFragmentInMinutes(aCalendar, Calendar.MONTH);
        assertEquals( minutes  +((hours * DateUtils.MILLIS_PER_HOUR) + ((days - 1) * DateUtils.MILLIS_PER_DAY))
                        / DateUtils.MILLIS_PER_MINUTE,
                testResult);
    }
",non-flaky,5
156471,apache_commons-lang,DateUtilsFragmentTest.testHoursOfMonthWithDate,"    @Test
    public void testHoursOfMonthWithDate() {
        final long testResult = DateUtils.getFragmentInHours(aDate, Calendar.MONTH);
        assertEquals(hours + (((days - 1) * DateUtils.MILLIS_PER_DAY))
                        / DateUtils.MILLIS_PER_HOUR,
                testResult);
    }
",non-flaky,5
156472,apache_commons-lang,DateUtilsFragmentTest.testHoursOfMonthWithCalendar,"    @Test
    public void testHoursOfMonthWithCalendar() {
        final long testResult = DateUtils.getFragmentInHours(aCalendar, Calendar.MONTH);
        assertEquals( hours +(((days - 1) * DateUtils.MILLIS_PER_DAY))
                        / DateUtils.MILLIS_PER_HOUR,
                testResult);
    }
",non-flaky,5
156473,apache_commons-lang,DateUtilsFragmentTest.testMillisecondsOfYearWithDate,"    @Test
    public void testMillisecondsOfYearWithDate() {
        final long testResult = DateUtils.getFragmentInMilliseconds(aDate, Calendar.YEAR);
        final Calendar cal = Calendar.getInstance();
        cal.setTime(aDate);
        assertEquals(millis + (seconds * DateUtils.MILLIS_PER_SECOND) + (minutes * DateUtils.MILLIS_PER_MINUTE)
                                + (hours * DateUtils.MILLIS_PER_HOUR) + ((cal.get(Calendar.DAY_OF_YEAR) - 1)* DateUtils.MILLIS_PER_DAY),
                testResult);
    }
",non-flaky,5
156474,apache_commons-lang,DateUtilsFragmentTest.testMillisecondsOfYearWithCalendar,"    @Test
    public void testMillisecondsOfYearWithCalendar() {
        final long testResult = DateUtils.getFragmentInMilliseconds(aCalendar, Calendar.YEAR);
        assertEquals(millis + (seconds * DateUtils.MILLIS_PER_SECOND) + (minutes * DateUtils.MILLIS_PER_MINUTE)
                + (hours * DateUtils.MILLIS_PER_HOUR) + ((aCalendar.get(Calendar.DAY_OF_YEAR) - 1) * DateUtils.MILLIS_PER_DAY),
testResult);
    }
",non-flaky,5
176775,ctco_cukes,RunCukesRabbmitMQTest.name,"    @Test
    public void name() throws Exception {
        System.out.println(""aaaa"");
    }
",non-flaky,5
176776,ctco_cukes,SingletonObjectFactoryTests.shouldThrowExceptionWhenAlreadyUsed,"    @Test(expected = IllegalStateException.class)
    public void shouldThrowExceptionWhenAlreadyUsed() throws Exception {
        // simulate cucumber scenario start
        simulateCucumberScenarioStart();

        instance.addModule(binder -> {
        });
    }
",non-flaky,5
176777,ctco_cukes,SingletonObjectFactoryTests.shouldSupportScenarioScope,"    @Test
    public void shouldSupportScenarioScope() {
        simulateCucumberScenarioStart();

        final ScenarioScopedClass a = instance.getInstance(ScenarioScopedClass.class);
        a.value = 10;
        assertEquals(10, a.value);

        final ScenarioScopedClass b = instance.getInstance(ScenarioScopedClass.class);
        assertEquals(10, b.value);

        simulateCucumberScenarioStop();
        simulateCucumberScenarioStart();

        final ScenarioScopedClass c = instance.getInstance(ScenarioScopedClass.class);
        assertEquals(0, c.value);

        simulateCucumberScenarioStop();
    }
",non-flaky,5
176778,ctco_cukes,RandomGeneratorFacadeImplTest.byInvalidPattern,"    @Test(expected = CukesRuntimeException.class)
    public void byInvalidPattern() throws Exception {
        generator.byPattern(""b"");
    }
",non-flaky,5
176779,ctco_cukes,RandomGeneratorFacadeImplTest.byPattern1,"    @Test
    public void byPattern1() throws Exception {
        assertThat(generator.byPattern(""A""), ContainsPattern.matchesPattern(""[A-Z]""));
        assertThat(generator.byPattern(""a""), ContainsPattern.matchesPattern(""[a-z]""));
        assertThat(generator.byPattern(""0""), ContainsPattern.matchesPattern(""[0-9]""));

        assertThat(generator.byPattern(""0Aa""), ContainsPattern.matchesPattern(Pattern.compile(""[0-9][A-Z][a-z]"")));
    }
",non-flaky,5
176780,ctco_cukes,RandomGeneratorFacadeImplTest.withLength,"    @Test
    public void withLength() throws Exception {
        assertThat(generator.withLength(5), ContainsPattern.matchesPattern(Pattern.compile(""[A-Za-z0-9]{5}"")));
    }
",non-flaky,5
176781,ctco_cukes,BaseContextHandlerTest.shouldExtractNoGroupsInPattern,"    @Test
    public void shouldExtractNoGroupsInPattern() throws Exception {
        List<String> groups = capturer.extractGroups(""(hello)"");
        assertThat(groups, is(empty()));
    }
",non-flaky,5
176782,ctco_cukes,BaseContextHandlerTest.shouldExtractSingleGroupInPattern,"    @Test
    public void shouldExtractSingleGroupInPattern() throws Exception {
        List<String> groups = capturer.extractGroups(""{(hello)}"");
        assertThat(groups, contains(""hello""));
    }
",non-flaky,5
176783,ctco_cukes,BaseContextHandlerTest.shouldExtractTwoGroupsInPattern,"    @Test
    public void shouldExtractTwoGroupsInPattern() throws Exception {
        List<String> groups = capturer.extractGroups(""{(hello)}, {(world)}"");
        assertThat(groups, contains(""hello"", ""world""));
    }
",non-flaky,5
176784,ctco_cukes,BaseContextHandlerTest.shouldNotExtractGroupsInPatternWithSpacesInName,"    @Test
    public void shouldNotExtractGroupsInPatternWithSpacesInName() throws Exception {
        List<String> groups = capturer.extractGroups(""{(hello world)}"");
        assertThat(groups, is(empty()));
    }
",non-flaky,5
176785,ctco_cukes,BaseContextHandlerTest.shouldExtractGroupsInPatternWithUnderscoreInName,"    @Test
    public void shouldExtractGroupsInPatternWithUnderscoreInName() throws Exception {
        List<String> groups = capturer.extractGroups(""{(hello_world)}"");
        assertThat(groups, contains(""hello_world""));
    }
",non-flaky,5
176786,ctco_cukes,BaseContextHandlerTest.shouldExtractDotSeparatedName,"    @Test
    public void shouldExtractDotSeparatedName() throws Exception {
        List<String> groups = capturer.extractGroups(""{(hello.world)}"");
        assertThat(groups, contains(""hello.world""));
    }
",non-flaky,5
176787,ctco_cukes,ContextInflaterTest.testInflateGroups,"    @Test
    public void testInflateGroups() throws Exception {
        doReturn(Optional.of(""foo"")).when(world).get(""foo"");
        String value = inflater.inflateGroups(""{(foo)} bar"", Sets.newHashSet(""foo""));
        assertThat(value, equalTo(""foo bar""));
    }
",non-flaky,5
176788,ctco_cukes,ContextInflaterTest.testInflateGroups_emptyWorld,"    @Test
    public void testInflateGroups_emptyWorld() throws Exception {
        String value = inflater.inflateGroups(""{(foo)} bar"", Sets.newHashSet(""foo""));
        assertThat(value, equalTo(""{(foo)} bar""));
    }
",non-flaky,5
176789,ctco_cukes,ContextInflaterTest.testInflateGroups_multipleEmpty,"    @Test
    public void testInflateGroups_multipleEmpty() throws Exception {
        String value = inflater.inflateGroups(""{(foo)} {(bar)}"", Sets.newHashSet(""foo"", ""bar""));
        assertThat(value, equalTo(""{(foo)} {(bar)}""));
    }
",non-flaky,5
176790,ctco_cukes,ContextInflaterTest.testInflateGroups_halfEmpty,"    @Test
    public void testInflateGroups_halfEmpty() throws Exception {
        doReturn(Optional.of(""foo"")).when(world).get(""foo"");
        String value = inflater.inflateGroups(""{(foo)} {(bar)}"", Sets.newHashSet(""foo"", ""bar""));
        assertThat(value, equalTo(""foo {(bar)}""));
    }
",non-flaky,5
176791,ctco_cukes,ContextInflaterTest.testInflateGroups_withPlainText,"    @Test
    public void testInflateGroups_withPlainText() throws Exception {
        doReturn(Optional.of(""foo"")).when(world).get(""foo"");
        String value = inflater.inflateGroups(""my {(foo)} is very {(bar)} !"", Sets.newHashSet(""foo"", ""bar""));
        assertThat(value, equalTo(""my foo is very {(bar)} !""));
    }
",non-flaky,5
176792,ctco_cukes,ContextInflaterTest.testInflateGroups_multipleExist,"    @Test
    public void testInflateGroups_multipleExist() throws Exception {
        doReturn(Optional.of(""foo"")).when(world).get(""foo"");
        doReturn(Optional.of(""bar"")).when(world).get(""bar"");
        String value = inflater.inflateGroups(""{(foo)} {(bar)}"", Sets.newHashSet(""foo"", ""bar""));
        assertThat(value, equalTo(""foo bar""));
    }
",non-flaky,5
176793,ctco_cukes,ContextInflaterTest.testInflateGroups_multipleSameExist,"    @Test
    public void testInflateGroups_multipleSameExist() throws Exception {
        doReturn(Optional.of(""foo"")).when(world).get(""foo"");
        String value = inflater.inflateGroups(""{(foo)} {(foo)}"", Sets.newHashSet(""foo""));
        assertThat(value, equalTo(""foo foo""));
    }
",non-flaky,5
176794,ctco_cukes,ContextInflaterTest.testInflateGroups_multipleSameEmpty,"    @Test
    public void testInflateGroups_multipleSameEmpty() throws Exception {
        String value = inflater.inflateGroups(""{(foo)} {(foo)}"", Sets.newHashSet(""foo""));
        assertThat(value, equalTo(""{(foo)} {(foo)}""));
    }
",non-flaky,5
176795,ctco_cukes,ContextCapturerTest.shouldTransformPatternToValidRegex,"    @Test
    public void shouldTransformPatternToValidRegex() throws Exception {
        String regex = capturer.transformToRegex(""{(hello)} world"");
        assertThat(regex, equalTo(""(.*) world""));
    }
",non-flaky,5
176796,ctco_cukes,ContextCapturerTest.shouldTransformMultiplePatternToValidRegex,"    @Test
    public void shouldTransformMultiplePatternToValidRegex() throws Exception {
        String regex = capturer.transformToRegex(""{(hello)} {(world)}"");
        assertThat(regex, equalTo(""(.*) (.*)""));
    }
",non-flaky,5
176797,ctco_cukes,ContextCapturerTest.shouldCaptureValuesFromSimplePattern,"    @Test
    public void shouldCaptureValuesFromSimplePattern() throws Exception {
        capturer.captureValuesFromPattern(""(.*) world"", Lists.newArrayList(""hello""), ""Hi world"");
        verify(world).put(""hello"", ""Hi"");
    }
",non-flaky,5
176798,ctco_cukes,ContextCapturerTest.shouldCaptureValuesFromMinimalPattern,"    @Test
    public void shouldCaptureValuesFromMinimalPattern() throws Exception {
        capturer.captureValuesFromPattern(""(.*)"", Lists.newArrayList(""hello""), ""world"");
        verify(world).put(""hello"", ""world"");
    }
",non-flaky,5
176799,ctco_cukes,ContextCapturerTest.shouldNotInvokeCaptureValuesFromPatternIfNoGroupsFound,"    @Test
    public void shouldNotInvokeCaptureValuesFromPatternIfNoGroupsFound() throws Exception {
        capturer.capture(""hello"", ""world"");
        verify(capturer, never()).captureValuesFromPattern(anyString(), anyListOf(String.class), anyString());
    }
",non-flaky,5
176800,ctco_cukes,ContextCapturerTest.shouldInvokeCaptureValuesFromPatternIfAtLeastOneGroupFound,"    @Test
    public void shouldInvokeCaptureValuesFromPatternIfAtLeastOneGroupFound() throws Exception {
        capturer.capture(""{(hello)}"", ""world"");
        verify(capturer).captureValuesFromPattern(anyString(), anyListOf(String.class), anyString());
    }
",non-flaky,5
176801,ctco_cukes,ContextCapturerTest.shouldNotInvokeCaptureValuesFromPatternIfRegexDoesNotMatchValue,"    @Test
    public void shouldNotInvokeCaptureValuesFromPatternIfRegexDoesNotMatchValue() throws Exception {
        capturer.capture(""{(hello)} Riga"", ""hello world"");
        verify(capturer, never()).captureValuesFromPattern(anyString(), anyListOf(String.class), anyString());
    }
",non-flaky,5
176802,ctco_cukes,TemplatingEngineTest.testBody,"    @Test
    public void testBody() {
        String body = ""{\n"" +
            "" \""business\"": {\n"" +
            "" \""businessDirection\"": 1006415,\n"" +
            "" \""transactionType\"": 101759,\n"" +
            "" \""businessSegment\"": 1022645\n"" +
            "" },\n"" +
            "" \""contractName\"": \""@contractName\"",\n"" +
            "" \""underwritingYear\"": 2015,\n"" +
            "" \""businessAndParticipationType\"": 1001011,\n"" +
            "" \""agreementType\"": \""@agreementType\"",\n"" +
            "" \""fasClassification\"": \""@fasClassification\"",\n"" +
            "" \""accountingBasis\"": 100003,\n"" +
            "" \""underwritingObjectStatus\"": 1003797,\n"" +
            "" \""inceptionDate\"": \""2015-01-01T00:00:00.000+0000\"",\n"" +
            "" \""expirationDate\"": \""2015-12-31T00:00:00.000+0000\"",\n"" +
            "" \""contractCurrency\"": \""EUR\"",\n"" +
            "" \""profitCentre\"": @profitCentre,\n"" +
            "" \""involvedParties\"": [\n"" +
            "" {\n"" +
            "" \""partnerId\"": \""@partnerId_1\"",\n"" +
            "" \""partnerRole\"": @partnerRole\n"" +
            "" },\n"" +
            "" {\n"" +
            "" \""partnerId\"": @partnerId_2,\n"" +
            "" \""partnerRole\"": 2173\n"" +
            "" }\n"" +
            "" ]\n"" +
            ""}"";

        String processBody = TemplatingEngine.processBody(body);

        assertTrue(processBody.contains(""\""contractName\"": \""test1\""""));
        assertTrue(processBody.contains(""\""profitCentre\"": 24342""));
    }
",non-flaky,5
176803,ctco_cukes,HttpLoggingPluginTest.testOutputStream,"    @Test
    public void testOutputStream() throws UnsupportedEncodingException {
        when(world.get(LOGGING_REQUEST_INCLUDES, """")).thenReturn(""all"");

        RequestSpecification specification = RestAssured.given()
            .config(config.getConfig())
            .baseUri(""http://google.com"")
            .param(""q"", ""hi"");

        plugin.beforeRequest(specification);

        specification.get();

        String requestLog = testOut.toString(""UTF-8"");
        assertThat(requestLog, is(EXPECTED_RESULT));
    }
",non-flaky,5
176804,ctco_cukes,HttpAssertionFacadeImplTest.shouldNotInflateVarName,"    @Test
    public void shouldNotInflateVarName() throws Exception {
        String headerName = ""name"";
        HttpResponseFacade mock = mock(HttpResponseFacade.class);
        Response response = mock(Response.class);
        when(response.getHeader(anyString())).thenReturn(headerName);
        when(mock.response()).thenReturn(response);
        ((HttpAssertionFacadeImpl) facade).facade = mock;

        world.put(""id"", ""1"");
        facade.varAssignedFromHeader(""{(id)}"", headerName);
        Optional<String> value = world.get(""id"");
        assertThat(value, CustomMatchers.equalToOptional(headerName));
    }
",non-flaky,5
176805,ctco_cukes,HttpAssertionFacadeImplTest.shouldReturnBodyWhenEnabledWithMax,"    @Test
    public void shouldReturnBodyWhenEnabledWithMax() {
        String body = ""{\n"" +
            ""  \""error\"": \""not found\""\n"" +
            ""}"";

        HttpResponseFacade mock = mock(HttpResponseFacade.class);
        when(mock.response()).thenReturn(generateResponse(
            ""application/json"",
            404,
            body.getBytes()));

        ((HttpAssertionFacadeImpl) facade).facade = mock;
        world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true"");
        world.put(ASSERTS_STATUS_CODE_MAX_SIZE, ""100"");

        validateException(
            200,
            ""1 expectation failed.\n"" +
                ""Expected status code \""200\"" but was \""404\"" with body:\n"" +
                ""\""\""\""\n"" +
                body +
                ""\n\""\""\"".\n"");
    }
",non-flaky,5
176806,ctco_cukes,HttpAssertionFacadeImplTest.shouldReturnBodyWhenEnabledAndNoMax,"    @Test
    public void shouldReturnBodyWhenEnabledAndNoMax() {
        String body = ""{\n"" +
            ""  \""error\"": \""not found\""\n"" +
            ""}"";

        HttpResponseFacade mock = mock(HttpResponseFacade.class);
        when(mock.response()).thenReturn(generateResponse(
            ""application/json"",
            404,
            body.getBytes()));

        ((HttpAssertionFacadeImpl) facade).facade = mock;
        world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true"");

        validateException(
            200,
            ""1 expectation failed.\n"" +
                ""Expected status code \""200\"" but was \""404\"" with body:\n"" +
                ""\""\""\""\n"" +
                body +
                ""\n\""\""\"".\n"");
    }
",non-flaky,5
176807,ctco_cukes,HttpAssertionFacadeImplTest.shouldNotReturnBodyWhenDisabled,"    @Test
    public void shouldNotReturnBodyWhenDisabled() {
        String body = ""{\n"" +
            ""  \""error\"": \""not found\""\n"" +
            ""}"";

        HttpResponseFacade mock = mock(HttpResponseFacade.class);
        when(mock.response()).thenReturn(generateResponse(
            ""application/json"",
            404,
            body.getBytes()));

        ((HttpAssertionFacadeImpl) facade).facade = mock;
        world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""false"");
        world.put(ASSERTS_STATUS_CODE_MAX_SIZE, ""100"");

        validateException(
            200,
            ""1 expectation failed.\n"" +
                ""Expected status code \""200\"" but was \""404\"".\n"");
    }
",non-flaky,5
176808,ctco_cukes,HttpAssertionFacadeImplTest.shouldNotReturnBodyWhenEnabledButLongerThanMaxSize,"    @Test
    public void shouldNotReturnBodyWhenEnabledButLongerThanMaxSize() {
        String body = ""{\n"" +
            ""  \""error\"": \""not found\""\n"" +
            ""}"";

        HttpResponseFacade mock = mock(HttpResponseFacade.class);
        when(mock.response()).thenReturn(generateResponse(
            ""application/json"",
            404,
            body.getBytes()));

        ((HttpAssertionFacadeImpl) facade).facade = mock;
        world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true"");
        world.put(ASSERTS_STATUS_CODE_MAX_SIZE, ""5"");


        validateException(
            200,
            ""1 expectation failed.\n"" +
                ""Expected status code \""200\"" but was \""404\"" with body <exceeding max size to show>.\n"");
    }
",non-flaky,5
176809,ctco_cukes,HttpAssertionFacadeImplTest.shouldNotReturnBodyWhenEnabledButContentTypeOctet,"    @Test
    public void shouldNotReturnBodyWhenEnabledButContentTypeOctet() {
        byte[] body = RandomUtils.nextBytes(20);

        HttpResponseFacade mock = mock(HttpResponseFacade.class);
        when(mock.response()).thenReturn(generateResponse(
            ""application/octet-stream"",
            404,
            body));

        ((HttpAssertionFacadeImpl) facade).facade = mock;
        world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true"");
        world.put(ASSERTS_STATUS_CODE_MAX_SIZE, ""5000"");

        validateException(
            200,
            ""1 expectation failed.\n"" +
                ""Expected status code \""200\"" but was \""404\"" with body <binary>.\n"");
    }
",non-flaky,5
176810,ctco_cukes,EndsWithRegexpTest.matchesDirectMatch,"    @Test
    public void matchesDirectMatch() throws Exception {
        assertThat(""hello"", EndsWithRegexp.endsWithRegexp(""hello""));
    }
",non-flaky,5
176811,ctco_cukes,EndsWithRegexpTest.matchesEndWith,"    @Test
    public void matchesEndWith() throws Exception {
        assertThat(""hello world"", EndsWithRegexp.endsWithRegexp(""world""));
    }
",non-flaky,5
176812,ctco_cukes,EndsWithRegexpTest.matchesEndWithRegexp,"    @Test
    public void matchesEndWithRegexp() throws Exception {
        assertThat(""hello world"", EndsWithRegexp.endsWithRegexp(""el.*world""));
    }
",non-flaky,5
176813,ctco_cukes,EndsWithRegexpTest.matchesNotEndWith,"    @Test
    public void matchesNotEndWith() throws Exception {
        assertThat(""hello world"", Matchers.not(EndsWithRegexp.endsWithRegexp(""hello"")));
    }
",non-flaky,5
176814,ctco_cukes,EndsWithRegexpTest.matchesNotEndWithRegexp,"    @Test
    public void matchesNotEndWithRegexp() throws Exception {
        assertThat(""hello world"", Matchers.not(EndsWithRegexp.endsWithRegexp(""h.*o"")));
    }
",non-flaky,5
176815,ctco_cukes,EndsWithRegexpTest.matchesLocationUrl,"    @Test
    public void matchesLocationUrl() throws Exception {
        assertThat(""http://company.com:80/webapp/orx/rest/index/types/CLIENT/nodes/6f1155df-644b-4228-89af"" +
                ""-7d24b8fe1a8d"", EndsWithRegexp.endsWithRegexp(""/index/types/CLIENT/nodes/.+""));
    }
",non-flaky,5
176816,ctco_cukes,LoadRunnerFeatureTest.shouldCheckFileNameGeneration,"    @Test
    public void shouldCheckFileNameGeneration() throws Exception {
        String filename = ""My feature"";
        String refactoredName = loadRunnerFeature.createName(filename);
        assertThat(refactoredName, is(""My_feature""));
    }
",non-flaky,5
176817,ctco_cukes,LoadRunnerTransactionTest.formatShouldEscapeWhitespaces,"    @Test
    public void formatShouldEscapeWhitespaces() throws Exception {
        LoadRunnerTransaction trx = new LoadRunnerTransaction() {{
            setName(""hello world"");
            setTrxFlag(""LR_AUTO"");
        }};
        assertThat(trx.format(), containsString(""hello_world""));
    }
",non-flaky,5
176818,ctco_cukes,WebCustomRequestTest.formatShouldEscapeDoubleQuotes,"    @Test
    public void formatShouldEscapeDoubleQuotes() throws Exception {
        WebCustomRequest request = new WebCustomRequest() {{
            setBody(""hello \""world\"""");
        }};
        assertThat(request.format(), containsString(""hello \\\""world\\\""""));
    }
",non-flaky,5
176819,ctco_cukes,WebCustomRequestMapperTest.snapshotNumberShouldBeLessThan10Digits,"    @Test
    public void snapshotNumberShouldBeLessThan10Digits() {
        FilterableRequestSpecification requestSpec = mock(FilterableRequestSpecification.class);
        when(requestSpec.getURI()).thenReturn(""http://www.google.com"");
        when(requestSpec.getHeaders()).thenReturn(new Headers());

        WebCustomRequest request = mapper.map(requestSpec);
        assertThat(request, hasProperty(""snapshot"", CustomMatchers.stringWithLength(lessThanOrEqualTo(15)))); //10 digits + t + .inf
    }
",non-flaky,5
176820,ctco_cukes,EntityFacadeTest.byteArrayValueIsCheckedAsString,"    @Test
    public void byteArrayValueIsCheckedAsString() throws Exception {
        BasicAttributes entity = new BasicAttributes(true);
        entity.put(""userPassword"", new byte[]{50, 82, 115, 48, 67, 99, 54, 74});

        Whitebox.setInternalState(entityFacade, ""entity"", entity);

        entityFacade.entityHasAttributeWithValue(""userpassword"", ""2Rs0Cc6J"");
    }
",non-flaky,5
176821,ctco_cukes,EntityFacadeTest.charArrayValueIsCheckedAsString,"    @Test
    public void charArrayValueIsCheckedAsString() throws Exception {
        BasicAttributes entity = new BasicAttributes(true);
        entity.put(""userPassword"", new char[]{'h', 'e', 'l', 'l', 'o'});

        Whitebox.setInternalState(entityFacade, ""entity"", entity);

        entityFacade.entityHasAttributeWithValue(""userpassword"", ""hello"");
    }
",non-flaky,5
176822,ctco_cukes,EntityFacadeTest.stringValueIsCheckedAsString,"    @Test
    public void stringValueIsCheckedAsString() throws Exception {
        BasicAttributes entity = new BasicAttributes(true);
        entity.put(""userPassword"", ""hello"");

        Whitebox.setInternalState(entityFacade, ""entity"", entity);

        entityFacade.entityHasAttributeWithValue(""userpassword"", ""hello"");
    }
",non-flaky,5
176823,ctco_cukes,EntityFacadeTest.intArrayValueIsCheckedAsString,"    @Test
    public void intArrayValueIsCheckedAsString() throws Exception {
        BasicAttributes entity = new BasicAttributes(true);
        entity.put(""userPassword"", new int[]{1, 2, 3});

        Whitebox.setInternalState(entityFacade, ""entity"", entity);

        entityFacade.entityHasAttributeWithValue(""userpassword"", ""{1,2,3}"");
    }
",non-flaky,5
176824,ctco_cukes,EntityFacadeTest.intValueIsCheckedAsString,"    @Test
    public void intValueIsCheckedAsString() throws Exception {
        BasicAttributes entity = new BasicAttributes(true);
        entity.put(""userPassword"", 3);

        Whitebox.setInternalState(entityFacade, ""entity"", entity);

        entityFacade.entityHasAttributeWithValue(""userpassword"", ""3"");
    }
",non-flaky,5
176825,ctco_cukes,DnComparatorTest.compare_sameTree,"    @Test
    public void compare_sameTree() throws Exception {
        assertThat(comparator.compare(""cn=root"", ""cn=b,cn=root""), is(more()));
        assertThat(comparator.compare(""cn=a,cn=root"", ""cn=root""), is(less()));
        assertThat(comparator.compare(""cn=a,cn=root"", ""cn=a,cn=root""), is(same()));
    }
",non-flaky,5
176826,ctco_cukes,DnComparatorTest.compare_differentTrees,"    @Test
    public void compare_differentTrees() throws Exception {
        assertThat(comparator.compare(""cn=a,cn=root"", ""cn=b,cn=root""), is(more()));
        assertThat(comparator.compare(""cn=b,cn=root"", ""cn=a,cn=root""), is(less()));
    }
",non-flaky,5
176827,ctco_cukes,DnComparatorTest.sort,"    @Test
    public void sort() throws Exception {
        List<String> dns = new ArrayList<>(Arrays.asList(
            ""cn=root"",
            ""cn=a,cn=root"",
            ""cn=b,cn=root"",
            ""cn=c,cn=a,cn=root""
        ));
        Collections.sort(dns, comparator);
        assertThat(dns.get(0), is(""cn=root""));
        assertThat(dns.get(1), is(""cn=a,cn=root""));
        assertThat(dns.get(2), is(""cn=c,cn=a,cn=root""));
        assertThat(dns.get(3), is(""cn=b,cn=root""));
    }
",non-flaky,5
176828,ctco_cukes,LDIFUtilsTest.read,"    @Test
    public void read() throws Exception {
        Map<String, Attributes> entities = LDIFUtils.read(getClass().getResourceAsStream(""/example.ldif""));
        assertThat(entities.size(), is(4));
    }
",non-flaky,5
176829,ctco_cukes,LDIFUtilsTest.readSingleEntity,"    @Test
    public void readSingleEntity() throws Exception {
        String ldif = ""dn: dc=example,dc=com\n"" +
            ""objectClass: domain\n"" +
            ""objectClass: top\n"" +
            ""dc: example\n"";
        Map<String, Attributes> entities = LDIFUtils.read(new ByteArrayInputStream(ldif.getBytes()));
        assertThat(entities.size(), is(1));
        String dn = ""dc=example,dc=com"";
        Attributes entity = entities.get(dn);
        assertThat(entity, notNullValue());

        assertThat(entity.get(""dn""), nullValue());
        assertThat(entity.get(""dc"").get(), is(""example""));
        assertThat(entity.get(""objectClass"").contains(""domain""), is(true));
        assertThat(entity.get(""objectClass"").contains(""top""), is(true));
    }
",non-flaky,5
176830,ctco_cukes,LDIFUtilsTest.readMultipleEntities,"    @Test
    public void readMultipleEntities() throws Exception {
        String ldif = ""dn: dc=example,dc=com\n"" +
            ""objectClass: domain\n"" +
            ""objectClass: top\n"" +
            ""dc: example\n"" +
            ""\n"" +
            ""dn: ou=Users,dc=example,dc=com\n"" +
            ""objectClass: organizationalUnit\n"" +
            ""objectClass: top\n"" +
            ""ou: Users\n"";

        Map<String, Attributes> entities = LDIFUtils.read(new ByteArrayInputStream(ldif.getBytes()));
        assertThat(entities.size(), is(2));
        assertThat(entities.containsKey(""dc=example,dc=com""), is(true));
        assertThat(entities.containsKey(""ou=Users,dc=example,dc=com""), is(true));
    }
",non-flaky,5
176831,ctco_cukes,LDIFUtilsTest.readWithLineBreaks,"    @Test
    public void readWithLineBreaks() throws Exception {
        String ldif = ""dn: dc=example,dc=com\n"" +
            ""objectClass: top\n"" +
            ""test: this is\n"" +
            "" multi-line text\n"" +
            ""dc: example\n"";
        Map<String, Attributes> entities = LDIFUtils.read(new ByteArrayInputStream(ldif.getBytes()));
        assertThat(entities.size(), is(1));
        Attributes entity = entities.get(""dc=example,dc=com"");
        assertThat(entity.get(""test"").get(), is(""this is multi-line text""));

    }
",non-flaky,5
