full_code
"@Test
public void test_parseLString() throws Exception {
    DateFormat format = DateFormat.getDateTimeInstance(DateFormat.FULL, DateFormat.FULL, Locale.US);
    try {
        Date date = format.parse(format.format(current).toString());
        assertEquals(current.getDate(), date.getDate());
        assertEquals(current.getDay(), date.getDay());
        assertEquals(current.getMonth(), date.getMonth());
        assertEquals(current.getYear(), date.getYear());
        assertEquals(current.getHours(), date.getHours());
        assertEquals(current.getMinutes(), date.getMinutes());
    } catch(ParseException pe) {
    fail(""ParseException was thrown for current Date.""); }
    try {
        format.parse(""January 16, 1970 8:03:52 PM CET"");
        fail(""ParseException was not thrown."");
    } catch(ParseException pe) { }
}"
"@Test
public void testGetPartialRepairTasks() {
    Node node = mockNode(""DC1"");
    Node node2 = mockNode(""DC1"");
    ImmutableList<LongTokenRange> vnodes = ImmutableList.of(new LongTokenRange(1, 2), new LongTokenRange(2, 3), new LongTokenRange(4, 5));
    ReplicaRepairGroup replicaRepairGroup = new ReplicaRepairGroup(ImmutableSet.of(node, node2), vnodes);
    RepairGroup repairGroup = builderFor(replicaRepairGroup).build(priority);
    Collection<RepairTask> tasks = repairGroup.getRepairTasks();
    assertThat(tasks.size()).isEqualTo(3);
    Set<LongTokenRange> repairTaskRanges = new HashSet<>();
    for (RepairTask repairTask : tasks) {
        assertThat(repairTask.getTokenRanges().size()).isEqualTo(1);
        LongTokenRange range = repairTask.getTokenRanges().iterator().next();
        repairTaskRanges.add(range);
        assertThat(repairTask.getReplicas()).containsExactlyInAnyOrder(node, node2);
        assertThat(repairTask.getTableReference()).isEqualTo(tableReference);
        assertThat(repairTask.getRepairConfiguration().getRepairParallelism()).isEqualTo(PARALLEL);
    }
    assertThat(repairTaskRanges).containsExactlyElementsOf(vnodes);
}"
"@Test
public void testGenerateNewDayPairs() {
    PairCombinations pairs = getPairsList();
    List<Developer> devs = getStandardDevs();
    List<String> tracks = Arrays.asList(""track1"", ""track2"", ""track3"");
    Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);
    subject.buildDevelopersPairingDays(pairs, devs);
    DayPairs dayPairs = subject.generateNewDayPairs(tracks, devs, pairs, pairsWeight, getStandardCompanies());
    assertThat(dayPairs.getTracks().size(), is(2));
    assertThat(dayPairs.getTracks(), contains(""track1"", ""track2""));
    assertThat(dayPairs.getPairByTrack(""track1""),
    is(not(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2""))))));
    assertThat(dayPairs.getPairByTrack(""track2""),
    is(not(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4""))))));
    boolean trackOneHasContext = dayPairs.getPairByTrack(""track1"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track1"").getSecondDev().hasContext();
    boolean trackTwoHasContext = dayPairs.getPairByTrack(""track2"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track2"").getSecondDev().hasContext();
    assertThat(trackOneHasContext, is(true));
    assertThat(trackTwoHasContext, is(true));
}"
"@Test
public void kafkaTopicIsPattern() throws Exception {
    to.expectedMessageCount(5);
    to.expectedBodiesReceivedInAnyOrder(""message-0"", ""message-1"", ""message-2"", ""message-3"", ""message-4"");
    to.allMessages().header(TOPIC).isEqualTo(""test"");
    to.expectedHeaderValuesReceivedInAnyOrder(LAST_RECORD_BEFORE_COMMIT, null, null, null, null, null);
    for (int k = 0; k < 5; k++) {
        String msg = ""message-"" + k;
        ProducerRecord<String, String> data = new ProducerRecord<>(TOPIC, ""1"", msg);
        producer.send(data);
    }
    to.assertIsSatisfied(3000);
    assertEquals(5, StreamSupport.stream(recordsCaptured.get(0).records(TOPIC).spliterator(), false).count());
}"
"@Test
public void testRepairSuccessfully() throws InterruptedException {
    Collection<LongTokenRange> ranges = new ArrayList<>();
    LongTokenRange range1 = new LongTokenRange(1, 2);
    LongTokenRange range2 = new LongTokenRange(3, 4);
    ranges.add(range1);
    ranges.add(range2);
    final RepairTask repairTask = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(ranges).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build();
    CountDownLatch cdl = startRepair(repairTask, false);
    Notification notification = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(range1));
    notification.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2));
    proxy.notify(notification);
    notification = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(range2));
    notification.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2));
    proxy.notify(notification);
    notification = new Notification(""progress"", ""repair:1"", 2, ""Done with repair"");
    notification.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2));
    proxy.notify(notification);
    cdl.await();
    assertThat(repairTask.getUnknownRanges()).isNull();
    assertThat(repairTask.getCompletedRanges()).containsExactlyElementsOf(ranges);
    assertThat(proxy.myOptions.get(RANGES_KEY)).isNotEmpty();
    verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true));
    verify(repairSessions.get(range1)).start();
    verify(repairSessions.get(range2)).start();
    verify(repairSessions.get(range1)).finish(eq(SUCCESS));
    verify(repairSessions.get(range2)).finish(eq(SUCCESS));
}"
"@Test
public void healthCheckTest() throws Exception {
    RssGetShuffleAssignmentsRequest request = new RssGetShuffleAssignmentsRequest(""1"", 1, 1, 1, 1, Sets.newHashSet(SHUFFLE_SERVER_VERSION));
    Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS);
    assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount());
    List<ServerNode> nodes = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION));
    assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount());
    assertEquals(2, nodes.size());
    RssGetShuffleAssignmentsResponse response = coordinatorClient.getShuffleAssignments(request);
    assertFalse(response.getPartitionToServers().isEmpty());
    for (ServerNode node : nodes) {
        assertTrue(node.isHealthy());
    }
    byte[] bytes = new byte[writeDataSize];
    new Random().nextBytes(bytes);
    try (final FileOutputStream out = new FileOutputStream(tempDataFile)) {
        out.write(bytes);
    }
    Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS);
    CoordinatorTestUtils.waitForRegister(coordinatorClient, 2);
    nodes = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION));
    for (ServerNode node : nodes) {
        assertFalse(node.isHealthy());
    }
    assertEquals(0, nodes.size());
    response = coordinatorClient.getShuffleAssignments(request);
    assertEquals(INTERNAL_ERROR, response.getStatusCode());
    tempDataFile.delete();
    int i = 0;
    do {
        Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS);
        nodes = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION));
        i++;
        if (i == 10) {
            fail();
        }
    } while (nodes.size() != 2 );
    for (ServerNode node : nodes) {
        assertTrue(node.isHealthy());
    }
    assertEquals(2, nodes.size());
    response = coordinatorClient.getShuffleAssignments(request);
    assertFalse(response.getPartitionToServers().isEmpty());
}"
"@Test
public void testReplicaThreadedThroughputDegradationAndRejection() throws Exception {
    Settings settings = Settings.builder().put(IndexingPressure.MAX_INDEXING_BYTES.getKey(), ""10KB"")
    .put(ShardIndexingPressureSettings.SHARD_INDEXING_PRESSURE_ENABLED.getKey(), true)
    .put(ShardIndexingPressureSettings.SHARD_INDEXING_PRESSURE_ENFORCED.getKey(), true)
    .put(ShardIndexingPressureMemoryManager.THROUGHPUT_DEGRADATION_LIMITS.getKey(), 1)
    .put(ShardIndexingPressureSettings.REQUEST_SIZE_WINDOW.getKey(), 100)
    .build();
    final int NUM_THREADS = scaledRandomIntBetween(100, 120);
    ShardIndexingPressure shardIndexingPressure = new ShardIndexingPressure(settings, clusterService);
    Index index = new Index(""IndexName"", ""UUID"");
    ShardId shardId1 = new ShardId(index, 0);
    fireConcurrentAndParallelRequestsForUniformThroughPut(NUM_THREADS, shardIndexingPressure, shardId1, 100, 100,
    OperationType.REPLICA);
    fireAllThenCompleteConcurrentRequestsWithUniformDelay(ShardIndexingPressureSettings.REQUEST_SIZE_WINDOW.get(settings),
    shardIndexingPressure, shardId1, 100, 200, OperationType.REPLICA);
    expectThrows(OpenSearchRejectedExecutionException.class,
    () -> shardIndexingPressure.markReplicaOperationStarted(shardId1, 11 * 1024, false));
    assertEquals(0, shardIndexingPressure.coldStats().getIndexingPressureShardStats(shardId1).getCurrentReplicaBytes());
    assertEquals(15, shardIndexingPressure.coldStats().getIndexingPressureShardStats(shardId1).getCurrentReplicaLimits());
}"
"@Test
public void testLogbackStatusPrinterPrintStreamIsRestoredToSystemOut() throws Exception {
    Field field = StatusPrinter.class.getDeclaredField(""ps"");
    field.setAccessible(true);
    PrintStream out = (PrintStream) field.get(null);
    assertThat(out).isSameAs(System.out);
}"
"@Test
public void assertDurationIsInRange(long expectedMillis) {
    long minimum = (long) ((double) expectedMillis * 0.90);
    long maximum =
    Math.max((long) ((double) expectedMillis * 1.10), 10);
    long waitMillis = Math.max(expectedMillis * 10, 10);
    long duration = getDurationMillis(waitMillis);
    if (duration < minimum) {
        Assert.fail(""expected duration: "" + expectedMillis +
        "" minimum duration: "" + minimum +
        "" actual duration too short: "" + duration);
    } else if (duration > maximum) {
        Assert.fail(""expected duration: "" + expectedMillis +
        "" maximum duration: "" + maximum +
        "" actual duration too long: "" + duration);
    }
}"
"@Test
public void testEmptyByteArrayForEmptyInput() throws IOException {
    this.fstObjectInput = new FstObjectInput(new ByteArrayInputStream("""".getBytes()));
    byte[] bytes = fstObjectInput.readBytes();
    assertThat(bytes.length, is(0));
}"
"@Test
public void testRecordWithJsr310LogicalTypes() throws IOException {
    TestRecordWithJsr310LogicalTypes record = new TestRecordWithJsr310LogicalTypes(
    true,
    34,
    35L,
    3.14F,
    3019.34,
    null,
    java.time.LocalDate.now(),
    java.time.LocalTime.now().truncatedTo(ChronoUnit.MILLIS),
    java.time.Instant.now().truncatedTo(ChronoUnit.MILLIS),
    new BigDecimal(123.45f).setScale(2, BigDecimal.ROUND_HALF_DOWN)
    );
    File data = write(TestRecordWithJsr310LogicalTypes.getClassSchema(), record);
    List<TestRecordWithJsr310LogicalTypes> actual = read(
    TestRecordWithJsr310LogicalTypes.getClassSchema(), data);
    Assert.assertEquals(""Should match written record"", record, actual.get(0));
}"
"@Test
public void outerInnerErrorRace() {
    for (int i = 0; i < 500; i++) {
        List<Throwable> errors = TestHelper.trackPluginErrors();
        try {
            final PublishSubject<Integer> ps1 = PublishSubject.create();
            final PublishSubject<Integer> ps2 = PublishSubject.create();
            ps1.switchMap(new Function<Integer, ObservableSource<Integer>>() {
                @Override
                public ObservableSource<Integer> apply(Integer v) throws Exception {
                    if (v == 1) {
                        return ps2;
                    }
                    return Observable.never();
                }
            })
            .test();
            final TestException ex1 = new TestException();
            Runnable r1 = new Runnable() {
                @Override
                public void run() {
                    ps1.onError(ex1);
                }
            };
            final TestException ex2 = new TestException();
            Runnable r2 = new Runnable() {
                @Override
                public void run() {
                    ps2.onError(ex2);
                }
            };
            TestHelper.race(r1, r2);
            for (Throwable e : errors) {
                assertTrue(e.toString(), e instanceof TestException);
            }
        } finally {
            RxJavaPlugins.reset();
        }
    }
}"
"@Test
public void testWatch() throws Exception {
    final JsonArray operationTypes = new JsonArray(Arrays.asList(""insert"", ""update"", ""replace"", ""delete""));
    final JsonObject match = new JsonObject().put(""operationType"", new JsonObject().put(""$in"", operationTypes));
    final JsonArray pipeline = new JsonArray().add(new JsonObject().put(""$match"", match));
    final JsonObject fields = new JsonObject().put(""operationType"", true).put(""namespaceDocument"", true).put(""destinationNamespaceDocument"", true).put(""documentKey"", true).put(""updateDescription"", true).put(""fullDocument"", true);
    pipeline.add(new JsonObject().put(""$project"", fields));
    final String collection = randomCollection();
    final JsonObject doc = createDoc();
    final CountDownLatch latch = new CountDownLatch(4);
    final AtomicReference<ReadStream<ChangeStreamDocument<JsonObject>>> streamReference = new AtomicReference<>();
    mongoClient.createCollection(collection, onSuccess(( res) -> {
        ReadStream<ChangeStreamDocument<JsonObject>> stream = mongoClient.watch(collection, pipeline, true, 1).handler(( changeStreamDocument) -> {
            OperationType operationType = changeStreamDocument.getOperationType();
            assertNotNull(operationType);
            JsonObject fullDocument = changeStreamDocument.getFullDocument();
            switch (operationType.getValue()) {
                case ""insert"" :
                assertNotNull(fullDocument);
                assertNotNull(fullDocument.getString(MongoClientUpdateResult.ID_FIELD));
                assertEquals(""bar"", fullDocument.getString(""foo""));
                break;
                case ""update"" :
                assertNotNull(fullDocument);
                assertEquals(""updatedValue"", fullDocument.getString(""fieldToUpdate""));
                break;
                case ""replace"" :
                assertNotNull(fullDocument);
                assertEquals(""replacedValue"", fullDocument.getString(""fieldToReplace""));
                break;
                case ""delete"" :
                assertNull(fullDocument);
                break;
                default :
            }
            latch.countDown();
            if (latch.getCount() == 1) {
                mongoClient.removeDocuments(collection, new JsonObject());
            }
        }).endHandler(( v) -> assertEquals(0, latch.getCount())).exceptionHandler(this::fail).fetch(1);
        streamReference.set(stream);
        vertx.setTimer(50, ( v) -> {
            mongoClient.insert(collection, doc).compose(( idString) -> {
                doc.put(MongoClientUpdateResult.ID_FIELD, idString);
                doc.put(""fieldToUpdate"", ""updatedValue"");
                final JsonObject query = new JsonObject().put(MongoClientUpdateResult.ID_FIELD, idString);
                final JsonObject updateField = new JsonObject().put(""fieldToUpdate"", ""updatedValue"");
                return CompositeFuture.all(mongoClient.updateCollection(collection, query, new JsonObject().put(""$set"", updateField)), mongoClient.save(collection, doc.put(""fieldToReplace"", ""replacedValue"")));
            });
        });
    }));
    awaitLatch(latch);
    streamReference.get().handler(null);
}"
"@Test
public void test_empty_obj_toJson() {
    String j = Json.toJson(new Person(), JsonFormat.compact().setQuoteName(true));
    assertEquals(""{\""age\"":0,\""num\"":0}"", j);
}"
"@Test
public void createDefaultDirectoryManagerPath() throws IOException {
    Path path = Paths.get(System.getProperty(""user.dir""));
    DirectoryManager dm = DirectoryManagerFactory.createDirectoryManager(
    path, true);
    assertTrue(dm instanceof DirectoryManagerImpl);
    DirectoryManagerImpl dmi = (DirectoryManagerImpl) dm;
    assertTrue(dmi.readOnly);
    assertEquals(path, dmi.directory);
}"
"@Test
public void testListAllPort() throws RemotingException {
    String result = port.telnet(null, """");
    assertEquals(""20887"", result);
}"
"@Test
public void assertPersistEphemeralSequential() throws Exception {
    zkRegCenter.persistEphemeralSequential(""/sequential/test_ephemeral_sequential"");
    zkRegCenter.persistEphemeralSequential(""/sequential/test_ephemeral_sequential"");
    CuratorFramework client = CuratorFrameworkFactory.newClient(EmbedTestingServer.getConnectionString(), new RetryOneTime(2000));
    client.start();
    client.blockUntilConnected();
    List<String> actual = client.getChildren().forPath(""/"" + ZookeeperRegistryCenterModifyTest.class.getName() + ""/sequential"");
    assertThat(actual.size(), is(2));
    for (String each : actual) {
        assertThat(each, startsWith(""test_ephemeral_sequential""));
    }
    zkRegCenter.close();
    actual = client.getChildren().forPath(""/"" + ZookeeperRegistryCenterModifyTest.class.getName() + ""/sequential"");
    assertTrue(actual.isEmpty());
    zkRegCenter.init();
}"
"@Test
public void testRecursingTrace() throws Exception {
    TracePluginConfiguration conf = new TracePluginConfiguration();
    conf.traceProb = 1.0;
    conf.port = 51010;
    conf.clientPort = 12346;
    TracePlugin aPlugin = new TracePlugin(conf);
    conf.port = 51011;
    conf.clientPort = 12347;
    TracePlugin bPlugin = new TracePlugin(conf);
    conf.port = 51012;
    conf.clientPort = 12348;
    TracePlugin cPlugin = new TracePlugin(conf);
    conf.port = 51013;
    conf.clientPort = 12349;
    TracePlugin dPlugin = new TracePlugin(conf);
    Responder bRes = new RecursingResponder(TestBasicTracing.advancedProtocol, bPlugin);
    bRes.addRPCPlugin(bPlugin);
    HttpServer server1 = new HttpServer(bRes, 21005);
    server1.start();
    Responder cRes = new EndpointResponder(TestBasicTracing.advancedProtocol);
    cRes.addRPCPlugin(cPlugin);
    HttpServer server2 = new HttpServer(cRes, 21006);
    server2.start();
    Responder dRes = new EndpointResponder(TestBasicTracing.advancedProtocol);
    dRes.addRPCPlugin(dPlugin);
    HttpServer server3 = new HttpServer(dRes, 21007);
    server3.start();
    HttpTransceiver trans = new HttpTransceiver(new URL(""http:www.example.com""));
    GenericRequestor r = new GenericRequestor(TestBasicTracing.advancedProtocol, trans);
    r.addRPCPlugin(aPlugin);
    GenericRecord params = new GenericData.Record(advancedProtocol.getMessages().get(""w"").getRequest());
    params.put(""req"", 1);
    for (int i = 0; i < 40; i++) {
        r.request(""w"", params);
    }
    List<Span> allSpans = new ArrayList<Span>();
    allSpans.addAll(aPlugin.storage.getAllSpans());
    allSpans.addAll(bPlugin.storage.getAllSpans());
    allSpans.addAll(cPlugin.storage.getAllSpans());
    allSpans.addAll(dPlugin.storage.getAllSpans());
    SpanAggregationResults results = SpanAggregator.getFullSpans(allSpans);
    assertEquals(0, results.incompleteSpans.size());
    List<Span> merged = results.completeSpans;
    List<Trace> traces = SpanAggregator.getTraces(merged).traces;
    assertEquals(40, traces.size());
    TraceCollection collection = new TraceCollection(traces.get(0));
    for (Trace t : traces) {
        collection.addTrace(t);
    }
    server1.close();
    server2.close();
    server3.close();
    aPlugin.httpServer.close();
    aPlugin.clientFacingServer.stop();
    bPlugin.httpServer.close();
    bPlugin.clientFacingServer.stop();
    cPlugin.httpServer.close();
    cPlugin.clientFacingServer.stop();
    dPlugin.httpServer.close();
    dPlugin.clientFacingServer.stop();
}"
"@Test
void sendMessageOnMessage() throws Exception {
    final Workflow workflow = SwadlParser.fromYaml(getClass().getResourceAsStream(""/message/send-message-on-message.swadl.yaml""));
    final V4Message message = message(""Hello!"");
    engine.deploy(workflow);
    engine.onEvent(messageReceived(""/message""));
    when(messageService.send(anyString(), any(Message.class))).thenReturn(message);
    verify(messageService, timeout(5000)).send(anyString(), any(Message.class));
    assertThat(workflow).isExecuted().hasOutput(String.format(OUTPUTS_MSG_KEY, ""sendMessage1""), message).hasOutput(String.format(OUTPUTS_MSG_ID_KEY, ""sendMessage1""), message.getMessageId());
}"
"@Test
public void assertGetLocalFailoverItemsIfShutdown() {
    assertThat(failoverService.getLocalFailoverItems(), is(Collections.<Integer>emptyList()));
    verify(jobNodeStorage, times(0)).getJobNodeChildrenKeys(""sharding"");
}"
"@Test
public void testChangeServiceNotExport() throws RemotingException {
    String result = change.telnet(mockChannel, ""demo"");
    assertEquals(""No such service demo"", result);
}"
"@Test
public void createDirectoryManagerIoException() throws IOException {
    DirectoryManagerFactory.createDirectoryManager(
    ""/nonexisting-directory/123456789/hopefully"", true);
}"
"@Test
public void assertGetCurrentShardingTotalCountIfNull() {
    assertThat(JobRegistry.getInstance().getCurrentShardingTotalCount(""exist_job_instance""), is(0));
}"
"@Test
public void create_repo_and_uploads_commits() throws Exception {
    String challengeId = ""TCH"";
    String participantId = generateId();
    String s3destination = String.format(""%s/%s/file.srcs"", challengeId, participantId);
    TestSrcsFile srcsForTestChallenge = new TestSrcsFile(""HmmmLang_R1Cov33_R2Cov44.srcs"");
    S3Event s3Event = localS3Bucket.putObject(srcsForTestChallenge.asFile(), s3destination);
    coverageUploadHandler.handleRequest(convertToMap(wrapAsSNSEvent(s3Event)),NO_CONTEXT);
    waitForQueueToReceiveEvents();
    assertThat(languageDetectedEvents.size(), equalTo(1));
    System.out.println(""Received language detected events: ""+languageDetectedEvents);
    ProgrammingLanguageDetectedEvent languageEvent = languageDetectedEvents.get(0);
    assertThat(languageEvent.getParticipant(), equalTo(participantId));
    assertThat(languageEvent.getChallengeId(), equalTo(challengeId));
    assertThat(languageEvent.getProgrammingLanguage(), equalTo(""HmmmLang""));
    assertThat(coverageComputedEvents.size(), equalTo(2));
    System.out.println(""Received coverage events: ""+coverageComputedEvents);
    coverageComputedEvents.sort(Comparator.comparing(CoverageComputedEvent::getRoundId));
    CoverageComputedEvent coverageRound1 = coverageComputedEvents.get(0);
    assertThat(coverageRound1.getParticipant(), equalTo(participantId));
    assertThat(coverageRound1.getRoundId(), equalTo(challengeId+""_R1""));
    assertThat(coverageRound1.getCoverage(), equalTo(33));
    CoverageComputedEvent coverageRound2 = coverageComputedEvents.get(1);
    assertThat(coverageRound2.getParticipant(), equalTo(participantId));
    assertThat(coverageRound2.getRoundId(), equalTo(challengeId+""_R2""));
    assertThat(coverageRound2.getCoverage(), equalTo(44));
}"
"@Test
public void testShortCircuited() {
    HystrixCommandKey key = Factory.asKey(""CMD-Health-G"");
    stream = HealthCountsStream.getInstance(key, 10, 100);
    final CountDownLatch latch = new CountDownLatch(1);
    stream.observe().take(10).subscribe(getSubscriber(latch));
    CommandStreamTest.Command failure1 = Command.from(groupKey, key, FAILURE, 20);
    CommandStreamTest.Command failure2 = Command.from(groupKey, key, FAILURE, 20);
    CommandStreamTest.Command failure3 = Command.from(groupKey, key, FAILURE, 20);
    CommandStreamTest.Command shortCircuit1 = Command.from(groupKey, key, SUCCESS);
    CommandStreamTest.Command shortCircuit2 = Command.from(groupKey, key, SUCCESS);
    failure1.observe();
    failure2.observe();
    failure3.observe();
    try {
        Thread.sleep(100);
    } catch (InterruptedException ie) {
        fail(ie.getMessage());
    }
    shortCircuit1.observe();
    shortCircuit2.observe();
    try {
        assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
    } catch (InterruptedException ex) {
        fail(""Interrupted ex"");
    }
    assertTrue(shortCircuit1.isResponseShortCircuited());
    assertTrue(shortCircuit2.isResponseShortCircuited());
    System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
    assertEquals(3L, stream.getLatest().getErrorCount());
    assertEquals(3L, stream.getLatest().getTotalRequests());
}"
"@Test
public void test_enum() {
    assertEquals(""\""K\"""", Json.toJson(K.K));
    String expected = ""{\n"" + ((""   \""name\"": \""t\"",\n"" + ""   \""index\"": 1\n"") + ""}"");
    assertEquals(expected, Json.toJson(TT.T));
    assertEquals(""\""T\"""", Json.toJson(TT.T, JsonFormat.full().ignoreJsonShape()));
}"
"@Test
public void testSchedulingWithDueTime() throws InterruptedException {
    final CountDownLatch latch = new CountDownLatch(5);
    final AtomicInteger counter = new AtomicInteger();
    long start = System.currentTimeMillis();
    Schedulers.threadPoolForComputation().schedule(null, new Func2<Scheduler, String, Subscription>() {
        @Override
        public Subscription call(Scheduler scheduler, String state) {
            System.out.println(""doing work"");
            latch.countDown();
            counter.incrementAndGet();
            if (latch.getCount() == 0) {
                return Subscriptions.empty();
            } else {
                return scheduler.schedule(state, this, new Date(System.currentTimeMillis() + 50));
            }
        }
    }, new Date(System.currentTimeMillis() + 100));
    if (!latch.await(3000, TimeUnit.MILLISECONDS)) {
        fail(""didn't execute ... timed out"");
    }
    long end = System.currentTimeMillis();
    assertEquals(5, counter.get());
    if ((end - start) < 250) {
        fail(""it should have taken over 250ms since each step was scheduled 50ms in the future"");
    }
}"
"@Test
public void assertIsShutdownAlready() {
    shutdownListenerManager.new InstanceShutdownStatusJobListener().dataChanged(""/test_job/instances/127.0.0.1@-@0"", Type.NODE_REMOVED, """");
    verify(schedulerFacade, times(0)).shutdownInstance();
}"
"@Test
public void testPartialRepair() throws InterruptedException {
    Collection<LongTokenRange> ranges = new ArrayList<>();
    LongTokenRange range1 = new LongTokenRange(1, 2);
    LongTokenRange range2 = new LongTokenRange(3, 4);
    ranges.add(range1);
    ranges.add(range2);
    final RepairTask repairTask = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(ranges).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build();
    CountDownLatch cdl = startRepair(repairTask, false);
    Notification notification = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(range1));
    notification.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2));
    proxy.notify(notification);
    notification = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(range2));
    notification.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2));
    proxy.notify(notification);
    notification = new Notification(""progress"", ""repair:1"", 2, ""Done with repair"");
    notification.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2));
    proxy.notify(notification);
    cdl.await();
    assertThat(repairTask.getUnknownRanges()).isNull();
    assertThat(repairTask.getCompletedRanges()).containsExactlyElementsOf(ranges);
    assertThat(proxy.myOptions.get(RANGES_KEY)).isNotEmpty();
    verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true));
    verify(repairSessions.get(range1)).start();
    verify(repairSessions.get(range2)).start();
    verify(repairSessions.get(range1)).finish(eq(SUCCESS));
    verify(repairSessions.get(range2)).finish(eq(SUCCESS));
}"
"@Test
public void testListenerFailures() throws InterruptedException {
    int iters = iterations(10, 100);
    for (int i = 0; i < iters; i++) {
        try (TestIteration iteration = new TestIteration()) {
            iteration.transport.endConnectMode();
            final CountDownLatch latch = new CountDownLatch(1);
            final AtomicInteger finalFailures = new AtomicInteger();
            final AtomicReference<Throwable> finalFailure = new AtomicReference<>();
            final AtomicReference<TestResponse> response = new AtomicReference<>();
            ActionListener<TestResponse> actionListener = new ActionListener<TestResponse>();
            final AtomicInteger preSendFailures = new AtomicInteger();
            iteration.transportClientNodesService.execute((node, retryListener) -> {
                if (rarely()) {
                    preSendFailures.incrementAndGet();
                    throw new IllegalArgumentException();
                }
                iteration.transportService.sendRequest(node, ""action"", new TestRequest(),
                TransportRequestOptions.EMPTY, new TransportResponseHandler<TestResponse>() {
                }, actionListener);
                assertThat(latch.await(1, TimeUnit.SECONDS), equalTo(true));
                assertThat(preSendFailures.get() + iteration.transport.failures() + iteration.transport.successes(), lessThanOrEqualTo(1));
                if (iteration.transport.successes() == 1) {
                    assertThat(finalFailures.get(), equalTo(0));
                    assertThat(finalFailure.get(), nullValue());
                    assertThat(response.get(), notNullValue());
                } else {
                    assertThat(finalFailures.get(), equalTo(1));
                    assertThat(finalFailure.get(), notNullValue());
                    assertThat(response.get(), nullValue());
                    if (preSendFailures.get() == 0 && iteration.transport.failures() == 0) {
                        assertThat(finalFailure.get(), instanceOf(NoNodeAvailableException.class));
                    }
                }
                assertThat(iteration.transport.triedNodes().size(), lessThanOrEqualTo(iteration.listNodesCount));
                assertThat(iteration.transport.triedNodes().size(), equalTo(iteration.transport.connectTransportExceptions() + iteration.transport.failures() + iteration.transport.successes()));
            });
        }
    }
}"
"@Test
public void testFromFileToFtp() throws Exception {
    service.suspend();
    template.sendBodyAndHeader(""file:{{ftp.root.dir}}/reconnect"", ""Hello World"", FILE_NAME, ""hello.txt"");
    MockEndpoint mock = getMockEndpoint(""mock:result"");
    mock.expectedMessageCount(0);
    Thread.sleep(3000);
    assertMockEndpointsSatisfied();
    mock.reset();
    mock.expectedMessageCount(1);
    service.resume();
    Thread.sleep(3000);
    assertMockEndpointsSatisfied();
}"
"@Test
void close() throws Exception {
    when(webSocketClient.getConnection()).thenReturn(webSocket);
    when(webSocketClient.isOpen()).thenReturn(true);
    webSocketConnection.close();
    Thread.sleep(10);
    verify(webSocket).close();
}"
"@Test
public void shouldContainSyncCommitteeAggregates() throws Exception {
    primaryNode.start();
    primaryNode.startEventListener(List.of(contribution_and_proof));
    secondaryNode.start();
    secondaryNode.startEventListener(List.of(contribution_and_proof));
    validatorClient.start();
    primaryNode.waitForEpoch(1);
    secondaryNode.waitForFullSyncCommitteeAggregate();
    validatorClient.stop();
    secondaryNode.stop();
    primaryNode.stop();
    assertThat(primaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isGreaterThanOrEqualTo(8)).count()).isGreaterThan(0);
    assertThat(secondaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isLessThan(8)).count()).isGreaterThan(0);
}"
"@Test
public void testMonitor() throws IOException, InterruptedException {
    monitor.setScanInterval(5);
    assertTrue(monitor.getEntries().isEmpty());
    File fooFile = touchFile(""foo"", ""foo1"");
    Thread.sleep(MONITOR_CHECK_DELAY);
    Collection<TestInstance> entries = monitor.getEntries();
    assertEquals(1, entries.size());
    TestInstance[] entryArray = new TestInstance[1];
    entryArray = entries.toArray(entryArray);
    TestInstance fooInst = entryArray[0];
    assertEquals(""foo1"", fooInst.getMessage());
    touchFile(""bar"", ""bar1"");
    Thread.sleep(MONITOR_CHECK_DELAY);
    entries = monitor.getEntries();
    assertEquals(2, entries.size());
    TestInstance fooCheck = monitor.get(""foo"");
    TestUtil.testArray(entryNames(entries), new String[]{ ""foo1"", ""bar1"" });
    assertEquals(fooCheck, fooInst);
    touchFile(""foo"", ""foo2"");
    Thread.sleep(MONITOR_CHECK_DELAY);
    entries = monitor.getEntries();
    assertEquals(2, entries.size());
    TestUtil.testArray(entryNames(entries), new String[]{ ""foo2"", ""bar1"" });
    fooCheck = monitor.get(""foo"");
    assertNotSame(fooInst, fooCheck);
    assertEquals(""foo2"", fooCheck.getMessage());
    fooFile.delete();
    Thread.sleep(MONITOR_CHECK_DELAY);
    entries = monitor.getEntries();
    assertEquals(1, entries.size());
    TestUtil.testArray(entryNames(entries), new String[]{ ""bar1"" });
}"
"@Test
public void appliesOuterTimeout() {
    final WaitStrategy underTest = new WaitAllStrategy()
    .withStrategy(strategy1)
    .withStartupTimeout(Duration.ofMillis(10));
    doAnswer(invocation -> {
        Uninterruptibles.sleepUninterruptibly(20, TimeUnit.MILLISECONDS);
        return null;
    }).when(strategy1).waitUntilReady(eq(container));
    assertThrows(""The outer strategy timeout applies"", TimeoutException.class, () -> {
        underTest.waitUntilReady(container);
    });
}"
"@Test
public void testListDetail() throws RemotingException {
    String result = port.telnet(null, ""-l"");
    assertEquals(""dubbo://127.0.0.1:20887"", result);
}"
"@Test
public void shouldReturnBodyWhenEnabledAndNoMax() {
    String body = ""{\n"" +
    ""  \""error\"": \""not found\""\n"" +
    ""}"";
    HttpResponseFacade mock = mock(HttpResponseFacade.class);
    when(mock.response()).thenReturn(generateResponse(
    ""application/json"",
    404,
    body.getBytes()));
    ((HttpAssertionFacadeImpl) facade).facade = mock;
    world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true"");
    validateException(
    200,
    ""1 expectation failed.\n"" +
    ""Expected status code \""200\"" but was \""404\"" with body:\n"" +
    ""\""\""\""\n"" +
    body +
    ""\n\""\""\"".\n"");
}"
"@Test
public void testRetryWithBackpressure() throws InterruptedException {
    final int NUM_RETRIES = RxRingBuffer.SIZE * 2;
    for (int i = 0; i < 400; i++) {
        @SuppressWarnings(""unchecked"")
        Observer<String> observer = mock(Observer.class);
        Observable<String> origin = Observable.create(new FuncWithErrors(NUM_RETRIES));
        TestSubscriber<String> ts = new TestSubscriber<String>(observer);
        origin.retry().observeOn(Schedulers.computation()).unsafeSubscribe(ts);
        ts.awaitTerminalEvent(5, TimeUnit.SECONDS);
        InOrder inOrder = inOrder(observer);
        verify(observer, never()).onError(any(Throwable.class));
        inOrder.verify(observer, times(NUM_RETRIES + 1)).onNext(""beginningEveryTime"");
        inOrder.verify(observer, times(1)).onNext(""onSuccessOnly"");
        inOrder.verify(observer, times(1)).onCompleted();
        inOrder.verifyNoMoreInteractions();
    }
}"
"@Test
void shouldCompleteLogWhenCancelledByClient(SessionProtocol protocol) {
    final ClientFactory factory = ClientFactory.builder().build();
    final WebClient client = WebClient.builder(server.uri(protocol)).factory(factory).build();
    final CompletableFuture<AggregatedHttpResponse> responseFuture = client.get(""/reset"").aggregate();
    await().untilAtomic(ctxRef, Matchers.notNullValue());
    factory.close();
    final RequestLog log = ctxRef.get().log().whenComplete().join();
    if (protocol.isMultiplex()) {
        assertThat(log.responseCause()).isInstanceOf(ClosedStreamException.class).hasMessageContaining(""received a RST_STREAM frame: CANCEL"");
        assertThatThrownBy(responseFuture::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedStreamException.class);
    } else {
        assertThat(log.responseCause()).isInstanceOf(ClosedSessionException.class);
        assertThatThrownBy(responseFuture::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedSessionException.class);
    }
}"
"@Test
public void testCompositeKeys() {
    EntityHelper.initEntityNameMap(UserCompositeKeys.class, config);
    EntityTable entityTable = EntityHelper.getEntityTable(UserCompositeKeys.class);
    Assert.assertNotNull(entityTable);
    Set<EntityColumn> columns = entityTable.getEntityClassColumns();
    Assert.assertEquals(2, columns.size());
    Assert.assertEquals(2, entityTable.getEntityClassPKColumns().size());
    for (EntityColumn column : columns) {
        Assert.assertTrue(column.isId());
    }
    ResultMap resultMap = entityTable.getResultMap(configuration);
    Assert.assertEquals(2, resultMap.getResultMappings().size());
    Assert.assertTrue(resultMap.getResultMappings().get(0).getFlags().contains(ID));
    Assert.assertTrue(resultMap.getResultMappings().get(1).getFlags().contains(ID));
    Assert.assertEquals(""<where> AND name = #{name} AND orgId = #{orgId}</where>"", SqlHelper.wherePKColumns(UserCompositeKeys.class));
}"
"    @TestAnnotation(""libcore.java.lang.OldClassTest$ExtendTestClass"")
        public void setCount(int value) {

        }
"
"    @TestAnnotation(""libcore.java.lang.OldClassTest$PublicTestClass"")
        public Object getLocalClass() {
            class LocalClass {}
            Object returnedObject = new LocalClass();
            return returnedObject;
        }
"
"        @TestAnno
        public void annotatedMethod(){}

"
"    @Test
    public void testStatusEmpty()
    {
        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(new ArrayList<>());

        List<ScheduledRepairJob> response = GSON.fromJson(repairManagementREST.status(), scheduledRepairJobListType);

        assertThat(response).isEmpty();
    }
"
"    @Test
    public void testStatusEntry()
    {
        long repairInterval = TimeUnit.DAYS.toMillis(7);
        long lastRepairedAt = System.currentTimeMillis();

        RepairJobView repairJobView = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(lastRepairedAt)
                .withRepairInterval(repairInterval)
                .build();
        ScheduledRepairJob expectedResponse = new ScheduledRepairJob(repairJobView);

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.singletonList(repairJobView));

        List<ScheduledRepairJob> response = GSON.fromJson(repairManagementREST.status(), scheduledRepairJobListType);

        assertThat(response).containsExactly(expectedResponse);
    }
"
"    @Test
    public void testStatusMultipleEntries()
    {
        RepairJobView job1 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(1234L)
                .withRepairInterval(11)
                .build();
        RepairJobView job2 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withLastRepairedAt(2345L)
                .withRepairInterval(12)
                .build();
        RepairJobView job3 = new TestUtils.OnDemandRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withCompletedAt(3456L)
                .build();
        List<RepairJobView> repairJobViews = Arrays.asList(
                job1,
                job2,
                job3
        );

        List<ScheduledRepairJob> expectedResponse = repairJobViews.stream()
                .map(ScheduledRepairJob::new)
                .collect(Collectors.toList());

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(repairJobViews);

        List<ScheduledRepairJob> response = GSON.fromJson(repairManagementREST.status(), scheduledRepairJobListType);

        assertThat(response).isEqualTo(expectedResponse);
    }
"
"    @Test
    public void testKeyspaceStatusEmpty()
    {
        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(new ArrayList<>());

        List<ScheduledRepairJob> response = GSON.fromJson(repairManagementREST.keyspaceStatus(""""), scheduledRepairJobListType);

        assertThat(response).isEmpty();
    }
"
"    @Test
    public void testKeyspaceStatusNonExisting()
    {
        long expectedLastRepairedAt = 234;
        long expectedRepairInterval = 123;

        RepairJobView repairJobView = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(expectedLastRepairedAt)
                .withRepairInterval(expectedRepairInterval)
                .build();

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.singletonList(repairJobView));

        List<ScheduledRepairJob> response = GSON.fromJson(repairManagementREST.keyspaceStatus(""nonexistingkeyspace""), scheduledRepairJobListType);

        assertThat(response).isEmpty();
    }
"
"    @Test
    public void testKeyspaceStatusEntry()
    {
        long expectedLastRepairedAt = 234;
        long repairInterval = 123;

        RepairJobView repairJobView = new TestUtils.ScheduledRepairJobBuilder()
            .withKeyspace(""ks"")
            .withTable(""tb"")
            .withLastRepairedAt(expectedLastRepairedAt)
            .withRepairInterval(repairInterval)
            .build();
        ScheduledRepairJob expectedResponse = new ScheduledRepairJob(repairJobView);

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.singletonList(repairJobView));

        List<ScheduledRepairJob> response = GSON.fromJson(repairManagementREST.keyspaceStatus(""ks""), scheduledRepairJobListType);

        assertThat(response).containsExactly(expectedResponse);
    }
"
"    @Test
    public void testKeyspaceStatusMultipleEntries()
    {
        RepairJobView job1 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(1234L)
                .withRepairInterval(11)
                .build();
        RepairJobView job2 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withLastRepairedAt(2345L)
                .withRepairInterval(45)
                .build();
        RepairJobView job3 = new TestUtils.OnDemandRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withCompletedAt(3456L)
                .build();
        List<RepairJobView> repairJobViews = Arrays.asList(
                job1,
                job2,
                job3
        );
        List<ScheduledRepairJob> expectedResponse = repairJobViews.stream()
                .map(ScheduledRepairJob::new)
                .collect(Collectors.toList());

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(repairJobViews);

        List<ScheduledRepairJob> response = GSON.fromJson(repairManagementREST.keyspaceStatus(""ks""), scheduledRepairJobListType);

        assertThat(response).isEqualTo(expectedResponse);
    }
"
"    @Test
    public void testTableNonExisting()
    {
        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(new ArrayList<>());

        Map<Object, Object> response = GSON.fromJson(repairManagementREST.tableStatus(""ks"", ""tb""), new TypeToken<Map<Object, Object>>(){}.getType());

        assertThat(response).isEmpty();
    }
"
"    @Test
    public void testTableEntry() throws UnknownHostException
    {
        long expectedLastRepairedAt = 234;
        long repairInterval = 123;
        Node replica = mock(Node.class);
        when(replica.getPublicAddress()).thenReturn(InetAddress.getLocalHost());

        VnodeRepairState vnodeRepairState = TestUtils
                .createVnodeRepairState(2, 3, ImmutableSet.of(replica), expectedLastRepairedAt);
        RepairJobView repairJobView = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(expectedLastRepairedAt)
                .withRepairInterval(repairInterval)
                .withVnodeRepairStateSet(ImmutableSet.of(vnodeRepairState))
                .withStatus(Status.IN_QUEUE)
                .build();

        List<ScheduledRepairJob> expectedResponse = Collections.singletonList(new ScheduledRepairJob(repairJobView));

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.singletonList(repairJobView));

        List<ScheduledRepairJob> response = GSON.fromJson(repairManagementREST.tableStatus(""ks"", ""tb""), scheduledRepairJobListType);

        assertThat(response).isEqualTo(expectedResponse);
    }
"
"    @Test
    public void testTableMultipleEntries() throws UnknownHostException
    {
        Host host = mock(Host.class);
        when(host.getBroadcastAddress()).thenReturn(InetAddress.getLocalHost());
        RepairJobView job1 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(1234L)
                .withRepairInterval(11)
                .build();
        RepairJobView job2 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withLastRepairedAt(134L)
                .withRepairInterval(112)
                .build();
        RepairJobView job3 = new TestUtils.OnDemandRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withCompletedAt(3456L)
                .build();
        List<RepairJobView> repairJobViews = Arrays.asList(
                job1,
                job2,
                job3
        );

        List<ScheduledRepairJob> expectedResponse = repairJobViews.stream()
                .filter(job -> ""tb"".equals(job.getTableReference().getTable()))
                .map(ScheduledRepairJob::new)
                .collect(Collectors.toList());

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(repairJobViews);

        List<ScheduledRepairJob> response = GSON.fromJson(repairManagementREST.tableStatus(""ks"", ""tb""), scheduledRepairJobListType);

        assertThat(response).isEqualTo(expectedResponse);
    }
"
"    @Test
    public void testIdEntry() throws UnknownHostException
    {
        Host host = mock(Host.class);
        when(host.getBroadcastAddress()).thenReturn(InetAddress.getLocalHost());
        UUID expectedId = UUID.randomUUID();
        RepairJobView expectedRepairJob = new TestUtils.ScheduledRepairJobBuilder()
                .withId(expectedId)
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(1234L)
                .withRepairInterval(11)
                .build();
        RepairJobView job1 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withLastRepairedAt(134L)
                .withRepairInterval(112)
                .build();
        RepairJobView job2 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(132L)
                .withRepairInterval(132)
                .build();
        RepairJobView job3 = new TestUtils.OnDemandRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withCompletedAt(3456L)
                .build();

        CompleteRepairJob expectedResponse = new CompleteRepairJob(expectedRepairJob);

        List<RepairJobView> repairJobViews = Arrays.asList(
                expectedRepairJob,
                job3,
                job1,
                job2
        );

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(repairJobViews);

        CompleteRepairJob response = GSON.fromJson(repairManagementREST.jobStatus(expectedId.toString()), CompleteRepairJob.class);

        assertThat(response).isEqualTo(expectedResponse);
    }
"
"    @Test
    public void testIdEntryNotFound() throws UnknownHostException
    {
        Host host = mock(Host.class);
        when(host.getBroadcastAddress()).thenReturn(InetAddress.getLocalHost());
        RepairJobView job1 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(1234L)
                .withRepairInterval(11)
                .build();
        RepairJobView job2 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withLastRepairedAt(134L)
                .withRepairInterval(112)
                .build();
        RepairJobView job3 = new TestUtils.OnDemandRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withCompletedAt(3456L)
                .build();
        List<RepairJobView> repairJobViews = Arrays.asList(
                job1,
                job2,
                job3
        );

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(repairJobViews);

        String response = repairManagementREST.jobStatus(UUID.randomUUID().toString());

        assertThat(response).isEqualTo(""{}"");
    }
"
"    @Test
    public void testIdEntryEmpty()
    {
        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.emptyList());

        String response = repairManagementREST.jobStatus(UUID.randomUUID().toString());

        assertThat(response).isEqualTo(""{}"");
    }
"
"    @Test
    public void testIdInvalidUUID()
    {
        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.emptyList());

        String response = repairManagementREST.jobStatus(""123"");

        assertThat(response).isEqualTo(""{}"");
    }
"
"    @Test
    public void testConfigEmpty()
    {
        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(new ArrayList<>());

        List<TableRepairConfig> response = GSON.fromJson(repairManagementREST.config(), tableRepairConfigListType);

        assertThat(response).isEmpty();
    }
"
"    @Test
    public void testConfigEntry()
    {
        // Given
        RepairConfiguration repairConfig = TestUtils.createRepairConfiguration(11, 2.2, 33, 44);
        RepairJobView repairJobView = new ScheduledRepairJobView(UUID.randomUUID(), myTableReferenceFactory.forTable(""ks"", ""tbl""), repairConfig, null, Status.IN_QUEUE, 0);
        TableRepairConfig expectedResponse = new TableRepairConfig(repairJobView);

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.singletonList(repairJobView));

        List<TableRepairConfig> response = GSON.fromJson(repairManagementREST.config(), tableRepairConfigListType);

        assertThat(response).containsExactly(expectedResponse);
    }
"
"    @Test
    public void testConfigMultipleEntries()
    {
        // Given
        RepairConfiguration repairConfig = TestUtils.createRepairConfiguration(11, 2.2, 33, 44);
        RepairJobView repairJobView = new ScheduledRepairJobView(UUID.randomUUID(), myTableReferenceFactory.forTable(""ks"", ""tbl""), repairConfig, null, Status.IN_QUEUE, 0);

        RepairConfiguration repairConfig2 = TestUtils.createRepairConfiguration(22, 3.3, 44, 55);
        RepairJobView repairJobView2 = new ScheduledRepairJobView(UUID.randomUUID(), myTableReferenceFactory.forTable(""ks2"", ""tbl""), repairConfig2, null, Status.IN_QUEUE, 0);

        RepairJobView repairJobView3 = new OnDemandRepairJobView(UUID.randomUUID(), myTableReferenceFactory.forTable(""ks"", ""tbl""), RepairConfiguration.DEFAULT, Status.IN_QUEUE, 0, System.currentTimeMillis());

        List<TableRepairConfig> expectedResponse = Arrays.asList(
                new TableRepairConfig(repairJobView),
                new TableRepairConfig(repairJobView2),
                new TableRepairConfig(repairJobView3)
        );

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Arrays.asList(repairJobView, repairJobView2, repairJobView3));

        List<TableRepairConfig> response = GSON.fromJson(repairManagementREST.config(), tableRepairConfigListType);

        assertThat(response).isEqualTo(expectedResponse);
    }
"
"    @Test
    public void testKeyspaceConfigEmpty()
    {
        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(new ArrayList<>());

        List<TableRepairConfig> response = GSON.fromJson(repairManagementREST.keyspaceConfig(""""), tableRepairConfigListType);

        assertThat(response).isEmpty();
    }
"
"    @Test
    public void testKeyspaceConfigNonExisting()
    {
        RepairConfiguration repairConfig = TestUtils.createRepairConfiguration(11, 2.2, 33, 44);
        RepairJobView repairJobView = new ScheduledRepairJobView(UUID.randomUUID(), myTableReferenceFactory.forTable(""ks"", ""tbl""), repairConfig, null, Status.IN_QUEUE, 0);

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.singletonList(repairJobView));

        List<TableRepairConfig> response = GSON.fromJson(repairManagementREST.keyspaceConfig(""nonexistingkeyspace""), tableRepairConfigListType);

        assertThat(response).isEmpty();
    }
"
"    @Test
    public void testKeyspaceConfigEntry()
    {
        RepairConfiguration repairConfig = TestUtils.createRepairConfiguration(11, 2.2, 33, 44);
        RepairJobView repairJobView = new ScheduledRepairJobView(UUID.randomUUID(), myTableReferenceFactory.forTable(""ks"", ""tbl""), repairConfig, null, Status.IN_QUEUE, 0);

        TableRepairConfig expectedResponse = new TableRepairConfig(repairJobView);

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.singletonList(repairJobView));

        List<TableRepairConfig> response = GSON.fromJson(repairManagementREST.keyspaceConfig(""ks""), tableRepairConfigListType);

        assertThat(response).containsExactly(expectedResponse);
    }
"
"    @Test
    public void testKeyspaceConfigMultipleEntries()
    {
        RepairConfiguration repairConfig = TestUtils.createRepairConfiguration(11, 2.2, 33, 44);
        RepairJobView repairJobView = new ScheduledRepairJobView(UUID.randomUUID(), myTableReferenceFactory.forTable(""ks"", ""tbl""), repairConfig, null, Status.IN_QUEUE, 0);

        RepairConfiguration repairConfig2 = TestUtils.createRepairConfiguration(22, 3.3, 44, 55);
        RepairJobView repairJobView2 = new ScheduledRepairJobView(UUID.randomUUID(), myTableReferenceFactory.forTable(""ks"", ""tbl2""), repairConfig2, null, Status.IN_QUEUE, 0);

        List<TableRepairConfig> expectedResponse = Arrays.asList(
                new TableRepairConfig(repairJobView),
                new TableRepairConfig(repairJobView2)
        );

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Arrays.asList(repairJobView, repairJobView2));

        List<TableRepairConfig> response = GSON.fromJson(repairManagementREST.keyspaceConfig(""ks""), tableRepairConfigListType);

        assertThat(response).isEqualTo(expectedResponse);
    }
"
"    @Test
    public void testTableConfigEmpty()
    {
        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(new ArrayList<>());

        Map<Object, Object> response = GSON.fromJson(repairManagementREST.tableConfig(""ks"", ""tbl""), new TypeToken<Map<Object, Object>>(){}.getType());

        assertThat(response).isEmpty();
    }
"
"    @Test
    public void testTableConfigNonExisting()
    {
        RepairConfiguration repairConfig = TestUtils.createRepairConfiguration(11, 2.2, 33, 44);
        RepairJobView repairJobView = new ScheduledRepairJobView(UUID.randomUUID(), myTableReferenceFactory.forTable(""ks"", ""tbl""), repairConfig, null, Status.IN_QUEUE, 0);

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.singletonList(repairJobView));

        Map<Object, Object> response = GSON.fromJson(repairManagementREST.tableConfig(""nonexisting"", ""tbl""), new TypeToken<Map<Object, Object>>(){}.getType());

        assertThat(response).isEmpty();
    }
"
"    @Test
    public void testTableConfigEntry()
    {
        RepairConfiguration repairConfig = TestUtils.createRepairConfiguration(11, 2.2, 33, 44);
        RepairJobView repairJobView = new ScheduledRepairJobView(UUID.randomUUID(), myTableReferenceFactory.forTable(""ks"", ""tbl""), repairConfig, null, Status.IN_QUEUE, 0);

        List<TableRepairConfig> expectedResponse = Collections.singletonList(new TableRepairConfig(repairJobView));

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.singletonList(repairJobView));

        List<TableRepairConfig> response = GSON.fromJson(repairManagementREST.tableConfig(""ks"", ""tbl""), tableRepairConfigListType);

        assertThat(response).isEqualTo(expectedResponse);
    }
"
"    @Test
    public void testConfigIdEntry() throws UnknownHostException
    {
        Host host = mock(Host.class);
        when(host.getBroadcastAddress()).thenReturn(InetAddress.getLocalHost());
        UUID expectedId = UUID.randomUUID();
        RepairJobView expectedRepairJob = new TestUtils.ScheduledRepairJobBuilder()
                .withId(expectedId)
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(1234L)
                .withRepairInterval(11)
                .build();
        RepairJobView job1 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withLastRepairedAt(134L)
                .withRepairInterval(112)
                .build();
        RepairJobView job2 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(132L)
                .withRepairInterval(132)
                .build();
        RepairJobView job3 = new TestUtils.OnDemandRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withCompletedAt(3456L)
                .build();

        TableRepairConfig expectedResponse = new TableRepairConfig(expectedRepairJob);

        List<RepairJobView> repairJobViews = Arrays.asList(
                expectedRepairJob,
                job3,
                job1,
                job2
        );

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(repairJobViews);

        TableRepairConfig response = GSON.fromJson(repairManagementREST.jobConfig(expectedId.toString()), TableRepairConfig.class);
        assertThat(response).isEqualTo(expectedResponse);
    }
"
"    @Test
    public void testConfigIdEntryNotFound() throws UnknownHostException
    {
        Host host = mock(Host.class);
        when(host.getBroadcastAddress()).thenReturn(InetAddress.getLocalHost());
        RepairJobView job1 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(1234L)
                .withRepairInterval(11)
                .build();
        RepairJobView job2 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withLastRepairedAt(134L)
                .withRepairInterval(112)
                .build();
        RepairJobView job3 = new TestUtils.OnDemandRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withCompletedAt(3456L)
                .build();
        List<RepairJobView> repairJobViews = Arrays.asList(
                job1,
                job2,
                job3
        );

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(repairJobViews);

        String response = repairManagementREST.jobConfig(UUID.randomUUID().toString());

        assertThat(response).isEqualTo(""{}"");
    }
"
"    @Test
    public void testConfigIdEntryEmpty()
    {
        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.emptyList());

        String response = repairManagementREST.jobConfig(UUID.randomUUID().toString());

        assertThat(response).isEqualTo(""{}"");
    }
"
"    @Test
    public void testConfigIdInvalidUUID()
    {
        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.emptyList());

        String response = repairManagementREST.jobConfig(""123"");

        assertThat(response).isEqualTo(""{}"");
    }
"
"    @Test
    public void testScheduleRepair() throws EcChronosException
    {
        long expectedLastRepairedAt = 234;
        long repairInterval = 123;

        RepairJobView repairJobView = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(expectedLastRepairedAt)
                .withRepairInterval(repairInterval)
                .build();
        ScheduledRepairJob expectedResponse = new ScheduledRepairJob(repairJobView);

        when(myOnDemandRepairScheduler.scheduleJob(myTableReferenceFactory.forTable(""ks"",""tb""))).thenReturn(repairJobView);
        ScheduledRepairJob response = GSON.fromJson(repairManagementREST.scheduleJob(""ks"", ""tb""), ScheduledRepairJob.class);
        assertThat(response).isEqualTo(expectedResponse);
    }
"
"    @Test
    public void testCloseAllLocks()
    {
        List<DummyLock> locks = new ArrayList<>();
        for (int i = 0; i < 10; i++)
        {
            locks.add(new DummyLock());
        }

        new LockCollection(locks).close();

        for (DummyLock lock : locks)
        {
            assertThat(lock.closed).isTrue();
        }
    }
"
"    @Test
    public void testCloseAllLocksOneThrowing()
    {
        List<DistributedLock> locks = new ArrayList<>();
        for (int i = 0; i < 4; i++)
        {
            locks.add(new DummyLock());
        }

        locks.add(new ThrowingLock());

        for (int i = 0; i < 5; i++)
        {
            locks.add(new DummyLock());
        }

        new LockCollection(locks).close();

        for (DistributedLock lock : locks)
        {
            if (lock instanceof DummyLock)
            {
                assertThat(((DummyLock) lock).closed).isTrue();
            }
        }
    }
"
"    @Test
    public void testInsertRemoveOne()
    {
        DummyJob job = new DummyJob(Priority.LOW);

        queue.add(job);

        assertThat(queue.iterator()).toIterable().containsExactly(job);
    }
"
"    @Test
    public void testInsertDifferentPrio()
    {
        DummyJob job = new DummyJob(Priority.LOW);
        DummyJob job2 = new DummyJob(Priority.HIGH);

        queue.add(job);
        queue.add(job2);

        assertThat(queue.iterator()).toIterable().containsExactly(job2, job);
    }
"
"    @Test
    public void testEmptyQueue()
    {
        assertThat(queue.iterator()).toIterable().isEmpty();
    }
"
"    @Test
    public void testNonRunnableQueueIsEmpty() throws ScheduledJobException
    {
        final int nJobs = 10;

        for (int i = 0; i < nJobs; i++)
        {
            queue.add(new RunnableOnce(Priority.LOW));
        }

        for (ScheduledJob job : queue)
        {
            job.postExecute(true, null);
        }

        assertThat(queue.iterator()).toIterable().isEmpty();
    }
"
"    @Test
    public void testRemoveJobInQueueIsPossible()
    {
        DummyJob job = new DummyJob(Priority.HIGH);
        DummyJob job2 = new DummyJob(Priority.LOW);

        queue.add(job);
        queue.add(job2);

        Iterator<ScheduledJob> iterator = queue.iterator();

        queue.remove(job2);

        assertThat(iterator).toIterable().containsExactly(job, job2);
        assertThat(queue.iterator()).toIterable().containsExactly(job);
    }
"
"    @Test
    public void testRunOnceJobRemovedOnFinish()
    {
        StateJob job = new StateJob(ScheduledJob.Priority.LOW, ScheduledJob.State.FINISHED);
        StateJob job2 = new StateJob(ScheduledJob.Priority.LOW, ScheduledJob.State.RUNNABLE);

        queue.add(job);
        queue.add(job2);

        for (ScheduledJob next : queue)
        {
            assertThat(next.getState()).isEqualTo(ScheduledJob.State.RUNNABLE);
        }

        assertThat(queue.size()).isEqualTo(1);
        assertThat(queue.iterator()).toIterable().containsExactly(job2);
    }
"
"    @Test
    public void testRunOnceJobRemovedOnFailure()
    {
        StateJob job = new StateJob(ScheduledJob.Priority.LOW, ScheduledJob.State.FAILED);
        StateJob job2 = new StateJob(ScheduledJob.Priority.LOW, ScheduledJob.State.RUNNABLE);

        queue.add(job);
        queue.add(job2);

        for (ScheduledJob next : queue)
        {
            assertThat(next.getState()).isEqualTo(ScheduledJob.State.RUNNABLE);
        }

        assertThat(queue.size()).isEqualTo(1);
        assertThat(queue.iterator()).toIterable().containsExactly(job2);
    }
"
"    @Test
    public void testRunningNoJobs() throws LockException
    {
        myScheduler.run();

        verify(myLockFactory, never()).tryLock(any(), anyString(), anyInt(), anyMap());
    }
"
"    @Test
    public void testRunningOneJob()
    {
        DummyJob job = new DummyJob(ScheduledJob.Priority.LOW);
        myScheduler.schedule(job);

        myScheduler.run();

        assertThat(job.hasRun()).isTrue();
        assertThat(myScheduler.getQueueSize()).isEqualTo(1);
    }
"
"    @Test
    public void testRunningJobWithFailingRunPolicy()
    {
        DummyJob job = new DummyJob(ScheduledJob.Priority.LOW);
        myScheduler.schedule(job);

        when(myRunPolicy.validate(any(ScheduledJob.class))).thenReturn(1L);

        myScheduler.run();

        assertThat(job.hasRun()).isFalse();
        assertThat(myScheduler.getQueueSize()).isEqualTo(1);
    }
"
"    @Test
    public void testRunningTwoTasksStoppedAfterFirstByPolicy() throws LockException
    {
        ShortRunningMultipleTasks job = new ShortRunningMultipleTasks(ScheduledJob.Priority.LOW, 2, () -> {
            when(myRunPolicy.validate(any(ScheduledJob.class))).thenReturn(1L);
        });
        myScheduler.schedule(job);

        when(myLockFactory.tryLock(any(), anyString(), anyInt(), anyMap())).thenReturn(new DummyLock());

        myScheduler.run();

        assertThat(job.getNumRuns()).isEqualTo(1);
        assertThat(myScheduler.getQueueSize()).isEqualTo(1);
        verify(myLockFactory).tryLock(any(), anyString(), anyInt(), anyMap());
    }
"
"    @Test
    public void testRunningJobWithThrowingRunPolicy()
    {
        DummyJob job = new DummyJob(ScheduledJob.Priority.LOW);
        myScheduler.schedule(job);

        when(myRunPolicy.validate(any(ScheduledJob.class))).thenThrow(new IllegalStateException());

        myScheduler.run();

        assertThat(job.hasRun()).isFalse();
        assertThat(myScheduler.getQueueSize()).isEqualTo(1);
    }
"
"    @Test
    public void testRunningOneJobWithThrowingLock() throws LockException
    {
        DummyJob job = new DummyJob(ScheduledJob.Priority.LOW);
        myScheduler.schedule(job);

        when(myLockFactory.tryLock(any(), anyString(), anyInt(), anyMap())).thenThrow(new LockException(""""));

        myScheduler.run();

        assertThat(job.hasRun()).isFalse();
        assertThat(myScheduler.getQueueSize()).isEqualTo(1);
    }
"
"    @Test (timeout = 2000L)
    public void testRunningTwoJobsInParallelShouldFail() throws InterruptedException
    {
        LongRunningJob job = new LongRunningJob(ScheduledJob.Priority.HIGH);
        LongRunningJob job2 = new LongRunningJob(ScheduledJob.Priority.LOW);
        myScheduler.schedule(job);
        myScheduler.schedule(job2);

        final CountDownLatch cdl = new CountDownLatch(1);

        new Thread()
        {

            @Override
            public void run()
            {
                myScheduler.run();
                cdl.countDown();
            }
"
"    @Test
    public void testTwoJobsRejected()
    {
        DummyJob job = new DummyJob(ScheduledJob.Priority.LOW);
        DummyJob job2 = new DummyJob(ScheduledJob.Priority.LOW);
        myScheduler.schedule(job);
        myScheduler.schedule(job2);

        when(myRunPolicy.validate(any(ScheduledJob.class))).thenReturn(1L);

        myScheduler.run();

        assertThat(job.hasRun()).isFalse();
        assertThat(myScheduler.getQueueSize()).isEqualTo(2);
        verify(myRunPolicy, times(2)).validate(any(ScheduledJob.class));
    }
"
"    @Test
    public void testTwoJobsThrowingLock() throws LockException
    {
        DummyJob job = new DummyJob(ScheduledJob.Priority.LOW);
        DummyJob job2 = new DummyJob(ScheduledJob.Priority.LOW);
        myScheduler.schedule(job);
        myScheduler.schedule(job2);

        when(myLockFactory.tryLock(any(), anyString(), anyInt(), anyMap())).thenThrow(new LockException(""""));

        myScheduler.run();

        assertThat(job.hasRun()).isFalse();
        assertThat(myScheduler.getQueueSize()).isEqualTo(2);
        verify(myLockFactory, times(2)).tryLock(any(), anyString(), anyInt(), anyMap());
    }
"
"    @Test
    public void testThreeTasksOneThrowing() throws LockException
    {
        ShortRunningMultipleTasks job = new ShortRunningMultipleTasks(ScheduledJob.Priority.LOW, 3);
        myScheduler.schedule(job);

        when(myLockFactory.tryLock(any(), anyString(), anyInt(), anyMap()))
                .thenReturn(new DummyLock())
                .thenThrow(new LockException(""""))
                .thenReturn(new DummyLock());

        myScheduler.run();

        assertThat(job.getNumRuns()).isEqualTo(2);
        assertThat(myScheduler.getQueueSize()).isEqualTo(1);
        verify(myLockFactory, times(3)).tryLock(any(), anyString(), anyInt(), anyMap());
    }
"
"    @Test (timeout = 2000L)
    public void testRemoveLongRunningJob() throws InterruptedException
    {
        LongRunningJob job = new LongRunningJob(ScheduledJob.Priority.HIGH);
        myScheduler.schedule(job);

        final CountDownLatch cdl = new CountDownLatch(1);

        new Thread()
        {
            @Override
            public void run()
            {
                myScheduler.run();
                cdl.countDown();
            }
"
"    @Test
    public void testGetLock() throws LockException
    {
        DistributedLock expectedLock = doReturnLockOnGetLock();

        assertGetLockRetrievesExpectedLock(expectedLock);
    }
"
"    @Test
    public void testGetThrowingLockIsCached() throws LockException
    {
        LockException expectedExcetion = doThrowOnGetLock();

        assertGetLockThrowsException(expectedExcetion);

        // Reset return type, locking should still throw
        doReturnLockOnGetLock();

        assertGetLockThrowsException(expectedExcetion);
    }
"
"    @Test
    public void testGetMultipleLocks() throws LockException
    {
        String otherResource = ""RepairResource-b2e33e60-7af6-11e9-8f9e-2a86e4085a59-1"";

        DistributedLock expectedLock = doReturnLockOnGetLock(RESOURCE);
        DistributedLock expectedOtherLock = doReturnLockOnGetLock(otherResource);

        assertGetLockRetrievesExpectedLock(RESOURCE, expectedLock);
        assertGetLockRetrievesExpectedLock(otherResource, expectedOtherLock);
    }
"
"    @Test
    public void testGetOtherLockAfterThrowingOnAnotherResource() throws LockException
    {
        String otherResource = ""RepairResource-b2e33e60-7af6-11e9-8f9e-2a86e4085a59-1"";

        LockException expectedException = doThrowOnGetLock(RESOURCE);
        DistributedLock expectedOtherLock = doReturnLockOnGetLock(otherResource);

        assertGetLockThrowsException(RESOURCE, expectedException);
        assertGetLockRetrievesExpectedLock(otherResource, expectedOtherLock);
    }
"
"    @Test
    public void testGetLockAfterCachedExceptionHasExpired() throws LockException, InterruptedException
    {
        myLockCache = new LockCache(mockedLockSupplier, 20, TimeUnit.MILLISECONDS);

        LockException expectedException = doThrowOnGetLock();
        assertGetLockThrowsException(expectedException);

        Thread.sleep(20);

        DistributedLock expectedLock = doReturnLockOnGetLock();
        assertGetLockRetrievesExpectedLock(expectedLock);
    }
"
"    @Test
    public void testEqualsContract()
    {
        EqualsVerifier.forClass(LockCache.LockKey.class).usingGetClass().verify();
    }
"
"    @Test
    public void testUseNullJmxProxyFactoryShouldThrow()
    {
        assertThatExceptionOfType(IllegalArgumentException.class)
                .isThrownBy(() -> HostStatesImpl.builder()
                        .withJmxProxyFactory(null)
                        .build());
    }
"
"    @Test
    public void testIsInetAddressUp() throws UnknownHostException
    {
        InetAddress expectedAddress = InetAddress.getLocalHost();

        List<String> expectedLiveNodes = Collections.singletonList(expectedAddress.getHostName());
        List<String> expectedUnreachableNodes = Collections.emptyList();

        when(myJmxProxy.getLiveNodes()).thenReturn(expectedLiveNodes);
        when(myJmxProxy.getUnreachableNodes()).thenReturn(expectedUnreachableNodes);

        assertThat(myHostStates.isUp(expectedAddress)).isTrue();
    }
"
"    @Test
    public void testIsHostUp() throws UnknownHostException
    {
        InetAddress expectedAddress = InetAddress.getLocalHost();
        Host expectedHost = mock(Host.class);

        List<String> expectedLiveNodes = Collections.singletonList(expectedAddress.getHostName());
        List<String> expectedUnreachableNodes = Collections.emptyList();

        when(myJmxProxy.getLiveNodes()).thenReturn(expectedLiveNodes);
        when(myJmxProxy.getUnreachableNodes()).thenReturn(expectedUnreachableNodes);

        when(expectedHost.getBroadcastAddress()).thenReturn(expectedAddress);

        assertThat(myHostStates.isUp(expectedHost)).isTrue();
    }
"
"    @Test
    public void testIsInetAddressUpFaultyNode() throws UnknownHostException
    {
        InetAddress expectedAddress = InetAddress.getLocalHost();

        when(myJmxProxy.getLiveNodes()).thenReturn(Collections.emptyList());
        when(myJmxProxy.getUnreachableNodes()).thenReturn(Collections.emptyList());

        assertThat(myHostStates.isUp(expectedAddress)).isFalse();
    }
"
"    @Test
    public void testNodeIsNotRefreshed() throws UnknownHostException
    {
        final InetAddress expectedAddress = InetAddress.getLocalHost();

        when(myJmxProxy.getLiveNodes()).thenAnswer(new Answer<List<String>>()
        {
            private int counter = 0;

            @Override
            public List<String> answer(InvocationOnMock invocation)
            {
                if (counter++ == 2)
                {
                    return Collections.singletonList(expectedAddress.getHostAddress());
                }

                return Collections.emptyList();
            }
"
"    @Test
    public void testNodeIsRefreshed() throws UnknownHostException
    {
        final InetAddress expectedAddress = InetAddress.getLocalHost();

        HostStatesImpl hostStates = HostStatesImpl.builder()
                .withJmxProxyFactory(myJmxProxyFactory)
                .withRefreshIntervalInMs(1)
                .build();

        when(myJmxProxy.getLiveNodes()).thenAnswer(new Answer<List<String>>()
        {
            private int counter = 0;

            @Override
            public List<String> answer(InvocationOnMock invocation)
            {
                if (counter++ == 1)
                {
                    return Collections.singletonList(expectedAddress.getHostAddress());
                }
                return Collections.emptyList();
            }
"
"    @Test
    public void testConfigureNewTable()
    {
        RepairSchedulerImpl repairSchedulerImpl = defaultRepairSchedulerImplBuilder().build();

        repairSchedulerImpl.putConfiguration(TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        verify(scheduleManager, timeout(1000)).schedule(any(ScheduledJob.class));
        verify(scheduleManager, never()).deschedule(any(ScheduledJob.class));
        verify(myRepairStateFactory).create(eq(TABLE_REFERENCE), eq(RepairConfiguration.DEFAULT), any());
        verify(myRepairState, atLeastOnce()).update();
        assertOneTableViewExist(repairSchedulerImpl, TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        repairSchedulerImpl.close();
        verify(scheduleManager).deschedule(any(ScheduledJob.class));

        verifyNoMoreInteractions(ignoreStubs(myTableRepairMetrics));
        verifyNoMoreInteractions(myRepairStateFactory);
        verifyNoMoreInteractions(scheduleManager);
    }
"
"    @Test
    public void testConfigureTwoTables()
    {
        RepairSchedulerImpl repairSchedulerImpl = defaultRepairSchedulerImplBuilder().build();

        repairSchedulerImpl.putConfiguration(TABLE_REFERENCE, RepairConfiguration.DEFAULT);
        repairSchedulerImpl.putConfiguration(TABLE_REFERENCE2, RepairConfiguration.DEFAULT);

        verify(scheduleManager, timeout(1000).times(2)).schedule(any(ScheduledJob.class));
        verify(scheduleManager, never()).deschedule(any(ScheduledJob.class));
        verify(myRepairStateFactory).create(eq(TABLE_REFERENCE), eq(RepairConfiguration.DEFAULT), any());
        verify(myRepairStateFactory).create(eq(TABLE_REFERENCE2), eq(RepairConfiguration.DEFAULT), any());
        verify(myRepairState, atLeastOnce()).update();

        repairSchedulerImpl.close();
        verify(scheduleManager, times(2)).deschedule(any(ScheduledJob.class));

        verifyNoMoreInteractions(ignoreStubs(myTableRepairMetrics));
        verifyNoMoreInteractions(myRepairStateFactory);
        verifyNoMoreInteractions(scheduleManager);
    }
"
"    @Test
    public void testRemoveTableConfiguration()
    {
        RepairSchedulerImpl repairSchedulerImpl = defaultRepairSchedulerImplBuilder().build();

        repairSchedulerImpl.putConfiguration(TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        verify(scheduleManager, timeout(1000)).schedule(any(ScheduledJob.class));
        verify(scheduleManager, never()).deschedule(any(ScheduledJob.class));
        verify(myRepairStateFactory).create(eq(TABLE_REFERENCE), eq(RepairConfiguration.DEFAULT), any());
        verify(myRepairState, atLeastOnce()).update();
        assertOneTableViewExist(repairSchedulerImpl, TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        repairSchedulerImpl.removeConfiguration(TABLE_REFERENCE);
        verify(scheduleManager, timeout(1000)).deschedule(any(ScheduledJob.class));
        assertThat(repairSchedulerImpl.getCurrentRepairJobs()).isEmpty();

        repairSchedulerImpl.close();
        verifyNoMoreInteractions(ignoreStubs(myTableRepairMetrics));
        verifyNoMoreInteractions(myRepairStateFactory);
        verifyNoMoreInteractions(scheduleManager);
    }
"
"    @Test
    public void testUpdateTableConfiguration()
    {
        RepairSchedulerImpl repairSchedulerImpl = defaultRepairSchedulerImplBuilder().build();

        long expectedUpdatedRepairInterval = TimeUnit.DAYS.toMillis(1);

        RepairConfiguration updatedRepairConfiguration = RepairConfiguration.newBuilder()
                .withRepairInterval(expectedUpdatedRepairInterval, TimeUnit.MILLISECONDS)
                .build();

        repairSchedulerImpl.putConfiguration(TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        verify(scheduleManager, timeout(1000)).schedule(any(ScheduledJob.class));
        verify(scheduleManager, never()).deschedule(any(ScheduledJob.class));
        verify(myRepairStateFactory).create(eq(TABLE_REFERENCE), eq(RepairConfiguration.DEFAULT), any());
        verify(myRepairState, atLeastOnce()).update();
        assertOneTableViewExist(repairSchedulerImpl, TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        repairSchedulerImpl.putConfiguration(TABLE_REFERENCE, updatedRepairConfiguration);

        verify(scheduleManager, timeout(1000).times(2)).schedule(any(ScheduledJob.class));
        verify(scheduleManager, timeout(1000)).deschedule(any(ScheduledJob.class));
        verify(myRepairStateFactory).create(eq(TABLE_REFERENCE), eq(updatedRepairConfiguration), any());
        verify(myRepairState, atLeastOnce()).update();
        assertOneTableViewExist(repairSchedulerImpl, TABLE_REFERENCE, updatedRepairConfiguration);

        repairSchedulerImpl.close();
        verify(scheduleManager, times(2)).deschedule(any(ScheduledJob.class));
        assertThat(repairSchedulerImpl.getCurrentRepairJobs()).isEmpty();

        verifyNoMoreInteractions(ignoreStubs(myTableRepairMetrics));
        verifyNoMoreInteractions(myRepairStateFactory);
        verifyNoMoreInteractions(scheduleManager);
    }
"
"    @Test
    public void testUpdateTableConfigurationToSame()
    {
        RepairSchedulerImpl repairSchedulerImpl = defaultRepairSchedulerImplBuilder().build();

        repairSchedulerImpl.putConfiguration(TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        verify(scheduleManager, timeout(1000)).schedule(any(ScheduledJob.class));
        verify(scheduleManager, never()).deschedule(any(ScheduledJob.class));
        verify(myRepairStateFactory).create(eq(TABLE_REFERENCE), eq(RepairConfiguration.DEFAULT), any());
        verify(myRepairState, atLeastOnce()).update();
        assertOneTableViewExist(repairSchedulerImpl, TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        repairSchedulerImpl.putConfiguration(TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        assertOneTableViewExist(repairSchedulerImpl, TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        repairSchedulerImpl.close();
        verify(scheduleManager).deschedule(any(ScheduledJob.class));
        assertThat(repairSchedulerImpl.getCurrentRepairJobs()).isEmpty();

        verifyNoMoreInteractions(ignoreStubs(myTableRepairMetrics));
        verifyNoMoreInteractions(myRepairStateFactory);
        verifyNoMoreInteractions(scheduleManager);
    }
"
"    @Test
    public void testJobCorrectlyReturned()
    {
        OnDemandRepairJob repairJob = createOnDemandRepairJob();
        RepairJobView expectedView = new OnDemandRepairJobView(repairJob.getId(), myTableReference, RepairConfiguration.DEFAULT, RepairJobView.Status.IN_QUEUE, 0, System.currentTimeMillis());
        assertThat(repairJob.getId()).isEqualTo(repairJob.getId());
        assertThat(repairJob.getLastSuccessfulRun()).isEqualTo(-1);
        assertThat(repairJob.getRepairConfiguration()).isEqualTo(RepairConfiguration.DEFAULT);
        assertThat(repairJob.getTableReference()).isEqualTo(myTableReference);
        assertThat(repairJob.getView().getRepairConfiguration()).isEqualTo(expectedView.getRepairConfiguration());
        assertThat(repairJob.getView().getRepairStateSnapshot()).isNull();
        assertThat(repairJob.getView().getTableReference()).isEqualTo(expectedView.getTableReference());
        assertThat(repairJob.getView().getStatus()).isEqualTo(expectedView.getStatus());
    }
"
"    @Test
    public void testFailedJobCorrectlyReturned()
    {
        OnDemandRepairJob repairJob = createOnDemandRepairJob();
        Iterator<ScheduledTask> it = repairJob.iterator();
        repairJob.postExecute(false, it.next());
        RepairJobView expectedView = new OnDemandRepairJobView(repairJob.getId(), myTableReference, RepairConfiguration.DEFAULT, RepairJobView.Status.ERROR, 0, System.currentTimeMillis());
        assertThat(repairJob.getLastSuccessfulRun()).isEqualTo(-1);
        assertThat(repairJob.getRepairConfiguration()).isEqualTo(RepairConfiguration.DEFAULT);
        assertThat(repairJob.getTableReference()).isEqualTo(myTableReference);
        assertThat(repairJob.getView().getRepairConfiguration()).isEqualTo(expectedView.getRepairConfiguration());
        assertThat(repairJob.getView().getRepairStateSnapshot()).isNull();
        assertThat(repairJob.getView().getTableReference()).isEqualTo(expectedView.getTableReference());
        assertThat(repairJob.getView().getStatus()).isEqualTo(expectedView.getStatus());
    }
"
"    @Test
    public void testJobFinishedAfterExecution()
    {
        OnDemandRepairJob repairJob = createOnDemandRepairJob();
        Iterator<ScheduledTask> it = repairJob.iterator();
        assertThat(repairJob.getState()).isEqualTo(ScheduledJob.State.RUNNABLE);
        repairJob.postExecute(true, it.next());
        assertThat(repairJob.getState()).isEqualTo(ScheduledJob.State.RUNNABLE);
        repairJob.postExecute(true, it.next());
        assertThat(repairJob.getState()).isEqualTo(ScheduledJob.State.FINISHED);
    }
"
"    @Test
    public void testJobFinishedAfterRestart()
    {
        OnDemandRepairJob repairJob = createRestartedOnDemandRepairJob();
        Iterator<ScheduledTask> it = repairJob.iterator();
        assertThat(repairJob.getState()).isEqualTo(ScheduledJob.State.RUNNABLE);
        repairJob.postExecute(true, it.next());
        assertThat(repairJob.getState()).isEqualTo(ScheduledJob.State.FINISHED);
    }
"
"    @Test
    public void testJobFailedWhenTopologyChange()
    {
        OnDemandRepairJob repairJob = createOnDemandRepairJob();
        when(myOngoingJob.hasTopologyChanged()).thenReturn(true);
        assertThat(repairJob.getState()).isEqualTo(ScheduledJob.State.FAILED);
    }
"
"    @Test
    public void testJobUnsuccessful()
    {
        OnDemandRepairJob repairJob = createOnDemandRepairJob();
        Iterator<ScheduledTask> it = repairJob.iterator();
        repairJob.postExecute(true, it.next());
        assertThat(repairJob.getState()).isEqualTo(ScheduledJob.State.RUNNABLE);
        repairJob.postExecute(false, it.next());
        assertThat(repairJob.getState()).isEqualTo(ScheduledJob.State.FAILED);
    }
"
"    @Test
    public void testGetProgress()
    {
        OnDemandRepairJob repairJob = createOnDemandRepairJob();
        assertThat(repairJob.getProgress()).isEqualTo(0);
        Iterator<ScheduledTask> it = repairJob.iterator();
        repairJob.postExecute(true, it.next());
        assertThat(repairJob.getProgress()).isEqualTo(0.5);
        repairJob.postExecute(true, it.next());
        assertThat(repairJob.getProgress()).isEqualTo(1);
    }
"
"    @Test
    public void testScheduleRepairOnTable() throws EcChronosException
    {
        OnDemandRepairSchedulerImpl repairScheduler = defaultOnDemandRepairSchedulerImplBuilder().build();
        when(metadata.getKeyspace(TABLE_REFERENCE.getKeyspace())).thenReturn(myKeyspaceMetadata);
        when(myKeyspaceMetadata.getTable(TABLE_REFERENCE.getTable())).thenReturn(myTableMetadata);

        verify(scheduleManager, never()).schedule(any(ScheduledJob.class));
        RepairJobView repairJobView = repairScheduler.scheduleJob(TABLE_REFERENCE);
        verify(scheduleManager).schedule(any(ScheduledJob.class));

        assertTableViewExist(repairScheduler, repairJobView);

        repairScheduler.close();
        verify(scheduleManager).deschedule(any(ScheduledJob.class));

        verifyNoMoreInteractions(ignoreStubs(myTableRepairMetrics));
        verifyNoMoreInteractions(scheduleManager);
    }
"
"    @Test
    public void testScheduleTwoRepairOnTable() throws EcChronosException
    {
        OnDemandRepairSchedulerImpl repairScheduler = defaultOnDemandRepairSchedulerImplBuilder().build();
        when(metadata.getKeyspace(TABLE_REFERENCE.getKeyspace())).thenReturn(myKeyspaceMetadata);
        when(myKeyspaceMetadata.getTable(TABLE_REFERENCE.getTable())).thenReturn(myTableMetadata);

        verify(scheduleManager, never()).schedule(any(ScheduledJob.class));
        RepairJobView repairJobView = repairScheduler.scheduleJob(TABLE_REFERENCE);
        RepairJobView repairJobView2 = repairScheduler.scheduleJob(TABLE_REFERENCE);
        verify(scheduleManager, times(2)).schedule(any(ScheduledJob.class));

        assertTableViewExist(repairScheduler, repairJobView, repairJobView2);

        repairScheduler.close();
        verify(scheduleManager, times(2)).deschedule(any(ScheduledJob.class));

        verifyNoMoreInteractions(ignoreStubs(myTableRepairMetrics));
        verifyNoMoreInteractions(scheduleManager);
    }
"
"    @Test
    public void testRestartRepairOnTable() throws EcChronosException
    {
        Set<OngoingJob> ongoingJobs = new HashSet<>();
        ongoingJobs.add(myOngingJob);
        when(myOnDemandStatus.getOngoingJobs(replicationState)).thenReturn(ongoingJobs);

        OnDemandRepairSchedulerImpl repairScheduler = defaultOnDemandRepairSchedulerImplBuilder().build();

        verify(scheduleManager, timeout(1000)).schedule(any(ScheduledJob.class));

        repairScheduler.close();
        verify(scheduleManager).deschedule(any(ScheduledJob.class));

        verifyNoMoreInteractions(ignoreStubs(myTableRepairMetrics));
        verifyNoMoreInteractions(scheduleManager);
    }
"
"    @Test
    public void testRestartRepairOnTableWithException() throws EcChronosException
    {
        Set<OngoingJob> ongoingJobs = new HashSet<>();
        ongoingJobs.add(myOngingJob);
        Map<EndPoint, Throwable> errors = new HashMap<>();
        when(myOnDemandStatus.getOngoingJobs(replicationState)).thenThrow(new NoHostAvailableException(errors )).thenReturn(ongoingJobs);

        OnDemandRepairSchedulerImpl repairScheduler = defaultOnDemandRepairSchedulerImplBuilder().build();

        verify(scheduleManager, timeout(15000)).schedule(any(ScheduledJob.class));

        repairScheduler.close();
        verify(scheduleManager).deschedule(any(ScheduledJob.class));

        verifyNoMoreInteractions(ignoreStubs(myTableRepairMetrics));
        verifyNoMoreInteractions(scheduleManager);
    }
"
"    @Test (expected = EcChronosException.class)
    public void testScheduleRepairOnNonExistentKeyspaceTable() throws EcChronosException
    {
        OnDemandRepairSchedulerImpl repairScheduler = defaultOnDemandRepairSchedulerImplBuilder().build();

        verify(scheduleManager, never()).schedule(any(ScheduledJob.class));
        repairScheduler.scheduleJob(TABLE_REFERENCE);
    }
"
"    @Test (expected = EcChronosException.class)
    public void testScheduleRepairOnNonExistentTable() throws EcChronosException
    {
        OnDemandRepairSchedulerImpl repairScheduler = defaultOnDemandRepairSchedulerImplBuilder().build();
        when(metadata.getKeyspace(TABLE_REFERENCE.getKeyspace())).thenReturn(myKeyspaceMetadata);
        verify(scheduleManager, never()).schedule(any(ScheduledJob.class));
        repairScheduler.scheduleJob(TABLE_REFERENCE);
    }
"
"    @Test (expected = EcChronosException.class)
    public void testScheduleRepairOnNull() throws EcChronosException
    {
        OnDemandRepairSchedulerImpl repairScheduler = defaultOnDemandRepairSchedulerImplBuilder().build();
        verify(scheduleManager, never()).schedule(any(ScheduledJob.class));
        repairScheduler.scheduleJob(null);
    }
"
"    @Test
    public void testRepairResource()
    {
        RepairResource repairResource = new RepairResource(""dc1"", ""my-resource"");

        assertThat(repairResource.getDataCenter()).isEqualTo(""dc1"");
        assertThat(repairResource.getResourceName(1)).isEqualTo(""RepairResource-my-resource-1"");
        assertThat(repairResource.getResourceName(2)).isEqualTo(""RepairResource-my-resource-2"");
    }
"
"    @Test
    public void testRepairResourceEquality()
    {
        RepairResource repairResource = new RepairResource(""dc1"", ""my-resource"");
        RepairResource equalRepairResource = new RepairResource(""dc1"", ""my-resource"");
        RepairResource repairResourceWithDifferentDc = new RepairResource(""dc2"", ""my-resource"");
        RepairResource repairResourceWithDifferentResource = new RepairResource(""dc1"", ""not-my-resource"");

        assertThat(repairResource).isEqualTo(equalRepairResource);
        assertThat(repairResource).isNotEqualTo(repairResourceWithDifferentDc);
        assertThat(repairResource).isNotEqualTo(repairResourceWithDifferentResource);
    }
"
"    @Test
    public void testEqualsContract()
    {
        EqualsVerifier.forClass(RepairResource.class).usingGetClass().verify();
    }
"
"    @Test
    public void testPrevalidateNotRepairable()
    {
        // mock
        doReturn(false).when(myRepairStateSnapshot).canRepair();

        assertThat(myRepairJob.runnable()).isFalse();

        verify(myRepairState, times(1)).update();
        verify(myRepairStateSnapshot, times(1)).canRepair();
    }
"
"    @Test
    public void testPrevalidateNeedRepair()
    {
        // mock
        doReturn(true).when(myRepairStateSnapshot).canRepair();

        assertThat(myRepairJob.runnable()).isTrue();

        verify(myRepairState, times(1)).update();
        verify(myRepairStateSnapshot, times(1)).canRepair();
    }
"
"    @Test
    public void testPrevalidateNotRepairableThenRepairable()
    {
        // mock
        doReturn(false).doReturn(true).when(myRepairStateSnapshot).canRepair();

        assertThat(myRepairJob.runnable()).isFalse();
        assertThat(myRepairJob.runnable()).isTrue();

        verify(myRepairState, times(2)).update();
        verify(myRepairStateSnapshot, times(2)).canRepair();
    }
"
"    @Test
    public void testPrevalidateUpdateThrowsOverloadException()
    {
        // mock
        doReturn(false).when(myRepairStateSnapshot).canRepair();
        doThrow(new OverloadedException(null, ""Expected exception"")).when(myRepairState).update();

        assertThat(myRepairJob.runnable()).isFalse();

        verify(myRepairStateSnapshot, times(1)).canRepair();
    }
"
"    @Test
    public void testPrevalidateUpdateThrowsException()
    {
        // mock
        doReturn(false).when(myRepairStateSnapshot).canRepair();
        doThrow(new RuntimeException(""Expected exception"")).when(myRepairState).update();

        assertThat(myRepairJob.runnable()).isFalse();

        verify(myRepairStateSnapshot, times(1)).canRepair();
    }
"
"    @Test
    public void testPostExecuteRepaired()
    {
        // mock
        long repairedAt = System.currentTimeMillis();
        doReturn(repairedAt).when(myRepairStateSnapshot).lastCompletedAt();
        doReturn(false).when(myRepairStateSnapshot).canRepair();

        myRepairJob.postExecute(true, null);

        assertThat(myRepairJob.getLastSuccessfulRun()).isEqualTo(repairedAt);
        verify(myRepairState, times(1)).update();
    }
"
"    @Test
    public void testPostExecuteRepairedWithFailure()
    {
        // mock
        long repairedAt = System.currentTimeMillis();
        doReturn(repairedAt).when(myRepairStateSnapshot).lastCompletedAt();
        doReturn(false).when(myRepairStateSnapshot).canRepair();

        myRepairJob.postExecute(false, null);

        assertThat(myRepairJob.getLastSuccessfulRun()).isEqualTo(repairedAt);
        verify(myRepairState, times(1)).update();
    }
"
"    @Test
    public void testPostExecuteNotRepaired()
    {
        // mock
        doReturn(true).when(myRepairStateSnapshot).canRepair();

        long lastRun = myRepairJob.getLastSuccessfulRun();

        myRepairJob.postExecute(true, null);

        assertThat(myRepairJob.getLastSuccessfulRun()).isEqualTo(lastRun);
        verify(myRepairState, times(1)).update();
    }
"
"    @Test
    public void testPostExecuteNotRepairedWithFailure()
    {
        // mock
        doReturn(true).when(myRepairStateSnapshot).canRepair();

        long lastRun = myRepairJob.getLastSuccessfulRun();

        myRepairJob.postExecute(false, null);

        assertThat(myRepairJob.getLastSuccessfulRun()).isEqualTo(lastRun);
        verify(myRepairState, times(1)).update();
    }
"
"    @Test
    public void testPostExecuteUpdateThrowsException()
    {
        // mock
        doThrow(new RuntimeException(""Expected exception"")).when(myRepairState).update();

        long lastRun = myRepairJob.getLastSuccessfulRun();

        myRepairJob.postExecute(true, null);

        assertThat(myRepairJob.getLastSuccessfulRun()).isEqualTo(lastRun);
    }
"
"    @Test
    public void testGetView()
    {
        VnodeRepairState vnodeRepairState = TestUtils.createVnodeRepairState(1, 2, ImmutableSet.of(), System.currentTimeMillis());
        VnodeRepairStatesImpl vnodeRepairStates = VnodeRepairStatesImpl.newBuilder(Arrays.asList(vnodeRepairState)).build();
        when(myRepairStateSnapshot.getVnodeRepairStates()).thenReturn(vnodeRepairStates);
        RepairJobView repairJobView = myRepairJob.getView();

        assertThat(repairJobView.getId()).isEqualTo(myTableReference.getId());
        assertThat(repairJobView.getTableReference()).isEqualTo(myTableReference);
        assertThat(repairJobView.getRepairConfiguration()).isEqualTo(myRepairConfiguration);
        assertThat(repairJobView.getRepairStateSnapshot()).isEqualTo(myRepairStateSnapshot);
        assertThat(repairJobView.getStatus()).isEqualTo(RepairJobView.Status.ERROR);
    }
"
"    @Test
    public void testIterator()
    {
        LongTokenRange tokenRange = new LongTokenRange(0, 10);
        ImmutableSet<Node> replicas = ImmutableSet.of(mock(Node.class), mock(Node.class));
        ImmutableList<LongTokenRange> vnodes = ImmutableList.of(tokenRange);

        VnodeRepairStates vnodeRepairStates = VnodeRepairStatesImpl
                .newBuilder(ImmutableList.of(new VnodeRepairState(tokenRange, replicas, 1234L)))
                .build();
        ReplicaRepairGroup replicaRepairGroup = new ReplicaRepairGroup(replicas, vnodes);

        RepairStateSnapshot repairStateSnapshot = RepairStateSnapshot.newBuilder()
                .withReplicaRepairGroups(Collections.singletonList(replicaRepairGroup))
                .withLastCompletedAt(1234L)
                .withVnodeRepairStates(vnodeRepairStates)
                .build();
        when(myRepairState.getSnapshot()).thenReturn(repairStateSnapshot);

        Iterator<ScheduledTask> iterator = myRepairJob.iterator();

        ScheduledTask task = iterator.next();
        assertThat(task).isInstanceOf(RepairGroup.class);
        Collection<RepairTask> repairTasks = ((RepairGroup)task).getRepairTasks();

        assertThat(repairTasks).hasSize(1);
        RepairTask repairTask = repairTasks.iterator().next();
        assertThat(repairTask.getReplicas()).containsExactlyInAnyOrderElementsOf(replicas);
        assertThat(repairTask.getTokenRanges()).containsExactly(tokenRange);
        assertThat(repairTask.getRepairConfiguration()).isEqualTo(myRepairConfiguration);
        assertThat(repairTask.getTableReference()).isEqualTo(myTableReference);
    }
"
"    @Test
    public void testIteratorWithTargetSize()
    {
        List<LongTokenRange> expectedTokenRanges = Arrays.asList(
                new LongTokenRange(0, 1),
                new LongTokenRange(1, 2),
                new LongTokenRange(2, 3),
                new LongTokenRange(3, 4),
                new LongTokenRange(4, 5),
                new LongTokenRange(5, 6),
                new LongTokenRange(6, 7),
                new LongTokenRange(7, 8),
                new LongTokenRange(8, 9),
                new LongTokenRange(9, 10)
        );

        LongTokenRange tokenRange = new LongTokenRange(0, 10);
        ImmutableSet<Node> replicas = ImmutableSet.of(mock(Node.class), mock(Node.class));
        ImmutableList<LongTokenRange> vnodes = ImmutableList.of(tokenRange);

        VnodeRepairStates vnodeRepairStates = VnodeRepairStatesImpl.newBuilder(ImmutableList.of(new VnodeRepairState(tokenRange, replicas, 1234L))).build();
        ReplicaRepairGroup replicaRepairGroup = new ReplicaRepairGroup(replicas, vnodes);

        RepairStateSnapshot repairStateSnapshot = RepairStateSnapshot.newBuilder()
                .withReplicaRepairGroups(Collections.singletonList(replicaRepairGroup))
                .withLastCompletedAt(1234L)
                .withVnodeRepairStates(vnodeRepairStates)
                .build();
        when(myRepairState.getSnapshot()).thenReturn(repairStateSnapshot);
        // 100 MB target size, 1000MB in table
        when(myTableStorageStates.getDataSize(eq(myTableReference))).thenReturn(THOUSAND_MB_IN_BYTES);

        Iterator<ScheduledTask> iterator = myRepairJob.iterator();

        ScheduledTask task = iterator.next();
        assertThat(task).isInstanceOf(RepairGroup.class);
        Collection<RepairTask> repairTasks = ((RepairGroup)task).getRepairTasks();

        assertThat(repairTasks).hasSize(expectedTokenRanges.size());

        Iterator<RepairTask> repairTaskIterator = repairTasks.iterator();
        for (LongTokenRange expectedRange : expectedTokenRanges)
        {
            assertThat(repairTaskIterator.hasNext()).isTrue();
            RepairTask repairTask = repairTaskIterator.next();
            assertThat(repairTask.getReplicas()).containsExactlyInAnyOrderElementsOf(replicas);
            assertThat(repairTask.getRepairConfiguration()).isEqualTo(myRepairConfiguration);
            assertThat(repairTask.getTableReference()).isEqualTo(myTableReference);

            assertThat(repairTask.getTokenRanges()).containsExactly(expectedRange);
        }
    }
"
"    @Test
    public void testStatusCompleted()
    {
        long repairedAt = System.currentTimeMillis();
        doReturn(repairedAt).when(myRepairStateSnapshot).lastCompletedAt();
        VnodeRepairState vnodeRepairState = TestUtils.createVnodeRepairState(1, 2, ImmutableSet.of(), repairedAt);
        VnodeRepairStatesImpl vnodeRepairStates = VnodeRepairStatesImpl.newBuilder(Arrays.asList(vnodeRepairState)).build();
        when(myRepairStateSnapshot.getVnodeRepairStates()).thenReturn(vnodeRepairStates);

        assertThat(myRepairJob.getView().getStatus()).isEqualTo(RepairJobView.Status.COMPLETED);
    }
"
"    @Test
    public void testStatusError()
    {
        long repairedAt = System.currentTimeMillis() - TimeUnit.DAYS.toMillis(10);
        VnodeRepairState vnodeRepairState = TestUtils.createVnodeRepairState(1, 2, ImmutableSet.of(), repairedAt);
        VnodeRepairStatesImpl vnodeRepairStates = VnodeRepairStatesImpl.newBuilder(Arrays.asList(vnodeRepairState)).build();
        when(myRepairStateSnapshot.getVnodeRepairStates()).thenReturn(vnodeRepairStates);
        doReturn(repairedAt).when(myRepairStateSnapshot).lastCompletedAt();

        assertThat(myRepairJob.getView().getStatus()).isEqualTo(RepairJobView.Status.ERROR);
    }
"
"    @Test
    public void testStatusInQueue()
    {
        long repairedAt = System.currentTimeMillis() - TimeUnit.DAYS.toMillis(1);
        VnodeRepairState vnodeRepairState = TestUtils.createVnodeRepairState(1, 2, ImmutableSet.of(), repairedAt);
        VnodeRepairStatesImpl vnodeRepairStates = VnodeRepairStatesImpl.newBuilder(Arrays.asList(vnodeRepairState)).build();
        when(myRepairStateSnapshot.getVnodeRepairStates()).thenReturn(vnodeRepairStates);
        doReturn(repairedAt).when(myRepairStateSnapshot).lastCompletedAt();

        assertThat(myRepairJob.getView().getStatus()).isEqualTo(RepairJobView.Status.IN_QUEUE);
    }
"
"    @Test
    public void testStatusWarning()
    {
        long repairedAt = System.currentTimeMillis() - TimeUnit.DAYS.toMillis(7);
        VnodeRepairState vnodeRepairState = TestUtils.createVnodeRepairState(1, 2, ImmutableSet.of(), repairedAt);
        VnodeRepairStatesImpl vnodeRepairStates = VnodeRepairStatesImpl.newBuilder(Arrays.asList(vnodeRepairState)).build();
        when(myRepairStateSnapshot.getVnodeRepairStates()).thenReturn(vnodeRepairStates);
        doReturn(repairedAt).when(myRepairStateSnapshot).lastCompletedAt();

        assertThat(myRepairJob.getView().getStatus()).isEqualTo(RepairJobView.Status.WARNING);
    }
"
"	@Test
	public void testParseDevOpsCompany() {
		PairingBoard pairingBoard = new PairingBoard(null, null, null);
		
		assertThat(pairingBoard.parseDevOpsCompanies(""devops:company""), is(new String[] {""company""}));
		assertThat(pairingBoard.parseDevOpsCompanies(""devops:company,companyb""), is(new String[] {""company"", ""companyb""}));
		assertThat(pairingBoard.parseDevOpsCompanies(""devops:""), is(new String[] {}));
	}
"
"	@Test
	public void testGetAndSetDevs()  {
		Pair subject = new Pair();
		subject.setDevs(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		
		assertThat(subject.getDevs(), is(equalTo(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")))));
	}
"
"	@Test
	public void testGetAndSetDevsWithNullValues()  {
		Pair subject = new Pair();
		subject.setDevs(Arrays.asList(null, new Developer(""dev2"")));
		
		assertThat(subject.getDevs(), is(equalTo(Arrays.asList(new Developer(""dev2"")))));
	}
"
"	@Test
	public void testAddDev()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.getDevs(), is(equalTo(Arrays.asList(new Developer(""dev1"")))));
	}
"
"	@Test
	public void testAddDevWithNull()  {
		Pair subject = new Pair();
		
		subject.addDev(null);
		
		assertThat(subject.getDevs().isEmpty(), is(true));
	}
"
"	@Test
	public void testHasDev()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.hasDev(new Developer(""dev1"")), is(true));
	}
"
"	@Test
	public void testGetOtherDev()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		
		assertThat(subject.getOtherDev(new Developer(""dev1"")), is(equalTo(new Developer(""dev2""))));
	}
"
"	@Test
	public void testOtherDevWithOneDev()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.getOtherDev(new Developer(""dev1"")), nullValue());
	}
"
"	@Test
	public void testIsComplete()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		
		assertThat(subject.isComplete(), is(true));
	}
"
"	@Test
	public void testIsCompleteWithOneDev()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.isComplete(), is(false));
	}
"
"	@Test
	public void testToString()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.toString(), is(equalTo(""Pair [devs=[dev1], opsPair=false, locked=false]"")));
	}
"
"	@Test
	public void testHashCode()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.hashCode(), is(equalTo(subject2.hashCode())));
	}
"
"	@Test
	public void testHashCodeNotEqual()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev2"")));
		
		assertThat(subject.hashCode(), is(not(equalTo(subject2.hashCode()))));
	}
"
"	@Test
	public void testEqual()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.equals(subject2), is(true));
	}
"
"	@Test
	public void testEqualWithOpsTrue()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		subject.setOpsPair(true);
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev1"")));
		subject2.setOpsPair(true);
		
		assertThat(subject.equals(subject2), is(true));
	}
"
"	@Test
	public void testEqualDifferentPairs()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev2"")));
		
		assertThat(subject.equals(subject2), is(false));
	}
"
"	@Test
	public void testIsSolo()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		
		assertThat(subject.equals(subject2), is(false));
	}
"
"	@Test
	public void testIsBuildPairFalse()  {
		Pair subject = new Pair();
		
		subject.setBuildPair(false);
		
		assertThat(subject.isBuildPair(), is(false));
	}
"
"	@Test
	public void testIsBuildPairTrue()  {
		Pair subject = new Pair();
		
		subject.setBuildPair(true);
		
		assertThat(subject.isBuildPair(), is(true));
	}
"
"	@Test
	public void testIsCommunitydPairFalse()  {
		Pair subject = new Pair();
		
		subject.setCommunityPair(false);
		
		assertThat(subject.isCommunityPair(), is(false));
	}
"
"	@Test
	public void testIsOpsPairTrue()  {
		Pair subject = new Pair();
		
		subject.setOpsPair(true);
		
		assertThat(subject.isOpsPair(), is(true));
	}
"
"	@Test
	public void testIsOpsPairFalse()  {
		Pair subject = new Pair();
		
		subject.setOpsPair(false);
		
		assertThat(subject.isOpsPair(), is(false));
	}
"
"	@Test
	public void testIsCommunityPairTrue()  {
		Pair subject = new Pair();
		
		subject.setCommunityPair(true);
		
		assertThat(subject.isCommunityPair(), is(true));
	}
"
"	@Test
	public void testTrackDefault() {
		Pair subject = new Pair();
		
		assertThat(subject.getTrack(), is(""""));
	}
"
"	@Test
	public void testTrackSet() {
		Pair subject = new Pair();
		
		subject.setTrack(""track"");
		
		assertThat(subject.getTrack(), is(""track""));
	}
"
"	@Test
	public void testGetPairsReturnOnlyDevPairs() {
		List<DayPairs> pairsListFromDevs = getPairsListFromDevs(getStandardDevs(), false);
		Pair opsPair = pairsListFromDevs.get(0).getPairByTrack(""track1"");
		opsPair.setOpsPair(true);
		
		List<Pair> pairs = new OpsPairCombinations(pairsListFromDevs).getPairs();
		
		assertThat(pairs.contains(opsPair), is(true));
		assertThat(pairs.size(), is(1));
	}
"
"	@Test
	public void testGetPastPairs() {
		List<Developer> standardDevs = getStandardDevs();
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(getPairsListFromDevs(standardDevs));
		
		
		assertThat(devPairCombinations.getPastPairs(0), is(getPairsListFromDevs(standardDevs).get(0).getPairs().values().stream().collect(Collectors.toList())));
		assertThat(devPairCombinations.getPastPairs(1), is(getPairsListFromDevs(standardDevs).get(1).getPairs().values().stream().collect(Collectors.toList())));
		assertThat(devPairCombinations.getPastPairs(2), is(getPairsListFromDevs(standardDevs).get(2).getPairs().values().stream().collect(Collectors.toList())));
	}
"
"	@Test
	public void testGetPastPairsFiltersOps() {
		List<DayPairs> pairsListFromDevs = getPairsListFromDevs(getStandardDevs(), false);
		Pair opsPair = pairsListFromDevs.get(0).getPairByTrack(""track1"");
		opsPair.setOpsPair(true);
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(pairsListFromDevs);
		
		
		assertThat(devPairCombinations.getPastPairs(0), is(Arrays.asList(pairsListFromDevs.get(0).getPairByTrack(""track1""))));
	}
"
"	@Test
	public void testGetPastPairsForMissingHistory() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairs(3), is(nullValue()));
	}
"
"	@Test
	public void testGetPastPairByTrack() {
		List<Developer> standardDevs = getStandardDevs();
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(getPairsListFromDevs(standardDevs));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(0, ""track1""), is(getPairsListFromDevs(standardDevs).get(0).getPairByTrack(""track1"")));
		assertThat(devPairCombinations.getPastPairByTrack(1, ""track2""), is(getPairsListFromDevs(standardDevs).get(1).getPairByTrack(""track2"")));
		assertThat(devPairCombinations.getPastPairByTrack(2, ""track1""), is(getPairsListFromDevs(standardDevs).get(2).getPairByTrack(""track1"")));
	}
"
"	@Test(expected =  RuntimeException.class)
	public void testGetPastPairByTrackThrowsRuntimeErrorForOpsPair() {
		List<DayPairs> pairsListFromDevs = getPairsListFromDevs(getStandardDevs(), false);
		Pair opsPair = pairsListFromDevs.get(0).getPairByTrack(""track1"");
		opsPair.setOpsPair(true);
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(pairsListFromDevs);
		
		
		devPairCombinations.getPastPairByTrack(0, ""track2"");
	}
"
"	@Test
	public void testGetPastPairByTrackForMissingHistory() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(3, ""track1""), is(nullValue()));
	}
"
"	@Test
	public void testGetPastPairByTrackForMissingTrack() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(1, ""track5""), is(nullValue()));
	}
"
"	@Test
	public void testIsRotationTimeForEmptyHistory() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(new ArrayList<>());
		Company company = new Company(""myCompany"");
		company.setDevOpsRotationStrategy(""weekly"");
		devPairCombinations.setCompany(company);

		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1""), getStandardDevs(), false), is(false));
	}
"
"	@Test
	public void testIsRotationTimeForEmptyHistoryWithEveryDayRotation() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(new ArrayList<>());
		Company company = new Company(""myCompany"");
		company.setDevOpsRotationStrategy(""weekly"");
		devPairCombinations.setCompany(company);

		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1""), getStandardDevs(), true), is(false));
	}
"
"	@Test
	public void testIsRotationTimeForEmptyHistoryWithEveryDayRotationAnNoWeeklyRotation() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(new ArrayList<>());

		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1""), getStandardDevs(), true), is(true));
	}
"
"	@Test
	public void testIsRotationTimeForSameWeek() {
		List<Developer> standardDevs = getStandardDevs();
		DayPairs pairs = new DayPairs();
		pairs.setDate(new Date());
		pairs.addPair(""track1"", new Pair(Arrays.asList(standardDevs.get(0), standardDevs.get(1)), true, ""track1""));
		
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(Arrays.asList(pairs));
		Company company = new Company(""myCompany"");
		company.setDevOpsRotationStrategy(""weekly"");
		devPairCombinations.setCompany(company);
		
		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1""), standardDevs, false), is(false));
	}
"
"	@Test
	public void testIsRotationTimeForSameWeekWithEveryDayRotation() {
		List<Developer> standardDevs = getStandardDevs();
		DayPairs pairs = new DayPairs();
		pairs.setDate(new Date());
		pairs.addPair(""track1"", new Pair(Arrays.asList(standardDevs.get(0), standardDevs.get(1)), true, ""track1""));
		
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(Arrays.asList(pairs));
		Company company = new Company(""myCompany"");
		company.setDevOpsRotationStrategy(""weekly"");
		devPairCombinations.setCompany(company);

		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1""), standardDevs, true), is(false));
	}
"
"	@Test
	public void testIsRotationForDifferentWeekPairs() {
		List<Developer> standardDevs = getStandardDevs();
		DayPairs pairs = new DayPairs();
		pairs.setDate(getDateWeeksBefore(1));
		pairs.addPair(""track1"", new Pair(Arrays.asList(standardDevs.get(0), standardDevs.get(1)), true, ""track1""));
		
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(Arrays.asList(pairs));
		Company company = new Company(""myCompany"");
		company.setDevOpsRotationStrategy(""weekly"");
		devPairCombinations.setCompany(company);

		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1""), standardDevs, false), is(true));
	}
"
"	@Test
	public void testId() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.getId(), is(""developerId""));
	}
"
"	@Test
	public void testCompanyDefault() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.getCompany().getName(), is(""""));
	}
"
"	@Test
	public void testCompany() {
		Developer developer = new Developer(""developerId"");
		developer.setCompany(new Company(""my-company""));
		
		assertThat(developer.getCompany().getName(), is(""my-company""));
	}
"
"	@Test
	public void testNew() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.getNew(), is(false));
		
		developer.setNew(true);
		
		assertThat(developer.getNew(), is(true));
	}
"
"	@Test
	public void testHasContext() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.hasContext(), is(false));
		
		developer.setHasContext(true);
		
		assertThat(developer.hasContext(), is(true));
	}
"
"	@Test
	public void testCompareTo() {
		Developer developer = new Developer(""developerId"");
		Developer developer2 = new Developer(""developerId2"");
		
		assertThat(developer.getId().compareTo(developer2.getId()), is(-1));
		assertThat(developer2.getId().compareTo(developer.getId()), is(1));
		assertThat(developer.getId().compareTo(developer.getId()), is(0));
	}
"
"	@Test
	public void testHashCodeOfEqualInstances() {
		Developer developer = new Developer(""developerId"");
		Developer sameDeveloper = new Developer(""developerId"");
		
		assertThat(developer.hashCode(), is(sameDeveloper.hashCode()));
	}
"
"	@Test
	public void testHashCodeOfDifferentInstances() {
		Developer developer = new Developer(""developerId"");
		Developer differentDeveloper = new Developer(""developerId2"");
		
		assertThat(developer.hashCode(), is(not(differentDeveloper.hashCode())));
	}
"
"	@Test
	public void testEqualsOfEqualInstances() {
		Developer developer = new Developer(""developerId"");
		Developer sameDeveloper = new Developer(""developerId"");
		
		assertThat(developer.equals(sameDeveloper), is(true));
		assertThat(sameDeveloper.equals(developer), is(true));
	}
"
"	@Test
	public void testEqualsOfDifferentInstances() {
		Developer developer = new Developer(""developerId"");
		Developer differentDeveloper = new Developer(""developerId2"");
		
		assertThat(developer.equals(differentDeveloper), is(false));
		assertThat(differentDeveloper.equals(developer), is(false));
	}
"
"	@Test
	public void testToString() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.toString(), is(""developerId""));
	}
"
"	@Test
	public void testGetTrackWeightDefault() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.getTrackWeight(""track""), is(0));
	}
"
"	@Test
	public void testGetTrackWeightOne() {
		Developer developer = new Developer(""developerId"");
		
		developer.updateTrackWeight(""track"");
		
		assertThat(developer.getTrackWeight(""track""), is(1));
	}
"
"	@Test
	public void testGetPairingDaysDefault() {
		Developer developer = new Developer(""developerId"");
		
		assertThat(developer.getPairingDays(), is(0));
	}
"
"	@Test
	public void testGetPairingDaysOne() {
		Developer developer = new Developer(""developerId"");
		
		developer.udpatePairingDays();
		
		assertThat(developer.getPairingDays(), is(1));
	}
"
"	@Test
	public void testGetPairsReturnOnlyDevPairs() {
		List<DayPairs> pairsListFromDevs = getPairsListFromDevs(getStandardDevs());
		Pair opsPair = pairsListFromDevs.get(0).getPairByTrack(""track1"");
		opsPair.setOpsPair(true);
		
		List<Pair> pairs = new DevPairCombinations(pairsListFromDevs).getPairs();
		
		assertThat(pairs.size(), is(5));
		for (Pair pair : pairs) {
			assertThat(pair.isOpsPair(), is(false));
		}
	}
"
"	@Test
	public void testGetPastPairs() {
		List<Developer> standardDevs = getStandardDevs();
		DevPairCombinations devPairCombinations = new DevPairCombinations(getPairsListFromDevs(standardDevs));
		
		
		assertThat(devPairCombinations.getPastPairs(0), is(getPairsListFromDevs(standardDevs).get(0).getPairs().values().stream().collect(Collectors.toList())));
		assertThat(devPairCombinations.getPastPairs(1), is(getPairsListFromDevs(standardDevs).get(1).getPairs().values().stream().collect(Collectors.toList())));
		assertThat(devPairCombinations.getPastPairs(2), is(getPairsListFromDevs(standardDevs).get(2).getPairs().values().stream().collect(Collectors.toList())));
	}
"
"	@Test
	public void testGetPastPairsFiltersOps() {
		List<DayPairs> pairsListFromDevs = getPairsListFromDevs(getStandardDevs());
		Pair opsPair = pairsListFromDevs.get(0).getPairByTrack(""track1"");
		opsPair.setOpsPair(true);
		DevPairCombinations devPairCombinations = new DevPairCombinations(pairsListFromDevs);
		
		
		assertThat(devPairCombinations.getPastPairs(0), is(Arrays.asList(pairsListFromDevs.get(0).getPairByTrack(""track2""))));
	}
"
"	@Test
	public void testGetPastPairsForMissingHistory() {
		DevPairCombinations devPairCombinations = new DevPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairs(3), is(nullValue()));
	}
"
"	@Test
	public void testGetPastPairByTrack() {
		List<Developer> standardDevs = getStandardDevs();
		DevPairCombinations devPairCombinations = new DevPairCombinations(getPairsListFromDevs(standardDevs));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(0, ""track1""), is(getPairsListFromDevs(standardDevs).get(0).getPairByTrack(""track1"")));
		assertThat(devPairCombinations.getPastPairByTrack(1, ""track2""), is(getPairsListFromDevs(standardDevs).get(1).getPairByTrack(""track2"")));
		assertThat(devPairCombinations.getPastPairByTrack(2, ""track1""), is(getPairsListFromDevs(standardDevs).get(2).getPairByTrack(""track1"")));
	}
"
"	@Test(expected =  RuntimeException.class)
	public void testGetPastPairByTrackThrowsRuntimeErrorForOpsPair() {
		List<DayPairs> pairsListFromDevs = getPairsListFromDevs(getStandardDevs());
		Pair opsPair = pairsListFromDevs.get(0).getPairByTrack(""track1"");
		opsPair.setOpsPair(true);
		DevPairCombinations devPairCombinations = new DevPairCombinations(pairsListFromDevs);
		
		
		assertThat(devPairCombinations.getPastPairByTrack(0, ""track1""), is(Arrays.asList(getPairsListFromDevs(getStandardDevs()).get(0).getPairByTrack(""track1""))));
	}
"
"	@Test
	public void testGetPastPairByTrackForMissingHistory() {
		DevPairCombinations devPairCombinations = new DevPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(3, ""track1""), is(nullValue()));
	}
"
"	@Test
	public void testGetPastPairByTrackForMissingTrack() {
		DevPairCombinations devPairCombinations = new DevPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(1, ""track4""), is(nullValue()));
	}
"
"	@Test
	public void testIsRotationTimeForTwoDayPair() {
		List<Developer> standardDevs = getStandardDevs();
		DevPairCombinations devPairCombinations = new DevPairCombinations(getPairsListFromDevs(standardDevs));
		
		
		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1"", ""track2""), standardDevs, false), is(true));
	}
"
"	@Test
	public void testIsRotationTimeForNewDevUnconformPair() {
		List<Developer> standardDevs = getStandardDevs();
		standardDevs.stream().forEach(developer -> developer.setNew(true));
		List<DayPairs> pastPairs = getPairsListFromDevs(standardDevs);
		pastPairs.remove(2);
		pastPairs.remove(1);		
		DevPairCombinations devPairCombinations = new DevPairCombinations(pastPairs);
		
		
		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1"", ""track2""), standardDevs, false), is(true));
	}
"
"	@Test
	public void testIsRotationForOneDayPair() {
		List<Developer> standardDevs = getStandardDevs();
		List<DayPairs> pastPairs = getPairsListFromDevs(standardDevs);
		pastPairs.remove(2);
		pastPairs.remove(1);
		DevPairCombinations devPairCombinations = new DevPairCombinations(pastPairs);
		
		
		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1"", ""track2""), standardDevs, false), is(false));
	}
"
"	@Test
	public void testIsRotationForOneDayPairWithEveryDayRotation() {
		List<Developer> standardDevs = getStandardDevs();
		List<DayPairs> pastPairs = getPairsListFromDevs(standardDevs);
		pastPairs.remove(2);
		pastPairs.remove(1);
		DevPairCombinations devPairCombinations = new DevPairCombinations(pastPairs);
		
		
		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1"", ""track2""), standardDevs, true), is(true));
	}
"
"	@Test
	public void testGetPairsNewInstance() {
		assertThat(new DayPairs().getPairs().isEmpty(), is(true));
	}
"
"	@Test
	public void testAddPairAndGetTracks(){
		HashMap<String, Pair> expectedPairs = new HashMap<String, Pair>();
		expectedPairs.put(""testTrack"", new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2""))));
		DayPairs pairs = new DayPairs();
		pairs.addPair(""testTrack"", expectedPairs.get(""testTrack""));
		
		assertThat(pairs.getPairs(), is(equalTo(expectedPairs)));
		assertThat(pairs.getTracks(), is(equalTo(new HashSet<>(Arrays.asList(""testTrack"")))));
	}
"
"	@Test
	public void testSetDate() throws ParseException {
		DayPairs pairs = new DayPairs();
		Date expectedDate = new Date();
		pairs.setDate(expectedDate);
		
		assertThat(pairs.getDate(), is(equalTo(getDateWithoutTime(expectedDate))));
	}
"
"	@Test
	public void testGetDate() throws ParseException {
		assertThat(new DayPairs().getDate(), is(equalTo(getDateWithoutTime(new Date()))));
	}
"
"	@Test
	public void testCompareTo() {
		DayPairs todaysPairs = new DayPairs();
		todaysPairs.setDate(new Date());
		DayPairs yesterdayPairs = new DayPairs();
		yesterdayPairs.setDate(getYesterdayDate());
		
		assertThat(todaysPairs.compareTo(yesterdayPairs), is(equalTo(1)));
		assertThat(yesterdayPairs.compareTo(todaysPairs), is(equalTo(-1)));
		assertThat(todaysPairs.compareTo(todaysPairs), is(equalTo(0)));
	}
"
"	@Test
	public void testGetPairByTrack() {
		Pair pair1 = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		Pair pair2 = new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")));
		DayPairs pairs = new DayPairs();
		pairs.addPair(""track1"", pair1);
		pairs.addPair(""track2"", pair2);
		
		assertThat(pairs.getPairByTrack(""track1""), is(equalTo(pair1)));
		assertThat(pairs.getPairByTrack(""track2""), is(equalTo(pair2)));
	}
"
"	@Test
	public void testHashCode() {
		DayPairs pairsOfToday = new DayPairs();
		DayPairs differentPairsOfToday = new DayPairs();
		DayPairs yesterdayPairs = new DayPairs();
		yesterdayPairs.setDate(getYesterdayDate());
		Pair pair1 = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		Pair pair2 = new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")));
		pairsOfToday.addPair(""track1"", pair1);
		differentPairsOfToday.addPair(""track2"", pair2);
		yesterdayPairs.addPair(""track1"", pair1);
		
		assertThat(pairsOfToday.hashCode(), is(equalTo(differentPairsOfToday.hashCode())));
		assertThat(yesterdayPairs.hashCode(), is(not(equalTo(pairsOfToday.hashCode()))));
	}
"
"	@Test
	public void testEquals() {
		DayPairs pairsOfToday = new DayPairs();
		DayPairs differentPairsOfToday = new DayPairs();
		DayPairs yesterdayPairs = new DayPairs();
		yesterdayPairs.setDate(getYesterdayDate());
		Pair pair1 = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		Pair pair2 = new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")));
		pairsOfToday.addPair(""track1"", pair1);
		differentPairsOfToday.addPair(""track2"", pair2);
		yesterdayPairs.addPair(""track1"", pair1);
		
		assertThat(pairsOfToday, is(equalTo(differentPairsOfToday)));
		assertThat(yesterdayPairs, is(not(equalTo(pairsOfToday))));
	}
"
"	@Test
	public void testToString() {
		DayPairs pairs = new DayPairs();
		Pair pair = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		pairs.addPair(""track"", pair);
		
		assertThat(pairs.toString(), is(equalTo(""Pairs [pairs="" + pairs.getPairs() + "", date="" + pairs.format(pairs.getDate()) + ""]"")));
	}
"
"	@Test
	public void testHasPair() {
		DayPairs pairs = new DayPairs();
		Pair pair = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		Pair differentPair = new Pair();
		pairs.addPair(""track"", pair);
		
		assertThat(pairs.hasPair(pair), is(true));
		assertThat(pairs.hasPair(differentPair), is(false));
	}
"
"	@Test
	public void testReplacePairWith() {
		DayPairs pairs = new DayPairs();
		Pair pair = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		Pair differentPair = new Pair();
		pairs.addPair(""track"", pair);
		
		assertThat(pairs.hasPair(pair), is(true));
		assertThat(pairs.hasPair(differentPair), is(false));
		
		pairs.replacePairWith(pair, differentPair);
		
		assertThat(pairs.hasPair(pair), is(false));
		assertThat(pairs.hasPair(differentPair), is(true));
	}
"
"	@Test
	public void testGetTrackByPair() {
		DayPairs pairs = new DayPairs();
		Pair pair = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		Pair differentPair = new Pair();
		pairs.addPair(""track"", pair);
		
		assertThat(pairs.getTrackByPair(pair), is(equalTo(""track"")));
		assertThat(pairs.getTrackByPair(differentPair), is(nullValue()));
	}
"
"	@Test
	public void testSimpleDateFormatNotPersisted() throws NoSuchFieldException, SecurityException {
		DayPairs pairs = new DayPairs();
		Field dateFormatterField = pairs.getClass().getDeclaredField(""dateFormatter"");
		dateFormatterField.setAccessible(true);
		Transient annotation = dateFormatterField.getAnnotation(Transient.class);
		
		assertThat(annotation, is(not(nullValue())));
	}
"
"	@Test
	public void testGetCompanyName() {
		assertThat(new Company(""company"").getName(), is(""company""));
	}
"
"	@Test
	public void testGetCompanyNameWithSaces() {
		assertThat(new Company(""  company  "").getName(), is(""company""));
	}
"
"	@Test
	public void testGetCompanyNameWithUpperCase() {
		assertThat(new Company(""COMPANY"").getName(), is(""company""));
	}
"
"	@Test
	public void testGetCompanyOriginalName() {
		assertThat(new Company(""Company"").getOriginalName(), is(""Company""));
	}
"
"	@Test
	public void testGetTrack() {
		assertThat(new Company(""Company"").getTrack(), is(""COMPANY-ops/interrupt""));
	}
"
"	@Test
	public void testGetCompanyExperiencedDevs() {
		Developer developerCompanyA = new Developer(""a"");
		developerCompanyA.setCompany(new Company(""a""));
		Developer newDeveloperCompanyA = new Developer(""a"");
		newDeveloperCompanyA.setCompany(new Company(""a""));
		newDeveloperCompanyA.setNew(true);
		Developer developerCompanyB = new Developer(""b"");
		developerCompanyB.setCompany(new Company(""b""));
		
		List<Developer> companyDevs = new Company(""a"").getCompanyExperiencedDevs(Arrays.asList(developerCompanyA, developerCompanyB, newDeveloperCompanyA));
		
		assertThat(companyDevs.size(), is(1));
		assertThat(companyDevs.get(0), is(developerCompanyA));
	}
"
"	@Test
	public void testGetCompanyTracks() {
		List<String> tracks = Arrays.asList(""other-company-track"", ""company-track"", ""companyB-track"");
		
		String companyTrack = new Company(""Company"").getCompanyTrack(tracks);
		
		assertThat(companyTrack, is(""company-track""));
	}
"
"	@Test
	public void testGetCompanyTracksNoHit() {
		List<String> tracks = Arrays.asList(""other-company-track"", ""third-track"");
		
		String companyTrack = new Company(""Company"").getCompanyTrack(tracks);
		
		assertThat(companyTrack, is(nullValue()));
	}
"
"	@Test
	public void testIsCompanyTrack() {
		boolean isCompanyTrack = new Company(""Company"").isCompanyTrack(""company-track"");
		
		assertThat(isCompanyTrack, is(true));
	}
"
"	@Test
	public void testIsCompanyTrackFalse() {
		boolean isCompanyTrack = new Company(""Company"").isCompanyTrack(""companyB-track"");

		assertThat(isCompanyTrack, is(false));
	}
"
"	@Test
	public void testIsDevOpsRotationWeekly() {
		Company company = new Company(""Company"");

		company.setDevOpsRotationStrategy(""weekly"");

		assertThat(company.isDevOpsRotationWeekly(), is(true));
	}
"
"	@Test
	public void testIsDevOpsRotationWeeklyFalse() {
		Company company = new Company(""Company"");

		company.setDevOpsRotationStrategy("""");
		assertThat(company.isDevOpsRotationWeekly(), is(false));

		company.setDevOpsRotationStrategy(""foo"");
		assertThat(company.isDevOpsRotationWeekly(), is(false));
	}
"
"	@Test
	public void testGetCompanyDevs() {
		Developer developerCompanyA = new Developer(""a"");
		developerCompanyA.setCompany(new Company(""a""));
		Developer newDeveloperCompanyA = new Developer(""a"");
		newDeveloperCompanyA.setCompany(new Company(""a""));
		newDeveloperCompanyA.setNew(true);
		Developer developerCompanyB = new Developer(""b"");
		developerCompanyB.setCompany(new Company(""b""));

		List<Developer> companyDevs = new Company(""a"").getDevs(Arrays.asList(developerCompanyA, developerCompanyB, newDeveloperCompanyA));

		assertThat(companyDevs, is(Arrays.asList(developerCompanyA, newDeveloperCompanyA)));
	}
"
"	@Test(expected = RuntimeException.class)
	public void testUpdateDataBaseWithTrelloContentWithException() {
		List<DayPairs> pairsList = getPairsListFromDevs(getStandardDevs());
		when(trelloPairsRepository.findByDate(pairsList.get(2).getDate())).thenReturn(pairsList);

		subject.updateDataBaseWithTrelloContent(pairsList);
	}
"
"	@Test
	public void testUpdateDataBaseWithTrelloContent() {
		List<DayPairs> pairsList = getPairsListFromDevs(getStandardDevs());
		DayPairs oldPairs = new DayPairs();
		oldPairs.setDate(pairsList.get(0).getDate());
		oldPairs.addPair(""oldTrack"", new Pair());
		when(trelloPairsRepository.findByDate(pairsList.get(0).getDate())).thenReturn(Arrays.asList(oldPairs));
		when(trelloPairsRepository.findByDate(pairsList.get(1).getDate())).thenReturn(Arrays.asList());

		subject.updateDataBaseWithTrelloContent(pairsList);

		verify(trelloPairsRepository, atLeast(1)).save(pairsList.get(0));
		verify(trelloPairsRepository, atLeast(1)).save(pairsList.get(1));
	}
"
"	@Test
	public void testBuildPairsWeightFromPastPairing() {
		PairCombinations pairs = getPairsList();
		List<Developer> devs = getStandardDevs();

		Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);

		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")))), is(2));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev3"")))), is(0));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev4"")))), is(1));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev2""), new Developer(""dev3"")))), is(1));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev2""), new Developer(""dev4"")))), is(0));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")))), is(2));
	}
"
"	@Test
	public void testAdaptPairsWeightForNewDevelopers() {

		Developer developer1 = new Developer(""dev1"");
		developer1.setNew(true);
		Developer developer2 = new Developer(""dev2"");
		developer2.setNew(true);
		Developer developer3 = new Developer(""dev3"");
		Developer developer4 = new Developer(""dev4"");
		List<Developer> devs = Arrays.asList(developer1, developer2, developer3, developer4);
		PairCombinations pairs = new DevPairCombinations(getPairsListFromDevs(devs));

		Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);
		subject.adaptPairsWeight(pairsWeight, devs);

		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")))), is(102));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev3"")))), is(0));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev4"")))), is(1));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev2""), new Developer(""dev3"")))), is(1));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev2""), new Developer(""dev4"")))), is(0));
		assertThat(pairsWeight.get(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")))), is(2));
	}
"
"	@Test
	public void testGenerateNewDayPairs() {
		PairCombinations pairs = getPairsList();
		List<Developer> devs = getStandardDevs();
		List<String> tracks = Arrays.asList(""track1"", ""track2"", ""track3"");
		Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);
		subject.buildDevelopersPairingDays(pairs, devs);
		
		DayPairs dayPairs = subject.generateNewDayPairs(tracks, devs, pairs, pairsWeight, getStandardCompanies());

		assertThat(dayPairs.getTracks().size(), is(2));
		assertThat(dayPairs.getTracks(), containsInAnyOrder(""track1"", ""track2""));
		assertThat(dayPairs.getPairByTrack(""track1""),
				is(not(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2""))))));
		assertThat(dayPairs.getPairByTrack(""track2""),
				is(not(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4""))))));
		
		boolean trackOneHasContext = dayPairs.getPairByTrack(""track1"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track1"").getSecondDev().hasContext();
		boolean trackTwoHasContext = dayPairs.getPairByTrack(""track2"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track2"").getSecondDev().hasContext();
		assertThat(trackOneHasContext, is(true));
		assertThat(trackTwoHasContext, is(true));
	}
"
"	@Test
	public void testGenerateNewDayPairsWithEverydayRotation() {
		PairCombinations pairs = getPairsList();
		List<Developer> devs = getStandardDevs();
		List<String> tracks = Arrays.asList(""track1"", ""track2"", ""track3"");
		Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);
		subject.buildDevelopersPairingDays(pairs, devs);
		
		DayPairsHelper subjectWithEverydayRotation = new DayPairsHelper(trelloPairsRepository, true);
		DayPairs dayPairs = subjectWithEverydayRotation.generateNewDayPairs(tracks, devs, pairs, pairsWeight, getStandardCompanies());

		assertThat(dayPairs.getTracks().size(), is(2));
		assertThat(dayPairs.getTracks(), containsInAnyOrder(""track1"", ""track2""));
		assertThat(dayPairs.getPairByTrack(""track1""),
				is(not(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2""))))));
		assertThat(dayPairs.getPairByTrack(""track2""),
				is(not(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4""))))));
		
		boolean trackOneHasDev2 = dayPairs.getPairByTrack(""track1"").getFirstDev().equals(new Developer(""dev2"")) || dayPairs.getPairByTrack(""track1"").getSecondDev().equals(new Developer(""dev2""));
		boolean trackTwoHasDev4 = dayPairs.getPairByTrack(""track2"").getFirstDev().equals(new Developer(""dev4"")) || dayPairs.getPairByTrack(""track2"").getSecondDev().equals(new Developer(""dev4""));
		assertThat(trackOneHasDev2, is(true));
		assertThat(trackTwoHasDev4, is(true));
	}
"
"	@Test
	public void testGenerateNewDayPairsWithSmallestWeight() {
		PairCombinations pairs = getLongPairsList();
		List<Developer> devs = Arrays.asList(new Developer(""dev1""), new Developer(""dev2""), new Developer(""dev3""),
				new Developer(""dev4""), new Developer(""dev5""), new Developer(""dev6""));
		List<String> tracks = Arrays.asList(""track1"", ""track2"", ""track3"");
		Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);
		subject.buildDevelopersPairingDays(pairs, devs);
		
		DayPairs dayPairs = subject.generateNewDayPairs(tracks, devs, pairs, pairsWeight, getStandardCompanies());

		assertThat(dayPairs.getTracks().size(), is(3));
		assertThat(dayPairs.getTracks(), containsInAnyOrder(""track1"", ""track2"", ""track3""));
		System.out.println(dayPairs.getPairs());
		assertThat(dayPairs.hasPair(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev6"")))), is(true));
		assertThat(dayPairs.hasPair(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev2"")))), is(true));
		assertThat(dayPairs.hasPair(new Pair(Arrays.asList(new Developer(""dev5""), new Developer(""dev4"")))), is(true));
	}
"
"	@Test
	public void testGenerateNewDayPairsSoloRequired() {
		PairCombinations pairs = getPairsList();
		List<Developer> devs = Arrays.asList(new Developer(""dev1""), new Developer(""dev2""), new Developer(""dev3""));
		List<String> tracks = Arrays.asList(""track1"", ""track2"", ""track3"");
		Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);

		DayPairs dayPairs = subject.generateNewDayPairs(tracks, devs, pairs, pairsWeight, getStandardCompanies());

		assertThat(dayPairs.getTracks().size(), is(2));
		assertThat(dayPairs.getTracks(), containsInAnyOrder(""track1"", ""track2""));
		assertThat(dayPairs.getPairByTrack(""track1""),
				is((new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2""))))));
	}
"
"    @Test
    public void testFromWithNoOutputs() throws Exception {
        MockEndpoint mock = getMockEndpoint(""mock:result"");
        mock.expectedMinimumMessageCount(2);

        assertMockEndpointsSatisfied();

        assertTrue(counter >= 2, ""Counter should be 2 or higher"");
    }
"
"    @Test
    public void testAsyncStress() throws Exception {
        // do not test on windows
        assumeFalse(isPlatform(""windows""));

        // test by starting the unit test FileAsyncStressFileDropper in another
        // JVM

        MockEndpoint mock = getMockEndpoint(""mock:result"");
        mock.expectedMinimumMessageCount(250);

        assertMockEndpointsSatisfied();
    }
"
"    @Test
    public void testDropInNewFiles() throws Exception {
        // do not test on windows
        assumeFalse(isPlatform(""windows""));

        MockEndpoint mock = getMockEndpoint(""mock:result"");
        mock.expectedMinimumMessageCount(250);

        assertMockEndpointsSatisfied();
    }
"
"    @BeforeEach
    public void clean() {
        template.sendBodyAndHeader(ironQueue1, ""fo"", IronMQConstants.OPERATION, IronMQConstants.CLEARQUEUE);
        template.sendBodyAndHeader(ironQueue2, ""fo"", IronMQConstants.OPERATION, IronMQConstants.CLEARQUEUE);
    }
"
"    @Test
    public void testSendMessagesBetweenQueues() throws Exception {
        getMockEndpoint(""mock:result"").expectedMessageCount(100);
        for (int i = 1; i <= 100; i++) {
            String payloadToSend = PAYLOAD.replace(""#"", """" + i);
            template.sendBody(""direct:start"", payloadToSend);
        }
        assertMockEndpointsSatisfied(2, TimeUnit.MINUTES);
    }
"
"    @BeforeEach
    public void clean() {
        template.sendBodyAndHeader(ironMQEndpoint, ""fo"", IronMQConstants.OPERATION, IronMQConstants.CLEARQUEUE);
        deleteDirectory(""target/out"");
    }
"
"    @Test
    public void testCopyFileOverIronMQ() throws Exception {
        getMockEndpoint(""mock:result"").expectedMessageCount(1);
        assertMockEndpointsSatisfied();
        assertFileExists(""target/out/test.txt"");
    }
"
"    @Test
    public void testConfiguration() throws Exception {
        FhirEndpoint endpoint = getMandatoryEndpoint(TEST_URI, FhirEndpoint.class);
        GenericClient client = (GenericClient) endpoint.getClient();
        FhirConfiguration configuration = endpoint.getConfiguration();
        assertEquals(this.componentConfiguration, configuration);
        assertEquals(""http://localhost:8080/hapi-fhir-jpaserver-example/baseDstu3"", client.getUrlBase());
        assertEquals(EncodingEnum.JSON, client.getEncoding());
        assertEquals(SummaryEnum.TEXT, client.getSummary());
        List<Object> interceptors = client.getInterceptorService().getAllRegisteredInterceptors();
        assertEquals(5, interceptors.size());

        long counter = context.adapt(ExtendedCamelContext.class).getBeanIntrospection().getInvokedCounter();
        assertEquals(0, counter, ""Should not use reflection"");
    }
"
"    @Test
    public void testOnInstance() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());
        // parameter type is String
        headers.put(""CamelFhir.name"", ""everything"");
        // parameter type is org.hl7.fhir.instance.model.api.IBaseParameters
        headers.put(""CamelFhir.parameters"", null);
        // parameter type is Class
        headers.put(""CamelFhir.outputParameterType"", Parameters.class);
        headers.put(""CamelFhir.useHttpGet"", Boolean.FALSE);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", null);
        // parameter type is java.util.Map
        headers.put(""CamelFhir.extraParameters"", null);

        final Parameters result = requestBodyAndHeaders(""direct://ON_INSTANCE"", null, headers);

        LOG.debug(""onInstance: "" + result);
        assertNotNull(result, ""onInstance result"");
        Bundle bundle = (Bundle) result.getParameter().get(0).getResource();
        assertNotNull(bundle, ""onInstance result"");
        IdType id = bundle.getEntry().get(0).getResource().getIdElement().toUnqualifiedVersionless();
        assertEquals(patient.getIdElement().toUnqualifiedVersionless(), id);
    }
"
"    @Test
    public void testOnInstanceVersion() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());
        // parameter type is String
        headers.put(""CamelFhir.name"", ""everything"");
        // parameter type is org.hl7.fhir.instance.model.api.IBaseParameters
        headers.put(""CamelFhir.parameters"", null);
        // parameter type is Class
        headers.put(""CamelFhir.outputParameterType"", Parameters.class);
        headers.put(""CamelFhir.useHttpGet"", Boolean.FALSE);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", null);
        // parameter type is java.util.Map
        headers.put(""CamelFhir.extraParameters"", null);

        final Parameters result = requestBodyAndHeaders(""direct://ON_INSTANCE_VERSION"", null, headers);

        LOG.debug(""onInstance: "" + result);
        assertNotNull(result, ""onInstance result"");
        Bundle bundle = (Bundle) result.getParameter().get(0).getResource();
        assertNotNull(bundle, ""onInstance result"");
        IdType id = bundle.getEntry().get(0).getResource().getIdElement().toUnqualifiedVersionless();
        assertEquals(patient.getIdElement().toUnqualifiedVersionless(), id);
    }
"
"    @Test
    public void testOnServer() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.name"", ""$get-resource-counts"");
        // parameter type is org.hl7.fhir.instance.model.api.IBaseParameters
        headers.put(""CamelFhir.parameters"", null);
        // parameter type is Class
        headers.put(""CamelFhir.outputParameterType"", Parameters.class);
        headers.put(""CamelFhir.useHttpGet"", Boolean.TRUE);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", null);
        // parameter type is java.util.Map
        headers.put(""CamelFhir.extraParameters"", null);

        final Parameters result = requestBodyAndHeaders(""direct://ON_SERVER"", null, headers);
        assertNotNull(result, ""onServer result"");
    }
"
"    @Test
    public void testOnType() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resourceType"", Patient.class);
        // parameter type is String
        headers.put(""CamelFhir.name"", ""everything"");
        // parameter type is org.hl7.fhir.instance.model.api.IBaseParameters
        headers.put(""CamelFhir.parameters"", null);
        // parameter type is Class
        headers.put(""CamelFhir.outputParameterType"", Parameters.class);
        headers.put(""CamelFhir.useHttpGet"", Boolean.FALSE);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", null);
        // parameter type is java.util.Map
        headers.put(""CamelFhir.extraParameters"", null);

        final org.hl7.fhir.instance.model.api.IBaseResource result = requestBodyAndHeaders(""direct://ON_TYPE"", null, headers);

        assertNotNull(result, ""onType result"");
        LOG.debug(""onType: "" + result);
    }
"
"    @Test
    public void testProcessMessage() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.respondToUri"", null);
        // parameter type is org.hl7.fhir.instance.model.api.IBaseBundle
        headers.put(""CamelFhir.msgBundle"", null);
        headers.put(""CamelFhir.asynchronous"", Boolean.FALSE);
        // parameter type is Class
        headers.put(""CamelFhir.responseClass"", null);
        // parameter type is java.util.Map
        headers.put(""CamelFhir.extraParameters"", null);

        final org.hl7.fhir.instance.model.api.IBaseBundle result
                = requestBodyAndHeaders(""direct://PROCESS_MESSAGE"", null, headers);

        assertNotNull(result, ""processMessage result"");
        LOG.debug(""processMessage: "" + result);
    }
"
"    @Test
    public void testWithBundle() throws Exception {
        // using org.hl7.fhir.instance.model.api.IBaseBundle message body for single parameter ""bundle""
        Bundle result = requestBody(""direct://WITH_BUNDLE"", createTransactionBundle());

        assertNotNull(result, ""withBundle result"");
        assertTrue(result.getEntry().get(0).getResponse().getStatus().contains(""Created""));
        LOG.debug(""withBundle: "" + result);
    }
"
"    @Test
    public void testWithStringBundle() throws Exception {
        Bundle transactionBundle = createTransactionBundle();
        String stringBundle = fhirContext.newJsonParser().encodeResourceToString(transactionBundle);

        // using String message body for single parameter ""sBundle""
        final String result = requestBody(""direct://WITH_STRING_BUNDLE"", stringBundle);

        assertNotNull(result, ""withBundle result"");
        assertTrue(result.contains(""Bundle""));
        LOG.debug(""withBundle: "" + result);
    }
"
"    @Test
    public void testWithResources() throws Exception {
        Patient oscar = new Patient().addName(new HumanName().addGiven(""Oscar"").setFamily(""Peterson""));
        Patient bobbyHebb = new Patient().addName(new HumanName().addGiven(""Bobby"").setFamily(""Hebb""));
        List<IBaseResource> patients = new ArrayList<>(2);
        patients.add(oscar);
        patients.add(bobbyHebb);

        // using java.util.List message body for single parameter ""resources""
        List<IBaseResource> result = requestBody(""direct://WITH_RESOURCES"", patients);

        assertNotNull(result, ""withResources result"");
        LOG.debug(""withResources: "" + result);
        assertEquals(2, result.size());
    }
"
"    @Test
    public void testWithResourcesSummaryEnum() throws Exception {
        Patient oscar = new Patient().addName(new HumanName().addGiven(""Oscar"").setFamily(""Peterson""));
        Patient bobbyHebb = new Patient().addName(new HumanName().addGiven(""Bobby"").setFamily(""Hebb""));
        List<IBaseResource> patients = new ArrayList<>(2);
        patients.add(oscar);
        patients.add(bobbyHebb);
        final Map<String, Object> headers = new HashMap<>();
        headers.put(ExtraParameters.SUMMARY_ENUM.getHeaderName(), SummaryEnum.DATA);

        // using java.util.List message body for single parameter ""resources""
        List<IBaseResource> result = requestBodyAndHeaders(""direct://WITH_RESOURCES"", patients, headers);

        assertNotNull(result, ""withResources result"");
        LOG.debug(""withResources: "" + result);
        assertEquals(2, result.size());
    }
"
"    @Test
    public void testOfType() throws Exception {
        org.hl7.fhir.instance.model.api.IBaseConformance result = requestBody(""direct://OF_TYPE"", CapabilityStatement.class);

        LOG.debug(""ofType: "" + result);
        assertNotNull(result, ""ofType result"");
        assertEquals(Enumerations.PublicationStatus.ACTIVE, ((CapabilityStatement) result).getStatus());
    }
"
"    @Test
    public void testEncodeJSON() throws Exception {
        Map<String, Object> headers = new HashMap<>();
        headers.put(ExtraParameters.ENCODE_JSON.getHeaderName(), Boolean.TRUE);

        org.hl7.fhir.instance.model.api.IBaseConformance result
                = requestBodyAndHeaders(""direct://OF_TYPE"", CapabilityStatement.class, headers);

        LOG.debug(""ofType: "" + result);
        assertNotNull(result, ""ofType result"");
        assertEquals(Enumerations.PublicationStatus.ACTIVE, ((CapabilityStatement) result).getStatus());
    }
"
"    @Test
    public void testDeleteResource() throws Exception {
        assertTrue(patientExists());
        // using org.hl7.fhir.instance.model.api.IBaseResource message body for single parameter ""resource""
        IBaseOperationOutcome result = requestBody(""direct://RESOURCE"", this.patient);

        LOG.debug(""resource: "" + result);
        assertNotNull(result, ""resource result"");
        assertFalse(patientExists());
    }
"
"    @Test
    public void testDeleteResourceById() throws Exception {
        assertTrue(patientExists());

        // using org.hl7.fhir.instance.model.api.IIdType message body for single parameter ""id""
        IBaseOperationOutcome result = requestBody(""direct://RESOURCE_BY_ID"", this.patient.getIdElement());

        LOG.debug(""resourceById: "" + result);
        assertNotNull(result, ""resourceById result"");
        assertFalse(patientExists());
    }
"
"    @Test
    public void testDeleteResourceByStringId() throws Exception {
        assertTrue(patientExists());

        Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.type"", ""Patient"");
        // parameter type is String
        headers.put(""CamelFhir.stringId"", this.patient.getIdElement().getIdPart());

        IBaseOperationOutcome result = requestBodyAndHeaders(""direct://RESOURCE_BY_STRING_ID"", null, headers);

        LOG.debug(""resourceById: "" + result);
        assertNotNull(result, ""resourceById result"");
        assertFalse(patientExists());
    }
"
"    @Test
    public void testDeleteResourceConditionalByUrl() throws Exception {
        assertTrue(patientExists());

        IBaseOperationOutcome result
                = requestBody(""direct://RESOURCE_CONDITIONAL_BY_URL"", ""Patient?given=Vincent&family=Freeman"");

        LOG.debug(""resourceConditionalByUrl: "" + result);
        assertNotNull(result, ""resourceConditionalByUrl result"");
        assertFalse(patientExists());
    }
"
"    @Test
    public void testDeleteResourceConditionalByUrlCacheControlDirective() throws Exception {
        assertTrue(patientExists());
        Map<String, Object> headers = new HashMap<>();
        headers.put(ExtraParameters.CACHE_CONTROL_DIRECTIVE.getHeaderName(), new CacheControlDirective().setNoCache(true));

        IBaseOperationOutcome result = requestBodyAndHeaders(""direct://RESOURCE_CONDITIONAL_BY_URL"",
                ""Patient?given=Vincent&family=Freeman"", headers);

        LOG.debug(""resourceConditionalByUrl: "" + result);
        assertNotNull(result, ""resourceConditionalByUrl result"");
        assertFalse(patientExists());
    }
"
"    @Test
    public void testResource() throws Exception {
        Patient bobbyHebb = new Patient().addName(new HumanName().addGiven(""Bobby"").setFamily(""Hebb""));
        // using org.hl7.fhir.instance.model.api.IBaseResource message body for single parameter ""resource""
        MethodOutcome result = requestBody(""direct://RESOURCE"", bobbyHebb);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertNotNull(result.getOperationOutcome());
        assertTrue(((OperationOutcome) result.getOperationOutcome()).getText().getDivAsString()
                .contains(""No issues detected during validation""));
    }
"
"    @Test
    public void testResourceAsString() throws Exception {
        Patient bobbyHebb = new Patient().addName(new HumanName().addGiven(""Bobby"").setFamily(""Hebb""));
        // using org.hl7.fhir.instance.model.api.IBaseResource message body for single parameter ""resource""
        MethodOutcome result
                = requestBody(""direct://RESOURCE_AS_STRING"", this.fhirContext.newXmlParser().encodeResourceToString(bobbyHebb));

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertNotNull(result.getOperationOutcome());
        assertTrue(((OperationOutcome) result.getOperationOutcome()).getText().getDivAsString()
                .contains(""No issues detected during validation""));
    }
"
"    @Test
    public void testPatchById() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.patchBody"", PATCH);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", null);

        MethodOutcome result = requestBodyAndHeaders(""direct://PATCH_BY_ID"", null, headers);
        assertNotNull(result, ""patchById result"");
        assertActive(result);
    }
"
"    @Test
    public void testPatchByStringId() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.patchBody"", PATCH);
        // parameter type is String
        headers.put(""CamelFhir.stringId"", this.patient.getId());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", null);

        MethodOutcome result = requestBodyAndHeaders(""direct://PATCH_BY_SID"", null, headers);
        assertActive(result);
    }
"
"    @Test
    public void testPatchByStringIdPreferResponseTypes() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.patchBody"", PATCH);
        // parameter type is String
        headers.put(""CamelFhir.stringId"", this.patient.getId());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", null);

        List<Class<? extends IBaseResource>> preferredResponseTypes = new ArrayList<>();
        preferredResponseTypes.add(Patient.class);
        headers.put(ExtraParameters.PREFER_RESPONSE_TYPES.getHeaderName(), preferredResponseTypes);

        MethodOutcome result = requestBodyAndHeaders(""direct://PATCH_BY_SID"", null, headers);
        assertActive(result);
    }
"
"    @Test
    public void testPatchByUrl() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.patchBody"", PATCH);
        // parameter type is String
        headers.put(""CamelFhir.url"", ""Patient?given=Vincent&family=Freeman"");
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", null);

        MethodOutcome result = requestBodyAndHeaders(""direct://PATCH_BY_URL"", null, headers);

        assertNotNull(result, ""patchByUrl result"");
        LOG.debug(""patchByUrl: "" + result);
        assertActive(result);
    }
"
"    @Test
    public void testConfigurationWithCustomClient() throws Exception {
        FhirEndpoint endpoint = getMandatoryEndpoint(TEST_URI_CUSTOM_CLIENT, FhirEndpoint.class);
        IGenericClient client = endpoint.getClient();
        assertTrue(client instanceof CustomClient);
    }
"
"    @Test
    public void testConfigurationWithCustomFactory() throws Exception {
        FhirEndpoint endpoint = getMandatoryEndpoint(TEST_URI_CUSTOM_CLIENT_FACTORY, FhirEndpoint.class);
        IGenericClient client = endpoint.getClient();
        assertTrue(client instanceof CustomClient);
    }
"
"    @Test
    public void testCreateResource() throws Exception {
        Patient patient = new Patient().addName(new HumanName().addGiven(""Vincent"").setFamily(""Freeman""));

        MethodOutcome result = requestBody(""direct://RESOURCE"", patient);

        LOG.debug(""resource: "" + result);
        assertNotNull(result, ""resource result"");
        assertTrue(result.getCreated());
    }
"
"    @Test
    public void testCreateStringResource() throws Exception {
        Patient patient = new Patient().addName(new HumanName().addGiven(""Vincent"").setFamily(""Freeman""));
        String patientString = this.fhirContext.newXmlParser().encodeResourceToString(patient);

        MethodOutcome result = requestBody(""direct://RESOURCE_STRING"", patientString);

        LOG.debug(""resource: "" + result);
        assertNotNull(result, ""resource result"");
        assertTrue(result.getCreated());
    }
"
"    @Test
    public void testCreateStringResourceEncodeXml() throws Exception {
        Patient patient = new Patient().addName(new HumanName().addGiven(""Vincent"").setFamily(""Freeman""));
        String patientString = this.fhirContext.newXmlParser().encodeResourceToString(patient);
        Map<String, Object> headers = new HashMap<>();
        headers.put(ExtraParameters.ENCODE_XML.getHeaderName(), Boolean.TRUE);
        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE_STRING"", patientString, headers);

        LOG.debug(""resource: "" + result);
        assertNotNull(result, ""resource result"");
        assertTrue(result.getCreated());
    }
"
"    @Test
    public void testOnInstance() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        headers.put(""CamelFhir.id"", this.patient.getIdElement());
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", Bundle.class);
        // parameter type is Integer
        headers.put(""CamelFhir.count"", 1);

        Bundle result = requestBodyAndHeaders(""direct://ON_INSTANCE"", null, headers);

        LOG.debug(""onInstance: "" + result);
        assertNotNull(result, ""onInstance result"");
        assertEquals(1, result.getEntry().size());
    }
"
"    @Test
    public void testOnServer() throws Exception {
        Map<String, Object> headers = new HashMap<>();
        headers.put(""CamelFhir.returnType"", Bundle.class);
        headers.put(""CamelFhir.count"", 1);
        Bundle result = requestBodyAndHeaders(""direct://ON_SERVER"", null, headers);

        LOG.debug(""onServer: "" + result);
        assertNotNull(result, ""onServer result"");
        assertEquals(1, result.getEntry().size());
    }
"
"    @Test
    public void testOnType() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resourceType"", Patient.class);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", Bundle.class);
        // parameter type is Integer
        headers.put(""CamelFhir.count"", 1);

        Bundle result = requestBodyAndHeaders(""direct://ON_TYPE"", null, headers);

        LOG.debug(""onType: "" + result);
        assertNotNull(result, ""onType result"");
        assertEquals(1, result.getEntry().size());
    }
"
"    @Test
    public void testOnTypeWithSubsetElements() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resourceType"", Patient.class);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", Bundle.class);
        // parameter type is Integer
        headers.put(""CamelFhir.count"", 1);
        // only include the identifier and name
        headers.put(ExtraParameters.SUBSET_ELEMENTS.getHeaderName(), new String[] { ""identifier"", ""name"" });

        Bundle result = requestBodyAndHeaders(""direct://ON_TYPE"", null, headers);

        LOG.debug(""onType: "" + result);
        assertNotNull(result, ""onType result"");
        assertEquals(1, result.getEntry().size());
    }
"
"    @Test
    public void testResource() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resource"", this.patient);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
"
"    @Test
    public void testResourceNoId() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resource"", this.patient);
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
"
"    @Test
    public void testResourceStringId() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resource"", this.patient);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.stringId"", this.patient.getIdElement().getIdPart());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE_WITH_STRING_ID"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
"
"    @Test
    public void testResourceAsString() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resourceAsString"", this.fhirContext.newJsonParser().encodeResourceToString(this.patient));
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE_AS_STRING"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
"
"    @Test
    public void testResourceAsStringWithStringId() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resourceAsString"", this.fhirContext.newJsonParser().encodeResourceToString(this.patient));
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.stringId"", this.patient.getIdElement().getIdPart());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE_AS_STRING_WITH_STRING_ID"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
"
"    @Test
    public void testResourceBySearchUrl() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        String url = ""Patient?"" + Patient.SP_IDENTIFIER + '=' + URLEncoder.encode(this.patient.getId(), ""UTF-8"");
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resource"", this.patient);
        // parameter type is String
        headers.put(""CamelFhir.url"", url);
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE_BY_SEARCH_URL"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
"
"    @Test
    public void testResourceBySearchUrlAndResourceAsString() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        String url = ""Patient?"" + Patient.SP_IDENTIFIER + '=' + URLEncoder.encode(this.patient.getId(), ""UTF-8"");
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resourceAsString"", this.fhirContext.newJsonParser().encodeResourceToString(this.patient));
        // parameter type is String
        headers.put(""CamelFhir.url"", url);
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE_BY_SEARCH_URL_AND_RESOURCE_AS_STRING"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
"
"    @Test
    public void testSearchByUrl() throws Exception {
        String url = ""Patient?given=Vincent&family=Freeman&_format=json"";
        Bundle result = requestBody(""direct://SEARCH_BY_URL"", url);

        LOG.debug(""searchByUrl: "" + result);
        assertNotNull(result, ""searchByUrl result"");
        Patient patient = (Patient) result.getEntry().get(0).getResource();
        assertNotNull(patient);
        assertEquals(""Freeman"", patient.getName().get(0).getFamily());
    }
"
"    @Test
    public void testByUrl() throws Exception {
        String url = ""Patient?_count=2"";
        Bundle bundle = this.fhirClient.search()
                .byUrl(url)
                .returnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_NEXT));

        String nextPageLink = bundle.getLink(""next"").getUrl();

        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.url"", nextPageLink);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", Bundle.class);

        IBaseBundle result = requestBodyAndHeaders(""direct://BY_URL"", null, headers);

        LOG.debug(""byUrl: "" + result);
        assertNotNull(result, ""byUrl result"");
    }
"
"    @Test
    public void testNext() throws Exception {
        String url = ""Patient?_count=2"";
        Bundle bundle = this.fhirClient.search()
                .byUrl(url)
                .returnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_NEXT));

        // using org.hl7.fhir.instance.model.api.IBaseBundle message body for single parameter ""bundle""
        Bundle result = requestBody(""direct://NEXT"", bundle);

        assertNotNull(result, ""next result"");
        LOG.debug(""next: "" + result);
    }
"
"    @Test
    public void testPrevious() throws Exception {
        String url = ""Patient?_count=2"";
        Bundle bundle = this.fhirClient.search()
                .byUrl(url)
                .returnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_NEXT));

        String nextPageLink = bundle.getLink(""next"").getUrl();
        bundle = this.fhirClient.loadPage().byUrl(nextPageLink).andReturnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_PREV));

        // using org.hl7.fhir.instance.model.api.IBaseBundle message body for single parameter ""bundle""
        Bundle result = requestBody(""direct://PREVIOUS"", bundle);

        LOG.debug(""previous: "" + result);
        assertNotNull(result, ""previous result"");
    }
"
"    @Test
    public void testPreviousWithEncodingEnum() throws Exception {
        String url = ""Patient?_count=2"";
        Bundle bundle = this.fhirClient.search()
                .byUrl(url)
                .returnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_NEXT));

        String nextPageLink = bundle.getLink(""next"").getUrl();
        bundle = this.fhirClient.loadPage().byUrl(nextPageLink).andReturnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_PREV));
        Map<String, Object> headers = new HashMap<>();
        headers.put(ExtraParameters.ENCODING_ENUM.getHeaderName(), EncodingEnum.XML);

        // using org.hl7.fhir.instance.model.api.IBaseBundle message body for single parameter ""bundle""
        Bundle result = requestBodyAndHeaders(""direct://PREVIOUS"", bundle, headers);

        LOG.debug(""previous: "" + result);
        assertNotNull(result, ""previous result"");
    }
"
"    @BeforeEach
    public void populateServer() {
        List<IBaseResource> input = new ArrayList<>();

        Patient p1 = new Patient();
        p1.addName().setFamily(""PATIENT1"");
        input.add(p1);

        Patient p2 = new Patient();
        p2.addName().setFamily(""PATIENT2"");
        input.add(p2);

        input.add(new Patient().addName(new HumanName().setFamily(""PATIENT3"")));

        List<IBaseResource> response = fhirClient.transaction()
                .withResources(input)
                .encodedJson()
                .execute();
        assertEquals(3, response.size());
    }
"
"    @Test
    public void testAdd() throws Exception {
        //assert no meta
        Meta meta = fhirClient.meta().get(Meta.class).fromResource(this.patient.getIdElement()).execute();
        assertEquals(0, meta.getTag().size());
        Meta inMeta = new Meta();
        inMeta.addTag().setSystem(""urn:system1"").setCode(""urn:code1"");
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseMetaType
        headers.put(""CamelFhir.meta"", inMeta);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());

        IBaseMetaType result = requestBodyAndHeaders(""direct://ADD"", null, headers);

        LOG.debug(""add: "" + result);
        assertNotNull(result, ""add result"");
        assertEquals(1, result.getTag().size());
    }
"
"    @Test
    public void testDelete() throws Exception {
        //assert no meta
        Meta meta = fhirClient.meta().get(Meta.class).fromResource(this.patient.getIdElement()).execute();
        assertEquals(0, meta.getTag().size());
        Meta inMeta = new Meta();
        inMeta.addTag().setSystem(""urn:system1"").setCode(""urn:code1"");
        // add meta
        meta = fhirClient.meta().add().onResource(this.patient.getIdElement()).meta(inMeta).execute();
        assertEquals(1, meta.getTag().size());

        //delete meta
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseMetaType
        headers.put(""CamelFhir.meta"", meta);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());

        IBaseMetaType result = requestBodyAndHeaders(""direct://DELETE"", null, headers);

        LOG.debug(""delete: "" + result);
        assertNotNull(result, ""delete result"");
        assertEquals(0, result.getTag().size());
    }
"
"    @Test
    public void testGetFromResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.metaType"", Meta.class);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());

        IBaseMetaType result = requestBodyAndHeaders(""direct://GET_FROM_RESOURCE"", null, headers);

        LOG.debug(""getFromResource: "" + result);
        assertNotNull(result, ""getFromResource result"");
        assertEquals(0, result.getTag().size());
    }
"
"    @Test
    public void testGetFromServer() throws Exception {
        // using Class message body for single parameter ""metaType""
        IBaseMetaType result = requestBody(""direct://GET_FROM_SERVER"", Meta.class);
        assertNotNull(result, ""getFromServer result"");
        LOG.debug(""getFromServer: "" + result);
    }
"
"    @Test
    public void testGetFromType() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.metaType"", Meta.class);
        // parameter type is String
        headers.put(""CamelFhir.resourceType"", ""Patient"");

        IBaseMetaType result = requestBodyAndHeaders(""direct://GET_FROM_TYPE"", null, headers);

        LOG.debug(""getFromType: "" + result);
        assertNotNull(result, ""getFromType result"");
    }
"
"    @Test
    public void testGetFromTypePreferResponseType() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.metaType"", Meta.class);
        // parameter type is String
        headers.put(""CamelFhir.resourceType"", ""Patient"");
        headers.put(ExtraParameters.PREFER_RESPONSE_TYPE.getHeaderName(), Patient.class);

        Meta result = requestBodyAndHeaders(""direct://GET_FROM_TYPE"", null, headers);

        LOG.debug(""getFromType: "" + result);
        assertNotNull(result, ""getFromType result"");
    }
"
"    @Test
    public void testEncodeRequestToXml() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // encode request to XML
        headers.put(ExtraParameters.ENCODE_XML.getHeaderName(), Boolean.TRUE);
        String url = ""Patient?given=Vincent&family=Freeman&_format=json"";

        Bundle result = requestBodyAndHeaders(""direct://SEARCH_BY_URL"", url, headers);

        LOG.debug(""searchByUrl: "" + result);
        assertNotNull(result, ""searchByUrl result"");
        Patient patient = (Patient) result.getEntry().get(0).getResource();
        assertNotNull(patient);
        assertEquals(""Freeman"", patient.getName().get(0).getFamily());
    }
"
"    @Test
    public void testResourceById() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", patient.getIdElement());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_ID"", null, headers);

        assertValidResponse(result);
    }
"
"    @Test
    public void testResourceByLongId() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is Long
        headers.put(""CamelFhir.longId"", Long.valueOf(patient.getIdElement().getIdPart()));

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_LONG_ID"", null, headers);

        assertValidResponse(result);
    }
"
"    @Test
    public void testResourceByStringId() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is Long
        headers.put(""CamelFhir.stringId"", patient.getIdElement().getIdPart());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_STRING_ID"", null, headers);

        assertValidResponse(result);
    }
"
"    @Test
    public void testResourceByIdAndStringResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resourceClass"", ""Patient"");
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", patient.getIdElement());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_ID_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
"
"    @Test
    public void testResourceByLongIdAndStringResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is Long
        headers.put(""CamelFhir.longId"", Long.valueOf(patient.getIdElement().getIdPart()));

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_LONG_ID_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
"
"    @Test
    public void testResourceByStringIdAndStringResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is Long
        headers.put(""CamelFhir.stringId"", patient.getIdElement().getIdPart());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_STRING_ID_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
"
"    @Test
    public void testResourceByStringIdAndVersion() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is Long
        headers.put(""CamelFhir.stringId"", patient.getIdElement().getIdPart());
        // parameter type is String
        headers.put(""CamelFhir.version"", patient.getIdElement().getVersionIdPart());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_STRING_ID_AND_VERSION"", null, headers);

        assertValidResponse(result);
    }
"
"    @Test
    public void testResourceByStringIdAndVersionWithResourceClass() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resourceClass"", ""Patient"");
        // parameter type is Long
        headers.put(""CamelFhir.stringId"", patient.getIdElement().getIdPart());
        // parameter type is String
        headers.put(""CamelFhir.version"", patient.getIdElement().getVersionIdPart());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_STRING_ID_AND_VERSION_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
"
"    @Test
    public void testResourceByiUrl() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.iUrl"", new IdType(this.patient.getId()));

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_IURL"", null, headers);

        assertValidResponse(result);
    }
"
"    @Test
    public void testResourceByUrl() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is String
        headers.put(""CamelFhir.url"", this.patient.getId());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_URL"", null, headers);

        assertValidResponse(result);
    }
"
"    @Test
    public void testResourceByStringUrlAndStringResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.resourceClass"", ""Patient"");
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.iUrl"", new IdType(this.patient.getId()));

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_STRING_URL_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
"
"    @Test
    public void testResourceByUrlAndStringResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.resourceClass"", ""Patient"");
        // parameter type is String
        headers.put(""CamelFhir.url"", this.patient.getId());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_URL_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
"
"    @Test
    public void testResourceByUrlAndStringResourcePrettyPrint() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.resourceClass"", ""Patient"");
        // parameter type is String
        headers.put(""CamelFhir.url"", this.patient.getId());
        headers.put(ExtraParameters.PRETTY_PRINT.getHeaderName(), Boolean.TRUE);

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_URL_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
"
"    @Test
    public void testUnmarshalWithExplicitUTF16Charset() throws Exception {
        MockEndpoint mock = getMockEndpoint(""mock:result"");
        mock.setExpectedMessageCount(1);

        // Message with explicit encoding in MSH
        String charset = ""ASCII"";
        byte[] body = HL7_MESSAGE.getBytes(Charset.forName(charset));
        template.sendBodyAndHeader(""direct:input"", new ByteArrayInputStream(body), Exchange.CHARSET_NAME, charset);

        mock.assertIsSatisfied();

        MethodOutcome result = mock.getExchanges().get(0).getIn().getBody(MethodOutcome.class);
        assertNotNull(result, ""resource result"");
        assertTrue(result.getCreated());
    }
"
"    @Test
            public void configure() {
                from(""direct:start"").to(""beanstalk:"" + tubeName + ""?command=release"").to(""mock:result"");
            }
"
"    @Test
            public void configure() {
                from(""direct:start"").to(""beanstalk:"" + tubeName + ""?command=bury"").to(""mock:result"");
            }
"
"    @Test
            public void configure() {
                from(""direct:start"").to(""beanstalk:"" + tubeName + ""?command=touch"").to(""mock:result"");
            }
"
"    @Test
            public void configure() {
                from(""direct:start"").to(""beanstalk:"" + tubeName + ""?command=delete"").to(""mock:result"");
            }
"
"    @Test
            public void configure() {
                from(""direct:start"").to(""beanstalk:"" + tubeName + ""?jobPriority=1000&jobTimeToRun=5"").to(""mock:result"");
            }
"
"    @Test
            public void configure() {
                from(""beanstalk:"" + tubeName).to(""mock:result"");
            }
"
"    @Test
    public void testOperations() throws Exception {
        Map<String, Object> headers = new HashMap<>();
        assertFalse(gridFSBucket.find(eq(FILE_NAME)).cursor().hasNext());

        headers.put(Exchange.FILE_NAME, FILE_NAME);
        headers.put(Exchange.CONTENT_TYPE, ""text/plain"");
        template.requestBodyAndHeaders(""direct:create"", FILE_DATA, headers);
        assertTrue(gridFSBucket.find(eq(GridFsConstants.GRIDFS_FILE_KEY_FILENAME, FILE_NAME)).cursor().hasNext());
        assertEquals(1, template.requestBodyAndHeaders(""direct:count"", null, headers, Long.class).longValue());
        Exchange result = template.request(""direct:findOne"", exchange -> exchange.getMessage().setHeaders(headers));
        assertTrue(result.getMessage().getHeader(Exchange.FILE_LENGTH, Long.class) > 0);
        assertNotNull(result.getMessage().getHeader(Exchange.FILE_LAST_MODIFIED));

        InputStream ins = result.getMessage().getBody(InputStream.class);
        assertNotNull(ins);
        byte b[] = new byte[2048];
        int i = ins.read(b);
        assertEquals(FILE_DATA, new String(b, 0, i, StandardCharsets.UTF_8));

        headers.put(Exchange.FILE_NAME, ""2-"" + FILE_NAME);
        headers.put(GridFsEndpoint.GRIDFS_CHUNKSIZE, 10);
        headers.put(GridFsEndpoint.GRIDFS_METADATA, ""{'foo': 'bar'}"");

        template.requestBodyAndHeaders(""direct:create"", FILE_DATA + ""data2"", headers);
        assertEquals(1, template.requestBodyAndHeaders(""direct:count"", null, headers, Long.class).longValue());
        assertEquals(2, template.requestBody(""direct:count"", null, Long.class).longValue());

        String s = template.requestBody(""direct:listAll"", null, String.class);
        assertTrue(s.contains(""2-"" + FILE_NAME));
        template.requestBodyAndHeaders(""direct:remove"", null, headers);
        assertEquals(1, template.requestBody(""direct:count"", null, Long.class).longValue());
        s = template.requestBodyAndHeader(""direct:listAll"", null, Exchange.FILE_NAME, ""2-"" + FILE_NAME, String.class);
        assertFalse(s.contains(""2-"" + FILE_NAME));
    }
"
"    @Test
    public void testRemoveByObjectId() {
        Map<String, Object> headers = new HashMap<>();
        headers.put(Exchange.FILE_NAME, FILE_NAME);

        Exchange result = template.request(
                ""mongodb-gridfs:myDb?database={{mongodb.testDb}}&operation=create&bucket="" + getBucket(), new Processor() {
                    @Override
                    public void process(Exchange exchange) throws Exception {
                        exchange.getMessage().setBody(FILE_DATA);
                        exchange.getMessage().setHeaders(headers);
                    }
"
"    @Test
    public void testTimestamp() throws Exception {
        runTest(""direct:create"", gridFSBucket);
    }
"
"    @Test
    public void testAttribute() throws Exception {
        runTest(""direct:create-a"", GridFSBuckets.create(mongo.getDatabase(""test""), getBucket() + ""-a""));
    }
"
"    @Test
    public void testPersistentTS() throws Exception {
        runTest(""direct:create-pts"", GridFSBuckets.create(mongo.getDatabase(""test""), getBucket() + ""-pts""));
    }
"
"    @Test
    public void testCustomFileQuery() throws Exception {
        Map<String, Object> headers = new HashMap<>();
        headers.put(Exchange.FILE_NAME, FILE_NAME);

        Exchange result = template.request(
                ""mongodb-gridfs:myDb?database={{mongodb.testDb}}&operation=create&bucket=customFileFilterTest"",
                new Processor() {
                    @Override
                    public void process(Exchange exchange) throws Exception {
                        exchange.getMessage().setBody(FILE_DATA);
                        exchange.getMessage().setHeaders(headers);
                    }
"
"    @BeforeEach
    public void setup() throws Exception {
        // Create the LDAPConnection
        ldapContext = getWiredContext(service);

        SimpleRegistry reg = getSimpleRegistry();
        camel = new DefaultCamelContext(reg);
        template = camel.createProducerTemplate();
    }
"
"    @AfterEach
    public void tearDown() throws Exception {
        if (camel != null) {
            camel.stop();
        }
    }
"
"    @Test
    public void addOne() throws Exception {
        camel.addRoutes(createRouteBuilder(ENDPOINT_LDIF));
        camel.start();

        Endpoint endpoint = camel.getEndpoint(ENDPOINT_START);
        Exchange exchange = endpoint.createExchange();

        // then we set the LDAP filter on the in body
        URL loc = this.getClass().getResource(""/org/apache/camel/component/ldif/AddOne.ldif"");
        exchange.getIn().setBody(loc.toString());

        // now we send the exchange to the endpoint, and receives the response
        // from Camel
        Exchange out = template.send(endpoint, exchange);

        // Check the results
        List<String> ldifResults = defaultLdapModuleOutAssertions(out);
        assertThat(ldifResults, notNullValue());
        assertThat(ldifResults.size(), equalTo(2)); // Container and user
        assertThat(ldifResults.get(0), equalTo(""success""));
        assertThat(ldifResults.get(1), equalTo(""success""));

        // Check LDAP
        SearchResult sr;
        NamingEnumeration<SearchResult> searchResults = ldapContext.search(""dc=example,dc=org"", ""(uid=test*)"", SEARCH_CONTROLS);
        assertNotNull(searchResults);

        checkDN(""uid=test1"", searchResults);
    }
"
"    @Test
    public void deleteOne() throws Exception {
        setupData(""/org/apache/camel/component/ldif/DeleteOneSetup.ldif"");

        camel.addRoutes(createRouteBuilder(ENDPOINT_LDIF));
        camel.start();

        Endpoint endpoint = camel.getEndpoint(ENDPOINT_START);
        Exchange exchange = endpoint.createExchange();

        // then we set the LDAP filter on the in body
        URL loc = this.getClass().getResource(""/org/apache/camel/component/ldif/DeleteOne.ldif"");
        exchange.getIn().setBody(loc.toString());

        // now we send the exchange to the endpoint, and receives the response
        // from Camel
        Exchange out = template.send(endpoint, exchange);

        // Check the results
        List<String> ldifResults = defaultLdapModuleOutAssertions(out);
        assertThat(ldifResults, notNullValue());
        assertThat(ldifResults.size(), equalTo(1));
        assertThat(ldifResults.get(0), equalTo(""success""));

        // Check LDAP
        NamingEnumeration<SearchResult> searchResults = ldapContext.search(""dc=example,dc=org"", ""(uid=test*)"", SEARCH_CONTROLS);
        // test2
        while (searchResults.hasMore()) {
            assertThat(searchResults.next().getName(), not(containsString(""test2"")));
        }
    }
"
"    @Test
    public void addDuplicate() throws Exception {
        setupData(""/org/apache/camel/component/ldif/AddDuplicateSetup.ldif"");

        camel.addRoutes(createRouteBuilder(ENDPOINT_LDIF));
        camel.start();

        Endpoint endpoint = camel.getEndpoint(ENDPOINT_START);
        Exchange exchange = endpoint.createExchange();

        // then we set the LDAP filter on the in body
        URL loc = this.getClass().getResource(""/org/apache/camel/component/ldif/AddDuplicate.ldif"");
        exchange.getIn().setBody(loc.toString());

        // now we send the exchange to the endpoint, and receives the response
        // from Camel
        Exchange out = template.send(endpoint, exchange);

        // Check the results
        List<String> ldifResults = defaultLdapModuleOutAssertions(out);
        assertThat(ldifResults, notNullValue());
        assertThat(ldifResults.size(), equalTo(1));
        assertThat(ldifResults.get(0), not(equalTo(""success"")));
    }
"
"    @Test
    public void modify() throws Exception {
        setupData(""/org/apache/camel/component/ldif/ModifySetup.ldif"");

        camel.addRoutes(createRouteBuilder(ENDPOINT_LDIF));
        camel.start();

        Endpoint endpoint = camel.getEndpoint(ENDPOINT_START);
        Exchange exchange = endpoint.createExchange();

        // then we set the LDAP filter on the in body
        URL loc = this.getClass().getResource(""/org/apache/camel/component/ldif/Modify.ldif"");
        exchange.getIn().setBody(loc.toString());

        // now we send the exchange to the endpoint, and receives the response
        // from Camel
        Exchange out = template.send(endpoint, exchange);

        // Check the results
        List<String> ldifResults = defaultLdapModuleOutAssertions(out);
        assertThat(ldifResults, notNullValue());
        assertThat(ldifResults.size(), equalTo(1));
        assertThat(ldifResults.get(0), equalTo(""success""));

        // Check LDAP
        SearchResult sr;
        NamingEnumeration<SearchResult> searchResults = ldapContext.search(""dc=example,dc=org"", ""(uid=test*)"", SEARCH_CONTROLS);
        assertNotNull(searchResults);

        boolean uidFound = false;
        while (searchResults.hasMore()) {
            sr = searchResults.next();
            if (sr.getName().contains(""uid=test4"")) {
                uidFound = true;

                // Check the attributes of the search result
                Attributes attribs = sr.getAttributes();
                assertNotNull(attribs);
                Attribute attrib = attribs.get(""sn"");
                assertNotNull(attribs);
                assertThat(1, equalTo(attrib.size()));
                assertThat(""5"", equalTo(attrib.get(0).toString()));
            }
        }

        assertThat(""uid=test4 not found"", uidFound, equalTo(true));
    }
"
"    @Test
    public void modRdn() throws Exception {
        setupData(""/org/apache/camel/component/ldif/ModRdnSetup.ldif"");

        camel.addRoutes(createRouteBuilder(ENDPOINT_LDIF));
        camel.start();

        Endpoint endpoint = camel.getEndpoint(ENDPOINT_START);
        Exchange exchange = endpoint.createExchange();

        // then we set the LDAP filter on the in body
        URL loc = this.getClass().getResource(""/org/apache/camel/component/ldif/ModRdn.ldif"");
        exchange.getIn().setBody(loc.toString());

        // now we send the exchange to the endpoint, and receives the response
        // from Camel
        Exchange out = template.send(endpoint, exchange);

        // Check the results
        List<String> ldifResults = defaultLdapModuleOutAssertions(out);
        assertThat(ldifResults, notNullValue());
        assertThat(ldifResults.size(), equalTo(1));
        assertThat(ldifResults.get(0), equalTo(""success""));

        // Check LDAP
        NamingEnumeration<SearchResult> searchResults = ldapContext.search(""dc=example,dc=org"", ""(uid=test*)"", SEARCH_CONTROLS);
        assertNotNull(searchResults);

        checkDN(""uid=test6"", searchResults);
    }
"
"    @Test
    public void modDn() throws Exception {
        setupData(""/org/apache/camel/component/ldif/ModDnSetup.ldif"");

        camel.addRoutes(createRouteBuilder(ENDPOINT_LDIF));
        camel.start();

        Endpoint endpoint = camel.getEndpoint(ENDPOINT_START);
        Exchange exchange = endpoint.createExchange();

        // then we set the LDAP filter on the in body
        URL loc = this.getClass().getResource(""/org/apache/camel/component/ldif/ModDn.ldif"");
        exchange.getIn().setBody(loc.toString());

        // now we send the exchange to the endpoint, and receives the response
        // from Camel
        Exchange out = template.send(endpoint, exchange);

        // Check the results
        List<String> ldifResults = defaultLdapModuleOutAssertions(out);
        assertThat(ldifResults, notNullValue());
        assertThat(ldifResults.size(), equalTo(1));
        assertThat(ldifResults.get(0), equalTo(""success""));

        // Check LDAP
        NamingEnumeration<SearchResult> searchResults = ldapContext.search(""dc=example,dc=org"", ""(uid=test*)"", SEARCH_CONTROLS);
        assertNotNull(searchResults);

        checkDN(""uid=test7"", searchResults);
    }
"
"    @Test
    public void vaultTrackByWithSortingTest() throws Exception {
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
    }
"
"    @Test
    public void vaultTrackByCriteriaTest() throws Exception {
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
    }
"
"    @Test
    public void vaultTrackTest() throws Exception {
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
    }
"
"    @Test
    public void stateMachineFeedTest() throws Exception {
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
    }
"
"    @Test
    public void vaultTrackByTest() throws Exception {
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
    }
"
"    @Test
    public void startTrackedFlowDynamicTest() throws Exception {
        //Expects CamelFlow is deployed on the node
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
        assertEquals(""Hello world!"", mockResult.getExchanges().get(0).getIn().getBody());
    }
"
"    @Test
    public void currentNodeTimeTest() throws Exception {
        Exchange exchange = createExchangeWithBodyAndHeader(null, OPERATION, CURRENT_NODE_TIME);
        template.send(exchange);
        Object body = exchange.getIn().getBody();
        assertNotNull(body);
        Object exception = exchange.getException();
        assertNull(exception);
    }
"
"  @Test
  public void compressionTest() {
    List<Integer> testSizes = Lists.newArrayList(
        1, 1024, 128 * 1024, 512 * 1024, 1024 * 1024, 4 * 1024 * 1024);
    for (int size : testSizes) {
      singleTest(size);
    }
  }
"
"  @Test
  public void odfsConfigurationTest() {
    SparkConf conf = new SparkConf();
    Configuration conf1 = RssShuffleUtils.newHadoopConfiguration(conf);
    assertFalse(conf1.getBoolean(""dfs.namenode.odfs.enable"", false));
    assertEquals(""org.apache.hadoop.fs.Hdfs"", conf1.get(""fs.AbstractFileSystem.hdfs.impl""));

    conf.set(RssClientConfig.RSS_OZONE_DFS_NAMENODE_ODFS_ENABLE, ""true"");
    conf1 = RssShuffleUtils.newHadoopConfiguration(conf);
    assertTrue(conf1.getBoolean(""dfs.namenode.odfs.enable"", false));
    assertEquals(""org.apache.hadoop.odfs.HdfsOdfsFilesystem"", conf1.get(""fs.hdfs.impl""));
    assertEquals(""org.apache.hadoop.odfs.HdfsOdfs"", conf1.get(""fs.AbstractFileSystem.hdfs.impl""));

    conf.set(RssClientConfig.RSS_OZONE_FS_HDFS_IMPL, ""expect_odfs_impl"");
    conf.set(RssClientConfig.RSS_OZONE_FS_ABSTRACT_FILE_SYSTEM_HDFS_IMPL, ""expect_odfs_abstract_impl"");
    conf1 = RssShuffleUtils.newHadoopConfiguration(conf);
    assertEquals(""expect_odfs_impl"", conf1.get(""fs.hdfs.impl""));
    assertEquals(""expect_odfs_abstract_impl"", conf1.get(""fs.AbstractFileSystem.hdfs.impl""));
  }
"
"  @Test
  public void readTest1() throws Exception {
    String basePath = HDFS_URI + ""readTest1"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test1"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 5, expectedData,
        blockIdBitmap, ""key"", KRYO_SERIALIZER, 0);

    RssShuffleDataIterator rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);

    validateResult(rssShuffleDataIterator, expectedData, 10);

    blockIdBitmap.add(ClientUtils.getBlockId(0, 0, Constants.MAX_SEQUENCE_NO));
    rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);
    int recNum = 0;
    try {
      // can't find all expected block id, data loss
      while (rssShuffleDataIterator.hasNext()) {
        rssShuffleDataIterator.next();
        recNum++;
      }
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().startsWith(""Blocks read inconsistent:""));
    }
    assertEquals(10, recNum);
  }
"
"  @Test
  public void readTest2() throws Exception {
    String basePath = HDFS_URI + ""readTest2"";
    HdfsShuffleWriteHandler writeHandler1 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test2_1"", conf);
    HdfsShuffleWriteHandler writeHandler2 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test2_2"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler1, 2, 5, expectedData,
        blockIdBitmap, ""key1"", KRYO_SERIALIZER, 0);
    writeTestData(writeHandler2, 2, 5, expectedData,
        blockIdBitmap, ""key2"", KRYO_SERIALIZER, 0);

    RssShuffleDataIterator rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);

    validateResult(rssShuffleDataIterator, expectedData, 20);
    assertEquals(20, rssShuffleDataIterator.getShuffleReadMetrics().recordsRead());
    assertEquals(256, rssShuffleDataIterator.getShuffleReadMetrics().remoteBytesRead());
    assertTrue(rssShuffleDataIterator.getShuffleReadMetrics().fetchWaitTime() > 0);
  }
"
"  @Test
  public void readTest3() throws Exception {
    String basePath = HDFS_URI + ""readTest3"";
    HdfsShuffleWriteHandler writeHandler1 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test3_1"", conf);
    HdfsShuffleWriteHandler writeHandler2 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test3_2"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler1, 2, 5, expectedData,
        blockIdBitmap, ""key1"", KRYO_SERIALIZER, 0);
    writeTestData(writeHandler2, 2, 5, expectedData,
        blockIdBitmap, ""key2"", KRYO_SERIALIZER, 0);

    // duplicate file created, it should be used in product environment
    String shuffleFolder = basePath + ""/appId/0/0-1"";
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_1_0.data""), fs,
        new Path(shuffleFolder + ""/test3_1_0.cp.data""), false, conf);
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_1_0.index""), fs,
        new Path(shuffleFolder + ""/test3_1_0.cp.index""), false, conf);
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_2_0.data""), fs,
        new Path(shuffleFolder + ""/test3_2_0.cp.data""), false, conf);
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_2_0.index""), fs,
        new Path(shuffleFolder + ""/test3_2_0.cp.index""), false, conf);

    RssShuffleDataIterator rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);

    validateResult(rssShuffleDataIterator, expectedData, 20);
  }
"
"  @Test
  public void readTest4() throws Exception {
    String basePath = HDFS_URI + ""readTest4"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test1"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 5, expectedData,
        blockIdBitmap, ""key"", KRYO_SERIALIZER, 0);

    RssShuffleDataIterator rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);
    // data file is deleted after iterator initialization
    Path dataFile = new Path(basePath + ""/appId/0/0-1/test1_0.data"");
    fs.delete(dataFile, true);
    // sleep to wait delete operation
    Thread.sleep(10000);
    try {
      fs.listStatus(dataFile);
      fail(""Index file should be deleted"");
    } catch (Exception e) {
    }

    try {
      while (rssShuffleDataIterator.hasNext()) {
        rssShuffleDataIterator.next();
      }
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().startsWith(""Blocks read inconsistent: expected""));
    }
  }
"
"  @Test
  public void readTest5() throws Exception {
    String basePath = HDFS_URI + ""readTest5"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 5, expectedData,
        blockIdBitmap, ""key"", KRYO_SERIALIZER, 0);

    RssShuffleDataIterator rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);
    // index file is deleted after iterator initialization, it should be ok, all index infos are read already
    Path indexFile = new Path(basePath + ""/appId/0/0-1/test.index"");
    fs.delete(indexFile, true);
    // sleep to wait delete operation
    Thread.sleep(10000);
    try {
      fs.listStatus(indexFile);
      fail(""Index file should be deleted"");
    } catch (Exception e) {
    }
    validateResult(rssShuffleDataIterator, expectedData, 10);
  }
"
"  @Test
  public void readTest7() throws Exception {
    String basePath = HDFS_URI + ""readTest7"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 5, expectedData,
        blockIdBitmap, ""key"", KRYO_SERIALIZER, 0);

    RssShuffleDataIterator rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);

    // crc32 is incorrect
    try (MockedStatic<ChecksumUtils> checksumUtilsMock = Mockito.mockStatic(ChecksumUtils.class)) {
      checksumUtilsMock.when(() -> ChecksumUtils.getCrc32((ByteBuffer) any())).thenReturn(-1L);
      try {
        while (rssShuffleDataIterator.hasNext()) {
          rssShuffleDataIterator.next();
        }
        fail(EXPECTED_EXCEPTION_MESSAGE);
      } catch (Exception e) {
        assertTrue(e.getMessage().startsWith(""Unexpected crc value""));
      }
    }
  }
"
"  @Test
  public void test() {
    WriterBuffer wb = new WriterBuffer(32);
    assertEquals(0, wb.getMemoryUsed());
    assertEquals(0, wb.getDataLength());

    serializeData(""key"", ""value"");
    // size of serialized kv is 12
    wb.addRecord(serializedData, serializedDataLength);
    assertEquals(32, wb.getMemoryUsed());
    assertEquals(12, wb.getDataLength());
    wb.addRecord(serializedData, serializedDataLength);
    assertEquals(32, wb.getMemoryUsed());
    // case: data size < output buffer size, when getData(), [] + buffer with 24b = 24b
    assertEquals(24, wb.getData().length);
    wb.addRecord(serializedData, serializedDataLength);
    // case: data size > output buffer size, when getData(), [1 buffer] + buffer with 12 = 36b
    assertEquals(36, wb.getData().length);
    assertEquals(64, wb.getMemoryUsed());
    wb.addRecord(serializedData, serializedDataLength);
    wb.addRecord(serializedData, serializedDataLength);
    // case: data size > output buffer size, when getData(), 2 buffer + output with 12b = 60b
    assertEquals(60, wb.getData().length);
    assertEquals(96, wb.getMemoryUsed());

    wb = new WriterBuffer(32);

    serializeData(""key1111111111111111111111111111"", ""value222222222222222222222222222"");
    wb.addRecord(serializedData, serializedDataLength);
    assertEquals(67, wb.getMemoryUsed());
    assertEquals(67, wb.getDataLength());

    serializeData(""key"", ""value"");
    wb.addRecord(serializedData, serializedDataLength);
    // 67 + 32
    assertEquals(99, wb.getMemoryUsed());
    // 67 + 12
    assertEquals(79, wb.getDataLength());
    assertEquals(79, wb.getData().length);

    wb.addRecord(serializedData, serializedDataLength);
    assertEquals(99, wb.getMemoryUsed());
    assertEquals(91, wb.getDataLength());
    assertEquals(91, wb.getData().length);
  }
"
"  @Test
  public void addRecordTest() {
    SparkConf conf = getConf();
    WriteBufferManager wbm = createManager(conf);
    wbm.setShuffleWriteMetrics(new ShuffleWriteMetrics());
    String testKey = ""Key"";
    String testValue = ""Value"";
    List<ShuffleBlockInfo> result = wbm.addRecord(0, testKey, testValue);
    // single buffer is not full, there is no data return
    assertEquals(0, result.size());
    assertEquals(512, wbm.getAllocatedBytes());
    assertEquals(32, wbm.getUsedBytes());
    assertEquals(0, wbm.getInSendListBytes());
    assertEquals(1, wbm.getBuffers().size());
    wbm.addRecord(0, testKey, testValue);
    wbm.addRecord(0, testKey, testValue);
    wbm.addRecord(0, testKey, testValue);
    result = wbm.addRecord(0, testKey, testValue);
    // single buffer is full
    assertEquals(1, result.size());
    assertEquals(512, wbm.getAllocatedBytes());
    assertEquals(96, wbm.getUsedBytes());
    assertEquals(96, wbm.getInSendListBytes());
    assertEquals(0, wbm.getBuffers().size());
    wbm.addRecord(0, testKey, testValue);
    wbm.addRecord(1, testKey, testValue);
    wbm.addRecord(2, testKey, testValue);
    // single buffer is not full, and less than spill size
    assertEquals(512, wbm.getAllocatedBytes());
    assertEquals(192, wbm.getUsedBytes());
    assertEquals(96, wbm.getInSendListBytes());
    assertEquals(3, wbm.getBuffers().size());
    // all buffer size > spill size
    wbm.addRecord(3, testKey, testValue);
    wbm.addRecord(4, testKey, testValue);
    result = wbm.addRecord(5, testKey, testValue);
    assertEquals(6, result.size());
    assertEquals(512, wbm.getAllocatedBytes());
    assertEquals(288, wbm.getUsedBytes());
    assertEquals(288, wbm.getInSendListBytes());
    assertEquals(0, wbm.getBuffers().size());
    // free memory
    wbm.freeAllocatedMemory(96);
    assertEquals(416, wbm.getAllocatedBytes());
    assertEquals(192, wbm.getUsedBytes());
    assertEquals(192, wbm.getInSendListBytes());

    assertEquals(11, wbm.getShuffleWriteMetrics().recordsWritten());
    assertTrue(wbm.getShuffleWriteMetrics().bytesWritten() > 0);

    wbm.freeAllocatedMemory(192);
    wbm.addRecord(0, testKey, testValue);
    wbm.addRecord(1, testKey, testValue);
    wbm.addRecord(2, testKey, testValue);
    result = wbm.clear();
    assertEquals(3, result.size());
    assertEquals(224, wbm.getAllocatedBytes());
    assertEquals(96, wbm.getUsedBytes());
    assertEquals(96, wbm.getInSendListBytes());
  }
"
"  @Test
  public void createBlockIdTest() {
    SparkConf conf = getConf();
    WriteBufferManager wbm = createManager(conf);
    WriterBuffer mockWriterBuffer = mock(WriterBuffer.class);
    when(mockWriterBuffer.getData()).thenReturn(new byte[]{});
    when(mockWriterBuffer.getMemoryUsed()).thenReturn(0);
    ShuffleBlockInfo sbi = wbm.createShuffleBlock(0, mockWriterBuffer);
    // seqNo = 0, partitionId = 0, taskId = 0
    assertEquals(0L, sbi.getBlockId());

    // seqNo = 1, partitionId = 0, taskId = 0
    sbi = wbm.createShuffleBlock(0, mockWriterBuffer);
    assertEquals(17592186044416L, sbi.getBlockId());

    // seqNo = 0, partitionId = 1, taskId = 0
    sbi = wbm.createShuffleBlock(1, mockWriterBuffer);
    assertEquals(1048576L, sbi.getBlockId());

    // seqNo = 1, partitionId = 1, taskId = 0
    sbi = wbm.createShuffleBlock(1, mockWriterBuffer);
    assertEquals(17592187092992L, sbi.getBlockId());
  }
"
"  @Test
  public void readTest() throws Exception {

    String basePath = HDFS_URI + ""readTest1"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 0, basePath, ""test"", conf);
    HdfsShuffleWriteHandler writeHandler1 =
        new HdfsShuffleWriteHandler(""appId"", 0, 1, 1, basePath, ""test"", conf);

    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    writeTestData(writeHandler, 2, 5, expectedData,
        blockIdBitmap, ""key"", KRYO_SERIALIZER, 0);



    TaskContext contextMock = mock(TaskContext.class);
    RssShuffleHandle handleMock = mock(RssShuffleHandle.class);
    ShuffleDependency dependencyMock = mock(ShuffleDependency.class);
    when(handleMock.getAppId()).thenReturn(""appId"");
    when(handleMock.getDependency()).thenReturn(dependencyMock);
    when(handleMock.getShuffleId()).thenReturn(1);
    when(dependencyMock.serializer()).thenReturn(KRYO_SERIALIZER);
    when(contextMock.attemptNumber()).thenReturn(1);
    when(contextMock.taskAttemptId()).thenReturn(1L);
    when(contextMock.taskMetrics()).thenReturn(new TaskMetrics());
    doNothing().when(contextMock).killTaskIfInterrupted();
    when(dependencyMock.aggregator()).thenReturn(Option.empty());
    when(dependencyMock.keyOrdering()).thenReturn(Option.empty());
    when(dependencyMock.mapSideCombine()).thenReturn(false);

    Map<Integer, Roaring64NavigableMap> partitionToExpectBlocks = Maps.newHashMap();
    partitionToExpectBlocks.put(0, blockIdBitmap);
    RssShuffleReader rssShuffleReaderSpy = spy(new RssShuffleReader<String, String>(
        0,
        1,
        0,
        Integer.MAX_VALUE,
        contextMock,
        handleMock,
        basePath,
        1000,
        conf,
        StorageType.HDFS.name(),
        1000,
        1,
        partitionToExpectBlocks,
        taskIdBitmap,
        new ShuffleReadMetrics()));
    validateResult(rssShuffleReaderSpy.read(), expectedData, 10);

    writeTestData(writeHandler1, 2, 4, expectedData,
        blockIdBitmap1, ""another_key"", KRYO_SERIALIZER, 1);
    partitionToExpectBlocks.put(1, blockIdBitmap1);
    RssShuffleReader rssShuffleReaderSpy1 = spy(new RssShuffleReader<String, String>(
        0,
        2,
        0,
        Integer.MAX_VALUE,
        contextMock,
        handleMock,
        basePath,
        1000,
        conf,
        StorageType.HDFS.name(),
        1000,
        2,
        partitionToExpectBlocks,
        taskIdBitmap,
        new ShuffleReadMetrics()));
    validateResult(rssShuffleReaderSpy1.read(), expectedData, 18);

    RssShuffleReader rssShuffleReaderSpy2 = spy(new RssShuffleReader<String, String>(
        0,
        2,
        0,
        Integer.MAX_VALUE,
        contextMock,
        handleMock,
        basePath,
        1000,
        conf,
        StorageType.HDFS.name(),
        1000,
        2,
        partitionToExpectBlocks,
        Roaring64NavigableMap.bitmapOf(),
        new ShuffleReadMetrics()));
    validateResult(rssShuffleReaderSpy2.read(), Maps.newHashMap(), 0);
  }
"
"  @Test
  public void checkBlockSendResultTest() {
    SparkConf conf = new SparkConf();
    conf.setAppName(""testApp"")
        .setMaster(""local[2]"")
        .set(RssClientConfig.RSS_TEST_FLAG, ""true"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_TIMEOUT, ""10000"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_INTERVAL, ""1000"")
        .set(RssClientConfig.RSS_COORDINATOR_QUORUM, ""127.0.0.1:12345,127.0.0.1:12346"");
    // init SparkContext
    SparkContext sc = SparkContext.getOrCreate(conf);
    Map<String, Set<Long>> failBlocks = Maps.newConcurrentMap();
    Map<String, Set<Long>> successBlocks = Maps.newConcurrentMap();
    Serializer kryoSerializer = new KryoSerializer(conf);
    RssShuffleManager manager = TestUtils.createShuffleManager(
        conf,
        false,
        null,
        successBlocks,
        failBlocks);

    ShuffleWriteClient mockShuffleWriteClient = mock(ShuffleWriteClient.class);
    Partitioner mockPartitioner = mock(Partitioner.class);
    RssShuffleHandle mockHandle = mock(RssShuffleHandle.class);
    ShuffleDependency mockDependency = mock(ShuffleDependency.class);
    when(mockHandle.getDependency()).thenReturn(mockDependency);
    when(mockPartitioner.numPartitions()).thenReturn(2);
    TaskMemoryManager mockTaskMemoryManager = mock(TaskMemoryManager.class);
    when(mockHandle.getPartitionToServers()).thenReturn(Maps.newHashMap());
    when(mockDependency.partitioner()).thenReturn(mockPartitioner);

    BufferManagerOptions bufferOptions = new BufferManagerOptions(conf);
    WriteBufferManager bufferManager = new WriteBufferManager(
        0, 0, bufferOptions, kryoSerializer,
        Maps.newHashMap(), mockTaskMemoryManager, new ShuffleWriteMetrics());
    WriteBufferManager bufferManagerSpy = spy(bufferManager);

    RssShuffleWriter rssShuffleWriter = new RssShuffleWriter(""appId"", 0, ""taskId"", 1L,
        bufferManagerSpy, (new TaskMetrics()).shuffleWriteMetrics(),
        manager, conf, mockShuffleWriteClient, mockHandle);
    doReturn(1000000L).when(bufferManagerSpy).acquireMemory(anyLong());

    // case 1: all blocks are sent successfully
    successBlocks.put(""taskId"", Sets.newHashSet(1L, 2L, 3L));
    rssShuffleWriter.checkBlockSendResult(Sets.newHashSet(1L, 2L, 3L));
    successBlocks.clear();

    // case 2: partial blocks aren't sent before spark.rss.writer.send.check.timeout,
    // Runtime exception will be thrown
    successBlocks.put(""taskId"", Sets.newHashSet(1L, 2L));
    thrown.expect(RuntimeException.class);
    thrown.expectMessage(StringStartsWith.startsWith(""Timeout:""));
    rssShuffleWriter.checkBlockSendResult(Sets.newHashSet(1L, 2L, 3L));
    successBlocks.clear();

    // case 3: partial blocks are sent failed, Runtime exception will be thrown
    successBlocks.put(""taskId"", Sets.newHashSet(1L, 2L));
    failBlocks.put(""taskId"", Sets.newHashSet(3L));
    thrown.expect(RuntimeException.class);
    thrown.expectMessage(StringStartsWith.startsWith(""Send failed:""));
    rssShuffleWriter.checkBlockSendResult(Sets.newHashSet(1L, 2L, 3L));
    successBlocks.clear();
    failBlocks.clear();

    sc.stop();
  }
"
"  @Test
  public void writeTest() throws Exception {
    SparkConf conf = new SparkConf();
    conf.setAppName(""testApp"").setMaster(""local[2]"")
        .set(RssClientConfig.RSS_WRITER_SERIALIZER_BUFFER_SIZE, ""32"")
        .set(RssClientConfig.RSS_WRITER_BUFFER_SIZE, ""32"")
        .set(RssClientConfig.RSS_TEST_FLAG, ""true"")
        .set(RssClientConfig.RSS_WRITER_BUFFER_SEGMENT_SIZE, ""64"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_TIMEOUT, ""10000"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_INTERVAL, ""1000"")
        .set(RssClientConfig.RSS_WRITER_BUFFER_SPILL_SIZE, ""128"")
        .set(RssClientConfig.RSS_COORDINATOR_QUORUM, ""127.0.0.1:12345,127.0.0.1:12346"");
    // init SparkContext
    List<ShuffleBlockInfo> shuffleBlockInfos = Lists.newArrayList();
    SparkContext sc = SparkContext.getOrCreate(conf);
    Map<String, Set<Long>> successBlockIds = Maps.newConcurrentMap();
    EventLoop<AddBlockEvent> testLoop = new EventLoop<AddBlockEvent>(""test"") {
      @Override
      public void onReceive(AddBlockEvent event) {
        assertEquals(""taskId"", event.getTaskId());
        shuffleBlockInfos.addAll(event.getShuffleDataInfoList());
        Set<Long> blockIds = event.getShuffleDataInfoList().parallelStream()
            .map(sdi -> sdi.getBlockId()).collect(Collectors.toSet());
        successBlockIds.putIfAbsent(event.getTaskId(), Sets.newConcurrentHashSet());
        successBlockIds.get(event.getTaskId()).addAll(blockIds);
      }
"
"  @Test
  public void postBlockEventTest() throws Exception {
    WriteBufferManager mockBufferManager = mock(WriteBufferManager.class);
    ShuffleDependency mockDependency = mock(ShuffleDependency.class);
    ShuffleWriteMetrics mockMetrics = mock(ShuffleWriteMetrics.class);
    Partitioner mockPartitioner = mock(Partitioner.class);
    when(mockDependency.partitioner()).thenReturn(mockPartitioner);
    SparkConf sparkConf = new SparkConf();
    when(mockPartitioner.numPartitions()).thenReturn(2);
    List<AddBlockEvent> events = Lists.newArrayList();

    EventLoop<AddBlockEvent> eventLoop = new EventLoop<AddBlockEvent>(""test"") {
      @Override
      public void onReceive(AddBlockEvent event) {
        events.add(event);
      }
"
"  @Test
  public void readTest() throws Exception {

    String basePath = HDFS_URI + ""readTest1"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
     writeTestData(writeHandler, 2, 5, expectedData,
        blockIdBitmap, ""key"", KRYO_SERIALIZER, 0);

    TaskContext contextMock = mock(TaskContext.class);
    RssShuffleHandle handleMock = mock(RssShuffleHandle.class);
    ShuffleDependency dependencyMock = mock(ShuffleDependency.class);
    when(handleMock.getAppId()).thenReturn(""appId"");
    when(handleMock.getShuffleId()).thenReturn(1);
    when(handleMock.getDependency()).thenReturn(dependencyMock);
    when(dependencyMock.serializer()).thenReturn(KRYO_SERIALIZER);
    when(contextMock.taskAttemptId()).thenReturn(1L);
    when(contextMock.attemptNumber()).thenReturn(1);
    when(contextMock.taskMetrics()).thenReturn(new TaskMetrics());
    doNothing().when(contextMock).killTaskIfInterrupted();
    when(dependencyMock.mapSideCombine()).thenReturn(false);
    when(dependencyMock.aggregator()).thenReturn(Option.empty());
    when(dependencyMock.keyOrdering()).thenReturn(Option.empty());

    RssShuffleReader rssShuffleReaderSpy = spy(new RssShuffleReader<String, String>(0, 1, contextMock,
        handleMock, basePath, 1000, conf, StorageType.HDFS.name(),
        1000, 2, 10, blockIdBitmap, taskIdBitmap));

    validateResult(rssShuffleReaderSpy.read(), expectedData, 10);
  }
"
"  @Test
  public void checkBlockSendResultTest() {
    SparkConf conf = new SparkConf();
    conf.setAppName(""testApp"")
        .setMaster(""local[2]"")
        .set(RssClientConfig.RSS_TEST_FLAG, ""true"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_TIMEOUT, ""10000"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_INTERVAL, ""1000"")
        .set(RssClientConfig.RSS_COORDINATOR_QUORUM, ""127.0.0.1:12345,127.0.0.1:12346"");
    // init SparkContext
    SparkContext sc = SparkContext.getOrCreate(conf);
    RssShuffleManager manager = new RssShuffleManager(conf, false);

    Serializer kryoSerializer = new KryoSerializer(conf);
    ShuffleWriteClient mockShuffleWriteClient = mock(ShuffleWriteClient.class);
    Partitioner mockPartitioner = mock(Partitioner.class);
    ShuffleDependency mockDependency = mock(ShuffleDependency.class);
    RssShuffleHandle mockHandle = mock(RssShuffleHandle.class);
    when(mockHandle.getDependency()).thenReturn(mockDependency);
    when(mockDependency.partitioner()).thenReturn(mockPartitioner);
    when(mockPartitioner.numPartitions()).thenReturn(2);
    when(mockHandle.getPartitionToServers()).thenReturn(Maps.newHashMap());
    TaskMemoryManager mockTaskMemoryManager = mock(TaskMemoryManager.class);

    BufferManagerOptions bufferOptions = new BufferManagerOptions(conf);
    WriteBufferManager bufferManager = new WriteBufferManager(
        0, 0, bufferOptions, kryoSerializer,
        Maps.newHashMap(), mockTaskMemoryManager, new ShuffleWriteMetrics());
    WriteBufferManager bufferManagerSpy = spy(bufferManager);
    doReturn(1000000L).when(bufferManagerSpy).acquireMemory(anyLong());

    RssShuffleWriter rssShuffleWriter = new RssShuffleWriter(""appId"", 0, ""taskId"", 1L,
        bufferManagerSpy, (new TaskMetrics()).shuffleWriteMetrics(),
        manager, conf, mockShuffleWriteClient, mockHandle);

    // case 1: all blocks are sent successfully
    manager.addSuccessBlockIds(""taskId"", Sets.newHashSet(1L, 2L, 3L));
    rssShuffleWriter.checkBlockSendResult(Sets.newHashSet(1L, 2L, 3L));
    manager.clearCachedBlockIds();

    // case 2: partial blocks aren't sent before spark.rss.writer.send.check.timeout,
    // Runtime exception will be thrown
    manager.addSuccessBlockIds(""taskId"", Sets.newHashSet(1L, 2L));
    thrown.expect(RuntimeException.class);
    thrown.expectMessage(StringStartsWith.startsWith(""Timeout:""));
    rssShuffleWriter.checkBlockSendResult(Sets.newHashSet(1L, 2L, 3L));

    manager.clearCachedBlockIds();

    // case 3: partial blocks are sent failed, Runtime exception will be thrown
    manager.addSuccessBlockIds(""taskId"", Sets.newHashSet(1L, 2L));
    manager.addFailedBlockIds(""taskId"", Sets.newHashSet(3L));
    thrown.expect(RuntimeException.class);
    thrown.expectMessage(StringStartsWith.startsWith(""Send failed:""));
    rssShuffleWriter.checkBlockSendResult(Sets.newHashSet(1L, 2L, 3L));
    manager.clearCachedBlockIds();

    sc.stop();
  }
"
"  @Test
  public void writeTest() throws Exception {
    SparkConf conf = new SparkConf();
    conf.setAppName(""testApp"").setMaster(""local[2]"")
        .set(RssClientConfig.RSS_TEST_FLAG, ""true"")
        .set(RssClientConfig.RSS_WRITER_BUFFER_SIZE, ""32"")
        .set(RssClientConfig.RSS_WRITER_SERIALIZER_BUFFER_SIZE, ""32"")
        .set(RssClientConfig.RSS_WRITER_BUFFER_SEGMENT_SIZE, ""64"")
        .set(RssClientConfig.RSS_WRITER_BUFFER_SPILL_SIZE, ""128"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_TIMEOUT, ""10000"")
        .set(RssClientConfig.RSS_WRITER_SEND_CHECK_INTERVAL, ""1000"")
        .set(RssClientConfig.RSS_COORDINATOR_QUORUM, ""127.0.0.1:12345,127.0.0.1:12346"");
    // init SparkContext
    SparkContext sc = SparkContext.getOrCreate(conf);
    RssShuffleManager manager = new RssShuffleManager(conf, false);
    List<ShuffleBlockInfo> shuffleBlockInfos = Lists.newArrayList();

    manager.setEventLoop(new EventLoop<AddBlockEvent>(""test"") {
      @Override
      public void onReceive(AddBlockEvent event) {
        assertEquals(""taskId"", event.getTaskId());
        shuffleBlockInfos.addAll(event.getShuffleDataInfoList());
        Set<Long> blockIds = event.getShuffleDataInfoList().parallelStream()
            .map(sdi -> sdi.getBlockId()).collect(Collectors.toSet());
        manager.addSuccessBlockIds(event.getTaskId(), blockIds);
      }
"
"  @Test
  public void postBlockEventTest() throws Exception {
    WriteBufferManager mockBufferManager = mock(WriteBufferManager.class);
    ShuffleWriteMetrics mockMetrics = mock(ShuffleWriteMetrics.class);
    ShuffleDependency mockDependency = mock(ShuffleDependency.class);
    Partitioner mockPartitioner = mock(Partitioner.class);
    RssShuffleManager mockShuffleManager = mock(RssShuffleManager.class);
    when(mockDependency.partitioner()).thenReturn(mockPartitioner);
    when(mockPartitioner.numPartitions()).thenReturn(2);
    List<AddBlockEvent> events = Lists.newArrayList();

    EventLoop<AddBlockEvent> eventLoop = new EventLoop<AddBlockEvent>(""test"") {
      @Override
      public void onReceive(AddBlockEvent event) {
        events.add(event);
      }
"
"  @Test
  public void getBlockIdTest() {
    // max value of blockId
    assertEquals(
        new Long(9223372036854775807L), ClientUtils.getBlockId(16777215, 1048575, 524287));
    // just a random test
    assertEquals(
        new Long(1759218709299300L), ClientUtils.getBlockId(100, 100, 100));
    // min value of blockId
    assertEquals(
        new Long(0L), ClientUtils.getBlockId(0, 0, 0));
    try {
      ClientUtils.getBlockId(16777216, 0, 0);
      fail(EXCEPTION_EXPECTED);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Can't support partitionId[16777216], the max value should be 16777215""));
    }
    try {
      ClientUtils.getBlockId(0, 1048576, 0);
      fail(EXCEPTION_EXPECTED);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Can't support taskAttemptId[1048576], the max value should be 1048575""));
    }
    try {
      ClientUtils.getBlockId(0, 0, 524288);
      fail(EXCEPTION_EXPECTED);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Can't support sequence[524288], the max value should be 524287""));
    }
  }
"
"  @Test
  public void getBitmapNumTest() {
    // max value of taskNum, partitionNum, blockNumPerTaskPerPartition, it is unexpected in real job
    assertEquals(
        2147483647, ClientUtils.getBitmapNum(Integer.MAX_VALUE, Integer.MAX_VALUE, 1000000, 100000000L));
    // taskNum * partitionNum * blockNumPerTaskPerPartition / blockNumPerBitmap > 0
    assertEquals(
        5001, ClientUtils.getBitmapNum(100000, 100000, 50, 100000000L));
    // taskNum * partitionNum * blockNumPerTaskPerPartition / blockNumPerBitmap = 0
    assertEquals(
        1, ClientUtils.getBitmapNum(1999, 1999, 50, 100000000L));
    try {
      ClientUtils.getBitmapNum(1, 1, 1, 19999999L);
      fail(EXCEPTION_EXPECTED);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""blockNumPerBitmap should be greater than""));
    }
    try {
      ClientUtils.getBitmapNum(1, 1, 1000001, 20000000L);
      fail(EXCEPTION_EXPECTED);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""blockNumPerTaskPerPartition should be less than""));
    }
  }
"
"  @Test
  public void readTest1() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest1"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 1, 1, basePath, ""test1"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 30, 0, expectedData,
        blockIdBitmap);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 100, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    blockIdBitmap.addLong(Constants.MAX_TASK_ATTEMPT_ID - 1);
    taskIdBitmap.addLong(Constants.MAX_TASK_ATTEMPT_ID - 1);
    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 100, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());
    TestUtils.validateResult(readClient, expectedData);
    try {
      // can't find all expected block id, data loss
      readClient.checkProcessedBlockIds();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Blocks read inconsistent:""));
    } finally {
      readClient.close();
    }
  }
"
"  @Test
  public void readTest2() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest2"";
    HdfsShuffleWriteHandler writeHandler1 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test2_1"", conf);
    HdfsShuffleWriteHandler writeHandler2 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test2_2"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler1, 2, 30, 0, expectedData, blockIdBitmap);
    writeTestData(writeHandler2, 2, 30, 0, expectedData, blockIdBitmap);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
"
"  @Test
  public void readTest3() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest3"";
    HdfsShuffleWriteHandler writeHandler1 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test3_1"", conf);
    HdfsShuffleWriteHandler writeHandler2 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test3_2"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler1, 2, 30, 0, expectedData, blockIdBitmap);
    writeTestData(writeHandler2, 2, 30, 0, expectedData, blockIdBitmap);

    // duplicate file created, it should be used in product environment
    String shuffleFolder = basePath + ""/appId/0/0-1"";
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_1_0.data""), fs,
        new Path(basePath + ""/test3_1.cp.data""), false, conf);
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_1_0.index""), fs,
        new Path(basePath + ""/test3_1.cp.index""), false, conf);
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_2_0.data""), fs,
        new Path(basePath + ""/test3_2.cp.data""), false, conf);
    FileUtil.copy(fs, new Path(shuffleFolder + ""/test3_2_0.index""), fs,
        new Path(basePath + ""/test3_2.cp.index""), false, conf);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
"
"  @Test
  public void readTest4() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest4"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test1"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 30, 0, expectedData, blockIdBitmap);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());
    Path dataFile = new Path(basePath + ""/appId/0/0-1/test1_0.data"");
    // data file is deleted after readClient checkExpectedBlockIds
    fs.delete(new Path(basePath + ""/appId/0/0-1/test1_0.data""), true);
    // sleep to wait delete operation
    Thread.sleep(10000);

    assertNull(readClient.readShuffleBlockData());
    try {
      fs.listStatus(dataFile);
      fail(""Index file should be deleted"");
    } catch (Exception e) {
    }

    try {
      readClient.checkProcessedBlockIds();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().startsWith(""Blocks read inconsistent: expected""));
    }
    readClient.close();
  }
"
"  @Test
  public void readTest5() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest5"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 30, 0, expectedData, blockIdBitmap);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());
    // index file is deleted after iterator initialization, it should be ok, all index infos are read already
    Path indexFile = new Path(basePath + ""/appId/0/0-1/test.index"");
    fs.delete(indexFile, true);
    readClient.close();

    assertNull(readClient.readShuffleBlockData());
  }
"
"  @Test
  public void readTest7() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest7"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<Long, byte[]> expectedData1 = Maps.newHashMap();
    Map<Long, byte[]> expectedData2 = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 10, 30, 0, expectedData1, blockIdBitmap1);

    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    writeTestData(writeHandler, 10, 30, 0, expectedData2, blockIdBitmap2);

    writeTestData(writeHandler, 10, 30, 0, expectedData1, blockIdBitmap1);

    ShuffleReadClientImpl readClient1 = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 0, 100, 2, 10, 100,
        basePath, blockIdBitmap1, taskIdBitmap, Lists.newArrayList(), new Configuration());
    ShuffleReadClientImpl readClient2 = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 100,
        basePath, blockIdBitmap2, taskIdBitmap, Lists.newArrayList(), new Configuration());
    TestUtils.validateResult(readClient1, expectedData1);
    readClient1.checkProcessedBlockIds();
    readClient1.close();

    TestUtils.validateResult(readClient2, expectedData2);
    readClient2.checkProcessedBlockIds();
    readClient2.close();
  }
"
"  @Test
  public void readTest8() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest8"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 30, 0, expectedData, blockIdBitmap);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());
    // crc32 is incorrect
    try (MockedStatic<ChecksumUtils> checksumUtilsMock = Mockito.mockStatic(ChecksumUtils.class)) {
      checksumUtilsMock.when(() -> ChecksumUtils.getCrc32((ByteBuffer) any())).thenReturn(-1L);
      try {
        ByteBuffer bb = readClient.readShuffleBlockData().getByteBuffer();
        while (bb != null) {
          bb = readClient.readShuffleBlockData().getByteBuffer();
        }
        fail(EXPECTED_EXCEPTION_MESSAGE);
      } catch (Exception e) {
        assertTrue(e.getMessage().startsWith(""Unexpected crc value""));
      }
    }
    readClient.close();
  }
"
"  @Test
  public void readTest9() {
    // empty data
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        ""basePath"", Roaring64NavigableMap.bitmapOf(), Roaring64NavigableMap.bitmapOf(),
        Lists.newArrayList(), new Configuration());
    assertNull(readClient.readShuffleBlockData());
    readClient.checkProcessedBlockIds();
  }
"
"  @Test
  public void readTest10() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest10"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 5, 30, 0, expectedData, blockIdBitmap);
    Roaring64NavigableMap wrongBlockIdBitmap = Roaring64NavigableMap.bitmapOf();
    LongIterator iter = blockIdBitmap.getLongIterator();
    while (iter.hasNext()) {
      wrongBlockIdBitmap.addLong(iter.next() + (1 << Constants.TASK_ATTEMPT_ID_MAX_LENGTH));
    }

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 0, 100, 2, 10, 100,
        basePath, wrongBlockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());
    assertNull(readClient.readShuffleBlockData());
    try {
      readClient.checkProcessedBlockIds();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Blocks read inconsistent:""));
    }
  }
"
"  @Test
  public void readTest11() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest11"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 1, 1, basePath, ""test1"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 10, 30, 0, expectedData, blockIdBitmap);

    // test with different indexReadLimit to validate result
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 1, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 2, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 3, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 10, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 11, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
"
"  @Test
  public void readTest12() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest12"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 1, 1, basePath, ""test1"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0, 1);
    writeTestData(writeHandler, 5, 30, 0, expectedData, blockIdBitmap);
    writeTestData(writeHandler, 5, 30, 1, expectedData, blockIdBitmap);
    writeTestData(writeHandler, 5, 30, 2, Maps.newHashMap(), blockIdBitmap);

    // unexpected taskAttemptId should be filtered
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 100, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    assertEquals(15, readClient.getProcessedBlockIds().getLongCardinality());
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
"
"  @Test
  public void readTest13() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest13"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 1, 1, basePath, ""test1"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0, 3);
    writeTestData(writeHandler, 5, 30, 0, expectedData, blockIdBitmap);
    // test case: data generated by speculation task without report result
    writeTestData(writeHandler, 5, 30, 1, Maps.newHashMap(), Roaring64NavigableMap.bitmapOf());
    // test case: data generated by speculation task with report result
    writeTestData(writeHandler, 5, 30, 2, Maps.newHashMap(), blockIdBitmap);
    writeTestData(writeHandler, 5, 30, 3, expectedData, blockIdBitmap);

    // unexpected taskAttemptId should be filtered
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 100, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    assertEquals(20, readClient.getProcessedBlockIds().getLongCardinality());
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
"
"  @Test
  public void readTest14() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest14"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 1, 1, basePath, ""test1"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0, 2);
    writeDuplicatedData(writeHandler, 5, 30, 0, expectedData, blockIdBitmap);
    writeTestData(writeHandler, 5, 30, 1, Maps.newHashMap(), Roaring64NavigableMap.bitmapOf());
    writeTestData(writeHandler, 5, 30, 2, expectedData, blockIdBitmap);

    // unexpected taskAttemptId should be filtered
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(), ""appId"", 0, 1, 100, 1,
        10, 1000, basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    assertEquals(15, readClient.getProcessedBlockIds().getLongCardinality());
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
"
"  @Test
  public void testSendData() {
    ShuffleWriteClientImpl shuffleWriteClient =
        new ShuffleWriteClientImpl(""GRPC"", 3, 2000, 4);
    ShuffleServerClient mockShuffleServerClient = mock(ShuffleServerClient.class);
    ShuffleWriteClientImpl spyClient = spy(shuffleWriteClient);
    doReturn(mockShuffleServerClient).when(spyClient).getShuffleServerClient(any());
    when(mockShuffleServerClient.sendShuffleData(any())).thenReturn(
        new RssSendShuffleDataResponse(ResponseStatusCode.NO_BUFFER));

    List<ShuffleServerInfo> shuffleServerInfoList =
        Lists.newArrayList(new ShuffleServerInfo(""id"", ""host"", 0));
    List<ShuffleBlockInfo> shuffleBlockInfoList = Lists.newArrayList(new ShuffleBlockInfo(
        0, 0, 10, 10, 10, new byte[]{1}, shuffleServerInfoList, 10, 100, 0));
    SendShuffleDataResult result = spyClient.sendShuffleData(""appId"", shuffleBlockInfoList);

    assertTrue(result.getFailedBlockIds().contains(10L));
  }
"
"  @Test
  public void jettyServerTest() throws FileNotFoundException {
    RssBaseConf conf = new RssBaseConf();
    conf.setString(""rss.jetty.http.port"", ""9527"");
    JettyServer jettyServer = new JettyServer(conf);
    Server server = jettyServer.getServer();

    assertEquals(4, server.getBeans().size());
    assertEquals(30000, server.getStopTimeout());
    assertTrue(server.getThreadPool() instanceof ExecutorThreadPool);

    assertEquals(1, server.getConnectors().length);
    assertEquals(server, server.getHandler().getServer());
    assertTrue(server.getConnectors()[0] instanceof ServerConnector);
    ServerConnector connector = (ServerConnector) server.getConnectors()[0];
    assertEquals(9527, connector.getPort());

    assertEquals(1, server.getHandlers().length);
    Handler handler = server.getHandler();
    assertTrue(handler instanceof ServletContextHandler);
  }
"
"  @Test
  public void jettyServerStartTest() throws Exception {
    try {
      RssBaseConf conf = new RssBaseConf();
      conf.setString(""rss.jetty.http.port"", ""9527"");
      JettyServer jettyServer1 = new JettyServer(conf);
      JettyServer jettyServer2 = new JettyServer(conf);
      jettyServer1.start();

      ExitUtils.disableSystemExit();
      final String expectMessage = ""Fail to start jetty http server"";
      final int expectStatus = 1;
      try {
        jettyServer2.start();
      } catch (Exception e) {
        assertEquals(expectMessage, e.getMessage());
        assertEquals(expectStatus, ((ExitException) e).getStatus());
      }

      final Thread t = new Thread(null, () -> {
        throw new AssertionError(""TestUncaughtException"");
      }, ""testThread"");
      t.start();
      t.join();
    } catch (Exception e) {
      e.printStackTrace();
      fail();
    }

  }
"
"  @Test
  public void testBasicTypes() {
    final ConfigOption<Integer> intConfig = ConfigOptions
        .key(""rss.key1"")
        .intType()
        .defaultValue(1000)
        .withDescription(""Int config key1"");
    assertSame(Integer.class, intConfig.getClazz());
    assertEquals(1000, (int) intConfig.defaultValue());
    assertEquals(""Int config key1"", intConfig.description());

    final ConfigOption<Long> longConfig = ConfigOptions
        .key(""rss.key2"")
        .longType()
        .defaultValue(1999L);
    assertTrue(longConfig.hasDefaultValue());
    assertEquals(1999L, (long) longConfig.defaultValue());

    final ConfigOption<String> stringConfig = ConfigOptions
        .key(""rss.key3"")
        .stringType()
        .noDefaultValue();
    assertFalse(stringConfig.hasDefaultValue());
    assertEquals("""", stringConfig.description());

    final ConfigOption<Boolean> booleanConfig = ConfigOptions
        .key(""key4"")
        .booleanType()
        .defaultValue(false)
        .withDescription(""Boolean config key"");
    assertFalse(booleanConfig.defaultValue());
    assertEquals(""Boolean config key"", booleanConfig.description());

    final ConfigOption<Integer> positiveInt = ConfigOptions
        .key(""key5"")
        .intType()
        .checkValue((v) -> {return v > 0;}, ""The value of key5 must be positive"")
        .defaultValue(1)
        .withDescription(""Positive integer key"");
    RssBaseConf conf = new RssBaseConf();
    conf.set(positiveInt, -1);
    boolean isException = false;
    try {
      conf.get(positiveInt);
    } catch (IllegalArgumentException ie) {
      isException = true;
      assertTrue(ie.getMessage().contains(""The value of key5 must be positive""));
    }
    assertTrue(isException);
    conf.set(positiveInt, 1);
    try {
      conf.get(positiveInt);
    } catch (IllegalArgumentException ie) {
      fail();
    }
  }
"
"    @Test
    public void testOptionWithDefault() {
        RssConf cfg = new RssConf();
        cfg.setInteger(""int-key"", 11);
        cfg.setString(""string-key"", ""abc"");

        ConfigOption<String> presentStringOption = ConfigOptions
                .key(""string-key"")
                .stringType()
                .defaultValue(""my-beautiful-default"");
        ConfigOption<Integer> presentIntOption = ConfigOptions
                .key(""int-key"")
                .intType()
                .defaultValue(87);

        assertEquals(""abc"", cfg.getString(presentStringOption));
        assertEquals(""abc"", cfg.getValue(presentStringOption));

        assertEquals(11, cfg.getInteger(presentIntOption));
        assertEquals(""11"", cfg.getValue(presentIntOption));
    }
"
"    @Test
    public void testSetStringAndGetConcreteType() {
        RssConf conf = new RssConf();
        conf.setString(""boolean-type"", ""true"");
        conf.setString(""int-type"", ""1111"");
        conf.setString(""long-type"", ""1000"");
        assertTrue(conf.getBoolean(""boolean-type"", false));
        assertEquals(conf.getInteger(""int-type"", 100), 1111);
        assertEquals(conf.getLong(""long-type"", 222L), 1000L);
    }
"
"    @Test
    public void testOptionWithNoDefault() {
        RssConf cfg = new RssConf();
        cfg.setInteger(""int-key"", 11);
        cfg.setString(""string-key"", ""abc"");

        ConfigOption<String> presentStringOption = ConfigOptions
                .key(""string-key"")
                .stringType()
                .noDefaultValue();

        assertEquals(""abc"", cfg.getString(presentStringOption));
        assertEquals(""abc"", cfg.getValue(presentStringOption));

        // test getting default when no value is present

        ConfigOption<String> stringOption = ConfigOptions
                .key(""test"")
                .stringType()
                .noDefaultValue();

        // getting strings for null should work
        assertNull(cfg.getValue(stringOption));
        assertNull(cfg.getString(stringOption));

        // overriding the null default should work
        assertEquals(""override"", cfg.getString(stringOption, ""override""));
    }
"
"  @Test
  public void crc32TestWithByte() {
    byte[] data = new byte[32 * 1024 * 1024];
    new Random().nextBytes(data);
    CRC32 crc32 = new CRC32();
    crc32.update(data);
    long expected = crc32.getValue();
    assertEquals(expected, ChecksumUtils.getCrc32(data));

    data = new byte[32 * 1024];
    new Random().nextBytes(data);
    crc32 = new CRC32();
    crc32.update(data);
    expected = crc32.getValue();
    assertEquals(expected, ChecksumUtils.getCrc32(data));
  }
"
"  @Test
  public void crc32TestWithByteBuff() throws Exception {
    int length = 32 * 1024 * 1024;
    byte[] data = new byte[length];
    new Random().nextBytes(data);

    String tempDir = Files.createTempDirectory(""rss"").toString();
    File file = new File(tempDir, ""crc_test.txt"");
    file.createNewFile();
    file.deleteOnExit();

    try (FileOutputStream outputStream = new FileOutputStream(file)) {
      outputStream.write(data);
    }

    long expectedChecksum = ChecksumUtils.getCrc32(data);

    // test direct ByteBuffer
    Path path = Paths.get(file.getAbsolutePath());
    FileChannel fileChannel = FileChannel.open(path);
    ByteBuffer buffer = ByteBuffer.allocateDirect(length);
    int bytesRead = fileChannel.read(buffer);
    fileChannel.close();
    assertEquals(length, bytesRead);
    buffer.flip();
    assertEquals(expectedChecksum, ChecksumUtils.getCrc32(buffer));
    assertEquals(length, buffer.position());

    // test heap ByteBuffer
    path = Paths.get(file.getAbsolutePath());
    fileChannel = FileChannel.open(path);
    buffer = ByteBuffer.allocate(length);
    bytesRead = fileChannel.read(buffer);
    fileChannel.close();
    assertEquals(length, bytesRead);
    buffer.flip();
    assertEquals(expectedChecksum, ChecksumUtils.getCrc32(buffer));

  }
"
"  @Test
  public void testGetPropertiesFromFile() {
    final String filePath = Objects.requireNonNull(
        getClass().getClassLoader().getResource(""rss-defaults.conf"")).getFile();
    Map<String, String> properties = RssUtils.getPropertiesFromFile(filePath);
    assertEquals(""12121"", properties.get(""rss.coordinator.port""));
    assertEquals(""155"", properties.get(""rss.server.heartbeat.interval""));
    assertEquals(""true"", properties.get(""rss.x.y.z""));
    assertEquals(""-XX:+PrintGCDetails-Dkey=value-Dnumbers=\""one two three\"""",
        properties.get(""rss.a.b.c.extraJavaOptions""));
  }
"
"  @Test
  public void testGetHostIp() {
    try {
      String address = InetAddress.getLocalHost().getHostAddress();
      String realIp = RssUtils.getHostIp();
      assertNotEquals(""127.0.0.1"", realIp);
      if (!address.equals(""127.0.0.1"")) {
        assertEquals(address, realIp);
      }
    } catch (Exception e) {
      fail(e.getMessage());
    }
  }
"
"  @Test
  public void testSerializeBitmap() throws Exception {
    Roaring64NavigableMap bitmap1 = Roaring64NavigableMap.bitmapOf(1, 2, 100, 10000);
    byte[] bytes = RssUtils.serializeBitMap(bitmap1);
    Roaring64NavigableMap bitmap2 = RssUtils.deserializeBitMap(bytes);
    assertEquals(bitmap1, bitmap2);
    assertEquals(Roaring64NavigableMap.bitmapOf(), RssUtils.deserializeBitMap(new byte[]{}));
  }
"
"  @Test
  public void testShuffleIndexSegment() {
    ShuffleIndexResult shuffleIndexResult = new ShuffleIndexResult();
    List<ShuffleDataSegment> shuffleDataSegments =
        RssUtils.transIndexDataToSegments(shuffleIndexResult, 1000);
    assertTrue(shuffleDataSegments.isEmpty());

    int readBufferSize = 32;
    int totalLength = 0;
    List<BufferSegment> bufferSegments = Lists.newArrayList();
    int[] dataSegmentLength = new int[]{32, 16, 10, 32, 6};

    for (int i = 0; i < dataSegmentLength.length; ++i) {
      long offset = totalLength;
      int length = dataSegmentLength[i];
      bufferSegments.add(new BufferSegment(i, offset, length, i, i, i));
      totalLength += length;
    }

    // those 5 segment's data length are [32, 16, 10, 32, 6] so the index should be
    // split into 3 ShuffleDataSegment, which are [32, 16 + 10 + 32, 6]
    int expectedTotalSegmentNum = 3;
    ByteBuffer byteBuffer = ByteBuffer.allocate(5 * 40);

    for (BufferSegment bufferSegment : bufferSegments) {
      byteBuffer.putLong(bufferSegment.getOffset());
      byteBuffer.putInt(bufferSegment.getLength());
      byteBuffer.putInt(bufferSegment.getUncompressLength());
      byteBuffer.putLong(bufferSegment.getCrc());
      byteBuffer.putLong(bufferSegment.getBlockId());
      byteBuffer.putLong(bufferSegment.getTaskAttemptId());
    }

    byte[] data = byteBuffer.array();
    shuffleDataSegments = RssUtils.transIndexDataToSegments(new ShuffleIndexResult(data), readBufferSize);
    assertEquals(expectedTotalSegmentNum, shuffleDataSegments.size());

    assertEquals(0, shuffleDataSegments.get(0).getOffset());
    assertEquals(32, shuffleDataSegments.get(0).getLength());
    assertEquals(1, shuffleDataSegments.get(0).getBufferSegments().size());

    assertEquals(32, shuffleDataSegments.get(1).getOffset());
    assertEquals(58, shuffleDataSegments.get(1).getLength());
    assertEquals(3,shuffleDataSegments.get(1).getBufferSegments().size());

    assertEquals(90, shuffleDataSegments.get(2).getOffset());
    assertEquals(6, shuffleDataSegments.get(2).getLength());
    assertEquals(1, shuffleDataSegments.get(2).getBufferSegments().size());
  }
"
"  @Test
  public void test() {
    try {
    final int status = -1;
    final String testExitMessage = ""testExitMessage"";
    try {
      ExitUtils.disableSystemExit();
      ExitUtils.terminate(status, testExitMessage, null, null);
      fail();
    } catch (ExitException e) {
      assertEquals(status, e.getStatus());
      assertEquals(testExitMessage, e.getMessage());
    }

    final Thread t = new Thread(null, () -> {
      throw new AssertionError(""TestUncaughtException"");
    }, ""testThread"");
    t.start();
    t.join();
  } catch (Exception e) {
      e.printStackTrace();
      fail();
    }

  }
"
"  @Test
  public void testByteString() {

    assertEquals(10 * PB, UnitConverter.byteStringAs(""10PB"", ByteUnit.BYTE));
    assertEquals(10 * PB, UnitConverter.byteStringAs(""10pb"", ByteUnit.BYTE));
    assertEquals(10 * PB, UnitConverter.byteStringAs(""10pB"", ByteUnit.BYTE));
    assertEquals(10 * PB, UnitConverter.byteStringAs(""10p"", ByteUnit.BYTE));
    assertEquals(10 * PB, UnitConverter.byteStringAs(""10P"", ByteUnit.BYTE));

    assertEquals(10 * TB, UnitConverter.byteStringAs(""10TB"", ByteUnit.BYTE));
    assertEquals(10 * TB, UnitConverter.byteStringAs(""10tb"", ByteUnit.BYTE));
    assertEquals(10 * TB, UnitConverter.byteStringAs(""10tB"", ByteUnit.BYTE));
    assertEquals(10 * TB, UnitConverter.byteStringAs(""10T"", ByteUnit.BYTE));
    assertEquals(10 * TB, UnitConverter.byteStringAs(""10t"", ByteUnit.BYTE));

    assertEquals(10 * GB, UnitConverter.byteStringAs(""10GB"", ByteUnit.BYTE));
    assertEquals(10 * GB, UnitConverter.byteStringAs(""10gb"", ByteUnit.BYTE));
    assertEquals(10 * GB, UnitConverter.byteStringAs(""10gB"", ByteUnit.BYTE));

    assertEquals(10 * MB, UnitConverter.byteStringAs(""10MB"", ByteUnit.BYTE));
    assertEquals(10 * MB, UnitConverter.byteStringAs(""10mb"", ByteUnit.BYTE));
    assertEquals(10 * MB, UnitConverter.byteStringAs(""10mB"", ByteUnit.BYTE));
    assertEquals(10 * MB, UnitConverter.byteStringAs(""10M"", ByteUnit.BYTE));
    assertEquals(10 * MB, UnitConverter.byteStringAs(""10m"", ByteUnit.BYTE));

    assertEquals(10 * KB, UnitConverter.byteStringAs(""10KB"", ByteUnit.BYTE));
    assertEquals(10 * KB, UnitConverter.byteStringAs(""10kb"", ByteUnit.BYTE));
    assertEquals(10 * KB, UnitConverter.byteStringAs(""10Kb"", ByteUnit.BYTE));
    assertEquals(10 * KB, UnitConverter.byteStringAs(""10K"", ByteUnit.BYTE));
    assertEquals(10 * KB, UnitConverter.byteStringAs(""10k"", ByteUnit.BYTE));

    assertEquals(1111, UnitConverter.byteStringAs(""1111"", ByteUnit.BYTE));
  }
"
"  @Test
  public void argTest() {
    String[] args = {""-c"", confFile};
    Arguments arguments = new Arguments();
    CommandLine commandLine = new CommandLine(arguments);
    commandLine.parseArgs(args);
    assertEquals(confFile, arguments.getConfigFile());
  }
"
"  @Test
  public void argEmptyTest() {
    String[] args = new String[0];
    Arguments arguments = new Arguments();
    CommandLine commandLine = new CommandLine(arguments);
    commandLine.parseArgs(args);
    assertNull(arguments.getConfigFile());
  }
"
"  @Test
  public void testMetricsManager() {
    MetricsManager metricsManager = new MetricsManager();
    assertEquals(CollectorRegistry.defaultRegistry, metricsManager.getCollectorRegistry());

    CollectorRegistry expectedRegistry = new CollectorRegistry();
    metricsManager = new MetricsManager(expectedRegistry);
    assertEquals(expectedRegistry, metricsManager.getCollectorRegistry());

    String expectedName1 = ""counter"";
    String expectedHelp1 = ""Counter "" + expectedName1;
    metricsManager.addCounter(expectedName1);

    String expectedName2 = ""name2"";
    String expectedHelp2 = ""Gauge "" + expectedName2;
    String label = ""gaugeLabel"";
    Gauge gauge = metricsManager.addGauge(expectedName2, label);
    gauge.labels(""lv1"").inc();
    gauge.labels(""lv2"").inc();

    Map<String, MetricFamilySamples> metricsSamples = new HashMap<>();
    Enumeration<MetricFamilySamples> mfs = expectedRegistry.metricFamilySamples();
    while (mfs.hasMoreElements()) {
      MetricFamilySamples cur = mfs.nextElement();
      metricsSamples.put(cur.name, cur);
    }

    assertEquals(expectedHelp1, metricsSamples.get(expectedName1).help);
    assertEquals(1, metricsSamples.get(expectedName1).samples.size());

    assertEquals(expectedHelp2, metricsSamples.get(expectedName2).help);
    List<MetricFamilySamples.Sample> f = metricsSamples.get(expectedName2).samples;
    assertEquals(2, metricsSamples.get(expectedName2).samples.size());
    String[] actualLabelValues = metricsSamples
        .get(expectedName2).samples
        .stream().map(i -> i.labelValues.get(0))
        .collect(Collectors.toList()).toArray(new String[0]);
    Arrays.sort(actualLabelValues);
    assertArrayEquals(new String[]{""lv1"", ""lv2""}, actualLabelValues);
  }
"
"  @Test
  public void shufflePartitionedBlockTest() {
    byte[] buf = new byte[3];
    new Random().nextBytes(buf);

    ShufflePartitionedBlock b1 = new ShufflePartitionedBlock(1, 1, 2, 3, 1, buf);
    assertEquals(1, b1.getLength());
    assertEquals(2, b1.getCrc());
    assertEquals(3, b1.getBlockId());

    ShufflePartitionedBlock b3 = new ShufflePartitionedBlock(1, 1, 2, 3, 3, buf);
    assertArrayEquals(buf, b3.getData());
  }
"
"  @Test
  public void readTest1() {
    String testAppId = ""localReadTest1"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    createTestData(testAppId, expectedData, blockIdBitmap, taskIdBitmap);
    blockIdBitmap.addLong((1 << Constants.TASK_ATTEMPT_ID_MAX_LENGTH));
    ShuffleReadClientImpl readClient;
    readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", blockIdBitmap, taskIdBitmap, shuffleServerInfo, null);
    validateResult(readClient, expectedData);
    try {
      // can't find all expected block id, data loss
      readClient.checkProcessedBlockIds();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Blocks read inconsistent:""));
    } finally {
      readClient.close();
    }
  }
"
"  @Test
  public void readTest2() {
    String testAppId = ""localReadTest2"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 2, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);
    blocks = createShuffleBlockList(
        0, 0, 0, 2, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(),
        testAppId, 0, 0, 100, 1, 10, 1000,
        """", blockIdBitmap, taskIdBitmap, shuffleServerInfo, null);

    validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
"
"  @Test
  public void readTest3() throws Exception {
    String testAppId = ""localReadTest3"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 2, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(),
        testAppId, 0, 0, 100, 1, 10, 1000,
        """", blockIdBitmap, taskIdBitmap, shuffleServerInfo, null);
    FileUtils.deleteDirectory(new File(DATA_DIR1.getAbsolutePath() + ""/"" + testAppId + ""/0/0-0""));
    FileUtils.deleteDirectory(new File(DATA_DIR2.getAbsolutePath() + ""/"" + testAppId + ""/0/0-0""));
    // sleep to wait delete operation
    Thread.sleep(2000);

    try {
      readClient.readShuffleBlockData();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Failed to read shuffle index""));
    }
    readClient.close();
  }
"
"  @Test
  public void readTest4() {
    String testAppId = ""localReadTest4"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 1)));

    Map<Long, byte[]> expectedData1 = Maps.newHashMap();
    Map<Long, byte[]> expectedData2 = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 10, 30, blockIdBitmap1, expectedData1, mockSSI);
    sendTestData(testAppId, blocks);

    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    blocks = createShuffleBlockList(
        0, 1, 0, 10, 30, blockIdBitmap2, expectedData2, mockSSI);
    sendTestData(testAppId, blocks);

    blocks = createShuffleBlockList(
        0, 0, 0, 10, 30, blockIdBitmap1, expectedData1, mockSSI);
    sendTestData(testAppId, blocks);

    ShuffleReadClientImpl readClient1 = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(),
        testAppId, 0, 0, 100, 2, 10, 100,
        """", blockIdBitmap1, taskIdBitmap, shuffleServerInfo, null);
    ShuffleReadClientImpl readClient2 = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(),
        testAppId, 0, 1, 100, 2, 10, 100,
        """", blockIdBitmap2, taskIdBitmap, shuffleServerInfo, null);
    validateResult(readClient1, expectedData1);
    readClient1.checkProcessedBlockIds();
    readClient1.close();

    validateResult(readClient2, expectedData2);
    readClient2.checkProcessedBlockIds();
    readClient2.close();
  }
"
"  @Test
  public void readTest5() {
    String testAppId = ""localReadTest5"";
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(),
        testAppId, 0, 1, 100, 2, 10, 1000,
        """", Roaring64NavigableMap.bitmapOf(), Roaring64NavigableMap.bitmapOf(),
        shuffleServerInfo, null);
    assertNull(readClient.readShuffleBlockData());
    readClient.checkProcessedBlockIds();
  }
"
"  @Test
  public void readTest6() {
    String testAppId = ""localReadTest6"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 5, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);

    Roaring64NavigableMap wrongBlockIdBitmap = Roaring64NavigableMap.bitmapOf();
    LongIterator iter = blockIdBitmap.getLongIterator();
    while (iter.hasNext()) {
      wrongBlockIdBitmap.addLong(iter.next() + (1 << Constants.TASK_ATTEMPT_ID_MAX_LENGTH));
    }

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(),
        testAppId, 0, 0, 100, 1, 10, 100,
        """", wrongBlockIdBitmap, taskIdBitmap, shuffleServerInfo, null);
    assertNull(readClient.readShuffleBlockData());
    try {
      readClient.checkProcessedBlockIds();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Blocks read inconsistent:""));
    }
  }
"
"  @Test
  public void readTest7() {
    String testAppId = ""localReadTest7"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0, 1);

    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 5, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);

    blocks = createShuffleBlockList(
        0, 0, 1, 5, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);

    blocks = createShuffleBlockList(
        0, 0, 2, 5, 30, blockIdBitmap, Maps.newHashMap(), mockSSI);
    sendTestData(testAppId, blocks);

    // unexpected taskAttemptId should be filtered
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", blockIdBitmap, taskIdBitmap, shuffleServerInfo, null);

    validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
"
"  @Test
  public void readTest8() {
    String testAppId = ""localReadTest8"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0, 3);
    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 5, 30, blockIdBitmap, expectedData, mockSSI);
    sendTestData(testAppId, blocks);

    // test case: data generated by speculation task without report result
    blocks = createShuffleBlockList(
        0, 0, 1, 5, 30, Roaring64NavigableMap.bitmapOf(), Maps.newHashMap(), mockSSI);
    sendTestData(testAppId, blocks);
    // test case: data generated by speculation task with report result
    blocks = createShuffleBlockList(
        0, 0, 2, 5, 30, blockIdBitmap, Maps.newHashMap(), mockSSI);
    sendTestData(testAppId, blocks);

    blocks = createShuffleBlockList(
        0, 0, 3, 5, 30, Roaring64NavigableMap.bitmapOf(), Maps.newHashMap(), mockSSI);
    sendTestData(testAppId, blocks);

    // unexpected taskAttemptId should be filtered
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", blockIdBitmap, taskIdBitmap, shuffleServerInfo, null);

    validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
"
"  @Test
  public void readTest9() throws Exception {
    String testAppId = ""localReadTest9"";
    registerApp(testAppId, Lists.newArrayList(new PartitionRange(0, 0)));
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);

    List<ShuffleBlockInfo> blocks;
    ShuffleReadClientImpl readClient;

    createTestData(testAppId, expectedData, blockIdBitmap, taskIdBitmap);
    Roaring64NavigableMap beforeAdded = RssUtils.deserializeBitMap(RssUtils.serializeBitMap(blockIdBitmap));
    // write data by another task, read data again, the cache for index file should be updated
    blocks = createShuffleBlockList(
        0, 0, 1, 3, 25, blockIdBitmap, Maps.newHashMap(), mockSSI);
    sendTestData(testAppId, blocks);
    // test with un-changed expected blockId
    readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", beforeAdded, taskIdBitmap,
        shuffleServerInfo, null);
    validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    // test with changed expected blockId
    readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", blockIdBitmap, taskIdBitmap,
        shuffleServerInfo, null);
    validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
"
"  @Test
  public void combineByKeyTest() throws Exception {
    run();
  }
"
"  @Test
  public void resultCompareTest() throws Exception {
    run();
    checkShuffleData();
  }
"
"  @Test
  public void resultCompareTest() throws Exception {
    run();
  }
"
"  @Test
  public void testMemoryRelease() throws Exception {
    String fileName = generateTextFile(10000, 10000);
    SparkConf sparkConf = createSparkConf();
    updateSparkConfWithRss(sparkConf);
    sparkConf.set(""spark.executor.memory"", ""500m"");
    updateRssStorage(sparkConf);

    // oom if there has no memory release
    runSparkApp(sparkConf, fileName);
  }
"
"  @Test
  public void groupByTest() throws Exception {
    run();
  }
"
"  @Test
  public void resultCompareTest() throws Exception {
    run();
    checkShuffleData();
  }
"
"  @Test
  public void rpcFailTest() throws Exception {
    String testAppId = ""rpcFailTest"";
    shuffleWriteClientImpl.registerShuffle(shuffleServerInfo1,
        testAppId, 0, Lists.newArrayList(new PartitionRange(0, 0)));
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();

    // simulator a failed server
    ShuffleServerInfo fakeShuffleServerInfo =
        new ShuffleServerInfo(""127.0.0.1-20001"", shuffleServers.get(0).getIp(), SHUFFLE_SERVER_PORT + 100);
    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 3, 25, blockIdBitmap,
        expectedData, Lists.newArrayList(shuffleServerInfo1, fakeShuffleServerInfo));
    SendShuffleDataResult result = shuffleWriteClientImpl.sendShuffleData(testAppId, blocks);
    Roaring64NavigableMap failedBlockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap succBlockIdBitmap = Roaring64NavigableMap.bitmapOf();
    for (Long blockId : result.getFailedBlockIds()) {
      failedBlockIdBitmap.addLong(blockId);
    }
    for (Long blockId : result.getSuccessBlockIds()) {
      succBlockIdBitmap.addLong(blockId);
    }
    assertEquals(blockIdBitmap, failedBlockIdBitmap);
    assertEquals(blockIdBitmap, succBlockIdBitmap);

    boolean commitResult = shuffleWriteClientImpl.sendCommit(Sets.newHashSet(
        shuffleServerInfo1, fakeShuffleServerInfo), testAppId, 0, 2);
    assertFalse(commitResult);

    Map<Integer, List<Long>> ptb = Maps.newHashMap();
    ptb.put(1, Lists.newArrayList(1L));
    try {
      Map<Integer, List<ShuffleServerInfo>> partitionToServers = Maps.newHashMap();
      partitionToServers.put(1, Lists.newArrayList(
          shuffleServerInfo1, fakeShuffleServerInfo));
      shuffleWriteClientImpl.reportShuffleResult(partitionToServers, testAppId, 0, 0, ptb, 2);
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Report shuffle result is failed for""));
    }
  }
"
"  @Test
  public void reportMultipleServerTest() throws Exception {
    String testAppId = ""reportMultipleServerTest"";

    shuffleWriteClientImpl.registerShuffle(shuffleServerInfo1,
        testAppId, 1, Lists.newArrayList(new PartitionRange(1, 1)));

    shuffleWriteClientImpl.registerShuffle(shuffleServerInfo2,
        testAppId, 1, Lists.newArrayList(new PartitionRange(2, 2)));

    Map<Integer, List<ShuffleServerInfo>> partitionToServers = Maps.newHashMap();
    partitionToServers.putIfAbsent(1, Lists.newArrayList(shuffleServerInfo1));
    partitionToServers.putIfAbsent(2, Lists.newArrayList(shuffleServerInfo2));
    Map<Integer, List<Long>> partitionToBlocks = Maps.newHashMap();
    List<Long> blockIds = Lists.newArrayList();
    for (int i = 0; i < 5; i++ ) {
      blockIds.add(ClientUtils.getBlockId(1, 0, i));
    }
    partitionToBlocks.put(1, blockIds);
    blockIds = Lists.newArrayList();
    for (int i = 0; i < 7; i++ ) {
      blockIds.add(ClientUtils.getBlockId(2, 0, i));
    }
    partitionToBlocks.put(2, blockIds);
    shuffleWriteClientImpl
        .reportShuffleResult(partitionToServers, testAppId, 1, 0, partitionToBlocks, 1);

    Roaring64NavigableMap bitmap = shuffleWriteClientImpl
        .getShuffleResult(""GRPC"", Sets.newHashSet(shuffleServerInfo1), testAppId,
        1, 0);
    assertTrue(bitmap.isEmpty());

    bitmap = shuffleWriteClientImpl
        .getShuffleResult(""GRPC"", Sets.newHashSet(shuffleServerInfo1), testAppId,
        1, 1);
    assertEquals(5, bitmap.getLongCardinality());
    for (int i = 0; i < 5; i++) {
      assertTrue(bitmap.contains(partitionToBlocks.get(1).get(i)));
    }

    bitmap = shuffleWriteClientImpl
        .getShuffleResult(""GRPC"", Sets.newHashSet(shuffleServerInfo1), testAppId,
        1, 2);
    assertTrue(bitmap.isEmpty());

    bitmap = shuffleWriteClientImpl
        .getShuffleResult(""GRPC"", Sets.newHashSet(shuffleServerInfo2), testAppId,
        1, 0);
    assertTrue(bitmap.isEmpty());

    bitmap = shuffleWriteClientImpl
        .getShuffleResult(""GRPC"", Sets.newHashSet(shuffleServerInfo2), testAppId,
        1, 1);
    assertTrue(bitmap.isEmpty());

    bitmap = shuffleWriteClientImpl
        .getShuffleResult(""GRPC"", Sets.newHashSet(shuffleServerInfo2), testAppId,
        1, 2);
    assertEquals(7, bitmap.getLongCardinality());
    for (int i = 0; i < 7; i++) {
      assertTrue(bitmap.contains(partitionToBlocks.get(2).get(i)));
    }
  }
"
"  @Test
  public void writeReadTest() throws Exception {
    String testAppId = ""writeReadTest"";
    shuffleWriteClientImpl.registerShuffle(shuffleServerInfo1,
        testAppId, 0, Lists.newArrayList(new PartitionRange(0, 0)));
    shuffleWriteClientImpl.registerShuffle(shuffleServerInfo2,
        testAppId, 0, Lists.newArrayList(new PartitionRange(0, 0)));
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);

    List<ShuffleBlockInfo> blocks = createShuffleBlockList(
        0, 0, 0, 3, 25, blockIdBitmap,
        expectedData, Lists.newArrayList(shuffleServerInfo1, shuffleServerInfo2));
    shuffleWriteClientImpl.sendShuffleData(testAppId, blocks);
    // send 1st commit, finish commit won't be sent to Shuffle server and data won't be persisted to disk
    boolean commitResult = shuffleWriteClientImpl
        .sendCommit(Sets.newHashSet(shuffleServerInfo1, shuffleServerInfo2), testAppId, 0, 2);
    assertTrue(commitResult);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", blockIdBitmap, taskIdBitmap,
        Lists.newArrayList(shuffleServerInfo1, shuffleServerInfo2), null);

    try {
      readClient.readShuffleBlockData();
      fail(EXPECTED_EXCEPTION_MESSAGE);
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Failed to read shuffle index for""));
    }
    readClient.close();

    // send 2nd commit, data will be persisted to disk
    commitResult = shuffleWriteClientImpl
        .sendCommit(Sets.newHashSet(shuffleServerInfo1, shuffleServerInfo2), testAppId, 0, 2);
    assertTrue(commitResult);
    readClient = new ShuffleReadClientImpl(StorageType.LOCALFILE.name(), testAppId, 0, 0, 100, 1,
        10, 1000, """", blockIdBitmap, taskIdBitmap,
        Lists.newArrayList(shuffleServerInfo1, shuffleServerInfo2), null);
    validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();

    // commit will be failed because of fakeIp
    commitResult = shuffleWriteClientImpl.sendCommit(Sets.newHashSet(new ShuffleServerInfo(
        ""127.0.0.1-20001"", ""fakeIp"", SHUFFLE_SERVER_PORT)), testAppId, 0, 2);
    assertFalse(commitResult);

    // wait resource to be deleted
    Thread.sleep(6000);

    // commit is ok, but finish shuffle rpc will failed because resource was deleted
    commitResult = shuffleWriteClientImpl
        .sendCommit(Sets.newHashSet(shuffleServerInfo1, shuffleServerInfo2), testAppId, 0, 2);
    assertFalse(commitResult);
  }
"
"  @Test
  public void emptyTaskTest() {
    String testAppId = ""emptyTaskTest"";
    shuffleWriteClientImpl.registerShuffle(shuffleServerInfo1,
        testAppId, 0, Lists.newArrayList(new PartitionRange(0, 0)));
    boolean commitResult = shuffleWriteClientImpl
        .sendCommit(Sets.newHashSet(shuffleServerInfo1), testAppId, 0, 2);
    assertTrue(commitResult);
    commitResult = shuffleWriteClientImpl
        .sendCommit(Sets.newHashSet(shuffleServerInfo2), testAppId, 0, 2);
    assertFalse(commitResult);
  }
"
"  @Test
  public void testGetPartitionToServers() {
    GetShuffleAssignmentsResponse testResponse = generateShuffleAssignmentsResponse();

    Map<Integer, List<ShuffleServerInfo>> partitionToServers =
        coordinatorClient.getPartitionToServers(testResponse);

    assertEquals(Arrays.asList(new ShuffleServerInfo(""id1"", ""0.0.0.1"", 100),
        new ShuffleServerInfo(""id2"", ""0.0.0.2"", 100)),
        partitionToServers.get(0));
    assertEquals(Arrays.asList(new ShuffleServerInfo(""id1"", ""0.0.0.1"", 100),
        new ShuffleServerInfo(""id2"", ""0.0.0.2"", 100)),
        partitionToServers.get(1));
    assertEquals(Arrays.asList(new ShuffleServerInfo(""id3"", ""0.0.0.3"", 100),
        new ShuffleServerInfo(""id4"", ""0.0.0.4"", 100)),
        partitionToServers.get(2));
    assertEquals(Arrays.asList(new ShuffleServerInfo(""id3"", ""0.0.0.3"", 100),
        new ShuffleServerInfo(""id4"", ""0.0.0.4"", 100)),
        partitionToServers.get(3));
    assertNull(partitionToServers.get(4));
  }
"
"  @Test
  public void getShuffleRegisterInfoTest() {
    GetShuffleAssignmentsResponse testResponse = generateShuffleAssignmentsResponse();
    Map<ShuffleServerInfo, List<PartitionRange>> serverToPartitionRanges =
        coordinatorClient.getServerToPartitionRanges(testResponse);
    List<ShuffleRegisterInfo> expected = Arrays.asList(
        new ShuffleRegisterInfo(new ShuffleServerInfo(""id1"", ""0.0.0.1"", 100),
            Lists.newArrayList(new PartitionRange(0, 1))),
        new ShuffleRegisterInfo(new ShuffleServerInfo(""id2"", ""0.0.0.2"", 100),
            Lists.newArrayList(new PartitionRange(0, 1))),
        new ShuffleRegisterInfo(new ShuffleServerInfo(""id3"", ""0.0.0.3"", 100),
            Lists.newArrayList(new PartitionRange(2, 3))),
        new ShuffleRegisterInfo(new ShuffleServerInfo(""id4"", ""0.0.0.4"", 100),
            Lists.newArrayList(new PartitionRange(2, 3))));
    assertEquals(4, serverToPartitionRanges.size());
    for (ShuffleRegisterInfo sri : expected) {
      List<PartitionRange> partitionRanges = serverToPartitionRanges.get(sri.getShuffleServerInfo());
      assertEquals(sri.getPartitionRanges(), partitionRanges);
    }
  }
"
"  @Test
  public void getShuffleAssignmentsTest() throws Exception {
    String appId = ""getShuffleAssignmentsTest"";
    CoordinatorTestUtils.waitForRegister(coordinatorClient,2);
    RssGetShuffleAssignmentsRequest request = new RssGetShuffleAssignmentsRequest(
        appId, 1, 10, 4, 1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    RssGetShuffleAssignmentsResponse response = coordinatorClient.getShuffleAssignments(request);
    Set<Integer> expectedStart = Sets.newHashSet(0, 4, 8);

    Map<ShuffleServerInfo, List<PartitionRange>> serverToPartitionRanges = response.getServerToPartitionRanges();
    assertEquals(2, serverToPartitionRanges.size());
    List<PartitionRange> partitionRanges = Lists.newArrayList();
    for (List<PartitionRange> ranges : serverToPartitionRanges.values()) {
      partitionRanges.addAll(ranges);
    }
    for (PartitionRange pr : partitionRanges) {
      switch (pr.getStart()) {
        case 0:
          assertEquals(3, pr.getEnd());
          expectedStart.remove(0);
          break;
        case 4:
          assertEquals(7, pr.getEnd());
          expectedStart.remove(4);
          break;
        case 8:
          assertEquals(11, pr.getEnd());
          expectedStart.remove(8);
          break;
        default:
          fail(""Shouldn't be here"");
      }
    }
    assertTrue(expectedStart.isEmpty());

    request = new RssGetShuffleAssignmentsRequest(
        appId, 1, 10, 4, 2,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    response = coordinatorClient.getShuffleAssignments(request);
    serverToPartitionRanges = response.getServerToPartitionRanges();
    assertEquals(2, serverToPartitionRanges.size());
    partitionRanges = Lists.newArrayList();
    for (List<PartitionRange> ranges : serverToPartitionRanges.values()) {
      partitionRanges.addAll(ranges);
    }
    assertEquals(6, partitionRanges.size());
    int range0To3 = 0;
    int range4To7 = 0;
    int range8To11 = 0;
    for (PartitionRange pr : partitionRanges) {
      switch (pr.getStart()) {
        case 0:
          assertEquals(3, pr.getEnd());
          range0To3++;
          break;
        case 4:
          assertEquals(7, pr.getEnd());
          range4To7++;
          break;
        case 8:
          assertEquals(11, pr.getEnd());
          range8To11++;
          break;
        default:
          fail(""Shouldn't be here"");
      }
    }
    assertEquals(2, range0To3);
    assertEquals(2, range4To7);
    assertEquals(2, range8To11);

    request = new RssGetShuffleAssignmentsRequest(
        appId, 3, 2, 1, 1,
        Sets.newHashSet(""fake_version""));
    try {
      coordinatorClient.getShuffleAssignments(request);
      fail(""Exception should be thrown"");
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Empty assignment""));
    }
  }
"
"  @Test
  public void appHeartbeatTest() throws Exception {
    RssAppHeartBeatResponse response =
        coordinatorClient.sendAppHeartBeat(new RssAppHeartBeatRequest(""appHeartbeatTest1"", 1000));
    assertEquals(ResponseStatusCode.SUCCESS, response.getStatusCode());
    assertEquals(Sets.newHashSet(""appHeartbeatTest1""),
        coordinators.get(0).getApplicationManager().getAppIds());
    coordinatorClient.sendAppHeartBeat(new RssAppHeartBeatRequest(""appHeartbeatTest2"", 1000));
    assertEquals(Sets.newHashSet(""appHeartbeatTest1"", ""appHeartbeatTest2""),
        coordinators.get(0).getApplicationManager().getAppIds());
    int retry = 0;
    while (retry < 5) {
      coordinatorClient.sendAppHeartBeat(new RssAppHeartBeatRequest(""appHeartbeatTest1"", 1000));
      retry++;
      Thread.sleep(1000);
    }
    // appHeartbeatTest2 was removed because of expired
    assertEquals(Sets.newHashSet(""appHeartbeatTest1""),
        coordinators.get(0).getApplicationManager().getAppIds());
  }
"
"  @Test
  public void shuffleServerHeartbeatTest() throws Exception {
    CoordinatorTestUtils.waitForRegister(coordinatorClient, 2);
    shuffleServers.get(0).stopServer();
    Thread.sleep(5000);
    SimpleClusterManager scm = (SimpleClusterManager) coordinators.get(0).getClusterManager();
    List<ServerNode> nodes = scm.getServerList(Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    assertEquals(1, nodes.size());
    ServerNode node = nodes.get(0);
    assertTrue(node.getTags().contains(Constants.SHUFFLE_SERVER_VERSION));
    assertTrue(scm.getTagToNodes().get(Constants.SHUFFLE_SERVER_VERSION).contains(node));
    ShuffleServerConf shuffleServerConf = shuffleServers.get(0).getShuffleServerConf();
    shuffleServerConf.setInteger(""rss.rpc.server.port"", SHUFFLE_SERVER_PORT + 2);
    shuffleServerConf.setInteger(""rss.jetty.http.port"", 18082);
    ShuffleServer ss = new ShuffleServer(shuffleServerConf);
    ss.start();
    shuffleServers.set(0, ss);
    Thread.sleep(3000);
    assertEquals(2, coordinators.get(0).getClusterManager().getNodesNum());
  }
"
"  @Test
  public void rpcMetricsTest() throws Exception{
    String appId = ""rpcMetricsTest"";
    double oldValue = coordinators.get(0).getGrpcMetrics().getCounterMap()
        .get(CoordinatorGrpcMetrics.HEARTBEAT_METHOD).get();
    CoordinatorTestUtils.waitForRegister(coordinatorClient,2);
    double newValue = coordinators.get(0).getGrpcMetrics().getCounterMap()
        .get(CoordinatorGrpcMetrics.HEARTBEAT_METHOD).get();
    assertTrue(newValue - oldValue > 1);
    assertEquals(0,
        coordinators.get(0).getGrpcMetrics().getGaugeMap()
            .get(CoordinatorGrpcMetrics.HEARTBEAT_METHOD).get(), 0.5);

    RssGetShuffleAssignmentsRequest request = new RssGetShuffleAssignmentsRequest(
        appId, 1, 10, 4, 1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    oldValue = coordinators.get(0).getGrpcMetrics().getCounterMap()
        .get(CoordinatorGrpcMetrics.GET_SHUFFLE_ASSIGNMENTS_METHOD).get();
    coordinatorClient.getShuffleAssignments(request);
    newValue = coordinators.get(0).getGrpcMetrics().getCounterMap()
        .get(CoordinatorGrpcMetrics.GET_SHUFFLE_ASSIGNMENTS_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        coordinators.get(0).getGrpcMetrics().getGaugeMap()
            .get(CoordinatorGrpcMetrics.GET_SHUFFLE_ASSIGNMENTS_METHOD).get(), 0.5);
  }
"
"  @Test
  public void getShuffleAssignmentsTest() throws Exception {
    CoordinatorTestUtils.waitForRegister(coordinatorClient, 3);
    RssGetShuffleAssignmentsRequest request = new RssGetShuffleAssignmentsRequest(
        ""app1"",
        1,
        1,
        1,
        1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    RssGetShuffleAssignmentsResponse response = coordinatorClient.getShuffleAssignments(request);
    assertEquals(1, response.getPartitionToServers().size());
    for (Map.Entry<Integer, List<ShuffleServerInfo>> entry : response.getPartitionToServers().entrySet()) {
      assertEquals(1, entry.getValue().size());
      assertEquals(SHUFFLE_SERVER_PORT + 1, entry.getValue().get(0).getPort());
    }
    request = new RssGetShuffleAssignmentsRequest(
        ""app1"",
        2,
        1,
        1,
        1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    response = coordinatorClient.getShuffleAssignments(request);
    assertEquals(1, response.getPartitionToServers().size());
    for (Map.Entry<Integer, List<ShuffleServerInfo>> entry : response.getPartitionToServers().entrySet()) {
      assertEquals(1, entry.getValue().size());
      assertEquals(SHUFFLE_SERVER_PORT + 1, entry.getValue().get(0).getPort());
    }
    request = new RssGetShuffleAssignmentsRequest(
        ""app1"",
        2,
        1,
        1,
        1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    response = coordinatorClient.getShuffleAssignments(request);
    assertEquals(1, response.getPartitionToServers().size());
    for (Map.Entry<Integer, List<ShuffleServerInfo>> entry : response.getPartitionToServers().entrySet()) {
      assertEquals(1, entry.getValue().size());
      assertEquals(SHUFFLE_SERVER_PORT, entry.getValue().get(0).getPort());
    }
  }
"
"  @Test
  public void hdfsWriteReadTest() {
    String appId = ""app_hdfs_read_write"";
    String dataBasePath = HDFS_URI + ""rss/test"";
    RssRegisterShuffleRequest rrsr = new RssRegisterShuffleRequest(appId, 0,
        Lists.newArrayList(new PartitionRange(0, 1)));
    shuffleServerClient.registerShuffle(rrsr);
    rrsr = new RssRegisterShuffleRequest(appId, 0, Lists.newArrayList(new PartitionRange(2, 3)));
    shuffleServerClient.registerShuffle(rrsr);

    Roaring64NavigableMap[] bitmaps = new Roaring64NavigableMap[4];
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Map<Integer, List<ShuffleBlockInfo>>  dataBlocks = createTestData(bitmaps, expectedData);
    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = Maps.newHashMap();
    partitionToBlocks.put(0, dataBlocks.get(0));
    partitionToBlocks.put(1, dataBlocks.get(1));

    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);

    RssSendShuffleDataRequest rssdr = new RssSendShuffleDataRequest(appId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    assertEquals(456, shuffleServers.get(0).getShuffleBufferManager().getUsedMemory());
    assertEquals(0, shuffleServers.get(0).getShuffleBufferManager().getPreAllocatedSize());
    RssSendCommitRequest rscr = new RssSendCommitRequest(appId, 0);
    shuffleServerClient.sendCommit(rscr);
    RssFinishShuffleRequest rfsr = new RssFinishShuffleRequest(appId, 0);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        appId, 0, 0, 100, 2, 10, 1000,
        dataBasePath, bitmaps[0], Roaring64NavigableMap.bitmapOf(0), Lists.newArrayList(), new Configuration());
    assertNull(readClient.readShuffleBlockData());
    shuffleServerClient.finishShuffle(rfsr);

    partitionToBlocks.clear();
    partitionToBlocks.put(2, dataBlocks.get(2));
    shuffleToBlocks.clear();
    shuffleToBlocks.put(0, partitionToBlocks);
    rssdr = new RssSendShuffleDataRequest(appId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    assertEquals(0, shuffleServers.get(0).getShuffleBufferManager().getPreAllocatedSize());
    rscr = new RssSendCommitRequest(appId, 0);
    shuffleServerClient.sendCommit(rscr);
    rfsr = new RssFinishShuffleRequest(appId, 0);
    shuffleServerClient.finishShuffle(rfsr);

    partitionToBlocks.clear();
    partitionToBlocks.put(3, dataBlocks.get(3));
    shuffleToBlocks.clear();
    shuffleToBlocks.put(0, partitionToBlocks);
    rssdr = new RssSendShuffleDataRequest(appId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    rscr = new RssSendCommitRequest(appId, 0);
    shuffleServerClient.sendCommit(rscr);
    rfsr = new RssFinishShuffleRequest(appId, 0);
    shuffleServerClient.finishShuffle(rfsr);

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        appId, 0, 0, 100, 2, 10, 1000,
        dataBasePath, bitmaps[0], Roaring64NavigableMap.bitmapOf(0), Lists.newArrayList(), new Configuration());
    validateResult(readClient, expectedData, bitmaps[0]);

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        appId, 0, 1, 100, 2, 10, 1000,
        dataBasePath, bitmaps[1], Roaring64NavigableMap.bitmapOf(1), Lists.newArrayList(), new Configuration());
    validateResult(readClient, expectedData, bitmaps[1]);

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        appId, 0, 2, 100, 2, 10, 1000,
        dataBasePath, bitmaps[2], Roaring64NavigableMap.bitmapOf(2), Lists.newArrayList(), new Configuration());
    validateResult(readClient, expectedData, bitmaps[2]);

    readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        appId, 0, 3, 100, 2, 10, 1000,
        dataBasePath, bitmaps[3], Roaring64NavigableMap.bitmapOf(3), Lists.newArrayList(), new Configuration());
    validateResult(readClient, expectedData, bitmaps[3]);
  }
"
"  @Test
  public void hdfsFaultTolerance() {
    try {
      String appId = ""app_hdfs_fault_tolerance_data"";
      Map<Long, byte[]> expectedData = Maps.newHashMap();
      Map<Integer, List<Integer>> map = Maps.newHashMap();
      map.put(2, Lists.newArrayList(0, 3));
      map.put(3, Lists.newArrayList(3));
      registerShuffle(appId, map);

      Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
      Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
      Roaring64NavigableMap blockIdBitmap3 = Roaring64NavigableMap.bitmapOf();

      List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
          2, 0, 1,11, 10 * 1024 * 1024, blockIdBitmap1, expectedData);

      List<ShuffleBlockInfo> blocks2 = createShuffleBlockList(
          3, 3, 2,9, 10 * 1024 * 1024, blockIdBitmap2, expectedData);

      List<ShuffleBlockInfo> blocks3 = createShuffleBlockList(
          2, 3, 2,9, 10 * 1024 * 1024, blockIdBitmap3, expectedData);

      assertEquals(0, ShuffleStorageUtils.getStorageIndex(2, appId, 2, 0));
      assertEquals(0, ShuffleStorageUtils.getStorageIndex(2, appId, 3, 3));
      assertEquals(0, ShuffleStorageUtils.getStorageIndex(2, appId, 2, 3));
      assertEquals(1, cluster.getDataNodes().size());
      cluster.stopDataNode(0);
      assertEquals(0, cluster.getDataNodes().size());

      sendSinglePartitionToShuffleServer(appId, 2, 0, 1, blocks1);
      boolean isException = false;
      try {
        sendSinglePartitionToShuffleServer(appId, 3, 3,2, blocks2);
      } catch (RuntimeException re) {
        isException = true;
        assertTrue(re.getMessage().contains(""Fail to finish""));
      }
      assertTrue(isException);

      cluster.startDataNodes(conf, 1, true, HdfsServerConstants.StartupOption.REGULAR,
          null, null, null, false, true);
      assertEquals(1, cluster.getDataNodes().size());

      sendSinglePartitionToShuffleServer(appId, 2, 3, 2, blocks3);

      validateResult(appId, 2, 0, blockIdBitmap1, Roaring64NavigableMap.bitmapOf(1), expectedData);
      validateResult(appId, 2, 3, blockIdBitmap3, Roaring64NavigableMap.bitmapOf(2), expectedData);
    } catch (Exception e) {
      e.printStackTrace();
      fail();
    }
  }
"
"  @Test
  public void diskFaultTolerance() {
    String appId = ""app_disk_fault_tolerance_data"";
    Map<Long, byte[]> expectedData = Maps.newHashMap();

    Map<Integer, List<Integer>> map = Maps.newHashMap();
    map.put(2, Lists.newArrayList(1, 3));
    map.put(3, Lists.newArrayList(1));
    registerShuffle(appId, map);

    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap3 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap4 = Roaring64NavigableMap.bitmapOf();

    List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
        2, 1, 1,11, 10 * 1024 * 1024, blockIdBitmap1, expectedData);

    List<ShuffleBlockInfo> blocks2 = createShuffleBlockList(
        3, 1, 2,9, 10 * 1024 * 1024, blockIdBitmap2, expectedData);

    List<ShuffleBlockInfo> blocks3 = createShuffleBlockList(
        2, 3, 2,9, 10 * 1024 * 1024, blockIdBitmap3, expectedData);

    List<ShuffleBlockInfo> blocks4 = createShuffleBlockList(
        2, 1, 1, 11, 10 * 1024 * 1024, blockIdBitmap4, expectedData);

    assertEquals(1, ShuffleStorageUtils.getStorageIndex(2, appId, 2, 1));
    assertEquals(1, ShuffleStorageUtils.getStorageIndex(2, appId, 3, 1));
    assertEquals(1, ShuffleStorageUtils.getStorageIndex(2, appId, 2, 3));
    assertEquals(1, ShuffleStorageUtils.getStorageIndex(2, appId, 2, 1));
    try {
      sendSinglePartitionToShuffleServer(appId, 2, 1, 1, blocks1);
      sendSinglePartitionToShuffleServer(appId, 3, 1,2, blocks2);
      sendSinglePartitionToShuffleServer(appId, 2, 3, 2, blocks3);
      sendSinglePartitionToShuffleServer(appId, 2, 1, 1, blocks4);
    } catch (Exception e) {
      e.printStackTrace();
      fail();
    }
    validateResult(appId, 2, 1, blockIdBitmap1, Roaring64NavigableMap.bitmapOf(1), expectedData);
    validateResult(appId, 3, 1, blockIdBitmap2, Roaring64NavigableMap.bitmapOf(2), expectedData);
    validateResult(appId, 2, 3, blockIdBitmap3, Roaring64NavigableMap.bitmapOf(2), expectedData);
  }
"
"  @Test
  public void localWriteReadTest() throws Exception {
    String testAppId = ""localWriteReadTest"";
    RssRegisterShuffleRequest rrsr = new RssRegisterShuffleRequest(testAppId, 0,
        Lists.newArrayList(new PartitionRange(0, 1)));
    shuffleServerClient.registerShuffle(rrsr);
    rrsr = new RssRegisterShuffleRequest(testAppId, 0, Lists.newArrayList(new PartitionRange(2, 3)));
    shuffleServerClient.registerShuffle(rrsr);

    Map<Long, byte[]> expectedData = Maps.newHashMap();

    Roaring64NavigableMap[] bitmaps = new Roaring64NavigableMap[4];
    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = createTestData(bitmaps, expectedData);

    Set<Long> expectedBlockIds1 = transBitmapToSet(bitmaps[0]);
    Set<Long> expectedBlockIds2 = transBitmapToSet(bitmaps[1]);
    Set<Long> expectedBlockIds3 = transBitmapToSet(bitmaps[2]);
    Set<Long> expectedBlockIds4 = transBitmapToSet(bitmaps[3]);

    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);

    RssSendShuffleDataRequest rssdr = new RssSendShuffleDataRequest(
        testAppId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    RssSendCommitRequest rscr = new RssSendCommitRequest(testAppId, 0);
    shuffleServerClient.sendCommit(rscr);
    RssFinishShuffleRequest rfsr = new RssFinishShuffleRequest(testAppId, 0);
    shuffleServerClient.finishShuffle(rfsr);

    ShuffleDataResult sdr  = readShuffleData(
        shuffleServerClient, testAppId, 0, 0, 2,
        10, 1000, 0);
    validateResult(sdr, expectedBlockIds1, expectedData, 0);
    sdr  = readShuffleData(
        shuffleServerClient, testAppId, 0, 1, 2,
        10, 1000, 0);
    validateResult(sdr, expectedBlockIds2, expectedData, 1);
    sdr  = readShuffleData(
        shuffleServerClient, testAppId, 0, 2, 2,
        10, 1000, 0);
    validateResult(sdr, expectedBlockIds3, expectedData, 2);
    sdr  = readShuffleData(
        shuffleServerClient, testAppId, 0, 3, 2,
        10, 1000, 0);
    validateResult(sdr, expectedBlockIds4, expectedData, 3);

    assertEquals(4, shuffleServers.get(0).getShuffleTaskManager()
        .getServerReadHandlers().get(testAppId).size());
    assertNotNull(shuffleServers.get(0).getShuffleTaskManager()
        .getPartitionsToBlockIds().get(testAppId));
    Thread.sleep(8000);
    assertNull(shuffleServers.get(0).getShuffleTaskManager().getServerReadHandlers().get(testAppId));
    assertNull(shuffleServers.get(0).getShuffleTaskManager().getPartitionsToBlockIds().get(testAppId));
  }
"
"  @Test
  public void clearResourceTest() throws Exception {
    final ShuffleWriteClient shuffleWriteClient =
        ShuffleClientFactory.getInstance().createShuffleWriteClient(
            ""GRPC"", 2, 10000L, 4);
    shuffleWriteClient.registerCoordinators(""127.0.0.1:19999"");
    shuffleWriteClient.registerShuffle(
        new ShuffleServerInfo(""127.0.0.1-20001"", ""127.0.0.1"", 20001),
        ""clearResourceTest1"",
        0,
        Lists.newArrayList(new PartitionRange(0, 1)));

    shuffleWriteClient.sendAppHeartbeat(""clearResourceTest1"", 1000L);
    shuffleWriteClient.sendAppHeartbeat(""clearResourceTest2"", 1000L);

    RssRegisterShuffleRequest rrsr = new RssRegisterShuffleRequest(""clearResourceTest1"", 0,
        Lists.newArrayList(new PartitionRange(0, 1)));
    shuffleServerClient.registerShuffle(rrsr);
    rrsr = new RssRegisterShuffleRequest(""clearResourceTest2"", 0,
        Lists.newArrayList(new PartitionRange(0, 1)));
    shuffleServerClient.registerShuffle(rrsr);
    assertEquals(Sets.newHashSet(""clearResourceTest1"", ""clearResourceTest2""),
        shuffleServers.get(0).getShuffleTaskManager().getAppIds().keySet());

    // Thread will keep refresh clearResourceTest1 in coordinator
    Thread t = new Thread(() -> {
      int i = 0;
      while (i < 20) {
        shuffleWriteClient.sendAppHeartbeat(""clearResourceTest1"", 1000L);
        i++;
        try {
          Thread.sleep(1000);
        } catch (InterruptedException e) {
          return;
        }
      }
    });
    t.start();

    // Heartbeat is sent to coordinator too]
    Thread.sleep(3000);
    shuffleServerClient.registerShuffle(new RssRegisterShuffleRequest(""clearResourceTest1"", 0,
        Lists.newArrayList(new PartitionRange(0, 1))));
    assertEquals(Sets.newHashSet(""clearResourceTest1""),
        coordinators.get(0).getApplicationManager().getAppIds());
    // clearResourceTest2 will be removed because of rss.server.app.expired.withoutHeartbeat
    Thread.sleep(2000);
    assertEquals(Sets.newHashSet(""clearResourceTest1""),
        shuffleServers.get(0).getShuffleTaskManager().getAppIds().keySet());

    // clearResourceTest1 will be removed because of rss.server.app.expired.withoutHeartbeat
    t.interrupt();
    Thread.sleep(8000);
    assertEquals(0, shuffleServers.get(0).getShuffleTaskManager().getAppIds().size());

  }
"
"  @Test
  public void shuffleResultTest() throws Exception {
    Map<Integer, List<Long>> partitionToBlockIds = Maps.newHashMap();
    List<Long> blockIds1 = getBlockIdList(1, 3);
    List<Long> blockIds2 = getBlockIdList(2, 2);
    List<Long> blockIds3 = getBlockIdList(3, 1);
    partitionToBlockIds.put(1, blockIds1);
    partitionToBlockIds.put(2, blockIds2);
    partitionToBlockIds.put(3, blockIds3);

    RssReportShuffleResultRequest request =
        new RssReportShuffleResultRequest(""shuffleResultTest"", 0, 0L, partitionToBlockIds, 1);
    try {
      shuffleServerClient.reportShuffleResult(request);
      fail(""Exception should be thrown"");
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""error happened when report shuffle result""));
    }

    RssGetShuffleResultRequest req = new RssGetShuffleResultRequest(""shuffleResultTest"", 1, 1);
    try {
      shuffleServerClient.getShuffleResult(req);
      fail(""Exception should be thrown"");
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Can't get shuffle result""));
    }

    RssRegisterShuffleRequest rrsr = new RssRegisterShuffleRequest(""shuffleResultTest"", 100,
        Lists.newArrayList(new PartitionRange(0, 1)));
    shuffleServerClient.registerShuffle(rrsr);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 1);
    RssGetShuffleResultResponse result = shuffleServerClient.getShuffleResult(req);
    Roaring64NavigableMap blockIdBitmap = result.getBlockIdBitmap();
    assertEquals(Roaring64NavigableMap.bitmapOf(), blockIdBitmap);

    request =
        new RssReportShuffleResultRequest(""shuffleResultTest"", 0, 0L, partitionToBlockIds, 1);
    RssReportShuffleResultResponse response = shuffleServerClient.reportShuffleResult(request);
    assertEquals(ResponseStatusCode.SUCCESS, response.getStatusCode());
    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 1);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    Roaring64NavigableMap expectedP1 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP1, blockIds1);
    assertEquals(expectedP1, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 2);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    Roaring64NavigableMap expectedP2 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP2, blockIds2);
    assertEquals(expectedP2, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 3);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    Roaring64NavigableMap expectedP3 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP3, blockIds3);
    assertEquals(expectedP3, blockIdBitmap);

    partitionToBlockIds = Maps.newHashMap();
    blockIds1 = getBlockIdList(1, 3);
    blockIds2 = getBlockIdList(2, 2);
    blockIds3 = getBlockIdList(3, 1);
    partitionToBlockIds.put(1, blockIds1);
    partitionToBlockIds.put(2, blockIds2);
    partitionToBlockIds.put(3, blockIds3);

    request =
        new RssReportShuffleResultRequest(""shuffleResultTest"", 0, 1L, partitionToBlockIds, 1);
    shuffleServerClient.reportShuffleResult(request);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 1);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    addExpectedBlockIds(expectedP1, blockIds1);
    assertEquals(expectedP1, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 2);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    addExpectedBlockIds(expectedP2, blockIds2);
    assertEquals(expectedP2, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 0, 3);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    addExpectedBlockIds(expectedP3, blockIds3);
    assertEquals(expectedP3, blockIdBitmap);

    request =
        new RssReportShuffleResultRequest(""shuffleResultTest"", 1, 1L, Maps.newHashMap(), 1);
    shuffleServerClient.reportShuffleResult(request);
    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 1, 1);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    assertEquals(Roaring64NavigableMap.bitmapOf(), blockIdBitmap);

    // test with bitmapNum > 1
    partitionToBlockIds = Maps.newHashMap();
    blockIds1 = getBlockIdList(1, 3);
    blockIds2 = getBlockIdList(2, 2);
    blockIds3 = getBlockIdList(3, 1);
    partitionToBlockIds.put(1, blockIds1);
    partitionToBlockIds.put(2, blockIds2);
    partitionToBlockIds.put(3, blockIds3);
    request =
        new RssReportShuffleResultRequest(""shuffleResultTest"", 2, 1L, partitionToBlockIds, 3);
    shuffleServerClient.reportShuffleResult(request);
    // validate bitmap in shuffleTaskManager
    Roaring64NavigableMap[] bitmaps = shuffleServers.get(0).getShuffleTaskManager()
        .getPartitionsToBlockIds().get(""shuffleResultTest"").get(2);
    assertEquals(3, bitmaps.length);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 2, 1);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    expectedP1 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP1, blockIds1);
    assertEquals(expectedP1, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 2, 2);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    expectedP2 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP2, blockIds2);
    assertEquals(expectedP2, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 2, 3);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    expectedP3 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP3, blockIds3);
    assertEquals(expectedP3, blockIdBitmap);

    partitionToBlockIds = Maps.newHashMap();
    blockIds1 = getBlockIdList((int) Constants.MAX_PARTITION_ID, 3);
    blockIds2 = getBlockIdList(2, 2);
    blockIds3 = getBlockIdList(3, 1);
    partitionToBlockIds.put((int) Constants.MAX_PARTITION_ID, blockIds1);
    partitionToBlockIds.put(2, blockIds2);
    partitionToBlockIds.put(3, blockIds3);
    // bimapNum = 2
    request =
        new RssReportShuffleResultRequest(""shuffleResultTest"", 4, 1L, partitionToBlockIds, 2);
    shuffleServerClient.reportShuffleResult(request);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 4, (int) Constants.MAX_PARTITION_ID);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    expectedP1 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP1, blockIds1);
    assertEquals(expectedP1, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 4, 2);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    expectedP2 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP2, blockIds2);
    assertEquals(expectedP2, blockIdBitmap);

    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 4, 3);
    result = shuffleServerClient.getShuffleResult(req);
    blockIdBitmap = result.getBlockIdBitmap();
    expectedP3 = Roaring64NavigableMap.bitmapOf();
    addExpectedBlockIds(expectedP3, blockIds3);
    assertEquals(expectedP3, blockIdBitmap);

    // wait resources are deleted
    Thread.sleep(12000);
    req = new RssGetShuffleResultRequest(""shuffleResultTest"", 1, 1);
    try {
      shuffleServerClient.getShuffleResult(req);
      fail(""Exception should be thrown"");
    } catch (Exception e) {
      assertTrue(e.getMessage().contains(""Can't get shuffle result""));
    }
  }
"
"  @Test
  public void registerTest() {
    shuffleServerClient.registerShuffle(new RssRegisterShuffleRequest(""registerTest"", 0,
        Lists.newArrayList(new PartitionRange(0, 1))));
    RssGetShuffleResultRequest req = new RssGetShuffleResultRequest(""registerTest"", 0, 0);
    // no exception with getShuffleResult means register successfully
    shuffleServerClient.getShuffleResult(req);
    req = new RssGetShuffleResultRequest(""registerTest"", 0, 1);
    shuffleServerClient.getShuffleResult(req);
    shuffleServerClient.registerShuffle(new RssRegisterShuffleRequest(""registerTest"", 1,
        Lists.newArrayList(new PartitionRange(0, 0), new PartitionRange(1, 1), new PartitionRange(2, 2))));
    req = new RssGetShuffleResultRequest(""registerTest"", 1, 0);
    shuffleServerClient.getShuffleResult(req);
    req = new RssGetShuffleResultRequest(""registerTest"", 1, 1);
    shuffleServerClient.getShuffleResult(req);
    req = new RssGetShuffleResultRequest(""registerTest"", 1, 2);
    shuffleServerClient.getShuffleResult(req);
  }
"
"  @Test
  public void sendDataWithoutRegisterTest() throws Exception {
    List<ShuffleBlockInfo> blockInfos = Lists.newArrayList(new ShuffleBlockInfo(0, 0, 0, 100, 0,
        new byte[]{}, Lists.newArrayList(), 0, 100, 0));
    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = Maps.newHashMap();
    partitionToBlocks.put(0, blockInfos);
    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);

    RssSendShuffleDataRequest rssdr = new RssSendShuffleDataRequest(
        ""sendDataWithoutRegisterTest"", 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    assertEquals(132, shuffleServers.get(0).getPreAllocatedMemory());
    Thread.sleep(10000);
    assertEquals(0, shuffleServers.get(0).getPreAllocatedMemory());
  }
"
"  @Test
  public void multipleShuffleResultTest() throws Exception {
    Set<Long> expectedBlockIds = Sets.newConcurrentHashSet();
    RssRegisterShuffleRequest rrsr = new RssRegisterShuffleRequest(""multipleShuffleResultTest"", 100,
        Lists.newArrayList(new PartitionRange(0, 1)));
    shuffleServerClient.registerShuffle(rrsr);

    Runnable r1 = () -> {
      for (int i = 0; i < 100; i++) {
        Map<Integer, List<Long>> ptbs = Maps.newHashMap();
        List<Long> blockIds = Lists.newArrayList();
        Long blockId = ClientUtils.getBlockId(1, 0, i);
        expectedBlockIds.add(blockId);
        blockIds.add(blockId);
        ptbs.put(1, blockIds);
        RssReportShuffleResultRequest req1 =
            new RssReportShuffleResultRequest(""multipleShuffleResultTest"", 1, 0, ptbs, 1);
        shuffleServerClient.reportShuffleResult(req1);
      }
    };
    Runnable r2 = () -> {
      for (int i = 100; i < 200; i++) {
        Map<Integer, List<Long>> ptbs = Maps.newHashMap();
        List<Long> blockIds = Lists.newArrayList();
        Long blockId = ClientUtils.getBlockId(1, 1, i);
        expectedBlockIds.add(blockId);
        blockIds.add(blockId);
        ptbs.put(1, blockIds);
        RssReportShuffleResultRequest req1 =
            new RssReportShuffleResultRequest(""multipleShuffleResultTest"", 1, 1, ptbs, 1);
        shuffleServerClient.reportShuffleResult(req1);
      }
    };
    Runnable r3 = () -> {
      for (int i = 200; i < 300; i++) {
        Map<Integer, List<Long>> ptbs = Maps.newHashMap();
        List<Long> blockIds = Lists.newArrayList();
        Long blockId = ClientUtils.getBlockId(1, 2, i);
        expectedBlockIds.add(blockId);
        blockIds.add(blockId);
        ptbs.put(1, blockIds);
        RssReportShuffleResultRequest req1 =
            new RssReportShuffleResultRequest(""multipleShuffleResultTest"", 1, 2, ptbs, 1);
        shuffleServerClient.reportShuffleResult(req1);
      }
    };
    Thread t1 = new Thread(r1);
    Thread t2 = new Thread(r2);
    Thread t3 = new Thread(r3);
    t1.start();
    t2.start();
    t3.start();
    t1.join();
    t2.join();
    t3.join();

    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    for (Long blockId : expectedBlockIds) {
      blockIdBitmap.addLong(blockId);
    }

    RssGetShuffleResultRequest req = new RssGetShuffleResultRequest(
        ""multipleShuffleResultTest"", 1, 1);
    RssGetShuffleResultResponse result = shuffleServerClient.getShuffleResult(req);
    Roaring64NavigableMap actualBlockIdBitmap = result.getBlockIdBitmap();
    assertEquals(blockIdBitmap, actualBlockIdBitmap);
  }
"
"  @Test
  public void rpcMetricsTest() {
    String appId = ""rpcMetricsTest"";
    int shuffleId = 0;
    double oldGrpcTotal = shuffleServers.get(0).getGrpcMetrics().getCounterGrpcTotal().get();
    double oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().
        get(ShuffleServerGrpcMetrics.REGISTER_SHUFFLE_METHOD).get();
    shuffleServerClient.registerShuffle(new RssRegisterShuffleRequest(appId, shuffleId,
        Lists.newArrayList(new PartitionRange(0, 1))));
    double newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap()
        .get(ShuffleServerGrpcMetrics.REGISTER_SHUFFLE_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.REGISTER_SHUFFLE_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.APP_HEARTBEAT_METHOD).get();
    shuffleServerClient.sendHeartBeat(new RssAppHeartBeatRequest(appId, 10000));
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.APP_HEARTBEAT_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.APP_HEARTBEAT_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.REQUIRE_BUFFER_METHOD).get();
    shuffleServerClient.requirePreAllocation(100, 10, 1000);
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.REQUIRE_BUFFER_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.REQUIRE_BUFFER_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.SEND_SHUFFLE_DATA_METHOD).get();
    List<ShuffleBlockInfo> blockInfos = Lists.newArrayList(new ShuffleBlockInfo(shuffleId, 0, 0, 100, 0,
        new byte[]{}, Lists.newArrayList(), 0, 100, 0));
    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = Maps.newHashMap();
    partitionToBlocks.put(0, blockInfos);
    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);
    RssSendShuffleDataRequest rssdr = new RssSendShuffleDataRequest(
        appId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.SEND_SHUFFLE_DATA_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.SEND_SHUFFLE_DATA_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.COMMIT_SHUFFLE_TASK_METHOD).get();
    shuffleServerClient.sendCommit(new RssSendCommitRequest(appId, shuffleId));
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.COMMIT_SHUFFLE_TASK_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.COMMIT_SHUFFLE_TASK_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.FINISH_SHUFFLE_METHOD).get();
    shuffleServerClient.finishShuffle(new RssFinishShuffleRequest(appId, shuffleId));
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.FINISH_SHUFFLE_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.FINISH_SHUFFLE_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.REPORT_SHUFFLE_RESULT_METHOD).get();
    Map<Integer, List<Long>> partitionToBlockIds = Maps.newHashMap();
    List<Long> blockIds1 = getBlockIdList(1, 3);
    List<Long> blockIds2 = getBlockIdList(2, 2);
    List<Long> blockIds3 = getBlockIdList(3, 1);
    partitionToBlockIds.put(1, blockIds1);
    partitionToBlockIds.put(2, blockIds2);
    partitionToBlockIds.put(3, blockIds3);
    RssReportShuffleResultRequest request =
        new RssReportShuffleResultRequest(appId, shuffleId, 0L, partitionToBlockIds, 1);
    shuffleServerClient.reportShuffleResult(request);
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.REPORT_SHUFFLE_RESULT_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.REPORT_SHUFFLE_RESULT_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_RESULT_METHOD).get();
    shuffleServerClient.getShuffleResult(new RssGetShuffleResultRequest(appId, shuffleId, 1));
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_RESULT_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.GET_SHUFFLE_RESULT_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_INDEX_METHOD).get();
    try {
      shuffleServerClient.getShuffleIndex(new RssGetShuffleIndexRequest(
          appId, shuffleId, 1, 1, 3));
    } catch (Exception e) {
      // ignore the exception, just test metrics value
    }
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_INDEX_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.GET_SHUFFLE_INDEX_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_DATA_METHOD).get();
    try {
      shuffleServerClient.getShuffleData(new RssGetShuffleDataRequest(
          appId, shuffleId, 0, 1, 3,
          0, 100));
    } catch (Exception e) {
      // ignore the exception, just test metrics value
    }
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_DATA_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.GET_SHUFFLE_DATA_METHOD).get(), 0.5);

    double newGrpcTotal = shuffleServers.get(0).getGrpcMetrics().getCounterGrpcTotal().get();
    // require buffer will be called one more time when send data
    assertEquals(oldGrpcTotal + 11, newGrpcTotal, 0.5);
    assertEquals(0, shuffleServers.get(0).getGrpcMetrics().getGaugeGrpcOpen().get(), 0.5);
  }
"
"  @Test
  public void readUploadedDataTest() {
    String appId = ""ap_read_uploaded_data"";
    RssRegisterShuffleRequest rr1 =  new RssRegisterShuffleRequest(appId, 0,
        Lists.newArrayList(new PartitionRange(0, 0)));
    RssRegisterShuffleRequest rr2 =  new RssRegisterShuffleRequest(appId, 0,
        Lists.newArrayList(new PartitionRange(1, 1)));
    RssRegisterShuffleRequest rr3 =  new RssRegisterShuffleRequest(appId, 0,
        Lists.newArrayList(new PartitionRange(2, 2)));
    RssRegisterShuffleRequest rr4 =  new RssRegisterShuffleRequest(appId, 0,
        Lists.newArrayList(new PartitionRange(4, 4)));
    shuffleServerClient.registerShuffle(rr1);
    shuffleServerClient.registerShuffle(rr2);
    shuffleServerClient.registerShuffle(rr3);
    shuffleServerClient.registerShuffle(rr4);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Set<Long> expectedBlock1 = Sets.newHashSet();
    Set<Long> expectedBlock2 = Sets.newHashSet();

    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap3 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap4 = Roaring64NavigableMap.bitmapOf();

    List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
        0, 0, 1,3, 25, blockIdBitmap1, expectedData);
    List<ShuffleBlockInfo> blocks2 = createShuffleBlockList(
        0, 1, 1,5,1024 * 1024, blockIdBitmap2, expectedData);
    List<ShuffleBlockInfo> blocks3 = createShuffleBlockList(
        0, 2, 2,4, 25, blockIdBitmap3, expectedData);
    List<ShuffleBlockInfo> blocks4 = createShuffleBlockList(
        0, 4, 3,1, 1024 * 1024, blockIdBitmap4, expectedData);


    blocks1.forEach(b -> expectedBlock1.add(b.getBlockId()));
    blocks2.forEach(b -> expectedBlock2.add(b.getBlockId()));

    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = Maps.newHashMap();
    partitionToBlocks.put(0, blocks1);
    partitionToBlocks.put(1, blocks2);
    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);
    RssSendShuffleDataRequest rs1 = new RssSendShuffleDataRequest(appId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rs1);

    RssSendCommitRequest rc1 = new RssSendCommitRequest(appId, 0);
    shuffleServerClient.sendCommit(rc1);
    RssFinishShuffleRequest rf1 = new RssFinishShuffleRequest(appId, 0);
    shuffleServerClient.finishShuffle(rf1);
    Map<Integer, List<Long>> partitionToBlockIds = Maps.newHashMap();
    partitionToBlockIds.put(0, new ArrayList<>(expectedBlock1));
    partitionToBlockIds.put(1, new ArrayList<>(expectedBlock2));
    RssReportShuffleResultRequest rrp1 = new RssReportShuffleResultRequest(
        appId, 0, 1L, partitionToBlockIds, 2);
    shuffleServerClient.reportShuffleResult(rrp1);

    DiskItem item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 0);
    assertTrue(item.canWrite());
    assertEquals(3 * 25, item.getNotUploadedSize(appId + ""/"" + 0));
    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 1);
    assertTrue(item.canWrite());
    assertEquals(5 * 1024 * 1024, item.getNotUploadedSize(appId + ""/"" + 0));

    sendSinglePartitionToShuffleServer(appId, 0,2, 2L, blocks3);
    sendSinglePartitionToShuffleServer(appId, 0, 4, 3L, blocks4);

    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 2);
    assertTrue(item.canWrite());
    assertEquals(3 * 25 + 4 * 25, item.getNotUploadedSize(appId + ""/"" + 0));

    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 4);
    assertTrue(item.canWrite());
    assertEquals(5 * 1024 * 1024 + 1024 * 1024, item.getNotUploadedSize(appId + ""/"" + 0));


    RssGetShuffleResultRequest rg1 = new RssGetShuffleResultRequest(appId, 0, 0);
    shuffleServerClient.getShuffleResult(rg1);
    RssGetShuffleResultRequest rg2 = new RssGetShuffleResultRequest(appId, 0, 1);
    shuffleServerClient.getShuffleResult(rg2);
    RssGetShuffleResultRequest rg3 = new RssGetShuffleResultRequest(appId, 0, 2);
    shuffleServerClient.getShuffleResult(rg3);
    RssGetShuffleResultRequest rg4 = new RssGetShuffleResultRequest(appId, 0, 4);
    shuffleServerClient.getShuffleResult(rg4);

    readShuffleData(shuffleServerClient, appId, 0, 0, 1, 10, 100, 0);
    readShuffleData(shuffleServerClient, appId, 0, 1, 1, 10, 100, 0);


    wait(appId);

    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 0);
    assertTrue(item.canWrite());
    assertEquals(0, item.getNotUploadedSize(appId + ""/"" + 0));

    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 1);
    assertTrue(item.canWrite());
    assertEquals(0, item.getNotUploadedSize(appId + ""/"" + 0));

    boolean isException = false;
    try {
      ShuffleDataResult result = readShuffleData(shuffleServerClient, appId, 0, 0,
          1, 10, 1000,  0);
    } catch (RuntimeException re) {
      isException = true;
      assertTrue(re.getMessage().contains(""Can't get shuffle index""));
    }
    assertTrue(isException);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(""LOCALFILE_AND_HDFS"",
        appId, 0, 0, 100, 1, 10, 1000, HDFS_URI + ""rss/multi_storage"",
        blockIdBitmap1, Roaring64NavigableMap.bitmapOf(1), Lists.newArrayList(), conf);
    validateResult(readClient, expectedData, blockIdBitmap1);

    readClient = new ShuffleReadClientImpl(""LOCALFILE_AND_HDFS"",
        appId, 0, 1, 100, 1, 10, 1000, HDFS_URI + ""rss/multi_storage"",
        blockIdBitmap2, Roaring64NavigableMap.bitmapOf(1), Lists.newArrayList(), conf);
    validateResult(readClient, expectedData, blockIdBitmap2);

    readClient = new ShuffleReadClientImpl(""LOCALFILE_AND_HDFS"",
        appId, 0, 2, 100, 1, 10, 1000, HDFS_URI + ""rss/multi_storage"",
        blockIdBitmap3, Roaring64NavigableMap.bitmapOf(2), Lists.newArrayList(), conf);
    validateResult(readClient, expectedData, blockIdBitmap3);

    readClient = new ShuffleReadClientImpl(""LOCALFILE_AND_HDFS"",
        appId, 0, 4, 100, 1, 10, 1000, HDFS_URI + ""rss/multi_storage"",
        blockIdBitmap4, Roaring64NavigableMap.bitmapOf(3), Lists.newArrayList(), conf);
    validateResult(readClient, expectedData, blockIdBitmap4);
  }
"
"  @Test
  public void readLocalDataTest() {
    String appId = ""app_read_not_uploaded_data"";
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    RssRegisterShuffleRequest rr1 =  new RssRegisterShuffleRequest(appId, 1,
        Lists.newArrayList(new PartitionRange(0, 0)));
    RssRegisterShuffleRequest rr2 =  new RssRegisterShuffleRequest(appId, 1,
        Lists.newArrayList(new PartitionRange(1, 1)));
    RssRegisterShuffleRequest rr3 =  new RssRegisterShuffleRequest(appId, 1,
        Lists.newArrayList(new PartitionRange(2, 2)));
    RssRegisterShuffleRequest rr4 =  new RssRegisterShuffleRequest(appId, 1,
        Lists.newArrayList(new PartitionRange(3, 3)));
    shuffleServerClient.registerShuffle(rr1);
    shuffleServerClient.registerShuffle(rr2);
    shuffleServerClient.registerShuffle(rr3);
    shuffleServerClient.registerShuffle(rr4);

    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap3 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap4 = Roaring64NavigableMap.bitmapOf();

    List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
        1, 0, 1,3, 25, blockIdBitmap1, expectedData);
    List<ShuffleBlockInfo> blocks2 = createShuffleBlockList(
        1, 1, 2,5,1024 * 1024, blockIdBitmap2, expectedData);
    List<ShuffleBlockInfo> blocks3 = createShuffleBlockList(
        1, 2, 3,4, 25, blockIdBitmap3, expectedData);
    List<ShuffleBlockInfo> blocks4 = createShuffleBlockList(
        1, 3, 4,1, 1024 * 1024, blockIdBitmap4, expectedData);

    sendSinglePartitionToShuffleServer(appId, 1,0, 1L, blocks1);
    sendSinglePartitionToShuffleServer(appId, 1,1, 2L, blocks2);
    sendSinglePartitionToShuffleServer(appId, 1,2, 3L, blocks3);
    sendSinglePartitionToShuffleServer(appId, 1,3, 4L, blocks4);

    RssGetShuffleResultRequest rg1 = new RssGetShuffleResultRequest(appId, 1, 0);
    shuffleServerClient.getShuffleResult(rg1);
    RssGetShuffleResultRequest rg2 = new RssGetShuffleResultRequest(appId, 1, 1);
    shuffleServerClient.getShuffleResult(rg2);
    RssGetShuffleResultRequest rg3 = new RssGetShuffleResultRequest(appId, 1, 2);
    shuffleServerClient.getShuffleResult(rg3);
    RssGetShuffleResultRequest rg4 = new RssGetShuffleResultRequest(appId, 1, 3);
    shuffleServerClient.getShuffleResult(rg4);

    Uninterruptibles.sleepUninterruptibly(2, TimeUnit.SECONDS);
    validateResult(appId, 1, 0, expectedData, getExpectBlockIds(blocks1));
    Uninterruptibles.sleepUninterruptibly(2, TimeUnit.SECONDS);
    validateResult(appId, 1, 1, expectedData, getExpectBlockIds(blocks2));
    Uninterruptibles.sleepUninterruptibly(2, TimeUnit.SECONDS);
    validateResult(appId, 1, 2, expectedData, getExpectBlockIds(blocks3));
    Uninterruptibles.sleepUninterruptibly(2, TimeUnit.SECONDS);
    validateResult(appId, 1, 3, expectedData, getExpectBlockIds(blocks4));
    Uninterruptibles.sleepUninterruptibly(20, TimeUnit.SECONDS);
    boolean isException = false;
    try {
      readShuffleData(shuffleServerClient, appId, 1, 0,
          1, 10, 1000,  0);
    } catch (RuntimeException re) {
      isException = true;
      assertTrue(re.getMessage().contains(""Can't get shuffle index""));
    }
    assertTrue(isException);
  }
"
"  @Test
  public void readMixedDataTest() {
    String appId = ""app_read_mix_data"";
    RssRegisterShuffleRequest rr1 =  new RssRegisterShuffleRequest(appId, 0,
        Lists.newArrayList(new PartitionRange(0, 0)));
    shuffleServerClient.registerShuffle(rr1);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Set<Long> expectedBlock1 = Sets.newHashSet();

    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();

    List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
        0, 0, 1,15, 1024 * 1024, blockIdBitmap1, expectedData);

    blocks1.forEach(b -> expectedBlock1.add(b.getBlockId()));

    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = Maps.newHashMap();
    partitionToBlocks.put(0, blocks1);
    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);
    RssSendShuffleDataRequest rs1 = new RssSendShuffleDataRequest(appId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rs1);

    RssSendCommitRequest rc1 = new RssSendCommitRequest(appId, 0);
    shuffleServerClient.sendCommit(rc1);
    RssFinishShuffleRequest rf1 = new RssFinishShuffleRequest(appId, 0);
    shuffleServerClient.finishShuffle(rf1);
    Map<Integer, List<Long>> partitionToBlockIds = Maps.newHashMap();
    partitionToBlockIds.put(0, new ArrayList<>(expectedBlock1));
    RssReportShuffleResultRequest rrp1 = new RssReportShuffleResultRequest(
        appId, 0, 1L, partitionToBlockIds, 1);
    shuffleServerClient.reportShuffleResult(rrp1);

    RssGetShuffleResultRequest rg1 = new RssGetShuffleResultRequest(appId, 0, 0);
    shuffleServerClient.getShuffleResult(rg1);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(""LOCALFILE_AND_HDFS"",
        appId, 0, 0, 100, 1, 10, 1000, HDFS_URI + ""rss/multi_storage"",
        blockIdBitmap1, Roaring64NavigableMap.bitmapOf(1), Lists.newArrayList(new ShuffleServerInfo(""test"", LOCALHOST, SHUFFLE_SERVER_PORT)), conf);

    CompressedShuffleBlock csb = readClient.readShuffleBlockData();
    Roaring64NavigableMap matched = Roaring64NavigableMap.bitmapOf();
    assertNotNull(csb);
    assertNotNull(csb.getByteBuffer());
    for (Map.Entry<Long, byte[]> entry : expectedData.entrySet()) {
      if (compareByte(entry.getValue(), csb.getByteBuffer())) {
        matched.addLong(entry.getKey());
      }
    }
    wait(appId);

    csb = readClient.readShuffleBlockData();
    while (csb != null && csb.getByteBuffer() != null) {
      for (Map.Entry<Long, byte[]> entry : expectedData.entrySet()) {
        if (compareByte(entry.getValue(), csb.getByteBuffer())) {
          matched.addLong(entry.getKey());
          break;
        }
      }
      csb = readClient.readShuffleBlockData();
    }
    assertTrue(blockIdBitmap1.equals(matched));

    boolean isException = false;
    try {
      readShuffleData(shuffleServerClient, appId, 0, 0,
          1, 10, 1000, 0);
    } catch (RuntimeException re) {
      isException = true;
      assertTrue(re.getMessage().contains(""Can't get shuffle index""));
    }
    assertTrue(isException);

    List<ShuffleBlockInfo> blocks5 = createShuffleBlockList(
        0, 0, 1,15, 1024 * 1024, blockIdBitmap1, expectedData);
    partitionToBlocks.clear();
    shuffleToBlocks.clear();
    partitionToBlocks.put(0, blocks5);
    shuffleToBlocks.put(0, partitionToBlocks);
    RssSendShuffleDataRequest rs5 = new RssSendShuffleDataRequest(appId, 3, 1000, shuffleToBlocks);
    DiskItem diskItem = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 0);
    String path = ShuffleStorageUtils.getFullShuffleDataFolder(diskItem.getBasePath(),
        ShuffleStorageUtils.getShuffleDataPath(appId, 0, 0, 0));
    File file = new File(path);
    assertFalse(file.exists());
    try {
      shuffleServerClient.sendShuffleData(rs5);
      shuffleServerClient.sendCommit(rc1);
      shuffleServerClient.finishShuffle(rf1);
      shuffleServerClient.reportShuffleResult(rrp1);
    } catch (Exception e) {
      fail();
    }
    assertFalse(file.exists());
  }
"
"  @Test
  public void diskUsageTest() {
    String appId = ""app_read_diskusage_data"";
    long originSize = shuffleServers.get(0).getShuffleBufferManager().getCapacity();
    Map<Long, byte[]> expectedData = Maps.newHashMap();

    RssRegisterShuffleRequest rr1 =  new RssRegisterShuffleRequest(appId, 2,
        Lists.newArrayList(new PartitionRange(0, 0)));
    shuffleServerClient.registerShuffle(rr1);

    RssRegisterShuffleRequest rr2 =  new RssRegisterShuffleRequest(appId, 3,
        Lists.newArrayList(new PartitionRange(1, 1)));
    shuffleServerClient.registerShuffle(rr2);

    RssRegisterShuffleRequest rr3 =  new RssRegisterShuffleRequest(appId, 2,
        Lists.newArrayList(new PartitionRange(1, 1)));
    shuffleServerClient.registerShuffle(rr3);

    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap3 = Roaring64NavigableMap.bitmapOf();

    List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
        2, 0, 1,30, 10 * 1024 * 1024, blockIdBitmap1, expectedData);

    List<ShuffleBlockInfo> blocks2 = createShuffleBlockList(
        3, 1, 2,9, 10 * 1024 * 1024, blockIdBitmap2, expectedData);

    List<ShuffleBlockInfo> blocks3 = createShuffleBlockList(
        2, 1, 2,9, 10 * 1024 * 1024, blockIdBitmap3, expectedData);

    DiskItem item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 2, 0);
    item.createMetadataIfNotExist(appId + ""/"" + 2);
    item.getLock(appId + ""/"" + 2).readLock().lock();
    sendSinglePartitionToShuffleServer(appId, 2, 0, 1, blocks1);
    assertFalse(item.canWrite());
    assertEquals(30 * 1024 * 1024 * 10, item.getNotUploadedSize(appId + ""/"" + 2));
    assertEquals(1, item.getNotUploadedPartitions(appId + ""/"" + 2).getCardinality());
    boolean isException = false;
    try {
      sendSinglePartitionToShuffleServer(appId, 2, 1, 2, blocks3);
    } catch (RuntimeException re) {
      isException = true;
      assertTrue(re.getMessage().contains(""Can't finish shuffle process""));
    }
    item.getLock(appId + ""/"" + 2).readLock().unlock();
    Uninterruptibles.sleepUninterruptibly(6, TimeUnit.SECONDS);
    assertEquals(originSize, shuffleServers.get(0).getShuffleBufferManager().getCapacity());
    assertTrue(isException);
    RssGetShuffleResultRequest rg1 = new RssGetShuffleResultRequest(appId, 2, 0);
    shuffleServerClient.getShuffleResult(rg1);
    validateResult(appId, 2, 0, expectedData, Sets.newHashSet());
    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(""LOCALFILE_AND_HDFS"",
        appId, 2, 0, 100, 1, 10, 1000, HDFS_URI + ""rss/multi_storage"",
        blockIdBitmap1, Roaring64NavigableMap.bitmapOf(1), Lists.newArrayList(new ShuffleServerInfo(""test"", LOCALHOST, SHUFFLE_SERVER_PORT)), conf);
    validateResult(readClient, expectedData, blockIdBitmap1);
    try {
      sendSinglePartitionToShuffleServer(appId, 3, 1,2, blocks2);
    } catch (RuntimeException re) {
      fail();
    }
    RssGetShuffleResultRequest rg2 = new RssGetShuffleResultRequest(appId, 3, 1);
    shuffleServerClient.getShuffleResult(rg2);
    validateResult(appId, 3, 1, expectedData,
        getExpectBlockIds(blocks2));

    Uninterruptibles.sleepUninterruptibly(5, TimeUnit.SECONDS);
  }
"
"  @Test
  public void removeMetaTest() {
    String appId = ""app_read_diskusage_data_without_report"";
    Map<Long, byte[]> expectedData = Maps.newHashMap();
    RssRegisterShuffleRequest rr1 =  new RssRegisterShuffleRequest(appId, 2,
        Lists.newArrayList(new PartitionRange(0, 0)));
    shuffleServerClient.registerShuffle(rr1);
    RssRegisterShuffleRequest rr2 =  new RssRegisterShuffleRequest(appId, 3,
        Lists.newArrayList(new PartitionRange(1, 1)));
    shuffleServerClient.registerShuffle(rr2);

    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();

    List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
        2, 0, 1,30, 10 * 1024 * 1024, blockIdBitmap1, expectedData);
    List<ShuffleBlockInfo> blocks2 = createShuffleBlockList(
        3, 1, 2,9, 10 * 1024 * 1024, blockIdBitmap2, expectedData);

    sendSinglePartitionToShuffleServerWithoutReport(appId, 2, 2, 2, blocks1);
    sendSinglePartitionToShuffleServerWithoutReport(appId, 3, 1,2, blocks2);
    shuffleServers.get(0).getShuffleTaskManager().removeResources(appId);
    DiskItem item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 2, 0);
    Uninterruptibles.sleepUninterruptibly(1500, TimeUnit.MILLISECONDS);
    Set<String> keys = item.getShuffleMetaSet();
    assertTrue(keys.isEmpty());
    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 3, 1);
    keys = item.getShuffleMetaSet();
    assertTrue(keys.isEmpty());

    appId = ""app_read_diskusage_data_with_report"";
    rr1 =  new RssRegisterShuffleRequest(appId, 0, Lists.newArrayList(new PartitionRange(0, 0)));
    shuffleServerClient.registerShuffle(rr1);
    blocks1 = createShuffleBlockList(
        0, 0, 1,30, 10 * 1024, blockIdBitmap1, expectedData);
    sendSinglePartitionToShuffleServer(appId, 0, 0, 2, blocks1);
    shuffleServers.get(0).getShuffleTaskManager().removeResources(appId);
    item = shuffleServers.get(0).getMultiStorageManager().getDiskItem(appId, 0, 0);
    Uninterruptibles.sleepUninterruptibly(1500, TimeUnit.MILLISECONDS);
    keys = item.getShuffleMetaSet();
    assertTrue(keys.isEmpty());
  }
"
"  @Test
  public void resultCompareTest() throws Exception {
    run();
  }
"
"  @Test
  public void resultCompareTest() throws Exception {
    run();
  }
"
"  @Test
  public void testUploadFile() {
    FileOutputStream fileOut = null;
    DataOutputStream dataOut = null;
    try {
      TemporaryFolder tmpDir = new TemporaryFolder();
      tmpDir.create();
      File file = tmpDir.newFile(""test"");
      fileOut = new FileOutputStream(file);
      dataOut = new DataOutputStream(fileOut);
      byte[] buf = new byte[2096];
      new Random().nextBytes(buf);
      dataOut.write(buf);
      dataOut.close();
      fileOut.close();
      String path = HDFS_URI + ""test"";
      HdfsFileWriter writer = new HdfsFileWriter(new Path(path), conf);
      long size = ShuffleStorageUtils.uploadFile(file, writer, 1024);
      assertEquals(2096, size);
      size = ShuffleStorageUtils.uploadFile(file, writer, 100);
      assertEquals(2096, size);
      writer.close();
      tmpDir.delete();
    } catch (Exception e) {
      e.printStackTrace();
      fail();
    }
  }
"
"  @Test
  public void mergeSegmentsTest() {
    List<FileBasedShuffleSegment> segments = Lists.newArrayList(
        new FileBasedShuffleSegment(1, 0, 40, 0, 0, 0));
    List<DataFileSegment> fileSegments = ShuffleStorageUtils.mergeSegments(""path"", segments, 100);
    assertEquals(1, fileSegments.size());
    for (DataFileSegment seg : fileSegments) {
      assertEquals(0, seg.getOffset());
      assertEquals(40, seg.getLength());
      assertEquals(""path"", seg.getPath());
      List<BufferSegment> bufferSegments = seg.getBufferSegments();
      assertEquals(1, bufferSegments.size());
      assertEquals(new BufferSegment(1, 0, 40, 0, 0, 0), bufferSegments.get(0));
    }

    segments = Lists.newArrayList(
        new FileBasedShuffleSegment(1, 0, 40, 0, 0, 0),
        new FileBasedShuffleSegment(2, 40, 40, 0, 0, 0),
        new FileBasedShuffleSegment(3, 80, 20, 0, 0, 0));
    fileSegments = ShuffleStorageUtils.mergeSegments(""path"", segments, 100);
    assertEquals(1, fileSegments.size());
    for (DataFileSegment seg : fileSegments) {
      assertEquals(0, seg.getOffset());
      assertEquals(100, seg.getLength());
      assertEquals(""path"", seg.getPath());
      List<BufferSegment> bufferSegments = seg.getBufferSegments();
      assertEquals(3, bufferSegments.size());
      Set<Long> testedBlockIds = Sets.newHashSet();
      for (BufferSegment segment : bufferSegments) {
        if (segment.getBlockId() == 1) {
          assertTrue(segment.equals(new BufferSegment(1, 0, 40, 0, 0, 0)));
          testedBlockIds.add(1L);
        } else if (segment.getBlockId() == 2) {
          assertTrue(segment.equals(new BufferSegment(2, 40, 40, 0, 0, 0)));
          testedBlockIds.add(2L);
        } else if (segment.getBlockId() == 3) {
          assertTrue(segment.equals(new BufferSegment(3, 80, 20, 0, 0, 0)));
          testedBlockIds.add(3L);
        }
      }
      assertEquals(3, testedBlockIds.size());
    }

    segments = Lists.newArrayList(
        new FileBasedShuffleSegment(1, 0, 40, 0, 0, 0),
        new FileBasedShuffleSegment(2, 40, 40, 0, 0, 0),
        new FileBasedShuffleSegment(3, 80, 20, 0, 0, 0),
        new FileBasedShuffleSegment(4, 100, 20, 0, 0, 0));
    fileSegments = ShuffleStorageUtils.mergeSegments(""path"", segments, 100);
    assertEquals(2, fileSegments.size());
    boolean tested = false;
    for (DataFileSegment seg : fileSegments) {
      if (seg.getOffset() == 100) {
        tested = true;
        assertEquals(20, seg.getLength());
        assertEquals(""path"", seg.getPath());
        List<BufferSegment> bufferSegments = seg.getBufferSegments();
        assertEquals(1, bufferSegments.size());
        assertTrue(bufferSegments.get(0).equals(new BufferSegment(4, 0, 20, 0, 0, 0)));
      }
    }
    assertTrue(tested);

    segments = Lists.newArrayList(
        new FileBasedShuffleSegment(1, 0, 40, 0, 0, 0),
        new FileBasedShuffleSegment(2, 40, 40, 0, 0, 0),
        new FileBasedShuffleSegment(3, 80, 20, 0, 0, 0),
        new FileBasedShuffleSegment(4, 100, 20, 0, 0, 0),
        new FileBasedShuffleSegment(5, 120, 100, 0, 0, 0));
    fileSegments = ShuffleStorageUtils.mergeSegments(""path"", segments, 100);
    assertEquals(2, fileSegments.size());
    tested = false;
    for (DataFileSegment seg : fileSegments) {
      if (seg.getOffset() == 100) {
        tested = true;
        assertEquals(120, seg.getLength());
        assertEquals(""path"", seg.getPath());
        List<BufferSegment> bufferSegments = seg.getBufferSegments();
        assertEquals(2, bufferSegments.size());
        Set<Long> testedBlockIds = Sets.newHashSet();
        for (BufferSegment segment : bufferSegments) {
          if (segment.getBlockId() == 4) {
            assertTrue(segment.equals(new BufferSegment(4, 0, 20, 0, 0, 0)));
            testedBlockIds.add(4L);
          } else if (segment.getBlockId() == 5) {
            assertTrue(segment.equals(new BufferSegment(5, 20, 100, 0, 0, 0)));
            testedBlockIds.add(5L);
          }
        }
        assertEquals(2, testedBlockIds.size());
      }
    }
    assertTrue(tested);

    segments = Lists.newArrayList(
        new FileBasedShuffleSegment(1, 10, 40, 0, 0, 0),
        new FileBasedShuffleSegment(2, 80, 20, 0, 0, 0),
        new FileBasedShuffleSegment(3, 500, 120, 0, 0, 0),
        new FileBasedShuffleSegment(4, 700, 20, 0, 0, 0));
    fileSegments = ShuffleStorageUtils.mergeSegments(""path"", segments, 100);
    assertEquals(3, fileSegments.size());
    Set<Long> expectedOffset = Sets.newHashSet(10L, 500L, 700L);
    for (DataFileSegment seg : fileSegments) {
      if (seg.getOffset() == 10) {
        validResult(seg, 90, 1, 40, 2, 70);
        expectedOffset.remove(10L);
      }
      if (seg.getOffset() == 500) {
        assertEquals(120, seg.getLength());
        List<BufferSegment> bufferSegments = seg.getBufferSegments();
        assertEquals(1, bufferSegments.size());
        assertTrue(bufferSegments.get(0).equals(new BufferSegment(3, 0, 120, 0, 0, 0)));
        expectedOffset.remove(500L);
      }
      if (seg.getOffset() == 700) {
        assertEquals(20, seg.getLength());
        List<BufferSegment> bufferSegments = seg.getBufferSegments();
        assertEquals(1, bufferSegments.size());
        assertTrue(bufferSegments.get(0).equals(new BufferSegment(4, 0, 20, 0, 0, 0)));
        expectedOffset.remove(700L);
      }
    }
    assertTrue(expectedOffset.isEmpty());

    segments = Lists.newArrayList(
        new FileBasedShuffleSegment(5, 500, 120, 0, 0, 0),
        new FileBasedShuffleSegment(3, 630, 10, 0, 0, 0),
        new FileBasedShuffleSegment(2, 80, 20, 0, 0, 0),
        new FileBasedShuffleSegment(1, 10, 40, 0, 0, 0),
        new FileBasedShuffleSegment(6, 769, 20, 0, 0, 0),
        new FileBasedShuffleSegment(4, 700, 20, 0, 0, 0));
    fileSegments = ShuffleStorageUtils.mergeSegments(""path"", segments, 100);
    assertEquals(4, fileSegments.size());
    expectedOffset = Sets.newHashSet(10L, 500L, 630L, 700L);
    for (DataFileSegment seg : fileSegments) {
      if (seg.getOffset() == 10) {
        validResult(seg, 90, 1, 40, 2, 70);
        expectedOffset.remove(10L);
      }
      if (seg.getOffset() == 500) {
        assertEquals(120, seg.getLength());
        List<BufferSegment> bufferSegments = seg.getBufferSegments();
        assertEquals(1, bufferSegments.size());
        assertTrue(bufferSegments.get(0).equals(new BufferSegment(5, 0, 120, 0, 0, 0)));
        expectedOffset.remove(500L);
      }
      if (seg.getOffset() == 630) {
        assertEquals(10, seg.getLength());
        List<BufferSegment> bufferSegments = seg.getBufferSegments();
        assertEquals(1, bufferSegments.size());
        assertTrue(bufferSegments.get(0).equals(new BufferSegment(3, 0, 10, 0, 0, 0)));
        expectedOffset.remove(630L);
      }
      if (seg.getOffset() == 700) {
        validResult(seg, 89, 4, 20, 6, 69);
        expectedOffset.remove(700L);
      }
    }
    assertTrue(expectedOffset.isEmpty());
  }
"
"  @Test
  public void getShuffleDataPathWithRangeTest() {
    String result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 1, 3, 6);
    assertEquals(""appId/0/0-2"", result);
    result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 2, 3, 6);
    assertEquals(""appId/0/0-2"", result);
    result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 3, 3, 6);
    assertEquals(""appId/0/3-5"", result);
    result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 5, 3, 6);
    assertEquals(""appId/0/3-5"", result);
    try {
      ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 6, 3, 6);
      fail(""shouldn't be here"");
    } catch (Exception e) {
      assertTrue(e.getMessage().startsWith(""Can't generate ShuffleData Path""));
    }
    result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 6, 3, 7);
    assertEquals(""appId/0/6-8"", result);
  }
"
"  @Test
  public void getStorageIndexTest() {
    int index = ShuffleStorageUtils.getStorageIndex(3, ""abcde"", 3, 1);
    assertEquals(2, index);
    index = ShuffleStorageUtils.getStorageIndex(3, ""abcde"", 3, 4);
    assertEquals(1, index);
  }
"
"    @Test(expected = IllegalArgumentException.class)
    public void testExceptionOnEmpty() {
        new BwcVersions(asList(""foo"", ""bar""), Version.fromString(""7.0.0""));
    }
"
"    @Test(expected = IllegalStateException.class)
    public void testExceptionOnNonCurrent() {
        new BwcVersions(singletonList(formatVersionToLine(""6.5.0"")), Version.fromString(""7.0.0""));
    }
"
"    @Test(expected = IllegalStateException.class)
    public void testExceptionOnTooManyMajors() {
        new BwcVersions(
            asList(formatVersionToLine(""5.6.12""), formatVersionToLine(""6.5.0""), formatVersionToLine(""7.0.0"")),
            Version.fromString(""6.5.0"")
        );
    }
"
"    @Test
    public void whenDependencyDoesntExistThenShouldDeleteDependencySha() throws IOException, NoSuchAlgorithmException {

        File unusedSha = createFileIn(getLicensesDir(project), ""test.sha1"", """");
        task.updateShas();

        assertFalse(unusedSha.exists());
    }
"
"    @Test
    public void whenDependencyExistsButShaNotThenShouldCreateNewShaFile() throws IOException, NoSuchAlgorithmException {
        project.getDependencies().add(""compile"", dependency);

        getLicensesDir(project).mkdir();
        task.updateShas();

        Path groovySha = Files.list(getLicensesDir(project).toPath()).findFirst().get();

        assertTrue(groovySha.toFile().getName().startsWith(""groovy-all""));
    }
"
"    @Test
    public void whenDependencyAndWrongShaExistsThenShouldNotOverwriteShaFile() throws IOException, NoSuchAlgorithmException {
        project.getDependencies().add(""compile"", dependency);

        File groovyJar = task.getParentTask().getDependencies().getFiles().iterator().next();
        String groovyShaName = groovyJar.getName() + "".sha1"";

        File groovySha = createFileIn(getLicensesDir(project), groovyShaName, ""content"");
        task.updateShas();

        assertThat(FileUtils.readFileToString(groovySha), equalTo(""content""));
    }
"
"    @Test
    public void whenLicensesDirDoesntExistThenShouldThrowException() throws IOException, NoSuchAlgorithmException {
        expectedException.expect(GradleException.class);
        expectedException.expectMessage(containsString(""isn't a valid directory""));

        task.updateShas();
    }
"
"    @Test
    public void givenProjectWithLicensesDirButNoDependenciesThenShouldThrowException() throws Exception {
        expectedException.expect(GradleException.class);
        expectedException.expectMessage(containsString(""exists, but there are no dependencies""));

        getLicensesDir(project).mkdir();
        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithoutLicensesDirButWithDependenciesThenShouldThrowException() throws Exception {
        expectedException.expect(GradleException.class);
        expectedException.expectMessage(containsString(""does not exist, but there are dependencies""));

        project.getDependencies().add(""compile"", dependency);
        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithoutLicensesDirNorDependenciesThenShouldReturnSilently() throws Exception {
        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithDependencyButNoShaFileThenShouldReturnException() throws Exception {
        expectedException.expect(GradleException.class);
        expectedException.expectMessage(containsString(""Missing SHA for ""));

        File licensesDir = getLicensesDir(project);
        createFileIn(licensesDir, ""groovy-all-LICENSE.txt"", PERMISSIVE_LICENSE_TEXT);
        createFileIn(licensesDir, ""groovy-all-NOTICE.txt"", """");

        project.getDependencies().add(""compile"", project.getDependencies().localGroovy());
        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithDependencyButNoLicenseFileThenShouldReturnException() throws Exception {
        expectedException.expect(GradleException.class);
        expectedException.expectMessage(containsString(""Missing LICENSE for ""));

        project.getDependencies().add(""compile"", project.getDependencies().localGroovy());

        getLicensesDir(project).mkdir();
        updateShas.updateShas();
        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithDependencyButNoNoticeFileThenShouldReturnException() throws Exception {
        expectedException.expect(GradleException.class);
        expectedException.expectMessage(containsString(""Missing NOTICE for ""));

        project.getDependencies().add(""compile"", dependency);

        createFileIn(getLicensesDir(project), ""groovy-all-LICENSE.txt"", PERMISSIVE_LICENSE_TEXT);

        updateShas.updateShas();
        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithStrictDependencyButNoSourcesFileThenShouldReturnException() throws Exception {
        expectedException.expect(GradleException.class);
        expectedException.expectMessage(containsString(""Missing SOURCES for ""));

        project.getDependencies().add(""compile"", dependency);

        createFileIn(getLicensesDir(project), ""groovy-all-LICENSE.txt"", STRICT_LICENSE_TEXT);
        createFileIn(getLicensesDir(project), ""groovy-all-NOTICE.txt"", """");

        updateShas.updateShas();
        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithStrictDependencyAndEverythingInOrderThenShouldReturnSilently() throws Exception {
        project.getDependencies().add(""compile"", dependency);

        createFileIn(getLicensesDir(project), ""groovy-all-LICENSE.txt"", STRICT_LICENSE_TEXT);
        createFileIn(getLicensesDir(project), ""groovy-all-NOTICE.txt"", """");
        createFileIn(getLicensesDir(project), ""groovy-all-SOURCES.txt"", """");

        updateShas.updateShas();
        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithDependencyAndEverythingInOrderThenShouldReturnSilently() throws Exception {
        project.getDependencies().add(""compile"", dependency);

        File licensesDir = getLicensesDir(project);

        createAllDefaultDependencyFiles(licensesDir, ""groovy-all"");
        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithALicenseButWithoutTheDependencyThenShouldThrowException() throws Exception {
        expectedException.expect(GradleException.class);
        expectedException.expectMessage(containsString(""Unused license ""));

        project.getDependencies().add(""compile"", dependency);

        File licensesDir = getLicensesDir(project);
        createAllDefaultDependencyFiles(licensesDir, ""groovy-all"");
        createFileIn(licensesDir, ""non-declared-LICENSE.txt"", """");

        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithANoticeButWithoutTheDependencyThenShouldThrowException() throws Exception {
        expectedException.expect(GradleException.class);
        expectedException.expectMessage(containsString(""Unused notice ""));

        project.getDependencies().add(""compile"", dependency);

        File licensesDir = getLicensesDir(project);
        createAllDefaultDependencyFiles(licensesDir, ""groovy-all"");
        createFileIn(licensesDir, ""non-declared-NOTICE.txt"", """");

        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithAShaButWithoutTheDependencyThenShouldThrowException() throws Exception {
        expectedException.expect(GradleException.class);
        expectedException.expectMessage(containsString(""Unused sha files found: \n""));

        project.getDependencies().add(""compile"", dependency);

        File licensesDir = getLicensesDir(project);
        createAllDefaultDependencyFiles(licensesDir, ""groovy-all"");
        createFileIn(licensesDir, ""non-declared.sha1"", """");

        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithADependencyWithWrongShaThenShouldThrowException() throws Exception {
        expectedException.expect(GradleException.class);
        expectedException.expectMessage(containsString(""SHA has changed! Expected ""));

        project.getDependencies().add(""compile"", dependency);

        File licensesDir = getLicensesDir(project);
        createAllDefaultDependencyFiles(licensesDir, ""groovy-all"");

        Path groovySha = Files.list(licensesDir.toPath()).filter(file -> file.toFile().getName().contains(""sha"")).findFirst().get();

        Files.write(groovySha, new byte[] { 1 }, StandardOpenOption.CREATE);

        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithADependencyMappingThenShouldReturnSilently() throws Exception {
        project.getDependencies().add(""compile"", dependency);

        File licensesDir = getLicensesDir(project);
        createAllDefaultDependencyFiles(licensesDir, ""groovy"");

        Map<String, String> mappings = new HashMap<>();
        mappings.put(""from"", ""groovy-all"");
        mappings.put(""to"", ""groovy"");

        task.get().mapping(mappings);
        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithAIgnoreShaConfigurationAndNoShaFileThenShouldReturnSilently() throws Exception {
        project.getDependencies().add(""compile"", dependency);

        File licensesDir = getLicensesDir(project);
        createFileIn(licensesDir, ""groovy-all-LICENSE.txt"", PERMISSIVE_LICENSE_TEXT);
        createFileIn(licensesDir, ""groovy-all-NOTICE.txt"", """");

        task.get().ignoreSha(""groovy-all"");
        task.get().checkDependencies();
    }
"
"    @Test
    public void givenProjectWithoutLicensesDirWhenAskingForShaFilesThenShouldThrowException() {
        expectedException.expect(GradleException.class);
        expectedException.expectMessage(containsString(""isn't a valid directory""));

        task.get().getShaFiles();
    }
"
"        @Test
        public void annotatedTestMethod() {

        }
"
"    @Test
    public void annotatedTestMethod() {

    }
"
"    @Test
    public void testPluginInstalled() {
        try (TransportClient client = new PreBuiltTransportClient(Settings.EMPTY)) {
            Settings settings = client.settings();
            assertEquals(Netty4Plugin.NETTY_TRANSPORT_NAME, NetworkModule.HTTP_DEFAULT_TYPE_SETTING.get(settings));
            assertEquals(Netty4Plugin.NETTY_TRANSPORT_NAME, NetworkModule.TRANSPORT_DEFAULT_TYPE_SETTING.get(settings));
        }
    }
"
"    @Test
    public void testInstallPluginTwice() {
        for (Class<? extends Plugin> plugin :
                Arrays.asList(ParentJoinPlugin.class, ReindexPlugin.class, PercolatorPlugin.class,
                    MustachePlugin.class)) {
            try {
                new PreBuiltTransportClient(Settings.EMPTY, plugin);
                fail(""exception expected"");
            } catch (IllegalArgumentException ex) {
                assertTrue(""Expected message to start with [plugin already exists: ] but was instead ["" + ex.getMessage() + ""]"",
                        ex.getMessage().startsWith(""plugin already exists: ""));
            }
        }
    }
"
"    @TestGroup(enabled = false, sysProperty = ""tests.awaitsfix"")
    public void setup() throws Exception {
        assumeFalse(failed); // skip rest of tests once one fails

        sh.reset();
        if (distribution().hasJdk == false) {
            Platforms.onLinux(() -> sh.getEnv().put(""JAVA_HOME"", systemJavaHome));
            Platforms.onWindows(() -> sh.getEnv().put(""JAVA_HOME"", systemJavaHome));
        }
    }
"
"@TestRuleLimitSysouts.Limit(bytes = 14000)
    public void testRestClient() throws URISyntaxException, IOException {
        final String baseUrl = buildBaseUrl();

        try (CloseableHttpClient client = HttpClientBuilder.create().build()) {
            final String endpoint = baseUrl + ""/employees/1"";
            logger.info(""Connecting to uri: "" + baseUrl);

            final HttpPut put = new HttpPut(new URI(endpoint));

            final String body = ""{""
                + ""  \""first_name\"": \""John\"",""
                + ""  \""last_name\"": \""Smith\"",""
                + ""  \""age\"": 25,""
                + ""  \""about\"": \""I love to go rock climbing\"",""
                + ""  \""interests\"": [""
                + ""    \""sports\"",""
                + ""    \""music\""""
                + ""  ]""
                + ""}"";

            put.setEntity(new StringEntity(body, ContentType.APPLICATION_JSON));
            try (CloseableHttpResponse response = client.execute(put)) {
                int status = response.getStatusLine().getStatusCode();
                assertThat(
                    ""expected a 201 response but got: "" + status + "" - body: "" + EntityUtils.toString(response.getEntity()),
                    status,
                    equalTo(201)
                );
            }

            logger.info(""Fetching resource at "" + endpoint);

            final HttpGet get = new HttpGet(new URI(endpoint));
            try (
                CloseableHttpResponse response = client.execute(get);
                XContentParser parser = JsonXContent.jsonXContent.createParser(
                    new NamedXContentRegistry(ClusterModule.getNamedXWriteables()),
                    DeprecationHandler.THROW_UNSUPPORTED_OPERATION,
                    response.getEntity().getContent()
                )
            ) {
                final Map<String, Object> map = parser.map();
                assertThat(map.get(""first_name""), equalTo(""John""));
                assertThat(map.get(""last_name""), equalTo(""Smith""));
                assertThat(map.get(""age""), equalTo(25));
                assertThat(map.get(""about""), equalTo(""I love to go rock climbing""));
                final Object interests = map.get(""interests"");
                assertThat(interests, instanceOf(List.class));
                @SuppressWarnings(""unchecked"")
                final List<String> interestsAsList = (List<String>) interests;
                assertThat(interestsAsList, containsInAnyOrder(""sports"", ""music""));
            }
        }
    }
"
"    @TestGroup(enabled = false, sysProperty = OpenSearchIntegTestCase.SYSPROP_THIRDPARTY)
    public ClusterService clusterService() {
        return internalCluster().clusterService();
    }
"
"    @TestLogging(
    public void testTracerLog() throws Exception {
        TransportRequestHandler<TransportRequest> handler = (request, channel, task) -> channel.sendResponse(new StringMessageResponse(""""));
        TransportRequestHandler<StringMessageRequest> handlerWithError = (request, channel, task) -> {
            if (request.timeout() > 0) {
                Thread.sleep(request.timeout);
            }
            channel.sendResponse(new RuntimeException(""""));

        };

        TransportResponseHandler<StringMessageResponse> noopResponseHandler = new TransportResponseHandler<StringMessageResponse>() {

            @Override
            public StringMessageResponse read(StreamInput in) throws IOException {
                return new StringMessageResponse(in);
            }
"
"    @Test
    public void testReproducible() throws IOException {
        if (ITER++ == 0) {
            CLUSTER_SEED = cluster().seed();
            for (int i = 0; i < SEQUENCE.length; i++) {
                SEQUENCE[i] = randomLong();
            }
        } else {
            assertEquals(CLUSTER_SEED, Long.valueOf(cluster().seed()));
            for (int i = 0; i < SEQUENCE.length; i++) {
                assertThat(SEQUENCE[i], equalTo(randomLong()));
            }
        }
    }
"
"        @TestLogging(value = ""xyz:TRACE,foo:WARN,foo.bar:ERROR"", reason = ""testing TestLogging method annotations"")
        public void annotatedTestMethod() {

        }
"
"        @TestLogging(value = ""abc:TRACE,xyz:DEBUG"", reason = ""testing TestLogging method annotations"")
        public void annotatedTestMethod2() {

        }
"
"        @TestIssueLogging(value = ""xyz:TRACE,foo:WARN,foo.bar:ERROR"", issueUrl = ""https://example.com"")
        public void annotatedTestMethod() {

        }
"
"        @TestIssueLogging(value = ""abc:TRACE,xyz:DEBUG"", issueUrl = ""https://example.com"")
        public void annotatedTestMethod2() {

        }
"
"        @TestIssueLogging(value =""foo.bar:ERROR"", issueUrl = ""https://example.com"")
        public void annotatedTestMethod() {

        }
"
"        @TestIssueLogging(value = ""xyz:DEBUG"", issueUrl = ""https://example.com"")
        public void annotatedTestMethod2() {

        }
"
"        @TestLogging(value = ""abc:INFO:WARN"", reason = ""testing an invalid TestLogging method annotation"")
        public void invalidMethod() {

        }
"
"        @TestIssueLogging(value = ""abc:INFO:WARN"", issueUrl = ""https://example.com"")
        public void invalidMethod() {

        }
"
"    @TestLogging(reason=""ensure logging happens"", value=""org.opensearch.discovery.HandshakingTransportAddressConnector:INFO"")
    public void testLogsFullConnectionFailureAfterSuccessfulHandshake() throws Exception {

        remoteNode = new DiscoveryNode(""remote-node"", buildNewFakeTransportAddress(), Version.CURRENT);
        remoteClusterName = ""local-cluster"";
        discoveryAddress = buildNewFakeTransportAddress();

        fullConnectionFailure = new ConnectTransportException(remoteNode, ""simulated"", new OpenSearchException(""root cause""));

        FailureListener failureListener = new FailureListener();

        MockLogAppender mockAppender = new MockLogAppender();
        mockAppender.start();
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""message"",
                HandshakingTransportAddressConnector.class.getCanonicalName(),
                Level.WARN,
                ""*completed handshake with [*] but followup connection failed*""));
        Logger targetLogger = LogManager.getLogger(HandshakingTransportAddressConnector.class);
        Loggers.addAppender(targetLogger, mockAppender);

        try {
            handshakingTransportAddressConnector.connectToRemoteMasterNode(discoveryAddress, failureListener);
            failureListener.assertFailure();
            mockAppender.assertAllExpectationsMatched();
        } finally {
            Loggers.removeAppender(targetLogger, mockAppender);
            mockAppender.stop();
        }
    }
"
"    @TestLogging(value = ""org.opensearch.cluster.service:TRACE"", reason = ""to ensure that we log cluster state events on TRACE level"")
    public void testClusterStateUpdateLogging() throws Exception {
        MockLogAppender mockAppender = new MockLogAppender();
        mockAppender.start();
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test1 start"",
                MasterService.class.getCanonicalName(),
                Level.DEBUG,
                ""executing cluster state update for [test1]""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test1 computation"",
                MasterService.class.getCanonicalName(),
                Level.DEBUG,
                ""took [1s] to compute cluster state update for [test1]""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test1 notification"",
                MasterService.class.getCanonicalName(),
                Level.DEBUG,
                ""took [0s] to notify listeners on unchanged cluster state for [test1]""));

        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test2 start"",
                MasterService.class.getCanonicalName(),
                Level.DEBUG,
                ""executing cluster state update for [test2]""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test2 failure"",
                MasterService.class.getCanonicalName(),
                Level.TRACE,
                ""failed to execute cluster state update (on version: [*], uuid: [*]) for [test2]*""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test2 computation"",
                MasterService.class.getCanonicalName(),
                Level.DEBUG,
                ""took [2s] to compute cluster state update for [test2]""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test2 notification"",
                MasterService.class.getCanonicalName(),
                Level.DEBUG,
                ""took [0s] to notify listeners on unchanged cluster state for [test2]""));

        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test3 start"",
                MasterService.class.getCanonicalName(),
                Level.DEBUG,
                ""executing cluster state update for [test3]""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test3 computation"",
                MasterService.class.getCanonicalName(),
                Level.DEBUG,
                ""took [3s] to compute cluster state update for [test3]""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test3 notification"",
                MasterService.class.getCanonicalName(),
                Level.DEBUG,
                ""took [4s] to notify listeners on successful publication of cluster state (version: *, uuid: *) for [test3]""));

        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test4"",
                MasterService.class.getCanonicalName(),
                Level.DEBUG,
                ""executing cluster state update for [test4]""));

        Logger clusterLogger = LogManager.getLogger(MasterService.class);
        Loggers.addAppender(clusterLogger, mockAppender);
        try (MasterService masterService = createMasterService(true)) {
            masterService.submitStateUpdateTask(""test1"", new ClusterStateUpdateTask() {
                @Override
                public ClusterState execute(ClusterState currentState) {
                    relativeTimeInMillis += TimeValue.timeValueSeconds(1).millis();
                    return currentState;
                }
"
"    @TestLogging(value = ""org.opensearch.cluster.service:WARN"", reason = ""to ensure that we log cluster state events on WARN level"")
    public void testLongClusterStateUpdateLogging() throws Exception {
        MockLogAppender mockAppender = new MockLogAppender();
        mockAppender.start();
        mockAppender.addExpectation(
            new MockLogAppender.UnseenEventExpectation(
                ""test1 shouldn't log because it was fast enough"",
                MasterService.class.getCanonicalName(),
                Level.WARN,
                ""*took*test1*""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test2"",
                MasterService.class.getCanonicalName(),
                Level.WARN,
                ""*took [*], which is over [10s], to compute cluster state update for [test2]""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test3"",
                MasterService.class.getCanonicalName(),
                Level.WARN,
                ""*took [*], which is over [10s], to compute cluster state update for [test3]""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test4"",
                MasterService.class.getCanonicalName(),
                Level.WARN,
                ""*took [*], which is over [10s], to compute cluster state update for [test4]""));
        mockAppender.addExpectation(
            new MockLogAppender.UnseenEventExpectation(
                ""test5 should not log despite publishing slowly"",
                MasterService.class.getCanonicalName(),
                Level.WARN,
                ""*took*test5*""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test6 should log due to slow and failing publication"",
                MasterService.class.getCanonicalName(),
                Level.WARN,
                ""took [*] and then failed to publish updated cluster state (version: *, uuid: *) for [test6]:*""));

        Logger clusterLogger = LogManager.getLogger(MasterService.class);
        Loggers.addAppender(clusterLogger, mockAppender);
        try (MasterService masterService = new MasterService(Settings.builder()
            .put(ClusterName.CLUSTER_NAME_SETTING.getKey(), MasterServiceTests.class.getSimpleName())
            .put(Node.NODE_NAME_SETTING.getKey(), ""test_node"")
            .build(), new ClusterSettings(Settings.EMPTY, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS), threadPool)) {

            final DiscoveryNode localNode = new DiscoveryNode(""node1"", buildNewFakeTransportAddress(), emptyMap(),
                emptySet(), Version.CURRENT);
            final ClusterState initialClusterState = ClusterState.builder(new ClusterName(MasterServiceTests.class.getSimpleName()))
                .nodes(DiscoveryNodes.builder().add(localNode).localNodeId(localNode.getId()).masterNodeId(localNode.getId()))
                .blocks(ClusterBlocks.EMPTY_CLUSTER_BLOCK).build();
            final AtomicReference<ClusterState> clusterStateRef = new AtomicReference<>(initialClusterState);
            masterService.setClusterStatePublisher((event, publishListener, ackListener) -> {
                if (event.source().contains(""test5"")) {
                    relativeTimeInMillis += MasterService.MASTER_SERVICE_SLOW_TASK_LOGGING_THRESHOLD_SETTING.get(Settings.EMPTY).millis()
                        + randomLongBetween(1, 1000000);
                }
                if (event.source().contains(""test6"")) {
                    relativeTimeInMillis += MasterService.MASTER_SERVICE_SLOW_TASK_LOGGING_THRESHOLD_SETTING.get(Settings.EMPTY).millis()
                        + randomLongBetween(1, 1000000);
                    throw new OpenSearchException(""simulated error during slow publication which should trigger logging"");
                }
                clusterStateRef.set(event.state());
                publishListener.onResponse(null);
            });
            masterService.setClusterStateSupplier(clusterStateRef::get);
            masterService.start();

            final CountDownLatch latch = new CountDownLatch(6);
            final CountDownLatch processedFirstTask = new CountDownLatch(1);
            masterService.submitStateUpdateTask(""test1"", new ClusterStateUpdateTask() {
                @Override
                public ClusterState execute(ClusterState currentState) {
                    relativeTimeInMillis += randomLongBetween(0L,
                        MasterService.MASTER_SERVICE_SLOW_TASK_LOGGING_THRESHOLD_SETTING.get(Settings.EMPTY).millis());
                    return currentState;
                }
"
"    @TestLogging(value = ""org.opensearch.cluster.service:TRACE"", reason = ""to ensure that we log cluster state events on TRACE level"")
    public void testClusterStateUpdateLogging() throws Exception {
        MockLogAppender mockAppender = new MockLogAppender();
        mockAppender.start();
        mockAppender.addExpectation(
                new MockLogAppender.SeenEventExpectation(
                        ""test1"",
                        ClusterApplierService.class.getCanonicalName(),
                        Level.DEBUG,
                        ""*processing [test1]: took [1s] no change in cluster state""));
        mockAppender.addExpectation(
                new MockLogAppender.SeenEventExpectation(
                        ""test2"",
                        ClusterApplierService.class.getCanonicalName(),
                        Level.TRACE,
                        ""*failed to execute cluster state applier in [2s]*""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test3"",
                ClusterApplierService.class.getCanonicalName(),
                Level.DEBUG,
                ""*processing [test3]: took [0s] no change in cluster state*""));

        Logger clusterLogger = LogManager.getLogger(ClusterApplierService.class);
        Loggers.addAppender(clusterLogger, mockAppender);
        try {
            clusterApplierService.currentTimeOverride = threadPool.relativeTimeInMillis();
            clusterApplierService.runOnApplierThread(""test1"",
                currentState -> clusterApplierService.currentTimeOverride += TimeValue.timeValueSeconds(1).millis(),
                new ClusterApplyListener() {
                    @Override
                    public void onSuccess(String source) { }

"
"    @TestLogging(value = ""org.opensearch.cluster.service:WARN"", reason = ""to ensure that we log cluster state events on WARN level"")
    public void testLongClusterStateUpdateLogging() throws Exception {
        MockLogAppender mockAppender = new MockLogAppender();
        mockAppender.start();
        mockAppender.addExpectation(
                new MockLogAppender.UnseenEventExpectation(
                        ""test1 shouldn't see because setting is too low"",
                        ClusterApplierService.class.getCanonicalName(),
                        Level.WARN,
                        ""*cluster state applier task [test1] took [*] which is above the warn threshold of *""));
        mockAppender.addExpectation(
                new MockLogAppender.SeenEventExpectation(
                        ""test2"",
                        ClusterApplierService.class.getCanonicalName(),
                        Level.WARN,
                        ""*cluster state applier task [test2] took [32s] which is above the warn threshold of [*]: "" +
                            ""[running task [test2]] took [*""));
        mockAppender.addExpectation(
                new MockLogAppender.SeenEventExpectation(
                        ""test4"",
                        ClusterApplierService.class.getCanonicalName(),
                        Level.WARN,
                        ""*cluster state applier task [test3] took [34s] which is above the warn threshold of [*]: "" +
                            ""[running task [test3]] took [*""));

        Logger clusterLogger = LogManager.getLogger(ClusterApplierService.class);
        Loggers.addAppender(clusterLogger, mockAppender);
        try {
            final CountDownLatch latch = new CountDownLatch(4);
            final CountDownLatch processedFirstTask = new CountDownLatch(1);
            clusterApplierService.currentTimeOverride = threadPool.relativeTimeInMillis();
            clusterApplierService.runOnApplierThread(""test1"",
                currentState -> clusterApplierService.currentTimeOverride += TimeValue.timeValueSeconds(1).millis(),
                new ClusterApplyListener() {
                    @Override
                    public void onSuccess(String source) {
                        latch.countDown();
                        processedFirstTask.countDown();
                    }
"
"    @TestLogging(reason=""testing that DEBUG-level logging is reasonable"", value=""org.opensearch.cluster.NodeConnectionsService:DEBUG"")
    public void testDebugLogging() throws IllegalAccessException {
        final DeterministicTaskQueue deterministicTaskQueue
            = new DeterministicTaskQueue(builder().put(NODE_NAME_SETTING.getKey(), ""node"").build(), random());

        MockTransport transport = new MockTransport(deterministicTaskQueue.getThreadPool());
        TestTransportService transportService = new TestTransportService(transport, deterministicTaskQueue.getThreadPool());
        transportService.start();
        transportService.acceptIncomingRequests();

        final NodeConnectionsService service
            = new NodeConnectionsService(Settings.EMPTY, deterministicTaskQueue.getThreadPool(), transportService);
        service.start();

        final List<DiscoveryNode> allNodes = generateNodes();
        final DiscoveryNodes targetNodes = discoveryNodesFromList(randomSubsetOf(allNodes));
        service.connectToNodes(targetNodes, () -> {});
        deterministicTaskQueue.runAllRunnableTasks();

        // periodic reconnections to unexpectedly-disconnected nodes are logged
        final Set<DiscoveryNode> disconnectedNodes = new HashSet<>(randomSubsetOf(allNodes));
        for (DiscoveryNode disconnectedNode : disconnectedNodes) {
            transportService.disconnectFromNode(disconnectedNode);
        }
        MockLogAppender appender = new MockLogAppender();
        try {
            appender.start();
            Loggers.addAppender(LogManager.getLogger(""org.opensearch.cluster.NodeConnectionsService""), appender);
            for (DiscoveryNode targetNode : targetNodes) {
                if (disconnectedNodes.contains(targetNode)) {
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""connecting to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connecting to "" + targetNode));
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""connected to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connected to "" + targetNode));
                } else {
                    appender.addExpectation(new MockLogAppender.UnseenEventExpectation(""connecting to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connecting to "" + targetNode));
                    appender.addExpectation(new MockLogAppender.UnseenEventExpectation(""connected to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connected to "" + targetNode));
                }
            }

            runTasksUntil(deterministicTaskQueue, CLUSTER_NODE_RECONNECT_INTERVAL_SETTING.get(Settings.EMPTY).millis());
            appender.assertAllExpectationsMatched();
        } finally {
            Loggers.removeAppender(LogManager.getLogger(""org.opensearch.cluster.NodeConnectionsService""), appender);
            appender.stop();
        }        for (DiscoveryNode disconnectedNode : disconnectedNodes) {
            transportService.disconnectFromNode(disconnectedNode);
        }

        // changes to the expected set of nodes are logged, including reconnections to any unexpectedly-disconnected nodes
        final DiscoveryNodes newTargetNodes = discoveryNodesFromList(randomSubsetOf(allNodes));
        for (DiscoveryNode disconnectedNode : disconnectedNodes) {
            transportService.disconnectFromNode(disconnectedNode);
        }
        appender = new MockLogAppender();
        try {
            appender.start();
            Loggers.addAppender(LogManager.getLogger(""org.opensearch.cluster.NodeConnectionsService""), appender);
            for (DiscoveryNode targetNode : targetNodes) {
                if (disconnectedNodes.contains(targetNode) && newTargetNodes.get(targetNode.getId()) != null) {
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""connecting to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connecting to "" + targetNode));
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""connected to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connected to "" + targetNode));
                } else {
                    appender.addExpectation(new MockLogAppender.UnseenEventExpectation(""connecting to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connecting to "" + targetNode));
                    appender.addExpectation(new MockLogAppender.UnseenEventExpectation(""connected to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connected to "" + targetNode));
                }
                if (newTargetNodes.get(targetNode.getId()) == null) {
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""disconnected from "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""disconnected from "" + targetNode));
                }
            }
            for (DiscoveryNode targetNode : newTargetNodes) {
                appender.addExpectation(new MockLogAppender.UnseenEventExpectation(""disconnected from "" + targetNode,
                    ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                    ""disconnected from "" + targetNode));
                if (targetNodes.get(targetNode.getId()) == null) {
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""connecting to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connecting to "" + targetNode));
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""connected to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connected to "" + targetNode));
                }
            }

            service.disconnectFromNodesExcept(newTargetNodes);
            service.connectToNodes(newTargetNodes, () -> {});
            deterministicTaskQueue.runAllRunnableTasks();
            appender.assertAllExpectationsMatched();
        } finally {
            Loggers.removeAppender(LogManager.getLogger(""org.opensearch.cluster.NodeConnectionsService""), appender);
            appender.stop();
        }
    }
"
"    @TestLogging(value=""org.opensearch.cluster.routing.allocation.DiskThresholdMonitor:INFO"", reason=""testing INFO/WARN logging"")
    public void testDiskMonitorLogging() throws IllegalAccessException {
        final ClusterState clusterState = ClusterState.builder(ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY))
            .nodes(DiscoveryNodes.builder().add(newNode(""node1""))).build();
        final AtomicReference<ClusterState> clusterStateRef = new AtomicReference<>(clusterState);
        final AtomicBoolean advanceTime = new AtomicBoolean(randomBoolean());

        final LongSupplier timeSupplier = new LongSupplier() {
            long time;

            @Override
            public long getAsLong() {
                if (advanceTime.get()) {
                    time += DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_REROUTE_INTERVAL_SETTING.get(Settings.EMPTY).getMillis() + 1;
                }
                logger.info(""time: [{}]"", time);
                return time;
            }
"
"    @TestLogging(value = ""org.opensearch.gateway:WARN"", reason = ""to ensure that we log gateway events on WARN level"")
    public void testSlowLogging() throws WriteStateException, IllegalAccessException {
        final long slowWriteLoggingThresholdMillis;
        final Settings settings;
        if (randomBoolean()) {
            slowWriteLoggingThresholdMillis = PersistedClusterStateService.SLOW_WRITE_LOGGING_THRESHOLD.get(Settings.EMPTY).millis();
            settings = Settings.EMPTY;
        } else {
            slowWriteLoggingThresholdMillis = randomLongBetween(2, 100000);
            settings = Settings.builder()
                .put(PersistedClusterStateService.SLOW_WRITE_LOGGING_THRESHOLD.getKey(), slowWriteLoggingThresholdMillis + ""ms"")
                .build();
        }

        final DiscoveryNode localNode = newNode(""node"");
        final ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
            .nodes(DiscoveryNodes.builder().add(localNode).localNodeId(localNode.getId())).build();

        final long startTimeMillis = randomLongBetween(0L, Long.MAX_VALUE - slowWriteLoggingThresholdMillis * 10);
        final AtomicLong currentTime = new AtomicLong(startTimeMillis);
        final AtomicLong writeDurationMillis = new AtomicLong(slowWriteLoggingThresholdMillis);

        final ClusterSettings clusterSettings = new ClusterSettings(settings, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);
        final IncrementalClusterStateWriter incrementalClusterStateWriter
            = new IncrementalClusterStateWriter(settings, clusterSettings, mock(MetaStateService.class),
            new Manifest(randomNonNegativeLong(), randomNonNegativeLong(), randomNonNegativeLong(), Collections.emptyMap()),
            clusterState, () -> currentTime.getAndAdd(writeDurationMillis.get()));

        assertExpectedLogs(clusterState, incrementalClusterStateWriter, new MockLogAppender.SeenEventExpectation(
            ""should see warning at threshold"",
            IncrementalClusterStateWriter.class.getCanonicalName(),
            Level.WARN,
            ""writing cluster state took [*] which is above the warn threshold of [*]; "" +
                ""wrote metadata for [0] indices and skipped [0] unchanged indices""));

        writeDurationMillis.set(randomLongBetween(slowWriteLoggingThresholdMillis, slowWriteLoggingThresholdMillis * 2));
        assertExpectedLogs(clusterState, incrementalClusterStateWriter, new MockLogAppender.SeenEventExpectation(
            ""should see warning above threshold"",
            IncrementalClusterStateWriter.class.getCanonicalName(),
            Level.WARN,
            ""writing cluster state took [*] which is above the warn threshold of [*]; "" +
                ""wrote metadata for [0] indices and skipped [0] unchanged indices""));

        writeDurationMillis.set(randomLongBetween(1, slowWriteLoggingThresholdMillis - 1));
        assertExpectedLogs(clusterState, incrementalClusterStateWriter, new MockLogAppender.UnseenEventExpectation(
            ""should not see warning below threshold"",
            IncrementalClusterStateWriter.class.getCanonicalName(),
            Level.WARN,
            ""*""));

        clusterSettings.applySettings(Settings.builder()
            .put(PersistedClusterStateService.SLOW_WRITE_LOGGING_THRESHOLD.getKey(), writeDurationMillis.get() + ""ms"")
            .build());
        assertExpectedLogs(clusterState, incrementalClusterStateWriter, new MockLogAppender.SeenEventExpectation(
            ""should see warning at reduced threshold"",
            IncrementalClusterStateWriter.class.getCanonicalName(),
            Level.WARN,
            ""writing cluster state took [*] which is above the warn threshold of [*]; "" +
                ""wrote metadata for [0] indices and skipped [0] unchanged indices""));

        assertThat(currentTime.get(), lessThan(startTimeMillis + 10 * slowWriteLoggingThresholdMillis)); // ensure no overflow
    }
"
"    @TestLogging(value = ""org.opensearch.gateway:WARN"", reason = ""to ensure that we log gateway events on WARN level"")
    public void testSlowLogging() throws IOException, IllegalAccessException {
        final long slowWriteLoggingThresholdMillis;
        final Settings settings;
        if (randomBoolean()) {
            slowWriteLoggingThresholdMillis = PersistedClusterStateService.SLOW_WRITE_LOGGING_THRESHOLD.get(Settings.EMPTY).millis();
            settings = Settings.EMPTY;
        } else {
            slowWriteLoggingThresholdMillis = randomLongBetween(2, 100000);
            settings = Settings.builder()
                .put(PersistedClusterStateService.SLOW_WRITE_LOGGING_THRESHOLD.getKey(), slowWriteLoggingThresholdMillis + ""ms"")
                .build();
        }

        final DiscoveryNode localNode = new DiscoveryNode(""node"", buildNewFakeTransportAddress(), Version.CURRENT);
        final ClusterState clusterState = ClusterState.builder(ClusterName.DEFAULT)
            .nodes(DiscoveryNodes.builder().add(localNode).localNodeId(localNode.getId())).build();

        final long startTimeMillis = randomLongBetween(0L, Long.MAX_VALUE - slowWriteLoggingThresholdMillis * 10);
        final AtomicLong currentTime = new AtomicLong(startTimeMillis);
        final AtomicLong writeDurationMillis = new AtomicLong(slowWriteLoggingThresholdMillis);

        final ClusterSettings clusterSettings = new ClusterSettings(settings, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);
        try (NodeEnvironment nodeEnvironment = newNodeEnvironment(createDataPaths())) {
            PersistedClusterStateService persistedClusterStateService = new PersistedClusterStateService(nodeEnvironment,
                    xContentRegistry(), getBigArrays(), clusterSettings, () -> currentTime.getAndAdd(writeDurationMillis.get()));

            try (Writer writer = persistedClusterStateService.createWriter()) {
                assertExpectedLogs(1L, null, clusterState, writer, new MockLogAppender.SeenEventExpectation(
                    ""should see warning at threshold"",
                    PersistedClusterStateService.class.getCanonicalName(),
                    Level.WARN,
                    ""writing cluster state took [*] which is above the warn threshold of [*]; "" +
                        ""wrote full state with [0] indices""));

                writeDurationMillis.set(randomLongBetween(slowWriteLoggingThresholdMillis, slowWriteLoggingThresholdMillis * 2));
                assertExpectedLogs(1L, null, clusterState, writer, new MockLogAppender.SeenEventExpectation(
                    ""should see warning above threshold"",
                    PersistedClusterStateService.class.getCanonicalName(),
                    Level.WARN,
                    ""writing cluster state took [*] which is above the warn threshold of [*]; "" +
                        ""wrote full state with [0] indices""));

                writeDurationMillis.set(randomLongBetween(1, slowWriteLoggingThresholdMillis - 1));
                assertExpectedLogs(1L, null, clusterState, writer, new MockLogAppender.UnseenEventExpectation(
                    ""should not see warning below threshold"",
                    PersistedClusterStateService.class.getCanonicalName(),
                    Level.WARN,
                    ""*""));

                clusterSettings.applySettings(Settings.builder()
                    .put(PersistedClusterStateService.SLOW_WRITE_LOGGING_THRESHOLD.getKey(), writeDurationMillis.get() + ""ms"")
                    .build());
                assertExpectedLogs(1L, null, clusterState, writer, new MockLogAppender.SeenEventExpectation(
                    ""should see warning at reduced threshold"",
                    PersistedClusterStateService.class.getCanonicalName(),
                    Level.WARN,
                    ""writing cluster state took [*] which is above the warn threshold of [*]; "" +
                        ""wrote full state with [0] indices""));

                final ClusterState newClusterState = ClusterState.builder(clusterState)
                    .metadata(Metadata.builder(clusterState.metadata())
                        .version(clusterState.version())
                        .put(IndexMetadata.builder(""test"")
                            .settings(Settings.builder()
                                .put(IndexMetadata.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)
                                .put(IndexMetadata.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 0)
                                .put(IndexMetadata.SETTING_INDEX_VERSION_CREATED.getKey(), Version.CURRENT)
                                .put(IndexMetadata.SETTING_INDEX_UUID, ""test-uuid""))))
                    .incrementVersion().build();

                assertExpectedLogs(1L, clusterState, newClusterState, writer, new MockLogAppender.SeenEventExpectation(
                    ""should see warning at threshold"",
                    PersistedClusterStateService.class.getCanonicalName(),
                    Level.WARN,
                    ""writing cluster state took [*] which is above the warn threshold of [*]; "" +
                        ""wrote global metadata [false] and metadata for [1] indices and skipped [0] unchanged indices""));

                writeDurationMillis.set(randomLongBetween(0, writeDurationMillis.get() - 1));
                assertExpectedLogs(1L, clusterState, newClusterState, writer, new MockLogAppender.UnseenEventExpectation(
                    ""should not see warning below threshold"",
                    PersistedClusterStateService.class.getCanonicalName(),
                    Level.WARN,
                    ""*""));

                assertThat(currentTime.get(), lessThan(startTimeMillis + 14 * slowWriteLoggingThresholdMillis)); // ensure no overflow
            }
        }
    }
"
"    @TestLogging(value=""org.opensearch.common.settings.IndexScopedSettings:INFO"",
    public void testLogSettingUpdate() throws Exception {
        final IndexMetadata metadata = newIndexMeta(""index1"",
            Settings.builder().put(IndexSettings.INDEX_REFRESH_INTERVAL_SETTING.getKey(), ""20s"").build());
        final IndexSettings settings = new IndexSettings(metadata, Settings.EMPTY);

        final MockLogAppender mockLogAppender = new MockLogAppender();
        mockLogAppender.addExpectation(new MockLogAppender.SeenEventExpectation(
            ""message"",
            ""org.opensearch.common.settings.IndexScopedSettings"",
            Level.INFO,
            ""updating [index.refresh_interval] from [20s] to [10s]"") {
            @Override
            public boolean innerMatch(LogEvent event) {
                return event.getMarker().getName().equals("" [index1]"");
            }
"
"    @TestLogging(
    public void testTracerLog() throws Exception {
        final String includeSettings;
        final String excludeSettings;
        if (randomBoolean()) {
            includeSettings = randomBoolean() ? ""*"" : """";
        } else {
            includeSettings = ""/internal/test"";
        }
        excludeSettings = ""/internal/testNotSeen"";

        final ClusterSettings clusterSettings = new ClusterSettings(Settings.EMPTY, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);
        try (AbstractHttpServerTransport transport =
                 new AbstractHttpServerTransport(Settings.EMPTY, networkService, bigArrays, threadPool, xContentRegistry(),
                     new HttpServerTransport.Dispatcher() {
                         @Override
                         public void dispatchRequest(RestRequest request, RestChannel channel, ThreadContext threadContext) {
                             channel.sendResponse(emptyResponse(RestStatus.OK));
                         }
"
"    @TestLogging(reason = ""testing logging"", value = ""org.opensearch.transport.TcpTransport:DEBUG"")
    public void testExceptionHandling() throws IllegalAccessException {
        testExceptionHandling(false, new OpenSearchException(""simulated""), true,
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.ERROR, ""*""),
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.WARN, ""*""),
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.INFO, ""*""),
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.DEBUG, ""*""));
        testExceptionHandling(new OpenSearchException(""simulated""),
            new MockLogAppender.SeenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"",
                Level.WARN, ""exception caught on transport layer [*], closing connection""));
        testExceptionHandling(new ClosedChannelException(),
            new MockLogAppender.SeenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"",
                Level.DEBUG, ""close connection exception caught on transport layer [*], disconnecting from relevant node""));
        testExceptionHandling(new OpenSearchException(""Connection reset""),
            new MockLogAppender.SeenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"",
                Level.DEBUG, ""close connection exception caught on transport layer [*], disconnecting from relevant node""));
        testExceptionHandling(new BindException(),
            new MockLogAppender.SeenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"",
                Level.DEBUG, ""bind exception caught on transport layer [*]""));
        testExceptionHandling(new CancelledKeyException(),
            new MockLogAppender.SeenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"",
                Level.DEBUG, ""cancelled key exception caught on transport layer [*], disconnecting from relevant node""));
        testExceptionHandling(true, new TcpTransport.HttpRequestOnTransportException(""test""), false,
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.ERROR, ""*""),
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.WARN, ""*""),
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.INFO, ""*""),
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.DEBUG, ""*""));
        testExceptionHandling(new StreamCorruptedException(""simulated""),
            new MockLogAppender.SeenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"",
                Level.WARN, ""simulated, [*], closing connection""));
    }
"
"@TestLogging(value = ""org.opensearch.transport.TransportLogger:trace"", reason = ""to ensure we log network events on TRACE level"")
    public void setUp() throws Exception {
        super.setUp();
        appender = new MockLogAppender();
        Loggers.addAppender(LogManager.getLogger(TransportLogger.class), appender);
        appender.start();
    }
"
"    @TestLogging(
    public void testEnsureWeReconnect() throws Exception {
        Settings remoteSettings = Settings.builder().put(ClusterName.CLUSTER_NAME_SETTING.getKey(), ""foo_bar_cluster"").build();
        try (MockTransportService remoteTransport = startTransport(""remote_node"", Collections.emptyList(), Version.CURRENT, threadPool,
            remoteSettings)) {
            DiscoveryNode remoteNode = remoteTransport.getLocalDiscoNode();
            Settings localSettings = Settings.builder()
                .put(onlyRole(DiscoveryNodeRole.REMOTE_CLUSTER_CLIENT_ROLE))
                .put(""cluster.remote.test.seeds"",
                    remoteNode.getAddress().getAddress() + "":"" + remoteNode.getAddress().getPort()).build();
            try (MockTransportService service = MockTransportService.createNewService(localSettings, Version.CURRENT, threadPool, null)) {
                service.start();
                // this test is not perfect since we might reconnect concurrently but it will fail most of the time if we don't have
                // the right calls in place in the RemoteAwareClient
                service.acceptIncomingRequests();
                RemoteClusterService remoteClusterService = service.getRemoteClusterService();
                assertBusy(() -> assertTrue(remoteClusterService.isRemoteNodeConnected(""test"", remoteNode)));
                for (int i = 0; i < 10; i++) {
                    RemoteClusterConnection remoteClusterConnection = remoteClusterService.getRemoteClusterConnection(""test"");
                    assertBusy(remoteClusterConnection::assertNoRunningConnections);
                    ConnectionManager connectionManager = remoteClusterConnection.getConnectionManager();
                    Transport.Connection connection = connectionManager.getConnection(remoteNode);
                    PlainActionFuture<Void> closeFuture = PlainActionFuture.newFuture();
                    connection.addCloseListener(closeFuture);
                    connectionManager.disconnectFromNode(remoteNode);
                    closeFuture.get();

                    Client client = remoteClusterService.getRemoteClusterClient(threadPool, ""test"");
                    ClusterStateResponse clusterStateResponse = client.admin().cluster().prepareState().execute().get();
                    assertNotNull(clusterStateResponse);
                    assertEquals(""foo_bar_cluster"", clusterStateResponse.getState().getClusterName().value());
                    assertTrue(remoteClusterConnection.isNodeConnected(remoteNode));
                }
            }
        }
    }
"
"    @TestLogging(value = ""org.opensearch.monitor.fs:WARN"", reason = ""to ensure that we log on hung IO at WARN level"")
    public void testLoggingOnHungIO() throws Exception {
        long slowLogThreshold = randomLongBetween(100, 200);
        final Settings settings = Settings.builder().put(FsHealthService.SLOW_PATH_LOGGING_THRESHOLD_SETTING.getKey(),
            slowLogThreshold + ""ms"").build();
        FileSystem fileSystem = PathUtils.getDefaultFileSystem();
        TestThreadPool testThreadPool = new TestThreadPool(getClass().getName(), settings);
        FileSystemFsyncHungProvider disruptFileSystemProvider = new FileSystemFsyncHungProvider(fileSystem,
            randomLongBetween(slowLogThreshold + 1 , 400), testThreadPool);
        fileSystem = disruptFileSystemProvider.getFileSystem(null);
        PathUtilsForTesting.installMock(fileSystem);
        final ClusterSettings clusterSettings = new ClusterSettings(Settings.EMPTY, ClusterSettings.BUILT_IN_CLUSTER_SETTINGS);

        MockLogAppender mockAppender = new MockLogAppender();
        mockAppender.start();

        Logger logger = LogManager.getLogger(FsHealthService.class);
        Loggers.addAppender(logger, mockAppender);
        try (NodeEnvironment env = newNodeEnvironment()) {
            FsHealthService fsHealthService = new FsHealthService(settings, clusterSettings, testThreadPool, env);
            int counter = 0;
            for(Path path : env.nodeDataPaths()){
                mockAppender.addExpectation(
                    new MockLogAppender.SeenEventExpectation(
                        ""test"" + ++counter,
                        FsHealthService.class.getCanonicalName(),
                        Level.WARN,
                        ""health check of ["" + path + ""] took [*ms] which is above the warn threshold*""));
            }

            //disrupt file system
            disruptFileSystemProvider.injectIODelay.set(true);
            fsHealthService.new FsHealthMonitor().run();
            assertEquals(env.nodeDataPaths().length, disruptFileSystemProvider.getInjectedPathCount());
            assertBusy(mockAppender::assertAllExpectationsMatched);
        } finally {
            Loggers.removeAppender(logger, mockAppender);
            mockAppender.stop();
            PathUtilsForTesting.teardown();
            ThreadPool.terminate(testThreadPool, 500, TimeUnit.MILLISECONDS);
        }
    }
"
"    @Test
            public void execute(Map<String, List<String>> parameters, PrintWriter output) {
                output.println(""Vacuum cleaning"");
            }
"
"    @Test
            public void execute(Map<String, List<String>> parameters, PrintWriter output) throws Exception {
                output.println(""Vacuum cleaning"");
            }
"
"    @Test
            public void execute(Map<String, List<String>> parameters, PrintWriter output) {
                throw new RuntimeException(""The engine has died"");
            }
"
"    @Test
        public boolean isFinished() {
            return false;
        }
"
"    @Test
            public FileAppender<ILoggingEvent> buildAppender(LoggerContext context) {
                return super.buildAppender(context);
            }
"
"    @Test
        public InputStream open(String s) throws IOException {
            // used to test that the stream is properly closed
            lastStream = new BufferedInputStream(new ByteArrayInputStream(s.getBytes(StandardCharsets.UTF_8)));
            return lastStream;
        }
"
"    @ParameterizedTest
    public void shouldDiscoverAllFields(String name, boolean isPrimitive,
                                        boolean isCollectionOrArrayType,
"
"    @ParameterizedTest
    public void isCollectionOfStringsShouldWork(String name, boolean isCollectionOfStrings) {
        final ConfigurationMetadata metadata = new ConfigurationMetadata(
                Jackson.newObjectMapper(), ExampleConfiguration.class);

        assertThat(metadata.isCollectionOfStrings(name)).isEqualTo(isCollectionOfStrings);
    }
"
"    @Test
        public CustomProperty deserialize(JsonParser parser, DeserializationContext context) throws IOException {
            assertThat(parser.getCodec()).isNotNull();

            TreeNode treeNode = parser.readValueAsTree();
            final TextNode custom = (TextNode) treeNode.path(""custom"");
            return new CustomProperty(custom.asText());
        }
"
"    @BeforeEach
    public void throwsAnExceptionOnMalformedFiles() {
        assertThatThrownBy(super::throwsAnExceptionOnMalformedFiles)
                .hasMessageContaining(""* Malformed JSON at line:"");
    }
"
"    @Test
        public void validateCorrect(ViolationCollector col) {
        }
"
"    @BeforeEach
    public void clearAllLoggers() {
        //this must be a clear all because the validation runs in other threads
        TestLoggerFactory.clearAll();
    }
"
"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();
    }
"
"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();
    }
"
"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();
    }
"
"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();
    }
"
"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();
    }
"
"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();
    }
"
"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();
    }
"
"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();
    }
"
"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();
    }
"
"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();
    }
"
"    @Test
        public void filter(ContainerRequestContext requestContext) throws IOException {
            requestContext.setSecurityContext(new SecurityContext() {
                @Override
                public Principal getUserPrincipal() {
                    return new NullPrincipal();
                }
"
"    @Test
        public void filter(ContainerRequestContext requestContext) throws IOException {
            authenticate(requestContext, ""some-password"", ""SOME_SCHEME"");
        }
"
"    @Test
    public void hasAWorkingEqualsMethod() {
        assertThat(credentials)
            .isEqualTo(credentials)
            .isEqualTo(new BasicCredentials(""u"", ""p""))
            .isNotEqualTo(null)
            .isNotEqualTo(""string"")
            .isNotEqualTo(new BasicCredentials(""u1"", ""p""))
            .isNotEqualTo(new BasicCredentials(""u"", ""p1""));
    }
"
"    @Test
    public void runWithoutConfigFile() {
        Map<String, String> response = RULE.client().target(""http://localhost:"" + RULE.getLocalPort() + ""/test"")
            .request()
            .get(new GenericType<Map<String, String>>() {
            });
        assertThat(response).containsOnly(entry(""color"", ""orange""));
    }
"
"    @Test
    public void runWithExplicitConfig() {
        Map<String, String> response = RULE.client().target(""http://localhost:"" + RULE.getLocalPort() + ""/test"")
            .request()
            .get(new GenericType<Map<String, String>>() {
            });
        assertThat(response).containsOnly(entry(""message"", ""stuff!""));
    }
"
"    @Test
    public void ruleCreatedSessionFactory() {
        final SessionFactory sessionFactory = daoTestRule.getSessionFactory();

        assertThat(sessionFactory).isNotNull();
    }
"
"    @Test
    public void test2() throws Exception {
        dropwizardAppRule.before();
        assertThat(System.getProperty(""app-rule-reset.message"")).isEqualTo(""A new way to say Hooray!"");
        assertThat(System.getProperty(""app-rule-reset.extra"")).isNull();
        dropwizardAppRule.after();

        System.setProperty(""app-rule-reset.extra"", ""Some extra system property"");
        dropwizardAppRule.before();
        assertThat(System.getProperty(""app-rule-reset.message"")).isEqualTo(""A new way to say Hooray!"");
        assertThat(System.getProperty(""app-rule-reset.extra"")).isEqualTo(""Some extra system property"");
        dropwizardAppRule.after();

        assertThat(System.getProperty(""app-rule-reset.message"")).isNull();
        assertThat(System.getProperty(""app-rule-reset.extra"")).isEqualTo(""Some extra system property"");
        System.clearProperty(""app-rule-reset.extra"");
    }
"
"    @Test
    public void ruleCreatedSessionFactory() {
        final SessionFactory sessionFactory = daoTestRule.getSessionFactory();

        assertThat(sessionFactory).isNotNull();
    }
"
"    @Test
    public void ruleCanOpenTransaction() {
        final Long id = daoTestRule.inTransaction(() -> persist(new TestEntity(""description"")).getId());

        assertThat(id).isNotNull();
    }
"
"    @Test
    public void ruleCanRoundtrip() {
        final Long id = daoTestRule.inTransaction(() -> persist(new TestEntity(""description"")).getId());

        final TestEntity testEntity = get(id);

        assertThat(testEntity).isNotNull();
        assertThat(testEntity.getDescription()).isEqualTo(""description"");
    }
"
"    @Test
    public void transactionThrowsExceptionAsExpected() {
        assertThatExceptionOfType(ConstraintViolationException.class).isThrownBy(()->
            daoTestRule.inTransaction(() -> persist(new TestEntity(null))));
    }
"
"    @Test
    public void rollsBackTransaction() {
        // given a successfully persisted entity
        final TestEntity testEntity = new TestEntity(""description"");
        daoTestRule.inTransaction(() -> persist(testEntity));

        // when we prepare an update of that entity
        testEntity.setDescription(""newDescription"");
        // ... but cause a constraint violation during the actual update
        assertThatExceptionOfType(ConstraintViolationException.class)
            .isThrownBy(() -> daoTestRule.inTransaction(() -> {
                persist(testEntity);
                persist(new TestEntity(null));
            }));
        // ... the entity has the original value
        assertThat(get(testEntity.getId()).getDescription()).isEqualTo(""description"");
    }
"
"    @Test
    public void canGetExpectedResourceOverHttp() {
        final String content = ClientBuilder.newClient().target(
            ""http://localhost:"" + RULE.getLocalPort() + ""/test"").request().get(String.class);

        assertThat(content).isEqualTo(""Yes, it's here"");
    }
"
"    @Test
    public void returnsConfiguration() {
        final TestConfiguration config = RULE.getConfiguration();
        assertThat(config.getMessage()).isEqualTo(""Yes, it's here"");
    }
"
"    @Test
    public void returnsApplication() {
        final DropwizardTestApplication application = RULE.getApplication();
        assertThat(application).isNotNull();
    }
"
"    @Test
    public void returnsEnvironment() {
        final Environment environment = RULE.getEnvironment();
        assertThat(environment.getName()).isEqualTo(""DropwizardTestApplication"");
    }
"
"    @Test
    public void canPerformAdminTask() {
        final String response
            = RULE.client().target(""http://localhost:""
            + RULE.getAdminPort() + ""/tasks/hello?name=test_user"")
            .request()
            .post(Entity.entity("""", MediaType.TEXT_PLAIN), String.class);

        assertThat(response).isEqualTo(""Hello has been said to test_user"");
    }
"
"    @Test
    public void canPerformAdminTaskWithPostBody() {
        final String response
            = RULE.client().target(""http://localhost:""
            + RULE.getAdminPort() + ""/tasks/echo"")
            .request()
            .post(Entity.entity(""Custom message"", MediaType.TEXT_PLAIN), String.class);

        assertThat(response).isEqualTo(""Custom message"");
    }
"
"    @Test
    public void clientUsesJacksonMapperFromEnvironment() {
        assertThat(RULE.client().target(""http://localhost:"" + RULE.getLocalPort() + ""/message"")
            .request()
            .get(DropwizardTestApplication.MessageView.class).getMessage())
            .contains(""Yes, it's here"");
    }
"
"    @Test
    public void clientSupportsPatchMethod() {
        assertThat(RULE.client().target(""http://localhost:"" + RULE.getLocalPort() + ""/echoPatch"")
            .request()
            .method(""PATCH"", Entity.text(""Patch is working""), String.class))
            .contains(""Patch is working"");
    }
"
"    @Test
    public void explicitConfigCreatesSessionFactory() {
        // it yields a valid SessionFactory instance
        final SessionFactory sessionFactory = database.getSessionFactory();
        assertThat(sessionFactory).isNotNull();
        assertThat(sessionFactory.getProperties())
                .containsEntry(AvailableSettings.FORMAT_SQL, ""true"")
                .containsEntry(""foobar"", ""baz"");

        final Session currentSession = sessionFactory.getCurrentSession();

        // an instance of an entity contained in the package can be saved
        currentSession.saveOrUpdate(new TestEntity(""foo""));
    }
"
"    @Test
    public void shouldGetStringBodyFromDropWizard() throws IOException {
        final URL url = new URL(RULE_WITH_INSTANCE.baseUri() + ""/test"");
        assertThat(""foo"").isEqualTo(Resources.toString(url, StandardCharsets.UTF_8));
    }
"
"    @Test
    public void shouldGetDefaultStringBodyFromDropWizard() throws IOException {
        final URL url = new URL(RULE_WITH_CLASS.baseUri() + ""/test"");
        assertThat(Resources.toString(url, StandardCharsets.UTF_8)).isEqualTo(TestResource.DEFAULT_MESSAGE);
    }
"
"    @Test
    public void supportsConfigAttributeOverrides() {
        final String content = RULE.client().target(""http://localhost:"" + RULE.getLocalPort() + ""/test"")
            .request().get(String.class);

        assertThat(content).isEqualTo(""A new way to say Hooray!"");
    }
"
"    @Test
    public void supportsSuppliedConfigAttributeOverrides() throws Exception {
        assertThat(System.getProperty(""app-rule.extra"")).isEqualTo(""supplied"");
        assertThat(System.getProperty(""dw.extra"")).isEqualTo(""supplied again"");
    }
"
"    @Test
    public void testReentrantRuleStartsApplicationOnlyOnce() throws Throwable {
        @SuppressWarnings(""deprecation"")
        DropwizardAppRule<TestConfiguration> dropwizardAppRule = new DropwizardAppRule<>(testSupport);

        RuleChain.outerRule(dropwizardAppRule)
            .around(dropwizardAppRule) // recursive
            .apply(statement, description)
            .evaluate();

        InOrder inOrder = inOrder(testSupport, statement, description);
        inOrder.verify(testSupport, times(1)).before();
        inOrder.verify(statement).evaluate();
        inOrder.verify(testSupport, times(1)).after();
        inOrder.verifyNoMoreInteractions();
    }
"
"    @Test
        public void initialize(Bootstrap<TestConfiguration> bootstrap) {
            bootstrap.setConfigurationFactoryFactory(FailingConfigurationFactory::new);
        }
"
"    @Test
    public void testResource() {
        assertThat(resourceTestRule.target(""test"").request()
                .get(String.class))
                .isEqualTo(""Default message"");
    }
"
"    @Test
    public void testResource() {
        assertThat(resourceTestRule.target(""test"").request()
                .get(String.class))
                .isEqualTo(""test"");
    }
"
"    @Test
    public void testExceptionMapper() {
        final Response resp = resourceTestRule.target(""test"").request()
                .post(Entity.json(""""));
        assertThat(resp.getStatus()).isEqualTo(500);
        assertThat(resp.readEntity(String.class)).isEqualTo(""Can't touch this"");
    }
"
"    @Test
    public void testClientSupportsPatchMethod() {
        final String resp = resourceTestRule.target(""test"")
            .request()
            .method(""PATCH"", Entity.text(""Patch is working""), String.class);
        assertThat(resp).isEqualTo(""Patch is working"");
    }
"
"    @Test
    public void testDefaultConstraintViolation() {
        assertThat(RESOURCES.target(""/person/blah/index"")
            .queryParam(""ind"", -1).request()
            .get().readEntity(String.class))
            .isEqualTo(""Invalid data"");
    }
"
"    @Test
    public void testDefaultJsonProcessingMapper() {
        assertThat(RESOURCES.target(""/person/blah/runtime-exception"")
            .request()
            .post(Entity.json(""{ \""he: \""ho\""}""))
            .readEntity(String.class))
            .startsWith(""Something went wrong: Unexpected character"");
    }
"
"    @Test
    public void testDefaultExceptionMapper() {
        assertThat(RESOURCES.target(""/person/blah/runtime-exception"")
            .request()
            .post(Entity.json(""{}""))
            .readEntity(String.class))
            .isEqualTo(""Something went wrong: I'm an exception!"");
    }
"
"    @Test
    public void testDefaultEofExceptionMapper() {
        assertThat(RESOURCES.target(""/person/blah/eof-exception"")
            .request()
            .get().readEntity(String.class))
            .isEqualTo(""Something went wrong: I'm an eof exception!"");
    }
"
"    @Test
    public void testGetPerson() {
        assertThat(resourceTestRule.target(""/person/blah"").request()
                .get(Person.class))
                .isEqualTo(person);
        verify(peopleStore).fetchPerson(""blah"");
    }
"
"    @Test
    public void testGetImmutableListOfPersons() {
        assertThat(resourceTestRule.target(""/person/blah/list"").request()
                .get(new GenericType<List<Person>>() {
                })).isEqualTo(Collections.singletonList(person));
    }
"
"    @Test
    public void testGetPersonWithQueryParam() {
        // Test to ensure that the dropwizard validator is registered so that
        // it can validate the ""ind"" IntParam.
        assertThat(resourceTestRule.target(""/person/blah/index"")
                .queryParam(""ind"", 0).request()
                .get(Person.class))
                .isEqualTo(person);
        verify(peopleStore).fetchPerson(""blah"");
    }
"
"    @Test
    public void testDefaultConstraintViolation() {
        assertThat(resourceTestRule.target(""/person/blah/index"")
                .queryParam(""ind"", -1).request()
                .get().readEntity(String.class))
                .isEqualTo(""{\""errors\"":[\""query param ind must be greater than or equal to 0\""]}"");
    }
"
"    @Test
    public void testDefaultJsonProcessingMapper() {
        assertThat(resourceTestRule.target(""/person/blah/runtime-exception"")
                .request()
                .post(Entity.json(""{ \""he: \""ho\""}""))
                .readEntity(String.class))
                .isEqualTo(""{\""code\"":400,\""message\"":\""Unable to process JSON\""}"");
    }
"
"    @Test
    public void testDefaultEofExceptionMapper() {
        assertThat(resourceTestRule.target(""/person/blah/eof-exception"")
                .request()
                .get().getStatus())
                .isEqualTo(Response.Status.BAD_REQUEST.getStatusCode());
    }
"
"    @Test
    public void testValidationGroupsException() {
        final Response resp = resourceTestRule.target(""/person/blah/validation-groups-exception"")
                .request()
                .post(Entity.json(""{}""));
        assertThat(resp.getStatus()).isEqualTo(Response.Status.INTERNAL_SERVER_ERROR.getStatusCode());
        assertThat(resp.readEntity(String.class))
                .isEqualTo(""{\""code\"":500,\""message\"":\""Parameters must have the same"" +
                        "" validation groups in validationGroupsException\""}"");
    }
"
"    @Test
    public void testCustomClientConfiguration() {
        assertThat(resourceTestRule.client().getConfiguration().isRegistered(DummyExceptionMapper.class)).isTrue();
    }
"
"    @Test
    public void testDefaultVaryHeader() {
        final Response clientResponse = RULE.client().target(
            ""http://localhost:"" + RULE.getLocalPort() + ""/test"").request().header(ACCEPT_ENCODING, ""gzip"").get();

        assertThat(clientResponse.getHeaders().get(VARY)).isEqualTo(Collections.singletonList((Object) ACCEPT_ENCODING));
        assertThat(clientResponse.getHeaders().get(CONTENT_ENCODING)).isEqualTo(Collections.singletonList((Object) ""gzip""));
    }
"
"    @Test
    public void testBuildConfigurationMetadata(CheckedConsumer<String> classFilter) throws Exception {
        try (ByteArrayOutputStream byteStream = captureStderr();
                CustomClassLoader loader = new CustomClassLoader(classFilter)) {
            // create class objects from custom loader
            Class<ConfigurationMetadata> cmType = loader.reloadClass(ConfigurationMetadata.class);
            Class<ObjectMapper> omType = loader.reloadClass(ObjectMapper.class);
            Class<Configuration> confType = loader.reloadClass(Configuration.class);
            // construct ConfigurationMetadata object using class object associated with custom loader so that we can
            // simulate Logback not being in the classpath
            cmType.getConstructor(omType, Class.class).newInstance(omType.newInstance(), confType);

            // make sure nothing is emitted to stderr; previously the absence of Logback in the classpath would cause
            // ""class io.dropwizard.configuration.ConfigurationMetadata$1: Type ch.qos.logback.access.spi.IAccessEvent
            // not present"" to be emitted to stderr
            String err = byteStream.toString();
            assertThat(err).isEmpty();
        }
    }
"
"    @Test
        public void run(Configuration configuration, Environment environment) throws Exception {
            environment.jersey().register(new TestResource());
        }
"
"    @Test
        public String getPersonName() {
            return person.getName();
        }
"
"    @Test
        public Response toResponse(WebApplicationException e) {
            throw new UnsupportedOperationException();
        }
"
"    @Test
        public void run(TestConfiguration configuration, Environment environment) throws Exception {
            environment.jersey().register(new TestResource(configuration.getMessage()));
        }
"
"    @Test
        public Response toResponse(JerseyViolationException exception) {
            return Response.status(Response.Status.BAD_REQUEST)
                .type(MediaType.TEXT_PLAIN)
                .entity(""Invalid data"")
                .build();
        }
"
"    @Test
    public void eachTestShouldUseANewPort() throws Throwable {
        final ResourceExtension resources = ResourceExtension.builder()
                .setTestContainerFactory(new GrizzlyTestContainerFactory())
                .build();
        Set<Integer> usedPorts = new HashSet<>();

        for (int i = 0; i < 10; i++) {
            resources.before();
            final int port = resources.target(""/"").getUri().getPort();
            usedPorts.add(port);
        }
        assertThat(usedPorts).hasSizeGreaterThanOrEqualTo(2);
    }
"
"    @Test
        public Response toResponse(WebApplicationException e) {
            throw new UnsupportedOperationException();
        }
"
"    @Test
        public InputStream open(String path) throws IOException {
            openCalled = true;
            return super.open(path);
        }
"
"    @Test
        public OptionalInt showWithQueryParam(@QueryParam(""id"") OptionalInt id) {
            return id;
        }
"
"    @Test
        public OptionalDouble showWithQueryParam(@QueryParam(""id"") OptionalDouble id) {
            return id;
        }
"
"    @Test
        public Optional<String> showWithQueryParam(@QueryParam(""id"") String id) {
            return Optional.ofNullable(id);
        }
"
"    @Test
        public String getMessage(@QueryParam(""message"") Optional<String> message) {
            return message.orElse(""Default Message"");
        }
"
"    @Test
        public String getMessage(@HeaderParam(""message"") Optional<String> message) {
            return message.orElse(""Default Message"");
        }
"
"    @Test
        public OptionalLong showWithQueryParam(@QueryParam(""id"") OptionalLong id) {
            return id;
        }
"
"    @Test
        public String getMessage(@CookieParam(""message"") Optional<String> message) {
            return message.orElse(""Default Message"");
        }
"
"    @Test
        public String getMessage(@FormParam(""message"") Optional<String> message) {
            return message.orElse(""Default Message"");
        }
"
"    @Test
        public String foo() {
            return ""bar"";
        }
"
"    @Test
        public String getMessage(@QueryParam(""message"") NonEmptyStringParam message) {
            return message.get().orElse(""Hello"");
        }
"
"    @BeforeEach
    public void setUp() throws Exception {
        assumeThat(Locale.getDefault().getLanguage()).isEqualTo(""en"");
        super.setUp();
    }
"
"    @Test
        public Optional<String> showWithQueryParam(@QueryParam(""id"") String id) {
            return Optional.fromNullable(id);
        }
"
"    @Test
        public String getMessage(@QueryParam(""message"") Optional<String> message) {
            return message.or(""Default Message"");
        }
"
"    @Test
        public String getMessage(@HeaderParam(""message"") Optional<String> message) {
            return message.or(""Default Message"");
        }
"
"    @Test
        public String getMessage(@CookieParam(""message"") Optional<String> message) {
            return message.or(""Default Message"");
        }
"
"    @Test
        public String getMessage(@FormParam(""message"") Optional<String> message) {
            return message.or(""Default Message"");
        }
"
"    @Test
            public void write(int i) throws IOException {
                //void
            }
"
"    @Test
        public Response streamForever() {
            final StreamingOutput output = os -> {
                //noinspection InfiniteLoopStatement
                while (true) {
                    os.write('a');
                    os.flush();
                }
            };

            return Response.ok(output).build();
        }
"
"    @Test
        public String getReturnUserAgentHeader(@HeaderParam(""User-Agent"") String userAgentHeader) {
            return userAgentHeader;
        }
"
"    @Test
            public List<Proxy> select(URI uri) {
                return Collections.singletonList(new Proxy(Proxy.Type.HTTP, new InetSocketAddress(""192.168.52.1"", 8080)));
            }
"
"    @Test
            public void setCredentials(AuthScope authscope, Credentials credentials) {
            }
"
"    @Test
            public boolean isRedirected(HttpRequest httpRequest,
                                        HttpResponse httpResponse,
"
"    @Test
    public void usesAnExecutorServiceFromTheEnvironment() {
        final JerseyClientConfiguration configuration = new JerseyClientConfiguration();
        configuration.setMinThreads(7);
        configuration.setMaxThreads(532);
        configuration.setWorkQueueSize(16);

        final ExecutorServiceBuilder executorServiceBuilderMock = mock(ExecutorServiceBuilder.class);
        when(lifecycleEnvironment.executorService(""jersey-client-test-%d"")).thenReturn(executorServiceBuilderMock);

        when(executorServiceBuilderMock.minThreads(7)).thenReturn(executorServiceBuilderMock);
        when(executorServiceBuilderMock.maxThreads(532)).thenReturn(executorServiceBuilderMock);

        final ArgumentCaptor<ArrayBlockingQueue> arrayBlockingQueueCaptor =
                ArgumentCaptor.forClass(ArrayBlockingQueue.class);
        when(executorServiceBuilderMock.workQueue(arrayBlockingQueueCaptor.capture()))
                .thenReturn(executorServiceBuilderMock);
        when(executorServiceBuilderMock.build()).thenReturn(mock(ExecutorService.class));

        builder.using(configuration).using(environment).build(""test"");

        assertThat(arrayBlockingQueueCaptor.getValue().remainingCapacity()).isEqualTo(16);
    }
"
"    @Test
                public void checkClientTrusted(X509Certificate[] xcs, String string) {
                }
"
"    @Test
            public List<Proxy> select(URI uri) {
                return Collections.singletonList(new Proxy(Proxy.Type.HTTP, new InetSocketAddress(""192.168.53.12"", 8080)));
            }
"
"    @Test
    public void testGeneric() {
        DemoService server = new DemoServiceImpl();
        ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();
        Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();
        URL url = URL.valueOf(""dubbo://127.0.0.1:5342/"" + DemoService.class.getName() + ""?version=1.0.0"");
        Exporter<DemoService> exporter = protocol.export(proxyFactory.getInvoker(server, DemoService.class, url));
        Invoker<DemoService> invoker = protocol.refer(DemoService.class, url);

        GenericService client = (GenericService) proxyFactory.getProxy(invoker, true);
        Object result = client.$invoke(""sayHello"", new String[]{""java.lang.String""}, new Object[]{""haha""});
        Assert.assertEquals(""hello haha"", result);

        org.apache.dubbo.rpc.service.GenericService newClient = (org.apache.dubbo.rpc.service.GenericService) proxyFactory.getProxy(invoker, true);
        Object res = newClient.$invoke(""sayHello"", new String[]{""java.lang.String""}, new Object[]{""hehe""});
        Assert.assertEquals(""hello hehe"", res);
        invoker.destroy();
        exporter.unexport();
    }
"
"    @Test
    public void testGeneric2() {
        DemoService server = new DemoServiceImpl();
        ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();
        Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();
        URL url = URL.valueOf(""dubbo://127.0.0.1:5342/"" + DemoService.class.getName() + ""?version=1.0.0&generic=true"");
        Exporter<DemoService> exporter = protocol.export(proxyFactory.getInvoker(server, DemoService.class, url));
        Invoker<GenericService> invoker = protocol.refer(GenericService.class, url);

        GenericService client = proxyFactory.getProxy(invoker, true);
        Object result = client.$invoke(""sayHello"", new String[]{""java.lang.String""}, new Object[]{""haha""});
        Assert.assertEquals(""hello haha"", result);

        Invoker<DemoService> invoker2 = protocol.refer(DemoService.class, url);

        GenericService client2 = (GenericService) proxyFactory.getProxy(invoker2, true);
        Object result2 = client2.$invoke(""sayHello"", new String[]{""java.lang.String""}, new Object[]{""haha""});
        Assert.assertEquals(""hello haha"", result2);

        invoker.destroy();
        exporter.unexport();
    }
"
"    @Test
    public void testName() throws Exception {
        ApplicationConfig application = new ApplicationConfig();
        application.setName(""app"");
        assertThat(application.getName(), equalTo(""app""));
        application = new ApplicationConfig(""app2"");
        assertThat(application.getName(), equalTo(""app2""));
        Map<String, String> parameters = new HashMap<String, String>();
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(Constants.APPLICATION_KEY, ""app2""));
    }
"
"    @Test
    public void testVersion() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setVersion(""1.0.0"");
        assertThat(application.getVersion(), equalTo(""1.0.0""));
        Map<String, String> parameters = new HashMap<String, String>();
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(""application.version"", ""1.0.0""));
    }
"
"    @Test
    public void testOwner() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setOwner(""owner"");
        assertThat(application.getOwner(), equalTo(""owner""));
    }
"
"    @Test
    public void testOrganization() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setOrganization(""org"");
        assertThat(application.getOrganization(), equalTo(""org""));
    }
"
"    @Test
    public void testArchitecture() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setArchitecture(""arch"");
        assertThat(application.getArchitecture(), equalTo(""arch""));
    }
"
"    @Test
    public void testEnvironment1() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setEnvironment(""develop"");
        assertThat(application.getEnvironment(), equalTo(""develop""));
        application.setEnvironment(""test"");
        assertThat(application.getEnvironment(), equalTo(""test""));
        application.setEnvironment(""product"");
        assertThat(application.getEnvironment(), equalTo(""product""));
    }
"
"    @Test(expected = IllegalStateException.class)
    public void testEnvironment2() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setEnvironment(""illegal-env"");
    }
"
"    @Test
    public void testRegistry() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        RegistryConfig registry = new RegistryConfig();
        application.setRegistry(registry);
        assertThat(application.getRegistry(), sameInstance(registry));
        application.setRegistries(Collections.singletonList(registry));
        assertThat(application.getRegistries(), contains(registry));
        assertThat(application.getRegistries(), hasSize(1));
    }
"
"    @Test
    public void testMonitor() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setMonitor(new MonitorConfig(""monitor-addr""));
        assertThat(application.getMonitor().getAddress(), equalTo(""monitor-addr""));
        application.setMonitor(""monitor-addr"");
        assertThat(application.getMonitor().getAddress(), equalTo(""monitor-addr""));
    }
"
"    @Test
    public void testLogger() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setLogger(""log4j"");
        assertThat(application.getLogger(), equalTo(""log4j""));
    }
"
"    @Test
    public void testDefault() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setDefault(true);
        assertThat(application.isDefault(), is(true));
    }
"
"    @Test
    public void testDumpDirectory() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setDumpDirectory(""/dump"");
        assertThat(application.getDumpDirectory(), equalTo(""/dump""));
        Map<String, String> parameters = new HashMap<String, String>();
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(Constants.DUMP_DIRECTORY, ""/dump""));
    }
"
"    @Test
    public void testQosEnable() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setQosEnable(true);
        assertThat(application.getQosEnable(), is(true));
        Map<String, String> parameters = new HashMap<String, String>();
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(Constants.QOS_ENABLE, ""true""));
    }
"
"    @Test
    public void testQosPort() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setQosPort(8080);
        assertThat(application.getQosPort(), equalTo(8080));
    }
"
"    @Test
    public void testQosAcceptForeignIp() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setQosAcceptForeignIp(true);
        assertThat(application.getQosAcceptForeignIp(), is(true));
        Map<String, String> parameters = new HashMap<String, String>();
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(Constants.ACCEPT_FOREIGN_IP, ""true""));
    }
"
"    @Test
    public void testParameters() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setQosAcceptForeignIp(true);
        Map<String, String> parameters = new HashMap<String, String>();
        parameters.put(""k1"", ""v1"");
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(""k1"", ""v1""));
        assertThat(parameters, hasEntry(Constants.ACCEPT_FOREIGN_IP, ""true""));
    }
"
"    @Test
    public void testProtocol() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setProtocol(""protocol"");
        assertThat(registry.getProtocol(), equalTo(registry.getProtocol()));
    }
"
"    @Test
    public void testAddress() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setAddress(""localhost"");
        assertThat(registry.getAddress(), equalTo(""localhost""));
        Map<String, String> parameters = new HashMap<String, String>();
        RegistryConfig.appendParameters(parameters, registry);
        assertThat(parameters, not(hasKey(""address"")));
    }
"
"    @Test
    public void testUsername() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setUsername(""username"");
        assertThat(registry.getUsername(), equalTo(""username""));
    }
"
"    @Test
    public void testPassword() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setPassword(""password"");
        assertThat(registry.getPassword(), equalTo(""password""));
    }
"
"    @Test
    public void testWait() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setWait(10);
        assertThat(registry.getWait(), is(10));
        assertThat(System.getProperty(Constants.SHUTDOWN_WAIT_KEY), equalTo(""10""));
    }
"
"    @Test
    public void testCheck() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setCheck(true);
        assertThat(registry.isCheck(), is(true));
    }
"
"    @Test
    public void testFile() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setFile(""file"");
        assertThat(registry.getFile(), equalTo(""file""));
    }
"
"    @Test
    public void testTransporter() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setTransporter(""transporter"");
        assertThat(registry.getTransporter(), equalTo(""transporter""));
    }
"
"    @Test
    public void testClient() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setClient(""client"");
        assertThat(registry.getClient(), equalTo(""client""));
    }
"
"    @Test
    public void testTimeout() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setTimeout(10);
        assertThat(registry.getTimeout(), is(10));
    }
"
"    @Test
    public void testSession() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setSession(10);
        assertThat(registry.getSession(), is(10));
    }
"
"    @Test
    public void testDynamic() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setDynamic(true);
        assertThat(registry.isDynamic(), is(true));
    }
"
"    @Test
    public void testRegister() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setRegister(true);
        assertThat(registry.isRegister(), is(true));
    }
"
"    @Test
    public void testSubscribe() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setSubscribe(true);
        assertThat(registry.isSubscribe(), is(true));
    }
"
"    @Test
    public void testCluster() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setCluster(""cluster"");
        assertThat(registry.getCluster(), equalTo(""cluster""));
    }
"
"    @Test
    public void testGroup() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setGroup(""group"");
        assertThat(registry.getGroup(), equalTo(""group""));
    }
"
"    @Test
    public void testVersion() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setVersion(""1.0.0"");
        assertThat(registry.getVersion(), equalTo(""1.0.0""));
    }
"
"    @Test
    public void testParameters() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setParameters(Collections.singletonMap(""k1"", ""v1""));
        assertThat(registry.getParameters(), hasEntry(""k1"", ""v1""));
        Map<String, String> parameters = new HashMap<String, String>();
        RegistryConfig.appendParameters(parameters, registry);
        assertThat(parameters, hasEntry(""k1"", ""v1""));
    }
"
"    @Test
    public void testDefault() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setDefault(true);
        assertThat(registry.isDefault(), is(true));
    }
"
"    @Test
    public void testTimeout() throws Exception {
        try {
            System.clearProperty(""sun.rmi.transport.tcp.responseTimeout"");
            ConsumerConfig consumer = new ConsumerConfig();
            consumer.setTimeout(10);
            assertThat(consumer.getTimeout(), is(10));
            assertThat(System.getProperty(""sun.rmi.transport.tcp.responseTimeout""), equalTo(""10""));
        } finally {
            System.clearProperty(""sun.rmi.transport.tcp.responseTimeout"");
        }
    }
"
"    @Test
    public void testDefault() throws Exception {
        ConsumerConfig consumer = new ConsumerConfig();
        consumer.setDefault(true);
        assertThat(consumer.isDefault(), is(true));
    }
"
"    @Test
    public void testClient() throws Exception {
        ConsumerConfig consumer = new ConsumerConfig();
        consumer.setClient(""client"");
        assertThat(consumer.getClient(), equalTo(""client""));
    }
"
"    @Test(expected = IllegalStateException.class)
    public void testName1() throws Exception {
        ModuleConfig module = new ModuleConfig();
        Map<String, String> parameters = new HashMap<String, String>();
        ModuleConfig.appendParameters(parameters, module);
    }
"
"    @Test
    public void testName2() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setName(""module-name"");
        assertThat(module.getName(), equalTo(""module-name""));
        assertThat(module.getId(), equalTo(""module-name""));
        Map<String, String> parameters = new HashMap<String, String>();
        ModuleConfig.appendParameters(parameters, module);
        assertThat(parameters, hasEntry(""module"", ""module-name""));
    }
"
"    @Test
    public void testVersion() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setName(""module-name"");
        module.setVersion(""1.0.0"");
        assertThat(module.getVersion(), equalTo(""1.0.0""));
        Map<String, String> parameters = new HashMap<String, String>();
        ModuleConfig.appendParameters(parameters, module);
        assertThat(parameters, hasEntry(""module.version"", ""1.0.0""));
    }
"
"    @Test
    public void testOwner() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setOwner(""owner"");
        assertThat(module.getOwner(), equalTo(""owner""));
    }
"
"    @Test
    public void testOrganization() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setOrganization(""org"");
        assertThat(module.getOrganization(), equalTo(""org""));
    }
"
"    @Test
    public void testRegistry() throws Exception {
        ModuleConfig module = new ModuleConfig();
        RegistryConfig registry = new RegistryConfig();
        module.setRegistry(registry);
        assertThat(module.getRegistry(), sameInstance(registry));
    }
"
"    @Test
    public void testRegistries() throws Exception {
        ModuleConfig module = new ModuleConfig();
        RegistryConfig registry = new RegistryConfig();
        module.setRegistries(Collections.singletonList(registry));
        assertThat(module.getRegistries(), Matchers.<org.apache.dubbo.config.RegistryConfig>hasSize(1));
        assertThat(module.getRegistries(), contains(registry));
    }
"
"    @Test
    public void testMonitor() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setMonitor(""monitor-addr1"");
        assertThat(module.getMonitor().getAddress(), equalTo(""monitor-addr1""));
        module.setMonitor(new MonitorConfig(""monitor-addr2""));
        assertThat(module.getMonitor().getAddress(), equalTo(""monitor-addr2""));
    }
"
"    @Test
    public void testDefault() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setDefault(true);
        assertThat(module.isDefault(), is(true));
    }
"
"    @Test
    public void testIndex() throws Exception {
        ArgumentConfig argument = new ArgumentConfig();
        argument.setIndex(1);
        assertThat(argument.getIndex(), is(1));
    }
"
"    @Test
    public void testType() throws Exception {
        ArgumentConfig argument = new ArgumentConfig();
        argument.setType(""int"");
        assertThat(argument.getType(), equalTo(""int""));
    }
"
"    @Test
    public void testCallback() throws Exception {
        ArgumentConfig argument = new ArgumentConfig();
        argument.setCallback(true);
        assertThat(argument.isCallback(), is(true));
    }
"
"    @Test
    public void testArguments() throws Exception {
        ArgumentConfig argument = new ArgumentConfig();
        argument.setIndex(1);
        argument.setType(""int"");
        argument.setCallback(true);
        Map<String, String> parameters = new HashMap<String, String>();
        AbstractServiceConfig.appendParameters(parameters, argument);
        assertThat(parameters, hasEntry(""callback"", ""true""));
        assertThat(parameters.size(), is(1));
    }
"
"    @Test
    public void testProtocol() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setProtocol(""protocol"");
        assertThat(provider.getProtocol().getName(), equalTo(""protocol""));
    }
"
"    @Test
    public void testDefault() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setDefault(true);
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.isDefault(), is(true));
        assertThat(parameters, not(hasKey(""default"")));
    }
"
"    @Test
    public void testHost() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setHost(""demo-host"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.getHost(), equalTo(""demo-host""));
        assertThat(parameters, not(hasKey(""host"")));
    }
"
"    @Test
    public void testPort() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setPort(8080);
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.getPort(), is(8080));
        assertThat(parameters, not(hasKey(""port"")));
    }
"
"    @Test
    public void testPath() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setPath(""/path"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.getPath(), equalTo(""/path""));
        assertThat(provider.getContextpath(), equalTo(""/path""));
        assertThat(parameters, not(hasKey(""path"")));
    }
"
"    @Test
    public void testContextPath() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setContextpath(""/context-path"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.getContextpath(), equalTo(""/context-path""));
        assertThat(parameters, not(hasKey(""/context-path"")));
    }
"
"    @Test
    public void testThreads() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setThreads(10);
        assertThat(provider.getThreads(), is(10));
    }
"
"    @Test
    public void testIothreads() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setIothreads(10);
        assertThat(provider.getIothreads(), is(10));
    }
"
"    @Test
    public void testQueues() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setQueues(10);
        assertThat(provider.getQueues(), is(10));
    }
"
"    @Test
    public void testAccepts() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setAccepts(10);
        assertThat(provider.getAccepts(), is(10));
    }
"
"    @Test
    public void testCharset() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setCharset(""utf-8"");
        assertThat(provider.getCharset(), equalTo(""utf-8""));
    }
"
"    @Test
    public void testPayload() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setPayload(10);
        assertThat(provider.getPayload(), is(10));
    }
"
"    @Test
    public void testBuffer() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setBuffer(10);
        assertThat(provider.getBuffer(), is(10));
    }
"
"    @Test
    public void testServer() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setServer(""demo-server"");
        assertThat(provider.getServer(), equalTo(""demo-server""));
    }
"
"    @Test
    public void testClient() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setClient(""client"");
        assertThat(provider.getClient(), equalTo(""client""));
    }
"
"    @Test
    public void testPrompt() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setPrompt(""#"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.getPrompt(), equalTo(""#""));
        assertThat(parameters, hasEntry(""prompt"", ""%23""));
    }
"
"    @Test
    public void testDispatcher() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setDispatcher(""mockdispatcher"");
        assertThat(provider.getDispatcher(), equalTo(""mockdispatcher""));
    }
"
"    @Test
    public void testNetworker() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setNetworker(""networker"");
        assertThat(provider.getNetworker(), equalTo(""networker""));
    }
"
"    @Test
    public void testWait() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setWait(10);
        assertThat(provider.getWait(), equalTo(10));
    }
"
"    @Test
    public void testName() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setName(""hello"");
        assertThat(method.getName(), equalTo(""hello""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters, not(hasKey(""name"")));
    }
"
"    @Test
    public void testStat() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setStat(10);
        assertThat(method.getStat(), equalTo(10));
    }
"
"    @Test
    public void testRetry() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setRetry(true);
        assertThat(method.isRetry(), is(true));
    }
"
"    @Test
    public void testReliable() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setReliable(true);
        assertThat(method.isReliable(), is(true));
    }
"
"    @Test
    public void testExecutes() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setExecutes(10);
        assertThat(method.getExecutes(), equalTo(10));
    }
"
"    @Test
    public void testDeprecated() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setDeprecated(true);
        assertThat(method.getDeprecated(), is(true));
    }
"
"    @Test
    public void testArguments() throws Exception {
        MethodConfig method = new MethodConfig();
        ArgumentConfig argument = new ArgumentConfig();
        method.setArguments(Collections.singletonList(argument));
        assertThat(method.getArguments(), contains(argument));
        assertThat(method.getArguments(), Matchers.<org.apache.dubbo.config.ArgumentConfig>hasSize(1));
    }
"
"    @Test
    public void testSticky() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setSticky(true);
        assertThat(method.getSticky(), is(true));
    }
"
"    @Test
    public void testOnreturn() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setOnreturn(""on-return-object"");
        assertThat(method.getOnreturn(), equalTo((Object) ""on-return-object""));
        Map<Object, Object> attribute = new HashMap<Object, Object>();
        MethodConfig.appendAttributes(attribute, method);
        assertThat(attribute, hasEntry((Object) Constants.ON_RETURN_INSTANCE_KEY, (Object) ""on-return-object""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters.size(), is(0));
    }
"
"    @Test
    public void testOnreturnMethod() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setOnreturnMethod(""on-return-method"");
        assertThat(method.getOnreturnMethod(), equalTo(""on-return-method""));
        Map<Object, Object> attribute = new HashMap<Object, Object>();
        MethodConfig.appendAttributes(attribute, method);
        assertThat(attribute, hasEntry((Object) Constants.ON_RETURN_METHOD_KEY, (Object) ""on-return-method""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters.size(), is(0));
    }
"
"    @Test
    public void testOnthrow() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setOnthrow(""on-throw-object"");
        assertThat(method.getOnthrow(), equalTo((Object) ""on-throw-object""));
        Map<Object, Object> attribute = new HashMap<Object, Object>();
        MethodConfig.appendAttributes(attribute, method);
        assertThat(attribute, hasEntry((Object) Constants.ON_THROW_INSTANCE_KEY, (Object) ""on-throw-object""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters.size(), is(0));
    }
"
"    @Test
    public void testOnthrowMethod() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setOnthrowMethod(""on-throw-method"");
        assertThat(method.getOnthrowMethod(), equalTo(""on-throw-method""));
        Map<Object, Object> attribute = new HashMap<Object, Object>();
        MethodConfig.appendAttributes(attribute, method);
        assertThat(attribute, hasEntry((Object) Constants.ON_THROW_METHOD_KEY, (Object) ""on-throw-method""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters.size(), is(0));
    }
"
"    @Test
    public void testOninvoke() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setOninvoke(""on-invoke-object"");
        assertThat(method.getOninvoke(), equalTo((Object) ""on-invoke-object""));
        Map<Object, Object> attribute = new HashMap<Object, Object>();
        MethodConfig.appendAttributes(attribute, method);
        assertThat(attribute, hasEntry((Object) Constants.ON_INVOKE_INSTANCE_KEY, (Object) ""on-invoke-object""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters.size(), is(0));
    }
"
"    @Test
    public void testOninvokeMethod() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setOninvokeMethod(""on-invoke-method"");
        assertThat(method.getOninvokeMethod(), equalTo(""on-invoke-method""));
        Map<Object, Object> attribute = new HashMap<Object, Object>();
        MethodConfig.appendAttributes(attribute, method);
        assertThat(attribute, hasEntry((Object) Constants.ON_INVOKE_METHOD_KEY, (Object) ""on-invoke-method""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters.size(), is(0));
    }
"
"    @Test
    public void testReturn() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setReturn(true);
        assertThat(method.isReturn(), is(true));
    }
"
"    @Test
    public void testConfig() {
        com.alibaba.dubbo.config.ServiceConfig<DemoService> service = new ServiceConfig<>();
        service.setApplication(new com.alibaba.dubbo.config.ApplicationConfig(""first-dubbo-provider""));
        service.setRegistry(new com.alibaba.dubbo.config.RegistryConfig(""multicast://224.5.6.7:1234""));
        service.setInterface(DemoService.class);
        service.setRef(new DemoServiceImpl());
        service.export();

        com.alibaba.dubbo.config.ReferenceConfig<DemoService> reference = new ReferenceConfig<>();
        reference.setApplication(new ApplicationConfig(""first-dubbo-client""));
        reference.setRegistry(new RegistryConfig(""multicast://224.5.6.7:1234""));
        reference.setInterface(DemoService.class);
        DemoService demoService = reference.get();
        String message = demoService.sayHello(""dubbo"");
        Assert.assertEquals(""hello dubbo"", message);
    }
"
"    @Test
    public void testName() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setName(""name"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProtocolConfig.appendParameters(parameters, protocol);
        assertThat(protocol.getName(), equalTo(""name""));
        assertThat(protocol.getId(), equalTo(""name""));
        assertThat(parameters.isEmpty(), is(true));
    }
"
"    @Test
    public void testHost() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setHost(""host"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProtocolConfig.appendParameters(parameters, protocol);
        assertThat(protocol.getHost(), equalTo(""host""));
        assertThat(parameters.isEmpty(), is(true));
    }
"
"    @Test
    public void testPort() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setPort(8080);
        Map<String, String> parameters = new HashMap<String, String>();
        ProtocolConfig.appendParameters(parameters, protocol);
        assertThat(protocol.getPort(), equalTo(8080));
        assertThat(parameters.isEmpty(), is(true));
    }
"
"    @Test
    public void testPath() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setContextpath(""context-path"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProtocolConfig.appendParameters(parameters, protocol);
        assertThat(protocol.getPath(), equalTo(""context-path""));
        assertThat(protocol.getContextpath(), equalTo(""context-path""));
        assertThat(parameters.isEmpty(), is(true));
        protocol.setPath(""path"");
        assertThat(protocol.getPath(), equalTo(""path""));
        assertThat(protocol.getContextpath(), equalTo(""path""));
    }
"
"    @Test
    public void testThreads() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setThreads(10);
        assertThat(protocol.getThreads(), is(10));
    }
"
"    @Test
    public void testIothreads() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setIothreads(10);
        assertThat(protocol.getIothreads(), is(10));
    }
"
"    @Test
    public void testQueues() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setQueues(10);
        assertThat(protocol.getQueues(), is(10));
    }
"
"    @Test
    public void testAccepts() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setAccepts(10);
        assertThat(protocol.getAccepts(), is(10));
    }
"
"    @Test
    public void testAccesslog() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setAccesslog(""access.log"");
        assertThat(protocol.getAccesslog(), equalTo(""access.log""));
    }
"
"    @Test
    public void testRegister() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setRegister(true);
        assertThat(protocol.isRegister(), is(true));
    }
"
"    @Test
    public void testParameters() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setParameters(Collections.singletonMap(""k1"", ""v1""));
        assertThat(protocol.getParameters(), hasEntry(""k1"", ""v1""));
    }
"
"    @Test
    public void testDefault() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setDefault(true);
        assertThat(protocol.isDefault(), is(true));
    }
"
"  @Test
  public void testCanReadTemplateFilesOnTheFilesystem() throws IOException {
    SpecificCompiler compiler = createCompiler();
    compiler.compileToDestination(this.src, OUTPUT_DIR.getRoot());
    assertTrue(new File(OUTPUT_DIR.getRoot(),""SimpleRecord.java"").exists());
  }
"
"  @Test
  public void testPublicFieldVisibility() throws IOException {
    SpecificCompiler compiler = createCompiler();
    compiler.setFieldVisibility(SpecificCompiler.FieldVisibility.PUBLIC);
    assertFalse(compiler.deprecatedFields());
    assertTrue(compiler.publicFields());
    assertFalse(compiler.privateFields());
    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
    assertTrue(this.outputFile.exists());
    try(BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {
      String line;
      while ((line = reader.readLine()) != null) {
        // No line, once trimmed, should start with a deprecated field declaration
        // nor a private field declaration.  Since the nested builder uses private
        // fields, we cannot do the second check.
        line = line.trim();
        assertFalse(""Line started with a deprecated field declaration: "" + line,
                line.startsWith(""@Deprecated public int value""));
      }
    }
  }
"
"  @Test
  public void testCreateAllArgsConstructor() throws Exception {
    SpecificCompiler compiler = createCompiler();
    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
    assertTrue(this.outputFile.exists());
    boolean foundAllArgsConstructor = false;
    try(BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {
      String line;
      while (!foundAllArgsConstructor && (line = reader.readLine()) != null) {
        foundAllArgsConstructor = line.contains(""All-args constructor"");
      }
    }
    assertTrue(foundAllArgsConstructor);
  }
"
"  @Test
  public void testMaxValidParameterCounts() throws Exception {
    Schema validSchema1 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT, 0);
    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ""1""), new SpecificCompiler(validSchema1).compile());

    Schema validSchema2 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT - 2, 1);
    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ""2""), new SpecificCompiler(validSchema1).compile());
  }
"
"  @Test
  public void testInvalidParameterCounts() throws Exception {
    Schema invalidSchema1 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT + 1, 0);
    SpecificCompiler compiler = new SpecificCompiler(invalidSchema1);
    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ""1""), compiler.compile());

    Schema invalidSchema2 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT, 10);
    compiler = new SpecificCompiler(invalidSchema2);
    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName() + ""2""), compiler.compile());
  }
"
"  @Test
  public void testMaxParameterCounts() throws Exception {
    Schema validSchema1 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT, 0);
    assertTrue(new SpecificCompiler(validSchema1).compile().size() > 0);

    Schema validSchema2 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT - 2, 1);
    assertTrue(new SpecificCompiler(validSchema2).compile().size() > 0);

    Schema validSchema3 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT - 1, 1);
    assertTrue(new SpecificCompiler(validSchema3).compile().size() > 0);

    Schema validSchema4 = createSampleRecordSchema(SpecificCompiler.MAX_FIELD_PARAMETER_UNIT_COUNT + 1, 0);
    assertTrue(new SpecificCompiler(validSchema4).compile().size() > 0);
  }
"
"  @Test(expected=RuntimeException.class)
  public void testCalcAllArgConstructorParameterUnitsFailure() {
    Schema nonRecordSchema = SchemaBuilder.array().items().booleanType();
    new SpecificCompiler().calcAllArgConstructorParameterUnits(nonRecordSchema);
  }
"
"  @Test
  public void testPublicDeprecatedFieldVisibility() throws IOException {
    SpecificCompiler compiler = createCompiler();
    assertTrue(compiler.deprecatedFields());
    assertTrue(compiler.publicFields());
    assertFalse(compiler.privateFields());
    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
    assertTrue(this.outputFile.exists());
    BufferedReader reader = new BufferedReader(new FileReader(this.outputFile));
    String line;
    while ((line = reader.readLine()) != null) {
      // No line, once trimmed, should start with a public field declaration
      line = line.trim();
      assertFalse(""Line started with a public field declaration: "" + line,
        line.startsWith(""public int value""));
    }
    reader.close();
  }
"
"  @Test
  public void testPrivateFieldVisibility() throws IOException {
    SpecificCompiler compiler = createCompiler();
    compiler.setFieldVisibility(SpecificCompiler.FieldVisibility.PRIVATE);
    assertFalse(compiler.deprecatedFields());
    assertFalse(compiler.publicFields());
    assertTrue(compiler.privateFields());
    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
    assertTrue(this.outputFile.exists());
    BufferedReader reader = new BufferedReader(new FileReader(this.outputFile));
    String line = null;
    while ((line = reader.readLine()) != null) {
      // No line, once trimmed, should start with a public field declaration
      // or with a deprecated public field declaration
      line = line.trim();
      assertFalse(""Line started with a public field declaration: "" + line,
        line.startsWith(""public int value""));
      assertFalse(""Line started with a deprecated field declaration: "" + line,
        line.startsWith(""@Deprecated public int value""));
    }
    reader.close();
  }
"
"  @Test
  public void testSettersCreatedByDefault() throws IOException {
    SpecificCompiler compiler = createCompiler();
    assertTrue(compiler.isCreateSetters());
    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
    assertTrue(this.outputFile.exists());
    int foundSetters = 0;
    try(BufferedReader reader = new BufferedReader(new FileReader(this.outputFile))) {
      String line;
      while ((line = reader.readLine()) != null) {
        // We should find the setter in the main class
        line = line.trim();
        if (line.startsWith(""public void setValue("")) {
          foundSetters++;
        }
"
"  @Test
  public void testSettingOutputCharacterEncoding() throws Exception {
    SpecificCompiler compiler = createCompiler();
    // Generated file in default encoding
    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
    byte[] fileInDefaultEncoding = new byte[(int) this.outputFile.length()];
    FileInputStream is = new FileInputStream(this.outputFile);
    is.read(fileInDefaultEncoding);
    is.close(); //close input stream otherwise delete might fail
    if (!this.outputFile.delete()) {
      throw new IllegalStateException(""unable to delete "" + this.outputFile); //delete otherwise compiler might not overwrite because src timestamp hasn't changed.
    }
    // Generate file in another encoding (make sure it has different number of bytes per character)
    String differentEncoding = Charset.defaultCharset().equals(Charset.forName(""UTF-16"")) ? ""UTF-32"" : ""UTF-16"";
    compiler.setOutputCharacterEncoding(differentEncoding);
    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
    byte[] fileInDifferentEncoding = new byte[(int) this.outputFile.length()];
    is = new FileInputStream(this.outputFile);
    is.read(fileInDifferentEncoding);
    is.close();
    // Compare as bytes
    assertThat(""Generated file should contain different bytes after setting non-default encoding"",
      fileInDefaultEncoding, not(equalTo(fileInDifferentEncoding)));
    // Compare as strings
    assertThat(""Generated files should contain the same characters in the proper encodings"",
      new String(fileInDefaultEncoding), equalTo(new String(fileInDifferentEncoding, differentEncoding)));
  }
"
"  @Test
  public void testJavaTypeWithDecimalLogicalTypeEnabled() throws Exception {
    SpecificCompiler compiler = createCompiler();
    compiler.setEnableDecimalLogicalType(true);

    Schema dateSchema = LogicalTypes.date()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timeSchema = LogicalTypes.timeMillis()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timestampSchema = LogicalTypes.timestampMillis()
        .addToSchema(Schema.create(Schema.Type.LONG));
    Schema decimalSchema = LogicalTypes.decimal(9,2)
        .addToSchema(Schema.create(Schema.Type.BYTES));
    Schema uuidSchema = LogicalTypes.uuid()
        .addToSchema(Schema.create(Schema.Type.STRING));

    // Date/time types should always use upper level java classes
    // Decimal type target class depends on configuration
    // UUID should always be CharSequence since we haven't added its
    // support in SpecificRecord
    Assert.assertEquals(""Should use Joda LocalDate for date type"",
        ""org.joda.time.LocalDate"", compiler.javaType(dateSchema));
    Assert.assertEquals(""Should use Joda LocalTime for time-millis type"",
        ""org.joda.time.LocalTime"", compiler.javaType(timeSchema));
    Assert.assertEquals(""Should use Joda DateTime for timestamp-millis type"",
        ""org.joda.time.DateTime"", compiler.javaType(timestampSchema));
    Assert.assertEquals(""Should use Java BigDecimal type"",
        ""java.math.BigDecimal"", compiler.javaType(decimalSchema));
    Assert.assertEquals(""Should use Java CharSequence type"",
        ""java.lang.CharSequence"", compiler.javaType(uuidSchema));
  }
"
"  @Test
  public void testJavaTypeWithDecimalLogicalTypeDisabled() throws Exception {
    SpecificCompiler compiler = createCompiler();
    compiler.setEnableDecimalLogicalType(false);

    Schema dateSchema = LogicalTypes.date()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timeSchema = LogicalTypes.timeMillis()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timestampSchema = LogicalTypes.timestampMillis()
        .addToSchema(Schema.create(Schema.Type.LONG));
    Schema decimalSchema = LogicalTypes.decimal(9,2)
        .addToSchema(Schema.create(Schema.Type.BYTES));
    Schema uuidSchema = LogicalTypes.uuid()
        .addToSchema(Schema.create(Schema.Type.STRING));

    // Date/time types should always use upper level java classes
    // Decimal type target class depends on configuration
    // UUID should always be CharSequence since we haven't added its
    // support in SpecificRecord
    Assert.assertEquals(""Should use Joda LocalDate for date type"",
        ""org.joda.time.LocalDate"", compiler.javaType(dateSchema));
    Assert.assertEquals(""Should use Joda LocalTime for time-millis type"",
        ""org.joda.time.LocalTime"", compiler.javaType(timeSchema));
    Assert.assertEquals(""Should use Joda DateTime for timestamp-millis type"",
        ""org.joda.time.DateTime"", compiler.javaType(timestampSchema));
    Assert.assertEquals(""Should use ByteBuffer type"",
        ""java.nio.ByteBuffer"", compiler.javaType(decimalSchema));
    Assert.assertEquals(""Should use Java CharSequence type"",
        ""java.lang.CharSequence"", compiler.javaType(uuidSchema));
  }
"
"  @Test
  public void testJavaTypeWithJsr310DateTimeTypes() throws Exception {
    SpecificCompiler compiler = createCompiler(JSR310);

    Schema dateSchema = LogicalTypes.date()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timeSchema = LogicalTypes.timeMillis()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timestampSchema = LogicalTypes.timestampMillis()
        .addToSchema(Schema.create(Schema.Type.LONG));

    // Date/time types should always use upper level java classes
    Assert.assertEquals(""Should use java.time.LocalDate for date type"",
        ""java.time.LocalDate"", compiler.javaType(dateSchema));
    Assert.assertEquals(""Should use java.time.LocalTime for time-millis type"",
        ""java.time.LocalTime"", compiler.javaType(timeSchema));
    Assert.assertEquals(""Should use java.time.Instant for timestamp-millis type"",
        ""java.time.Instant"", compiler.javaType(timestampSchema));
  }
"
"  @Test
  public void testJavaUnbox() throws Exception {
    SpecificCompiler compiler = createCompiler();
    compiler.setEnableDecimalLogicalType(false);

    Schema intSchema = Schema.create(Schema.Type.INT);
    Schema longSchema = Schema.create(Schema.Type.LONG);
    Schema floatSchema = Schema.create(Schema.Type.FLOAT);
    Schema doubleSchema = Schema.create(Schema.Type.DOUBLE);
    Schema boolSchema = Schema.create(Schema.Type.BOOLEAN);
    Assert.assertEquals(""Should use int for Type.INT"",
        ""int"", compiler.javaUnbox(intSchema));
    Assert.assertEquals(""Should use long for Type.LONG"",
        ""long"", compiler.javaUnbox(longSchema));
    Assert.assertEquals(""Should use float for Type.FLOAT"",
        ""float"", compiler.javaUnbox(floatSchema));
    Assert.assertEquals(""Should use double for Type.DOUBLE"",
        ""double"", compiler.javaUnbox(doubleSchema));
    Assert.assertEquals(""Should use boolean for Type.BOOLEAN"",
        ""boolean"", compiler.javaUnbox(boolSchema));

    Schema dateSchema = LogicalTypes.date()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timeSchema = LogicalTypes.timeMillis()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timestampSchema = LogicalTypes.timestampMillis()
        .addToSchema(Schema.create(Schema.Type.LONG));
    // Date/time types should always use upper level java classes, even though
    // their underlying representations are primitive types
    Assert.assertEquals(""Should use Joda LocalDate for date type"",
        ""org.joda.time.LocalDate"", compiler.javaUnbox(dateSchema));
    Assert.assertEquals(""Should use Joda LocalTime for time-millis type"",
        ""org.joda.time.LocalTime"", compiler.javaUnbox(timeSchema));
    Assert.assertEquals(""Should use Joda DateTime for timestamp-millis type"",
        ""org.joda.time.DateTime"", compiler.javaUnbox(timestampSchema));
  }
"
"  @Test
  public void testJavaUnboxJsr310DateTime() throws Exception {
    SpecificCompiler compiler = createCompiler(JSR310);

    Schema dateSchema = LogicalTypes.date()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timeSchema = LogicalTypes.timeMillis()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timestampSchema = LogicalTypes.timestampMillis()
        .addToSchema(Schema.create(Schema.Type.LONG));
    // Date/time types should always use upper level java classes, even though
    // their underlying representations are primitive types
    Assert.assertEquals(""Should use java.time.LocalDate for date type"",
        ""java.time.LocalDate"", compiler.javaUnbox(dateSchema));
    Assert.assertEquals(""Should use java.time.LocalTime for time-millis type"",
        ""java.time.LocalTime"", compiler.javaUnbox(timeSchema));
    Assert.assertEquals(""Should use java.time.Instant for timestamp-millis type"",
        ""java.time.Instant"", compiler.javaUnbox(timestampSchema));
  }
"
"  @Test
  public void testNullableTypesJavaUnbox() throws Exception {
    SpecificCompiler compiler = createCompiler();
    compiler.setEnableDecimalLogicalType(false);

    // Nullable types should return boxed types instead of primitive types
    Schema nullableIntSchema1 = Schema.createUnion(
        Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.INT));
    Schema nullableIntSchema2 = Schema.createUnion(
        Schema.create(Schema.Type.INT), Schema.create(Schema.Type.NULL));
    Assert.assertEquals(""Should return boxed type"",
        compiler.javaUnbox(nullableIntSchema1), ""java.lang.Integer"");
    Assert.assertEquals(""Should return boxed type"",
        compiler.javaUnbox(nullableIntSchema2), ""java.lang.Integer"");

    Schema nullableLongSchema1 = Schema.createUnion(
        Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.LONG));
    Schema nullableLongSchema2 = Schema.createUnion(
        Schema.create(Schema.Type.LONG), Schema.create(Schema.Type.NULL));
    Assert.assertEquals(""Should return boxed type"",
        compiler.javaUnbox(nullableLongSchema1), ""java.lang.Long"");
    Assert.assertEquals(""Should return boxed type"",
        compiler.javaUnbox(nullableLongSchema2), ""java.lang.Long"");

    Schema nullableFloatSchema1 = Schema.createUnion(
        Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.FLOAT));
    Schema nullableFloatSchema2 = Schema.createUnion(
        Schema.create(Schema.Type.FLOAT), Schema.create(Schema.Type.NULL));
    Assert.assertEquals(""Should return boxed type"",
        compiler.javaUnbox(nullableFloatSchema1), ""java.lang.Float"");
    Assert.assertEquals(""Should return boxed type"",
        compiler.javaUnbox(nullableFloatSchema2), ""java.lang.Float"");

    Schema nullableDoubleSchema1 = Schema.createUnion(
        Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.DOUBLE));
    Schema nullableDoubleSchema2 = Schema.createUnion(
        Schema.create(Schema.Type.DOUBLE), Schema.create(Schema.Type.NULL));
    Assert.assertEquals(""Should return boxed type"",
        compiler.javaUnbox(nullableDoubleSchema1), ""java.lang.Double"");
    Assert.assertEquals(""Should return boxed type"",
        compiler.javaUnbox(nullableDoubleSchema2), ""java.lang.Double"");

    Schema nullableBooleanSchema1 = Schema.createUnion(
        Schema.create(Schema.Type.NULL), Schema.create(Schema.Type.BOOLEAN));
    Schema nullableBooleanSchema2 = Schema.createUnion(
        Schema.create(Schema.Type.BOOLEAN), Schema.create(Schema.Type.NULL));
    Assert.assertEquals(""Should return boxed type"",
        compiler.javaUnbox(nullableBooleanSchema1), ""java.lang.Boolean"");
    Assert.assertEquals(""Should return boxed type"",
        compiler.javaUnbox(nullableBooleanSchema2), ""java.lang.Boolean"");
  }
"
"  @Test
  public void testLogicalTypesWithMultipleFields() throws Exception {
    Schema logicalTypesWithMultipleFields = new Schema.Parser().parse(
        new File(""src/test/resources/logical_types_with_multiple_fields.avsc""));
    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName()),
        new SpecificCompiler(logicalTypesWithMultipleFields).compile());
  }
"
"  @Test
  public void testUnionAndFixedFields() throws Exception {
    Schema unionTypesWithMultipleFields = new Schema.Parser().parse(
        new File(""src/test/resources/union_and_fixed_fields.avsc""));
    assertCompilesWithJavaCompiler(new File(this.outputFile, name.getMethodName()),
        new SpecificCompiler(unionTypesWithMultipleFields).compile());
  }
"
"  @Test
  public void testLogicalTypesWithMultipleFieldsJsr310DateTime() throws Exception {
    Schema logicalTypesWithMultipleFields = new Schema.Parser().parse(
        new File(""src/test/resources/logical_types_with_multiple_fields.avsc""));
    assertCompilesWithJavaCompiler(new File(this.outputFile, name.getMethodName()),
        new SpecificCompiler(logicalTypesWithMultipleFields, JSR310).compile());
  }
"
"  @Test
  public void testConversionInstanceWithDecimalLogicalTypeDisabled() throws Exception {
    SpecificCompiler compiler = createCompiler();
    compiler.setEnableDecimalLogicalType(false);

    Schema dateSchema = LogicalTypes.date()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timeSchema = LogicalTypes.timeMillis()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timestampSchema = LogicalTypes.timestampMillis()
        .addToSchema(Schema.create(Schema.Type.LONG));
    Schema decimalSchema = LogicalTypes.decimal(9,2)
        .addToSchema(Schema.create(Schema.Type.BYTES));
    Schema uuidSchema = LogicalTypes.uuid()
        .addToSchema(Schema.create(Schema.Type.STRING));

    Assert.assertEquals(""Should use DATE_CONVERSION for date type"",
        ""DATE_CONVERSION"", compiler.conversionInstance(dateSchema));
    Assert.assertEquals(""Should use TIME_CONVERSION for time type"",
        ""TIME_CONVERSION"", compiler.conversionInstance(timeSchema));
    Assert.assertEquals(""Should use TIMESTAMP_CONVERSION for date type"",
        ""TIMESTAMP_CONVERSION"", compiler.conversionInstance(timestampSchema));
    Assert.assertEquals(""Should use null for decimal if the flag is off"",
        ""null"", compiler.conversionInstance(decimalSchema));
    Assert.assertEquals(""Should use null for decimal if the flag is off"",
        ""null"", compiler.conversionInstance(uuidSchema));
  }
"
"  @Test
  public void testConversionInstanceWithDecimalLogicalTypeEnabled() throws Exception {
    SpecificCompiler compiler = createCompiler();
    compiler.setEnableDecimalLogicalType(true);

    Schema dateSchema = LogicalTypes.date()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timeSchema = LogicalTypes.timeMillis()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timestampSchema = LogicalTypes.timestampMillis()
        .addToSchema(Schema.create(Schema.Type.LONG));
    Schema decimalSchema = LogicalTypes.decimal(9,2)
        .addToSchema(Schema.create(Schema.Type.BYTES));
    Schema uuidSchema = LogicalTypes.uuid()
        .addToSchema(Schema.create(Schema.Type.STRING));

    Assert.assertEquals(""Should use DATE_CONVERSION for date type"",
        ""DATE_CONVERSION"", compiler.conversionInstance(dateSchema));
    Assert.assertEquals(""Should use TIME_CONVERSION for time type"",
        ""TIME_CONVERSION"", compiler.conversionInstance(timeSchema));
    Assert.assertEquals(""Should use TIMESTAMP_CONVERSION for date type"",
        ""TIMESTAMP_CONVERSION"", compiler.conversionInstance(timestampSchema));
    Assert.assertEquals(""Should use null for decimal if the flag is off"",
        ""DECIMAL_CONVERSION"", compiler.conversionInstance(decimalSchema));
    Assert.assertEquals(""Should use null for decimal if the flag is off"",
        ""null"", compiler.conversionInstance(uuidSchema));
  }
"
"  @Test
  public void textCloning() {
    Schema recSchema = new Schema.Parser().parse(SCHEMA);
    Schemas.visit(recSchema, new PrintingVisitor());


    CloningVisitor cv = new CloningVisitor(recSchema);
    Schema trimmed = Schemas.visit(recSchema, cv);
    Assert.assertNull(trimmed.getDoc());
    Assert.assertNotNull(recSchema.getDoc());

    SchemaCompatibility.SchemaCompatibilityType compat =
        SchemaCompatibility.checkReaderWriterCompatibility(trimmed, recSchema).getType();
    Assert.assertEquals(SchemaCompatibility.SchemaCompatibilityType.COMPATIBLE, compat);
    compat = SchemaCompatibility.checkReaderWriterCompatibility(recSchema, trimmed).getType();
    Assert.assertEquals(SchemaCompatibility.SchemaCompatibilityType.COMPATIBLE, compat);
    Assert.assertNotNull(cv.toString());
  }
"
"  @Test
  public void textCloningCopyDocs() {
    Schema recSchema = new Schema.Parser().parse(SCHEMA);
    Schemas.visit(recSchema, new PrintingVisitor());


    Schema trimmed = Schemas.visit(recSchema, new CloningVisitor(new CloningVisitor.PropertyCopier() {
      @Override
      public void copy(final Schema first, final Schema second) {
        Schemas.copyLogicalTypes(first, second);
        Schemas.copyAliases(first, second);
      }
"
"  @Test(expected = IllegalStateException.class)
  public void testCloningError1() {
    // Visit Terminal with union
    Schema recordSchema = new Schema.Parser().parse(
        ""{\""type\"": \""record\"", \""name\"": \""R\"", \""fields\"":[{\""name\"": \""f1\"", \""type\"": [\""int\"", \""long\""]}]}"");
    new CloningVisitor(recordSchema).visitTerminal(recordSchema.getField(""f1"").schema());
  }
"
"  @Test(expected = IllegalStateException.class)
  public void testCloningError2() {
    // After visit Non-terminal with int
    Schema recordSchema = new Schema.Parser().parse(
        ""{\""type\"": \""record\"", \""name\"": \""R\"", \""fields\"":[{\""name\"": \""f1\"", \""type\"": \""int\""}]}"");
    new CloningVisitor(recordSchema).afterVisitNonTerminal(recordSchema.getField(""f1"").schema());
  }
"
"  @Test
  public void testHasGeneratedJavaClass() {
    Assert.assertTrue(Schemas.hasGeneratedJavaClass(
        new Schema.Parser().parse(""{\""type\"": \""fixed\"", \""name\"": \""N\"", \""size\"": 10}"")));
    Assert.assertFalse(Schemas.hasGeneratedJavaClass(new Schema.Parser().parse(""{\""type\"": \""int\""}"")));
  }
"
"  @Test
  public void testGetJavaClassName() {
    Assert.assertEquals(""N"", Schemas.getJavaClassName(
        new Schema.Parser().parse(""{\""type\"": \""fixed\"", \""name\"": \""N\"", \""size\"": 10}"")));
    Assert.assertEquals(""N"", Schemas.getJavaClassName(
        new Schema.Parser().parse(""{\""type\"": \""fixed\"", \""name\"": \""N\"", \""size\"": 10, \""namespace\"": \""\""}"")));
    Assert.assertEquals(""com.example.N"", Schemas.getJavaClassName(
        new Schema.Parser().parse(""{\""type\"": \""fixed\"", \""name\"": \""N\"", \""size\"": 10, \""namespace\"": \""com.example\""}"")));
  }
"
"  @Test
  public void testVisit1() {
    String s1 = ""{\""type\"": \""record\"", \""name\"": \""t1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": \""int\""}"" +
        ""]}"";
    Assert.assertEquals(""t1."", Schemas.visit(new Schema.Parser().parse(s1), new TestVisitor()));
  }
"
"  @Test
  public void testVisit2() {
    String s2 = ""{\""type\"": \""record\"", \""name\"": \""c1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": \""int\""}"" +
        ""]}"";
    Assert.assertEquals(""c1.\""int\""!"", Schemas.visit(new Schema.Parser().parse(s2), new TestVisitor()));

  }
"
"  @Test
  public void testVisit3() {
    String s3 = ""{\""type\"": \""record\"", \""name\"": \""ss1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": \""int\""}"" +
        ""]}"";
    Assert.assertEquals(""ss1."", Schemas.visit(new Schema.Parser().parse(s3), new TestVisitor()));

  }
"
"  @Test
  public void testVisit4() {
    String s4 = ""{\""type\"": \""record\"", \""name\"": \""st1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": \""int\""}"" +
        ""]}"";
    Assert.assertEquals(""st1.!"", Schemas.visit(new Schema.Parser().parse(s4), new TestVisitor()));

  }
"
"  @Test
  public void testVisit5() {
    String s5 = ""{\""type\"": \""record\"", \""name\"": \""c1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": {\""type\"": \""record\"", \""name\"": \""c2\"", \""fields\"": "" +
        ""[{\""name\"": \""f11\"", \""type\"": \""int\""}]}},"" +
        ""{\""name\"": \""f2\"", \""type\"": \""long\""}"" +
        ""]}"";
    Assert.assertEquals(""c1.c2.\""int\""!\""long\""!"",
        Schemas.visit(new Schema.Parser().parse(s5), new TestVisitor()));

  }
"
"  @Test
  public void testVisit6() {
    String s6 = ""{\""type\"": \""record\"", \""name\"": \""c1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": {\""type\"": \""record\"", \""name\"": \""ss2\"", \""fields\"": "" +
        ""[{\""name\"": \""f11\"", \""type\"": \""int\""}]}},"" +
        ""{\""name\"": \""f2\"", \""type\"": \""long\""}"" +
        ""]}"";
    Assert.assertEquals(""c1.ss2.!"",
        Schemas.visit(new Schema.Parser().parse(s6), new TestVisitor()));

  }
"
"  @Test
  public void testVisit7() {
    String s7 = ""{\""type\"": \""record\"", \""name\"": \""c1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": {\""type\"": \""record\"", \""name\"": \""css2\"", \""fields\"": "" +
        ""[{\""name\"": \""f11\"", \""type\"": \""int\""}]}},"" +
        ""{\""name\"": \""f2\"", \""type\"": \""long\""}"" +
        ""]}"";
    Assert.assertEquals(""c1.css2.\""int\""!!"",
        Schemas.visit(new Schema.Parser().parse(s7), new TestVisitor()));
  }
"
"  @Test(expected = UnsupportedOperationException.class)
  public void testVisit8() {
    String s8 = ""{\""type\"": \""record\"", \""name\"": \""c1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": {\""type\"": \""record\"", \""name\"": \""cst2\"", \""fields\"": "" +
        ""[{\""name\"": \""f11\"", \""type\"": \""int\""}]}},"" +
        ""{\""name\"": \""f2\"", \""type\"": \""int\""}"" +
        ""]}"";
    Schemas.visit(new Schema.Parser().parse(s8), new TestVisitor());
  }
"
"  @Test
  public void testVisit9() {
    String s9 = ""{\""type\"": \""record\"", \""name\"": \""c1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": {\""type\"": \""record\"", \""name\"": \""ct2\"", \""fields\"": "" +
        ""[{\""name\"": \""f11\"", \""type\"": \""int\""}]}},"" +
        ""{\""name\"": \""f2\"", \""type\"": \""long\""}"" +
        ""]}"";
    Assert.assertEquals(""c1.ct2.\""int\""!"", Schemas.visit(new Schema.Parser().parse(s9), new TestVisitor()));
  }
"
"  @Test(expected = UnsupportedOperationException.class)
  public void testVisit10() {
    String s10 = ""{\""type\"": \""record\"", \""name\"": \""c1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": {\""type\"": \""record\"", \""name\"": \""ct2\"", \""fields\"": "" +
        ""[{\""name\"": \""f11\"", \""type\"": \""int\""}]}},"" +
        ""{\""name\"": \""f2\"", \""type\"": \""int\""}"" +
        ""]}"";
    Schemas.visit(new Schema.Parser().parse(s10),
        new TestVisitor() {
          public SchemaVisitorAction visitTerminal(Schema terminal) {
            return SchemaVisitorAction.SKIP_SUBTREE;
          }
"
"  @Test
  public void testVisit11() {
    String s11 = ""{\""type\"": \""record\"", \""name\"": \""c1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": {\""type\"": \""record\"", \""name\"": \""c2\"", \""fields\"": "" +
        ""[{\""name\"": \""f11\"", \""type\"": \""int\""},{\""name\"": \""f12\"", \""type\"": \""double\""}"" +
        ""]}},"" +
        ""{\""name\"": \""f2\"", \""type\"": \""long\""}"" +
        ""]}"";
    Assert.assertEquals(""c1.c2.\""int\"".!\""long\"".!"", Schemas.visit(new Schema.Parser().parse(s11),
        new TestVisitor() {
          public SchemaVisitorAction visitTerminal(Schema terminal) {
            sb.append(terminal).append('.');
            return SchemaVisitorAction.SKIP_SIBLINGS;
          }
"
"  @Test
  public void testVisit12() {
    String s12 = ""{\""type\"": \""record\"", \""name\"": \""c1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": {\""type\"": \""record\"", \""name\"": \""ct2\"", \""fields\"": "" +
        ""[{\""name\"": \""f11\"", \""type\"": \""int\""}]}},"" +
        ""{\""name\"": \""f2\"", \""type\"": \""long\""}"" +
        ""]}"";
    Assert.assertEquals(""c1.ct2.\""int\""."", Schemas.visit(new Schema.Parser().parse(s12),
        new TestVisitor() {
          public SchemaVisitorAction visitTerminal(Schema terminal) {
            sb.append(terminal).append('.');
            return SchemaVisitorAction.TERMINATE;
          }
"
"  @Test
  public void testVisit13() {
    String s12 = ""{\""type\"": \""int\""}"";
    Assert.assertEquals(""\""int\""."", Schemas.visit(new Schema.Parser().parse(s12),
        new TestVisitor() {
          public SchemaVisitorAction visitTerminal(Schema terminal) {
            sb.append(terminal).append('.');
            return SchemaVisitorAction.SKIP_SIBLINGS;
          }
"
"  @Test
  public void runTests() throws Exception {
    if (! ""run"".equals(TEST_MODE)) return;

    int passed = 0, failed = 0;

    for (GenTest t : tests) {
      try {
        t.run();
        passed++;
      } catch (Exception e) {
        failed++;
        System.err.println(""Failed: "" + t.testName());
        e.printStackTrace(System.err);
      }
    }

    if (failed > 0) {
      fail(String.valueOf(failed) + "" tests failed"");
    }
  }
"
"  @Test
  public void writeTests() throws Exception {
    if (! ""write"".equals(TEST_MODE)) return;

    for (GenTest t : tests) {
      t.write();
    }
  }
"
"  @Test
  public void testResolving() throws ParseException, MalformedURLException, IOException {
    File file = new File(""."");
    String currentWorkPath = file.getAbsolutePath();
    String testIdl = currentWorkPath + File.separator + ""src"" + File.separator + ""test""
        + File.separator + ""idl"" + File.separator + ""cycle.avdl"";
    Idl compiler = new Idl(new File(testIdl));
    Protocol protocol = compiler.CompilationUnit();
    System.out.println(protocol);
    Assert.assertEquals(5, protocol.getTypes().size());
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testIsUnresolvedSchemaError1() {
    // No ""org.apache.avro.compiler.idl.unresolved.name"" property
    Schema s = SchemaBuilder.record(""R"").fields().endRecord();
    SchemaResolver.getUnresolvedSchemaName(s);
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testIsUnresolvedSchemaError2() {
    // No ""UnresolvedSchema"" property
    Schema s = SchemaBuilder.record(""R"")
        .prop(""org.apache.avro.compiler.idl.unresolved.name"", ""x"").fields().endRecord();
    SchemaResolver.getUnresolvedSchemaName(s);
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testIsUnresolvedSchemaError3() {
    // Namespace not ""org.apache.avro.compiler"".
    Schema s = SchemaBuilder.record(""UnresolvedSchema"")
        .prop(""org.apache.avro.compiler.idl.unresolved.name"", ""x"")
        .fields().endRecord();
    SchemaResolver.getUnresolvedSchemaName(s);
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testGetUnresolvedSchemaNameError() {
    Schema s = SchemaBuilder.fixed(""a"").size(10);
    SchemaResolver.getUnresolvedSchemaName(s);
  }
"
"  @Test
  public void testCycleGeneration() throws ParseException, IOException {
    final ClassLoader cl = Thread.currentThread().getContextClassLoader();
    Idl idl = new Idl(cl.getResourceAsStream(""input/cycle.avdl""),
            ""UTF-8"");
    Protocol protocol = idl.CompilationUnit();
    String json = protocol.toString();
    LOG.info(json);

    SpecificCompiler compiler = new SpecificCompiler(protocol);
    compiler.setStringType(GenericData.StringType.String);
    File output = new File(""./target"");
    compiler.compileToDestination(null, output);

    Map<String, Schema> schemas = new HashMap<>();
    for (Schema schema : protocol.getTypes()) {
      final String name = schema.getName();
      schemas.put(name, schema);
    }

    GenericRecordBuilder rb2 = new GenericRecordBuilder(schemas.get(""SampleNode""));
    rb2.set(""count"", 10);
    rb2.set(""subNodes"", Collections.EMPTY_LIST);
    GenericData.Record node = rb2.build();

    GenericRecordBuilder mb = new GenericRecordBuilder(schemas.get(""Method""));
    mb.set(""declaringClass"", ""Test"");
    mb.set(""methodName"", ""test"");
    GenericData.Record method = mb.build();

    GenericRecordBuilder spb = new GenericRecordBuilder(schemas.get(""SamplePair""));
    spb.set(""method"", method);
    spb.set(""node"", node);
    GenericData.Record sp = spb.build();

    GenericRecordBuilder rb = new GenericRecordBuilder(schemas.get(""SampleNode""));
    rb.set(""count"", 10);
    rb.set(""subNodes"", Arrays.asList(sp));
    GenericData.Record record = rb.build();

    serDeserRecord(record);

  }
"
"  @Test
  public void withoutSchemaMigration() throws IOException {
    FullRecordV1 src = new FullRecordV1(true, 87231, 731L, 54.2832F, 38.321, ""Hi there"", null);
    Assert.assertTrue(""Test schema must allow for custom coders."",
                      ((SpecificRecordBase)src).hasCustomCoders());

    ByteArrayOutputStream out = new ByteArrayOutputStream(1024);
    Encoder e = EncoderFactory.get().directBinaryEncoder(out, null);
    DatumWriter<FullRecordV1> w = (DatumWriter<FullRecordV1>)MODEL.createDatumWriter(V1S);
    w.write(src, e);
    e.flush();

    ByteArrayInputStream in = new ByteArrayInputStream(out.toByteArray());
    Decoder d = DecoderFactory.get().directBinaryDecoder(in, null);
    DatumReader<FullRecordV1> r = (DatumReader<FullRecordV1>)MODEL.createDatumReader(V1S);
    FullRecordV1 dst = r.read(null, d);

    Assert.assertEquals(src, dst);
  }
"
"  @Test
  public void withSchemaMigration() throws IOException {
    FullRecordV2 src = new FullRecordV2(true, 731, 87231, 38L, 54.2832F, ""Hi there"",
                                        ByteBuffer.wrap(Utf8.getBytesFor(""Hello, world!"")));
    Assert.assertTrue(""Test schema must allow for custom coders."",
                      ((SpecificRecordBase)src).hasCustomCoders());

    ByteArrayOutputStream out = new ByteArrayOutputStream(1024);
    Encoder e = EncoderFactory.get().directBinaryEncoder(out, null);
    DatumWriter<FullRecordV2> w = (DatumWriter<FullRecordV2>)MODEL.createDatumWriter(V2S);
    w.write(src, e);
    e.flush();

    ByteArrayInputStream in = new ByteArrayInputStream(out.toByteArray());
    Decoder d = DecoderFactory.get().directBinaryDecoder(in, null);
    DatumReader<FullRecordV1> r = (DatumReader<FullRecordV1>)MODEL.createDatumReader(V2S, V1S);
    FullRecordV1 dst = r.read(null, d);

    FullRecordV1 expected = new FullRecordV1(true, 87231, 731L, 54.2832F, 38.0, null,
                                             ""Hello, world!"");
    Assert.assertEquals(expected, dst);
  }
"
"  @Test
  public void testSetSyncInterval() {
    JobConf jobConf = new JobConf();
    int newSyncInterval = 100000;
    AvroOutputFormat.setSyncInterval(jobConf, newSyncInterval);

    assertEquals(newSyncInterval, jobConf.getInt(
            AvroOutputFormat.SYNC_INTERVAL_KEY, -1));
  }
"
"  @Test
  public void testNoCodec() {
    JobConf job = new JobConf();
    assertNull(AvroOutputFormat.getCodecFactory(job));

    job = new JobConf();
    job.set(""mapred.output.compress"", ""false"");
    job.set(""mapred.output.compression.codec"", ""org.apache.hadoop.io.compress.BZip2Codec"");
    assertNull(AvroOutputFormat.getCodecFactory(job));

    job = new JobConf();
    job.set(""mapred.output.compress"", ""false"");
    job.set(AvroJob.OUTPUT_CODEC, ""bzip2"");
    assertNull(AvroOutputFormat.getCodecFactory(job));
  }
"
"  @Test
  public void testBZip2CodecUsingHadoopClass() {
    CodecFactory avroBZip2Codec = CodecFactory.fromString(""bzip2"");

    JobConf job = new JobConf();
    job.set(""mapred.output.compress"", ""true"");
    job.set(""mapred.output.compression.codec"", ""org.apache.hadoop.io.compress.BZip2Codec"");
    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
    assertNotNull(factory);
    assertEquals(factory.getClass(), avroBZip2Codec.getClass());
  }
"
"  @Test
  public void testBZip2CodecUsingAvroCodec() {
    CodecFactory avroBZip2Codec = CodecFactory.fromString(""bzip2"");

    JobConf job = new JobConf();
    job.set(""mapred.output.compress"", ""true"");
    job.set(AvroJob.OUTPUT_CODEC, ""bzip2"");
    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
    assertNotNull(factory);
    assertEquals(factory.getClass(), avroBZip2Codec.getClass());
  }
"
"  @Test
  public void testDeflateCodecUsingHadoopClass() {
    CodecFactory avroDeflateCodec = CodecFactory.fromString(""deflate"");

    JobConf job = new JobConf();
    job.set(""mapred.output.compress"", ""true"");
    job.set(""mapred.output.compression.codec"", ""org.apache.hadoop.io.compress.DeflateCodec"");
    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
    assertNotNull(factory);
    assertEquals(factory.getClass(), avroDeflateCodec.getClass());
  }
"
"  @Test
  public void testDeflateCodecUsingAvroCodec() {
    CodecFactory avroDeflateCodec = CodecFactory.fromString(""deflate"");

    JobConf job = new JobConf();
    job.set(""mapred.output.compress"", ""true"");
    job.set(AvroJob.OUTPUT_CODEC, ""deflate"");
    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
    assertNotNull(factory);
    assertEquals(factory.getClass(), avroDeflateCodec.getClass());
  }
"
"  @Test
  public void testSnappyCodecUsingHadoopClass() {
    CodecFactory avroSnappyCodec = CodecFactory.fromString(""snappy"");

    JobConf job = new JobConf();
    job.set(""mapred.output.compress"", ""true"");
    job.set(""mapred.output.compression.codec"", ""org.apache.hadoop.io.compress.SnappyCodec"");
    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
    assertNotNull(factory);
    assertEquals(factory.getClass(), avroSnappyCodec.getClass());
  }
"
"  @Test
  public void testSnappyCodecUsingAvroCodec() {
    CodecFactory avroSnappyCodec = CodecFactory.fromString(""snappy"");

    JobConf job = new JobConf();
    job.set(""mapred.output.compress"", ""true"");
    job.set(AvroJob.OUTPUT_CODEC, ""snappy"");
    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
    assertNotNull(factory);
    assertEquals(factory.getClass(), avroSnappyCodec.getClass());
  }
"
"  @Test
  public void testGZipCodecUsingHadoopClass() {
    CodecFactory avroDeflateCodec = CodecFactory.fromString(""deflate"");

    JobConf job = new JobConf();
    job.set(""mapred.output.compress"", ""true"");
    job.set(""mapred.output.compression.codec"", ""org.apache.hadoop.io.compress.GZipCodec"");
    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
    assertNotNull(factory);
    assertEquals(factory.getClass(), avroDeflateCodec.getClass());
  }
"
"  @Test
  public void testJob() throws Exception {
    JobConf job = new JobConf();
    String dir = ""target/testReflectJob"";
    Path inputPath = new Path(dir + ""/in"");
    Path outputPath = new Path(dir + ""/out"");

    outputPath.getFileSystem(job).delete(outputPath);
    inputPath.getFileSystem(job).delete(inputPath);

    writeLinesFile(new File(dir+""/in""));

    job.setJobName(""reflect"");

    AvroJob.setInputSchema(job, ReflectData.get().getSchema(Text.class));
    AvroJob.setMapOutputSchema
      (job, new Pair(new Text(""""), new Count(0L)).getSchema());
    AvroJob.setOutputSchema(job, ReflectData.get().getSchema(WordCount.class));

    AvroJob.setMapperClass(job, MapImpl.class);
    //AvroJob.setCombinerClass(job, ReduceImpl.class);
    AvroJob.setReducerClass(job, ReduceImpl.class);

    FileInputFormat.setInputPaths(job, inputPath);
    FileOutputFormat.setOutputPath(job, outputPath);

    AvroJob.setReflect(job); // use reflection

    JobClient.runJob(job);

    validateCountsFile(new File(new File(dir, ""out""), ""part-00000.avro""));
  }
"
"  @Test
  public void testIgnoreFilesWithoutExtension() throws Exception {
    fs.mkdirs(inputDir);
    Path avroFile = new Path(inputDir, ""somefile.avro"");
    Path textFile = new Path(inputDir, ""someotherfile.txt"");
    fs.create(avroFile).close();
    fs.create(textFile).close();

    FileInputFormat.setInputPaths(conf, inputDir);

    AvroInputFormat inputFormat = new AvroInputFormat();
    FileStatus[] statuses = inputFormat.listStatus(conf);
    Assert.assertEquals(1, statuses.length);
    Assert.assertEquals(""somefile.avro"", statuses[0].getPath().getName());

    conf.setBoolean(AvroInputFormat.IGNORE_FILES_WITHOUT_EXTENSION_KEY, false);
    statuses = inputFormat.listStatus(conf);
    Assert.assertEquals(2, statuses.length);
    Set<String> names = new HashSet<>();
    names.add(statuses[0].getPath().getName());
    names.add(statuses[1].getPath().getName());
    Assert.assertTrue(names.contains(""somefile.avro""));
    Assert.assertTrue(names.contains(""someotherfile.txt""));
  }
"
"  @Test
  public void testToString() {
    String datum = ""my string"";
    AvroWrapper<CharSequence> wrapper = new AvroWrapper<>(datum);
    assertEquals(datum, wrapper.toString());
  }
"
"  @Test
  public void runTestsInOrder() throws Exception {
    String pathOut = OUTPUT_DIR.getRoot().getPath();
    testJob(pathOut);
    testProjection(pathOut);
  }
"
"  @Test
  public void testSort() throws Exception {
    JobConf job = new JobConf();
    String inputPath = INPUT_DIR.getRoot().getPath();
    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());
    outputPath.getFileSystem(job).delete(outputPath);

    WordCountUtil.writeLinesBytesFile(inputPath);

    job.setInputFormat(AvroAsTextInputFormat.class);
    job.setOutputFormat(AvroTextOutputFormat.class);
    job.setOutputKeyClass(Text.class);

    FileInputFormat.setInputPaths(job, new Path(inputPath));
    FileOutputFormat.setOutputPath(job, outputPath);

    JobClient.runJob(job);

    WordCountUtil.validateSortedFile(outputPath.toString() + ""/part-00000.avro"");
  }
"
"  @Test
  public void testJob() throws Exception {
    JobConf job = new JobConf();
    Path inputPath1 = new Path(INPUT_DIR_1.getRoot().getPath());
    Path inputPath2 = new Path(INPUT_DIR_2.getRoot().getPath());
    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());

    outputPath.getFileSystem(job).delete(outputPath);

    writeNamesFiles(new File(inputPath1.toUri().getPath()));
    writeBalancesFiles(new File(inputPath2.toUri().getPath()));

    job.setJobName(""multiple-inputs-join"");
    AvroMultipleInputs.addInputPath(job, inputPath1, NamesMapImpl.class,
            ReflectData.get().getSchema(NamesRecord.class));
    AvroMultipleInputs.addInputPath(job, inputPath2, BalancesMapImpl.class,
            ReflectData.get().getSchema(BalancesRecord.class));

    Schema keySchema = ReflectData.get().getSchema(KeyRecord.class);
    Schema valueSchema = ReflectData.get().getSchema(JoinableRecord.class);
    AvroJob.setMapOutputSchema(job,
            Pair.getPairSchema(keySchema, valueSchema));
    AvroJob.setOutputSchema(job,
            ReflectData.get().getSchema(CompleteRecord.class));

    AvroJob.setReducerClass(job, ReduceImpl.class);
    job.setNumReduceTasks(1);

    FileOutputFormat.setOutputPath(job, outputPath);

    AvroJob.setReflect(job);

    JobClient.runJob(job);

    validateCompleteFile(new File(OUTPUT_DIR.getRoot(), ""part-00000.avro""));
  }
"
"  @Test
  public void testAvroTextRecordWriter() throws Exception {
    File file = new File(tmpFolder.getRoot().getPath(), ""writer"");
    Schema schema = Schema.create(Schema.Type.BYTES);
    DatumWriter<ByteBuffer> datumWriter =
      new GenericDatumWriter<>(schema);
    DataFileWriter<ByteBuffer> fileWriter =
      new DataFileWriter<>(datumWriter);
    fileWriter.create(schema, file);
    RecordWriter<Object, Object> rw = new AvroTextOutputFormat<>()
      .new AvroTextRecordWriter(fileWriter, ""\t"".getBytes(UTF8));

    rw.write(null, null);
    rw.write(null, NullWritable.get());
    rw.write(NullWritable.get(), null);
    rw.write(NullWritable.get(), NullWritable.get());

    rw.write(""k1"", null);
    rw.write(""k2"", NullWritable.get());

    rw.write(null, ""v1"");
    rw.write(NullWritable.get(), ""v2"");

    rw.write(""k3"", ""v3"");
    rw.write(new Text(""k4""), new Text(""v4""));

    rw.close(null);

    DatumReader<ByteBuffer> reader = new GenericDatumReader<>();
    DataFileReader<ByteBuffer> fileReader =
      new DataFileReader<>(file, reader);
    assertEquals(""k1"", asString(fileReader.next()));
    assertEquals(""k2"", asString(fileReader.next()));
    assertEquals(""v1"", asString(fileReader.next()));
    assertEquals(""v2"", asString(fileReader.next()));
    assertEquals(""k3\tv3"", asString(fileReader.next()));
    assertEquals(""k4\tv4"", asString(fileReader.next()));
    assertFalse(""End"", fileReader.hasNext());
  }
"
"  @Test
  public void runTestsInOrder() throws Exception {
    String avroPath = OUTPUT_DIR.getRoot().getPath();
    testJob(avroPath);
    testProjection(avroPath);
    testProjectionNewMethodsOne(avroPath);
    testProjectionNewMethodsTwo(avroPath);
    testProjection1(avroPath);
    testJobNoreducer();
    testProjectionNoreducer(avroPath);
  }
"
"  @Test
  public void testReadSequenceFile() throws Exception {
    checkFile(new SequenceFileReader<>(file()));
  }
"
"  @Test
  public void testSequenceFileInputFormat() throws Exception {
    JobConf job = new JobConf();
    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());
    outputPath.getFileSystem(job).delete(outputPath);

    // configure input for Avro from sequence file
    AvroJob.setInputSequenceFile(job);
    FileInputFormat.setInputPaths(job, file().toURI().toString());
    AvroJob.setInputSchema(job, SCHEMA);

    // mapper is default, identity
    // reducer is default, identity

    // configure output for avro
    AvroJob.setOutputSchema(job, SCHEMA);
    FileOutputFormat.setOutputPath(job, outputPath);

    JobClient.runJob(job);

    checkFile(new DataFileReader<>
              (new File(outputPath.toString() + ""/part-00000.avro""),
               new SpecificDatumReader<>()));
  }
"
"  @Test
  public void testNonAvroMapper() throws Exception {
    JobConf job = new JobConf();
    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());
    outputPath.getFileSystem(job).delete(outputPath);

    // configure input for non-Avro sequence file
    job.setInputFormat(SequenceFileInputFormat.class);
    FileInputFormat.setInputPaths(job, file().toURI().toString());

    // use a hadoop mapper that emits Avro output
    job.setMapperClass(NonAvroMapper.class);

    // reducer is default, identity

    // configure output for avro
    FileOutputFormat.setOutputPath(job, outputPath);
    AvroJob.setOutputSchema(job, SCHEMA);

    JobClient.runJob(job);

    checkFile(new DataFileReader<>
              (new File(outputPath.toString() + ""/part-00000.avro""),
               new SpecificDatumReader<>()));
  }
"
"  @Test
  public void testNonAvroMapOnly() throws Exception {
    JobConf job = new JobConf();
    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());
    outputPath.getFileSystem(job).delete(outputPath);

    // configure input for non-Avro sequence file
    job.setInputFormat(SequenceFileInputFormat.class);
    FileInputFormat.setInputPaths(job, file().toURI().toString());

    // use a hadoop mapper that emits Avro output
    job.setMapperClass(NonAvroOnlyMapper.class);

    // configure output for avro
    job.setNumReduceTasks(0);                     // map-only
    FileOutputFormat.setOutputPath(job, outputPath);
    AvroJob.setOutputSchema(job, SCHEMA);

    JobClient.runJob(job);

    checkFile(new DataFileReader<>
              (new File(outputPath.toString() + ""/part-00000.avro""),
               new SpecificDatumReader<>()));
  }
"
"  @Test
  public void testNonAvroReducer() throws Exception {
    JobConf job = new JobConf();
    Path outputPath = new Path(OUTPUT_DIR.getRoot().getPath());
    outputPath.getFileSystem(job).delete(outputPath);

    // configure input for Avro from sequence file
    AvroJob.setInputSequenceFile(job);
    AvroJob.setInputSchema(job, SCHEMA);
    FileInputFormat.setInputPaths(job, file().toURI().toString());

    // mapper is default, identity

    // use a hadoop reducer that consumes Avro input
    AvroJob.setMapOutputSchema(job, SCHEMA);
    job.setReducerClass(NonAvroReducer.class);

    // configure outputPath for non-Avro SequenceFile
    job.setOutputFormat(SequenceFileOutputFormat.class);
    FileOutputFormat.setOutputPath(job, outputPath);

    // output key/value classes are default, LongWritable/Text

    JobClient.runJob(job);

    checkFile(new SequenceFileReader<>
              (new File(outputPath.toString() + ""/part-00000"")));
  }
"
"  @Test
  public void testMapOnly() throws Exception {
    JobConf job = new JobConf();
    String inDir = System.getProperty(""share.dir"",""../../../share"")+""/test/data"";
    Path input = new Path(inDir+""/weather.avro"");
    Path output = new Path(""target/test/weather-ident"");

    output.getFileSystem(job).delete(output);

    job.setJobName(""identity map weather"");

    AvroJob.setInputSchema(job, Weather.SCHEMA$);
    AvroJob.setOutputSchema(job, Weather.SCHEMA$);

    FileInputFormat.setInputPaths(job, input);
    FileOutputFormat.setOutputPath(job, output);
    FileOutputFormat.setCompressOutput(job, true);

    job.setNumReduceTasks(0);                     // map-only

    JobClient.runJob(job);

    // check output is correct
    DatumReader<Weather> reader = new SpecificDatumReader<>();
    DataFileReader<Weather> check = new DataFileReader<>
      (new File(inDir + ""/weather.avro""), reader);
    DataFileReader<Weather> sorted = new DataFileReader<>
      (new File(output.toString() + ""/part-00000.avro""), reader);

    for (Weather w : sorted)
      assertEquals(check.next(), w);

    check.close();
    sorted.close();
  }
"
"  @Test
  public void testSort() throws Exception {
    JobConf job = new JobConf();
    String inDir = ""../../../share/test/data"";
    Path input = new Path(inDir+""/weather.avro"");
    Path output = new Path(""target/test/weather-sort"");

    output.getFileSystem(job).delete(output);

    job.setJobName(""sort weather"");

    AvroJob.setInputSchema(job, Weather.SCHEMA$);
    AvroJob.setMapOutputSchema
      (job, Pair.getPairSchema(Weather.SCHEMA$, Schema.create(Type.NULL)));
    AvroJob.setOutputSchema(job, Weather.SCHEMA$);

    AvroJob.setMapperClass(job, SortMapper.class);
    AvroJob.setReducerClass(job, SortReducer.class);

    FileInputFormat.setInputPaths(job, input);
    FileOutputFormat.setOutputPath(job, output);
    FileOutputFormat.setCompressOutput(job, true);
    AvroJob.setOutputCodec(job, SNAPPY_CODEC);

    JobClient.runJob(job);

    // check output is correct
    DatumReader<Weather> reader = new SpecificDatumReader<>();
    DataFileReader<Weather> check = new DataFileReader<>
      (new File(inDir + ""/weather-sorted.avro""), reader);
    DataFileReader<Weather> sorted = new DataFileReader<>
      (new File(output.toString() + ""/part-00000.avro""), reader);

    for (Weather w : sorted)
      assertEquals(check.next(), w);

    check.close();
    sorted.close();

    // check that AvroMapper and AvroReducer get close() and configure() called
    assertEquals(1, mapCloseCalls.get());
    assertEquals(1, reducerCloseCalls.get());
    assertEquals(1, mapConfigureCalls.get());
    assertEquals(1, reducerConfigureCalls.get());


  }
"
"  @Test
    public void testJob() throws Exception {
    JobConf job = new JobConf();
    Path outputPath = new Path(DIR.getRoot().getPath() + ""/out"");
    outputPath.getFileSystem(job).delete(outputPath);

    job.setInputFormat(TextInputFormat.class);
    FileInputFormat.setInputPaths(job, DIR.getRoot().getPath() + ""/in"");

    job.setMapperClass(AvroTestConverter.class);
    job.setNumReduceTasks(0);

    FileOutputFormat.setOutputPath(job, outputPath);
    System.out.println(createSchema());
    AvroJob.setOutputSchema(job,
                            Pair.getPairSchema(Schema.create(Schema.Type.LONG),
                                               createSchema()));
    job.setOutputFormat(AvroOutputFormat.class);

    JobClient.runJob(job);
  }
"
"  @Test
  public void testJob() throws Exception {
    _runjob(""sasl"");
  }
"
"  @Test
  public void testhtp() throws Exception {
    _runjob(""http"");
  }
"
"  @Test(expected=IllegalArgumentException.class)
  public void testWriteOutOfSortedOrder() throws IOException {
    LOG.debug(""Writing some records to a SortedKeyValueFile..."");

    Configuration conf = new Configuration();
    SortedKeyValueFile.Writer.Options options = new SortedKeyValueFile.Writer.Options()
        .withKeySchema(Schema.create(Schema.Type.STRING))
        .withValueSchema(Schema.create(Schema.Type.STRING))
        .withConfiguration(conf)
        .withPath(new Path(mTempDir.getRoot().getPath(), ""myfile""))
        .withIndexInterval(2);  // Index every other record.

    SortedKeyValueFile.Writer<CharSequence, CharSequence> writer
        = new SortedKeyValueFile.Writer<>(options);

    Utf8 key = new Utf8();                        // re-use key, to test copied

    try {
      writer.append(key.set(""banana""), ""Banana"");
      writer.append(key.set(""apple""), ""Apple"");  // Ruh, roh!
    } finally {
      writer.close();
    }
  }
"
"  @Test
  public void testNamedCodecs() throws IOException {
    Configuration conf = new Configuration();
    Path myfile = new Path(mTempDir.getRoot().getPath(), ""myfile"");
    Schema key = Schema.create(Schema.Type.STRING);
    Schema value = Schema.create(Schema.Type.STRING);
    Schema recordSchema = AvroKeyValue.getSchema(key, value);
    DatumReader<GenericRecord> datumReader = SpecificData.get().createDatumReader(recordSchema);
    DataFileReader<GenericRecord> reader;

    SortedKeyValueFile.Writer.Options options = new SortedKeyValueFile.Writer.Options()
        .withKeySchema(key)
        .withValueSchema(value)
        .withConfiguration(conf)
        .withPath(myfile);

    SortedKeyValueFile.Writer<CharSequence, CharSequence> writer;

    for(String codec : new String[]{""null"", ""deflate"", ""snappy"", ""bzip2""}) {
        LOG.debug(""Using "" + codec + ""codec for a SortedKeyValueFile..."");

        options.withCodec(codec);

        writer = new SortedKeyValueFile.Writer<>(options);
        writer.close();

        reader = new DataFileReader<>(
            new FsInput(new Path(myfile, SortedKeyValueFile.DATA_FILENAME), conf),
            datumReader);

        assertEquals(codec, reader.getMetaString(""avro.codec""));
        reader.close();
    }
  }
"
"  @Test
  public void testDeflateClassCodec() throws IOException {
    Configuration conf = new Configuration();
    Path myfile = new Path(mTempDir.getRoot().getPath(), ""myfile"");
    Schema key = Schema.create(Schema.Type.STRING);
    Schema value = Schema.create(Schema.Type.STRING);
    Schema recordSchema = AvroKeyValue.getSchema(key, value);
    DatumReader<GenericRecord> datumReader = SpecificData.get().createDatumReader(recordSchema);
    DataFileReader<GenericRecord> reader;

    LOG.debug(""Using CodecFactory.deflateCodec() for a SortedKeyValueFile..."");
    SortedKeyValueFile.Writer.Options options = new SortedKeyValueFile.Writer.Options()
        .withKeySchema(key)
        .withValueSchema(value)
        .withConfiguration(conf)
        .withPath(myfile)
        .withCodec(CodecFactory.deflateCodec(9));

    SortedKeyValueFile.Writer<CharSequence, CharSequence> writer =
        new SortedKeyValueFile.Writer<>(options);
    writer.close();

    reader = new DataFileReader<>(
        new FsInput(new Path(myfile, SortedKeyValueFile.DATA_FILENAME), conf),
        datumReader);

    assertEquals(""deflate"", reader.getMetaString(""avro.codec""));
    reader.close();
  }
"
"  @Test
  public void testBadCodec() throws IOException {
    LOG.debug(""Using a bad codec for a SortedKeyValueFile..."");

    try {
      SortedKeyValueFile.Writer.Options options =
          new SortedKeyValueFile.Writer.Options().withCodec(""foobar"");
    } catch (AvroRuntimeException e) {
        assertEquals(""Unrecognized codec: foobar"", e.getMessage());
    }
  }
"
"  @Test
  public void testWriter() throws IOException {
    LOG.debug(""Writing some records to a SortedKeyValueFile..."");

    Configuration conf = new Configuration();
    SortedKeyValueFile.Writer.Options options = new SortedKeyValueFile.Writer.Options()
        .withKeySchema(Schema.create(Schema.Type.STRING))
        .withValueSchema(Schema.create(Schema.Type.STRING))
        .withConfiguration(conf)
        .withPath(new Path(mTempDir.getRoot().getPath(), ""myfile""))
        .withIndexInterval(2);  // Index every other record.

    SortedKeyValueFile.Writer<CharSequence, CharSequence> writer
        = new SortedKeyValueFile.Writer<>(options);

    try {
      writer.append(""apple"", ""Apple"");  // Will be indexed.
      writer.append(""banana"", ""Banana"");
      writer.append(""carrot"", ""Carrot"");  // Will be indexed.
      writer.append(""durian"", ""Durian"");
    } finally {
      writer.close();
    }


    LOG.debug(""Checking the generated directory..."");
    File directory = new File(mTempDir.getRoot().getPath(), ""myfile"");
    assertTrue(directory.exists());


    LOG.debug(""Checking the generated index file..."");
    File indexFile = new File(directory, SortedKeyValueFile.INDEX_FILENAME);
    DatumReader<GenericRecord> indexReader = new GenericDatumReader<>(
        AvroKeyValue.getSchema(options.getKeySchema(), Schema.create(Schema.Type.LONG)));
    FileReader<GenericRecord> indexFileReader = DataFileReader.openReader(indexFile, indexReader);

    List<AvroKeyValue<CharSequence, Long>> indexRecords
        = new ArrayList<>();
    try {
      for (GenericRecord indexRecord : indexFileReader) {
        indexRecords.add(new AvroKeyValue<>(indexRecord));
      }
    } finally {
      indexFileReader.close();
    }

    assertEquals(2, indexRecords.size());
    assertEquals(""apple"", indexRecords.get(0).getKey().toString());
    LOG.debug(""apple's position in the file: "" + indexRecords.get(0).getValue());
    assertEquals(""carrot"", indexRecords.get(1).getKey().toString());
    LOG.debug(""carrot's position in the file: "" + indexRecords.get(1).getValue());

    LOG.debug(""Checking the generated data file..."");
    File dataFile = new File(directory, SortedKeyValueFile.DATA_FILENAME);
    DatumReader<GenericRecord> dataReader = new GenericDatumReader<>(
        AvroKeyValue.getSchema(options.getKeySchema(), options.getValueSchema()));
    DataFileReader<GenericRecord> dataFileReader
        = new DataFileReader<>(dataFile, dataReader);

    try {
      dataFileReader.seek(indexRecords.get(0).getValue());
      assertTrue(dataFileReader.hasNext());
      AvroKeyValue<CharSequence, CharSequence> appleRecord
          = new AvroKeyValue<>(dataFileReader.next());
      assertEquals(""apple"", appleRecord.getKey().toString());
      assertEquals(""Apple"", appleRecord.getValue().toString());

      dataFileReader.seek(indexRecords.get(1).getValue());
      assertTrue(dataFileReader.hasNext());
      AvroKeyValue<CharSequence, CharSequence> carrotRecord
          = new AvroKeyValue<>(dataFileReader.next());
      assertEquals(""carrot"", carrotRecord.getKey().toString());
      assertEquals(""Carrot"", carrotRecord.getValue().toString());

      assertTrue(dataFileReader.hasNext());
      AvroKeyValue<CharSequence, CharSequence> durianRecord
          = new AvroKeyValue<>(dataFileReader.next());
      assertEquals(""durian"", durianRecord.getKey().toString());
      assertEquals(""Durian"", durianRecord.getValue().toString());
    } finally {
      dataFileReader.close();
    }
  }
"
"  @Test
  public void testReader() throws IOException {
    Configuration conf = new Configuration();
    SortedKeyValueFile.Writer.Options writerOptions = new SortedKeyValueFile.Writer.Options()
        .withKeySchema(Schema.create(Schema.Type.STRING))
        .withValueSchema(Schema.create(Schema.Type.STRING))
        .withConfiguration(conf)
        .withPath(new Path(mTempDir.getRoot().getPath(), ""myfile""))
        .withIndexInterval(2);  // Index every other record.

    SortedKeyValueFile.Writer<CharSequence, CharSequence> writer
        = new SortedKeyValueFile.Writer<>(writerOptions);

    try {
      writer.append(""apple"", ""Apple"");  // Will be indexed.
      writer.append(""banana"", ""Banana"");
      writer.append(""carrot"", ""Carrot"");  // Will be indexed.
      writer.append(""durian"", ""Durian"");
    } finally {
      writer.close();
    }

    LOG.debug(""Reading the file back using a reader..."");
    SortedKeyValueFile.Reader.Options readerOptions = new SortedKeyValueFile.Reader.Options()
        .withKeySchema(Schema.create(Schema.Type.STRING))
        .withValueSchema(Schema.create(Schema.Type.STRING))
        .withConfiguration(conf)
        .withPath(new Path(mTempDir.getRoot().getPath(), ""myfile""));

    SortedKeyValueFile.Reader<CharSequence, CharSequence> reader
        = new SortedKeyValueFile.Reader<>(readerOptions);

    try {
      assertEquals(""Carrot"", reader.get(""carrot"").toString());
      assertEquals(""Banana"", reader.get(""banana"").toString());
      assertNull(reader.get(""a-vegetable""));
      assertNull(reader.get(""beet""));
      assertNull(reader.get(""zzz""));
    } finally {
      reader.close();
    }
  }
"
"  @Test
  public void testHadoopCodecFactoryDeflate(){
    CodecFactory hadoopDeflateCodec = HadoopCodecFactory.fromHadoopString(""org.apache.hadoop.io.compress.DeflateCodec"");
    CodecFactory avroDeflateCodec = CodecFactory.fromString(""deflate"");
    assertTrue(hadoopDeflateCodec.getClass().equals(avroDeflateCodec.getClass()));
  }
"
"  @Test
  public void testHadoopCodecFactorySnappy(){
    CodecFactory hadoopSnappyCodec = HadoopCodecFactory.fromHadoopString(""org.apache.hadoop.io.compress.SnappyCodec"");
    CodecFactory avroSnappyCodec = CodecFactory.fromString(""snappy"");
    assertTrue(hadoopSnappyCodec.getClass().equals(avroSnappyCodec.getClass()));
  }
"
"  @Test
  public void testHadoopCodecFactoryBZip2(){
    CodecFactory hadoopSnappyCodec = HadoopCodecFactory.fromHadoopString(""org.apache.hadoop.io.compress.BZip2Codec"");
    CodecFactory avroSnappyCodec = CodecFactory.fromString(""bzip2"");
    assertTrue(hadoopSnappyCodec.getClass().equals(avroSnappyCodec.getClass()));
  }
"
"  @Test
  public void testHadoopCodecFactoryGZip(){
    CodecFactory hadoopSnappyCodec = HadoopCodecFactory.fromHadoopString(""org.apache.hadoop.io.compress.GZipCodec"");
    CodecFactory avroSnappyCodec = CodecFactory.fromString(""deflate"");
    assertTrue(hadoopSnappyCodec.getClass().equals(avroSnappyCodec.getClass()));
  }
"
"  @Test
  public void testHadoopCodecFactoryFail(){
    CodecFactory hadoopSnappyCodec = HadoopCodecFactory.fromHadoopString(""org.apache.hadoop.io.compress.FooCodec"");
    assertTrue(hadoopSnappyCodec == null);
  }
"
"  @Test
  public void testCompareString() {
    assertEquals(0, mComparator.compare("""", """"));
    assertThat(mComparator.compare("""", ""a""), lessThan(0));
    assertThat(mComparator.compare(""a"", """"), greaterThan(0));

    assertEquals(0, mComparator.compare(""a"", ""a""));
    assertThat(mComparator.compare(""a"", ""b""), lessThan(0));
    assertThat(mComparator.compare(""b"", ""a""), greaterThan(0));

    assertEquals(0, mComparator.compare(""ab"", ""ab""));
    assertThat(mComparator.compare(""a"", ""aa""), lessThan(0));
    assertThat(mComparator.compare(""aa"", ""a""), greaterThan(0));

    assertThat(mComparator.compare(""abc"", ""abcdef""), lessThan(0));
    assertThat(mComparator.compare(""abcdef"", ""abc""), greaterThan(0));
  }
"
"  @Test
  public void testCompareUtf8() {
    assertEquals(0, mComparator.compare(new Utf8(""""), new Utf8("""")));
    assertThat(mComparator.compare(new Utf8(""""), new Utf8(""a"")), lessThan(0));
    assertThat(mComparator.compare(new Utf8(""a""), new Utf8("""")), greaterThan(0));

    assertEquals(0, mComparator.compare(new Utf8(""a""), new Utf8(""a"")));
    assertThat(mComparator.compare(new Utf8(""a""), new Utf8(""b"")), lessThan(0));
    assertThat(mComparator.compare(new Utf8(""b""), new Utf8(""a"")), greaterThan(0));

    assertEquals(0, mComparator.compare(new Utf8(""ab""), new Utf8(""ab"")));
    assertThat(mComparator.compare(new Utf8(""a""), new Utf8(""aa"")), lessThan(0));
    assertThat(mComparator.compare(new Utf8(""aa""), new Utf8(""a"")), greaterThan(0));

    assertThat(mComparator.compare(new Utf8(""abc""), new Utf8(""abcdef"")), lessThan(0));
    assertThat(mComparator.compare(new Utf8(""abcdef""), new Utf8(""abc"")), greaterThan(0));
  }
"
"  @Test
  public void testCompareUtf8ToString() {
    assertEquals(0, mComparator.compare(new Utf8(""""), """"));
    assertThat(mComparator.compare(new Utf8(""""), ""a""), lessThan(0));
    assertThat(mComparator.compare(new Utf8(""a""), """"), greaterThan(0));

    assertEquals(0, mComparator.compare(new Utf8(""a""), ""a""));
    assertThat(mComparator.compare(new Utf8(""a""), ""b""), lessThan(0));
    assertThat(mComparator.compare(new Utf8(""b""), ""a""), greaterThan(0));

    assertEquals(0, mComparator.compare(new Utf8(""ab""), ""ab""));
    assertThat(mComparator.compare(new Utf8(""a""), ""aa""), lessThan(0));
    assertThat(mComparator.compare(new Utf8(""aa""), ""a""), greaterThan(0));

    assertThat(mComparator.compare(new Utf8(""abc""), ""abcdef""), lessThan(0));
    assertThat(mComparator.compare(new Utf8(""abcdef""), ""abc""), greaterThan(0));
  }
"
"  @Test
  public void testSerialize() throws IOException {
    // Create a serializer.
    Schema writerSchema = Schema.create(Schema.Type.STRING);
    AvroSerializer<CharSequence> serializer = new AvroSerializer<>(writerSchema);

    // Check the writer schema.
    assertEquals(writerSchema, serializer.getWriterSchema());

    // Serialize two records, 'record1' and 'record2'.
    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
    serializer.open(outputStream);
    serializer.serialize(new AvroKey<>(""record1""));
    serializer.serialize(new AvroKey<>(""record2""));
    serializer.close();

    // Make sure the records were serialized correctly.
    ByteArrayInputStream inputStream = new ByteArrayInputStream(outputStream.toByteArray());
    Schema readerSchema = Schema.create(Schema.Type.STRING);
    DatumReader<CharSequence> datumReader = new GenericDatumReader<>(readerSchema);
    Decoder decoder = DecoderFactory.get().binaryDecoder(inputStream, null);
    CharSequence record = null;

    record = datumReader.read(record, decoder);
    assertEquals(""record1"", record.toString());

    record = datumReader.read(record, decoder);
    assertEquals(""record2"", record.toString());

    inputStream.close();
  }
"
"  @Test
  public void testDeserialize() throws IOException {
    // Create a deserializer.
    Schema writerSchema = Schema.create(Schema.Type.STRING);
    Schema readerSchema = Schema.create(Schema.Type.STRING);
    ClassLoader classLoader = this.getClass().getClassLoader();
    AvroKeyDeserializer<CharSequence> deserializer =
        new AvroKeyDeserializer<>(writerSchema, readerSchema, classLoader);

    // Check the schemas.
    assertEquals(writerSchema, deserializer.getWriterSchema());
    assertEquals(readerSchema, deserializer.getReaderSchema());

    // Write some records to deserialize.
    DatumWriter<CharSequence> datumWriter = new GenericDatumWriter<>(writerSchema);
    ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
    Encoder encoder = EncoderFactory.get().binaryEncoder(outputStream, null);
    datumWriter.write(""record1"", encoder);
    datumWriter.write(""record2"", encoder);
    encoder.flush();

    // Deserialize the records.
    ByteArrayInputStream inputStream = new ByteArrayInputStream(outputStream.toByteArray());
    deserializer.open(inputStream);
    AvroWrapper<CharSequence> record = null;

    record = deserializer.deserialize(record);
    assertEquals(""record1"", record.datum().toString());

    record = deserializer.deserialize(record);
    assertEquals(""record2"", record.datum().toString());

    deserializer.close();
  }
"
"  @Test
  public void testAccept() {
    AvroSerialization<CharSequence> serialization = new AvroSerialization<>();

    assertTrue(serialization.accept(AvroKey.class));
    assertTrue(serialization.accept(AvroValue.class));
    assertFalse(serialization.accept(AvroWrapper.class));
    assertFalse(serialization.accept(String.class));
  }
"
"  @Test
  public void testGetSerializerForKey() throws IOException {
    // Set the writer schema in the job configuration.
    Schema writerSchema = Schema.create(Schema.Type.STRING);
    Job job = new Job();
    AvroJob.setMapOutputKeySchema(job, writerSchema);

    // Get a serializer from the configuration.
    AvroSerialization serialization
        = ReflectionUtils.newInstance(AvroSerialization.class, job.getConfiguration());
    @SuppressWarnings(""unchecked"")
    Serializer<AvroWrapper> serializer = serialization.getSerializer(AvroKey.class);
    assertTrue(serializer instanceof AvroSerializer);
    AvroSerializer avroSerializer = (AvroSerializer) serializer;

    // Check that the writer schema is set correctly on the serializer.
    assertEquals(writerSchema, avroSerializer.getWriterSchema());
  }
"
"  @Test
  public void testGetSerializerForValue() throws IOException {
    // Set the writer schema in the job configuration.
    Schema writerSchema = Schema.create(Schema.Type.STRING);
    Job job = new Job();
    AvroJob.setMapOutputValueSchema(job, writerSchema);

    // Get a serializer from the configuration.
    AvroSerialization serialization
        = ReflectionUtils.newInstance(AvroSerialization.class, job.getConfiguration());
    @SuppressWarnings(""unchecked"")
    Serializer<AvroWrapper> serializer = serialization.getSerializer(AvroValue.class);
    assertTrue(serializer instanceof AvroSerializer);
    AvroSerializer avroSerializer = (AvroSerializer) serializer;

    // Check that the writer schema is set correctly on the serializer.
    assertEquals(writerSchema, avroSerializer.getWriterSchema());
  }
"
"  @Test
  public void testGetDeserializerForKey() throws IOException {
    // Set the reader schema in the job configuration.
    Schema readerSchema = Schema.create(Schema.Type.STRING);
    Job job = new Job();
    AvroJob.setMapOutputKeySchema(job, readerSchema);

    // Get a deserializer from the configuration.
    AvroSerialization serialization
        = ReflectionUtils.newInstance(AvroSerialization.class, job.getConfiguration());
    @SuppressWarnings(""unchecked"")
    Deserializer<AvroWrapper> deserializer = serialization.getDeserializer(AvroKey.class);
    assertTrue(deserializer instanceof AvroKeyDeserializer);
    AvroKeyDeserializer avroDeserializer = (AvroKeyDeserializer) deserializer;

    // Check that the reader schema is set correctly on the deserializer.
    assertEquals(readerSchema, avroDeserializer.getReaderSchema());
  }
"
"  @Test
  public void testGetDeserializerForValue() throws IOException {
    // Set the reader schema in the job configuration.
    Schema readerSchema = Schema.create(Schema.Type.STRING);
    Job job = new Job();
    AvroJob.setMapOutputValueSchema(job, readerSchema);

    // Get a deserializer from the configuration.
    AvroSerialization serialization
        = ReflectionUtils.newInstance(AvroSerialization.class, job.getConfiguration());
    @SuppressWarnings(""unchecked"")
    Deserializer<AvroWrapper> deserializer = serialization.getDeserializer(AvroValue.class);
    assertTrue(deserializer instanceof AvroValueDeserializer);
    AvroValueDeserializer avroDeserializer = (AvroValueDeserializer) deserializer;

    // Check that the reader schema is set correctly on the deserializer.
    assertEquals(readerSchema, avroDeserializer.getReaderSchema());
  }
"
"  @Test
  public void testRoundTrip() throws Exception {
    Schema schema = Schema.create(Schema.Type.STRING);
    assertTrue(roundTrip(schema, ""record"", null) instanceof String);
    assertTrue(roundTrip(schema, ""record"", GenericData.class) instanceof Utf8);
  }
"
"    @Test
    public void testZipObservableOfObservables() {
        EventStream.getEventStream(""HTTP-ClusterB"", 20)
                .groupBy(new Func1<Event, String>() {

                    @Override
                    public String call(Event e) {
                        return e.instanceId;
                    }
"
"    @Test
    public void testCovarianceOfZip() {
        Observable<HorrorMovie> horrors = Observable.from(new HorrorMovie());
        Observable<CoolRating> ratings = Observable.from(new CoolRating());

        Observable.<Movie, CoolRating, Result> zip(horrors, ratings, combine).toBlockingObservable().forEach(action);
        Observable.<Movie, CoolRating, Result> zip(horrors, ratings, combine).toBlockingObservable().forEach(action);
        Observable.<Media, Rating, ExtendedResult> zip(horrors, ratings, combine).toBlockingObservable().forEach(extendedAction);
        Observable.<Media, Rating, Result> zip(horrors, ratings, combine).toBlockingObservable().forEach(action);
        Observable.<Media, Rating, ExtendedResult> zip(horrors, ratings, combine).toBlockingObservable().forEach(action);

        Observable.<Movie, CoolRating, Result> zip(horrors, ratings, combine);
    }
"
"    @Test
    public void testCovarianceOfFrom() {
        Observable.<Movie> from(new HorrorMovie());
        Observable.<Movie> from(new ArrayList<HorrorMovie>());
        // Observable.<HorrorMovie>from(new Movie()); // may not compile
    }
"
"    @Test
    public void testSortedList() {
        Func2<Media, Media, Integer> SORT_FUNCTION = new Func2<Media, Media, Integer>() {

            @Override
            public Integer call(Media t1, Media t2) {
                return 1;
            }
"
"    @Test
    public void testWindow() {
        final ArrayList<List<Integer>> lists = new ArrayList<List<Integer>>();
        Observable.from(1, 2, 3, 4, 5, 6)
                .window(3).map(new Func1<Observable<Integer>, List<Integer>>() {

                    @Override
                    public List<Integer> call(Observable<Integer> o) {
                        return o.toList().toBlockingObservable().single();
                    }
"
"    @Test
    public void testConcatSimple() {
        Observable<String> o1 = Observable.from(""one"", ""two"");
        Observable<String> o2 = Observable.from(""three"", ""four"");

        List<String> values = Observable.concat(o1, o2).toList().toBlockingObservable().single();

        assertEquals(""one"", values.get(0));
        assertEquals(""two"", values.get(1));
        assertEquals(""three"", values.get(2));
        assertEquals(""four"", values.get(3));
    }
"
"    @Test
    public void testConcatWithObservableOfObservable() {
        Observable<String> o1 = Observable.from(""one"", ""two"");
        Observable<String> o2 = Observable.from(""three"", ""four"");
        Observable<String> o3 = Observable.from(""five"", ""six"");

        Observable<Observable<String>> os = Observable.from(o1, o2, o3);

        List<String> values = Observable.concat(os).toList().toBlockingObservable().single();

        assertEquals(""one"", values.get(0));
        assertEquals(""two"", values.get(1));
        assertEquals(""three"", values.get(2));
        assertEquals(""four"", values.get(3));
    }
"
"    @Test
    public void testConcatWithIterableOfObservable() {
        Observable<String> o1 = Observable.from(""one"", ""two"");
        Observable<String> o2 = Observable.from(""three"", ""four"");
        Observable<String> o3 = Observable.from(""five"", ""six"");

        @SuppressWarnings(""unchecked"")
        Iterable<Observable<String>> is = Arrays.asList(o1, o2, o3);

        List<String> values = Observable.concat(Observable.from(is)).toList().toBlockingObservable().single();

        assertEquals(""one"", values.get(0));
        assertEquals(""two"", values.get(1));
        assertEquals(""three"", values.get(2));
        assertEquals(""four"", values.get(3));
    }
"
"    @Test
    public void testConcatCovariance() {
        Observable<Media> o1 = Observable.<Media> from(new HorrorMovie(), new Movie());
        Observable<Media> o2 = Observable.from(new Media(), new HorrorMovie());

        Observable<Observable<Media>> os = Observable.from(o1, o2);

        List<Media> values = Observable.concat(os).toList().toBlockingObservable().single();
    }
"
"    @Test
    public void testConcatCovariance2() {
        Observable<Media> o1 = Observable.from(new HorrorMovie(), new Movie(), new Media());
        Observable<Media> o2 = Observable.from(new Media(), new HorrorMovie());

        Observable<Observable<Media>> os = Observable.from(o1, o2);

        List<Media> values = Observable.concat(os).toList().toBlockingObservable().single();
    }
"
"    @Test
    public void testConcatCovariance3() {
        Observable<Movie> o1 = Observable.from(new HorrorMovie(), new Movie());
        Observable<Media> o2 = Observable.from(new Media(), new HorrorMovie());

        List<Media> values = Observable.concat(o1, o2).toList().toBlockingObservable().single();
        
        assertTrue(values.get(0) instanceof HorrorMovie);
        assertTrue(values.get(1) instanceof Movie);
        assertTrue(values.get(2) instanceof Media);
        assertTrue(values.get(3) instanceof HorrorMovie);
    }
"
"    @Test
    public void testConcatCovariance4() {

        Observable<Movie> o1 = Observable.create(new OnSubscribeFunc<Movie>() {

            @Override
            public Subscription onSubscribe(Observer<? super Movie> o) {
                o.onNext(new HorrorMovie());
                o.onNext(new Movie());
                //                o.onNext(new Media()); // correctly doesn't compile
                o.onCompleted();
                return Subscriptions.empty();
            }
"
"	@Test public void demoInterval() throws Exception {
	public void testLongObservable(Observable<Long> o, final String testname) throws Exception {
		final List<Long> l = new ArrayList<Long>();
		Action1<Long> onNext = new Action1<Long>() {
			public void call(Long i) { 
				l.add(i);
				System.out.println(testname + "" got "" + i);
			}
"
"    @Test
    public void fromArray() {
        String[] items = new String[] { ""one"", ""two"", ""three"" };
        assertEquals(new Integer(3), Observable.from(items).count().toBlockingObservable().single());
        assertEquals(""two"", Observable.from(items).skip(1).take(1).toBlockingObservable().single());
        assertEquals(""three"", Observable.from(items).takeLast(1).toBlockingObservable().single());
    }
"
"    @Test
    public void fromIterable() {
        ArrayList<String> items = new ArrayList<String>();
        items.add(""one"");
        items.add(""two"");
        items.add(""three"");

        assertEquals(new Integer(3), Observable.from(items).count().toBlockingObservable().single());
        assertEquals(""two"", Observable.from(items).skip(1).take(1).toBlockingObservable().single());
        assertEquals(""three"", Observable.from(items).takeLast(1).toBlockingObservable().single());
    }
"
"    @Test
    public void fromArityArgs3() {
        Observable<String> items = Observable.from(""one"", ""two"", ""three"");

        assertEquals(new Integer(3), items.count().toBlockingObservable().single());
        assertEquals(""two"", items.skip(1).take(1).toBlockingObservable().single());
        assertEquals(""three"", items.takeLast(1).toBlockingObservable().single());
    }
"
"    @Test
    public void fromArityArgs1() {
        Observable<String> items = Observable.from(""one"");

        assertEquals(new Integer(1), items.count().toBlockingObservable().single());
        assertEquals(""one"", items.takeLast(1).toBlockingObservable().single());
    }
"
"    @Test
    public void testCreate() {

        Observable<String> observable = Observable.create(new OnSubscribeFunc<String>() {

            @Override
            public Subscription onSubscribe(Observer<? super String> Observer) {
                Observer.onNext(""one"");
                Observer.onNext(""two"");
                Observer.onNext(""three"");
                Observer.onCompleted();
                return Subscriptions.empty();
            }
"
"    @Test
    public void testCountAFewItems() {
        Observable<String> observable = Observable.from(""a"", ""b"", ""c"", ""d"");
        observable.count().subscribe(w);
        // we should be called only once
        verify(w, times(1)).onNext(anyInt());
        verify(w).onNext(4);
        verify(w, never()).onError(any(Throwable.class));
        verify(w, times(1)).onCompleted();
    }
"
"    @Test
    public void testCountZeroItems() {
        Observable<String> observable = Observable.empty();
        observable.count().subscribe(w);
        // we should be called only once
        verify(w, times(1)).onNext(anyInt());
        verify(w).onNext(0);
        verify(w, never()).onError(any(Throwable.class));
        verify(w, times(1)).onCompleted();
    }
"
"    @Test
    public void testCountError() {
        Observable<String> o = Observable.create(new OnSubscribeFunc<String>() {
            @Override
            public Subscription onSubscribe(Observer<? super String> obsv) {
                obsv.onError(new RuntimeException());
                return Subscriptions.empty();
            }
"
"    @Test
    public void testFirstWithPredicateOfNoneMatchingThePredicate() {
        Observable<Integer> observable = Observable.from(1, 3, 5, 7, 9, 7, 5, 3, 1);
        observable.first(IS_EVEN).subscribe(w);
        verify(w, never()).onNext(anyInt());
        verify(w, times(1)).onCompleted();
        verify(w, never()).onError(any(Throwable.class));
    }
"
"    @Test
    public void testFirstOfSome() {
        Observable<Integer> observable = Observable.from(1, 2, 3);
        observable.first().subscribe(w);
        verify(w, times(1)).onNext(anyInt());
        verify(w).onNext(1);
        verify(w, times(1)).onCompleted();
        verify(w, never()).onError(any(Throwable.class));
    }
"
"    @Test
    public void testFirstOfNone() {
        Observable<Integer> observable = Observable.empty();
        observable.first().subscribe(w);
        verify(w, never()).onNext(anyInt());
        verify(w, times(1)).onCompleted();
        verify(w, never()).onError(any(Throwable.class));
    }
"
"    @Test
    public void testReduce() {
        Observable<Integer> observable = Observable.from(1, 2, 3, 4);
        observable.reduce(new Func2<Integer, Integer, Integer>() {

            @Override
            public Integer call(Integer t1, Integer t2) {
                return t1 + t2;
            }
"
"    @Test
    public void testReduceWithInitialValue() {
        Observable<Integer> observable = Observable.from(1, 2, 3, 4);
        observable.reduce(50, new Func2<Integer, Integer, Integer>() {

            @Override
            public Integer call(Integer t1, Integer t2) {
                return t1 + t2;
            }
"
"    @Test
    public void testSequenceEqual() {
        Observable<Integer> first = Observable.from(1, 2, 3);
        Observable<Integer> second = Observable.from(1, 2, 4);
        @SuppressWarnings(""unchecked"")
        Observer<Boolean> result = mock(Observer.class);
        Observable.sequenceEqual(first, second).subscribe(result);
        verify(result, times(2)).onNext(true);
        verify(result, times(1)).onNext(false);
    }
"
"    @Test
    public void testOnSubscribeFails() {
        @SuppressWarnings(""unchecked"")
        Observer<String> observer = mock(Observer.class);
        final RuntimeException re = new RuntimeException(""bad impl"");
        Observable<String> o = Observable.create(new OnSubscribeFunc<String>() {

            @Override
            public Subscription onSubscribe(Observer<? super String> t1) {
                throw re;
            }
"
"    @Test
    public void testMaterializeDematerializeChaining() {
        Observable<Integer> obs = Observable.just(1);
        Observable<Integer> chained = obs.materialize().dematerialize();

        @SuppressWarnings(""unchecked"")
        Observer<Integer> observer = mock(Observer.class);
        chained.subscribe(observer);

        verify(observer, times(1)).onNext(1);
        verify(observer, times(1)).onCompleted();
        verify(observer, times(0)).onError(any(Throwable.class));
    }
"
"    @Test
    public void testCustomObservableWithErrorInObserverAsynchronous() throws InterruptedException {
        final CountDownLatch latch = new CountDownLatch(1);
        final AtomicInteger count = new AtomicInteger();
        final AtomicReference<Throwable> error = new AtomicReference<Throwable>();
        Observable.create(new OnSubscribeFunc<String>() {

            @Override
            public Subscription onSubscribe(final Observer<? super String> observer) {
                final BooleanSubscription s = new BooleanSubscription();
                new Thread(new Runnable() {

                    @Override
                    public void run() {
                        try {
                            if (!s.isUnsubscribed()) {
                                observer.onNext(""1"");
                                observer.onNext(""2"");
                                observer.onNext(""three"");
                                observer.onNext(""4"");
                                observer.onCompleted();
                            }
                        } finally {
                            latch.countDown();
                        }
                    }
"
"    @Test
    public void testCustomObservableWithErrorInObserverSynchronous() {
        final AtomicInteger count = new AtomicInteger();
        final AtomicReference<Throwable> error = new AtomicReference<Throwable>();
        Observable.create(new OnSubscribeFunc<String>() {

            @Override
            public Subscription onSubscribe(Observer<? super String> observer) {
                observer.onNext(""1"");
                observer.onNext(""2"");
                observer.onNext(""three"");
                observer.onNext(""4"");
                observer.onCompleted();
                return Subscriptions.empty();
            }
"
"    @Test
    public void testCustomObservableWithErrorInObservableSynchronous() {
        final AtomicInteger count = new AtomicInteger();
        final AtomicReference<Throwable> error = new AtomicReference<Throwable>();
        Observable.create(new OnSubscribeFunc<String>() {

            @Override
            public Subscription onSubscribe(Observer<? super String> observer) {
                observer.onNext(""1"");
                observer.onNext(""2"");
                throw new NumberFormatException();
            }
"
"    @Test
    public void testPublish() throws InterruptedException {
        final AtomicInteger counter = new AtomicInteger();
        ConnectableObservable<String> o = Observable.create(new OnSubscribeFunc<String>() {

            @Override
            public Subscription onSubscribe(final Observer<? super String> observer) {
                final BooleanSubscription subscription = new BooleanSubscription();
                new Thread(new Runnable() {

                    @Override
                    public void run() {
                        counter.incrementAndGet();
                        observer.onNext(""one"");
                        observer.onCompleted();
                    }
"
"    @Test
    public void testReplay() throws InterruptedException {
        final AtomicInteger counter = new AtomicInteger();
        ConnectableObservable<String> o = Observable.create(new OnSubscribeFunc<String>() {

            @Override
            public Subscription onSubscribe(final Observer<? super String> observer) {
                final BooleanSubscription subscription = new BooleanSubscription();
                new Thread(new Runnable() {

                    @Override
                    public void run() {
                        counter.incrementAndGet();
                        observer.onNext(""one"");
                        observer.onCompleted();
                    }
"
"    @Test
    public void testCache() throws InterruptedException {
        final AtomicInteger counter = new AtomicInteger();
        Observable<String> o = Observable.create(new OnSubscribeFunc<String>() {

            @Override
            public Subscription onSubscribe(final Observer<? super String> observer) {
                final BooleanSubscription subscription = new BooleanSubscription();
                new Thread(new Runnable() {

                    @Override
                    public void run() {
                        counter.incrementAndGet();
                        observer.onNext(""one"");
                        observer.onCompleted();
                    }
"
"    @Test
    public void testErrorThrownWithoutErrorHandlerSynchronous() {
        try {
            Observable.error(new RuntimeException(""failure"")).subscribe(new Action1<Object>() {

                @Override
                public void call(Object t1) {
                    // won't get anything
                }
"
"    @Test
    public void testErrorThrownWithoutErrorHandlerAsynchronous() throws InterruptedException {
        final CountDownLatch latch = new CountDownLatch(1);
        final AtomicReference<Throwable> exception = new AtomicReference<Throwable>();
        Observable.create(new OnSubscribeFunc<String>() {

            @Override
            public Subscription onSubscribe(final Observer<? super String> observer) {
                new Thread(new Runnable() {

                    @Override
                    public void run() {
                        try {
                            observer.onError(new Error(""failure""));
                        } catch (Throwable e) {
                            // without an onError handler it has to just throw on whatever thread invokes it
                            exception.set(e);
                        }
                        latch.countDown();
                    }
"
"    @Test
    public void testTakeWithErrorInObserver() {
        final AtomicInteger count = new AtomicInteger();
        final AtomicReference<Throwable> error = new AtomicReference<Throwable>();
        Observable.from(""1"", ""2"", ""three"", ""4"").take(3).subscribe(new Observer<String>() {

            @Override
            public void onCompleted() {
                System.out.println(""completed"");
            }
"
"    @Test
    public void testOfType() {
        Observable<String> observable = Observable.from(1, ""abc"", false, 2L).ofType(String.class);

        @SuppressWarnings(""unchecked"")
        Observer<Object> aObserver = mock(Observer.class);
        observable.subscribe(aObserver);
        verify(aObserver, never()).onNext(1);
        verify(aObserver, times(1)).onNext(""abc"");
        verify(aObserver, never()).onNext(false);
        verify(aObserver, never()).onNext(2L);
        verify(aObserver, never()).onError(
                org.mockito.Matchers.any(Throwable.class));
        verify(aObserver, times(1)).onCompleted();
    }
"
"    @Test
    public void testOfTypeWithPolymorphism() {
        ArrayList<Integer> l1 = new ArrayList<Integer>();
        l1.add(1);
        LinkedList<Integer> l2 = new LinkedList<Integer>();
        l2.add(2);

        @SuppressWarnings(""rawtypes"")
        Observable<List> observable = Observable.<Object>from(l1, l2, ""123"").ofType(List.class);

        @SuppressWarnings(""unchecked"")
        Observer<Object> aObserver = mock(Observer.class);
        observable.subscribe(aObserver);
        verify(aObserver, times(1)).onNext(l1);
        verify(aObserver, times(1)).onNext(l2);
        verify(aObserver, never()).onNext(""123"");
        verify(aObserver, never()).onError(
                org.mockito.Matchers.any(Throwable.class));
        verify(aObserver, times(1)).onCompleted();
    }
"
"    @Test
    public void testThrottle() {
        @SuppressWarnings(""unchecked"")
        Observer<Integer> observer = mock(Observer.class);
        TestScheduler s = new TestScheduler();
        PublishSubject<Integer> o = PublishSubject.create();
        o.throttleFirst(500, TimeUnit.MILLISECONDS, s).subscribe(observer);

        // send events with simulated time increments
        s.advanceTimeTo(0, TimeUnit.MILLISECONDS);
        o.onNext(1); // deliver
        o.onNext(2); // skip
        s.advanceTimeTo(501, TimeUnit.MILLISECONDS);
        o.onNext(3); // deliver
        s.advanceTimeTo(600, TimeUnit.MILLISECONDS);
        o.onNext(4); // skip
        s.advanceTimeTo(700, TimeUnit.MILLISECONDS);
        o.onNext(5); // skip
        o.onNext(6); // skip
        s.advanceTimeTo(1001, TimeUnit.MILLISECONDS);
        o.onNext(7); // deliver
        s.advanceTimeTo(1501, TimeUnit.MILLISECONDS);
        o.onCompleted();

        InOrder inOrder = inOrder(observer);
        inOrder.verify(observer).onNext(1);
        inOrder.verify(observer).onNext(3);
        inOrder.verify(observer).onNext(7);
        inOrder.verify(observer).onCompleted();
        inOrder.verifyNoMoreInteractions();
    }
"
"    @Test
    public void testObserveOnWithNewThreadScheduler() {
        final AtomicInteger count = new AtomicInteger();
        final int _multiple = 99;

        Observable.range(1, 100000).map(new Func1<Integer, Integer>() {

            @Override
            public Integer call(Integer t1) {
                return t1 * _multiple;
            }
"
"    @Test
    public void testObserveOnWithThreadPoolScheduler() {
        final AtomicInteger count = new AtomicInteger();
        final int _multiple = 99;

        Observable.range(1, 100000).map(new Func1<Integer, Integer>() {

            @Override
            public Integer call(Integer t1) {
                return t1 * _multiple;
            }
"
"    @Test
    public void testObserveOnOrderingConcurrency() {
        final AtomicInteger count = new AtomicInteger();
        final int _multiple = 99;

        Observable.range(1, 10000).map(new Func1<Integer, Integer>() {

            @Override
            public Integer call(Integer t1) {
                if (randomIntFrom0to100() > 98) {
                    try {
                        Thread.sleep(2);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                }
                return t1 * _multiple;
            }
"
"    @Test
    public void testCovarianceOfMerge() {
        Observable<HorrorMovie> horrors = Observable.from(new HorrorMovie());
        Observable<Observable<HorrorMovie>> metaHorrors = Observable.just(horrors);
        Observable.<Media> merge(metaHorrors);
    }
"
"    @Test
    public void testMergeCovariance() {
        Observable<Media> o1 = Observable.<Media> from(new HorrorMovie(), new Movie());
        Observable<Media> o2 = Observable.from(new Media(), new HorrorMovie());

        Observable<Observable<Media>> os = Observable.from(o1, o2);

        List<Media> values = Observable.merge(os).toList().toBlockingObservable().single();
    }
"
"    @Test
    public void testMergeCovariance2() {
        Observable<Media> o1 = Observable.from(new HorrorMovie(), new Movie(), new Media());
        Observable<Media> o2 = Observable.from(new Media(), new HorrorMovie());

        Observable<Observable<Media>> os = Observable.from(o1, o2);

        List<Media> values = Observable.merge(os).toList().toBlockingObservable().single();
    }
"
"    @Test
    public void testMergeCovariance3() {
        Observable<Movie> o1 = Observable.from(new HorrorMovie(), new Movie());
        Observable<Media> o2 = Observable.from(new Media(), new HorrorMovie());

        List<Media> values = Observable.merge(o1, o2).toList().toBlockingObservable().single();
        
        assertTrue(values.get(0) instanceof HorrorMovie);
        assertTrue(values.get(1) instanceof Movie);
        assertTrue(values.get(2) instanceof Media);
        assertTrue(values.get(3) instanceof HorrorMovie);
    }
"
"    @Test
    public void testMergeCovariance4() {

        Observable<Movie> o1 = Observable.create(new OnSubscribeFunc<Movie>() {

            @Override
            public Subscription onSubscribe(Observer<? super Movie> o) {
                o.onNext(new HorrorMovie());
                o.onNext(new Movie());
                //                o.onNext(new Media()); // correctly doesn't compile
                o.onCompleted();
                return Subscriptions.empty();
            }
"
"    @Test
    public void reduceInts() {
        Observable<Integer> o = Observable.from(1, 2, 3);
        int value = o.reduce(new Func2<Integer, Integer, Integer>() {

            @Override
            public Integer call(Integer t1, Integer t2) {
                return t1 + t2;
            }
"
"    @Test
    public void reduceWithObjects() {
        Observable<Movie> horrorMovies = Observable.<Movie> from(new HorrorMovie());

        Func2<Movie, Movie, Movie> chooseSecondMovie =
                new Func2<Movie, Movie, Movie>() {
                    public Movie call(Movie t1, Movie t2) {
                        return t2;
                    }
"
"    @Test
    public void reduceWithCovariantObjects() {
        Observable<Movie> horrorMovies = Observable.<Movie> from(new HorrorMovie());

        Func2<Movie, Movie, Movie> chooseSecondMovie =
                new Func2<Movie, Movie, Movie>() {
                    public Movie call(Movie t1, Movie t2) {
                        return t2;
                    }
"
"    @Test
    public void reduceCovariance() {
        // must type it to <Movie>
        Observable<Movie> horrorMovies = Observable.<Movie> from(new HorrorMovie());
        libraryFunctionActingOnMovieObservables(horrorMovies);
    }
"
"    @Test
    public void testCovarianceOfCombineLatest() {
        Observable<HorrorMovie> horrors = Observable.from(new HorrorMovie());
        Observable<CoolRating> ratings = Observable.from(new CoolRating());

        Observable.<Movie, CoolRating, Result> combineLatest(horrors, ratings, combine).toBlockingObservable().forEach(action);
        Observable.<Movie, CoolRating, Result> combineLatest(horrors, ratings, combine).toBlockingObservable().forEach(action);
        Observable.<Media, Rating, ExtendedResult> combineLatest(horrors, ratings, combine).toBlockingObservable().forEach(extendedAction);
        Observable.<Media, Rating, Result> combineLatest(horrors, ratings, combine).toBlockingObservable().forEach(action);
        Observable.<Media, Rating, ExtendedResult> combineLatest(horrors, ratings, combine).toBlockingObservable().forEach(action);

        Observable.<Movie, CoolRating, Result> combineLatest(horrors, ratings, combine);
    }
"
"    @Test
    public void testThrottle() {
        @SuppressWarnings(""unchecked"")
        Observer<Integer> observer = mock(Observer.class);
        TestScheduler s = new TestScheduler();
        PublishSubject<Integer> o = PublishSubject.create();
        o.throttleLast(500, TimeUnit.MILLISECONDS, s).subscribe(observer);

        // send events with simulated time increments
        s.advanceTimeTo(0, TimeUnit.MILLISECONDS);
        o.onNext(1); // skip
        o.onNext(2); // deliver
        s.advanceTimeTo(501, TimeUnit.MILLISECONDS);
        o.onNext(3); // skip
        s.advanceTimeTo(600, TimeUnit.MILLISECONDS);
        o.onNext(4); // skip
        s.advanceTimeTo(700, TimeUnit.MILLISECONDS);
        o.onNext(5); // skip
        o.onNext(6); // deliver
        s.advanceTimeTo(1001, TimeUnit.MILLISECONDS);
        o.onNext(7); // deliver
        s.advanceTimeTo(1501, TimeUnit.MILLISECONDS);
        o.onCompleted();

        InOrder inOrder = inOrder(observer);
        inOrder.verify(observer).onNext(2);
        inOrder.verify(observer).onNext(6);
        inOrder.verify(observer).onNext(7);
        inOrder.verify(observer).onCompleted();
        inOrder.verifyNoMoreInteractions();
    }
"
"    @Test
    public void testUnsubscribeScan() {

        EventStream.getEventStream(""HTTP-ClusterB"", 20)
                .scan(new HashMap<String, String>(), new Func2<Map<String, String>, Event, Map<String, String>>() {

                    @Override
                    public Map<String, String> call(Map<String, String> accum, Event perInstanceEvent) {
                        accum.put(""instance"", perInstanceEvent.instanceId);
                        return accum;
                    }

                })
                .take(10)
                .toBlockingObservable().forEach(new Action1<Map<String, String>>() {

                    @Override
                    public void call(Map<String, String> v) {
                        System.out.println(v);
                    }
"
"    @Test
    public void startWith1() {
        List<String> values = Observable.from(""one"", ""two"").startWith(""zero"").toList().toBlockingObservable().single();

        assertEquals(""zero"", values.get(0));
        assertEquals(""two"", values.get(2));
    }
"
"    @Test
    public void startWithIterable() {
        List<String> li = new ArrayList<String>();
        li.add(""alpha"");
        li.add(""beta"");
        List<String> values = Observable.from(""one"", ""two"").startWith(li).toList().toBlockingObservable().single();

        assertEquals(""alpha"", values.get(0));
        assertEquals(""beta"", values.get(1));
        assertEquals(""one"", values.get(2));
        assertEquals(""two"", values.get(3));
    }
"
"    @Test
    public void testThrottle() {
        @SuppressWarnings(""unchecked"")
        Observer<Integer> observer = mock(Observer.class);
        TestScheduler s = new TestScheduler();
        PublishSubject<Integer> o = PublishSubject.create();
        o.throttleWithTimeout(500, TimeUnit.MILLISECONDS, s).subscribe(observer);

        // send events with simulated time increments
        s.advanceTimeTo(0, TimeUnit.MILLISECONDS);
        o.onNext(1); // skip
        o.onNext(2); // deliver
        s.advanceTimeTo(501, TimeUnit.MILLISECONDS);
        o.onNext(3); // skip
        s.advanceTimeTo(600, TimeUnit.MILLISECONDS);
        o.onNext(4); // skip
        s.advanceTimeTo(700, TimeUnit.MILLISECONDS);
        o.onNext(5); // skip
        o.onNext(6); // deliver at 1300 after 500ms has passed since onNext(5)
        s.advanceTimeTo(1300, TimeUnit.MILLISECONDS);
        o.onNext(7); // deliver
        s.advanceTimeTo(1800, TimeUnit.MILLISECONDS);
        o.onCompleted();

        InOrder inOrder = inOrder(observer);
        inOrder.verify(observer).onNext(2);
        inOrder.verify(observer).onNext(6);
        inOrder.verify(observer).onNext(7);
        inOrder.verify(observer).onCompleted();
        inOrder.verifyNoMoreInteractions();
    }
"
"    @Test
    public void testTakeUnsubscribesOnGroupBy() {
        Observable.merge(
                EventStream.getEventStream(""HTTP-ClusterA"", 50),
                EventStream.getEventStream(""HTTP-ClusterB"", 20))
                // group by type (2 clusters)
                .groupBy(new Func1<Event, String>() {

                    @Override
                    public String call(Event event) {
                        return event.type;
                    }
"
"    @Test
    public void testTakeUnsubscribesOnFlatMapOfGroupBy() {
        Observable.merge(
                EventStream.getEventStream(""HTTP-ClusterA"", 50),
                EventStream.getEventStream(""HTTP-ClusterB"", 20))
                // group by type (2 clusters)
                .groupBy(new Func1<Event, String>() {

                    @Override
                    public String call(Event event) {
                        return event.type;
                    }
"
"  @Test
  public void testSavePreexistingLongID() throws Exception {
    //Override this test as it does not make sense for useObjectId = true
    assertTrue(true);
    testComplete();
    await();
  }
"
"  @Test
  public void testFindOneReturnsStringId() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject orig = createDoc();
      JsonObject doc = orig.copy();
      mongoClient.insert(collection, doc, onSuccess(id -> {
        assertNotNull(id);
        mongoClient.findOne(collection, new JsonObject().put(""foo"", ""bar""), null, onSuccess(obj -> {
          assertTrue(obj.containsKey(""_id""));
          assertTrue(obj.getValue(""_id"") instanceof String);
          obj.remove(""_id"");
          assertEquals(orig, obj);
          testComplete();
        }));
      }));
    }));
    await();
  }
"
"  @Test
  public void testFindOneReturnsNothing() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject orig = createDoc();
      JsonObject doc = orig.copy();
      mongoClient.insert(collection, doc, onSuccess(id -> {
        assertNotNull(id);
        mongoClient.findOne(collection, new JsonObject().put(""nothing"", ""xxrandomxx""), null, onSuccess(obj -> {
          assertNull(obj);
          testComplete();
        }));
      }));
    }));
    await();
  }
"
"  @Test
  public void testFindReturnsStringId() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject orig = createDoc();
      JsonObject doc = orig.copy();
      mongoClient.insert(collection, doc, onSuccess(id -> {
        assertNotNull(id);
        mongoClient.find(collection, new JsonObject().put(""foo"", ""bar""), onSuccess(list -> {
          assertTrue(list.size() == 1);
          JsonObject obj = list.get(0);
          assertTrue(obj.containsKey(""_id""));
          assertTrue(obj.getValue(""_id"") instanceof String);
          obj.remove(""_id"");
          assertEquals(orig, obj);
          testComplete();
        }));
      }));
    }));
    await();
  }
"
"  @Test
  public void testInsertPreexistingObjectID() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject doc = createDoc();
      //Changed to hex string as a random string will not be valid for useObjectId = true
      doc.put(""_id"", new ObjectId().toHexString());
      mongoClient.insertWithOptions(collection, doc, ACKNOWLEDGED, onSuccess(id -> {
        assertNull(id);
        testComplete();
      }));
    }));
    await();
  }
"
"  @Test
  public void testInsertPreexistingID() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject doc = createDoc();
      //Changed to hex string as a random string will not be valid for useObjectId = true
      doc.put(""_id"", new ObjectId().toHexString());
      mongoClient.insert(collection, doc, onSuccess(id -> {
        assertNull(id);
        testComplete();
      }));
    }));
    await();
  }
"
"  @Test
  public void testInsertRetrieve() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject doc = createDoc();
      doc.put(""_id"", new ObjectId().toHexString());
      mongoClient.insert(collection, doc, onSuccess(id -> {
        assertNull(id);
        mongoClient.findOne(collection, new JsonObject(), null, onSuccess(retrieved -> {
          assertEquals(doc, retrieved);
          testComplete();
        }));
      }));
    }));
    await();
  }
"
"  @Test
  public void testSavePreexistingObjectID() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject doc = createDoc();
      //Changed to hex string as a random string will not be valid for useObjectId = true
      doc.put(""_id"", new ObjectId().toHexString());
      mongoClient.saveWithOptions(collection, doc, ACKNOWLEDGED, onSuccess(id -> {
        assertNull(id);
        testComplete();
      }));
    }));
    await();
  }
"
"  @Test
  public void testInsertAlreadyExists() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject doc = createDoc();
      mongoClient.insert(collection, doc, onSuccess(id -> {
        assertNotNull(id);
        doc.put(""_id"", id);
        mongoClient.insert(collection, doc, response -> {
          assertFalse(response.succeeded());
          testComplete();
        });
      }));
    }));
    await();
  }
"
"  @Test
  public void testReplaceUpsert() {
    String collection = randomCollection();
    JsonObject doc = createDoc();
    mongoClient.insert(collection, doc, onSuccess(id -> {
      assertNotNull(id);
      JsonObject replacement = createDoc();
      replacement.put(""replacement"", true);
      mongoClient.replaceDocumentsWithOptions(collection, new JsonObject().put(""_id"", new ObjectId().toHexString()), replacement, new UpdateOptions(true), onSuccess(v -> {
        mongoClient.find(collection, new JsonObject(), onSuccess(list -> {
          assertNotNull(list);
          assertEquals(2, list.size());
          JsonObject result = null;
          for (JsonObject o : list) {
            if (o.containsKey(""replacement"")) {
              result = o;
            }
          }
          assertNotNull(result);
          testComplete();
        }));
      }));
    }));

    await();
  }
"
"  @Test
  public void testOptions() {
    UpdateOptions options = new UpdateOptions();

    WriteOption writeOption = ACKNOWLEDGED;
    assertEquals(options, options.setWriteOption(writeOption));
    assertEquals(writeOption, options.getWriteOption());

    boolean multi = TestUtils.randomBoolean();
    assertEquals(options, options.setMulti(multi));
    assertEquals(multi, options.isMulti());

    boolean upsert = TestUtils.randomBoolean();
    assertEquals(options, options.setUpsert(upsert));
    assertEquals(upsert, options.isUpsert());

    JsonArray arrayFilters = new JsonArray().add(new JsonObject().put(TestUtils.randomAlphaString(5), TestUtils.randomAlphaString(5)));
    assertEquals(options, options.setArrayFilters(arrayFilters));
    assertEquals(arrayFilters, options.getArrayFilters());
  }
"
"  @Test
  public void testDefaultOptions() {
    UpdateOptions options = new UpdateOptions();
    assertNull(options.getWriteOption());
    assertFalse(options.isMulti());
    assertFalse(options.isUpsert());
    assertNull(options.getArrayFilters());
  }
"
"  @Test
  public void testOptionsJson() {
    JsonObject json = new JsonObject();

    WriteOption writeOption = JOURNALED;
    json.put(""writeOption"", writeOption.name());

    boolean multi = TestUtils.randomBoolean();
    json.put(""multi"", multi);

    boolean upsert = TestUtils.randomBoolean();
    json.put(""upsert"", upsert);

    JsonArray arrayFilters = new JsonArray().add(new JsonObject().put(TestUtils.randomAlphaString(5), TestUtils.randomAlphaString(5)));
    json.put(""arrayFilters"", arrayFilters);

    UpdateOptions options = new UpdateOptions(json);
    assertEquals(writeOption, options.getWriteOption());
    assertEquals(multi, options.isMulti());
    assertEquals(upsert, options.isUpsert());
    assertEquals(arrayFilters, options.getArrayFilters());
  }
"
"  @Test
  public void testDefaultOptionsJson() {
    UpdateOptions options = new UpdateOptions(new JsonObject());
    UpdateOptions def = new UpdateOptions();
    assertEquals(def.getWriteOption(), options.getWriteOption());
    assertEquals(def.isMulti(), options.isMulti());
    assertEquals(def.isUpsert(), options.isUpsert());
    assertEquals(def.getArrayFilters(), options.getArrayFilters());
  }
"
"  @Test
  public void testCopyOptions() {
    UpdateOptions options = new UpdateOptions();
    WriteOption writeOption = REPLICA_ACKNOWLEDGED;
    boolean multi = TestUtils.randomBoolean();
    boolean upsert = TestUtils.randomBoolean();
    JsonArray arrayFilters = new JsonArray().add(new JsonObject().put(TestUtils.randomAlphaString(5), TestUtils.randomAlphaString(5)));

    options.setWriteOption(writeOption);
    options.setMulti(multi);
    options.setUpsert(upsert);
    options.setArrayFilters(arrayFilters);

    UpdateOptions copy = new UpdateOptions(options);
    assertEquals(options.getWriteOption(), copy.getWriteOption());
    assertEquals(options.isMulti(), copy.isMulti());
    assertEquals(options.isUpsert(), copy.isUpsert());
    assertEquals(options.getArrayFilters(), copy.getArrayFilters());
  }
"
"  @Test
  public void testToJson() {
    UpdateOptions options = new UpdateOptions();
    WriteOption writeOption = MAJORITY;
    boolean multi = TestUtils.randomBoolean();
    boolean upsert = TestUtils.randomBoolean();
    JsonArray arrayFilters = new JsonArray().add(new JsonObject().put(TestUtils.randomAlphaString(5), TestUtils.randomAlphaString(5)));

    options.setWriteOption(writeOption);
    options.setMulti(multi);
    options.setUpsert(upsert);
    options.setArrayFilters(arrayFilters);

    assertEquals(options, new UpdateOptions(options.toJson()));
  }
"
"  @Test
  public void testMongoClientUpdateResultStatuses() {
    long randomMatched = TestUtils.randomLong();
    JsonObject randomUpsertedId = randomUpsertId();
    long randomModified = TestUtils.randomLong();

    MongoClientUpdateResult mongoClientUpdateResult = new MongoClientUpdateResult(randomMatched, randomUpsertedId, randomModified);

    assertEquals(randomMatched, mongoClientUpdateResult.getDocMatched());
    assertEquals(randomUpsertedId, mongoClientUpdateResult.getDocUpsertedId());
    assertEquals(randomModified, mongoClientUpdateResult.getDocModified());
  }
"
"  @Test
  public void testDefaultMongoClientUpdateResult() {
    MongoClientUpdateResult mongoClientUpdateResult = new MongoClientUpdateResult();

    assertEquals(MongoClientUpdateResult.DEFAULT_DOCMATCHED, mongoClientUpdateResult.getDocMatched());
    assertNull(mongoClientUpdateResult.getDocUpsertedId());
    assertEquals(MongoClientUpdateResult.DEFAULT_DOCMODIFIED, mongoClientUpdateResult.getDocModified());
  }
"
"  @Test
  public void testCopyMongoClientUpdateResult() {
    MongoClientUpdateResult mongoClientUpdateResultOrigin = new MongoClientUpdateResult(TestUtils.randomLong(),
      randomUpsertId(), TestUtils.randomLong());
    MongoClientUpdateResult mongoClientUpdateResultCopy = new MongoClientUpdateResult(mongoClientUpdateResultOrigin);

    assertEquals(mongoClientUpdateResultOrigin.getDocMatched(), mongoClientUpdateResultCopy.getDocMatched());
    assertEquals(mongoClientUpdateResultOrigin.getDocUpsertedId(), mongoClientUpdateResultCopy.getDocUpsertedId());
    assertEquals(mongoClientUpdateResultOrigin.getDocModified(), mongoClientUpdateResultCopy.getDocModified());
  }
"
"  @Test
  public void testJsonMongoClientUpdateResult() {
    properJson();

    jsonWithoutRequiredFields();
  }
"
"  @Test
  public void testToJsonMongoClientUpdateResult() {
    JsonObject mongoClientUpdateResultJson = randomMongoClientUpdateResultJson();
    MongoClientUpdateResult mongoClientUpdateResult = new MongoClientUpdateResult(mongoClientUpdateResultJson);

    assertEquals(mongoClientUpdateResultJson, mongoClientUpdateResult.toJson());
  }
"
"  @Test
  public void testMongoUpdateResultEquality() {
    logicallyUnequal();

    logicallyEqual();
  }
"
"  @Test
  public void testMongoClientBulkWriteStatuses() {
    long randomMatched = TestUtils.randomLong();
    long randomModified = TestUtils.randomLong();
    long randomInserted = TestUtils.randomLong();
    long randomDeleted = TestUtils.randomLong();
    List<JsonObject> upserts = randomUpsertIds();

    MongoClientBulkWriteResult mongoClientBulkWriteResult = new MongoClientBulkWriteResult(randomInserted,
        randomMatched, randomDeleted, randomModified, upserts);

    assertEquals(randomMatched, mongoClientBulkWriteResult.getMatchedCount());
    assertEquals(randomModified, mongoClientBulkWriteResult.getModifiedCount());
    assertEquals(randomInserted, mongoClientBulkWriteResult.getInsertedCount());
    assertEquals(randomDeleted, mongoClientBulkWriteResult.getDeletedCount());
    assertEquals(upserts, mongoClientBulkWriteResult.getUpserts());
  }
"
"  @Test
  public void testDefaultMongoClientBulkWriteResult() {
    MongoClientBulkWriteResult mongoClientBulkWriteResult = new MongoClientBulkWriteResult();

    assertEquals(MongoClientBulkWriteResult.DEFAULT_MATCHED_COUNT, mongoClientBulkWriteResult.getMatchedCount());
    assertEquals(MongoClientBulkWriteResult.DEFAULT_MODIFIED_COUNT, mongoClientBulkWriteResult.getModifiedCount());
    assertEquals(MongoClientBulkWriteResult.DEFAULT_INSERTED_COUNT, mongoClientBulkWriteResult.getInsertedCount());
    assertEquals(MongoClientBulkWriteResult.DEFAULT_DELETED_COUNT, mongoClientBulkWriteResult.getDeletedCount());
    assertNull(mongoClientBulkWriteResult.getUpserts());
  }
"
"  @Test
  public void testCopyMongoClientBulkWriteResult() {
    MongoClientBulkWriteResult mongoClientBulkWriteResultOrigin = new MongoClientBulkWriteResult(TestUtils.randomLong(),
        TestUtils.randomLong(), TestUtils.randomLong(), TestUtils.randomLong(), randomUpsertIds());

    MongoClientBulkWriteResult mongoClientBulkWriteResultCopy = new MongoClientBulkWriteResult(
        mongoClientBulkWriteResultOrigin);

    assertEquals(mongoClientBulkWriteResultCopy.getMatchedCount(), mongoClientBulkWriteResultOrigin.getMatchedCount());
    assertEquals(mongoClientBulkWriteResultCopy.getModifiedCount(),
        mongoClientBulkWriteResultOrigin.getModifiedCount());
    assertEquals(mongoClientBulkWriteResultCopy.getInsertedCount(),
        mongoClientBulkWriteResultOrigin.getInsertedCount());
    assertEquals(mongoClientBulkWriteResultCopy.getDeletedCount(), mongoClientBulkWriteResultOrigin.getDeletedCount());
    assertEquals(mongoClientBulkWriteResultCopy.getUpserts(), mongoClientBulkWriteResultOrigin.getUpserts());
  }
"
"  @Test
  public void testJsonMongoClientBulkWriteResult() {
    properJson();

    jsonWithoutRequiredFields();
  }
"
"  @Test
  public void testToJsonMongoClientBulkWriteResult() {
    JsonObject mongoClientBulkWriteResultJson = randomMongoClientBulkWriteResultJson();
    MongoClientBulkWriteResult mongoClientBulkWriteResult = new MongoClientBulkWriteResult(
        mongoClientBulkWriteResultJson);

    assertEquals(mongoClientBulkWriteResultJson, mongoClientBulkWriteResult.toJson());
  }
"
"  @Test
  public void testMongoBulkWriteResultEquality() {
    logicallyUnequal();

    logicallyEqual();
  }
"
"  @Test
  public void testOptions() {
    AggregateOptions options = new AggregateOptions();

    long maxTime = TestUtils.randomLong();
    assertEquals(options, options.setMaxTime(maxTime));
    assertEquals(maxTime, options.getMaxTime());
  }
"
"  @Test
  public void testDefaultOptions() {
    AggregateOptions options = new AggregateOptions();
    assertEquals(AggregateOptions.DEFAULT_MAX_TIME, options.getMaxTime());
  }
"
"  @Test
  public void testOptionsJson() {
    JsonObject json = new JsonObject();

    long maxAwaitTime = TestUtils.randomLong();
    json.put(""maxAwaitTime"", maxAwaitTime);

    long maxTime = TestUtils.randomLong();
    json.put(""maxTime"", maxTime);

    AggregateOptions options = new AggregateOptions(json);
    assertEquals(maxTime, options.getMaxTime());
  }
"
"  @Test
  public void testDefaultOptionsJson() {
    AggregateOptions options = new AggregateOptions(new JsonObject());
    AggregateOptions def = new AggregateOptions();
    assertEquals(def.getMaxTime(), options.getMaxTime());
  }
"
"  @Test
  public void testCopyOptions() {
    AggregateOptions options = new AggregateOptions();
    options.setMaxTime(TestUtils.randomLong());

    AggregateOptions copy = new AggregateOptions(options);
    assertEquals(options.getMaxTime(), copy.getMaxTime());
  }
"
"  @Test
  public void testToJson() {
    AggregateOptions options = new AggregateOptions();
    long maxTime = TestUtils.randomPositiveLong();
    options.setMaxTime(maxTime);

    assertEquals(options, new AggregateOptions(options.toJson()));
  }
"
"  @Test
  public void testNonShared() {
    LocalMap<String, Object> map = getLocalMap();
    JsonObject config = getConfig();
    MongoClient client1 = MongoClient.create(vertx, config);
    assertEquals(1, map.size());
    MongoClient client2 = MongoClient.create(vertx, config);
    assertEquals(2, map.size());
    MongoClient client3 = MongoClient.create(vertx, config);
    assertEquals(3, map.size());
    client1.close();
    assertEquals(2, map.size());
    client2.close();
    assertEquals(1, map.size());
    client3.close();
    assertWaitUntil(() -> map.size() == 0);
    assertWaitUntil(() -> getLocalMap().size() == 0);
    assertWaitUntil(() -> map != getLocalMap()); // Map has been closed
  }
"
"  @Test
  public void testSharedDefault() throws Exception {
    LocalMap<String, Object> map = getLocalMap();
    JsonObject config = getConfig();
    MongoClient client1 = MongoClient.createShared(vertx, config);
    assertEquals(1, map.size());
    MongoClient client2 = MongoClient.createShared(vertx, config);
    assertEquals(1, map.size());
    MongoClient client3 = MongoClient.createShared(vertx, config);
    assertEquals(1, map.size());
    client1.close();
    assertEquals(1, map.size());
    client2.close();
    assertEquals(1, map.size());
    client3.close();
    assertEquals(0, map.size());
    assertNotSame(map, getLocalMap());
  }
"
"  @Test
  public void testSharedNamed() throws Exception {
    LocalMap<String, Object> map = getLocalMap();
    JsonObject config = getConfig();
    MongoClient client1 = MongoClient.createShared(vertx, config, ""ds1"");
    assertEquals(1, map.size());
    MongoClient client2 = MongoClient.createShared(vertx, config, ""ds1"");
    assertEquals(1, map.size());
    MongoClient client3 = MongoClient.createShared(vertx, config, ""ds1"");
    assertEquals(1, map.size());

    MongoClient client4 = MongoClient.createShared(vertx, config, ""ds2"");
    assertEquals(2, map.size());
    MongoClient client5 = MongoClient.createShared(vertx, config, ""ds2"");
    assertEquals(2, map.size());
    MongoClient client6 = MongoClient.createShared(vertx, config, ""ds2"");
    assertEquals(2, map.size());

    client1.close();
    assertEquals(2, map.size());
    client2.close();
    assertEquals(2, map.size());
    client3.close();
    assertEquals(1, map.size());

    client4.close();
    assertEquals(1, map.size());
    client5.close();
    assertEquals(1, map.size());
    client6.close();
    assertEquals(0, map.size());
    assertNotSame(map, getLocalMap());
  }
"
"  @Test
  public void testDelete() {
    String fileName = createTempFileWithContent((1024 * 3) + 70);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> mongoGridFsPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", mongoGridFsPromise);

    mongoGridFsPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<Void> deletePromise = Promise.promise();
      gridFsClient.get().delete(id, deletePromise);
      return deletePromise.future();
    }).onComplete(event -> {
      if (event.succeeded()) {
        testComplete();
      } else {
        fail(event.cause());
      }
    });
    await();
  }
"
"  @Test
  public void testFileUpload() {

    long fileLength = (1024 * 3) + 70;
    String fileName = createTempFileWithContent(fileLength);
    String downloadFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<Long> downloadPromise = Promise.promise();
      gridFsClient.get().downloadFileAs(fileName, downloadFileName, downloadPromise);
      return downloadPromise.future();
    }).compose(length -> {
      assertEquals((long)length, fileLength);
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      } else {
        testComplete();
      }
    });
    await();
  }
"
"  @Test
  public void testBigFileUpload() {
    String originalFileName = createTempFileWithContent((1024 * 50) + 16);
    long originalLength = new File(originalFileName).length();
    String copiedFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(originalFileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<Long> downloadPromise = Promise.promise();
      gridFsClient.get().downloadFileAs(originalFileName, copiedFileName, downloadPromise);
      return downloadPromise.future();
    }).compose(length -> {
      assertEquals(originalLength, length.longValue());
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      } else {
        testComplete();
      }
    });
    await();
  }
"
"  @Test
  public void testFileUploadWithOptions() {

    String fileName = createTempFileWithContent((1027) + 7000);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    JsonObject meta = new JsonObject();
    meta.put(""nick_name"", ""Puhi the eel"");

    GridFsUploadOptions options = new GridFsUploadOptions();
    options.setMetadata(meta);

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFileWithOptions(fileName, options, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
"
"  @Test
  public void testFindWithMetadata() {
    String fileName = createTempFileWithContent((1024 * 3) + 70);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    JsonObject meta = new JsonObject();
    meta.put(""nick_name"", ""Puhi the eel"");

    GridFsUploadOptions options = new GridFsUploadOptions();
    options.setMetadata(meta);

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFileWithOptions(fileName, options, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<List<String>> findPromise = Promise.promise();
      JsonObject query = new JsonObject().put(""metadata.nick_name"", ""Puhi the eel"");
      gridFsClient.get().findIds(query, findPromise);
      return findPromise.future();
    }).compose(list -> {
      assertTrue(list.size() > 0);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
"
"  @Test
  public void testFindAllIds() {

    String fileName = createTempFileWithContent((1024 * 3) + 70);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<List<String>> findPromise = Promise.promise();
      gridFsClient.get().findAllIds(findPromise);
      return findPromise.future();
    }).compose(list -> {
      assertTrue(list.size() == 1);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
"
"  @Test
  public void testDrop() {
    createTempFileWithContent((1024 * 3) + 70);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();

  }
"
"  @Test
  public void testDownloadStream() {
    long fileLength = (1024 * 3) + 70;
    String fileName = createTempFileWithContent(fileLength);
    String downloadFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createDefaultGridFsBucketService(gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<AsyncFile> openPromise = Promise.promise();
      vertx.fileSystem().open(downloadFileName, new OpenOptions().setWrite(true), openPromise);
      return openPromise.future();
    }).compose(asyncFile -> {
      Promise<Long> downloadedPromise = Promise.promise();
      gridFsClient.get().downloadByFileName(asyncFile, fileName, downloadedPromise);
      return downloadedPromise.future();
    }).compose(length -> {
      assertTrue(fileLength == length);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();

  }
"
"  @Test
  public void testDownloadStreamById() {
    long fileLength = (1027) + 7000;
    String fileName = createTempFileWithContent(fileLength);
    String downloadFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();
    AtomicReference<String> idCreated = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createDefaultGridFsBucketService(gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      idCreated.set(id);
      Promise<AsyncFile> openPromise = Promise.promise();
      vertx.fileSystem().open(downloadFileName, new OpenOptions().setWrite(true), openPromise);
      return openPromise.future();
    }).compose(asyncFile -> {
      Promise<Long> downloadedPromise = Promise.promise();
      gridFsClient.get().downloadById(asyncFile, idCreated.get(), downloadedPromise);
      return downloadedPromise.future();
    }).compose(length -> {
      assertTrue(fileLength == length);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
"
"  @Test
  public void testDownloadStreamWithOptions() {
    long fileLength = (1024 * 3) + 70;
    String fileName = createTempFileWithContent(fileLength);
    String downloadFileName = createTempFile();
    GridFsDownloadOptions options = new GridFsDownloadOptions();
    options.setRevision(GridFsDownloadOptions.DEFAULT_REVISION);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createDefaultGridFsBucketService(gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<AsyncFile> openPromise = Promise.promise();
      vertx.fileSystem().open(downloadFileName, new OpenOptions().setWrite(true), openPromise);
      return openPromise.future();
    }).compose(asyncFile -> {
      Promise<Long> downloadedPromise = Promise.promise();
      gridFsClient.get().downloadByFileNameWithOptions(asyncFile, fileName, options, downloadedPromise);
      return downloadedPromise.future();
    }).compose(length -> {
      assertTrue(fileLength == length);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
"
"  @Test
  public void testFileDownload() {
    String fileName = createTempFileWithContent(1024);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(uploaded -> {
      Promise<Long> downloadPromise = Promise.promise();
      gridFsClient.get().downloadFile(fileName, downloadPromise);
      return downloadPromise.future();
    }).compose(length -> {
      assertEquals(1024L, length.longValue());
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();

  }
"
"  @Test
  public void testStreamUpload() {
    String fileName = createTempFileWithContent(1024);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<AsyncFile> openPromise = Promise.promise();
      vertx.fileSystem().open(fileName, new OpenOptions(), openPromise);
      return openPromise.future();
    }).compose(asyncFile -> {
      Promise<String> uploadedPromise = Promise.promise();
      gridFsClient.get().uploadByFileName(asyncFile, fileName, uploadedPromise);
      return uploadedPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();

  }
"
"  @Test
  public void testStreamUploadWithOptions() {
    String fileName = createTempFileWithContent(1024);
    GridFsUploadOptions options = new GridFsUploadOptions();
    options.setChunkSizeBytes(1024);
    options.setMetadata(new JsonObject().put(""meta_test"", ""Kamapua`a""));

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<AsyncFile> openPromise = Promise.promise();
      vertx.fileSystem().open(fileName, new OpenOptions(), openPromise);
      return openPromise.future();
    }).compose(asyncFile -> {
      Promise<String> uploadedPromise = Promise.promise();
      gridFsClient.get().uploadByFileNameWithOptions(asyncFile, fileName, options, uploadedPromise);
      return uploadedPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
"
"  @Test
  public void testFileDownloadAs() {
    String fileName = createTempFileWithContent(1024);
    String asFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(uploaded -> {
      Promise<Long> downloadPromise = Promise.promise();
      gridFsClient.get().downloadFileAs(fileName, asFileName, downloadPromise);
      return downloadPromise.future();
    }).compose(length -> {
      assertEquals(1024L, length.longValue());
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
"
"  @Test
  public void testFileDownloadById() {
    String fileName = createTempFileWithContent(1024);
    String asFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      Promise<Long> downloadPromise = Promise.promise();
      gridFsClient.get().downloadFileByID(id, asFileName, downloadPromise);
      return downloadPromise.future();
    }).compose(length -> {
      assertEquals(1024L, length.longValue());
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
"
"  @Test
  public void testAggregateUpdateCollection() {
    String collection = randomCollection();
    mongoClient.insert(collection, new JsonObject().put(""price"", 10).put(""quantity"", 1), onSuccess(id -> {
      mongoClient.insert(collection, new JsonObject().put(""price"", 20).put(""quantity"", 2), onSuccess(id2 -> {
        mongoClient.insert(collection, new JsonObject().put(""price"", 30).put(""quantity"", 10), onSuccess(id3 -> {
          mongoClient.updateCollection(collection,
            // reduce price of low quantity items
            new JsonObject().put(""quantity"", new JsonObject().put(""$lte"", 2)),
            new JsonArray().add(new JsonObject().put(""$set"", new JsonObject().put(""price"", new JsonObject().put(""$subtract"", new JsonArray().add(""$price"").add(2))))),
            onSuccess(res -> {
              assertEquals(2, res.getDocModified());
              assertEquals(2, res.getDocMatched());
              testComplete();
            }));
        }));
      }));
    }));
    await();
  }
"
"  @Test
  public void testAggregateUpdateCollectionWithOptions() {
    String collection = randomCollection();
    mongoClient.insert(collection, new JsonObject().put(""price"", 10).put(""quantity"", 1), onSuccess(id -> {
      mongoClient.insert(collection, new JsonObject().put(""price"", 20).put(""quantity"", 2), onSuccess(id2 -> {
        mongoClient.insert(collection, new JsonObject().put(""price"", 30).put(""quantity"", 10), onSuccess(id3 -> {
          mongoClient.updateCollectionWithOptions(collection,
            // reduce price of low quantity items
            new JsonObject().put(""quantity"", new JsonObject().put(""$lte"", 2)),
            new JsonArray().add(new JsonObject().put(""$set"", new JsonObject().put(""price"", new JsonObject().put(""$subtract"", new JsonArray().add(""$price"").add(2))))),
            new UpdateOptions(),onSuccess(res -> {
              assertEquals(2, res.getDocModified());
              assertEquals(2, res.getDocMatched());
              testComplete();
            }));
        }));
      }));
    }));
    await();
  }
"
"  @Test
  public void testEquals() {
    BulkWriteOptions a = new BulkWriteOptions();
    BulkWriteOptions b = new BulkWriteOptions();
    assertEquals(a, b);

    a.setWriteOption(WriteOption.ACKNOWLEDGED);
    b.setWriteOption(WriteOption.JOURNALED);
    assertNotEquals(a, b);

    a.setWriteOption(WriteOption.MAJORITY);
    b.setWriteOption(WriteOption.MAJORITY);
    assertEquals(a, b);

    a.setOrdered(true);
    b.setOrdered(false);
    assertNotEquals(a, b);

    assertNotEquals(a, null);
  }
"
"  @Test
  public void testHashCode() {
    BulkWriteOptions a = new BulkWriteOptions()
      .setWriteOption(WriteOption.JOURNALED)
      .setOrdered(false);
    int hash = a.hashCode();

    a.setWriteOption(WriteOption.ACKNOWLEDGED);
    assertNotEquals(hash, a.hashCode());

    a.setWriteOption(WriteOption.JOURNALED);
    a.setOrdered(true);
    assertNotEquals(hash, a.hashCode());

    a.setWriteOption(WriteOption.JOURNALED);
    a.setOrdered(false);
    assertEquals(hash, a.hashCode());
  }
"
"  @Test
  public void testOptions() {
    FindOptions options = new FindOptions();

    JsonObject fields = randomJsonObject();
    assertEquals(options, options.setFields(fields));
    assertEquals(fields, options.getFields());

    JsonObject sort = randomJsonObject();
    assertEquals(options, options.setSort(sort));
    assertEquals(sort, options.getSort());

    int limit = TestUtils.randomInt();
    assertEquals(options, options.setLimit(limit));
    assertEquals(limit, options.getLimit());

    int skip = TestUtils.randomInt();
    assertEquals(options, options.setSkip(skip));
    assertEquals(skip, options.getSkip());
  }
"
"  @Test
  public void testDefaultOptions() {
    FindOptions options = new FindOptions();
    assertNotNull(options.getFields());
    assertTrue(options.getFields().isEmpty());
    assertNotNull(options.getSort());
    assertTrue(options.getSort().isEmpty());
    assertEquals(FindOptions.DEFAULT_LIMIT, options.getLimit());
    assertEquals(FindOptions.DEFAULT_SKIP, options.getSkip());
  }
"
"  @Test
  public void testOptionsJson() {
    JsonObject json = new JsonObject();

    JsonObject fields = randomJsonObject();
    json.put(""fields"", fields);

    JsonObject sort = randomJsonObject();
    json.put(""sort"", sort);

    int limit = TestUtils.randomInt();
    json.put(""limit"", limit);

    int skip = TestUtils.randomInt();
    json.put(""skip"", skip);

    FindOptions options = new FindOptions(json);
    assertEquals(fields, options.getFields());
    assertEquals(sort, options.getSort());
    assertEquals(limit, options.getLimit());
    assertEquals(skip, options.getSkip());
  }
"
"  @Test
  public void testDefaultOptionsJson() {
    FindOptions options = new FindOptions(new JsonObject());
    FindOptions def = new FindOptions();
    assertEquals(def.getFields(), options.getFields());
    assertEquals(def.getSort(), options.getSort());
    assertEquals(def.getLimit(), options.getLimit());
    assertEquals(def.getSkip(), options.getSkip());
  }
"
"  @Test
  public void testCopyOptions() {
    FindOptions options = new FindOptions();
    JsonObject fields = randomJsonObject();
    JsonObject sort = randomJsonObject();
    int limit = TestUtils.randomInt();
    int skip = TestUtils.randomInt();
    options.setFields(fields);
    options.setSort(sort);
    options.setLimit(limit);
    options.setSkip(skip);

    FindOptions copy = new FindOptions(options);
    assertEquals(options.getFields(), copy.getFields());
    assertEquals(options.getSort(), copy.getSort());
    assertEquals(options.getLimit(), copy.getLimit());
    assertEquals(options.getSkip(), copy.getSkip());
  }
"
"  @Test
  public void testToJson() {
    FindOptions options = new FindOptions();
    JsonObject fields = randomJsonObject();
    JsonObject sort = randomJsonObject();
    int limit = TestUtils.randomPositiveInt();
    int skip = TestUtils.randomPositiveInt();
    options.setFields(fields);
    options.setSort(sort);
    options.setLimit(limit);
    options.setSkip(skip);

    assertEquals(options, new FindOptions(options.toJson()));
  }
"
"  @Test
  public void testServerSettings() {
    long heartbeatFrequencyMS = 1234;
    long minHeartbeatFrequencyMS = heartbeatFrequencyMS / 2;
    JsonObject config = new JsonObject();
    config.put(""heartbeatFrequencyMS"", heartbeatFrequencyMS);
    config.put(""minHeartbeatFrequencyMS"", minHeartbeatFrequencyMS);

    ServerSettings settings = new ServerSettingsParser(config).settings();
    assertEquals(heartbeatFrequencyMS, settings.getHeartbeatFrequency(TimeUnit.MILLISECONDS));
    assertEquals(minHeartbeatFrequencyMS, settings.getMinHeartbeatFrequency(TimeUnit.MILLISECONDS));
  }
"
"  @Test
  public void testNoWriteConcern() {
    WriteConcern wc = new WriteConcernParser(null, new JsonObject()).writeConcern();
    assertNull(wc);
  }
"
"  @Test
  public void testWriteConcern() {
    JsonObject config = new JsonObject();
    config.put(""writeConcern"", ""ACKNOWLEDGED"");

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(WriteConcern.ACKNOWLEDGED, wc);
  }
"
"  @Test
  public void testWriteConcernCaseInsensitive() {
    JsonObject config = new JsonObject();
    config.put(""writeConcern"", ""acknowledged"");

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(WriteConcern.ACKNOWLEDGED, wc);
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidWriteConcern() {
    JsonObject config = new JsonObject();
    config.put(""writeConcern"", ""foo"");

    new WriteConcernParser(null, config).writeConcern();
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidTypeWriteConcern() {
    JsonObject config = new JsonObject();
    config.put(""writeConcern"", 123);

    new WriteConcernParser(null, config);
  }
"
"  @Test
  public void testAdvancedWriteConcern_w_int() {
    WriteConcern expected = new WriteConcern(3).withWTimeout(25, TimeUnit.MILLISECONDS).withJournal(true);
    JsonObject config = new JsonObject();
    config.put(""w"", 3);
    config.put(""wtimeoutMS"", 25);
    config.put(""j"", true);

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
"
"  @Test
  public void testAdvancedWriteConcern_w_string() {
    WriteConcern expected = WriteConcern.MAJORITY.withWTimeout(1, TimeUnit.MILLISECONDS).withJournal(true);
    JsonObject config = new JsonObject();
    config.put(""w"", ""majority"");
    config.put(""wtimeoutMS"", 1);
    config.put(""j"", true);

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
"
"  @Test
  public void testAdvancedWriteConcern_w_int_only() {
    WriteConcern expected = new WriteConcern(123);
    JsonObject config = new JsonObject();
    config.put(""w"", 123);

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
"
"  @Test
  public void testAdvancedWriteConcern_w_string_only() {
    WriteConcern expected = new WriteConcern(""foo"");
    JsonObject config = new JsonObject();
    config.put(""w"", ""foo"");

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
"
"  @Test
  public void testSimpleAndAdvancedWriteConcern() {
    WriteConcern expected = WriteConcern.JOURNALED;
    JsonObject config = new JsonObject();
    config.put(""w"", ""majority"");
    config.put(""wtimeoutMS"", 1);
    config.put(""j"", true);
    // this overwrites the other options
    config.put(""writeConcern"", ""journaled"");

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidWriteConcern_w_boolean() {
    JsonObject config = new JsonObject();
    config.put(""w"", true);

    new WriteConcernParser(null, config).writeConcern();
  }
"
"  @Test
  public void testConnStringNoWriteConcern() {
    final ConnectionString connString = new ConnectionString(""mongodb://localhost:27017/mydb?replicaSet=myapp"");
    WriteConcern rp = new WriteConcernParser(connString, new JsonObject()).writeConcern();
    assertNull(rp);
  }
"
"  @Test
  public void testConnStringWriteConcern() {
    final ConnectionString connString = new ConnectionString(""mongodb://localhost:27017/mydb?replicaSet=myapp&safe=true"");
    WriteConcern wc = new WriteConcernParser(connString, new JsonObject()).writeConcern();

    assertNotNull(wc);
    assertEquals(WriteConcern.ACKNOWLEDGED, wc);
  }
"
"  @Test
  public void testConnStringSimpleAndAdvancedWriteConcern() {
    final ConnectionString connString = new ConnectionString(""mongodb://localhost:27017/mydb?replicaSet=myapp"" +
      ""&w=majority&wtimeoutms=20&journal=false"");
    WriteConcern expected = new WriteConcern(""majority"").withWTimeout(20, TimeUnit.MILLISECONDS).withJournal(false);
    WriteConcern wc = new WriteConcernParser(connString, new JsonObject()).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
"
"  @Test
  public void ssl_should_be_disabled_by_default() {
    // given
    final JsonObject configWithoutSSLInfo = new JsonObject().put(
      ""connection_string"", ""mongodb://localhost:27017/mydb?replicaSet=myRs""
    );

    // when
    final MongoClientSettings parsedSettings = new MongoClientOptionsParser(vertx, configWithoutSSLInfo).settings();

    // then
    assertFalse(parsedSettings.getSslSettings().isEnabled());
    assertFalse(parsedSettings.getSslSettings().isInvalidHostNameAllowed());
  }
"
"  @Test
  public void one_should_be_able_to_enable_ssl_support_via_connection_string() {
    // given
    final JsonObject withSSLEnabled = new JsonObject().put(
      ""connection_string"", ""mongodb://localhost:27017/mydb?replicaSet=myRs&ssl=true""
    );

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLEnabled).settings().getSslSettings();

    // then
    assertTrue(sslSettings.isEnabled());
  }
"
"  @Test
  public void one_should_be_able_to_enable_ssl_support_via_config_property() {
    // given
    final JsonObject withSSLEnabled = new JsonObject().put(""ssl"", true);

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLEnabled).settings().getSslSettings();

    // then
    assertTrue(sslSettings.isEnabled());
  }
"
"  @Test
  public void one_should_be_able_to_allow_invalid_host_names_via_connection_string() {
    // given
    final JsonObject withSSLAndInvalidHostnameEnabled = new JsonObject().put(
      ""connection_string"", ""mongodb://localhost:27017/mydb?replicaSet=myRs&ssl=true&sslInvalidHostNameAllowed=true""
    );

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndInvalidHostnameEnabled)
      .settings()
      .getSslSettings();

    // then
    assertTrue(sslSettings.isInvalidHostNameAllowed());
  }
"
"  @Test
  public void one_should_be_able_to_allow_invalid_host_names_via_config_property() {
    // given
    final JsonObject withSSLAndInvalidHostnameEnabled = new JsonObject()
      .put(""ssl"", true)
      .put(""sslInvalidHostNameAllowed"", true);

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndInvalidHostnameEnabled)
      .settings()
      .getSslSettings();

    // then
    assertTrue(sslSettings.isInvalidHostNameAllowed());
  }
"
"  @Test
  public void testTrustAllProperty() {
    // given
    final JsonObject withSSLAndTrustAllEnabled = new JsonObject()
      .put(""ssl"", true)
      .put(""trustAll"", true);

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndTrustAllEnabled)
      .settings()
      .getSslSettings();

    // then
    assertNotNull(sslSettings.getContext());
  }
"
"  @Test
  public void testEmptyCaPathProperty() {
    // given
    final JsonObject withSSLwithoutCaPath = new JsonObject().put(""ssl"", true);

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLwithoutCaPath)
      .settings()
      .getSslSettings();

    // then
    assertNotNull(sslSettings.getContext());
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidCaPathProperty() {
    // given
    final JsonObject withSSLAndCaPath = new JsonObject()
      .put(""ssl"", true)
      .put(""caPath"", ""notExisting.pem"");

    // then
    new MongoClientOptionsParser(vertx, withSSLAndCaPath);
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testEmptyCaPemCertificate() throws IOException {
    // given
    final File tmpFile = tmpFolder.newFile(""invalidCa.pem"");
    final JsonObject withSSLAndCaPath = new JsonObject()
      .put(""ssl"", true)
      .put(""caPath"", tmpFile.getAbsolutePath());

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndCaPath)
      .settings()
      .getSslSettings();

    // then
    assertNull(sslSettings.getContext());
  }
"
"  @Test
  public void testValidCaPemCertificate() throws IOException {
    // given
    final File tmpFile = tmpFolder.newFile(""validCa.pem"");
    try (final FileWriter tmpWriter = new FileWriter(tmpFile)) {
      tmpWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICljCCAfigAwIBAgIJAK0oe+f4DaojMAoGCCqGSM49BAMEMFkxCzAJBgNVBAYT\n"" +
        ""AkFUMQ8wDQYDVQQIDAZWaWVubmExDjAMBgNVBAoMBU5vRW52MSkwJwYDVQQLDCBO\n"" +
        ""b0VudiBSb290IENlcnRpZmljYXRlIEF1dGhvcml0eTAeFw0xNjEwMjcxNTAwNTFa\n"" +
        ""Fw00NjEwMjAxNTAwNTFaMFkxCzAJBgNVBAYTAkFUMQ8wDQYDVQQIDAZWaWVubmEx\n"" +
        ""DjAMBgNVBAoMBU5vRW52MSkwJwYDVQQLDCBOb0VudiBSb290IENlcnRpZmljYXRl\n"" +
        ""IEF1dGhvcml0eTCBmzAQBgcqhkjOPQIBBgUrgQQAIwOBhgAEAHpsMQth12N0d+aE\n"" +
        ""FIFRd8in4MTYZNSQEyQ4fuPDNq0Zb+4TXpUmedLZQJKkAQxorak8ESC/tXuQJDUL\n"" +
        ""OoKa+R6NAT4EKR1aaVVd7clC9rfGqVwGYslppycy9zsN6O4XLUiripamQF78FzRF\n"" +
        ""8wRZvkwYhzud+jpV6shgEMw3zmcwDSYKo2YwZDAdBgNVHQ4EFgQUD96n//91CReu\n"" +
        ""Cz1K0qics6aNFV0wHwYDVR0jBBgwFoAUD96n//91CReuCz1K0qics6aNFV0wEgYD\n"" +
        ""VR0TAQH/BAgwBgEB/wIBATAOBgNVHQ8BAf8EBAMCAYYwCgYIKoZIzj0EAwQDgYsA\n"" +
        ""MIGHAkFOxsApSB7fn8ZnYG/EUscn/uAkjxHsvdEkPKCC+XYCKMssW4YP2kR6gZjo\n"" +
        ""J8vaOAJZwNevBe/R9J8zMvsAWRJmWgJCAKLedGLnBuJOK9jjnKBwbVm5OIQfApMA\n"" +
        ""I2mJVnNXvS12w4DTZlP0K1t63WxsykBBTOIVXnYdPkdZvvnoAIcfA7iM\n"" +
        ""-----END CERTIFICATE-----"");
    }
    final JsonObject withSSLAndCaPath = new JsonObject()
      .put(""ssl"", true)
      .put(""caPath"", tmpFile.getAbsolutePath());

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndCaPath)
      .settings()
      .getSslSettings();

    // then
    assertNotNull(sslSettings.getContext());
  }
"
"  @Test
  public void testValidCaPemCertificateChain() throws IOException {
    // given
    final File tmpFile = tmpFolder.newFile(""validCa.pem"");
    try (final FileWriter tmpWriter = new FileWriter(tmpFile)) {
      tmpWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICljCCAfigAwIBAgIJAK0oe+f4DaojMAoGCCqGSM49BAMEMFkxCzAJBgNVBAYT\n"" +
        ""AkFUMQ8wDQYDVQQIDAZWaWVubmExDjAMBgNVBAoMBU5vRW52MSkwJwYDVQQLDCBO\n"" +
        ""b0VudiBSb290IENlcnRpZmljYXRlIEF1dGhvcml0eTAeFw0xNjEwMjcxNTAwNTFa\n"" +
        ""Fw00NjEwMjAxNTAwNTFaMFkxCzAJBgNVBAYTAkFUMQ8wDQYDVQQIDAZWaWVubmEx\n"" +
        ""DjAMBgNVBAoMBU5vRW52MSkwJwYDVQQLDCBOb0VudiBSb290IENlcnRpZmljYXRl\n"" +
        ""IEF1dGhvcml0eTCBmzAQBgcqhkjOPQIBBgUrgQQAIwOBhgAEAHpsMQth12N0d+aE\n"" +
        ""FIFRd8in4MTYZNSQEyQ4fuPDNq0Zb+4TXpUmedLZQJKkAQxorak8ESC/tXuQJDUL\n"" +
        ""OoKa+R6NAT4EKR1aaVVd7clC9rfGqVwGYslppycy9zsN6O4XLUiripamQF78FzRF\n"" +
        ""8wRZvkwYhzud+jpV6shgEMw3zmcwDSYKo2YwZDAdBgNVHQ4EFgQUD96n//91CReu\n"" +
        ""Cz1K0qics6aNFV0wHwYDVR0jBBgwFoAUD96n//91CReuCz1K0qics6aNFV0wEgYD\n"" +
        ""VR0TAQH/BAgwBgEB/wIBATAOBgNVHQ8BAf8EBAMCAYYwCgYIKoZIzj0EAwQDgYsA\n"" +
        ""MIGHAkFOxsApSB7fn8ZnYG/EUscn/uAkjxHsvdEkPKCC+XYCKMssW4YP2kR6gZjo\n"" +
        ""J8vaOAJZwNevBe/R9J8zMvsAWRJmWgJCAKLedGLnBuJOK9jjnKBwbVm5OIQfApMA\n"" +
        ""I2mJVnNXvS12w4DTZlP0K1t63WxsykBBTOIVXnYdPkdZvvnoAIcfA7iM\n"" +
        ""-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\n"" +
        ""MIIE0zCCA7ugAwIBAgIQGNrRniZ96LtKIVjNzGs7SjANBgkqhkiG9w0BAQUFADCB\n"" +
        ""yjELMAkGA1UEBhMCVVMxFzAVBgNVBAoTDlZlcmlTaWduLCBJbmMuMR8wHQYDVQQL\n"" +
        ""ExZWZXJpU2lnbiBUcnVzdCBOZXR3b3JrMTowOAYDVQQLEzEoYykgMjAwNiBWZXJp\n"" +
        ""U2lnbiwgSW5jLiAtIEZvciBhdXRob3JpemVkIHVzZSBvbmx5MUUwQwYDVQQDEzxW\n"" +
        ""ZXJpU2lnbiBDbGFzcyAzIFB1YmxpYyBQcmltYXJ5IENlcnRpZmljYXRpb24gQXV0\n"" +
        ""aG9yaXR5IC0gRzUwHhcNMDYxMTA4MDAwMDAwWhcNMzYwNzE2MjM1OTU5WjCByjEL\n"" +
        ""MAkGA1UEBhMCVVMxFzAVBgNVBAoTDlZlcmlTaWduLCBJbmMuMR8wHQYDVQQLExZW\n"" +
        ""ZXJpU2lnbiBUcnVzdCBOZXR3b3JrMTowOAYDVQQLEzEoYykgMjAwNiBWZXJpU2ln\n"" +
        ""biwgSW5jLiAtIEZvciBhdXRob3JpemVkIHVzZSBvbmx5MUUwQwYDVQQDEzxWZXJp\n"" +
        ""U2lnbiBDbGFzcyAzIFB1YmxpYyBQcmltYXJ5IENlcnRpZmljYXRpb24gQXV0aG9y\n"" +
        ""aXR5IC0gRzUwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCvJAgIKXo1\n"" +
        ""nmAMqudLO07cfLw8RRy7K+D+KQL5VwijZIUVJ/XxrcgxiV0i6CqqpkKzj/i5Vbex\n"" +
        ""t0uz/o9+B1fs70PbZmIVYc9gDaTY3vjgw2IIPVQT60nKWVSFJuUrjxuf6/WhkcIz\n"" +
        ""SdhDY2pSS9KP6HBRTdGJaXvHcPaz3BJ023tdS1bTlr8Vd6Gw9KIl8q8ckmcY5fQG\n"" +
        ""BO+QueQA5N06tRn/Arr0PO7gi+s3i+z016zy9vA9r911kTMZHRxAy3QkGSGT2RT+\n"" +
        ""rCpSx4/VBEnkjWNHiDxpg8v+R70rfk/Fla4OndTRQ8Bnc+MUCH7lP59zuDMKz10/\n"" +
        ""NIeWiu5T6CUVAgMBAAGjgbIwga8wDwYDVR0TAQH/BAUwAwEB/zAOBgNVHQ8BAf8E\n"" +
        ""BAMCAQYwbQYIKwYBBQUHAQwEYTBfoV2gWzBZMFcwVRYJaW1hZ2UvZ2lmMCEwHzAH\n"" +
        ""BgUrDgMCGgQUj+XTGoasjY5rw8+AatRIGCx7GS4wJRYjaHR0cDovL2xvZ28udmVy\n"" +
        ""aXNpZ24uY29tL3ZzbG9nby5naWYwHQYDVR0OBBYEFH/TZafC3ey78DAJ80M5+gKv\n"" +
        ""MzEzMA0GCSqGSIb3DQEBBQUAA4IBAQCTJEowX2LP2BqYLz3q3JktvXf2pXkiOOzE\n"" +
        ""p6B4Eq1iDkVwZMXnl2YtmAl+X6/WzChl8gGqCBpH3vn5fJJaCGkgDdk+bW48DW7Y\n"" +
        ""5gaRQBi5+MHt39tBquCWIMnNZBU4gcmU7qKEKQsTb47bDN0lAtukixlE0kF6BWlK\n"" +
        ""WE9gyn6CagsCqiUXObXbf+eEZSqVir2G3l6BFoMtEMze/aiCKm0oHw0LxOXnGiYZ\n"" +
        ""4fQRbxC1lfznQgUy286dUV4otp6F01vvpX1FQHKOtw5rDgb7MzVIcbidJ4vEZV8N\n"" +
        ""hnacRHr2lVz2XTIIM6RUthg/aFzyQkqFOFSDX9HoLPKsEdao7WNq\n"" +
        ""-----END CERTIFICATE-----\n"");
    }
    final JsonObject withSSLAndCaPath = new JsonObject()
      .put(""ssl"", true)
      .put(""caPath"", tmpFile.getAbsolutePath());

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndCaPath)
      .settings()
      .getSslSettings();

    // then
    assertNotNull(sslSettings.getContext());
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidPemCertificate() throws IOException {
    // given
    final File tmpFile = tmpFolder.newFile(""brokenCa.pem"");
    try (final FileWriter tmpWriter = new FileWriter(tmpFile)) {
      tmpWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICljCCAfigAwIBAgI...BROKEN...xsykBBTOIVXnYdPkdZvvnoAIcfA7iM\n"" +
        ""-----END CERTIFICATE-----"");
    }
    final JsonObject withSSLAndCaPath = new JsonObject()
      .put(""ssl"", true)
      .put(""caPath"", tmpFile.getAbsolutePath());

    // then
    new MongoClientOptionsParser(vertx, withSSLAndCaPath);
  }
"
"  @Test
  public void testValidKeyAndCertificate() throws IOException {
    // given
    final File tmpKeyFile = tmpFolder.newFile(""validKey.pem"");
    try (final FileWriter tmpKeyWriter = new FileWriter(tmpKeyFile)) {
      tmpKeyWriter.write(""-----BEGIN PRIVATE KEY-----\n"" +
        ""MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDVmCecLdUZU917\n"" +
        ""hweVz4JqvZ9vZEi1rH+BG98HYfRR/h3QaobxPImZu3hzKHZ+MPbm94HunLPAVA9y\n"" +
        ""ZhvZMToNfOuD4TUPBPloBuNzwBfZk2O4CaXeG4ailVWUfm5t/l+RD/55zYKuhw1/\n"" +
        ""Vl9lcOryF2XAmPQ2F1gwEKK7wt1Ak8zw8/yeYgBv1/F+ibCMvR6FVj9ABBEfTM+o\n"" +
        ""Os4oy51otUv0h63GqYgXMJyLX7q+AGWdC3srwwLQROtkzi7y00g/YryXUoIqdXEI\n"" +
        ""7CrNL35rZXcZ5LfGRwFX9evX11PpT3OShYlsJBcFE9KMatRoIWd6xUKlxTk0yLjo\n"" +
        ""OUE2tsMJAgMBAAECggEAdewZAjqzidYpU0eLQoRcBj5GRaNiGRrxEgCnM1Y7IwFe\n"" +
        ""yG/nrEu11DASIdHXCXhS99Tx4SCWhLpkBM6m1VQ+LrAm/ppZRr+CSpJzBLaq9C5R\n"" +
        ""QYviDSu5Ow2jP+ZFZWiorlfcMLbrTRu2sfSnmkOrEpkkTh6jxTFCONcWYP8GU93D\n"" +
        ""YCA3hSH0li7CueS+GYJ1JB2Cd7buu+tOhl36AhBD96miExlgNn0YGpTJJ3I0Hb+O\n"" +
        ""lKIIQy+KK8f9TXrSeZC3OYlTtJaIr9ejspTXxIYN11EIit5MFEwnnkCglcsePjsx\n"" +
        ""qeOFRumJ5Nj5H8qyCNZ5MtzwbLkyktJzlumvnyr+AQKBgQDv/QfGKZJFeoCEWpoj\n"" +
        ""f+078JxSYyPVNXxbbr2NuN/V79hJBol87ukycz2CZkDCubIKfubc50eXDmhWCp4p\n"" +
        ""aJgl6BMhnovftYrIrGWJLwqXnwFwsKJSrJJqHlHDJDRGfUSQEWNclNeaB3Mr8W46\n"" +
        ""Zcaadeikstvka9xKA1LOCG3oIQKBgQDj2FFOxZK27KhY/9Oz1dUsPtAYYbLOor/P\n"" +
        ""Rbne3jICQStH3dnUEmWKIKrdYV1u2saw5djn3ujwB0xEXydRvRgiSF0qxYjbm9CG\n"" +
        ""TJaiHhTsQDjWkYMZaxk3gc7Yfh8DHF0wlvWpu1wMXNsCJ6jxqW2e+jSRioZICPK6\n"" +
        ""McWWmArd6QKBgDWjoHEyKXdOAhuTBJCarzOOe+IONpwY8EqfXc6nW6A9k2H/DAvY\n"" +
        ""elbEWyMiJ6deSeT+qCsHpoCkv707ck5fCmKulFgXT7wYn4Rqw+b9lKh+6Zt+X0mL\n"" +
        ""OM5vKGctWGHI7eIlgMfYnLfYom1X8QMsbE9puy3UrEFJulrwkzlpuOcBAoGAVRNV\n"" +
        ""sNsXIFSXu7uyueizU3UU0LXSRVQB2QxJDg3bkHnzBj+xcX15Cq2N/2G2uIjaPf1l\n"" +
        ""E5dpVQ70jGcXUG8SDuMEXs8pfg7dOvhoGpqu51RHpN7qm9ggr1g5+x6Ex+2UYmtL\n"" +
        ""yZfbFAasBE74x1ujQgRdEqct4sHsmFezVrro+9kCgYEAgl70mKk9yK/f7515OaO0\n"" +
        ""Y39tgVzpAG6RN1NKnY6NR5VNNemZx5jhKfk5byaYxX4XBjygD0sQ5KTpaZmoQIIX\n"" +
        ""FxuwhLRRMn6vtsEf1HexJAtRd82aL5wKS62l0AXG/CVLAygn4aSSqLrgTyFFVUR3\n"" +
        ""cASPpPIdZaKZG6q4Hmcpl58=\n"" +
        ""-----END PRIVATE KEY-----"");
    }
    final File tmpCertFile = tmpFolder.newFile(""validCert.pem"");
    try (final FileWriter tmpCertWriter = new FileWriter(tmpCertFile)) {
      tmpCertWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICwTCCAamgAwIBAgIEBeVm4jANBgkqhkiG9w0BAQsFADARMQ8wDQYDVQQDEwZj\n"" +
        ""bGllbnQwHhcNMTgwNTI2MTEzNjUxWhcNMjEwNTI1MTEzNjUxWjARMQ8wDQYDVQQD\n"" +
        ""EwZjbGllbnQwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDVmCecLdUZ\n"" +
        ""U917hweVz4JqvZ9vZEi1rH+BG98HYfRR/h3QaobxPImZu3hzKHZ+MPbm94HunLPA\n"" +
        ""VA9yZhvZMToNfOuD4TUPBPloBuNzwBfZk2O4CaXeG4ailVWUfm5t/l+RD/55zYKu\n"" +
        ""hw1/Vl9lcOryF2XAmPQ2F1gwEKK7wt1Ak8zw8/yeYgBv1/F+ibCMvR6FVj9ABBEf\n"" +
        ""TM+oOs4oy51otUv0h63GqYgXMJyLX7q+AGWdC3srwwLQROtkzi7y00g/YryXUoIq\n"" +
        ""dXEI7CrNL35rZXcZ5LfGRwFX9evX11PpT3OShYlsJBcFE9KMatRoIWd6xUKlxTk0\n"" +
        ""yLjoOUE2tsMJAgMBAAGjITAfMB0GA1UdDgQWBBQ6xJBQsJCJdj/u0iTLYYD2qQsB\n"" +
        ""DDANBgkqhkiG9w0BAQsFAAOCAQEAfoquV375+eAGmfnlLxB30v9VhsFckrxFVpYs\n"" +
        ""XXC6h2G8MtXLpIEpgJo+4SZ4YjNwf/8m9J5j/duU8RukYanyzJdgkFFqKDBYCX7U\n"" +
        ""SD1nQP7729KnQgxtbR/+i3zkNgo7FATdkLq+HOxklNOEE24Ldenya39bsG779B9n\n"" +
        ""Sskcbq++7rMM+onDYBv6PbUKCm6nfqPspq809CLxSaUJg9+9ykut6hiyke/i7GEP\n"" +
        ""XIZHrM+mEvG00ES/zBIdV6TE0AIBP7q2MN7ylT509Ko9sUBMOZdEzikYp5GaRdiv\n"" +
        ""zG9q6rqK5COK614BwJFOD1DKV1BoDFsgugvfvm/mrc3QfIUPDA==\n"" +
        ""-----END CERTIFICATE-----"");
    }
    final JsonObject withSSLAndCertKeyPath = new JsonObject()
      .put(""ssl"", true)
      .put(""keyPath"", tmpKeyFile.getAbsolutePath())
      .put(""certPath"", tmpCertFile.getAbsolutePath());

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndCertKeyPath)
      .settings()
      .getSslSettings();

    // then
    assertNotNull(sslSettings.getContext());
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidKey() throws IOException {
    // given
    final File tmpKeyFile = tmpFolder.newFile(""brokenKey.pem"");
    try (final FileWriter tmpKeyWriter = new FileWriter(tmpKeyFile)) {
      tmpKeyWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICljCCAfigAwIBAgI...BROKEN...xsykBBTOIVXnYdPkdZvvnoAIcfA7iM\n"" +
        ""-----END CERTIFICATE-----"");
    }
    final File tmpCertFile = tmpFolder.newFile(""validCert.pem"");
    try (final FileWriter tmpCertWriter = new FileWriter(tmpCertFile)) {
      tmpCertWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICwTCCAamgAwIBAgIEBeVm4jANBgkqhkiG9w0BAQsFADARMQ8wDQYDVQQDEwZj\n"" +
        ""bGllbnQwHhcNMTgwNTI2MTEzNjUxWhcNMjEwNTI1MTEzNjUxWjARMQ8wDQYDVQQD\n"" +
        ""EwZjbGllbnQwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDVmCecLdUZ\n"" +
        ""U917hweVz4JqvZ9vZEi1rH+BG98HYfRR/h3QaobxPImZu3hzKHZ+MPbm94HunLPA\n"" +
        ""VA9yZhvZMToNfOuD4TUPBPloBuNzwBfZk2O4CaXeG4ailVWUfm5t/l+RD/55zYKu\n"" +
        ""hw1/Vl9lcOryF2XAmPQ2F1gwEKK7wt1Ak8zw8/yeYgBv1/F+ibCMvR6FVj9ABBEf\n"" +
        ""TM+oOs4oy51otUv0h63GqYgXMJyLX7q+AGWdC3srwwLQROtkzi7y00g/YryXUoIq\n"" +
        ""dXEI7CrNL35rZXcZ5LfGRwFX9evX11PpT3OShYlsJBcFE9KMatRoIWd6xUKlxTk0\n"" +
        ""yLjoOUE2tsMJAgMBAAGjITAfMB0GA1UdDgQWBBQ6xJBQsJCJdj/u0iTLYYD2qQsB\n"" +
        ""DDANBgkqhkiG9w0BAQsFAAOCAQEAfoquV375+eAGmfnlLxB30v9VhsFckrxFVpYs\n"" +
        ""XXC6h2G8MtXLpIEpgJo+4SZ4YjNwf/8m9J5j/duU8RukYanyzJdgkFFqKDBYCX7U\n"" +
        ""SD1nQP7729KnQgxtbR/+i3zkNgo7FATdkLq+HOxklNOEE24Ldenya39bsG779B9n\n"" +
        ""Sskcbq++7rMM+onDYBv6PbUKCm6nfqPspq809CLxSaUJg9+9ykut6hiyke/i7GEP\n"" +
        ""XIZHrM+mEvG00ES/zBIdV6TE0AIBP7q2MN7ylT509Ko9sUBMOZdEzikYp5GaRdiv\n"" +
        ""zG9q6rqK5COK614BwJFOD1DKV1BoDFsgugvfvm/mrc3QfIUPDA==\n"" +
        ""-----END CERTIFICATE-----"");
    }
    final JsonObject withSSLAndCertKeyPath = new JsonObject()
      .put(""ssl"", true)
      .put(""keyPath"", tmpKeyFile.getAbsolutePath())
      .put(""certPath"", tmpCertFile.getAbsolutePath());

    // then
    new MongoClientOptionsParser(vertx, withSSLAndCertKeyPath);
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidCertificate() throws IOException {
    // given
    final File tmpKeyFile = tmpFolder.newFile(""validKey.pem"");
    try (final FileWriter tmpKeyWriter = new FileWriter(tmpKeyFile)) {
      tmpKeyWriter.write(""-----BEGIN PRIVATE KEY-----\n"" +
        ""MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDVmCecLdUZU917\n"" +
        ""hweVz4JqvZ9vZEi1rH+BG98HYfRR/h3QaobxPImZu3hzKHZ+MPbm94HunLPAVA9y\n"" +
        ""ZhvZMToNfOuD4TUPBPloBuNzwBfZk2O4CaXeG4ailVWUfm5t/l+RD/55zYKuhw1/\n"" +
        ""Vl9lcOryF2XAmPQ2F1gwEKK7wt1Ak8zw8/yeYgBv1/F+ibCMvR6FVj9ABBEfTM+o\n"" +
        ""Os4oy51otUv0h63GqYgXMJyLX7q+AGWdC3srwwLQROtkzi7y00g/YryXUoIqdXEI\n"" +
        ""7CrNL35rZXcZ5LfGRwFX9evX11PpT3OShYlsJBcFE9KMatRoIWd6xUKlxTk0yLjo\n"" +
        ""OUE2tsMJAgMBAAECggEAdewZAjqzidYpU0eLQoRcBj5GRaNiGRrxEgCnM1Y7IwFe\n"" +
        ""yG/nrEu11DASIdHXCXhS99Tx4SCWhLpkBM6m1VQ+LrAm/ppZRr+CSpJzBLaq9C5R\n"" +
        ""QYviDSu5Ow2jP+ZFZWiorlfcMLbrTRu2sfSnmkOrEpkkTh6jxTFCONcWYP8GU93D\n"" +
        ""YCA3hSH0li7CueS+GYJ1JB2Cd7buu+tOhl36AhBD96miExlgNn0YGpTJJ3I0Hb+O\n"" +
        ""lKIIQy+KK8f9TXrSeZC3OYlTtJaIr9ejspTXxIYN11EIit5MFEwnnkCglcsePjsx\n"" +
        ""qeOFRumJ5Nj5H8qyCNZ5MtzwbLkyktJzlumvnyr+AQKBgQDv/QfGKZJFeoCEWpoj\n"" +
        ""f+078JxSYyPVNXxbbr2NuN/V79hJBol87ukycz2CZkDCubIKfubc50eXDmhWCp4p\n"" +
        ""aJgl6BMhnovftYrIrGWJLwqXnwFwsKJSrJJqHlHDJDRGfUSQEWNclNeaB3Mr8W46\n"" +
        ""Zcaadeikstvka9xKA1LOCG3oIQKBgQDj2FFOxZK27KhY/9Oz1dUsPtAYYbLOor/P\n"" +
        ""Rbne3jICQStH3dnUEmWKIKrdYV1u2saw5djn3ujwB0xEXydRvRgiSF0qxYjbm9CG\n"" +
        ""TJaiHhTsQDjWkYMZaxk3gc7Yfh8DHF0wlvWpu1wMXNsCJ6jxqW2e+jSRioZICPK6\n"" +
        ""McWWmArd6QKBgDWjoHEyKXdOAhuTBJCarzOOe+IONpwY8EqfXc6nW6A9k2H/DAvY\n"" +
        ""elbEWyMiJ6deSeT+qCsHpoCkv707ck5fCmKulFgXT7wYn4Rqw+b9lKh+6Zt+X0mL\n"" +
        ""OM5vKGctWGHI7eIlgMfYnLfYom1X8QMsbE9puy3UrEFJulrwkzlpuOcBAoGAVRNV\n"" +
        ""sNsXIFSXu7uyueizU3UU0LXSRVQB2QxJDg3bkHnzBj+xcX15Cq2N/2G2uIjaPf1l\n"" +
        ""E5dpVQ70jGcXUG8SDuMEXs8pfg7dOvhoGpqu51RHpN7qm9ggr1g5+x6Ex+2UYmtL\n"" +
        ""yZfbFAasBE74x1ujQgRdEqct4sHsmFezVrro+9kCgYEAgl70mKk9yK/f7515OaO0\n"" +
        ""Y39tgVzpAG6RN1NKnY6NR5VNNemZx5jhKfk5byaYxX4XBjygD0sQ5KTpaZmoQIIX\n"" +
        ""FxuwhLRRMn6vtsEf1HexJAtRd82aL5wKS62l0AXG/CVLAygn4aSSqLrgTyFFVUR3\n"" +
        ""cASPpPIdZaKZG6q4Hmcpl58=\n"" +
        ""-----END PRIVATE KEY-----"");
    }
    final File tmpCertFile = tmpFolder.newFile(""brokenCert.pem"");
    try (final FileWriter tmpCertWriter = new FileWriter(tmpCertFile)) {
      tmpCertWriter.write(""-----BEGIN CERTIFICATE-----\n"" +
        ""MIICwTCCAamgAwIBA...BROKEN...FOD1DKV1BoDFsgugvfvm/mrc3QfIUPDA==\n"" +
        ""-----END CERTIFICATE-----"");
    }
    final JsonObject withSSLAndCertKeyPath = new JsonObject()
      .put(""ssl"", true)
      .put(""keyPath"", tmpKeyFile.getAbsolutePath())
      .put(""certPath"", tmpCertFile.getAbsolutePath());

    // then
    new MongoClientOptionsParser(vertx, withSSLAndCertKeyPath);
  }
"
"  @Test
  public void testSocketSettings() {
    int connectTimeoutMS = Math.abs(TestUtils.randomInt());
    int socketTimeoutMS = Math.abs(TestUtils.randomInt());
    int receiveBufferSize = Math.abs(TestUtils.randomInt());
    int sendBufferSize = Math.abs(TestUtils.randomInt());

    JsonObject config = new JsonObject();
    config.put(""connectTimeoutMS"", connectTimeoutMS);
    config.put(""socketTimeoutMS"", socketTimeoutMS);
    config.put(""receiveBufferSize"", receiveBufferSize);
    config.put(""sendBufferSize"", sendBufferSize);

    SocketSettings settings = new SocketSettingsParser(null, config).settings();
    assertEquals(connectTimeoutMS, settings.getConnectTimeout(TimeUnit.MILLISECONDS));
    assertEquals(socketTimeoutMS, settings.getReadTimeout(TimeUnit.MILLISECONDS));
    assertEquals(receiveBufferSize, settings.getReceiveBufferSize());
    assertEquals(sendBufferSize, settings.getSendBufferSize());
  }
"
"  @Test
  public void should_not_include_any_stream_type_by_default_for_backwards_compatibility() {
    // given
    final JsonObject noStreamTypeProvided = new JsonObject().put(
      ""connection_string"", ""mongodb://localhost:27017/mydb?replicaSet=myRs""
    );

    // when
    final MongoClientSettings parsedSettings = new MongoClientOptionsParser(vertx, noStreamTypeProvided).settings();

    // then
    assertNull(parsedSettings.getStreamFactoryFactory());
  }
"
"  @Test
  public void should_parse_stream_type_from_config_property(String streamTypeString, Class<StreamFactoryFactory> streamType) {
    // given
    final JsonObject cfgWithStreamTypeProvided = new JsonObject().put(""streamType"", streamTypeString);

    // when
    final MongoClientSettings parsedSettings = new MongoClientOptionsParser(vertx, cfgWithStreamTypeProvided).settings();

    // then
    assertThat(parsedSettings.getStreamFactoryFactory(), instanceOf(streamType));
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void only_valid_stream_type_values_allowed_as_config_property() {
    // given
    final JsonObject withInvalidStreamType = new JsonObject().put(""streamType"", ""unrecognized"");

    // expect thrown
    new MongoClientOptionsParser(vertx, withInvalidStreamType).settings();
  }
"
"  @Test
  public void testConnectionString() {
    String username = TestUtils.randomAlphaString(8);
    String password = TestUtils.randomAlphaString(20);

    ConnectionString connectionString = new ConnectionString(
      String.format(
        ""mongodb://%s:%s@%s/%s"",
        username,
        password,
        ""localhost:27017"",
        ""my-datasource""));

    List<MongoCredential> credentials = new CredentialListParser(connectionString, null).credentials();
    assertEquals(1, credentials.size());
    MongoCredential credential = credentials.get(0);
    assertEquals(username, credential.getUserName());
    assertArrayEquals(password.toCharArray(), credential.getPassword());
    assertEquals(""my-datasource"", credential.getSource());
  }
"
"  @Test
  public void testSimpleAuth() {
    JsonObject config = new JsonObject().put(""db_name"", ""my-datasource"");
    String username = TestUtils.randomAlphaString(8);
    String password = TestUtils.randomAlphaString(20);
    config.put(""username"", username);
    config.put(""password"", password);


    List<MongoCredential> credentials = new CredentialListParser(null, config).credentials();
    assertEquals(1, credentials.size());
    MongoCredential credential = credentials.get(0);
    assertEquals(username, credential.getUserName());
    assertArrayEquals(password.toCharArray(), credential.getPassword());
    // default source should be the database name - see https://github.com/vert-x3/vertx-mongo-client/issues/46.
    assertEquals(""my-datasource"", credential.getSource());
  }
"
"  @Test
  public void testSimpleAuthWithSource() {
    JsonObject config = new JsonObject();
    String username = TestUtils.randomAlphaString(8);
    String password = TestUtils.randomAlphaString(20);
    String authSource = TestUtils.randomAlphaString(10);
    config.put(""username"", username);
    config.put(""password"", password);
    config.put(""authSource"", authSource);

    List<MongoCredential> credentials = new CredentialListParser(null, config).credentials();
    assertEquals(1, credentials.size());
    MongoCredential credential = credentials.get(0);
    assertEquals(username, credential.getUserName());
    assertArrayEquals(password.toCharArray(), credential.getPassword());
    assertEquals(authSource, credential.getSource());
  }
"
"  @Test
  public void testAuth_GSSAPI() {
    JsonObject config = new JsonObject();
    String username = TestUtils.randomAlphaString(8);
    String authSource = TestUtils.randomAlphaString(10);
    config.put(""username"", username);
    config.put(""authSource"", authSource);
    config.put(""authMechanism"", ""GSSAPI"");

    List<MongoCredential> credentials = new CredentialListParser(null, config).credentials();
    assertEquals(1, credentials.size());
    MongoCredential credential = credentials.get(0);
    assertEquals(username, credential.getUserName());
    assertNotEquals(authSource, credential.getSource()); // It should ignore the source we pass in

    assertEquals(AuthenticationMechanism.GSSAPI, credential.getAuthenticationMechanism());
  }
"
"    @Test
    public void testGetAgainstTrustedCertServer() throws RepositoryException, ClientProtocolException, IOException {
        assumeTrue(""Cannot connect to http://www.apache.org"", canConnectTo(""http://www.apache.org""));
        RepositoryServiceImpl repositoryServiceImpl = RepositoryServiceImplTest.getRepositoryService(""https://jackrabbit.apache.org/jcr"", ConnectionOptions.builder().build());
        HttpClient client = repositoryServiceImpl.getClient(null);
        HttpGet get = new HttpGet(""https://jackrabbit.apache.org/jcr/index.html"");
        String content = client.execute(get, new BasicResponseHandler());
        assertFalse(content.isEmpty());
    }
"
"    @Test
    public void testGetAgainstTrustedCertServerWithSystemProperties() throws RepositoryException, ClientProtocolException, IOException {
        assumeTrue(""Cannot connect to http://www.apache.org"", canConnectTo(""http://www.apache.org""));
        // use dedicated trust store
        Path keyStorePath = tmpDirectory.getRoot().toPath().resolve(""emptyPKCS12.keystore"");
        try (InputStream is = this.getClass().getResourceAsStream(""emptyPKCS12.keystore"")) {
            Files.copy(is, keyStorePath);
        }
        String oldTrustStore = System.setProperty(""javax.net.ssl.trustStore"", keyStorePath.toString());
        String oldTrustStorePassword = System.setProperty(""javax.net.ssl.trustStorePassword"", ""storePassword"");
        String oldDebug = System.setProperty(""javax.net.debug"", ""ssl"");
        try {
            ConnectionOptions connectionOptions = ConnectionOptions.builder().useSystemProperties(true).build();
            RepositoryServiceImpl repositoryServiceImpl = RepositoryServiceImplTest.getRepositoryService(""https://jackrabbit.apache.org/jcr"", connectionOptions);
            HttpClient client = repositoryServiceImpl.getClient(null);
            HttpGet get = new HttpGet(""https://jackrabbit.apache.org/jcr/index.html"");
            // connection must fail as cert is not trusted due to used trust store being empty
            assertThrows(SSLException.class, () -> client.execute(get, new BasicResponseHandler()));
        } finally {
            setOrClearSystemProperty(""javax.net.ssl.trustStore"", oldTrustStore);
            setOrClearSystemProperty(""javax.net.ssl.trustStorePassword"", oldTrustStorePassword);
            setOrClearSystemProperty(""javax.net.debug"", oldDebug);
        }
    }
"
"    @Test
    public void testException() {

        String wspuri = ""https://example.org/foo/"";
        IdURICache cache = new IdURICache(wspuri);
        String test;

        // port number
        test = ""https://example.org:443/foo/x"";
        try {
            cache.add(test, null);
            fail(""should throw"");
        } catch (IllegalArgumentException ex) {
            assertEquals(""Workspace mismatch: '"" + test + ""' not under workspace '"" + wspuri
                    + ""' (position 18: '{https://example.org}:443/foo/x', expected: '/foo/')"", ex.getMessage());
        }

        // protocol
        test = ""http://example.org/foo/x"";
        try {
            cache.add(test, null);
            fail(""should throw"");
        } catch (IllegalArgumentException ex) {
            assertEquals(""Workspace mismatch: '"" + test + ""' not under workspace '"" + wspuri
                    + ""' (position 3: '{http}://example.org/foo/x', expected: 's://example.org/foo/')"", ex.getMessage());
        }

        // hostname
        test = ""https://example.com/foo/x"";
        try {
            cache.add(test, null);
            fail(""should throw"");
        } catch (IllegalArgumentException ex) {
            assertEquals(""Workspace mismatch: '"" + test + ""' not under workspace '"" + wspuri
                    + ""' (position 15: '{https://example.}com/foo/x', expected: 'org/foo/')"", ex.getMessage());
        }

        // root path
        test = ""https://example.org/bar/x"";
        try {
            cache.add(test, null);
            fail(""should throw"");
        } catch (IllegalArgumentException ex) {
            assertEquals(""Workspace mismatch: '"" + test + ""' not under workspace '"" + wspuri
                    + ""' (position 19: '{https://example.org/}bar/x', expected: 'foo/')"", ex.getMessage());
        }

        // too short
        test = ""https://example.org/fo/x"";
        try {
            cache.add(test, null);
            fail(""should throw"");
        } catch (IllegalArgumentException ex) {
            assertEquals(""Workspace mismatch: '"" + test + ""' not under workspace '"" + wspuri
                    + ""' (position 21: '{https://example.org/fo}/x', expected: 'o/')"", ex.getMessage());
        }

        // way too short
        test = ""https://x.org/foo/x"";
        try {
            cache.add(test, null);
            fail(""should throw"");
        } catch (IllegalArgumentException ex) {
            assertEquals(""Workspace mismatch: '"" + test + ""' not under workspace '"" + wspuri
                    + ""' (position 7: '{https://}x.org/foo/x', expected: 'example.org/foo/')"", ex.getMessage());
        }
    }
"
"    @Test
    public void testWithSystemPropertiesAndIncompatibleConnectionOptions() throws RepositoryException {
        ConnectionOptions connectionOptions = ConnectionOptions.builder().useSystemProperties(true).allowSelfSignedCertificates(true).build();
        assertThrows(RepositoryException.class, ()->getRepositoryService(""https://jackrabbit.apache.org/jcr"", connectionOptions));
        ConnectionOptions connectionOptions2 = ConnectionOptions.builder().useSystemProperties(true).disableHostnameVerification(true).build();
        assertThrows(RepositoryException.class, ()->getRepositoryService(""https://jackrabbit.apache.org/jcr"", connectionOptions2));
    }
"
"    @Test
    public void testFromServiceParameterToServiceParameters() {
        Map<String, String> serviceParameters = new HashMap<>();
        serviceParameters.put(ConnectionOptions.PARAM_USE_SYSTEM_PROPERTIES, ""true"");
        serviceParameters.put(ConnectionOptions.PARAM_MAX_CONNECTIONS, ""10"");
        serviceParameters.put(ConnectionOptions.PARAM_ALLOW_SELF_SIGNED_CERTIFICATES, ""true"");
        serviceParameters.put(ConnectionOptions.PARAM_DISABLE_HOSTNAME_VERIFICATION, ""true"");
        serviceParameters.put(ConnectionOptions.PARAM_CONNECTION_TIMEOUT_MS, ""100"");
        serviceParameters.put(ConnectionOptions.PARAM_REQUEST_TIMEOUT_MS, ""200"");
        serviceParameters.put(ConnectionOptions.PARAM_SOCKET_TIMEOUT_MS, ""300"");
        serviceParameters.put(ConnectionOptions.PARAM_PROXY_HOST, ""somehost"");
        serviceParameters.put(ConnectionOptions.PARAM_PROXY_PORT, ""111"");
        serviceParameters.put(ConnectionOptions.PARAM_PROXY_USERNAME, ""user"");
        serviceParameters.put(ConnectionOptions.PARAM_PROXY_PASSWORD, ""password"");
        Assert.assertEquals(serviceParameters, ConnectionOptions.fromServiceFactoryParameters(serviceParameters).toServiceFactoryParameters());
    }
"
"    @Test
    public void testLegacyMaxConnectionsParameter() {
        Map<String, String> serviceParameters = new HashMap<>();
        serviceParameters.put(""org.apache.jackrabbit.spi2davex.MaxConnections"", ""30"");
        ConnectionOptions connectionOptions = ConnectionOptions.builder().maxConnections(30).build();
        Assert.assertEquals(connectionOptions, ConnectionOptions.fromServiceFactoryParameters(serviceParameters));
    }
"
"    @Test
    public void testBuilder() {
        ConnectionOptions.Builder builder = ConnectionOptions.builder();
        builder.allowSelfSignedCertificates(true);
        builder.disableHostnameVerification(false);
        builder.maxConnections(10);
        builder.connectionTimeoutMs(100);
        builder.requestTimeoutMs(200);
        builder.socketTimeoutMs(300);
        builder.proxyHost(""proxyHost"");
        builder.proxyPort(1234);
        builder.proxyUsername(""proxyUser"");
        builder.proxyPassword(""proxyPassword"");
        builder.proxyProtocol(""https:"");
        ConnectionOptions options = builder.build();
        Assert.assertEquals(true, options.isAllowSelfSignedCertificates());
        Assert.assertEquals(false, options.isDisableHostnameVerification());
        Assert.assertEquals(10, options.getMaxConnections());
        Assert.assertEquals(100, options.getConnectionTimeoutMs());
        Assert.assertEquals(200, options.getRequestTimeoutMs());
        Assert.assertEquals(300, options.getSocketTimeoutMs());
        Assert.assertEquals(""proxyHost"", options.getProxyHost());
        Assert.assertEquals(1234, options.getProxyPort());
        Assert.assertEquals(""proxyUser"", options.getProxyUsername());
        Assert.assertEquals(""proxyPassword"", options.getProxyPassword());
        Assert.assertEquals(""https:"", options.getProxyProtocol());
    }
"
"    @Test
    public void testDavComplianceHeader() {

        List<String> l;

        l = FieldValueParser.tokenizeList(""1"");
        assertArrayEquals(new String[]{""1""}, l.toArray());

        l = FieldValueParser.tokenizeList(""1,2,,,,,3,,bind,"");
        assertArrayEquals(new String[]{""1"",""2"",""3"",""bind""}, l.toArray());

        l = FieldValueParser.tokenizeList(""1,2,<http://example.com/foo,bar>"");
        assertArrayEquals(new String[]{""1"",""2"",""<http://example.com/foo,bar>""}, l.toArray());
    }
"
"    @Test
    public void testDoubleOutput() throws Exception {
        StringWriter writer = new StringWriter();
        JsonWriter jsonWriter = new JsonWriter(writer);

        Node parent = createMock(Node.class);
        Property doubleProperty = createMock(Property.class);
        Value doublePropertyValue = createMock(Value.class);
        expect(doubleProperty.getType()).andReturn(PropertyType.DOUBLE).anyTimes();
        expect(doubleProperty.getName()).andReturn(""singleValued"").anyTimes();
        expect(doubleProperty.isMultiple()).andReturn(false).anyTimes();
        expect(doubleProperty.getValue()).andReturn(doublePropertyValue).anyTimes();
        expect(doublePropertyValue.getType()).andReturn(PropertyType.DOUBLE).anyTimes();
        expect(doublePropertyValue.getDouble()).andReturn(5d).anyTimes();
        expect(doublePropertyValue.getString()).andReturn(""5"").anyTimes();

        Property mvDoubleProperty = createMock(Property.class);
        Value mvDoublePropertyValue1 = createMock(Value.class);
        Value mvDoublePropertyValue2 = createMock(Value.class);
        expect(mvDoubleProperty.getType()).andReturn(PropertyType.DOUBLE).anyTimes();
        expect(mvDoubleProperty.getName()).andReturn(""multiValued"").anyTimes();
        expect(mvDoubleProperty.isMultiple()).andReturn(true).anyTimes();
        expect(mvDoubleProperty.getValues()).andReturn(new Value[] { mvDoublePropertyValue1, mvDoublePropertyValue2}).anyTimes();
        expect(mvDoublePropertyValue1.getType()).andReturn(PropertyType.DOUBLE).anyTimes();
        expect(mvDoublePropertyValue1.getDouble()).andReturn(42d).anyTimes();
        expect(mvDoublePropertyValue1.getString()).andReturn(""42"").anyTimes();
        expect(mvDoublePropertyValue2.getType()).andReturn(PropertyType.DOUBLE).anyTimes();
        expect(mvDoublePropertyValue2.getDouble()).andReturn(98.6).anyTimes();
        expect(mvDoublePropertyValue2.getString()).andReturn(""98.6"").anyTimes();

        final List<Property> properties = new ArrayList<Property>();
        properties.add(doubleProperty);
        properties.add(mvDoubleProperty);
        expect(parent.getProperties()).andAnswer(new IAnswer<PropertyIterator>() {
            @Override
            public PropertyIterator answer() throws Throwable {
                return new PropertyIteratorAdapter(properties.iterator());
            }
"
"    @Test
    public void createRepositories() throws Exception {
        doCreateRepositories(""jackrabbit-2.6"");
    }
"
"    @Test
    public void createRepositories() throws Exception {
        doCreateRepositories(""jackrabbit-1.2"");
    }
"
"    @Test
    public void createRepositories() throws Exception {
        doCreateRepositories(""jackrabbit-1.5"");
    }
"
"    @Test
    public void createRepositories() throws Exception {
        doCreateRepositories(""jackrabbit-1.4"");
    }
"
"    @Test
    public void createRepositories() throws Exception {
        doCreateRepositories(""jackrabbit-1.6"");
    }
"
"    @Test
    public void createRepositories() throws Exception {
        doCreateRepositories(""jackrabbit-1.0"");
    }
"
"    @Test
    public void createRepositories() throws Exception {
        doCreateRepositories(""jackrabbit-1.1"");
    }
"
"    @Test
    public void createRepositories() throws Exception {
        doCreateRepositories(""jackrabbit-2.1"");
    }
"
"    @Test
    public void createRepositories() throws Exception {
        doCreateRepositories(""jackrabbit-2.2"");
    }
"
"    @Test
    public void createRepositories() throws Exception {
        doCreateRepositories(""jackrabbit-1.3"");
    }
"
"    @Test
    public void createRepositories() throws Exception {
        doCreateRepositories(""jackrabbit-2.4"");
    }
"
"    @Test
    public void createRepositories() throws Exception {
        doCreateRepositories(""jackrabbit-2.0"");
    }
"
"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""2.3"");

        System.setProperty(QueryEngine.NATIVE_SORT_SYSTEM_PROPERTY, ""true"");
        testPerformance(""2.3-expSort"", getDefaultConfig());
        System.setProperty(QueryEngine.NATIVE_SORT_SYSTEM_PROPERTY, ""false"");
    }
"
"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""1.6"");
    }
"
"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""1.0"");
    }
"
"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""1.3"");
    }
"
"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""2.2"");
    }
"
"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""2.4"");

        System.setProperty(QueryEngine.NATIVE_SORT_SYSTEM_PROPERTY, ""true"");
        testPerformance(""2.4-expSort"", getDefaultConfig());
        System.setProperty(QueryEngine.NATIVE_SORT_SYSTEM_PROPERTY, ""false"");
    }
"
"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""1.5"");
    }
"
"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""2.1"");
    }
"
"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""1.1"");
    }
"
"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""2.0"");
    }
"
"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""1.4"");
    }
"
"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""2.6"");

        System.setProperty(QueryEngine.NATIVE_SORT_SYSTEM_PROPERTY, ""true"");
        testPerformance(""2.6-expSort"", getDefaultConfig());
        System.setProperty(QueryEngine.NATIVE_SORT_SYSTEM_PROPERTY, ""false"");
    }
"
"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""1.2"");
    }
"
"    @Test
    public void testGetOrCreateByPath1() throws RepositoryException {
        String path = testRoot + ""/foo"";
        Node node = JcrUtils.getOrCreateByPath(path, ""nt:unstructured"", superuser);
        superuser.save();
        assertEquals(path, node.getPath());
        assertTrue(superuser.nodeExists(path));

        // existing top-level node, two new descendant nodes
        String path2 = testRoot + ""/foo/a/b"";
        Node node2 = JcrUtils.getOrCreateByPath(path2, ""nt:unstructured"", superuser);
        superuser.save();
        assertEquals(path2, node2.getPath());
        assertTrue(superuser.nodeExists(path2));
    }
"
"    @Test
    public void testGetOrCreateByPathNoRoot() throws RepositoryException {
        String base = testRoot + ""/foo"";
        Node inter = JcrUtils.getOrCreateByPath(base, ""nt:unstructured"", superuser);
        assertEquals(base, inter.getPath());
        superuser.save();

        // test what happens if getRootNode() throws
        Session mockedSession = Mockito.spy(superuser);
        Mockito.when(mockedSession.getRootNode()).thenThrow(new AccessDeniedException(""access denied""));
        Mockito.when(mockedSession.getNode(""/"")).thenThrow(new AccessDeniedException(""access denied""));
        Mockito.when(mockedSession.getItem(""/"")).thenThrow(new AccessDeniedException(""access denied""));
        Mockito.when(mockedSession.nodeExists(""/"")).thenReturn(false);

        Node result = JcrUtils.getOrCreateByPath(base + ""/bar"", false, null, null, mockedSession, false);
        mockedSession.save();
        assertEquals(base + ""/bar"", result.getPath());

        // already exists -> nop
        Node result2 = JcrUtils.getOrCreateByPath(base + ""/bar"", false, null, null, mockedSession, false);
        mockedSession.save();
        assertEquals(base + ""/bar"", result2.getPath());

        // create unique
        Node result3 = JcrUtils.getOrCreateByPath(base + ""/bar"", true, null, null, mockedSession, false);
        mockedSession.save();
        assertEquals(base + ""/bar0"", result3.getPath());

        // already exists with createUnique == false should pass even when parent isn't readable
        Mockito.when(mockedSession.getNode(base)).thenThrow(new AccessDeniedException(""access denied""));
        Mockito.when(mockedSession.getItem(base)).thenThrow(new AccessDeniedException(""access denied""));
        Mockito.when(mockedSession.nodeExists(base)).thenReturn(false);
        Node result4 = JcrUtils.getOrCreateByPath(base + ""/bar"", false, null, null, mockedSession, false);
        mockedSession.save();
        assertEquals(base + ""/bar"", result4.getPath());
    }
"
"    @Test
    public void testQuery() throws Exception {
        if (Constants.WINDOWS) {
            return;
        }
        for (int i = 0; i < 100; i++) {
            session.getRootNode().addNode(""node"" + i, ""nt:unstructured"");
        }
        session.save();
        final QueryManager qm = session.getWorkspace().getQueryManager();
        final AtomicBoolean stop = new AtomicBoolean(false);
        final List<Exception> exceptions = Collections.synchronizedList(
                new ArrayList<Exception>());
        Thread t = new Thread(new Runnable() {
            @Override
            public void run() {
                while (!stop.get() && exceptions.isEmpty()) {
                    try {
                        // execute query
                        String stmt = ""//*[@jcr:primaryType='nt:unstructured']"";
                        qm.createQuery(stmt, Query.XPATH).execute();
                    } catch (RepositoryException e) {
                        if (Constants.SUN_OS) {
                            // on Solaris it's OK when the root cause
                            // of the exception is an InterruptedIOException
                            // the underlying file is not closed
                            Throwable t = e;
                            while (t.getCause() != null) {
                                t = t.getCause();
                            }
                            if (!(t instanceof InterruptedIOException)) {
                                exceptions.add(e);
                            }
                        } else {
                            exceptions.add(e);
                        }
                    }
                }
            }
"
"    @Test
    public void testEmptyGlobRestriction()throws Exception{
        Node grandchild = superuser.getNode(childNPath).addNode(""child"");
        String ccPath = grandchild.getPath();
        superuser.save();

        // first deny access to 'path' (read-access is granted in the test setup)
        Privilege[] read = privilegesFromName(Privilege.JCR_READ);
        withdrawPrivileges(path, read, Collections.EMPTY_MAP);

        Session testSession = getTestSession();
        assertFalse(testSession.nodeExists(path));
        assertFalse(canGetNode(testSession, path));
        assertFalse(testSession.nodeExists(childNPath));
        assertFalse(canGetNode(testSession, childNPath));
        assertFalse(testSession.nodeExists(ccPath));
        assertFalse(canGetNode(testSession, ccPath));
        assertFalse(testSession.propertyExists(childNPath + '/' + JcrConstants.JCR_PRIMARYTYPE));

        Map<String, Value> emptyStringRestriction = new HashMap<String, Value>(getRestrictions(superuser, childNPath));
        emptyStringRestriction.put(AccessControlConstants.P_GLOB.toString(), vf.createValue(""""));

        givePrivileges(childNPath, read, emptyStringRestriction);
        assertFalse(testSession.nodeExists(path));
        assertFalse(canGetNode(testSession, path));
        assertTrue(testSession.nodeExists(childNPath));
        assertTrue(canGetNode(testSession, childNPath));
        assertFalse(testSession.nodeExists(ccPath));
        assertFalse(canGetNode(testSession, ccPath));
        assertFalse(testSession.propertyExists(childNPath + '/' + JcrConstants.JCR_PRIMARYTYPE));

        givePrivileges(ccPath, read, Collections.EMPTY_MAP);
        assertTrue(testSession.nodeExists(ccPath));
        assertTrue(canGetNode(testSession, ccPath));
        assertTrue(testSession.propertyExists(ccPath + '/' + JcrConstants.JCR_PRIMARYTYPE));
    }
"
"    @Test
    public void testEmptyGlobRestriction2()throws Exception{
        Node grandchild = superuser.getNode(childNPath).addNode(""child"");
        String ccPath = grandchild.getPath();
        superuser.save();

        // first deny access to 'path' (read-access is granted in the test setup)
        Privilege[] read = privilegesFromName(Privilege.JCR_READ);
        withdrawPrivileges(path, read, Collections.EMPTY_MAP);

        Session testSession = getTestSession();
        assertFalse(testSession.nodeExists(path));
        assertFalse(canGetNode(testSession, path));
        assertFalse(testSession.nodeExists(childNPath));
        assertFalse(canGetNode(testSession, childNPath));
        assertFalse(testSession.nodeExists(ccPath));
        assertFalse(canGetNode(testSession, ccPath));
        assertFalse(testSession.propertyExists(childNPath + '/' + JcrConstants.JCR_PRIMARYTYPE));

        Map<String, Value> emptyStringRestriction = new HashMap<String, Value>(getRestrictions(superuser, path));
        emptyStringRestriction.put(AccessControlConstants.P_GLOB.toString(), vf.createValue(""""));

        givePrivileges(path, read, emptyStringRestriction);
        assertTrue(testSession.nodeExists(path));
        assertTrue(canGetNode(testSession, path));
        assertFalse(testSession.nodeExists(childNPath));
        assertFalse(canGetNode(testSession, childNPath));
        assertFalse(testSession.nodeExists(ccPath));
        assertFalse(canGetNode(testSession, ccPath));
        assertFalse(testSession.propertyExists(childNPath + '/' + JcrConstants.JCR_PRIMARYTYPE));
    }
"
"    @Test
    public void testEmptyGlobRestriction3()throws Exception{
        Node child2 = superuser.getNode(path).addNode(""child2"");
        String childNPath2 = child2.getPath();
        superuser.save();

        try {
            Group group1 = getTestGroup();
            Group group2 = getUserManager(superuser).createGroup(""group2"");
            group2.addMember(testUser);
            Group group3 = getUserManager(superuser).createGroup(""group3"");
            superuser.save();

            assertTrue(group1.isDeclaredMember(testUser));
            assertTrue(group2.isDeclaredMember(testUser));
            assertFalse(group3.isDeclaredMember(testUser));

            Privilege[] read = privilegesFromName(Privilege.JCR_READ);

            withdrawPrivileges(path, group1.getPrincipal(), read, Collections.EMPTY_MAP);
            Map<String, Value> emptyStringRestriction = new HashMap<String, Value>(getRestrictions(superuser, path));
            emptyStringRestriction.put(AccessControlConstants.P_GLOB.toString(), vf.createValue(""""));
            givePrivileges(path, group1.getPrincipal(), read, emptyStringRestriction);

            withdrawPrivileges(childNPath, group2.getPrincipal(), read, Collections.EMPTY_MAP);
            emptyStringRestriction = new HashMap<String, Value>(getRestrictions(superuser, childNPath));
            emptyStringRestriction.put(AccessControlConstants.P_GLOB.toString(), vf.createValue(""""));
            givePrivileges(childNPath, group2.getPrincipal(), read, emptyStringRestriction);

            withdrawPrivileges(childNPath2, group3.getPrincipal(), read, Collections.EMPTY_MAP);
            emptyStringRestriction = new HashMap<String, Value>(getRestrictions(superuser, childNPath2));
            emptyStringRestriction.put(AccessControlConstants.P_GLOB.toString(), vf.createValue(""""));
            givePrivileges(childNPath2, group3.getPrincipal(), read, emptyStringRestriction);

            // NOTE: test-session is created here and is expected to reflect the
            // group membership changes made above.
            Session testSession = getTestSession();
            assertTrue(testSession.nodeExists(path));
            assertTrue(testSession.nodeExists(childNPath));
            assertFalse(testSession.nodeExists(childNPath2));
        } finally {
            Authorizable g2 = getUserManager(superuser).getAuthorizable(""group2"");
            if (g2 != null) {
                g2.remove();
            }
            Authorizable g3 = getUserManager(superuser).getAuthorizable(""group3"");
            if (g3 != null) {
                g3.remove();
            }
            superuser.save();
        }
    }
"
"    @Test
    public void testRemove() throws RepositoryException {
        Session s = repository.login(new SimpleCredentials(""admin"", ""admin"".toCharArray()));
        Node n = s.getRootNode().addNode((""a""));
        s.save();

        n.remove();
        s.save();
    }
"
"    @Test
    public void testInsert() throws RepositoryException {
        ComparableArray ca = new ComparableArray(""a"", 1);
        assertEquals(""a"", ca.toString());
        assertEquals(1, ca.getOffset());

        // insert before
        ca.insert(""b"", 0);
        assertEquals(""[b, a]"", ca.toString());
        assertEquals(0, ca.getOffset());

        // insert after
        ca.insert(""c"", 3);
        assertEquals(""[b, a, null, c]"", ca.toString());
        assertEquals(0, ca.getOffset());

        // insert inside
        ca.insert(""d"", 2);
        assertEquals(""[b, a, d, c]"", ca.toString());
        assertEquals(0, ca.getOffset());
    }
"
"    @Test
    public void testFindUserWithSpecialCharIdByPrincipalName() throws RepositoryException {
        List<String> ids = Arrays.asList(""'"", Text.escapeIllegalJcrChars(""']""), Text.escape(""']""));
        for (String id : ids) {
            User user = null;
            try {
                user = userMgr.createUser(id, ""pw"");
                superuser.save();

                boolean found = false;
                Iterator<Authorizable> it = userMgr.findAuthorizables(""rep:principalName"", id, UserManager.SEARCH_TYPE_USER);
                while (it.hasNext() && !found) {
                    Authorizable a = it.next();
                    found = id.equals(a.getID());
                }
                assertTrue(found);
            } finally {
                if (user != null) {
                    user.remove();
                    superuser.save();
                }
            }
        }
    }
"
"    @Test
    public void testFindUserWithSpecialCharIdByPrincipalName2() throws RepositoryException {
        List<String> ids = Arrays.asList(""]"");
        for (String id : ids) {
            User user = null;
            try {
                user = userMgr.createUser(id, ""pw"");
                superuser.save();

                boolean found = false;
                Iterator<Authorizable> it = userMgr.findAuthorizables(""rep:principalName"", id, UserManager.SEARCH_TYPE_USER);
                while (it.hasNext() && !found) {
                    Authorizable a = it.next();
                    found = id.equals(a.getID());
                }
                assertTrue(found);
            } finally {
                if (user != null) {
                    user.remove();
                    superuser.save();
                }
            }
        }
    }
"
"    @Test
    public void testQueryUserWithSpecialCharId() throws Exception {
        List<String> ids = Arrays.asList(""'"", ""]"");
        for (String id : ids) {
            User user = null;
            try {
                user = userMgr.createUser(id, ""pw"");
                superuser.save();

                boolean found = false;
                String query = ""{\""condition\"":[{\""named\"":\"""" + id + ""\""}]}"";
                AuthorizableQueryManager queryManager = new AuthorizableQueryManager(userMgr, superuser.getValueFactory());
                Iterator<Authorizable> it = queryManager.execute(query);
                while (it.hasNext() && !found) {
                    Authorizable a = it.next();
                    found = id.equals(a.getID());
                }
                assertTrue(found);
            } finally {
                if (user != null) {
                    user.remove();
                    superuser.save();
                }
            }
        }
    }
"
"    @Test
    public void bundleStates() {
        for (Bundle bundle : context.getBundles()) {
            assertEquals(
                String.format(""Bundle %s not active. have a look at the logs"", bundle.toString()), 
                Bundle.ACTIVE, bundle.getState());
        }
    }
"
"    @Test
    public void listBundles() {
        for (Bundle bundle : context.getBundles()) {
            System.out.println(bundle);
        }
    }
"
"    @Test
    public void listServices() throws InvalidSyntaxException {
        for (ServiceReference<?> reference
                : context.getAllServiceReferences(null, null)) {
            System.out.println(reference);
        }
    }
"
"    @Test
    public void test_c() throws Throwable {
        File file = Files.findFile(getClass().getPackage().getName().replace('.', '/')
                                    + ""/snapshot.jpg"");
        //System.out.println(file.length());
        Images.clipScale(file, File.createTempFile(""abc"", ""jpg""), 256, 256);
    }
"
"    @Test
    public void test_clipScale_url() throws Throwable {
        File file = Files.findFile(getClass().getPackage().getName().replace('.', '/')
                                    + ""/snapshot.jpg"");
        Images.clipScale(file.toURI().toURL(), File.createTempFile(""abc"", ""jpg""), 256, 256);
    }
"
"        //å¾å°ææå¸¦@Testçæ¹æ³
            public void testFailure(Failure failure) throws Exception {
                result.addError(asTest(failure.getDescription()), failure.getException());
            }
"
"    @Test
    public void test_speed() throws SecurityException, NoSuchMethodException {
        final SimpleSpeedTest z = new SimpleSpeedTest();
        final String elstr = ""num + (i - 1 + 2 - 3 + 4 - 5 + 6 - 7)-z.abc(i)"";
        final Context context = Lang.context(""{num:0}"");
        context.set(""z"", z);

        System.out.println(""\n"" + Strings.dup('=', 100));

        Stopwatch sw = Stopwatch.run(new Atom() {
            public void run() {
                int num = 0;
                for (int i = 0; i < max; i++)
                    num = num + (i - 1 + 2 - 3 + 4 - 5 + 6 - 7) - z.abc(i);
                //System.out.println(""Num: "" + num);
            }
"
"    @Test
    public void simpleRPN() throws IOException{
        assertEquals(""11+1+"", parseRPN(""1+1+1""));
        assertEquals(""11-"", parseRPN(""1-1""));
        assertEquals(""11-1-"", parseRPN(""1-1-1""));
        assertEquals(""52%1+"",parseRPN(""5%2+1""));
        assertEquals(""152%+"",parseRPN(""1+5%2""));
    }
"
"    @Test
    public void mulRPn() throws IOException{
        assertEquals(""512+4*+3-"", parseRPN(""5+((1+2)*4)-3""));
        assertEquals(""987*+65+412*-3+-*+"", parseRPN(""9+8*7+(6+5)*(-(4-1*2+3))""));
    }
"
"    @Test
    public void test() throws InstantiationException, IllegalAccessException{
        String[] a = new String[]{""a"",""b""};
        Map<String, String[]> map = new HashMap<String, String[]>();
        map.put(""a"", a);
        El exp = new El(""util.test(map['a'])"");
        Context context = Lang.context();
        context.set(""util"",StringUtil.class.newInstance());
        context.set(""map"", map);
        assertEquals(""ab"", exp.eval(context));
    }
"
"    @Test
    public void test2(){
        String[] a = new String[]{""a"",""b""};
        String[] b = new String[]{""1"",""2""};
        Map<String,Object> map = new HashMap<String,Object>();
        map.put(""a"", a);
        map.put(""b"", b);
        El exp = new El(""util.test(map['a'][0],map['b'][0])"");  // é¢ç¼è¯ç»æä¸ºä¸ä¸ª El å¯¹è±¡
        Context context = Lang.context();
        context.set(""util"",new StringUtil());
        context.set(""map"", map);
        System.out.println(exp.eval(context));
    }
"
"    @Test
    public void notCalculateOneNumber() {
        assertEquals(1, El.eval(""1""));
        assertEquals(0.1, El.eval("".1""));
        assertEquals(0.1d, El.eval(""0.1""));
        assertEquals(0.1f, El.eval(""0.1f""));
        assertEquals(0.1d, El.eval(""0.1d""));
        assertEquals(true, El.eval(""true""));
        assertEquals(false, El.eval(""false""));
        assertEquals(""jk"", El.eval(""'jk'""));
    }
"
"    @Test
    public void simpleCalculate() {
        // å 
        assertEquals(2, El.eval(""1+1""));
        assertEquals(2.2, El.eval(""1.1+1.1""));
        // å
        assertEquals(1, El.eval(""2-1""));
        // ä¹
        assertEquals(9, El.eval(""3*3""));
        assertEquals(0, El.eval(""3*0""));
        // é¤
        assertEquals(3, El.eval(""9/3""));
        assertEquals(2.2, El.eval(""4.4/2""));
        assertEquals(9.9 / 3, El.eval(""9.9/3""));
        // åä½
        assertEquals(1, El.eval(""5%2""));
        assertEquals(1.0 % 0.1, El.eval(""1.0%0.1""));

    }
"
"    @Test
    public void bit() {
        assertEquals(-40, El.eval(""-5<<3""));
        assertEquals(-1, El.eval(""-5>>3""));
        assertEquals(5, El.eval(""5>>>32""));
        assertEquals(-5, El.eval(""-5>>>32""));
        assertEquals(1, El.eval(""5&3""));
        assertEquals(7, El.eval(""5|3""));
        assertEquals(-6, El.eval(""~5""));
        assertEquals(6, El.eval(""5^3""));
    }
"
"    @Test
    public void multiStageOperation() {
        assertEquals(3, El.eval(""1 + 1 + 1""));
        assertEquals(1, El.eval(""1+1-1""));
        assertEquals(-1, El.eval(""1-1-1""));
        assertEquals(1, El.eval(""1-(1-1)""));
        assertEquals(7, El.eval(""1+2*3""));
        assertEquals(2 * 4 + 2 * 3 + 4 * 5, El.eval(""2*4+2*3+4*5""));
        assertEquals(9 + 8 * 7 + (6 + 5) * ((4 - 1 * 2 + 3)), El.eval(""9+8*7+(6+5)*((4-1*2+3))""));
        assertEquals(.3 + .2 * .5, El.eval("".3+.2*.5""));
        assertEquals((.5 + 0.1) * .9, El.eval(""(.5 + 0.1)*.9""));
    }
"
"    @Test
    public void sikpSpace() {
        // ç©ºæ ¼æ£æµ
        assertEquals(3, El.eval(""    1 + 2    ""));
    }
"
"    @Test
    public void testNull() {
        assertEquals(null, El.eval(""null""));
        assertTrue((Boolean) El.eval(""null == null""));
    }
"
"    @Test
    public void logical() {
        assertEquals(true, El.eval(""2 > 1""));
        assertEquals(false, El.eval(""2 < 1""));
        assertEquals(true, El.eval(""2 >= 2""));
        assertEquals(true, El.eval(""2 <= 2""));
        assertEquals(true, El.eval(""2 == 2 ""));
        assertEquals(true, El.eval(""1 != 2""));
        assertEquals(true, El.eval(""!(1 == 2)""));
        assertEquals(true, El.eval(""!false""));
        assertEquals(true, El.eval(""true || false""));
        assertEquals(false, El.eval(""true && false""));
        assertEquals(false, El.eval(""false || true && false""));
    }
"
"    @Test
    public void threeTernary() {
        assertEquals(2, El.eval(""1>0?2:3""));
        assertEquals(2, El.eval(""1>0&&1<2?2:3""));
    }
"
"    @Test
    public void stringTest() {
        assertEquals(""jk"", El.eval(""'jk'""));
        assertEquals(2, El.eval(""'jk'.length()""));
        assertEquals(2, El.eval(""\""jk\"".length()""));
        assertEquals(""jk"", El.eval(""\""    jk   \"".trim()""));
        assertEquals(""j\\n\\tk"", El.eval(""\""j\\n\\tk\""""));
    }
"
"    @Test
    public void test_issue_397_3() {
        int expect = 1 / 1 + 10 * (1400 - 1400) / 400;
        Object val = El.eval(""1/1+10*(1400-1400)/400"");
        assertEquals(expect, val);
    }
"
"    @Test
    public void negative() {
        assertEquals(-1, El.eval(""-1""));
        assertEquals(0, El.eval(""-1+1""));
        assertEquals(-1 - -1, El.eval(""-1 - -1""));
        assertEquals(9 + 8 * 7 + (6 + 5) * (-(4 - 1 * 2 + 3)), El.eval(""9+8*7+(6+5)*(-(4-1*2+3))""));
    }
"
"    @Test
    public void callMethod() {
        assertEquals('j', El.eval(""'jk'.charAt(0)""));
        assertEquals(""cde"", El.eval(""\""abcde\"".substring(2)""));
        assertEquals(""b"", El.eval(""\""abcde\"".substring(1,2)""));
        assertEquals(true, El.eval(""\""abcd\"".regionMatches(2,\""ccd\"",1,2)""));
        assertEquals(""bbbb"", El.eval(""'  abab  '.replace('a','b').trim()""));
    }
"
"    @Test
    public void test_simple_condition() {
        Context context = Lang.context();
        context.set(""a"", 10);
        assertEquals(10, El.eval(context, ""a""));
        assertEquals(20, El.eval(context, ""a + a""));

        context.set(""b"", ""abc"");
        assertEquals(25, El.eval(context, ""a + 2 +a+ b.length()""));

        String s = ""a>5?'GT 5':'LTE 5'"";
        assertEquals(""GT 5"", El.eval(context, s));
        context.set(""a"", 5);
        assertEquals(""LTE 5"", El.eval(context, s));

        assertEquals(""jk"", El.eval(""\""j\""+\""k\""""));

    }
"
"    @Test
    public void context() {
        Context context = Lang.context();
        List<String> list = new ArrayList<String>();
        list.add(""jk"");
        context.set(""a"", list);
        assertEquals(""jk"", El.eval(context, ""a.get((1-1))""));
        assertEquals(""jk"", El.eval(context, ""a.get(1-1)""));
        assertEquals(""jk"", El.eval(context, ""a.get(0)""));

        assertTrue((Boolean) El.eval(Lang.context(), ""a==null""));
        try {
            assertTrue((Boolean) El.eval(Lang.context(), ""a.a""));
            fail();
        }
        catch (Exception e) {}
    }
"
"    @Test
    public void array() {
        Context context = Lang.context();
        String[] str = new String[]{""a"", ""b"", ""c""};
        String[][] bb = new String[][]{{""a"", ""b""}, {""c"", ""d""}};
        context.set(""a"", str);
        context.set(""b"", bb);
        assertEquals(""b"", El.eval(context, ""a[1]""));
        assertEquals(""b"", El.eval(context, ""a[1].toString()""));
        assertEquals(""b"", El.eval(context, ""a[2-1]""));
        assertEquals(""d"", El.eval(context, ""b[1][1]""));
    }
"
"    @Test
    public void field() {
        class abc {
            @SuppressWarnings(""unused"")
            public String name = ""jk"";
        }
        Context context = Lang.context();
        context.set(""a"", new abc());
        assertEquals(""jk"", El.eval(context, ""a.name""));
        // è¿ä¸ªåè½æ¾å¼
        // assertFalse((Boolean)El.eval(""java.lang.Boolean.FALSE""));
        // assertFalse((Boolean)El.eval(""Boolean.FALSE""));
    }
"
"    @Test
    public void custom() {
        assertEquals(2, El.eval(""max(1, 2)""));
        assertEquals(1, El.eval(""min(1, 2)""));
        assertEquals(""jk"", El.eval(""trim('    jk    ')""));
    }
"
"    @Test
    public void speed() {
        SimpleSpeedTest z = new SimpleSpeedTest();
        int num = 4988;
        String elstr = ""num + (i - 1 + 2 - 3 + 4 - 5 + 6 - 7)-z.abc(i)"";
        int i = 5000;
        Context con = Lang.context();
        con.set(""num"", num);
        con.set(""i"", i);
        con.set(""z"", z);
        assertEquals(num + (i - 1 + 2 - 3 + 4 - 5 + 6 - 7) - z.abc(i), El.eval(con, elstr));
    }
"
"    @Test
    public void lssue_486() {
        assertEquals(2 + (-3), El.eval(""2+(-3)""));
        assertEquals(2 + -3, El.eval(""2+-3""));
        assertEquals(2 * -3, El.eval(""2*-3""));
        assertEquals(-2 * -3, El.eval(""-2*-3""));
        assertEquals(2 / -3, El.eval(""2/-3""));
        assertEquals(2 % -3, El.eval(""2%-3""));
    }
"
"    @Test
    public void map() {
        Context context = Lang.context();
        context.set(""a"", Lang.map(""{x:10,y:50,txt:'Hello'}""));

        assertEquals(100, El.eval(context, ""a.get('x')*10""));
        assertEquals(100, El.eval(context, ""a.x*10""));
        assertEquals(100, El.eval(context, ""a['x']*10""));
        assertEquals(""Hello-40"", El.eval(context, ""a.get('txt')+(a.get('x')-a.get('y'))""));
    }
"
"    @Test
    public void list() {
        Context context = Lang.context();
        List<String> list = new ArrayList<String>();
        context.set(""b"", list);
        assertEquals(0, El.eval(context, ""b.size()""));
        list.add("""");
        assertEquals(1, El.eval(context, ""b.size()""));
        El.eval(context, ""b.add('Q\nQ')"");
        assertEquals(2, El.eval(context, ""b.size()""));
    }
"
"    @Test
    public void complexOperation() {
        assertEquals(1000
                     + 100.0
                     * 99
                     - (600 - 3 * 15)
                     % (((68 - 9) - 3) * 2 - 100)
                     + 10000
                     % 7
                     * 71, El.eval(""1000+100.0*99-(600-3*15)%(((68-9)-3)*2-100)+10000%7*71""));
        assertEquals(6.7 - 100 > 39.6 ? true ? 4 + 5 : 6 - 1 : !(100 % 3 - 39.0 < 27) ? 8 * 2 - 199
                                                                                     : 100 % 3,
                     El.eval(""6.7-100>39.6 ? 5==5? 4+5:6-1 : !(100%3-39.0<27) ? 8*2-199: 100%3""));

        Context vars = Lang.context();
        vars.set(""i"", 100);
        vars.set(""pi"", 3.14f);
        vars.set(""d"", -3.9);
        vars.set(""b"", (byte) 4);
        vars.set(""bool"", false);
        vars.set(""t"", """");
        String t = ""i * pi + (d * b - 199) / (1 - d * pi) - (2 + 100 - i / pi) % 99 ==i * pi + (d * b - 199) / (1 - d * pi) - (2 + 100 - i / pi) % 99"";
        // t =
        // ""i * pi + (d * b - 199) / (1 - d * pi) - (2 + 100 - i / pi) % 99"";
        assertEquals(true, El.eval(vars, t));

        // assertEquals('A' == ('A') || 'B' == 'B' && ""ABCD"" == """" && 'A' ==
        // 'A', el.eval(vars,
        // ""'A' == 'A' || 'B' == 'B' && 'ABCD' == t &&  'A' == 'A'""));
        assertEquals(true || true && false && true,
                     El.eval(vars, ""'A' == 'A' || 'B' == 'B' && 'ABCD' == t &&  'A' == 'A'""));
    }
"
"    @Test
    public void testIssues87() {
        Context context = Lang.context();
        context.set(""a"", new BigDecimal(""7""));
        context.set(""b"", new BigDecimal(""3""));
        assertEquals(10, El.eval(context, ""a.add(b).intValue()""));
    }
"
"    @Test
    public void testIssue168() {
        assertEquals(El.eval(""0.1354*((70-8)%70)*100""), 0.1354 * ((70 - 8) % 70) * 100);
        assertEquals(El.eval(""0.1354*((70d-8)/70)*100""), 0.1354 * ((70d - 8) / 70) * 100);
        assertEquals(El.eval(""0.5006*(70/600*100)""), 0.5006 * (70 / 600 * 100));
    }
"
"    @Test
    public void testIssue277() {
        Context context = Lang.context();
        context.set(""strings"", Strings.class);
        assertEquals(""a"", El.eval(context, ""strings.trim(\""  a  \"")""));
    }
"
"    @Test
    public void testIssue277_2() {
        Context context = Lang.context();
        context.set(""math"", Maths.class);
        assertEquals(2, El.eval(context, ""math.max(1, 2)""));
    }
"
"    @Test
    public void testIssue279() throws InterruptedException {
        Context context = Lang.context();
        context.set(""math"", Maths.class);
        System.out.println(Maths.class.toString());
        assertEquals(""class org.nutz.lang.Maths"", El.eval(context, ""math.toString()""));

        NutConf.load(""org/nutz/el/issue279/279.js"");
        assertEquals(El.eval(""uuuid(false)""), ""abc"");
        assertEquals(El.eval(""uuuid()""), ""abc"");
    }
"
"    @Test
    public void testIssue292() {
        Context context = Lang.context();
        context.set(""a"", 123);
        context.set(""b"", 20);
        Object o = El.eval(context, ""a>b?a:b"");
        assertEquals(123, o);
    }
"
"    @Test
    public void testIssue293() {

        Context context = Lang.context();
        context.set(""static"", new Issue293());
        context.set(""a"", Issue293.class);

        assertEquals(""xxx"", El.eval(context, ""a.printParam(a.info)""));
    }
"
"    @Test
    public void testIssue303() {
        Context context = Lang.context();
        Issue303 item = new Issue303(""item"");
        item.child = new Issue303(""child"");
        context.set(""item"", item);

        assertEquals(""child"", El.eval(context, ""item.child.getName()""));
        assertEquals(0, El.eval(context, ""item.list.size()""));
    }
"
"    @Test
    public void testIssue306() throws InterruptedException {
        int size = 100;
        final CountDownLatch count = new CountDownLatch(size);
        final List<Integer> error = new ArrayList<Integer>();
        for (int index = 0; index < size; index++) {
            new Thread() {
                public void run() {
                    try {
                        El.eval(""1+1"");
                    }
                    catch (Exception e) {
                        error.add(1);
                    }
                    finally {
                        count.countDown();
                    }
                }
"
"    @Test
    public void testIssue307(){
        Context context = Lang.context();
        List<String> list = new ArrayList<String>();
        list.add(""jk"");
        context.set(""list"", list);
        context.set(""System"", System.class);
        
        El.eval(context, ""list.add(list.get(0))"");
        assertEquals(2, list.size());
    }
"
"    @Test
    public void testIssue308(){
        Context context = Lang.context();
        List<String> list = new ArrayList<String>();
        list.add(""jk"");
        context.set(""list"", list);
        context.set(""System"", System.class);
        
        El.eval(context, ""System.getenv('PATH').getClass().getName()"");
        assertEquals(""1"", Mirror.me(String.class).invoke(String.class, ""valueOf"", 1));
        
        assertEquals(""jk"", Mirror.me(String.class).invoke(String.class, ""valueOf"", ""jk""));
    }
"
"    @Test
    public void test_issue314() {
        Context context = Lang.context();
        
        context.set(""String"", String.class);
        
        Issue314 i314 = new Issue314();
        List<String> list = new ArrayList<String>();
        list.add(""123"");
        i314.setList(list);
        context.set(""map"", i314);
        
        assertEquals(""123"", El.eval(context, ""String.valueOf(123)""));
        assertEquals(""123"", El.eval(context, ""map.list.get(0)""));
    }
"
"    @Test
    public void test_issue411(){
    	El el=new El(""a[0].b.isPass('')?'1':'2'"");
        Context ctx = Lang.context();
        ctx.set(""a"",new Object[]{new org.nutz.el.issue411.Issue411.A()} );
        assertEquals(""1"", el.eval(ctx));
    }
"
"    @Test
    public void test_uu32_uu64(){
        Context ctx = Lang.context();
        
        El el = new El(""uuid()"");
        assertEquals(32, el.eval(ctx).toString().length());
        
        el = new El(""uuid(32)"");
        assertTrue(26 >= el.eval(ctx).toString().length());
        
        el = new El(""uuid(64)"");
        assertTrue(23 >= el.eval(ctx).toString().length());
    }
"
"    @Test
    public void test_base64(){
        Context ctx = Lang.context();
        
        El el = new El(""base64('ä¸­æ,è±æabc,ç«ææ((%&(*')"");
        assertEquals(Base64.encodeToString(""ä¸­æ,è±æabc,ç«ææ((%&(*"".getBytes(Encoding.CHARSET_UTF8), false), el.eval(ctx));
        
        String str = Base64.encodeToString(""EEEä¸­æ"".getBytes(Encoding.CHARSET_UTF8), false);
        el = new El(""base64('decode', \'"" + str + ""\')"");
        assertEquals(""EEEä¸­æ"", el.eval(ctx));
    }
"
"    @Test
    public void test_urlencode() throws UnsupportedEncodingException {
        String re = El.eval(""urlencode('ä¸­æ')"").toString();
        assertEquals(URLEncoder.encode(""ä¸­æ"", Encoding.UTF8), re);
        
        re = El.eval(""urlencode('ä¸­æ', 'gbk')"").toString();
        assertEquals(URLEncoder.encode(""ä¸­æ"", Encoding.GBK), re);
        
        re = El.eval(""urlencode('ä¸­æ', 'gb2312')"").toString();
        assertEquals(URLEncoder.encode(""ä¸­æ"", Encoding.GB2312), re);
    }
"
"    @Test
    public void test_map_get() {
        Map<String, Object> map = new HashMap<String, Object>();
        map.put(""wendal"", ""http://wendal.net"");
        List<String> list = new ArrayList<String>();
        list.add(""abc"");
        assertEquals(""http://wendal.net"", El.eval(Lang.context().set(""ctx"", map), ""ctx['wendal']""));
        assertEquals(""abc"", El.eval(Lang.context().set(""list"", list), ""list[0]""));
    }
"
"    @Test
    public void test_el() {
        El el = new El(""'hi,'+name"");
        Context ctx = Lang.context();
        ctx.set(""name"", ""wendal"");
        assertEquals(""hi,wendal"", el.eval(ctx));
    }
"
"    @Test
    public void test_el2() throws Exception {
        El el = new El(""sayhi(name)"");
        Context ctx = Lang.context();
        ctx.set(""name"", ""wendal"");
        ctx.set(""sayhi"", getClass().getMethod(""sayhi"", String.class));
        assertEquals(""hi,wendal"", el.eval(ctx));
    }
"
"    @Test(timeout=5000, expected=Exception.class)
    public void test_el_issue1185() {
        Context context = Lang.context();
        El.eval(context, ""a.b)*0.30"");
    }
"
"    @Test
    public void test_issue_1307() {
        //assertTrue((Boolean)El.eval(""0 == 0""));
        assertTrue((Boolean)El.eval(""0 == 0.0""));
    }
"
"    @Test
    public void test_issue_1229() {
        Context ctx = Lang.context();
        ctx.set(""obj"", new NutMap(""pet"", null).setv(""girls"", new ArrayList<String>()));
        El.eval(ctx, ""obj.pet"");
        El.eval(ctx, ""!!(obj.pet)"");
        assertTrue((Boolean)El.eval(ctx, ""!!(obj.pet.name) == null""));
        assertTrue((Boolean)El.eval(ctx, ""!(!(!!(obj.pet.name) == null))""));
        assertEquals(""wendal"", El.eval(ctx, ""!!(obj.pet.name) ||| 'wendal'""));
        assertEquals(""dog"", El.eval(ctx, ""!!(obj.girls) ||| 'dog'""));
    }
"
"    @Test
    public void test_issue_1475_1476() {
        
        Context context = Lang.context();
        context.set(""Math"", Math.class);
        
        
        //Queue<Object> rpn = new ShuntingYard().parseToRPN(""Math.max(10, 0-11)"");
        //System.out.println(rpn);
        
//        Queue<Object> rpn = new ShuntingYard().parseToRPN(""Math.max(0,-10)"");
//        System.out.println(rpn);
        Object max = El.eval(context, ""Math.max(0,-11)"");
        assertEquals(0, max);
        
        
        assertEquals(0, El.eval(context, ""Math.max(-1,0)""));
        assertEquals(0, El.eval(context, ""Math.max(0,-1)""));
        assertEquals(0, El.eval(context, ""Math.max(-0,-1)""));
        

        assertEquals(0, El.eval(context, ""Math.max(-1,Math.max(-1,Math.max(-1,Math.max(-1,0))))""));
        assertEquals(0, El.eval(context, ""Math.max(Math.max(Math.max(Math.max(0,-1),-1),-1),-1)""));
        assertEquals(0, El.eval(context, ""Math.max(-Math.max(-Math.max(-Math.max(-0,-1),-1),-1),-1)""));
    }
"
"    @Test
    public void test_normal_debug() {
        Logs.setAdapter(new Log4jLogAdapter());
        Log log4nut = Logs.getLog(Dao.class);
        assertTrue(log4nut.getClass().getName().contains(Log4jLogAdapter.class.getName()));
        Logger log4j = LogManager.getLogger(Dao.class);

        assertEquals(log4nut.isInfoEnabled(), log4j.isInfoEnabled());
        assertEquals(log4nut.isDebugEnabled(), log4j.isDebugEnabled());
        assertEquals(log4nut.isTraceEnabled(), log4j.isTraceEnabled());
    }
"
"    @Test
    public void testGetLogger() {
        LogAdapter logAdapter = new SystemLogAdapter();
        assertNotNull(logAdapter.getLogger(Log.class.getName()));
    }
"
"    @Test
    public void testCanWork() {
        assertTrue(new SystemLogAdapter().canWork());
    }
"
"    @Test
    public void test_upload() throws Throwable {
        Request req = Request.create(getBaseURL()+""/upload/image"",METHOD.POST);
        File f = File.createTempFile(""nutz"", ""data"");
        FileWriter fw = new FileWriter(f);
        fw.write(""abc"");
        fw.flush();
        fw.close();
        req.getParams().put(""file"", f);
        FilePostSender sender = new FilePostSender(req);
        Response resp = sender.send();
        assertEquals(""image&3"", resp.getContent());
    }
"
"    @Test
    public void test_issue_543() {
        get(""/adaptor/github/issue/543?d=20120924"");
        assertEquals(200, resp.getStatus());

        long ms = Times.ams(""2012-09-24"", TimeZone.getTimeZone(""Asia/Shanghai""));
        long rems = Long.parseLong(resp.getContent());
        assertEquals(ms, rems);
    }
"
"    @Test
    public void test_err_param() {
        get(""/adaptor/err/param?id=ABC"");
        assertEquals(200, resp.getStatus());

        get(""/adaptor/err/param/ABC"");
        assertEquals(200, resp.getStatus());
    }
"
"    @Test
    public void test_err_param_anywhere() {
        get(""/adaptor/err/param/anywhere?id=ABC"");
        assertEquals(200, resp.getStatus());

        get(""/adaptor/err/param/anywhere/ABC"");
        assertEquals(200, resp.getStatus());
    }
"
"    @Test
    public void test_err_param_with_pathargs() {
        get(""/adaptor/err/param/pathargs/a?id=ABC"");
        assertEquals(200, resp.getStatus());

        get(""/adaptor/err/param/pathargs/a/ABC"");
        assertEquals(200, resp.getStatus());
    }
"
"    @Test
    public void test_multi_err_ctxs() {
        get(""/adaptor/multi/err/ctxs/a?id=ABC"");
        assertEquals(200, resp.getStatus());

        get(""/adaptor/multi/err/ctxs/a/ABC"");
        assertEquals(200, resp.getStatus());
    }
"
"    @Test
    public void test_multi_err_ctxs2() {
        get(""/adaptor/multi/err/ctxs2/a/b?id=ABC"");
        assertEquals(200, resp.getStatus());

        get(""/adaptor/multi/err/ctxs2/a/b/ABC"");
        assertEquals(200, resp.getStatus());
    }
"
"    @Test
    public void test_json_map_type() {
        resp = post(""/adaptor/json/type"", ""{'abc': 123456}"");
        if (resp.getStatus() != 200) {
            fail();
        }
    }
"
"    @Test
    public void test_inputstream_as_string() {
        resp = post(""/adaptor/ins"", ""I am abc"");
        if (resp.getStatus() != 200) {
            fail();
        }
        assertEquals(""I am abc"", resp.getContent());
    }
"
"    @Test
    public void test_reader_as_string() {
        resp = post(""/adaptor/reader"", ""I am abc"");
        if (resp.getStatus() != 200) {
            fail();
        }
        assertEquals(""I am abc"", resp.getContent());
    }
"
"    @Test
    public void test_default_value() {
    	resp = get(""/adaptor/default_value?abc=123"");
    	assertEquals(200, resp.getStatus());
    	assertEquals(""123"", resp.getContent());
    	

    	resp = get(""/adaptor/default_value"");
    	assertEquals(200, resp.getStatus());
    	assertEquals(""123456"", resp.getContent());
    }
"
"    @Test
    public void test_json_err_ctx() {
        resp = post(""/adaptor/err_ctx"", ""{}"");
        assertEquals(200, resp.getStatus());
        assertEquals(""true"", resp.getContent());
        
        resp = post(""/adaptor/err_ctx"", ""{1234,3445}"");
        assertEquals(200, resp.getStatus());
        assertEquals(""false"", resp.getContent());
    }
"
"    @Test
    public void test_sql_date() {
    	resp = post(""/adaptor/sqldate"", ""checkDate=2016-01-29"");
        assertEquals(200, resp.getStatus());
        assertEquals(""2016-01-29"", resp.getContent());
    }
"
"    @Test
    public void test_array_without_param() {
        assertEquals(200, get(""/adaptor/param_without_param"").getStatus());
        assertEquals(""[\""1\"", \""2\"", \""4\"", \""3\""]"".replaceAll("" "", """"), get(""/adaptor/param_without_param?uids=1,2,4,3"").getContent().replaceAll("" "", """"));
    }
"
"    @Test
    public void test_object_without_param() {
        assertEquals(200, get(""/adaptor/object_without_param"").getStatus());
        assertEquals(""{\""name\"": \""object\""}"".replaceAll("" "", """"), get(""/adaptor/object_without_param?name=object"").getContent().replaceAll("" "", """"));
    }
"
"    @Test
    public void test_path_args_and_object_without_param() {
        assertEquals(200, get(""/adaptor/path_args_and_object_without_param/1"").getStatus());
        assertEquals(""{\""name\"": \""1\""}"".replaceAll("" "", """"), get(""/adaptor/path_args_and_object_without_param/1?name=object"").getContent().replaceAll("" "", """"));
    }
"
"    @Test
    public void issue_1069() {
        resp = post(""/adaptor/issue1069"", """");
        assertEquals(200, resp.getStatus());
        assertEquals("""", resp.getContent());
        

        resp = post(""/adaptor/issue1069"", ""showAdd="");
        assertEquals(200, resp.getStatus());
        assertEquals("""", resp.getContent());
    }
"
"    @Test
    public void issue_1267() {
        resp = post(""/adaptor/issue1267"", new NutMap(""time"", ""Thu May 25 2017 07:16:32 GMT+0800 (CST)""));
        assertEquals(200, resp.getStatus());
        System.out.println(resp.getContent());
        //assertEquals(""1495667792000"", resp.getContent());
    }
"
"    @Test
    public void issue_1277() {
        resp = post(""/adaptor/issue1277"", new NutMap(""agex"", ""124""));
        assertEquals(200, resp.getStatus());
        String str = resp.getContent();
        Issue1277 issue = Json.fromJson(Issue1277.class, str);
        assertEquals(""abc"", issue.name);
        assertEquals(123, issue.age);
        //assertEquals(""1495667792000"", resp.getContent());
    }
"
"    @Test
    public void issue_1310() {
        resp = post(""/adaptor/issue1310"", new NutMap(""age"", ""123""));
        assertEquals(200, resp.getStatus());
        String str = resp.getContent();
        Issue1277 issue = Json.fromJson(Issue1277.class, str);
        assertEquals(123, issue.age);
        //assertEquals(""1495667792000"", resp.getContent());
    }
"
"    @Test
    public void re_view_with_NutMap() {
        resp = post(""/adaptor/issue13xx"", new NutMap(""age"", ""123""));
        assertEquals(200, resp.getStatus());
        String str = resp.getContent();
        assertEquals(Json.toJson(new NutMap(""id"", 1), JsonFormat.compact()), str);
    }
"
"    @Test
    public void test_localdt() {
        resp = post(""/adaptor/jdk8/localdt"", new NutMap(""date"", ""2018-02-20 21:11:51""));
        assertEquals(200, resp.getStatus());
        String str = resp.getContent();
        assertEquals(""2018-02-20T21:11:51"", str);
    }
"
"    @Test
    public void test_simple() {
        get(""/views/for?to=base"");
        assertEquals(200, resp.getStatus());
        assertEquals(getContextPath(), resp.getContent());
        
        get(""/views/for2?to=base"");
        assertEquals(200, resp.getStatus());
        assertEquals(getContextPath(), resp.getContent());

        get(""/views/for3?to=base"");
        assertEquals(200, resp.getStatus());
        assertEquals(getContextPath(), resp.getContent());
    }
"
"    @Test
    public void test_raw() {
        get(""/views/raw"");
        assertEquals(""ABC"", resp.getContent());

        get(""/views/raw2"");
        assertEquals(3, resp.getContent().length());

        get(""/views/raw3"");
        assertEquals(3, resp.getContent().length());

        get(""/views/raw4"");
        assertEquals("""", resp.getContent());

        get(""/views/raw5"");
        assertTrue(resp.getHeader().get(""Content-Type"").startsWith(""application/json""));
    }
"
"    // @Test
    public void test_raw2() throws Throwable {
        File src = new File(""H://main_qt"");
        File dst = new File(""H://cache.tmp"");
        RangeRange rangeRange = new RangeRange(0, src.length());
        // RawView.writeFileRange(src, new FileOutputStream(dst), rangeRange);
        //
        // System.out.println(Lang.digest(""md5"", src));
        // System.out.println(Lang.digest(""md5"", dst));

        List<RangeRange> rs = new ArrayList<RawView.RangeRange>();
        RawView.parseRange(""bytes=0-,-1000000,22222-22222222222"", rs, Long.MAX_VALUE);
        System.out.println(Json.toJson(rs));

        src = new File(""H://raw"");
        FileOutputStream out = new FileOutputStream(src);
        for (int i = 0; i < 255; i++) {
            out.write(i);
        }
        out.flush();
        out.close();

        rs = new ArrayList<RawView.RangeRange>();
        RawView.parseRange(""bytes=0-127"", rs, 256);
        rangeRange = rs.get(0);
        RawView.writeFileRange(src, new FileOutputStream(dst), rangeRange);
        System.out.println(dst.length());
        FileInputStream in = new FileInputStream(dst);
        for (int i = 0; i < 128; i++) {
            if (in.read() != i) {
                System.out.println(""ERR"");
            }
        }
        Streams.safeClose(in);

        rs = new ArrayList<RawView.RangeRange>();
        RawView.parseRange(""bytes=128-"", rs, 256);
        rangeRange = rs.get(0);
        RawView.writeFileRange(src, new FileOutputStream(dst), rangeRange);
        in = new FileInputStream(dst);
        for (int i = 0; i < 128; i++) {
            if (in.read() != (i + 128)) {
                System.out.println(""ERR"");
            }
        }
        Streams.safeClose(in);

        rs = new ArrayList<RawView.RangeRange>();
        RawView.parseRange(""bytes=-64"", rs, 256);
        rangeRange = rs.get(0);
        RawView.writeFileRange(src, new FileOutputStream(dst), rangeRange);
        in = new FileInputStream(dst);
        for (int i = 0; i < 64; i++) {
            if (in.read() != (i + 128 + 64)) {
                System.out.println(""ERR"");
            }
        }
        Streams.safeClose(in);

        System.out.println(""---------------------------END"");
    }
"
"    @Test
    public void test_view_resp() {
        get(""/views/resp/to/1"");
        assertEquals(""hi"", resp.getContent());
        get(""/views/resp/to/2"");
        assertEquals(200, resp.getStatus());
        assertEquals(""{\""name\"":\""wendal\""}"", resp.getContent());
    }
"
"    @Test
    public void test_simple() {
        get(""/views/red?to=base"");
        assertEquals(200, resp.getStatus());
        assertEquals(getContextPath(), resp.getContent());
        
        get(""/views/red2?to=base"");
        assertEquals(200, resp.getStatus());
        assertEquals(getContextPath(), resp.getContent());

        get(""/views/red3?to=base"");
        assertEquals(200, resp.getStatus());
        assertEquals(getContextPath(), resp.getContent());
    }
"
"    @Test
    public void test_simple(){
        get(""/views/jsp"");
        assertEquals(""null"", resp.getContent());
        get(""/views/jsp2"");
        assertEquals(""null"", resp.getContent());
        get(""/views/jsp3"");
        assertEquals(""null"", resp.getContent());
        get(""/views/jsp4"");
        assertEquals(""null"", resp.getContent());
    }
"
"    @Test
    public void test_issue_1212() {
        get(""/mapping/issue1212/sayhi"");
        assertEquals(200, resp.getStatus());
    }
"
"    @Test
    public void test_json_adaptor() {
        post(""/adaptor/json/pet/array"", ""{pets:[{name:'zzh'},{name:'wendal'}]}"");
        assertEquals(""pets(2) array"", resp.getContent());

        post(""/adaptor/json/pet/list"", ""{pets:[{name:'zzh'},{name:'wendal'}]}"");
        assertEquals(""pets(2) list"", resp.getContent());
    }
"
"    @Test
    public void test_base() {
        get(""/base.jsp"");
        assertNotNull(resp);
        assertEquals(200, resp.getStatus());
        assertEquals(getContextPath(), resp.getContent());
    }
"
"    @Test
    public void test_pathargs() {
        get(""/common/pathArgs/Wendal"");
        assertEquals(""Wendal"", resp.getContent());

        get(""/common/pathArgs2/Wendal/12345/123456789/123/123.00/200.9/true/n"");
        assertEquals(""Wendal12345123456789123123200truen"", resp.getContent());

        get(""/common/pathArgs3/public/blog/200"");
        assertEquals(""public&200"", resp.getContent());
        get(""/common/pathArgs3/puZ"");
        assertEquals(""puZ&Z"", resp.getContent());

        get(""/common/pathArgs4/nutz?name=wendal"");
        assertEquals(""nutz&wendal"", resp.getContent());

        get(""/common/pathArgs5/nutz?user.name=wendal&user2.name=zozoh"");
        assertEquals(""nutz&wendal&zozoh"", resp.getContent());
    }
"
"    @Test
    public void test_param() {
        get(""/common/param?id="" + Long.MAX_VALUE);
        assertEquals("""" + Long.MAX_VALUE, resp.getContent());
    }
"
"    @Test
    public void test_req_param() {
        get(""/common/path?key=base"");
        assertEquals(getContextPath(), resp.getContent());
    }
"
"    @Test
    public void test_req_param2() {
        get(""/common/path2?key=base"");
        assertEquals(""base"", resp.getContent());
        get(""/common/path2?key=T"");
        assertEquals(getContextPath(), resp.getContent());
    }
"
"    @Test
    public void test_servlet_obj() {
        get(""/common/servlet_obj"");
        assertEquals(200, resp.getStatus());
    }
"
"    @Test
    public void test_aop_trans_1() {
        String name = """"+System.currentTimeMillis();
        get(""/aop/test1?name=""+name);
        assertEquals(200, resp.getStatus());
        get(""/aop/test1/result?name=""+name);
        assertEquals(200, resp.getStatus());
        assertEquals(""0"", resp.getContent());
    }
"
"    @Test
    public void test_http_method_override() {
        Response resp = post(""/common/httpmethods?_method=DELETE"", new NutMap(""_method"", ""DELETE""));
        assertEquals(200, resp.getStatus());
        assertEquals(""DELETE"", resp.getContent());
    }
"
"    @Test
    public void test_issue_1220() throws IOException {
        File f = File.createTempFile(""abc_"", "".json"");
        org.nutz.lang.Files.write(f, ""abc"");
        File f2 = File.createTempFile(""def_"", "".json"");
        org.nutz.lang.Files.write(f2, ""def"");
        upload(""/upload/issue1220"", new NutMap(""file"", new File[]{f, f2}));
        assertEquals(200, resp.getStatus());
        String cnt = resp.getContent();
        System.out.println(cnt);
        assertEquals(""2,3,3"", cnt);
    }
"
"    @Test
    public void test_upload_empty_just_r_n() throws Exception {
        MockHttpServletRequest req = Mock.servlet.request();
        req.setPathInfo(""/nutz/junit/uploading"");
        MultipartInputStream ins = Mock.servlet.insmulti(charset);
        File f = Files.findFile(""org/nutz/mvc/upload/files/_r_n.txt"");
        ins.append(""theF"", f);
        req.setInputStream(ins);
        req.init();

        /*
         * é»è®¤ä¸å¿½ç¥ç©ºæä»¶
         */
        Uploading up = UploadUnit.TYPE.born();
        Map<String, Object> map = up.parse(req, UploadingContext.create(tmps));
        assertEquals(1, map.size());
        TempFile tf = (TempFile) map.get(""theF"");

        assertEquals(""_r_n.txt"", tf.getSubmittedFileName());
        assertTrue(Streams.equals(Streams.fileIn(f), tf.getInputStream()));
    }
"
"    @Test(expected = UploadUnsupportedFileTypeException.class)
    public void test_limit_file_content_type_fail() throws UploadException {
        MockHttpServletRequest req = Mock.servlet.request();
        req.setPathInfo(""/nutz/junit/uploading"");
        File blue = Files.findFile(""org/nutz/mvc/upload/files/quick/blue.png"");

        MultipartInputStream ins = Mock.servlet.insmulti(charset);
        ins.append(""blue"", blue);
        req.setInputStream(ins);
        req.init();

        /*
         * æä»¶è¶å¤§ï¼ä¼éå¶
         */
        Uploading up = UploadUnit.TYPE.born();
        up.parse(req,
                 UploadingContext.create(tmps)
                                 .setContentTypeFilter(""^image/gif$""));
    }
"
"    @Test(expected = UploadUnsupportedFileNameException.class)
    public void test_limit_file_name_fail() throws UploadException {
        MockHttpServletRequest req = Mock.servlet.request();
        req.setPathInfo(""/nutz/junit/uploading"");
        File blue = Files.findFile(""org/nutz/mvc/upload/files/quick/blue.png"");

        MultipartInputStream ins = Mock.servlet.insmulti(charset);
        ins.append(""blue"", blue);
        req.setInputStream(ins);
        req.init();

        /*
         * æä»¶è¶å¤§ï¼ä¼éå¶
         */
        Uploading up = UploadUnit.TYPE.born();
        up.parse(req,
                 UploadingContext.create(tmps)
                                 .setNameFilter(""^(.+[.])(gif|jpg)$""));
    }
"
"    @Test
    public void test_limit_file_size_ok() throws UploadException {
        MockHttpServletRequest req = Mock.servlet.request();
        req.setPathInfo(""/nutz/junit/uploading"");
        File blue = Files.findFile(""org/nutz/mvc/upload/files/quick/blue.png"");

        MultipartInputStream ins = Mock.servlet.insmulti(charset);
        ins.append(""blue"", blue);
        req.setInputStream(ins);
        req.init();

        /*
         * æä»¶è¶å¤§ï¼ä¼éå¶
         */
        Uploading up = UploadUnit.TYPE.born();
        up.parse(req, UploadingContext.create(tmps)
                                      .setBufferSize(1024)
                                      .setMaxFileSize(19152));
    }
"
"    @Test(expected = UploadOutOfSizeException.class)
    public void test_limit_file_size_fail() throws UploadException {
        MockHttpServletRequest req = Mock.servlet.request();
        req.setPathInfo(""/nutz/junit/uploading"");
        File blue = Files.findFile(""org/nutz/mvc/upload/files/quick/blue.png"");

        MultipartInputStream ins = Mock.servlet.insmulti(charset);
        ins.append(""blue"", blue);
        req.setInputStream(ins);
        req.init();

        /*
         * æä»¶è¶å¤§ï¼ä¼éå¶
         */
        Uploading up = UploadUnit.TYPE.born();
        // å½è®¾ç½®ä¸º170,pass
        // è®¾ç½®ä¸º171,fail åå æªæ
        // zzh: FastUploading çéå¶ä¸æ¯ç¹å«ç²¾ç¡®
        // å ä¸ºæ¯æåè¯»åç, æ¯æ¬¡å¾ªç¯ï¼è¦è¯»1-3ä¸ªåï¼æä»¥å°ºå¯¸çéå¶å ç¼å²å¤§å°ï¼ä¹ä¼æå³ç³»
        // å¦æç¼å²æ¯ 171, å¯è½æ­£å¥½è¯»å®
        up.parse(req, UploadingContext.create(tmps)
                                      .setBufferSize(171)
                                      .setMaxFileSize(18620));
    }
"
"	@Test
	public void testDefaults() {
		String[] args = new String[] { ""-a"", ""json"" };
		DumpProcessingOutputAction action = getActionFromArgs(args);

		assertEquals(action.compressionType,
				DumpProcessingOutputAction.COMPRESS_NONE);
		assertFalse(action.useStdOut);
	}
"
"	@Test
	public void testCompressionOutputArgumentsShort() {
		String[] args = new String[] { ""-a"", ""json"", ""-z"", ""bz2"" };
		DumpProcessingOutputAction action = getActionFromArgs(args);

		assertEquals(action.compressionType,
				DumpProcessingOutputAction.COMPRESS_BZ2);
	}
"
"	@Test
	public void testCompressionOutputArgumentsLong() {
		String[] args = new String[] { ""-a"", ""json"", ""--compression"", ""GZ"" };
		DumpProcessingOutputAction action = getActionFromArgs(args);

		assertEquals(action.compressionType,
				DumpProcessingOutputAction.COMPRESS_GZIP);
	}
"
"	@Test
	public void testStdOutOutputArgumentsShort() {
		String[] args = new String[] { ""-a"", ""json"", ""-s"" };
		DumpProcessingOutputAction action = getActionFromArgs(args);

		assertTrue(action.useStdOut);
	}
"
"	@Test
	public void testStdOutOutputArgumentsLong() {
		String[] args = new String[] { ""-a"", ""json"", ""--stdout"" };
		DumpProcessingOutputAction action = getActionFromArgs(args);

		assertTrue(action.useStdOut);
	}
"
"	@Test
	public void testInsertDumpInformation() {
		DumpProcessingOutputAction action = new JsonSerializationAction();
		action.setDumpInformation(""wikidata"", ""20150131"");
		String result = action
				.insertDumpInformation(""{PROJECT}-{DATE}-dump.json"");
		assertEquals(result, ""wikidata-20150131-dump.json"");
	}
"
"	@Test
	public void testDefaults() {
		String[] args = new String[] { ""-a"", ""json"" };
		DumpProcessingOutputAction action = DumpProcessingOutputActionTest
				.getActionFromArgs(args);

		assertTrue(action instanceof JsonSerializationAction);
		assertFalse(action.needsSites());
		assertTrue(action.isReady());
		assertEquals(action.getActionName(), ""JsonSerializationAction"");
	}
"
"	@Test
	public void testJsonOutput() throws IOException {
		String[] args = new String[] { ""-a"", ""json"", ""-o"",
				""/path/to/output.json"" };

		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);

		ClientConfiguration config = new ClientConfiguration(args);
		JsonSerializationAction jsa = (JsonSerializationAction) config
				.getActions().get(0);

		ItemIdValue subject1 = Datamodel.makeWikidataItemIdValue(""Q42"");
		ItemIdValue subject2 = Datamodel.makeWikidataItemIdValue(""Q43"");
		MonolingualTextValue mtv1 = Datamodel.makeMonolingualTextValue(""Test1"",
				""en"");
		MonolingualTextValue mtv2 = Datamodel.makeMonolingualTextValue(""Test2"",
				""fr"");

		ItemDocument id1 = Datamodel.makeItemDocument(subject1,
				Arrays.asList(mtv1, mtv2), Arrays.asList(mtv1),
				Collections.<MonolingualTextValue> emptyList(),
				Collections.<StatementGroup> emptyList(),
				Collections.<String, SiteLink> emptyMap());

		ItemDocument id2 = Datamodel.makeItemDocument(subject2,
				Collections.<MonolingualTextValue> emptyList(),
				Arrays.asList(mtv2),
				Collections.<MonolingualTextValue> emptyList(),
				Collections.<StatementGroup> emptyList(),
				Collections.<String, SiteLink> emptyMap());

		PropertyDocument pd1 = Datamodel
				.makePropertyDocument(
						Datamodel.makeWikidataPropertyIdValue(""P31""),
						Arrays.asList(mtv1),
						Collections.<MonolingualTextValue> emptyList(),
						Arrays.asList(mtv1),
						Collections.emptyList(),
						Datamodel
								.makeDatatypeIdValue(DatatypeIdValue.DT_MONOLINGUAL_TEXT));

		jsa.open();
		jsa.processItemDocument(id1);
		jsa.processPropertyDocument(pd1);
		jsa.processItemDocument(id2);
		jsa.close();

		MockDirectoryManager mdm = new MockDirectoryManager(
				Paths.get(""/path/to/""), false);

		ObjectMapper mapper = new DatamodelMapper(Datamodel.SITE_WIKIDATA);
		ObjectReader documentReader = mapper
				.readerFor(EntityDocumentImpl.class);
		MappingIterator<EntityDocument> documentIterator = documentReader
				.readValues(mdm.getInputStreamForFile(""output.json"",
						CompressionType.NONE));

		List<EntityDocument> results = new ArrayList<>();
		while (documentIterator.hasNextValue()) {
			EntityDocument document = documentIterator.nextValue();
			results.add(document);
		}
		documentIterator.close();

		assertEquals(3, results.size());
		assertEquals(id1, results.get(0));
		assertEquals(pd1, results.get(1));
		assertEquals(id2, results.get(2));

	}
"
"	@Test
	public void testJsonGzipOutput() throws IOException {
		String[] args = new String[] { ""-a"", ""json"", ""-o"",
				""/path/to/output.json"", ""-z"", ""gz"" };

		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);

		ClientConfiguration config = new ClientConfiguration(args);
		JsonSerializationAction jsa = (JsonSerializationAction) config
				.getActions().get(0);

		ItemIdValue subject1 = Datamodel.makeWikidataItemIdValue(""Q42"");
		MonolingualTextValue mtv1 = Datamodel.makeMonolingualTextValue(""Test1"",
				""en"");
		MonolingualTextValue mtv2 = Datamodel.makeMonolingualTextValue(""Test2"",
				""fr"");

		ItemDocument id1 = Datamodel.makeItemDocument(subject1,
				Arrays.asList(mtv1, mtv2), Arrays.asList(mtv1),
				Collections.<MonolingualTextValue> emptyList(),
				Collections.<StatementGroup> emptyList(),
				Collections.<String, SiteLink> emptyMap());

		jsa.open();
		jsa.processItemDocument(id1);
		jsa.close();

		MockDirectoryManager mdm = new MockDirectoryManager(
				Paths.get(""/path/to/""), false);

		ObjectMapper mapper = new DatamodelMapper(Datamodel.SITE_WIKIDATA);
		ObjectReader documentReader = mapper.readerFor(EntityDocumentImpl.class);
		MappingIterator<EntityDocument> documentIterator = documentReader
				.readValues(mdm.getInputStreamForFile(""output.json.gz"",
						CompressionType.GZIP));

		List<EntityDocument> results = new ArrayList<>();
		while (documentIterator.hasNextValue()) {
			EntityDocument document = documentIterator.nextValue();
			results.add(document);
		}
		documentIterator.close();

		assertEquals(1, results.size());
		assertEquals(id1, results.get(0));
	}
"
"	@Test
	public void testJsonBz2Output() throws IOException {
		String[] args = new String[] { ""-a"", ""json"", ""-o"", ""output.json"", ""-z"",
				""bz2"" };

		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);

		ClientConfiguration config = new ClientConfiguration(args);
		JsonSerializationAction jsa = (JsonSerializationAction) config
				.getActions().get(0);

		ItemIdValue subject1 = Datamodel.makeWikidataItemIdValue(""Q42"");
		MonolingualTextValue mtv1 = Datamodel.makeMonolingualTextValue(""Test1"",
				""en"");
		MonolingualTextValue mtv2 = Datamodel.makeMonolingualTextValue(""Test2"",
				""fr"");

		ItemDocument id1 = Datamodel.makeItemDocument(subject1,
				Arrays.asList(mtv1, mtv2), Arrays.asList(mtv1),
				Collections.<MonolingualTextValue> emptyList(),
				Collections.<StatementGroup> emptyList(),
				Collections.<String, SiteLink> emptyMap());

		jsa.open();
		jsa.processItemDocument(id1);
		jsa.close();

		MockDirectoryManager mdm = new MockDirectoryManager(Paths.get("".""),
				false);

		ObjectMapper mapper = new DatamodelMapper(Datamodel.SITE_WIKIDATA);
		ObjectReader documentReader = mapper.readerFor(EntityDocumentImpl.class);
		MappingIterator<EntityDocument> documentIterator = documentReader
				.readValues(mdm.getInputStreamForFile(""output.json.bz2"",
						CompressionType.BZ2));

		List<EntityDocument> results = new ArrayList<>();
		while (documentIterator.hasNextValue()) {
			EntityDocument document = documentIterator.nextValue();
			results.add(document);
		}
		documentIterator.close();

		assertEquals(1, results.size());
		assertEquals(id1, results.get(0));
	}
"
"	@Test
	public void testDefaults() {
		String[] args = new String[] { ""-a"", ""rdf"", ""--rdftasks"", ""entities"" };
		DumpProcessingOutputAction action = DumpProcessingOutputActionTest
				.getActionFromArgs(args);

		assertTrue(action instanceof RdfSerializationAction);
		assertTrue(action.needsSites());
		assertTrue(action.isReady());
		assertEquals(action.getActionName(), ""RdfSerializationAction"");
	}
"
"	@Test
	public void testDefaultsNoTasks() {
		String[] args = new String[] { ""-a"", ""rdf"", ""--stdout"" };
		DumpProcessingOutputAction action = DumpProcessingOutputActionTest
				.getActionFromArgs(args);
		action.open();
		action.close();

		assertTrue(action instanceof RdfSerializationAction);
		assertFalse(action.needsSites());
		assertFalse(action.isReady());
	}
"
"	@Test
	public void testSerializerSetup() {
		String[] args = new String[] { ""-a"", ""rdf"", ""--stdout"", ""--rdftasks"",
				""properties,labels"" };
		RdfSerializationAction action = (RdfSerializationAction) DumpProcessingOutputActionTest
				.getActionFromArgs(args);
		action.open(); // creates and initializes serializer (prints to stdout)
		action.close(); // just to test that this causes no exceptions

		assertTrue(action.needsSites());
		assertEquals(action.serializer.getTasks(),
				RdfSerializer.TASK_PROPERTIES | RdfSerializer.TASK_LABELS);

	}
"
"	@Test
	public void testDefaultLoggingConfig() throws ParseException, IOException {
		String[] args = new String[] {};
		Client client = new Client(mockDpc, args);
		client.performActions(); // print help

		assertEquals(Level.INFO, Client.consoleAppender.getThreshold());
		assertEquals(Level.WARN, Client.errorAppender.getThreshold());
	}
"
"	@Test
	public void testQuietStdOutLoggingConfig() throws ParseException,
			IOException {
		String[] args = new String[] { ""-a"", ""json"", ""-s"" };
		new Client(mockDpc, args);

		assertEquals(Level.OFF, Client.consoleAppender.getThreshold());
		assertEquals(Level.WARN, Client.errorAppender.getThreshold());
	}
"
"	@Test
	public void testQuietLoggingConfig() throws ParseException, IOException {
		String[] TEST_ARGS = new String[] { ""-a"", ""json"", ""-q"" };
		new Client(mockDpc, TEST_ARGS);

		assertEquals(Level.OFF, Client.consoleAppender.getThreshold());
		assertEquals(Level.WARN, Client.errorAppender.getThreshold());
	}
"
"	@Test
	public void testJsonOutput() {
		String[] args = { ""-a"", ""json"", ""-o"", ""output/wikidata.json"" };
		ClientConfiguration configuration = new ClientConfiguration(args);
		DumpProcessingAction action = configuration.actions.get(0);
		action.open();
		action.close();
		assertTrue(action
				.getReport()
				.matches(
						""Finished serialization of \\d+ EntityDocuments in file output/wikidata.json""));
	}
"
"	@Test
	public void testRdfOutput() {
		String[] args = { ""-a"", ""rdf"", ""-o"", ""output/wikidata.rdf"" };
		ClientConfiguration configuration = new ClientConfiguration(args);
		DumpProcessingAction action = configuration.actions.get(0);
		action.open();
		action.close();
		assertTrue(action
				.getReport()
				.matches(
						""Finished serialization of \\d+ RDF triples in file output/wikidata.rdf""));
	}
"
"	@Test
	public void testSitesAction() throws ParseException, IOException {
		String[] args = new String[] { ""-a"", ""rdf"", ""--rdftasks"",
				""items,labels"" };
		Client client = new Client(mockDpc, args);
		client.performActions();

		Mockito.verify(mockDpc).processDump(Mockito.<MwDumpFile> any());
		Mockito.verify(mockDpc).getSitesInformation();
	}
"
"	@Test
	public void testSetDumpsDirectoryException() throws ParseException,
			IOException {
		Mockito.doThrow(new IOException(""Mock exception for testing.""))
				.when(mockDpc).setDownloadDirectory(Mockito.anyString());

		String[] args = new String[] { ""-a"", ""rdf"", ""--rdftasks"",
				""items,labels"", ""--dumps"", ""/tmp/"" };
		Client client = new Client(mockDpc, args);
		client.performActions(); // print help

		Mockito.verify(mockDpc, Mockito.never()).processDump(
				Mockito.<MwDumpFile> any());
		Mockito.verify(mockDpc, Mockito.never()).getSitesInformation();
	}
"
"	@Test
	public void testSitesActionException() throws ParseException, IOException {
		Mockito.doThrow(new IOException()).when(mockDpc).getSitesInformation();

		String[] args = new String[] { ""-a"", ""rdf"", ""--rdftasks"",
				""items,labels"" };
		Client client = new Client(mockDpc, args);
		client.performActions(); // print help

		Mockito.verify(mockDpc, Mockito.never()).processDump(
				Mockito.<MwDumpFile> any());
		Mockito.verify(mockDpc).getSitesInformation();
	}
"
"	@Test
	public void testNonSitesAction() throws ParseException, IOException {
		String[] args = new String[] { ""-a"", ""json"", ""-q"" };
		Client client = new Client(mockDpc, args);
		client.performActions(); // print help

		Mockito.verify(mockDpc).processDump(Mockito.<MwDumpFile> any());
		Mockito.verify(mockDpc, Mockito.never()).getSitesInformation();
	}
"
"	@Test
	public void testWriteReport() throws IOException {
		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);

		MockDirectoryManager mdm = new MockDirectoryManager(
				Paths.get(""/output/""), false);

		String[] args = {""-n"", ""-a"", ""rdf"", ""--rdftasks"", ""aliases"", ""-o"",
				""/output/wikidata.rdf"", ""-r"", ""/output/report.txt"" };

		Client client = new Client(mockDpc, args);
		DumpProcessingAction action = client.clientConfiguration.actions.get(0);
		action.open();
		action.close();
		client.writeReport();
		assertTrue(IOUtils
				.toString(
						mdm.getInputStreamForFile(""report.txt"",
								CompressionType.NONE))
				.matches(
						""RdfSerializationAction: Finished serialization of \\d+ RDF triples in file /output/wikidata.rdf""
								+ System.lineSeparator()));

	}
"
"	@Test
	public void testInsertDumpInformation() throws IOException {
		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);

		MockDirectoryManager mdm = new MockDirectoryManager(
				Paths.get(""/output/""), false);

		String[] args = { ""-n"", ""-a"", ""rdf"", ""-o"", ""/output/wikidata.rdf"",
				""--rdftasks"", ""aliases"", ""-r"", ""/output/report-{DATE}.txt"" };

		Client client = new Client(mockDpc, args);
		client.performActions();

		assertTrue(mdm.hasFile(""/output/report-""
				+ client.clientConfiguration.getDateStamp() + "".txt""));
	}
"
"	@Test
	public void testNonExistingLocalDump() {
		String[] args = { ""-f"", ""./asfjl.json"" };
		Client client = new Client(mockDpc, args);
		client.performActions();

		Mockito.verify(mockDpc, Mockito.never()).processDump(
				Mockito.<MwDumpFile> any());
	}
"
"	@Test
	public void testReadConfigFile() throws IOException {
		String configFile = ""src/test/resources/testConf.ini"";
		String[] args = new String[] { ""-c"", configFile };
		ClientConfiguration config = new ClientConfiguration(args);

		assertTrue(config.getOfflineMode());
		assertTrue(config.isQuiet());
		assertEquals(""dumps/wikidata/"", config.getDumpDirectoryLocation());
		assertEquals(Collections.<String> emptySet(),
				config.getFilterSiteKeys());
		assertEquals(Collections.singleton(Datamodel
						.makeWikidataPropertyIdValue(""P31"")),
				config.getFilterProperties());
		Set<String> langFilters = new HashSet<>();
		langFilters.add(""fr"");
		langFilters.add(""zh"");
		assertEquals(langFilters, config.getFilterLanguages());

		assertEquals(2, config.getActions().size());
		assertTrue(config.getActions().get(0) instanceof RdfSerializationAction);
		assertTrue(config.getActions().get(1) instanceof JsonSerializationAction);
		RdfSerializationAction rdfAction = (RdfSerializationAction) config
				.getActions().get(0);
		JsonSerializationAction jsonAction = (JsonSerializationAction) config
				.getActions().get(1);

		assertTrue(rdfAction.useStdOut);
		assertEquals(DumpProcessingOutputAction.COMPRESS_GZIP,
				rdfAction.compressionType);
		assertEquals(""/tmp/wikidata-items.nt"", rdfAction.outputDestination);
		assertEquals(RdfSerializer.TASK_ITEMS | RdfSerializer.TASK_STATEMENTS
				| RdfSerializer.TASK_TERMS, rdfAction.tasks);

		assertFalse(jsonAction.useStdOut);
		assertEquals(DumpProcessingOutputAction.COMPRESS_BZ2,
				jsonAction.compressionType);
		assertEquals(""/tmp/wikidata-dump.json"", jsonAction.outputDestination);
	}
"
"	@Test
	public void testReadConfigFile2() throws IOException {
		String configFile = ""src/test/resources/testConf2.ini"";
		String[] args = new String[] { ""-c"", configFile };
		ClientConfiguration config = new ClientConfiguration(args);

		assertFalse(config.getOfflineMode());
		assertFalse(config.isQuiet());
		assertEquals(""testfile.json.gz"", config.getInputDumpLocation());
		assertEquals(""report.txt"", config.getReportFileName());
		// remaining content was already tested above
	}
"
"	@Test
	public void testDefaultArguments() {
		String[] args = new String[] {};
		ClientConfiguration config = new ClientConfiguration(args);
		assertFalse(config.getOfflineMode());
		assertEquals(null, config.getDumpDirectoryLocation());
		assertEquals(null, config.getFilterLanguages());
		assertEquals(null, config.getFilterSiteKeys());
		assertEquals(null, config.getFilterProperties());
		assertEquals(null, config.getReportFileName());
		assertEquals(null, config.getInputDumpLocation());
		assertEquals(null, config.getLocalDumpFile());
		assertFalse(config.isQuiet());
	}
"
"	@Test
	public void testUnknownAction() {
		String[] args = new String[] { ""-a"", ""notImplemented"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertEquals(0, config.getActions().size());
	}
"
"	@Test
	public void testUnknownArguments() {
		String[] args = new String[] { ""--unknown"", ""-foo"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertFalse(config.getOfflineMode());
		assertEquals(null, config.getDumpDirectoryLocation());
		assertFalse(config.isQuiet());
	}
"
"	@Test
	public void testDumpLocationArgumentsShort() {
		String[] args = new String[] { ""-d"", ""dumps/wikidata/"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertEquals(""dumps/wikidata/"", config.getDumpDirectoryLocation());
	}
"
"	@Test
	public void testDumpLocationArgumentsLong() {
		String[] args = new String[] { ""--dumps"", ""dumps/wikidata/"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertEquals(""dumps/wikidata/"", config.getDumpDirectoryLocation());
	}
"
"	@Test
	public void testOfflineModeArgumentsShort() {
		String[] args = new String[] { ""-n"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertTrue(config.getOfflineMode());
	}
"
"	@Test
	public void testOfflineModeArgumentsLong() {
		String[] args = new String[] { ""--offline"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertTrue(config.getOfflineMode());
	}
"
"	@Test
	public void testStdOutOutputArgumentsShort() {
		String[] args = new String[] { ""-a"", ""json"", ""-s"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertTrue(config.isQuiet());
	}
"
"	@Test
	public void testStdOutOutputArgumentsLong() {
		String[] args = new String[] { ""--action"", ""json"", ""--stdout"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertTrue(config.isQuiet());
	}
"
"	@Test
	public void testQuietArgumentsShort() {
		String[] args = new String[] { ""-q"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertTrue(config.isQuiet());
	}
"
"	@Test
	public void testQuietArgumentsLong() {
		String[] args = new String[] { ""--quiet"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertTrue(config.isQuiet());
	}
"
"	@Test
	public void testReportArgumentsShort() {
		String[] args = new String[] { ""-r"", ""output/report.txt"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertEquals(""output/report.txt"", config.getReportFileName());
	}
"
"	@Test
	public void testReportArgumentsLong() {
		String[] args = new String[] { ""--report"", ""output/report.txt"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertEquals(""output/report.txt"", config.getReportFileName());
	}
"
"	@Test
	public void testLanguageFilterArguments() {
		String[] args = new String[] { ""--fLang"", ""en,de"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<String> langFilters = new HashSet<>();
		langFilters.add(""en"");
		langFilters.add(""de"");

		assertEquals(langFilters, config.getFilterLanguages());
	}
"
"	@Test
	public void testLanguageFilterArgumentsEmpty() {
		String[] args = new String[] { ""--fLang"", ""-"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<String> langFilters = new HashSet<>();

		assertEquals(langFilters, config.getFilterLanguages());
	}
"
"	@Test
	public void testSiteLinkFilterArguments() {
		String[] args = new String[] { ""--fSite"", ""fawiki,dewiki"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<String> siteFilters = new HashSet<>();
		siteFilters.add(""fawiki"");
		siteFilters.add(""dewiki"");

		assertEquals(siteFilters, config.getFilterSiteKeys());
	}
"
"	@Test
	public void testSiteLinkFilterArgumentsEmpty() {
		String[] args = new String[] { ""--fSite"", ""-"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<String> siteFilters = new HashSet<>();

		assertEquals(siteFilters, config.getFilterSiteKeys());
	}
"
"	@Test
	public void testPropertyFilterArguments() {
		String[] args = new String[] { ""--fProp"", ""P100,P31"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<PropertyIdValue> propFilters = new HashSet<>();
		propFilters.add(Datamodel.makeWikidataPropertyIdValue(""P31""));
		propFilters.add(Datamodel.makeWikidataPropertyIdValue(""P100""));

		assertEquals(propFilters, config.getFilterProperties());
	}
"
"	@Test
	public void testPropertyFilterArgumentsEmpty() {
		String[] args = new String[] { ""--fProp"", ""-"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<PropertyIdValue> propFilters = new HashSet<>();

		assertEquals(propFilters, config.getFilterProperties());
	}
"
"	@Test
	public void testLocalDumpFileLong() {
		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);
		String[] args = new String[] { ""--input"", ""dumptest.json"" };
		ClientConfiguration config = new ClientConfiguration(args);

		MwDumpFile df = config.getLocalDumpFile();

		assertEquals(""dumptest.json"", config.getInputDumpLocation());
		assertTrue(df instanceof MwLocalDumpFile);
		MwLocalDumpFile ldf = (MwLocalDumpFile) df;

		assertEquals(Paths.get(""dumptest.json"").toAbsolutePath(), ldf.getPath());
	}
"
"	@Test
	public void testLocalDumpFileShort() {
		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);
		String[] args = new String[] { ""-i"", ""dumptest.json"" };
		ClientConfiguration config = new ClientConfiguration(args);

		MwDumpFile df = config.getLocalDumpFile();

		assertEquals(""dumptest.json"", config.getInputDumpLocation());
		assertTrue(df instanceof MwLocalDumpFile);
		MwLocalDumpFile ldf = (MwLocalDumpFile) df;

		assertEquals(Paths.get(""dumptest.json"").toAbsolutePath(), ldf.getPath());
	}
"
"	@Test
	public void testIteration() {
		List<String> list1 = new ArrayList<String>();
		list1.add(""1"");
		list1.add(""2"");
		List<String> list2 = new ArrayList<String>();
		list2.add(""3"");
		List<String> list3 = new ArrayList<String>();
		List<String> list4 = new ArrayList<String>();
		list4.add(""4"");

		List<List<String>> listOfLists = new ArrayList<>();
		listOfLists.add(list1);
		listOfLists.add(list2);
		listOfLists.add(list3);
		listOfLists.add(list4);

		NestedIterator<String> nestedIterator = new NestedIterator<>(
				listOfLists);

		assertTrue(nestedIterator.hasNext());
		assertEquals(""1"", nestedIterator.next());
		assertTrue(nestedIterator.hasNext());
		assertEquals(""2"", nestedIterator.next());
		assertTrue(nestedIterator.hasNext());
		assertEquals(""3"", nestedIterator.next());
		assertTrue(nestedIterator.hasNext());
		assertEquals(""4"", nestedIterator.next());
		assertEquals(false, nestedIterator.hasNext());
	}
"
"	@Test(expected = UnsupportedOperationException.class)
	public void removeNotSupported() {
		NestedIterator<String> nestedIterator = new NestedIterator<>(
				Collections.singletonList(Collections.singletonList(""Test"")));
		nestedIterator.remove();
	}
"
"	@Test(expected = NoSuchElementException.class)
	public void iterateBeyondInnerList() {
		NestedIterator<String> nestedIterator = new NestedIterator<>(
				Collections.singletonList(Collections.<String> emptyList()));
		nestedIterator.next();
	}
"
"	@Test(expected = NoSuchElementException.class)
	public void iterateBeyondOuterList() {
		NestedIterator<String> nestedIterator = new NestedIterator<>(
				Collections.<List<String>> emptyList());
		nestedIterator.next();
	}
"
"	@Test
	public void createDirectoryManagerString() throws IOException {
		Path path = Paths.get(System.getProperty(""user.dir""));
		DirectoryManagerFactory
				.setDirectoryManagerClass(DirectoryManagerImpl.class);
		DirectoryManager dm = DirectoryManagerFactory.createDirectoryManager(
				System.getProperty(""user.dir""), true);
		assertTrue(dm instanceof DirectoryManagerImpl);
		DirectoryManagerImpl dmi = (DirectoryManagerImpl) dm;
		assertTrue(dmi.readOnly);
		assertEquals(path, dmi.directory);
	}
"
"	@Test
	public void createDefaultDirectoryManagerPath() throws IOException {
		Path path = Paths.get(System.getProperty(""user.dir""));
		DirectoryManager dm = DirectoryManagerFactory.createDirectoryManager(
				path, true);
		assertTrue(dm instanceof DirectoryManagerImpl);
		DirectoryManagerImpl dmi = (DirectoryManagerImpl) dm;
		assertTrue(dmi.readOnly);
		assertEquals(path, dmi.directory);
	}
"
"	@Test(expected = RuntimeException.class)
	public void createDirectoryManagerNoConstructor() throws IOException {
		DirectoryManagerFactory
				.setDirectoryManagerClass(TestDirectoryManager.class);
		DirectoryManagerFactory.createDirectoryManager(""/"", true);
	}
"
"	@Test(expected = IOException.class)
	public void createDirectoryManagerIoException() throws IOException {
		DirectoryManagerFactory.createDirectoryManager(
				""/nonexisting-directory/123456789/hopefully"", true);
	}
"
"	@Test
	public void testSetUserAgent() {
		WebResourceFetcherImpl.setUserAgent(""My user agent"");
		assertEquals(""My user agent"", WebResourceFetcherImpl.getUserAgent());
	}
"
"	@Test
	public void testSetProxy() {
		Proxy proxy = new Proxy(Proxy.Type.HTTP, new InetSocketAddress(
				""test.adress"", 8080));
		WebResourceFetcherImpl.setProxy(proxy);
		assertTrue(WebResourceFetcherImpl.hasProxy());
		assertEquals(proxy, WebResourceFetcherImpl.getProxy());
	}
"
"	@Test
	public void testToString() throws IOException {
		assertEquals(Paths.get(System.getProperty(""user.dir"")).toString(),
				dm.toString());
	}
"
"	@Test(expected = IOException.class)
	public void MissingSubdirectoryReadOnly() throws IOException {
		dm.getSubdirectoryManager(""1 2 3 not a subdirectory that exists in the test system, hopefully"");
	}
"
"	@Test(expected = IOException.class)
	public void OutputStreamReadOnly() throws IOException {
		dm.getOutputStreamForFile(""file.txt"");
	}
"
"	@Test(expected = IOException.class)
	public void NoCreateFileStringReadOnly() throws IOException {
		dm.createFile(""new-test-file.txt"", ""new contents"");
	}
"
"	@Test(expected = IOException.class)
	public void NoCreateFileInputStreamReadOnly() throws IOException {
		ByteArrayInputStream in = new ByteArrayInputStream(
				""new contents"".getBytes(StandardCharsets.UTF_8));
		dm.createFile(""new-test-file.txt"", in);
	}
"
"	@Test(expected = IOException.class)
	public void NoCreateFileAtomicInputStreamReadOnly() throws IOException {
		ByteArrayInputStream in = new ByteArrayInputStream(
				""new contents"".getBytes(StandardCharsets.UTF_8));
		dm.createFileAtomic(""new-test-file.txt"", in);
	}
"
"	@Test
	public void getCompressionInputStreamNone() throws IOException {
		ByteArrayInputStream in = new ByteArrayInputStream(
				""new contents"".getBytes(StandardCharsets.UTF_8));
		assertEquals(in, dm.getCompressorInputStream(in, CompressionType.NONE));
	}
"
"	@Test
	public void getCompressionInputStreamGzip() throws IOException {
		ByteArrayOutputStream out = new ByteArrayOutputStream();
		OutputStreamWriter ow = new OutputStreamWriter(
				new GzipCompressorOutputStream(out), StandardCharsets.UTF_8);
		ow.write(""Test data"");
		ow.close();

		ByteArrayInputStream in = new ByteArrayInputStream(out.toByteArray());
		InputStream cin = dm.getCompressorInputStream(in, CompressionType.GZIP);

		assertEquals(""Test data"",
				new BufferedReader(new InputStreamReader(cin)).readLine());
	}
"
"	@Test
	public void getCompressionInputStreamBz2() throws IOException {
		ByteArrayOutputStream out = new ByteArrayOutputStream();
		OutputStreamWriter ow = new OutputStreamWriter(
				new BZip2CompressorOutputStream(out), StandardCharsets.UTF_8);
		ow.write(""Test data"");
		ow.close();

		ByteArrayInputStream in = new ByteArrayInputStream(out.toByteArray());
		InputStream cin = dm.getCompressorInputStream(in, CompressionType.BZ2);

		assertEquals(""Test data"",
				new BufferedReader(new InputStreamReader(cin)).readLine());
	}
"
"	@Test
	public void basicTimerOperation() {
		Timer timer = new Timer(""Test timer"", Timer.RECORD_ALL);
		assertEquals(timer.getName(), ""Test timer"");
		long threadId = timer.getThreadId();

		assertEquals(timer.getAvgCpuTime(), 0);
		assertEquals(timer.getAvgWallTime(), 0);

		ThreadMXBean tmxb = ManagementFactory.getThreadMXBean();
		if (!tmxb.isThreadCpuTimeEnabled()) {
			tmxb.setThreadCpuTimeEnabled(true);
		}

		long cpuTime1 = tmxb.getThreadCpuTime(threadId);
		long wallTime1 = System.nanoTime();
		timer.start();
		doDummyComputation();
		assertTrue(""Timer should be running"", timer.isRunning());
		timer.stop();
		cpuTime1 = tmxb.getThreadCpuTime(threadId) - cpuTime1;
		wallTime1 = System.nanoTime() - wallTime1;
		assertTrue(
				""Unrealistic CPU time: "" + timer.getTotalCpuTime()
						+ "" should be closer to "" + cpuTime1,
				(cpuTime1 - TimerTest.TIME_TOLERANCE) <= timer
						.getTotalCpuTime()
						&& timer.getTotalCpuTime() <= cpuTime1);
		assertTrue(
				""Unrealistic wall time: "" + timer.getTotalWallTime()
						+ "" should be closer to "" + wallTime1,
				(wallTime1 - 2 * TimerTest.TIME_TOLERANCE) <= timer
						.getTotalWallTime()
						&& timer.getTotalWallTime() <= wallTime1);

		long cpuTime2 = tmxb.getThreadCpuTime(threadId);
		long wallTime2 = System.nanoTime();
		timer.start();
		doDummyComputation();
		timer.stop();
		cpuTime1 += tmxb.getThreadCpuTime(threadId) - cpuTime2;
		wallTime1 += System.nanoTime() - wallTime2;
		assertTrue(
				""Unrealistic total CPU time: "" + timer.getTotalCpuTime()
						+ "" should be closer to "" + cpuTime1,
				(cpuTime1 - 2 * TimerTest.TIME_TOLERANCE) <= timer
						.getTotalCpuTime()
						&& timer.getTotalCpuTime() <= cpuTime1);
		assertTrue(
				""Unrealistic total wall time: "" + timer.getTotalWallTime()
						+ "" should be closer to "" + wallTime1,
				(wallTime1 - 4 * TimerTest.TIME_TOLERANCE) <= timer
						.getTotalWallTime()
						&& timer.getTotalWallTime() <= wallTime1);

		assertEquals(timer.getTotalCpuTime() / 2, timer.getAvgCpuTime());
		assertEquals(timer.getTotalWallTime() / 2, timer.getAvgWallTime());

		timer.reset();
		assertEquals(timer.getTotalCpuTime(), 0);
		assertEquals(timer.getTotalWallTime(), 0);
		assertFalse(""Timer should not be running"", timer.isRunning());
	}
"
"	@Test
	public void namedTimers() {
		Timer timerA1 = Timer.getNamedTimer(""test timer"");
		Timer timerA2 = Timer.getNamedTimer(""test timer"");
		Timer timerA3 = Timer.getNamedTimer(""test timer"", Timer.RECORD_ALL);
		Timer timerA4 = Timer.getNamedTimer(""test timer"", Timer.RECORD_ALL,
				timerA1.getThreadId());
		Timer timerCpu = Timer
				.getNamedTimer(""test timer"", Timer.RECORD_CPUTIME);
		Timer timerWall = Timer.getNamedTimer(""test timer"",
				Timer.RECORD_WALLTIME);
		Timer timerNoThread = Timer.getNamedTimer(""test timer"",
				Timer.RECORD_ALL, 0);
		Timer timerNone = Timer.getNamedTimer(""test timer none"",
				Timer.RECORD_NONE);
		Timer timerB = Timer.getNamedTimer(""test timer 2"");

		// Testing Timer equality:
		assertEquals(timerA1, timerA2);
		assertEquals(timerA1, timerA3);
		assertEquals(timerA1, timerA4);
		assertNotEquals(timerA1, timerCpu);
		assertNotEquals(timerA1, timerWall);
		assertNotEquals(timerA1, timerNoThread);
		assertNotEquals(timerA1, timerB);
		assertNotEquals(timerA1, this);

		// Testing start/stop operation:
		Timer.startNamedTimer(""test timer"");
		Timer.startNamedTimer(""test timer"", Timer.RECORD_CPUTIME);
		Timer.startNamedTimer(""test timer"", Timer.RECORD_WALLTIME);
		Timer.startNamedTimer(""test timer"", Timer.RECORD_ALL, 0);
		doDummyComputation();
		Timer.stopNamedTimer(""test timer"");
		Timer.stopNamedTimer(""test timer"", Timer.RECORD_CPUTIME);
		Timer.stopNamedTimer(""test timer"", Timer.RECORD_WALLTIME);
		Timer.stopNamedTimer(""test timer"", Timer.RECORD_ALL, 0);

		assertTrue(""Named timer should have measured a non-zero CPU time."",
				timerA1.getTotalCpuTime() > 0);
		assertTrue(""Named timer should have measured a non-zero wall time."",
				timerA1.getTotalWallTime() > 0);
		assertTrue(
				""Timer for CPU time should have measured a non-zero CPU time."",
				timerCpu.getTotalCpuTime() > 0);
		assertTrue(""Timer for CPU time should not have measured a wall time."",
				timerCpu.getTotalWallTime() == 0);
		assertTrue(""Timer for wall time should not have measured a CPU time."",
				timerWall.getTotalCpuTime() == 0);
		assertTrue(
				""Timer for wall time should have measured a non-zero wall time."",
				timerWall.getTotalWallTime() > 0);
		assertTrue(
				""Timer without threadId should not have measured a CPU time."",
				timerNoThread.getTotalCpuTime() == 0);
		assertTrue(
				""Timer without threadId should have measured a non-zero wall time."",
				timerNoThread.getTotalWallTime() > 0);

		// Testing total timer creation:
		Timer totalTimer1 = Timer.getNamedTotalTimer(""test timer"");
		// There should be four *distinct* timers of that name
		assertEquals(totalTimer1.getTotalCpuTime(), timerA1.getTotalCpuTime()
				+ timerCpu.getTotalCpuTime() + timerWall.getTotalCpuTime()
				+ timerNoThread.getTotalCpuTime());
		assertEquals(totalTimer1.getTotalWallTime(), timerA1.getTotalWallTime()
				+ timerCpu.getTotalWallTime() + timerWall.getTotalWallTime()
				+ timerNoThread.getTotalWallTime());

		Timer totalTimer2 = Timer.getNamedTotalTimer(""test timer 2"");
		// There should be just one timer of that name
		assertEquals(totalTimer2, timerB);

		// Testing toString operation
		assertTrue(timerA1.toString().startsWith(
				""Time for test timer (thread "" + timerA1.getThreadId()
						+ "") for 1 run(s) CPU/Wall/CPU avg/Wall avg (ms):""));
		assertTrue(timerCpu.toString().startsWith(
				""Time for test timer (thread "" + timerCpu.getThreadId()
						+ "") for 1 run(s) CPU/CPU avg (ms):""));
		assertTrue(timerWall.toString().startsWith(
				""Time for test timer (thread "" + timerWall.getThreadId()
						+ "") for 1 run(s) Wall/Wall avg (ms):""));
		assertTrue(totalTimer1.toString().startsWith(
				""Time for test timer (over 4 threads)""));
		assertTrue(timerNoThread.toString().startsWith(
				""Time for test timer for 1 run(s)""));
		assertEquals(timerNone.toString(), ""Timer test timer none (thread ""
				+ timerNone.getThreadId()
				+ "") recorded 0 run(s); no times taken"");
		timerA1.start();
		assertTrue(timerA1.toString().endsWith(""[timer running!]""));

		// Testing reset operation:
		Timer.resetNamedTimer(""test timer"");
		Timer.resetNamedTimer(""test timer"", Timer.RECORD_CPUTIME);
		Timer.resetNamedTimer(""test timer"", Timer.RECORD_WALLTIME);
		Timer.resetNamedTimer(""test timer"", Timer.RECORD_ALL, 0);

		assertTrue(""Named timer should have reset CPU time."",
				timerA1.getTotalCpuTime() == 0);
		assertTrue(""Named timer should have reset wall time."",
				timerA1.getTotalWallTime() == 0);
		assertTrue(""Timer for CPU time should have reset CPU time."",
				timerCpu.getTotalCpuTime() == 0);
		assertTrue(""Timer for CPU time should have reset wall time."",
				timerCpu.getTotalWallTime() == 0);
		assertTrue(""Timer for wall time should have reset CPU time."",
				timerWall.getTotalCpuTime() == 0);
		assertTrue(""Timer for wall time should have reset wall time."",
				timerWall.getTotalWallTime() == 0);
		assertTrue(""Timer without threadId should have reset CPU time."",
				timerNoThread.getTotalCpuTime() == 0);
		assertTrue(""Timer without threadId should have reset wall time."",
				timerNoThread.getTotalWallTime() == 0);

		// Testing unregistered timer stop (does not create one):
		assertEquals(Timer.stopNamedTimer(""unknown name""), -1);
	}
"
"	@Test
	public void timerStopReturnValues() {
		Timer timer1 = new Timer(""stop test timer"", Timer.RECORD_ALL);
		Timer timer2 = new Timer(""stop test timer wall"", Timer.RECORD_WALLTIME);

		timer1.start();
		timer2.start();
		doDummyComputation();
		long cpuTime1 = timer1.stop();
		long cpuTime2 = timer2.stop();

		assertEquals(cpuTime1, timer1.getTotalCpuTime());
		assertEquals(cpuTime2, -1);

		long cpuTime3 = timer1.stop();
		assertEquals(cpuTime3, -1);
	}
"
"	@Test
	public void enableCpuTimeTaking() {
		ThreadMXBean tmxb = ManagementFactory.getThreadMXBean();
		tmxb.setThreadCpuTimeEnabled(false);

		Timer timer = new Timer(""Test timer"", Timer.RECORD_ALL);
		timer.start();
		doDummyComputation();
		timer.stop();

		assertTrue(""Timer should have measured a CPU time."",
				timer.getTotalCpuTime() > 0);
	}
"
"	@Test
	public void testWriteQuantityValue() throws RDFHandlerException,
			RDFParseException, IOException {
		QuantityValueConverter valueConverter = new QuantityValueConverter(
				this.rdfWriter, this.propertyRegister, this.rdfConversionBuffer);

		QuantityValue value = this.objectFactory.getQuantityValue(
				new BigDecimal(100), new BigDecimal(100), new BigDecimal(100));
		PropertyIdValue propertyIdValue = objectFactory.getPropertyIdValue(
				""P1081"", ""http://www.wikidata.org/entity/"");
		Value valueURI = valueConverter.getRdfValue(value, propertyIdValue,
				false);
		valueConverter.writeValue(value, (Resource) valueURI);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""QuantityValue.rdf"")));
	}
"
"	@Test
	public void testWriteUnboundedQuantityValue() throws RDFHandlerException,
			RDFParseException, IOException {
		QuantityValueConverter valueConverter = new QuantityValueConverter(
				this.rdfWriter, this.propertyRegister, this.rdfConversionBuffer);

		QuantityValue value = this.objectFactory.getQuantityValue(new BigDecimal(100));
		PropertyIdValue propertyIdValue = objectFactory.getPropertyIdValue(
				""P1081"", ""http://www.wikidata.org/entity/"");
		Value valueURI = valueConverter.getRdfValue(value, propertyIdValue,
				false);
		valueConverter.writeValue(value, (Resource) valueURI);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""UnboundedQuantityValue.rdf"")));
	}
"
"	@Test
	public void testWriteMonolingualTextValue() throws RDFHandlerException {
		MonolingualTextValueConverter valueConverter = new MonolingualTextValueConverter(
				this.rdfWriter, this.propertyRegister, this.rdfConversionBuffer);

		MonolingualTextValue value = this.objectFactory
				.getMonolingualTextValue(""ä¸­åäººæ°å±åå½"", ""zh-hans"");
		PropertyIdValue propertyIdValue = this.objectFactory
				.getPropertyIdValue(""P1448"", ""http://www.wikidata.org/entity/"");
		Value valueURI = valueConverter.getRdfValue(value, propertyIdValue,
				true);
		this.rdfWriter.finish();

		assertEquals(valueURI.toString(), ""\""ä¸­åäººæ°å±åå½\""@zh-Hans"");
	}
"
"	@Test
	public void testWriteGlobeCoordinatesValue() throws RDFHandlerException,
			RDFParseException, IOException {
		GlobeCoordinatesValueConverter valueConverter = new GlobeCoordinatesValueConverter(
				this.rdfWriter, this.propertyRegister, this.rdfConversionBuffer);

		GlobeCoordinatesValue value = this.objectFactory
				.getGlobeCoordinatesValue(51.033333333333, 13.733333333333,
						(GlobeCoordinatesValue.PREC_DECI_DEGREE),
						""http://www.wikidata.org/entity/Q2"");
		PropertyIdValue propertyIdValue = objectFactory.getPropertyIdValue(
				""P625"", ""http://www.wikidata.org/entity/"");
		Value valueURI = valueConverter.getRdfValue(value, propertyIdValue,
				false);
		valueConverter.writeValue(value, (Resource) valueURI);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""GlobeCoordinatesValue.rdf"")));
	}
"
"	@Test
	public void testWriteTimeValue() throws RDFHandlerException,
			RDFParseException, IOException {
		TimeValueConverter valueConverter = new TimeValueConverter(
				this.rdfWriter, this.propertyRegister, this.rdfConversionBuffer);

		TimeValue value = objectFactory.getTimeValue(2008, (byte) 1, (byte) 1,
				(byte) 0, (byte) 0, (byte) 0, (byte) 9, 0, 0, 0,
				""http://www.wikidata.org/entity/Q1985727"");
		PropertyIdValue propertyIdValue = objectFactory.getPropertyIdValue(
				""P569"", ""http://www.wikidata.org/entity/"");
		Value valueURI = valueConverter.getRdfValue(value, propertyIdValue,
				false);
		valueConverter.writeValue(value, (Resource) valueURI);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""TimeValue.rdf"")));
	}
"
"	@Test
	public void testSerialization() throws RDFParseException,
			RDFHandlerException, IOException {
		this.rdfSerializer.open();
		this.rdfSerializer.processItemDocument(this.objectFactory
				.createItemDocument());
		this.rdfSerializer.close();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""completeRDFDocument.rdf"")), model);
	}
"
"	@Test
	public void testGetWikidataPropertyRegister() {
		assertEquals(""P1921"", this.propertyRegister.uriPatternPropertyId);
	}
"
"	@Test
	public void testFetchPropertyUriPattern() {
		PropertyIdValue pid = this.dataObjectFactory.getPropertyIdValue(""P434"",
				this.siteIri);
		assertEquals(""http://musicbrainz.org/$1/artist"",
				this.propertyRegister.getPropertyUriPattern(pid));
		// Check twice to test that the cached retrieval works too
		assertEquals(""http://musicbrainz.org/$1/artist"",
				this.propertyRegister.getPropertyUriPattern(pid));
		assertEquals(50,
				this.propertyRegister.smallestUnfetchedPropertyIdNumber);
		assertTrue(this.propertyRegister.datatypes.keySet().contains(""P434""));
	}
"
"	@Test
	public void testGetPropertyType() {
		assertEquals(DatatypeIdValue.DT_STRING,
				this.propertyRegister.getPropertyType(dataObjectFactory
						.getPropertyIdValue(""P434"", this.siteIri)));
		// Check twice to test that the cached retrieval works too
		assertEquals(DatatypeIdValue.DT_STRING,
				this.propertyRegister.getPropertyType(dataObjectFactory
						.getPropertyIdValue(""P434"", this.siteIri)));
		assertEquals(50,
				this.propertyRegister.smallestUnfetchedPropertyIdNumber);
		assertTrue(this.propertyRegister.datatypes.keySet().contains(""P434""));
	}
"
"	@Test
	public void testGetMissingPropertyType() {
		assertNull(this.propertyRegister.getPropertyType(dataObjectFactory
				.getPropertyIdValue(""P10"", this.siteIri)));
		// Check twice to test fast failing on retry
		assertNull(this.propertyRegister.getPropertyType(dataObjectFactory
				.getPropertyIdValue(""P10"", this.siteIri)));
	}
"
"	@Test
	public void testSetPropertyTypeFromEntityIdValue() {
		assertEquals(this.propertyRegister.setPropertyTypeFromEntityIdValue(
				this.dataObjectFactory
						.getPropertyIdValue(""P1001"", this.siteIri),
				this.dataObjectFactory.getItemIdValue(""Q20"", this.siteIri)),
				DatatypeIdValue.DT_ITEM);
	}
"
"	@Test
	public void testSetPropertyTypeFromStringValue() {
		assertEquals(this.propertyRegister.setPropertyTypeFromStringValue(
				dataObjectFactory.getPropertyIdValue(""P434"", this.siteIri),
				dataObjectFactory
						.getStringValue(""http://musicbrainz.org/$1/artist"")),
				""http://wikiba.se/ontology#String"");
	}
"
"	@Test
	public void testSetMissingPropertyTypeFromStringValue() {
		assertEquals(this.propertyRegister.setPropertyTypeFromStringValue(
				dataObjectFactory.getPropertyIdValue(""P10"", this.siteIri),
				dataObjectFactory
						.getStringValue(""http://musicbrainz.org/$1/artist"")),
				""http://wikiba.se/ontology#String"");
	}
"
"	@Test
	public void testWikidataPropertyRegister() {
		PropertyRegister pr = PropertyRegister.getWikidataPropertyRegister();
		assertEquals(Datamodel.SITE_WIKIDATA, pr.getUriPrefix());
		assertEquals(""P1921"", pr.uriPatternPropertyId);
	}
"
"	@Test
	public void testWriteItemDocument() throws RDFHandlerException,
			IOException, RDFParseException {
		ItemDocument document = this.objectFactory.createItemDocument();
		this.rdfConverter.writeItemDocument(document);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""ItemDocument.rdf"")));
	}
"
"	@Test
	public void testWriteItemDocumentWithNullPropertyTypes() throws RDFHandlerException,
			IOException, RDFParseException {
		this.rdfConverter = new RdfConverter(this.rdfWriter, this.sites,
				new MockPropertyRegister.WithNullPropertyTypes());

		ItemDocument document = this.objectFactory.createItemDocument();
		this.rdfConverter.writeItemDocument(document);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""ItemDocumentUnknownPropertyTypes.rdf"")));
	}
"
"    @Test
	public void testWritePropertyDocument() throws RDFHandlerException,
			RDFParseException, IOException {
		PropertyDocument document = this.objectFactory
				.createEmptyPropertyDocument();
		this.rdfConverter.writePropertyDocument(document);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""EmptyPropertyDocument.rdf"")));
	}
"
"	@Test
	public void testWriteStatementRankTriple() throws RDFHandlerException,
			RDFParseException, IOException {
		StatementRank rank = StatementRank.DEPRECATED;
		Resource subject = this.rdfFactory
				.createIRI(""http://www.wikidata.org/Q10Snone"");
		this.rdfConverter.writeStatementRankTriple(subject, rank);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""StatementRankTriple.rdf"")), model);
	}
"
"	@Test
	public void testStatementSimpleValue() throws RDFHandlerException,
			RDFParseException, IOException {
		Statement statement = objectFactory.createStatement(""Q100"", ""P227"");
		this.rdfConverter.writeStatement(statement);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""Statement.rdf"")));
	}
"
"	@Test
	public void testStatementComplexValue() throws RDFHandlerException,
			RDFParseException, IOException {
		GlobeCoordinatesValue value = Datamodel.makeGlobeCoordinatesValue(51,
				13, GlobeCoordinatesValue.PREC_DEGREE,
				GlobeCoordinatesValue.GLOBE_EARTH);
		Statement statement = StatementBuilder
				.forSubjectAndProperty(ItemIdValue.NULL, PropertyIdValue.NULL)
				.withValue(value).build();
		this.rdfConverter.writeStatement(statement);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""StatementCplx.rdf"")));
	}
"
"	@Test
	public void testStatementNoValue() throws RDFHandlerException,
			RDFParseException, IOException {
		PropertyIdValue pid = dataObjectFactory.getPropertyIdValue(""P31"", ""http://www.wikidata.org/"");
		Statement statement = StatementBuilder
				.forSubjectAndProperty(ItemIdValue.NULL, pid)
				.withNoValue().build();
		this.rdfConverter.writeStatement(statement);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""StatementNoValue.rdf"")));
	}
"
"	@Test
	public void testWriteBasicDeclarations() throws RDFHandlerException,
			RDFParseException, IOException {
		this.rdfConverter.writeBasicDeclarations();
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""BasicDeclarations.rdf"")), model);
	}
"
"	@Test
	public void testWriteNamespaceDeclarations() throws RDFHandlerException,
			RDFParseException, IOException {
		this.rdfConverter.writeNamespaceDeclarations();
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""Namespaces.rdf"")), model);
	}
"
"	@Test
	public void testWriteSiteLinks() throws RDFHandlerException, IOException,
			RDFParseException {
		this.sites.setSiteInformation(""enwiki"", ""wikipedia"", ""en"", ""mediawiki"",
				""http://en.wikipedia.org/w/$1"",
				""http://en.wikipedia.org/wiki/$1"");
		this.sites.setSiteInformation(""dewiki"", ""wikipedia"", ""de"", ""mediawiki"",
				""http://de.wikipedia.org/w/$1"",
				""http://de.wikipedia.org/wiki/$1"");
		Map<String, SiteLink> siteLinks = objectFactory.createSiteLinks();
		this.rdfConverter.writeSiteLinks(this.resource, siteLinks);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""SiteLinks.rdf"")));

	}
"
"	@Test
	public void testWriteSimpleStatements() throws RDFHandlerException,
			RDFParseException, IOException {
		ItemDocument document = createTestItemDocument();
		this.rdfConverter.writeSimpleStatements(resource, document);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(
				RdfTestHelpers
						.parseRdf(""\n<http://test.org/> <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/Q10> ;\n""
								+ ""<http://www.wikidata.org/prop/direct/P279> <http://www.wikidata.org/Q11> .\n""),
				model);
	}
"
"	@Test
	public void testWriteInterPropertyLinks() throws RDFHandlerException,
			RDFParseException, IOException {
		PropertyDocument document = this.dataObjectFactory.getPropertyDocument(
				this.dataObjectFactory.getPropertyIdValue(""P17"",
						""http://www.wikidata.org/""), Collections
						.<MonolingualTextValue> emptyList(), Collections
						.<MonolingualTextValue> emptyList(), Collections
						.<MonolingualTextValue> emptyList(), Collections
						.<StatementGroup> emptyList(), this.dataObjectFactory
						.getDatatypeIdValue(DatatypeIdValue.DT_ITEM), 0);
		this.rdfConverter.writeInterPropertyLinks(document);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(out.toString());

		assertEquals(RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""InterPropertyLinks.rdf"")), model);
	}
"
"	@Test
	public void missingDumpFile() throws IOException {
		MwLocalDumpFile df = new MwLocalDumpFile(
				""/non-existing-dump-file.json.gz"");
		assertFalse(df.isAvailable());
	}
"
"	@Test
	public void missingDumpFileDirectory() throws IOException {
		MwLocalDumpFile df = new MwLocalDumpFile(
				""/nonexisting-directory/non-existing-file.json.gz"");
		assertFalse(df.isAvailable());
	}
"
"	@Test
	public void testExplicitGetters() throws IOException {
		this.dm.setFileContents(this.dmPath
				.resolve(""testdump-20150512.json.gz""), """");
		MwLocalDumpFile df = new MwLocalDumpFile(
				""/testdump-20150512.json.gz"",
				DumpContentType.SITES, ""20150815"",
				""wikidatawiki"");

		assertEquals(""20150815"", df.getDateStamp());
		assertEquals(""wikidatawiki"", df.getProjectName());
		assertEquals(DumpContentType.SITES, df.getDumpContentType());
		String toString = df.toString();

		assertEquals(this.dmPath.resolve(""testdump-20150512.json.gz""),
				df.getPath());

		assertTrue(toString.contains(""20150815""));
		assertTrue(toString.contains(""wikidatawiki""));
		assertTrue(toString.toLowerCase().contains(
				DumpContentType.SITES.toString().toLowerCase()));
	}
"
"    @Test
    public void assertGetFilePathInHomeFolder() {
        assertThat(HomeFolderUtils.getFilePathInHomeFolder(""test_file""), is(HOME_FOLDER + ""test_file""));
    }
"
"    @Test
    public void assertJobInit() {
        while (!StreamingDataflowElasticJob.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
"
"    @Test
    public void assertJobInit() {
        while (!OneOffDataflowElasticJob.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
"
"    @Test
    public void assertJobInit() {
        while (!StreamingDataflowElasticJobForExecuteThrowsException.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
"
"    @Test
    public void assertJobInit() {
        while (!StreamingDataflowElasticJob.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
"
"    @Test
    public void assertJobInit() {
        while (!StreamingDataflowElasticJob.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
"
"    @Test
    public void assertJobInit() {
        while (!StreamingDataflowElasticJobForExecuteFailure.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
"
"    @Test
    public void assertJobInit() throws IOException {
        ScriptElasticJobUtil.buildScriptCommandLine();
        WaitingUtils.waitingShortTime();
        String scriptCommandLine = ((ScriptJobConfiguration) getLiteJobConfig().getTypeConfig()).getScriptCommandLine();
        LiteJobConfiguration liteJobConfig = LiteJobConfigurationGsonFactory.fromJson(getRegCenter().get(""/"" + getJobName() + ""/config""));
        assertThat(((ScriptJobConfiguration) liteJobConfig.getTypeConfig()).getScriptCommandLine(), is(scriptCommandLine));
    }
"
"    @Test
    public void assertJobInit() {
        initJob();
        assertRegCenterCommonInfoWithDisabled();
    }
"
"    @Test
    public void assertJobInit() {
        while (!FooSimpleElasticJob.isCompleted()) {
            WaitingUtils.waitingShortTime();
        }
        assertTrue(getRegCenter().isExisted(""/"" + getJobName() + ""/sharding""));
    }
"
"    @Test
    public void assertGetMessage() {
        assertThat(new JobConfigurationException(""message is: '%s'"", ""test"").getMessage(), is(""message is: 'test'""));
    }
"
"    @Test
    public void assertGetCause() {
        assertThat(new JobConfigurationException(new RuntimeException()).getCause(), instanceOf(RuntimeException.class));
    }
"
"    @Test
    public void assertGetCause() {
        assertThat(new JobStatisticException(new RuntimeException()).getCause(), instanceOf(RuntimeException.class));
    }
"
"    @Test
    public void assertGetMessage() {
        assertThat(new JobExecutionEnvironmentException(""message is: '%s'"", ""test"").getMessage(), is(""message is: 'test'""));
    }
"
"    @Test
    public void assertTransformWithError() {
        assertTrue(ExceptionUtil.transform(new Error(""Error"")).startsWith(""java.lang.Error""));
    }
"
"    @Test
    public void assertTransformWithException() {
        assertTrue(ExceptionUtil.transform(new Exception(""Exception"")).startsWith(""java.lang.Exception""));
    }
"
"    @Test
    public void assertTransformWithNull() {
        assertThat(ExceptionUtil.transform(null), is(""""));
    }
"
"    @Test
    public void assertGetMessage() {
        assertThat(new JobSystemException(""message is: '%s'"", ""test"").getMessage(), is(""message is: 'test'""));
    }
"
"    @Test
    public void assertGetCause() {
        assertThat(new JobSystemException(new RuntimeException()).getCause(), instanceOf(RuntimeException.class));
    }
"
"    @Test
    public void assertGetDefaultStrategy() {
        assertThat(JobShardingStrategyFactory.getStrategy(null), instanceOf(AverageAllocationJobShardingStrategy.class));
    }
"
"    @Test(expected = JobConfigurationException.class)
    public void assertGetStrategyFailureWhenClassNotFound() {
        JobShardingStrategyFactory.getStrategy(""NotClass"");
    }
"
"    @Test(expected = JobConfigurationException.class)
    public void assertGetStrategyFailureWhenNotStrategyClass() {
        JobShardingStrategyFactory.getStrategy(Object.class.getName());
    }
"
"    @Test(expected = JobConfigurationException.class)
    public void assertGetStrategyFailureWhenStrategyClassInvalid() {
        JobShardingStrategyFactory.getStrategy(InvalidJobShardingStrategy.class.getName());
    }
"
"    @Test
    public void assertGetStrategySuccess() {
        assertThat(JobShardingStrategyFactory.getStrategy(AverageAllocationJobShardingStrategy.class.getName()), instanceOf(AverageAllocationJobShardingStrategy.class));
    }
"
"    @Test
    public void shardingForZeroServer() {
        assertThat(jobShardingStrategy.sharding(Collections.<JobInstance>emptyList(), ""test_job"", 3), is(Collections.<JobInstance, List<Integer>>emptyMap()));
    }
"
"    @Test
    public void shardingForOneServer() {
        Map<JobInstance, List<Integer>> expected = new LinkedHashMap<>(1, 1);
        expected.put(new JobInstance(""host0@-@0""), Arrays.asList(0, 1, 2));
        assertThat(jobShardingStrategy.sharding(Collections.singletonList(new JobInstance(""host0@-@0"")), ""test_job"", 3), is(expected));
    }
"
"    @Test
    public void shardingForServersMoreThanShardingCount() {
        Map<JobInstance, List<Integer>> expected = new LinkedHashMap<>(3, 1);
        expected.put(new JobInstance(""host0@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host1@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host2@-@0""), Collections.<Integer>emptyList());
        assertThat(jobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""test_job"", 2), is(expected));
    }
"
"    @Test
    public void shardingForServersLessThanShardingCountAliquot() {
        Map<JobInstance, List<Integer>> expected = new LinkedHashMap<>(3, 1);
        expected.put(new JobInstance(""host0@-@0""), Arrays.asList(0, 1, 2));
        expected.put(new JobInstance(""host1@-@0""), Arrays.asList(3, 4, 5));
        expected.put(new JobInstance(""host2@-@0""), Arrays.asList(6, 7, 8));
        assertThat(jobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""test_job"", 9), is(expected));
    }
"
"    @Test
    public void shardingForServersLessThanShardingCountAliquantFor8ShardingCountAnd3Servers() {
        Map<JobInstance, List<Integer>> expected = new LinkedHashMap<>(3, 1);
        expected.put(new JobInstance(""host0@-@0""), Arrays.asList(0, 1, 6));
        expected.put(new JobInstance(""host1@-@0""), Arrays.asList(2, 3, 7));
        expected.put(new JobInstance(""host2@-@0""), Arrays.asList(4, 5));
        assertThat(jobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""test_job"", 8), is(expected));
    }
"
"    @Test
    public void shardingForServersLessThanShardingCountAliquantFor10ShardingCountAnd3Servers() {
        Map<JobInstance, List<Integer>> expected = new LinkedHashMap<>(3, 1);
        expected.put(new JobInstance(""host0@-@0""), Arrays.asList(0, 1, 2, 9));
        expected.put(new JobInstance(""host1@-@0""), Arrays.asList(3, 4, 5));
        expected.put(new JobInstance(""host2@-@0""), Arrays.asList(6, 7, 8));
        assertThat(jobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""test_job"", 10), is(expected));
    }
"
"    @Test
    public void assertSharding1() {
        Map<JobInstance, List<Integer>> expected = new HashMap<>();
        expected.put(new JobInstance(""host1@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host2@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host0@-@0""), Collections.<Integer>emptyList());
        assertThat(rotateServerByNameJobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""1"", 2), is(expected));
    }
"
"    @Test
    public void assertSharding2() {
        Map<JobInstance, List<Integer>> expected = new HashMap<>();
        expected.put(new JobInstance(""host2@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host0@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host1@-@0""), Collections.<Integer>emptyList());
        assertThat(rotateServerByNameJobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""2"", 2), is(expected));
    }
"
"    @Test
    public void assertSharding3() {
        Map<JobInstance, List<Integer>> expected = new HashMap<>();
        expected.put(new JobInstance(""host0@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host1@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host2@-@0""), Collections.<Integer>emptyList());
        assertThat(rotateServerByNameJobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""3"", 2), is(expected));
    }
"
"    @Test
    public void assertShardingByAsc() {
        Map<JobInstance, List<Integer>> expected = new HashMap<>();
        expected.put(new JobInstance(""host0@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host1@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host2@-@0""), Collections.<Integer>emptyList());
        assertThat(odevitySortByNameJobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""1"", 2), is(expected));
    }
"
"    @Test
    public void assertShardingByDesc() {
        Map<JobInstance, List<Integer>> expected = new HashMap<>();
        expected.put(new JobInstance(""host2@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host1@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host0@-@0""), Collections.<Integer>emptyList());
        assertThat(odevitySortByNameJobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""0"", 2), is(expected));
    }
"
"    @Test
    public void assertGetJobInstanceId() {
        assertThat(new JobInstance(""127.0.0.1@-@0"").getJobInstanceId(), is(""127.0.0.1@-@0""));
    }
"
"    @Test
    public void assertGetIp() {
        assertThat(new JobInstance().getIp(), Is.is(IpUtils.getIp()));
    }
"
"    @Test
    public void assertBeforeJobExecutedWhenIsAllStarted() {
        when(guaranteeService.isAllStarted()).thenReturn(true);
        distributeOnceElasticJobListener.beforeJobExecuted(shardingContexts);
        verify(guaranteeService).registerStart(Sets.newHashSet(0, 1));
        verify(elasticJobListenerCaller).before();
        verify(guaranteeService).clearAllStartedInfo();
    }
"
"    @Test
    public void assertBeforeJobExecutedWhenIsNotAllStartedAndNotTimeout() {
        when(guaranteeService.isAllStarted()).thenReturn(false);
        when(timeService.getCurrentMillis()).thenReturn(0L);
        distributeOnceElasticJobListener.beforeJobExecuted(shardingContexts);
        verify(guaranteeService).registerStart(Sets.newHashSet(0, 1));
        verify(guaranteeService, times(0)).clearAllStartedInfo();
    }
"
"    @Test(expected = JobSystemException.class)
    public void assertBeforeJobExecutedWhenIsNotAllStartedAndTimeout() {
        when(guaranteeService.isAllStarted()).thenReturn(false);
        when(timeService.getCurrentMillis()).thenReturn(0L, 2L);
        distributeOnceElasticJobListener.beforeJobExecuted(shardingContexts);
        verify(guaranteeService).registerStart(Arrays.asList(0, 1));
        verify(guaranteeService, times(0)).clearAllStartedInfo();
    }
"
"    @Test
    public void assertAfterJobExecutedWhenIsAllCompleted() {
        when(guaranteeService.isAllCompleted()).thenReturn(true);
        distributeOnceElasticJobListener.afterJobExecuted(shardingContexts);
        verify(guaranteeService).registerComplete(Sets.newHashSet(0, 1));
        verify(elasticJobListenerCaller).after();
        verify(guaranteeService).clearAllCompletedInfo();
    }
"
"    @Test
    public void assertAfterJobExecutedWhenIsAllCompletedAndNotTimeout() {
        when(guaranteeService.isAllCompleted()).thenReturn(false);
        when(timeService.getCurrentMillis()).thenReturn(0L);
        distributeOnceElasticJobListener.afterJobExecuted(shardingContexts);
        verify(guaranteeService).registerComplete(Sets.newHashSet(0, 1));
        verify(guaranteeService, times(0)).clearAllCompletedInfo();
    }
"
"    @Test(expected = JobSystemException.class)
    public void assertAfterJobExecutedWhenIsAllCompletedAndTimeout() {
        when(guaranteeService.isAllCompleted()).thenReturn(false);
        when(timeService.getCurrentMillis()).thenReturn(0L, 2L);
        distributeOnceElasticJobListener.afterJobExecuted(shardingContexts);
        verify(guaranteeService).registerComplete(Arrays.asList(0, 1));
        verify(guaranteeService, times(0)).clearAllCompletedInfo();
    }
"
"    @Test
    public void assertInit() throws NoSuchFieldException, SchedulerException {
        when(schedulerFacade.updateJobConfiguration(liteJobConfig)).thenReturn(liteJobConfig);
        when(schedulerFacade.newJobTriggerListener()).thenReturn(new JobTriggerListener(null, null));
        jobScheduler.init();
        verify(schedulerFacade).registerStartUpInfo(true);
        Scheduler scheduler = ReflectionUtils.getFieldValue(JobRegistry.getInstance().getJobScheduleController(""test_job""), JobScheduleController.class.getDeclaredField(""scheduler""));
        assertThat(scheduler.getListenerManager().getTriggerListeners().get(0), instanceOf(JobTriggerListener.class));
        assertTrue(scheduler.isStarted());
    }
"
"    @Test
    public void assertNew() {
        ShardingContexts shardingContexts = ShardingContextsBuilder.getMultipleShardingContexts();
        ShardingContext actual = new ShardingContext(shardingContexts, 1);
        assertThat(actual.getJobName(), is(shardingContexts.getJobName()));
        assertThat(actual.getTaskId(), is(shardingContexts.getTaskId()));
        assertThat(actual.getShardingTotalCount(), is(shardingContexts.getShardingTotalCount()));
        assertThat(actual.getJobParameter(), is(shardingContexts.getJobParameter()));
        assertThat(actual.getShardingItem(), is(1));
        assertThat(actual.getShardingParameter(), is(shardingContexts.getShardingItemParameters().get(1)));
    }
"
"    @Test
    public void assertToString() {
        assertThat(new ShardingContext(ShardingContextsBuilder.getMultipleShardingContexts(), 1).toString(), 
                is(""ShardingContext(jobName=test_job, taskId=fake_task_id, shardingTotalCount=2, jobParameter=, shardingItem=1, shardingParameter=B)""));
    }
"
"    @Test
    public void assertAddTaskResultStatistics() {
        for (StatisticInterval each : StatisticInterval.values()) {
            assertTrue(repository.add(new TaskResultStatistics(100, 0, each, new Date())));
        }
    }
"
"    @Test
    public void assertAddTaskRunningStatistics() {
        assertTrue(repository.add(new TaskRunningStatistics(100, new Date())));
    }
"
"    @Test
    public void assertAddJobRunningStatistics() {
        assertTrue(repository.add(new TaskRunningStatistics(100, new Date())));
    }
"
"    @Test
    public void assertAddJobRegisterStatistics() {
        assertTrue(repository.add(new JobRegisterStatistics(100, new Date())));
    }
"
"    @Test
    public void assertFindTaskResultStatisticsWhenTableIsEmpty() {
        assertThat(repository.findTaskResultStatistics(new Date(), StatisticInterval.MINUTE).size(), is(0));
        assertThat(repository.findTaskResultStatistics(new Date(), StatisticInterval.HOUR).size(), is(0));
        assertThat(repository.findTaskResultStatistics(new Date(), StatisticInterval.DAY).size(), is(0));
    }
"
"    @Test
    public void assertFindTaskResultStatisticsWithDifferentFromDate() {
        Date now = new Date();
        Date yesterday = getYesterday();
        for (StatisticInterval each : StatisticInterval.values()) {
            assertTrue(repository.add(new TaskResultStatistics(100, 0, each, yesterday)));
            assertTrue(repository.add(new TaskResultStatistics(100, 0, each, now)));
            assertThat(repository.findTaskResultStatistics(yesterday, each).size(), is(2));
            assertThat(repository.findTaskResultStatistics(now, each).size(), is(1));
        }
    }
"
"    @Test
    public void assertGetSummedTaskResultStatisticsWhenTableIsEmpty() {
        for (StatisticInterval each : StatisticInterval.values()) {
            TaskResultStatistics po = repository.getSummedTaskResultStatistics(new Date(), each);
            assertThat(po.getSuccessCount(), is(0));
            assertThat(po.getFailedCount(), is(0));
        }
    }
"
"    @Test
    public void assertGetSummedTaskResultStatistics() {
        for (StatisticInterval each : StatisticInterval.values()) {
            Date date = new Date();
            repository.add(new TaskResultStatistics(100, 2, each, date));
            repository.add(new TaskResultStatistics(200, 5, each, date));
            TaskResultStatistics po = repository.getSummedTaskResultStatistics(date, each);
            assertThat(po.getSuccessCount(), is(300));
            assertThat(po.getFailedCount(), is(7));
        }
    }
"
"    @Test
    public void assertFindLatestTaskResultStatisticsWhenTableIsEmpty() {
        for (StatisticInterval each : StatisticInterval.values()) {
            assertFalse(repository.findLatestTaskResultStatistics(each).isPresent());
        }
    }
"
"    @Test
    public void assertFindLatestTaskResultStatistics() {
        for (StatisticInterval each : StatisticInterval.values()) {
            repository.add(new TaskResultStatistics(100, 2, each, new Date()));
            repository.add(new TaskResultStatistics(200, 5, each, new Date()));
            Optional<TaskResultStatistics> po = repository.findLatestTaskResultStatistics(each);
            assertThat(po.get().getSuccessCount(), is(200));
            assertThat(po.get().getFailedCount(), is(5));
        }
    }
"
"    @Test
    public void assertFindTaskRunningStatisticsWhenTableIsEmpty() {
        assertThat(repository.findTaskRunningStatistics(new Date()).size(), is(0));
    }
"
"    @Test
    public void assertFindTaskRunningStatisticsWithDifferentFromDate() {
        Date now = new Date();
        Date yesterday = getYesterday();
        assertTrue(repository.add(new TaskRunningStatistics(100, yesterday)));
        assertTrue(repository.add(new TaskRunningStatistics(100, now)));
        assertThat(repository.findTaskRunningStatistics(yesterday).size(), is(2));
        assertThat(repository.findTaskRunningStatistics(now).size(), is(1));
    }
"
"    @Test
    public void assertFindLatestTaskRunningStatisticsWhenTableIsEmpty() {
        assertFalse(repository.findLatestTaskRunningStatistics().isPresent());
    }
"
"    @Test
    public void assertFindLatestTaskRunningStatistics() {
        repository.add(new TaskRunningStatistics(100, new Date()));
        repository.add(new TaskRunningStatistics(200, new Date()));
        Optional<TaskRunningStatistics> po = repository.findLatestTaskRunningStatistics();
        assertThat(po.get().getRunningCount(), is(200));
    }
"
"    @Test
    public void assertFindJobRunningStatisticsWhenTableIsEmpty() {
        assertThat(repository.findJobRunningStatistics(new Date()).size(), is(0));
    }
"
"    @Test
    public void assertFindJobRunningStatisticsWithDifferentFromDate() {
        Date now = new Date();
        Date yesterday = getYesterday();
        assertTrue(repository.add(new JobRunningStatistics(100, yesterday)));
        assertTrue(repository.add(new JobRunningStatistics(100, now)));
        assertThat(repository.findJobRunningStatistics(yesterday).size(), is(2));
        assertThat(repository.findJobRunningStatistics(now).size(), is(1));
    }
"
"    @Test
    public void assertFindLatestJobRunningStatisticsWhenTableIsEmpty() {
        assertFalse(repository.findLatestJobRunningStatistics().isPresent());
    }
"
"    @Test
    public void assertFindLatestJobRunningStatistics() {
        repository.add(new JobRunningStatistics(100, new Date()));
        repository.add(new JobRunningStatistics(200, new Date()));
        Optional<JobRunningStatistics> po = repository.findLatestJobRunningStatistics();
        assertThat(po.get().getRunningCount(), is(200));
    }
"
"    @Test
    public void assertFindJobRegisterStatisticsWhenTableIsEmpty() {
        assertThat(repository.findJobRegisterStatistics(new Date()).size(), is(0));
    }
"
"    @Test
    public void assertFindJobRegisterStatisticsWithDifferentFromDate() {
        Date now = new Date();
        Date yesterday = getYesterday();
        assertTrue(repository.add(new JobRegisterStatistics(100, yesterday)));
        assertTrue(repository.add(new JobRegisterStatistics(100, now)));
        assertThat(repository.findJobRegisterStatistics(yesterday).size(), is(2));
        assertThat(repository.findJobRegisterStatistics(now).size(), is(1));
    }
"
"    @Test
    public void assertFindLatestJobRegisterStatisticsWhenTableIsEmpty() {
        assertFalse(repository.findLatestJobRegisterStatistics().isPresent());
    }
"
"    @Test
    public void assertFindLatestJobRegisterStatistics() {
        repository.add(new JobRegisterStatistics(100, new Date()));
        repository.add(new JobRegisterStatistics(200, new Date()));
        Optional<JobRegisterStatistics> po = repository.findLatestJobRegisterStatistics();
        assertThat(po.get().getRegisteredCount(), is(200));
    }
"
"    @Test
    public void assertBuildAllProperties() {
        JobCoreConfiguration actual = JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3)
                .shardingItemParameters(""0=a,1=b,2=c"").jobParameter(""param"").failover(true).misfire(false).description(""desc"")
                .jobProperties(""job_exception_handler"", IgnoreJobExceptionHandler.class.getName()).build();
        assertRequiredProperties(actual);
        assertThat(actual.getShardingItemParameters(), is(""0=a,1=b,2=c""));
        assertThat(actual.getJobParameter(), is(""param""));
        assertTrue(actual.isFailover());
        assertFalse(actual.isMisfire());
        assertThat(actual.getDescription(), is(""desc""));
        assertThat(actual.getJobProperties().get(JobProperties.JobPropertiesEnum.JOB_EXCEPTION_HANDLER), is(IgnoreJobExceptionHandler.class.getName()));
    }
"
"    @Test
    public void assertBuildRequiredProperties() {
        JobCoreConfiguration actual = JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).build();
        assertRequiredProperties(actual);
        assertDefaultValues(actual);
    }
"
"    @Test
    public void assertBuildWhenOptionalParametersIsNull() {
        //noinspection NullArgumentToVariableArgMethod
        JobCoreConfiguration actual = JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).shardingItemParameters(null).jobParameter(null).description(null).build();
        assertRequiredProperties(actual);
        assertDefaultValues(actual);
    }
"
"    @Test(expected = IllegalArgumentException.class)
    public void assertBuildWhenJobNameIsNull() {
        JobCoreConfiguration.newBuilder(null, ""0/1 * * * * ?"", 3).build();
    }
"
"    @Test(expected = IllegalArgumentException.class)
    public void assertBuildWhenCronIsNull() {
        JobCoreConfiguration.newBuilder(""test_job"", null, 3).build();
    }
"
"    @Test(expected = IllegalArgumentException.class)
    public void assertBuildWhenTotalSHardingCountIsNegative() {
        JobCoreConfiguration.newBuilder(null, ""0/1 * * * * ?"", -1).build();
    }
"
"    @Test
    public void assertBuildAllProperties() {
        LiteJobConfiguration actual = LiteJobConfiguration.newBuilder(
                new SimpleJobConfiguration(JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).build(), TestSimpleJob.class.getCanonicalName()))
                .monitorExecution(false).maxTimeDiffSeconds(1000).monitorPort(8888).jobShardingStrategyClass(""testClass"").disabled(true).overwrite(true).reconcileIntervalMinutes(60).build();
        assertFalse(actual.isMonitorExecution());
        assertThat(actual.getMaxTimeDiffSeconds(), is(1000));
        assertThat(actual.getMonitorPort(), is(8888));
        assertThat(actual.getJobShardingStrategyClass(), is(""testClass""));
        assertTrue(actual.isDisabled());
        assertTrue(actual.isOverwrite());
        assertThat(actual.getReconcileIntervalMinutes(), is(60));
    }
"
"    @Test
    public void assertBuildRequiredProperties() {
        LiteJobConfiguration actual = LiteJobConfiguration.newBuilder(
                new SimpleJobConfiguration(JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).build(), TestSimpleJob.class.getCanonicalName())).build();
        assertTrue(actual.isMonitorExecution());
        assertThat(actual.getMaxTimeDiffSeconds(), is(-1));
        assertThat(actual.getMonitorPort(), is(-1));
        assertThat(actual.getJobShardingStrategyClass(), is(""""));
        assertFalse(actual.isDisabled());
        assertFalse(actual.isOverwrite());
    }
"
"    @Test
    public void assertBuildWhenOptionalParametersIsNull() {
        assertThat(LiteJobConfiguration.newBuilder(new SimpleJobConfiguration(JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).build(), 
                TestSimpleJob.class.getCanonicalName())).jobShardingStrategyClass(null).build().getJobShardingStrategyClass(), is(""""));
    }
"
"    @Test
    public void assertIsNotFailover() {
        assertFalse(LiteJobConfiguration.newBuilder(new SimpleJobConfiguration(JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).failover(false).build(), 
                TestSimpleJob.class.getCanonicalName())).monitorExecution(false).build().isFailover());
    }
"
"    @Test
    public void assertIsFailover() {
        assertTrue(LiteJobConfiguration.newBuilder(new SimpleJobConfiguration(JobCoreConfiguration.newBuilder(""test_job"", ""0/1 * * * * ?"", 3).failover(true).build(), 
                TestSimpleJob.class.getCanonicalName())).monitorExecution(true).build().isFailover());
    }
"
"    @Test
    public void assertCreateExecutorService() {
        executorServiceObject = new ExecutorServiceObject(""executor-service-test"", 1);
        assertThat(executorServiceObject.getActiveThreadCount(), is(0));
        assertThat(executorServiceObject.getWorkQueueSize(), is(0));
        assertFalse(executorServiceObject.isShutdown());
        ExecutorService executorService = executorServiceObject.createExecutorService();
        executorService.submit(new FooTask());
        BlockUtils.waitingShortTime();
        assertThat(executorServiceObject.getActiveThreadCount(), is(1));
        assertThat(executorServiceObject.getWorkQueueSize(), is(0));
        assertFalse(executorServiceObject.isShutdown());
        executorService.submit(new FooTask());
        BlockUtils.waitingShortTime();
        assertThat(executorServiceObject.getActiveThreadCount(), is(1));
        assertThat(executorServiceObject.getWorkQueueSize(), is(1));
        assertFalse(executorServiceObject.isShutdown());
        executorService.shutdownNow();
        assertThat(executorServiceObject.getWorkQueueSize(), is(0));
        assertTrue(executorServiceObject.isShutdown());
    }
"
"    @Test(expected = JobConfigurationException.class)
    public void assertNewWhenPairFormatInvalid() {
        new ShardingItemParameters(""xxx-xxx"");
    }
"
"    @Test(expected = JobConfigurationException.class)
    public void assertNewWhenItemIsNotNumber() {
        new ShardingItemParameters(""xxx=xxx"");
    }
"
"    @Test
    public void assertGetMapWhenIsEmpty() {
        assertThat(new ShardingItemParameters("""").getMap(), is(Collections.EMPTY_MAP));
    }
"
"    @Test
    public void assertGetMap() {
        Map<Integer, String> expected = new HashMap<>(3);
        expected.put(0, ""A"");
        expected.put(1, ""B"");
        expected.put(2, ""C"");
        assertThat(new ShardingItemParameters(""0=A,1=B,2=C"").getMap(), is(expected));
    }
"
"    @Test
    public void assertTtoItemListWhenNull() {
        assertThat(ShardingItems.toItemList(null), is(Collections.EMPTY_LIST));
    }
"
"    @Test
    public void assertToItemListWhenEmpty() {
        assertThat(ShardingItems.toItemList(""""), is(Collections.EMPTY_LIST));
    }
"
"    @Test
    public void assertToItemList() {
        assertThat(ShardingItems.toItemList(""0,1,2""), is(Arrays.asList(0, 1, 2)));
    }
"
"    @Test
    public void assertToItemListForDuplicated() {
        assertThat(ShardingItems.toItemList(""0,1,2,2""), is(Arrays.asList(0, 1, 2)));
    }
"
"    @Test
    public void assertToItemsStringWhenEmpty() {
        assertThat(ShardingItems.toItemsString(Collections.<Integer>emptyList()), is(""""));
    }
"
"    @Test
    public void assertToItemsString() {
        assertThat(ShardingItems.toItemsString(Arrays.asList(0, 1, 2)), is(""0,1,2""));
    }
"
"    @Test
    public void assertGetIp() {
        assertNotNull(IpUtils.getIp());
    }
"
"    @Test
    public void assertGetHostName() {
        assertNotNull(IpUtils.getHostName());
    }
"
"    @Test
    public void assertGetCause() {
        IOException cause = new IOException();
        assertThat(new HostException(cause).getCause(), Is.<Throwable>is(cause));
    }
"
"    @Test
    public void assertGetCurrentMillis() throws Exception {
        assertTrue(timeService.getCurrentMillis() <= System.currentTimeMillis());
    }
"
"    @Test
    public void assertToSimpleJobJson() {
        assertThat(GsonFactory.getGson().toJson(new TestJobRootConfiguration(
                new TestSimpleJobConfiguration(ThrowJobExceptionHandler.class.getCanonicalName(), DefaultExecutorServiceHandler.class.getCanonicalName()).getTypeConfig())),
                is(APIJsonConstants.getSimpleJobJson(ThrowJobExceptionHandler.class.getCanonicalName())));
    }
"
"    @Test
    public void assertToDataflowJobJson() {
        assertThat(GsonFactory.getGson().toJson(new TestJobRootConfiguration(new TestDataflowJobConfiguration(true).getTypeConfig())),
                is(APIJsonConstants.getDataflowJobJson(IgnoreJobExceptionHandler.class.getCanonicalName())));
    }
"
"    @Test
    public void assertToScriptJobJson() {
        assertThat(GsonFactory.getGson().toJson(new TestJobRootConfiguration(new TestScriptJobConfiguration(""test.sh"", ThrowJobExceptionHandler.class).getTypeConfig())),
                is(APIJsonConstants.getScriptJobJson(ThrowJobExceptionHandler.class.getCanonicalName())));
    }
"
"    @Test
    public void assertFromSimpleJobJson() {
        TestJobRootConfiguration actual = GsonFactory.getGson().fromJson(
                APIJsonConstants.getSimpleJobJson(ThrowJobExceptionHandler.class.getCanonicalName()), TestJobRootConfiguration.class);
        TestJobRootConfiguration expected = new TestJobRootConfiguration(
                new TestSimpleJobConfiguration(ThrowJobExceptionHandler.class.getCanonicalName(), DefaultExecutorServiceHandler.class.getCanonicalName()).getTypeConfig());
        assertThat(GsonFactory.getGson().toJson(actual), is(GsonFactory.getGson().toJson(expected)));
    }
"
"    @Test
    public void assertFromDataflowJobJson() {
        TestJobRootConfiguration actual = GsonFactory.getGson().fromJson(
                APIJsonConstants.getDataflowJobJson(IgnoreJobExceptionHandler.class.getCanonicalName()), TestJobRootConfiguration.class);
        TestJobRootConfiguration expected = new TestJobRootConfiguration(new TestDataflowJobConfiguration(true).getTypeConfig());
        assertThat(GsonFactory.getGson().toJson(actual), is(GsonFactory.getGson().toJson(expected)));
    }
"
"    @Test
    public void assertFromScriptJobJson() {
        TestJobRootConfiguration actual = GsonFactory.getGson().fromJson(
                APIJsonConstants.getScriptJobJson(ThrowJobExceptionHandler.class.getCanonicalName()), TestJobRootConfiguration.class);
        TestJobRootConfiguration expected = new TestJobRootConfiguration(new TestScriptJobConfiguration(""test.sh"", ThrowJobExceptionHandler.class).getTypeConfig());
        assertThat(GsonFactory.getGson().toJson(actual), is(GsonFactory.getGson().toJson(expected)));
    }
"
"@TestConfiguration
  public ResourceProvider workflowResourcesProvider() {
    return new TestResourcesProvider(Paths.get(""dummy"").toString());
  }
"
"    @Test
    public void correctly_create_s3_event() throws JsonProcessingException {
        S3Event s3Event = new S3Event(""my_bucket"", ""my_key"");

        String output = objectMapper.writeValueAsString(s3Event.asJsonNode());

        assertThat(output, equalTo(""{\""Records\"":[{\""s3\"":"" +
                ""{\""bucket\"":{\""name\"":\""my_bucket\""},"" +
                ""\""object\"":{\""key\"":\""my_key\""}}}"" +
                ""]}""));
    }
"
"    @Test
    public void correctly_create_sns_event() throws JsonProcessingException {
        SNSEvent snsEvent = new SNSEvent(""{ \""key\"": \""value\"" }"");

        String output = objectMapper.writeValueAsString(snsEvent.asJsonNode());

        assertThat(output, equalTo(""{\""Records\"":[{\""Sns\"":"" +
                ""{\""Message\"":\""{ \\\""key\\\"": \\\""value\\\"" }\""}}"" +
                ""]}""));
    }
"
"    @Test
    public void should_identify_language_based_on_key() throws IllegalLanguageException {
        assertThat(Language.of(""java""), is(JAVA));
    }
"
"    @Test
    public void should_identify_language_based_on_alternative_name() throws IllegalLanguageException {
        assertThat(Language.of(""js""), is(JAVASCRIPT));
        assertThat(Language.of(""C#""), is(CSHARP));
    }
"
"    @Test
    public void should_ignore_spaces_and_capitalisation_when_matching() throws IllegalLanguageException {
        assertThat(Language.of(""  JaVa \n  ""), is(JAVA));
    }
"
"    @Test
    public void should_throw_exception_if_language_not_recognised() throws IllegalLanguageException {
        thrown.expect(IllegalLanguageException.class);
        Language.of(""none"");
    }
"
"    @Test
    public void testFallback() {
        HystrixCommand<Integer> superCmd = new SuperCommand(""cache"", false);
        assertEquals(2, superCmd.execute().intValue());

        HystrixCommand<Integer> subNoOverridesCmd = new SubCommandNoOverride(""cache"", false);
        assertEquals(2, subNoOverridesCmd.execute().intValue());

        HystrixCommand<Integer> subOverriddenFallbackCmd = new SubCommandOverrideFallback(""cache"", false);
        assertEquals(3, subOverriddenFallbackCmd.execute().intValue());
    }
"
"    @Test
    public void testRequestCacheSuperClass() {
        HystrixCommand<Integer> superCmd1 = new SuperCommand(""cache"", true);
        assertEquals(1, superCmd1.execute().intValue());
        HystrixCommand<Integer> superCmd2 = new SuperCommand(""cache"", true);
        assertEquals(1, superCmd2.execute().intValue());
        HystrixCommand<Integer> superCmd3 = new SuperCommand(""no-cache"", true);
        assertEquals(1, superCmd3.execute().intValue());
        System.out.println(""REQ LOG : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        HystrixRequestLog reqLog = HystrixRequestLog.getCurrentRequest();
        assertEquals(3, reqLog.getAllExecutedCommands().size());
        List<HystrixInvokableInfo<?>> infos = new ArrayList<HystrixInvokableInfo<?>>(reqLog.getAllExecutedCommands());
        HystrixInvokableInfo<?> info1 = infos.get(0);
        assertEquals(""SuperCommand"", info1.getCommandKey().name());
        assertEquals(1, info1.getExecutionEvents().size());
        HystrixInvokableInfo<?> info2 = infos.get(1);
        assertEquals(""SuperCommand"", info2.getCommandKey().name());
        assertEquals(2, info2.getExecutionEvents().size());
        assertEquals(HystrixEventType.RESPONSE_FROM_CACHE, info2.getExecutionEvents().get(1));
        HystrixInvokableInfo<?> info3 = infos.get(2);
        assertEquals(""SuperCommand"", info3.getCommandKey().name());
        assertEquals(1, info3.getExecutionEvents().size());
    }
"
"    @Test
    public void testRequestCacheSubclassNoOverrides() {
        HystrixCommand<Integer> subCmd1 = new SubCommandNoOverride(""cache"", true);
        assertEquals(1, subCmd1.execute().intValue());
        HystrixCommand<Integer> subCmd2 = new SubCommandNoOverride(""cache"", true);
        assertEquals(1, subCmd2.execute().intValue());
        HystrixCommand<Integer> subCmd3 = new SubCommandNoOverride(""no-cache"", true);
        assertEquals(1, subCmd3.execute().intValue());
        System.out.println(""REQ LOG : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        HystrixRequestLog reqLog = HystrixRequestLog.getCurrentRequest();
        assertEquals(3, reqLog.getAllExecutedCommands().size());
        List<HystrixInvokableInfo<?>> infos = new ArrayList<HystrixInvokableInfo<?>>(reqLog.getAllExecutedCommands());
        HystrixInvokableInfo<?> info1 = infos.get(0);
        assertEquals(""SubCommandNoOverride"", info1.getCommandKey().name());
        assertEquals(1, info1.getExecutionEvents().size());
        HystrixInvokableInfo<?> info2 = infos.get(1);
        assertEquals(""SubCommandNoOverride"", info2.getCommandKey().name());
        assertEquals(2, info2.getExecutionEvents().size());
        assertEquals(HystrixEventType.RESPONSE_FROM_CACHE, info2.getExecutionEvents().get(1));
        HystrixInvokableInfo<?> info3 = infos.get(2);
        assertEquals(""SubCommandNoOverride"", info3.getCommandKey().name());
        assertEquals(1, info3.getExecutionEvents().size());
    }
"
"    @Test
    public void testRequestLogSuperClass() {
        HystrixCommand<Integer> superCmd = new SuperCommand(""cache"", true);
        assertEquals(1, superCmd.execute().intValue());
        System.out.println(""REQ LOG : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        HystrixRequestLog reqLog = HystrixRequestLog.getCurrentRequest();
        assertEquals(1, reqLog.getAllExecutedCommands().size());
        HystrixInvokableInfo<?> info = reqLog.getAllExecutedCommands().iterator().next();
        assertEquals(""SuperCommand"", info.getCommandKey().name());
    }
"
"    @Test
    public void testRequestLogSubClassNoOverrides() {
        HystrixCommand<Integer> subCmd = new SubCommandNoOverride(""cache"", true);
        assertEquals(1, subCmd.execute().intValue());
        System.out.println(""REQ LOG : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        HystrixRequestLog reqLog = HystrixRequestLog.getCurrentRequest();
        assertEquals(1, reqLog.getAllExecutedCommands().size());
        HystrixInvokableInfo<?> info = reqLog.getAllExecutedCommands().iterator().next();
        assertEquals(""SubCommandNoOverride"", info.getCommandKey().name());
    }
"
"	@Test
	public void shouldYieldNoExecutedTasksOnStartup() throws Exception {
		//given
		final Collection<HystrixThreadPoolMetrics> instances = HystrixThreadPoolMetrics.getInstances();

		//then
		assertEquals(0, instances.size());

	}
"
"	@Test
	public void shouldReturnOneExecutedTask() throws Exception {
		//given
		final Collection<HystrixThreadPoolMetrics> instances = HystrixThreadPoolMetrics.getInstances();
		RollingThreadPoolEventCounterStream.getInstance(tpKey, 10, 100).startCachingStreamValuesIfUnstarted();

		//when
		new NoOpHystrixCommand().execute();

		//then
		Thread.sleep(100);
		assertEquals(1, instances.size());
		assertEquals(1, instances.iterator().next().getRollingCountThreadsExecuted());
	}
"
"    @Test
    public void testExecutionHookSemaphoreSuccess() {
        assertHooksOnSuccess(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, FallbackResult.SUCCESS);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreBadRequestException() {
        assertHooksOnFailure(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.BAD_REQUEST, FallbackResult.SUCCESS);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreExceptionNoFallback() {
        assertHooksOnFailure(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.FAILURE, FallbackResult.UNIMPLEMENTED);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreExceptionSuccessfulFallback() {
        assertHooksOnSuccess(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.FAILURE, FallbackResult.SUCCESS);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreExceptionUnsuccessfulFallback() {
        assertHooksOnFailure(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.FAILURE, FallbackResult.FAILURE);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreRejectedNoFallback() {
        assertHooksOnFailFast(
                new Func0<C>() {
                    @Override
                    public C call() {
                        AbstractCommand.TryableSemaphore semaphore = new AbstractCommand.TryableSemaphoreActual(HystrixProperty.Factory.asProperty(2));

                        final C cmd1 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 500, FallbackResult.UNIMPLEMENTED, semaphore);
                        final C cmd2 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 500, FallbackResult.UNIMPLEMENTED, semaphore);

                        //saturate the semaphore
                        new Thread() {
                            @Override
                            public void run() {
                                cmd1.observe();
                            }
"
"    @Test
    public void testExecutionHookSemaphoreRejectedSuccessfulFallback() {
        assertHooksOnSuccess(
                new Func0<C>() {
                    @Override
                    public C call() {
                        AbstractCommand.TryableSemaphore semaphore = new AbstractCommand.TryableSemaphoreActual(HystrixProperty.Factory.asProperty(2));

                        final C cmd1 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 1500, FallbackResult.SUCCESS, semaphore);
                        final C cmd2 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 1500, FallbackResult.SUCCESS, semaphore);

                        //saturate the semaphore
                        new Thread() {
                            @Override
                            public void run() {
                                cmd1.observe();
                            }
"
"    @Test
    public void testExecutionHookSemaphoreRejectedUnsuccessfulFallback() {
        assertHooksOnFailFast(
                new Func0<C>() {
                    @Override
                    public C call() {
                        AbstractCommand.TryableSemaphore semaphore = new AbstractCommand.TryableSemaphoreActual(HystrixProperty.Factory.asProperty(2));

                        final C cmd1 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 500, FallbackResult.FAILURE, semaphore);
                        final C cmd2 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 500, FallbackResult.FAILURE, semaphore);

                        //saturate the semaphore
                        new Thread() {
                            @Override
                            public void run() {
                                cmd1.observe();
                            }
"
"    @Test
    public void testExecutionHookSemaphoreShortCircuitNoFallback() {
        assertHooksOnFailFast(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCircuitOpenCommand(ExecutionIsolationStrategy.SEMAPHORE, FallbackResult.UNIMPLEMENTED);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreShortCircuitSuccessfulFallback() {
        assertHooksOnSuccess(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCircuitOpenCommand(ExecutionIsolationStrategy.SEMAPHORE, FallbackResult.SUCCESS);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreShortCircuitUnsuccessfulFallback() {
        assertHooksOnFailFast(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCircuitOpenCommand(ExecutionIsolationStrategy.SEMAPHORE, FallbackResult.FAILURE);
                    }
"
"    @Test
    public void testGetErrorPercentage() {
        String key = ""cmd-metrics-A"";
        try {
            HystrixCommand<Boolean> cmd1 = new SuccessCommand(key, 1);
            HystrixCommandMetrics metrics = cmd1.metrics;
            cmd1.execute();
            Thread.sleep(100);
            assertEquals(0, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd2 = new FailureCommand(key, 1);
            cmd2.execute();
            Thread.sleep(100);
            assertEquals(50, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd3 = new SuccessCommand(key, 1);
            HystrixCommand<Boolean> cmd4 = new SuccessCommand(key, 1);
            cmd3.execute();
            cmd4.execute();
            Thread.sleep(100);
            assertEquals(25, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd5 = new TimeoutCommand(key);
            HystrixCommand<Boolean> cmd6 = new TimeoutCommand(key);
            cmd5.execute();
            cmd6.execute();
            Thread.sleep(100);
            assertEquals(50, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd7 = new SuccessCommand(key, 1);
            HystrixCommand<Boolean> cmd8 = new SuccessCommand(key, 1);
            HystrixCommand<Boolean> cmd9 = new SuccessCommand(key, 1);
            cmd7.execute();
            cmd8.execute();
            cmd9.execute();

            // latent
            HystrixCommand<Boolean> cmd10 = new SuccessCommand(key, 60);
            cmd10.execute();

            // 6 success + 1 latent success + 1 failure + 2 timeout = 10 total
            // latent success not considered error
            // error percentage = 1 failure + 2 timeout / 10
            Thread.sleep(100);
            assertEquals(30, metrics.getHealthCounts().getErrorPercentage());

        } catch (Exception e) {
            e.printStackTrace();
            fail(""Error occurred: "" + e.getMessage());
        }

    }
"
"    @Test
    public void testBadRequestsDoNotAffectErrorPercentage() {
        String key = ""cmd-metrics-B"";
        try {

            HystrixCommand<Boolean> cmd1 = new SuccessCommand(key ,1);
            HystrixCommandMetrics metrics = cmd1.metrics;
            cmd1.execute();
            Thread.sleep(100);
            assertEquals(0, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd2 = new FailureCommand(key, 1);
            cmd2.execute();
            Thread.sleep(100);
            assertEquals(50, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd3 = new BadRequestCommand(key, 1);
            HystrixCommand<Boolean> cmd4 = new BadRequestCommand(key, 1);
            try {
                cmd3.execute();
            } catch (HystrixBadRequestException ex) {
                System.out.println(""Caught expected HystrixBadRequestException from cmd3"");
            }
            try {
                cmd4.execute();
            } catch (HystrixBadRequestException ex) {
                System.out.println(""Caught expected HystrixBadRequestException from cmd4"");
            }
            Thread.sleep(100);
            assertEquals(50, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd5 = new FailureCommand(key, 1);
            HystrixCommand<Boolean> cmd6 = new FailureCommand(key, 1);
            cmd5.execute();
            cmd6.execute();
            Thread.sleep(100);
            assertEquals(75, metrics.getHealthCounts().getErrorPercentage());
        } catch (Exception e) {
            e.printStackTrace();
            fail(""Error occurred : "" + e.getMessage());
        }
    }
"
"    @Test
    public void testCurrentConcurrentExecutionCount() throws InterruptedException {
        String key = ""cmd-metrics-C"";

        HystrixCommandMetrics metrics = null;
        List<Observable<Boolean>> cmdResults = new ArrayList<Observable<Boolean>>();

        int NUM_CMDS = 8;
        for (int i = 0; i < NUM_CMDS; i++) {
            HystrixCommand<Boolean> cmd = new SuccessCommand(key, 900);
            if (metrics == null) {
                metrics = cmd.metrics;
            }
            Observable<Boolean> eagerObservable = cmd.observe();
            cmdResults.add(eagerObservable);
        }

        try {
            Thread.sleep(150);
        } catch (InterruptedException ie) {
            fail(ie.getMessage());
        }
        System.out.println(""ReqLog: "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertEquals(NUM_CMDS, metrics.getCurrentConcurrentExecutionCount());

        final CountDownLatch latch = new CountDownLatch(1);
        Observable.merge(cmdResults).subscribe(new Subscriber<Boolean>() {
            @Override
            public void onCompleted() {
                System.out.println(""All commands done"");
                latch.countDown();
            }
"
"    @Test
    public void testCommandRequiresContextConcurrencyStrategyProvidesItContextSetUpCorrectly() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(true);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is set up properly
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute());
        printRequestLog();
        assertNotNull(HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertNotNull(cmd.currentRequestLog);
        context.shutdown();
    }
"
"    @Test
    public void testCommandRequiresContextConcurrencyStrategyProvidesItContextLeftUninitialized() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(true);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is not set up
        HystrixRequestContext.setContextOnCurrentThread(null);
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute()); //command execution not affected by missing context
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
    }
"
"    @Test
    public void testCommandRequiresContextConcurrencyStrategyDoesNotProvideItContextSetUpCorrectly() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(false);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is set up properly
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute());
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
        context.shutdown();
    }
"
"    @Test
    public void testCommandRequiresContextConcurrencyStrategyDoesNotProvideItContextLeftUninitialized() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(false);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is not set up
        HystrixRequestContext.setContextOnCurrentThread(null);
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute()); //command execution not affected by missing context
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
    }
"
"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyProvidesItContextSetUpCorrectly() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(true);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is set up properly
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        HystrixCommand<Boolean> cmd = new TestCommand(false, false);
        assertTrue(cmd.execute());
        printRequestLog();
        assertNotNull(HystrixRequestLog.getCurrentRequest());
        assertNotNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
        context.shutdown();
    }
"
"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyProvidesItContextLeftUninitialized() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(true);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is not set up
        HystrixRequestContext.setContextOnCurrentThread(null);
        HystrixCommand<Boolean> cmd = new TestCommand(false, false);
        assertTrue(cmd.execute()); //command execution not affected by missing context
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
    }
"
"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyDoesNotProvideItContextSetUpCorrectly() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(false);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is set up properly
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute());
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
        context.shutdown();
    }
"
"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyDoesNotProvideItContextLeftUninitialized() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(false);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is not set up
        HystrixRequestContext.setContextOnCurrentThread(null);
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute()); //command execution unaffected by missing context
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
    }
"
"    @Test
    public void testNested1() {
        HystrixProperty<String> a = Factory.asProperty(""a"");
        assertEquals(""a"", a.get());

        HystrixProperty<String> aWithDefault = Factory.asProperty(a, ""b"");
        assertEquals(""a"", aWithDefault.get());
    }
"
"    @Test
    public void testNested2() {
        HystrixProperty<String> nullValue = Factory.nullProperty();

        HystrixProperty<String> withDefault = Factory.asProperty(nullValue, ""b"");
        assertEquals(""b"", withDefault.get());
    }
"
"    @Test
    public void testNested3() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, ""a"");

        HystrixProperty<String> withDefault = Factory.asProperty(a, ""b"");
        assertEquals(""a"", withDefault.get());
    }
"
"    @Test
    public void testNested4() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, null);

        HystrixProperty<String> withDefault = Factory.asProperty(a, ""b"");
        assertEquals(""b"", withDefault.get());
    }
"
"    @Test
    public void testNested5() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, null);

        @SuppressWarnings(""unchecked"")
        HystrixProperty<String> withDefault = Factory.asProperty(a, Factory.asProperty(""b""));
        assertEquals(""b"", withDefault.get());
    }
"
"    @Test
    public void testSeries1() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, null);

        @SuppressWarnings(""unchecked"")
        HystrixProperty<String> withDefault = Factory.asProperty(a, nullValue, nullValue, Factory.asProperty(""b""));
        assertEquals(""b"", withDefault.get());
    }
"
"    @Test
    public void testSeries2() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, null);

        @SuppressWarnings(""unchecked"")
        HystrixProperty<String> withDefault = Factory.asProperty(a, nullValue, Factory.asProperty(""b""), nullValue, Factory.asProperty(""c""));
        assertEquals(""b"", withDefault.get());
    }
"
"    @Test
    public void testString() throws Exception {

        DynamicStringProperty pString = new DynamicStringProperty(""defaultString"", ""default-default"");
        HystrixPropertiesChainedArchaiusProperty.StringProperty fString = new HystrixPropertiesChainedArchaiusProperty.StringProperty(""overrideString"", pString);

        assertTrue(""default-default"".equals(fString.get()));

        ConfigurationManager.getConfigInstance().setProperty(""defaultString"", ""default"");
        assertTrue(""default"".equals(fString.get()));

        ConfigurationManager.getConfigInstance().setProperty(""overrideString"", ""override"");
        assertTrue(""override"".equals(fString.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""overrideString"");
        assertTrue(""default"".equals(fString.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""defaultString"");
        assertTrue(""default-default"".equals(fString.get()));
    }
"
"    @Test
    public void testInteger() throws Exception {

        DynamicIntegerProperty pInt = new DynamicIntegerProperty(""defaultInt"", -1);
        HystrixPropertiesChainedArchaiusProperty.IntegerProperty fInt = new HystrixPropertiesChainedArchaiusProperty.IntegerProperty(""overrideInt"", pInt);

        assertTrue(-1 == fInt.get());

        ConfigurationManager.getConfigInstance().setProperty(""defaultInt"", 10);
        assertTrue(10 == fInt.get());

        ConfigurationManager.getConfigInstance().setProperty(""overrideInt"", 11);
        assertTrue(11 == fInt.get());

        ConfigurationManager.getConfigInstance().clearProperty(""overrideInt"");
        assertTrue(10 == fInt.get());

        ConfigurationManager.getConfigInstance().clearProperty(""defaultInt"");
        assertTrue(-1 == fInt.get());
    }
"
"    @Test
    public void testBoolean() throws Exception {

        DynamicBooleanProperty pBoolean = new DynamicBooleanProperty(""defaultBoolean"", true);
        HystrixPropertiesChainedArchaiusProperty.BooleanProperty fBoolean = new HystrixPropertiesChainedArchaiusProperty.BooleanProperty(""overrideBoolean"", pBoolean);

        System.out.println(""pBoolean: "" + pBoolean.get());
        System.out.println(""fBoolean: "" + fBoolean.get());

        assertTrue(fBoolean.get());

        ConfigurationManager.getConfigInstance().setProperty(""defaultBoolean"", Boolean.FALSE);

        System.out.println(""pBoolean: "" + pBoolean.get());
        System.out.println(""fBoolean: "" + fBoolean.get());

        assertFalse(fBoolean.get());

        ConfigurationManager.getConfigInstance().setProperty(""overrideBoolean"", Boolean.TRUE);
        assertTrue(fBoolean.get());

        ConfigurationManager.getConfigInstance().clearProperty(""overrideBoolean"");
        assertFalse(fBoolean.get());

        ConfigurationManager.getConfigInstance().clearProperty(""defaultBoolean"");
        assertTrue(fBoolean.get());
    }
"
"    @Test
    public void testChainingString() throws Exception {

        DynamicStringProperty node1 = new DynamicStringProperty(""node1"", ""v1"");
        StringProperty node2 = new HystrixPropertiesChainedArchaiusProperty.StringProperty(""node2"", node1);

        HystrixPropertiesChainedArchaiusProperty.StringProperty node3 = new HystrixPropertiesChainedArchaiusProperty.StringProperty(""node3"", node2);

        assertTrue("""" + node3.get(), ""v1"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node1"", ""v11"");
        assertTrue(""v11"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node2"", ""v22"");
        assertTrue(""v22"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""node1"");
        assertTrue(""v22"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node3"", ""v33"");
        assertTrue(""v33"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""node2"");
        assertTrue(""v33"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node2"", ""v222"");
        assertTrue(""v33"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""node3"");
        assertTrue(""v222"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""node2"");
        assertTrue(""v1"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node2"", ""v2222"");
        assertTrue(""v2222"".equals(node3.get()));
    }
"
"    @Test
    public void testChainingInteger() throws Exception {

        DynamicIntegerProperty node1 = new DynamicIntegerProperty(""node1"", 1);
        IntegerProperty node2 = new HystrixPropertiesChainedArchaiusProperty.IntegerProperty(""node2"", node1);

        HystrixPropertiesChainedArchaiusProperty.IntegerProperty node3 = new HystrixPropertiesChainedArchaiusProperty.IntegerProperty(""node3"", node2);

        assertTrue("""" + node3.get(), 1 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node1"", 11);
        assertTrue(11 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node2"", 22);
        assertTrue(22 == node3.get());

        ConfigurationManager.getConfigInstance().clearProperty(""node1"");
        assertTrue(22 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node3"", 33);
        assertTrue(33 == node3.get());

        ConfigurationManager.getConfigInstance().clearProperty(""node2"");
        assertTrue(33 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node2"", 222);
        assertTrue(33 == node3.get());

        ConfigurationManager.getConfigInstance().clearProperty(""node3"");
        assertTrue(222 == node3.get());

        ConfigurationManager.getConfigInstance().clearProperty(""node2"");
        assertTrue(1 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node2"", 2222);
        assertTrue(2222 == node3.get());
    }
"
"    @Test
    public void testAddCallback() throws Exception {

        final DynamicStringProperty node1 = new DynamicStringProperty(""n1"", ""n1"");
        final HystrixPropertiesChainedArchaiusProperty.StringProperty node2 = new HystrixPropertiesChainedArchaiusProperty.StringProperty(""n2"", node1);

        final AtomicInteger callbackCount = new AtomicInteger(0);

        node2.addCallback(new Runnable() {
            @Override
            public void run() {
                callbackCount.incrementAndGet();
            }
"
"    @Test
    public void testRequestContextPropagatesAcrossObserveOnPool() {
        new SimpleCommand().execute();
        new SimpleCommand().observe().map(new Func1<String, String>() {

            @Override
            public String call(String s) {
                System.out.println(""Map => Commands: "" + HystrixRequestLog.getCurrentRequest().getAllExecutedCommands());
                return s;
            }
"
"    @Test
    public void testThreadContextOnTimeout() {
        final AtomicBoolean isInitialized = new AtomicBoolean();
        new TimeoutCommand().toObservable()
                .doOnError(new Action1<Throwable>() {
                    @Override
                    public void call(Throwable throwable) {
                        isInitialized.set(HystrixRequestContext.isCurrentThreadInitialized());
                    }
"
"    @Test
    public void testNoRequestContextOnSimpleConcurencyStrategyWithoutException() throws Exception {
        shutdownContextIfExists();
        ConfigurationManager.getConfigInstance().setProperty(""hystrix.command.default.requestLog.enabled"", ""false"");

        new SimpleCommand().execute();

        assertTrue(""We are able to run the simple command without a context initialization error."", true);
    }
"
"    @Test(timeout = 2500)
    public void testUnsubscribeWrappedScheduler() throws InterruptedException {
        Scheduler s = Schedulers.newThread();
        final AtomicBoolean interrupted = new AtomicBoolean();
        final CountDownLatch start = new CountDownLatch(1);
        final CountDownLatch end = new CountDownLatch(1);

        HystrixContextScheduler hcs = new HystrixContextScheduler(s);

        Scheduler.Worker w = hcs.createWorker();
        try {
            w.schedule(new Action0() {
                @Override
                public void call() {
                    start.countDown();
                    try {
                        try {
                            Thread.sleep(5000);
                        } catch (InterruptedException ex) {
                            interrupted.set(true);
                        }
                    } finally {
                        end.countDown();
                    }
                }
"
"    @Test
    public void testSingleInitializePerKey() {
        final TestHystrixMetricsPublisher publisher = new TestHystrixMetricsPublisher();
        HystrixPlugins.getInstance().registerMetricsPublisher(publisher);
        final HystrixMetricsPublisherFactory factory = new HystrixMetricsPublisherFactory();
        ArrayList<Thread> threads = new ArrayList<Thread>();
        for (int i = 0; i < 20; i++) {
            threads.add(new Thread(new Runnable() {

                @Override
                public void run() {
                    factory.getPublisherForCommand(TestCommandKey.TEST_A, null, null, null, null);
                    factory.getPublisherForCommand(TestCommandKey.TEST_B, null, null, null, null);
                    factory.getPublisherForThreadPool(TestThreadPoolKey.TEST_A, null, null);
                }
"
"    @Test
    public void testMetricsPublisherReset() {
        // precondition: HystrixMetricsPublisherFactory class is not loaded. Calling HystrixPlugins.reset() here should be good enough to run this with other tests.

        // set first custom publisher
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""key"");
        HystrixMetricsPublisherCommand firstCommand = new HystrixMetricsPublisherCommandDefault(key, null, null, null, null);
        HystrixMetricsPublisher firstPublisher = new CustomPublisher(firstCommand);
        HystrixPlugins.getInstance().registerMetricsPublisher(firstPublisher);

        // ensure that first custom publisher is used
        HystrixMetricsPublisherCommand cmd = HystrixMetricsPublisherFactory.createOrRetrievePublisherForCommand(key, null, null, null, null);
        assertSame(firstCommand, cmd);

        // reset, then change to second custom publisher
        HystrixPlugins.reset();
        HystrixMetricsPublisherCommand secondCommand = new HystrixMetricsPublisherCommandDefault(key, null, null, null, null);
        HystrixMetricsPublisher secondPublisher = new CustomPublisher(secondCommand);
        HystrixPlugins.getInstance().registerMetricsPublisher(secondPublisher);

        // ensure that second custom publisher is used
        cmd = HystrixMetricsPublisherFactory.createOrRetrievePublisherForCommand(key, null, null, null, null);
        assertNotSame(firstCommand, cmd);
        assertSame(secondCommand, cmd);
    }
"
"    @Test
    public void testDynamicProperties() throws Exception {
        fakeServiceLoaderResource = 
                ""FAKE_META_INF_SERVICES/com.netflix.hystrix.strategy.properties.HystrixDynamicProperties"";
        HystrixPlugins plugins = setupMockServiceLoader();
        HystrixDynamicProperties properties = plugins.getDynamicProperties();
        plugins.getCommandExecutionHook();
        plugins.getPropertiesStrategy();
        assertTrue(properties instanceof MockHystrixDynamicPropertiesTest);

        assertEvents(
                ""[serviceloader: META-INF/services/com.netflix.hystrix.strategy.properties.HystrixDynamicProperties""
                        + "", debug: [Created HystrixDynamicProperties instance by loading from ServiceLoader. Using class: {}, com.netflix.hystrix.strategy.HystrixPluginsTest.MockHystrixDynamicPropertiesTest]""
                        + "", property: hystrix.plugin.HystrixCommandExecutionHook.implementation""
                        + "", serviceloader: META-INF/services/com.netflix.hystrix.strategy.executionhook.HystrixCommandExecutionHook""
                        + "", property: hystrix.plugin.HystrixPropertiesStrategy.implementation""
                        + "", serviceloader: META-INF/services/com.netflix.hystrix.strategy.properties.HystrixPropertiesStrategy]"");
    }
"
"    @Test(expected=ServiceConfigurationError.class)
    public void testDynamicPropertiesFailure() throws Exception {
        /*
         * James Bond: Do you expect me to talk?
         * Auric Goldfinger: No, Mr. Bond, I expect you to die!
         */
        fakeServiceLoaderResource = 
                ""FAKE_META_INF_SERVICES/com.netflix.hystrix.strategy.properties.HystrixDynamicPropertiesFail"";
        HystrixPlugins plugins = setupMockServiceLoader();
        plugins.getDynamicProperties();

    }
"
"    @Test
    public void testDynamicSystemProperties() throws Exception {
        //On the off chance this is the first test lets not screw up all the other tests
        HystrixPlugins.getInstance();
        
        System.setProperty(""hystrix.plugin.HystrixDynamicProperties.implementation"", 
                ""com.netflix.hystrix.strategy.properties.HystrixDynamicPropertiesSystemProperties"");
        
        HystrixPlugins plugins = setupMockServiceLoader();
        assertTrue(plugins.getDynamicProperties() instanceof HystrixDynamicPropertiesSystemProperties);
        
        HystrixDynamicProperties p = plugins.getDynamicProperties();
        //Some minimum testing of system properties wrapper
        //this probably should be in its own test class.
        assertTrue(p.getBoolean(""USE_DEFAULT"", true).get());
        assertEquals(""string"", p.getString(""USE_DEFAULT"", ""string"").get());
        assertEquals(1L, p.getLong(""USE_DEFAULT"", 1L).get().longValue());
        assertEquals(1, p.getInteger(""USE_DEFAULT"", 1).get().intValue());
        assertNotNull(p.getString(""path.separator"", null).get());
        
        assertEvents(""[debug: [Created HystrixDynamicProperties instance from System property named \""hystrix.plugin.HystrixDynamicProperties.implementation\"". Using class: {}, com.netflix.hystrix.strategy.properties.HystrixDynamicPropertiesSystemProperties]]"");

        System.clearProperty(""hystrix.plugin.HystrixDynamicProperties.implementation"");

    }
"
"    /*    @Test
    public void testCommandExecutionHookDefaultImpl() {
        HystrixCommandExecutionHook impl = HystrixPlugins.getInstance().getCommandExecutionHook();
        assertTrue(impl instanceof HystrixCommandExecutionHookDefault);
    }
"
"    @Test
    public void testCommandExecutionHookViaRegisterMethod() {
        HystrixPlugins.getInstance().registerCommandExecutionHook(new HystrixCommandExecutionHookTestImpl());
        HystrixCommandExecutionHook impl = HystrixPlugins.getInstance().getCommandExecutionHook();
        assertTrue(impl instanceof HystrixCommandExecutionHookTestImpl);
	}*/
"
"    /*@Test
    public void testEventNotifierDefaultImpl() {
        HystrixEventNotifier impl = HystrixPlugins.getInstance().getEventNotifier();
        assertTrue(impl instanceof HystrixEventNotifierDefault);
    }
"
"    @Test
    public void testEventNotifierViaRegisterMethod() {
        HystrixPlugins.getInstance().registerEventNotifier(new HystrixEventNotifierTestImpl());
        HystrixEventNotifier impl = HystrixPlugins.getInstance().getEventNotifier();
        assertTrue(impl instanceof HystrixEventNotifierTestImpl);
    }
"
"    @Test
    public void testEventNotifierViaProperty() {
        try {
            String fullClass = HystrixEventNotifierTestImpl.class.getName();
            System.setProperty(""hystrix.plugin.HystrixEventNotifier.implementation"", fullClass);
            HystrixEventNotifier impl = HystrixPlugins.getInstance().getEventNotifier();
            assertTrue(impl instanceof HystrixEventNotifierTestImpl);
        } finally {
            System.clearProperty(""hystrix.plugin.HystrixEventNotifier.implementation"");
        }
	}*/
"
"    /*@Test
    public void testConcurrencyStrategyDefaultImpl() {
        HystrixConcurrencyStrategy impl = HystrixPlugins.getInstance().getConcurrencyStrategy();
        assertTrue(impl instanceof HystrixConcurrencyStrategyDefault);
    }
"
"    @Test
    public void testConcurrencyStrategyViaRegisterMethod() {
        HystrixPlugins.getInstance().registerConcurrencyStrategy(new HystrixConcurrencyStrategyTestImpl());
        HystrixConcurrencyStrategy impl = HystrixPlugins.getInstance().getConcurrencyStrategy();
        assertTrue(impl instanceof HystrixConcurrencyStrategyTestImpl);
    }
"
"    @Test
    public void testConcurrencyStrategyViaProperty() {
        try {
            String fullClass = HystrixConcurrencyStrategyTestImpl.class.getName();
            System.setProperty(""hystrix.plugin.HystrixConcurrencyStrategy.implementation"", fullClass);
            HystrixConcurrencyStrategy impl = HystrixPlugins.getInstance().getConcurrencyStrategy();
            assertTrue(impl instanceof HystrixConcurrencyStrategyTestImpl);
        } finally {
            System.clearProperty(""hystrix.plugin.HystrixConcurrencyStrategy.implementation"");
        }
	}*/
"
"    /*@Test
    public void testMetricsPublisherDefaultImpl() {
        HystrixMetricsPublisher impl = HystrixPlugins.getInstance().getMetricsPublisher();
        assertTrue(impl instanceof HystrixMetricsPublisherDefault);
    }
"
"    @Test
    public void testMetricsPublisherViaRegisterMethod() {
        HystrixPlugins.getInstance().registerMetricsPublisher(new HystrixMetricsPublisherTestImpl());
        HystrixMetricsPublisher impl = HystrixPlugins.getInstance().getMetricsPublisher();
        assertTrue(impl instanceof HystrixMetricsPublisherTestImpl);
    }
"
"    @Test
    public void testMetricsPublisherViaProperty() {
        try {
            String fullClass = HystrixMetricsPublisherTestImpl.class.getName();
            System.setProperty(""hystrix.plugin.HystrixMetricsPublisher.implementation"", fullClass);
            HystrixMetricsPublisher impl = HystrixPlugins.getInstance().getMetricsPublisher();
            assertTrue(impl instanceof HystrixMetricsPublisherTestImpl);
        } finally {
            System.clearProperty(""hystrix.plugin.HystrixMetricsPublisher.implementation"");
        }
	}*/
"
"    /*@Test
    public void testPropertiesStrategyDefaultImpl() {
        HystrixPropertiesStrategy impl = HystrixPlugins.getInstance().getPropertiesStrategy();
        assertTrue(impl instanceof HystrixPropertiesStrategyDefault);
    }
"
"    @Test
    public void testPropertiesStrategyViaRegisterMethod() {
        HystrixPlugins.getInstance().registerPropertiesStrategy(new HystrixPropertiesStrategyTestImpl());
        HystrixPropertiesStrategy impl = HystrixPlugins.getInstance().getPropertiesStrategy();
        assertTrue(impl instanceof HystrixPropertiesStrategyTestImpl);
    }
"
"    @Test
    public void testPropertiesStrategyViaProperty() {
        try {
            String fullClass = HystrixPropertiesStrategyTestImpl.class.getName();
            System.setProperty(""hystrix.plugin.HystrixPropertiesStrategy.implementation"", fullClass);
            HystrixPropertiesStrategy impl = HystrixPlugins.getInstance().getPropertiesStrategy();
            assertTrue(impl instanceof HystrixPropertiesStrategyTestImpl);
        } finally {
            System.clearProperty(""hystrix.plugin.HystrixPropertiesStrategy.implementation"");
        }
	}*/
"
"    /*@Test
    public void testRequestContextViaPluginInTimeout() {
        HystrixPlugins.getInstance().registerConcurrencyStrategy(new HystrixConcurrencyStrategy() {
            @Override
            public <T> Callable<T> wrapCallable(final Callable<T> callable) {
                return new RequestIdCallable<T>(callable);
            }
        });

        HystrixRequestContext context = HystrixRequestContext.initializeContext();

        testRequestIdThreadLocal.set(""foobar"");
        final AtomicReference<String> valueInTimeout = new AtomicReference<String>();

        new DummyCommand().toObservable()
                .doOnError(new Action1<Throwable>() {
                    @Override
                    public void call(Throwable throwable) {
                        System.out.println(""initialized = "" + HystrixRequestContext.isCurrentThreadInitialized());
                        System.out.println(""requestId (timeout) = "" + testRequestIdThreadLocal.get());
                        valueInTimeout.set(testRequestIdThreadLocal.get());
                    }
"
"    @Test
    public void testSetResponseSuccess() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(""theResponse"");

        // fetch value
        assertEquals(""theResponse"", v.get());
    }
"
"    @Test
    public void testSetNullResponseSuccess() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(null);

        // fetch value
        assertEquals(null, v.get());
    }
"
"    @Test
    public void testSetException() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setException(new RuntimeException(""anException""));

        // fetch value
        try {
            v.get();
            fail(""expected exception"");
        } catch (ExecutionException e) {
            assertEquals(""anException"", e.getCause().getMessage());
        }
    }
"
"    @Test
    public void testSetExceptionAfterResponse() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(""theResponse"");

        try {
            cr.setException(new RuntimeException(""anException""));
            fail(""expected IllegalState"");
        } catch (IllegalStateException e) {

        }

        assertEquals(""theResponse"", v.get());
    }
"
"    @Test
    public void testSetResponseAfterException() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setException(new RuntimeException(""anException""));

        try {
            cr.setResponse(""theResponse"");
            fail(""expected IllegalState"");
        } catch (IllegalStateException e) {

        }

        try {
            v.get();
            fail(""expected exception"");
        } catch (ExecutionException e) {
            assertEquals(""anException"", e.getCause().getMessage());
        }
    }
"
"    @Test
    public void testSetResponseDuplicate() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(""theResponse"");

        try {
            cr.setResponse(""theResponse2"");
            fail(""expected IllegalState"");
        } catch (IllegalStateException e) {

        }

        assertEquals(""theResponse"", v.get());
    }
"
"    @Test(expected = CancellationException.class)
    public void testSetResponseAfterUnsubscribe() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> f = o.toBlocking().toFuture();

        // cancel/unsubscribe
        f.cancel(true);

        try {
            cr.setResponse(""theResponse"");
        } catch (IllegalStateException e) {
            fail(""this should have done nothing as it was unsubscribed already"");
        }

        // expect CancellationException after cancelling
        f.get();
    }
"
"    @Test(expected = CancellationException.class)
    public void testSetExceptionAfterUnsubscribe() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> f = o.toBlocking().toFuture();

        // cancel/unsubscribe
        f.cancel(true);

        try {
            cr.setException(new RuntimeException(""anException""));
        } catch (IllegalStateException e) {
            fail(""this should have done nothing as it was unsubscribed already"");
        }

        // expect CancellationException after cancelling
        f.get();
    }
"
"    @Test
    public void testUnsubscribeAfterSetResponse() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(""theResponse"");

        // unsubscribe after the value is sent
        v.cancel(true);

        // still get value as it was set before canceling
        assertEquals(""theResponse"", v.get());
    }
"
"    @Test
    public void testShutdown() {
        // other unit tests will probably have run before this so get the count
        int count = Factory.threadPools.size();

        HystrixThreadPool pool = Factory.getInstance(HystrixThreadPoolKey.Factory.asKey(""threadPoolFactoryTest""),
                HystrixThreadPoolProperties.Setter.getUnitTestPropertiesBuilder());

        assertEquals(count + 1, Factory.threadPools.size());
        assertFalse(pool.getExecutor().isShutdown());

        Factory.shutdown();

        // ensure all pools were removed from the cache
        assertEquals(0, Factory.threadPools.size());
        assertTrue(pool.getExecutor().isShutdown());
    }
"
"    @Test
    public void testShutdownWithWait() {
        // other unit tests will probably have run before this so get the count
        int count = Factory.threadPools.size();

        HystrixThreadPool pool = Factory.getInstance(HystrixThreadPoolKey.Factory.asKey(""threadPoolFactoryTest""),
                HystrixThreadPoolProperties.Setter.getUnitTestPropertiesBuilder());

        assertEquals(count + 1, Factory.threadPools.size());
        assertFalse(pool.getExecutor().isShutdown());

        Factory.shutdown(1, TimeUnit.SECONDS);

        // ensure all pools were removed from the cache
        assertEquals(0, Factory.threadPools.size());
        assertTrue(pool.getExecutor().isShutdown());
    }
"
"    @Test
    public void ensureThreadPoolInstanceIsTheOneRegisteredWithMetricsPublisherAndThreadPoolCache() throws IllegalAccessException, NoSuchFieldException {
        HystrixPlugins.getInstance().registerMetricsPublisher(new HystrixMetricsPublisher() {
            @Override
            public HystrixMetricsPublisherThreadPool getMetricsPublisherForThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixThreadPoolMetrics metrics, HystrixThreadPoolProperties properties) {
                return new HystrixMetricsPublisherThreadPoolContainer(metrics);
            }
"
"    @Test(timeout = 2500)
    public void testUnsubscribeHystrixThreadPool() throws InterruptedException {
        // methods are package-private so can't test it somewhere else
        HystrixThreadPool pool = Factory.getInstance(HystrixThreadPoolKey.Factory.asKey(""threadPoolFactoryTest""),
                HystrixThreadPoolProperties.Setter.getUnitTestPropertiesBuilder());
        
        final AtomicBoolean interrupted = new AtomicBoolean();
        final CountDownLatch start = new CountDownLatch(1);
        final CountDownLatch end = new CountDownLatch(1);

        HystrixContextScheduler hcs = new HystrixContextScheduler(HystrixPlugins.getInstance().getConcurrencyStrategy(), pool);

        Scheduler.Worker w = hcs.createWorker();

        try {
            w.schedule(new Action0() {
                @Override
                public void call() {
                    start.countDown();
                    try {
                        try {
                            Thread.sleep(5000);
                        } catch (InterruptedException ex) {
                            interrupted.set(true);
                        }
                    } finally {
                        end.countDown();
                    }
                }
"
"    @Test
    public void testTimeoutRace() throws InterruptedException {
        final int NUM_TRIALS = 10;

        for (int i = 0; i < NUM_TRIALS; i++) {
            List<Observable<String>> observables = new ArrayList<Observable<String>>();
            HystrixRequestContext context = null;

            try {
                context = HystrixRequestContext.initializeContext();
                for (int j = 0; j < NUM_CONCURRENT_COMMANDS; j++) {
                    observables.add(new TestCommand().observe());
                }

                Observable<String> overall = Observable.merge(observables);

                List<String> results = overall.toList().toBlocking().first(); //wait for all commands to complete

                for (String s : results) {
                    if (s == null) {
                        System.err.println(""Received NULL!"");
                        throw new RuntimeException(""Received NULL"");
                    }
                }

                for (HystrixInvokableInfo<?> hi : HystrixRequestLog.getCurrentRequest().getAllExecutedCommands()) {
                    if (!hi.isResponseTimedOut()) {
                        System.err.println(""Timeout not found in executed command"");
                        throw new RuntimeException(""Timeout not found in executed command"");
                    }
                    if (hi.isResponseTimedOut() && hi.getExecutionEvents().size() == 1) {
                        System.err.println(""Missing fallback status!"");
                        throw new RuntimeException(""Missing fallback status on timeout."");
                    }
                }

            } catch (Exception e) {
                System.err.println(""Error: "" + e.getMessage());
                e.printStackTrace();
                throw new RuntimeException(e);
            } finally {
                System.out.println(HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
                if (context != null) {
                    context.shutdown();
                }
            }

            System.out.println(""*************** TRIAL "" + i + "" ******************"");
            System.out.println();
            Thread.sleep(50);
        }

        Hystrix.reset();
    }
"
"    @Test
    public void testEmptyStreamProducesEmptyDistributions() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""Collapser-Batch-Size-A"");
        stream = RollingCollapserBatchSizeDistributionStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().skip(10).take(10).subscribe(new Subscriber<CachedValuesHistogram>() {
            @Override
            public void onCompleted() {
                latch.countDown();
            }
"
"    @Test
    public void testBatches() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""Collapser-Batch-Size-B"");
        stream = RollingCollapserBatchSizeDistributionStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(10).subscribe(new Subscriber<CachedValuesHistogram>() {
            @Override
            public void onCompleted() {
                latch.countDown();
            }
"
"    @Test
    public void testBatchesAgeOut() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""Collapser-Batch-Size-B"");
        stream = RollingCollapserBatchSizeDistributionStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(30).subscribe(new Subscriber<CachedValuesHistogram>() {
            @Override
            public void onCompleted() {
                latch.countDown();
            }
"
"    @Test
    public void testEmptyStreamProducesZeros() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-A"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(10).subscribe(getSubscriber(latch));

        //no writes

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        assertEquals(0, stream.getLatest(HystrixEventType.Collapser.ADDED_TO_BATCH));
        assertEquals(0, stream.getLatest(HystrixEventType.Collapser.BATCH_EXECUTED));
        assertEquals(0, stream.getLatest(HystrixEventType.Collapser.RESPONSE_FROM_CACHE));
    }
"
"    @Test
    public void testCollapsed() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-B"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(10).subscribe(getSubscriber(latch));

        for (int i = 0; i < 3; i++) {
            CommandStreamTest.Collapser.from(key, i).observe();
        }

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.Collapser.values().length];
        expected[HystrixEventType.Collapser.BATCH_EXECUTED.ordinal()] = 1;
        expected[HystrixEventType.Collapser.ADDED_TO_BATCH.ordinal()] = 3;
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testCollapsedAndResponseFromCache() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-C"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(10).subscribe(getSubscriber(latch));

        for (int i = 0; i < 3; i++) {
            CommandStreamTest.Collapser.from(key, i).observe();
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
        }

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.Collapser.values().length];
        expected[HystrixEventType.Collapser.BATCH_EXECUTED.ordinal()] = 1;
        expected[HystrixEventType.Collapser.ADDED_TO_BATCH.ordinal()] = 3;
        expected[HystrixEventType.Collapser.RESPONSE_FROM_CACHE.ordinal()] = 6;
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testCollapsedAndResponseFromCacheAgeOutOfCumulativeWindow() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-D"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(30).subscribe(getSubscriber(latch));

        for (int i = 0; i < 3; i++) {
            CommandStreamTest.Collapser.from(key, i).observe();
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
        }

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.Collapser.values().length];
        expected[HystrixEventType.Collapser.BATCH_EXECUTED.ordinal()] = 1;
        expected[HystrixEventType.Collapser.ADDED_TO_BATCH.ordinal()] = 3;
        expected[HystrixEventType.Collapser.RESPONSE_FROM_CACHE.ordinal()] = 6;
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testEmptyStreamProducesZeros() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-A"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //no writes

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        assertFalse(hasData(stream.getLatest()));
    }
"
"    @Test
    public void testSingleSuccess() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-B"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.SUCCESS, 20);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.SUCCESS.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testSingleFailure() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-C"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.FAILURE, 20);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 1;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testSingleTimeout() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-D"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.TIMEOUT);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.TIMEOUT.ordinal()] = 1;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testSingleBadRequest() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-E"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.BAD_REQUEST);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.BAD_REQUEST.ordinal()] = 1;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testRequestFromCache() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-F"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd1 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 20);
        Command cmd2 = Command.from(groupKey, key, HystrixEventType.RESPONSE_FROM_CACHE);
        Command cmd3 = Command.from(groupKey, key, HystrixEventType.RESPONSE_FROM_CACHE);

        cmd1.observe();
        cmd2.observe();
        cmd3.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }

        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.SUCCESS.ordinal()] = 1;
        expected[HystrixEventType.RESPONSE_FROM_CACHE.ordinal()] = 2;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testShortCircuited() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-G"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //3 failures in a row will trip circuit.  let bucket roll once then submit 2 requests.
        //should see 3 FAILUREs and 2 SHORT_CIRCUITs and then 5 FALLBACK_SUCCESSes

        Command failure1 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20);
        Command failure2 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20);
        Command failure3 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20);

        Command shortCircuit1 = Command.from(groupKey, key, HystrixEventType.SUCCESS);
        Command shortCircuit2 = Command.from(groupKey, key, HystrixEventType.SUCCESS);

        failure1.observe();
        failure2.observe();
        failure3.observe();

        try {
            Thread.sleep(500);
        } catch (InterruptedException ie) {
            fail(ie.getMessage());
        }

        shortCircuit1.observe();
        shortCircuit2.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }

        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertTrue(shortCircuit1.isResponseShortCircuited());
        assertTrue(shortCircuit2.isResponseShortCircuited());
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 3;
        expected[HystrixEventType.SHORT_CIRCUITED.ordinal()] = 2;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 5;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testSemaphoreRejected() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-H"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //10 commands will saturate semaphore when called from different threads.
        //submit 2 more requests and they should be SEMAPHORE_REJECTED
        //should see 10 SUCCESSes, 2 SEMAPHORE_REJECTED and 2 FALLBACK_SUCCESSes

        List<Command> saturators = new ArrayList<Command>();

        for (int i = 0; i < 10; i++) {
            saturators.add(Command.from(groupKey, key, HystrixEventType.SUCCESS, 500, HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE));
        }

        Command rejected1 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0, HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE);
        Command rejected2 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0, HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE);

        for (final Command saturator : saturators) {
            new Thread(new HystrixContextRunnable(new Runnable() {
                @Override
                public void run() {
                    saturator.observe();
                }
"
"    @Test
    public void testThreadPoolRejected() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-I"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //10 commands will saturate threadpools when called concurrently.
        //submit 2 more requests and they should be THREADPOOL_REJECTED
        //should see 10 SUCCESSes, 2 THREADPOOL_REJECTED and 2 FALLBACK_SUCCESSes

        List<Command> saturators = new ArrayList<Command>();

        for (int i = 0; i < 10; i++) {
            saturators.add(Command.from(groupKey, key, HystrixEventType.SUCCESS, 500));
        }

        Command rejected1 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0);
        Command rejected2 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0);

        for (final Command saturator : saturators) {
            saturator.observe();
        }

        try {
            Thread.sleep(100);
        } catch (InterruptedException ie) {
            fail(ie.getMessage());
        }

        rejected1.observe();
        rejected2.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }

        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertTrue(rejected1.isResponseThreadPoolRejected());
        assertTrue(rejected2.isResponseThreadPoolRejected());
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.SUCCESS.ordinal()] = 10;
        expected[HystrixEventType.THREAD_POOL_REJECTED.ordinal()] = 2;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 2;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testFallbackFailure() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-J"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_FAILURE);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 1;
        expected[HystrixEventType.FALLBACK_FAILURE.ordinal()] = 1;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testFallbackMissing() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-K"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_MISSING);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 1;
        expected[HystrixEventType.FALLBACK_MISSING.ordinal()] = 1;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testFallbackRejection() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-L"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //fallback semaphore size is 5.  So let 5 commands saturate that semaphore, then
        //let 2 more commands go to fallback.  they should get rejected by the fallback-semaphore

        List<Command> fallbackSaturators = new ArrayList<Command>();
        for (int i = 0; i < 5; i++) {
            fallbackSaturators.add(Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_SUCCESS, 400));
        }

        Command rejection1 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_SUCCESS, 0);
        Command rejection2 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_SUCCESS, 0);

        for (Command saturator: fallbackSaturators) {
            saturator.observe();
        }

        try {
            Thread.sleep(70);
        } catch (InterruptedException ex) {
            fail(ex.getMessage());
        }

        rejection1.observe();
        rejection2.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 7;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 5;
        expected[HystrixEventType.FALLBACK_REJECTION.ordinal()] = 2;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 2;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testCancelled() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-M"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command toCancel = Command.from(groupKey, key, HystrixEventType.SUCCESS, 500);

        System.out.println(System.currentTimeMillis() + "" : "" + Thread.currentThread().getName() + "" : about to observe and subscribe"");
        Subscription s = toCancel.observe().
                doOnUnsubscribe(new Action0() {
                    @Override
                    public void call() {
                        System.out.println(System.currentTimeMillis() + "" : "" + Thread.currentThread().getName() + "" : UnSubscribe from command.observe()"");
                    }
"
"    @BeforeEach
    public void setupPropertyReader() throws Exception {
      propertyReader = newSingletonPropertyReader(PRESENT_PROPERTY_VALUE);
    }
"
"    @Test
    public void shouldThrowExceptionWhenKeyIsNull() {
      assertThrows(NullPointerException.class, () -> propertyReader.readProperty(null));
    }
"
"    @Test
    public void shouldThrowExceptionWhenKeyIsEmptyOrOnlyWhitespace() {
      assertThrows(IllegalArgumentException.class, () -> propertyReader.readProperty(""""));
      assertThrows(IllegalArgumentException.class, () -> propertyReader.readProperty(""    ""));
    }
"
"    @Test
    public void shouldReturnValueWhenKeyIsPresent() {
      assertThat(propertyReader.readProperty(PRESENT_PROPERTY_KEY), is(PRESENT_PROPERTY_VALUE));
    }
"
"    @Test
    public void shouldReturnTrimmedValueWhenKeyIsPresentAndValueHasLeadingAndTrailingWhitespace()
        throws Exception {
      final PropertyReader propertyReader =
          newSingletonPropertyReader(""  "" + PRESENT_PROPERTY_VALUE + ""  "");

      assertThat(propertyReader.readProperty(PRESENT_PROPERTY_KEY), is(PRESENT_PROPERTY_VALUE));
    }
"
"    @Test
    public void shouldReturnEmptyWhenKeyIsAbsent() {
      assertThat(propertyReader.readProperty(ABSENT_PROPERTY_KEY), is(emptyString()));
    }
"
"    @Test
    public void shouldReturnValueWhenKeyIsPresent() throws Exception {
      final String value = ""value"";
      final PropertyReader propertyReader = newSingletonPropertyReader(value);

      assertThat(
          propertyReader.readPropertyOrDefault(PRESENT_PROPERTY_KEY, ""defaultValue""), is(value));
    }
"
"    @Test
    public void shouldReturnDefaultValueWhenKeyIsAbsent() throws Exception {
      final String defaultValue = ""defaultValue"";
      final PropertyReader propertyReader = newEmptyPropertyReader();

      assertThat(
          propertyReader.readPropertyOrDefault(ABSENT_PROPERTY_KEY, defaultValue),
          is(defaultValue));
    }
"
"    @Test
    public void shouldReturnValueWhenKeyIsPresent() throws Exception {
      final boolean value = true;
      final PropertyReader propertyReader = newSingletonPropertyReader(String.valueOf(value));

      assertThat(
          propertyReader.readBooleanPropertyOrDefault(PRESENT_PROPERTY_KEY, false), is(value));
    }
"
"    @Test
    public void shouldReturnDefaultValueWhenKeyIsAbsent() throws Exception {
      final boolean defaultValue = true;
      final PropertyReader propertyReader = newEmptyPropertyReader();

      assertThat(
          propertyReader.readBooleanPropertyOrDefault(ABSENT_PROPERTY_KEY, defaultValue),
          is(defaultValue));
    }
"
"    @Test
    public void shouldReturnValueWhenKeyIsPresent() throws Exception {
      final int value = 42;
      final PropertyReader propertyReader = newSingletonPropertyReader(String.valueOf(value));

      assertThat(propertyReader.readIntegerPropertyOrDefault(PRESENT_PROPERTY_KEY, -1), is(value));
    }
"
"    @Test
    public void shouldReturnDefaultValueWhenKeyIsPresentAndValueIsNotAnInteger() throws Exception {
      final int defaultValue = 777;
      final PropertyReader propertyReader = newSingletonPropertyReader(""other"");

      assertThat(
          propertyReader.readIntegerPropertyOrDefault(PRESENT_PROPERTY_KEY, defaultValue),
          is(defaultValue));
    }
"
"    @Test
    public void shouldReturnDefaultValueWhenKeyIsAbsent() throws Exception {
      final int defaultValue = 777;
      final PropertyReader propertyReader = newEmptyPropertyReader();

      assertThat(
          propertyReader.readIntegerPropertyOrDefault(ABSENT_PROPERTY_KEY, defaultValue),
          is(defaultValue));
    }
"
"  @Test
          public void connectionRemoved(final INode to) {
            serverCount.decrementAndGet();
          }
"
"  @Test
    public void messageReceived(final Serializable msg, final INode from) {
      synchronized (lock) {
        messages.add(msg);
        senders.add(from);
        lock.notifyAll();
      }
    }
"
"  @Test
    public void updatePlayerList(final Collection<ChatParticipant> players) {
      playerCount.set(players.size());
    }
"
"  @Test
    public int increment(final int testVal) {
      senderNode = MessageContext.getSender();
      return testVal + 1;
    }
"
"  @Test
    public void testNoParams() {
      incrementCount();
    }
"
"  @Test
    public void run() {
      Interruptibles.sleep(0L, 1);
      done = true;
    }
"
"    @BeforeEach
    public void createLobbyLoginValidator() throws Exception {
      lobbyLoginValidator =
          new LobbyLoginValidator(
              databaseDao,
              new RsaAuthenticator(TestSecurityUtils.loadRsaKeyPair()),
              () -> bcryptSalt,
              failedLoginThrottle,
              tempPasswordVerification,
              new AllowLoginRules(databaseDao),
              AllowCreateUserRules.builder()
                  .userDao(userDao)
                  .nameValidator(PlayerNameValidation::validate)
                  .emailValidator(PlayerEmailValidation::validate)
                  .build());
    }
"
"    @BeforeEach
    public void givenNoBans() {
      givenNoMacIsBanned();
      givenNoUsernameIsBanned();
      when(databaseDao.getBadWordDao()).thenReturn(badWordDao);
    }
"
"  @Test
  public void shouldExtractMetricsFromPrometheusMetricsAndSerialiseJson()
      throws JsonProcessingException {
    when(prometheusMock.streamObservations()).thenReturn(getMockObservations().stream());
    final MetricsDataFactory metricsDataFactory = new MetricsDataFactory(prometheusMock);

    final List<BaseMetricData> baseMetricData = metricsDataFactory.getMetricData(timeProvider);
    assertThat(baseMetricData.size()).isEqualTo(3);
    final String beaconNode = jsonProvider.objectToJSON(baseMetricData.get(0));
    final String validator = jsonProvider.objectToJSON(baseMetricData.get(1));
    final String system = jsonProvider.objectToJSON(baseMetricData.get(2));

    BeaconNodeMetricData beaconNodeDeserialized =
        jsonProvider.jsonToObject(beaconNode, BeaconNodeMetricData.class);
    ValidatorMetricData validatorDeserialized =
        jsonProvider.jsonToObject(validator, ValidatorMetricData.class);
    SystemMetricData systemDeserialized = jsonProvider.jsonToObject(system, SystemMetricData.class);

    assertThat(baseMetricData.get(0)).isInstanceOf(BeaconNodeMetricData.class);
    assertThat(baseMetricData.get(1)).isInstanceOf(ValidatorMetricData.class);
    assertThat(baseMetricData.get(2)).isInstanceOf(SystemMetricData.class);

    assertThat(baseMetricData.get(0)).isEqualTo(beaconNodeDeserialized);
    assertThat(baseMetricData.get(1)).isEqualTo(validatorDeserialized);
    assertThat(baseMetricData.get(2)).isEqualTo(systemDeserialized);
  }
"
"  @Test
  public void shouldDeserializeObjectFromString() throws JsonProcessingException {
    when(prometheusMock.streamObservations()).thenReturn(getMockObservations().stream());
    final MetricsDataFactory metricsDataFactory = new MetricsDataFactory(prometheusMock);
    final List<BaseMetricData> baseMetricData = metricsDataFactory.getMetricData(timeProvider);
    assertThat(baseMetricData.size()).isEqualTo(3);

    String listOfMetrics = jsonProvider.objectToJSON(baseMetricData);
    DeserializedMetricDataObject[] base =
        jsonProvider.jsonToObject(listOfMetrics, DeserializedMetricDataObject[].class);

    assertThat(base.length).isEqualTo(3);
  }
"
"  @Test
  public void shouldSerializeObjectFromPrometheusMetricsWithDefaultValues()
      throws JsonProcessingException {
    when(prometheusMock.streamObservations()).thenReturn(new ArrayList<Observation>().stream());
    final MetricsDataFactory metricsDataFactory = new MetricsDataFactory(prometheusMock);

    final List<BaseMetricData> baseMetricData = metricsDataFactory.getMetricData(timeProvider);
    assertThat(baseMetricData.size()).isEqualTo(3);
    final String beaconNode = jsonProvider.objectToJSON(baseMetricData.get(0));
    final String validator = jsonProvider.objectToJSON(baseMetricData.get(1));
    final String system = jsonProvider.objectToJSON(baseMetricData.get(2));

    BeaconNodeMetricData beaconNodeDeserialized =
        jsonProvider.jsonToObject(beaconNode, BeaconNodeMetricData.class);
    ValidatorMetricData validatorDeserialized =
        jsonProvider.jsonToObject(validator, ValidatorMetricData.class);
    SystemMetricData systemDeserialized = jsonProvider.jsonToObject(system, SystemMetricData.class);

    assertThat(baseMetricData.get(0)).isInstanceOf(BeaconNodeMetricData.class);
    assertThat(baseMetricData.get(1)).isInstanceOf(ValidatorMetricData.class);
    assertThat(baseMetricData.get(2)).isInstanceOf(SystemMetricData.class);

    assertThat(baseMetricData.get(0)).isEqualTo(beaconNodeDeserialized);
    assertThat(baseMetricData.get(1)).isEqualTo(validatorDeserialized);
    assertThat(baseMetricData.get(2)).isEqualTo(systemDeserialized);

    assertThat(beaconNodeDeserialized.network_peers_connected).isNull();
    assertThat(validatorDeserialized.validator_total).isNull();
    assertThat(systemDeserialized.cpu_node_system_seconds_total).isNull();
  }
"
"  @Test
  public void shouldSerializeObject() throws JsonProcessingException {
    final ValidatorMetricData process =
        new ValidatorMetricData(
            1, UInt64.valueOf(10L).longValue(), ""system"", 11L, 12L, ""teku"", ""21.8"", 3, 4);
    final String data = jsonProvider.objectToJSON(process);
    assertThat(process).isEqualTo(jsonProvider.jsonToObject(data, ValidatorMetricData.class));
  }
"
"  @BeforeEach
  public void beforeEach() throws Exception {
    mockWebServer.start();
  }
"
"  @AfterEach
  public void afterEach() throws Exception {
    mockWebServer.shutdown();
  }
"
"  @Test
  public void shouldRunPublisherEveryXSeconds() throws InterruptedException, IOException {
    MetricsPublisherManager publisherManager =
        new MetricsPublisherManager(asyncRunnerFactory, timeProvider, metricsEndpoint);
    publisherManager.setMetricsPublisher(metricsPublisher);
    verify(metricsPublisher, times(0)).publishMetrics(anyString(), anyString());
    SafeFuture<?> safeFuture = publisherManager.doStart();
    assertThat(asyncRunnerFactory.getStubAsyncRunners().size()).isEqualTo(1);
    asyncRunnerFactory.getStubAsyncRunners().get(0).executeQueuedActions();
    verify(metricsPublisher, times(1)).publishMetrics(anyString(), anyString());
    asyncRunnerFactory.getStubAsyncRunners().get(0).executeQueuedActions();
    verify(metricsPublisher, times(2)).publishMetrics(anyString(), anyString());
    Assertions.assertThat(safeFuture).isEqualTo(SafeFuture.COMPLETE);
  }
"
"  @Test
  public void shouldReturnHTTPStatusOk() throws IOException {
    MetricsPublisherManager publisherManager =
        new MetricsPublisherManager(asyncRunnerFactory, timeProvider, metricsEndpoint);
    publisherManager.setMetricsPublisher(metricsPublisher);
    Assertions.assertThat(publisherManager.publishMetrics()).isEqualTo(200);
  }
"
"  @Test
  public void shouldStopGracefully() throws IOException {
    MetricsPublisherManager publisherManager =
        new MetricsPublisherManager(asyncRunnerFactory, timeProvider, metricsEndpoint);
    publisherManager.setMetricsPublisher(metricsPublisher);
    SafeFuture<?> safeFuture = publisherManager.doStart();
    Assertions.assertThat(safeFuture).isEqualTo(SafeFuture.COMPLETE);
    safeFuture = publisherManager.doStop();
    Assertions.assertThat(safeFuture).isEqualTo(SafeFuture.COMPLETE);
  }
"
"  @Test
  public void shouldReadSlashingProtectionFile_withEmptyGenesisValidatorsRoot(@TempDir Path tempDir)
      throws IOException, URISyntaxException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtection.yml"", tempDir), log::add);
    assertThat(log).containsExactly(""Exporting "" + pubkey);
    assertThat(error).isEmpty();

    final SlashingProtectionInterchangeFormat parsedData =
        jsonProvider.jsonToObject(
            exporter.getPrettyJson(), SlashingProtectionInterchangeFormat.class);
    final SlashingProtectionInterchangeFormat expectedData = getExportData(null, 327, 51, 1741);
    assertThat(parsedData).isEqualTo(expectedData);
  }
"
"  @Test
  public void shouldReadSlashingProtectionFile_withGenesisValidatorsRoot(@TempDir Path tempDir)
      throws IOException, URISyntaxException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtectionWithGenesisRoot.yml"", tempDir), log::add);
    assertThat(log).containsExactly(""Exporting "" + pubkey);
    assertThat(error).isEmpty();

    final SlashingProtectionInterchangeFormat parsedData =
        jsonProvider.jsonToObject(
            exporter.getPrettyJson(), SlashingProtectionInterchangeFormat.class);
    final SlashingProtectionInterchangeFormat expectedData =
        getExportData(validatorsRoot, 327, 51, 1741);
    assertThat(parsedData).isEqualTo(expectedData);
  }
"
"  @Test
  public void shouldReadFilesWithEmptyRootAfterGenesisRootIsDefined(@TempDir Path tempDir)
      throws URISyntaxException, IOException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtectionWithGenesisRoot.yml"", tempDir), log::add);
    assertThat(error).isEmpty();
    error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtection.yml"", tempDir), log::add);
    assertThat(error).isEmpty();

    assertThat(log).containsExactly(""Exporting "" + pubkey, ""Exporting "" + pubkey);
  }
"
"  @Test
  public void shouldReadFileWithGenesisRootDefinedSecond(@TempDir Path tempDir)
      throws URISyntaxException, IOException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtection.yml"", tempDir), log::add);
    assertThat(error).isEmpty();
    error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtectionWithGenesisRoot.yml"", tempDir), log::add);
    assertThat(error).isEmpty();

    assertThat(log).containsExactly(""Exporting "" + pubkey, ""Exporting "" + pubkey);
  }
"
"  @Test
  public void shouldNotAcceptDifferentGenesisValidatorsRoot(@TempDir Path tempDir)
      throws URISyntaxException, IOException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtectionWithGenesisRoot2.yml"", tempDir), LOG::debug);
    assertThat(error).isEmpty();
    error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtectionWithGenesisRoot.yml"", tempDir), LOG::debug);
    assertThat(error.orElse("""")).startsWith(""The genesisValidatorsRoot of"");
  }
"
"  @Test
  public void shouldRequirePubkeyInFilename(@TempDir Path tempDir) throws URISyntaxException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    final Optional<String> error =
        exporter.readSlashProtectionFile(
            new File(Resources.getResource(""slashProtectionWithGenesisRoot.yml"").toURI()),
            LOG::debug);
    assertThat(error.orElse(""""))
        .contains(""Public key in file slashProtectionWithGenesisRoot.yml does not appear valid."");
  }
"
"  @Test
  public void shouldPrintIfFileCannotBeRead(@TempDir Path tempDir)
      throws URISyntaxException, IOException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    final File file = usingResourceFile(""slashProtection.yml"", tempDir);
    OSUtils.makeNonReadable(file.toPath());
    // It's not always possible to remove read permissions from a file
    assumeThat(file.canRead()).describedAs(""Can read file %s"", file).isFalse();
    final Optional<String> error = exporter.readSlashProtectionFile(file, LOG::debug);
    assertThat(error.orElse("""")).startsWith(""Failed to read from file"");
  }
"
"  @Test
  public void shouldExportSlashProtection(@TempDir Path tempDir)
      throws IOException, URISyntaxException {
    final Path exportedFile = tempDir.resolve(""exportedFile.json"").toAbsolutePath();
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);

    final Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtection.yml"", tempDir), LOG::debug);
    assertThat(error).isEmpty();
    assertThat(Files.exists(exportedFile)).isFalse();
    exporter.saveToFile(exportedFile.toString(), LOG::debug);
    assertThat(Files.exists(exportedFile)).isTrue();
  }
"
"  @Test
  public void shouldExportSlashProtection(@TempDir Path tempDir)
      throws IOException, URISyntaxException {
    final Path exportedFile = tempDir.resolve(""exportedFile.json"").toAbsolutePath();
    final SlashingProtectionIncrementalExporter exporter =
        new SlashingProtectionIncrementalExporter(tempDir);

    final Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtection.yml"", tempDir), LOG::debug);
    assertThat(error).isEmpty();
    assertThat(Files.exists(exportedFile)).isFalse();
    exporter.saveToFile(exportedFile.toString(), LOG::debug);

    final String exportedData = exporter.finalise();
    final String expectedResult = resourceFileAsString(""shouldExportSlashProtection.json"");
    assertThat(exportedData).isEqualTo(expectedResult);
  }
"
"  @Test
  public void shouldNotUpdateFilesWithInvalidPubkeys(@TempDir Path tempDir) throws IOException {
    setupPathForTest(tempDir, Map.of(""a.yml"", Optional.of(validatorSigningRecord)));
    SlashingProtectionRepairer repairer =
        SlashingProtectionRepairer.create(subCommandLogger, tempDir, true);
    assertThat(repairer.hasUpdates()).isFalse();
    verify(subCommandLogger).display("" --- a.yml - invalid public key - ignoring file"");

    repairer.updateRecords(UInt64.MAX_VALUE, UInt64.MAX_VALUE);
    verifyNoMoreInteractions(subCommandLogger);

    assertThat(fileContents(tempDir.resolve(""a.yml"")))
        .isEqualTo(Optional.of(validatorSigningRecord));
  }
"
"  @Test
  public void shouldUpdateValidAndInvalidFiles(@TempDir Path tempDir) throws IOException {
    setupPathForTest(tempDir, testData);
    SlashingProtectionRepairer repairer =
        SlashingProtectionRepairer.create(subCommandLogger, tempDir, true);
    assertThat(repairer.hasUpdates()).isTrue();

    final UInt64 blockSlot = UInt64.valueOf(1023999);
    final UInt64 attestationEpoch = UInt64.valueOf(2344);
    repairer.updateRecords(blockSlot, attestationEpoch);

    final Optional<ValidatorSigningRecord> defaultRecord =
        Optional.of(
            new ValidatorSigningRecord(null, blockSlot, attestationEpoch, attestationEpoch));

    assertThat(fileContents(tempDir.resolve(keys.get(0)))).isEqualTo(defaultRecord);
    // all original values were lower, so the entire file should get updated
    assertThat(fileContents(tempDir.resolve(keys.get(1)))).isEqualTo(defaultRecord);
    // sourceAttestation changed, but other values were higher
    assertThat(fileContents(tempDir.resolve(keys.get(2))))
        .isEqualTo(
            optionalSigningRecord(UInt64.valueOf(1024000), attestationEpoch, UInt64.valueOf(2345)));
    // all original values were better
    assertThat(fileContents(tempDir.resolve(keys.get(3)))).isEqualTo(testData.get(keys.get(3)));
  }
"
"  @Test
  public void shouldUpdateInvalidFiles(@TempDir Path tempDir) throws IOException {
    setupPathForTest(tempDir, testData);
    SlashingProtectionRepairer repairer =
        SlashingProtectionRepairer.create(subCommandLogger, tempDir, false);
    assertThat(repairer.hasUpdates()).isTrue();

    final UInt64 blockSlot = UInt64.valueOf(1023999);
    final UInt64 attestationEpoch = UInt64.valueOf(2344);
    repairer.updateRecords(blockSlot, attestationEpoch);

    final Optional<ValidatorSigningRecord> defaultRecord =
        Optional.of(
            new ValidatorSigningRecord(null, blockSlot, attestationEpoch, attestationEpoch));

    assertThat(fileContents(tempDir.resolve(keys.get(0)))).isEqualTo(defaultRecord);
    assertThat(fileContents(tempDir.resolve(keys.get(1)))).isEqualTo(testData.get(keys.get(1)));
    assertThat(fileContents(tempDir.resolve(keys.get(2)))).isEqualTo(testData.get(keys.get(2)));
    assertThat(fileContents(tempDir.resolve(keys.get(3)))).isEqualTo(testData.get(keys.get(3)));
  }
"
"  @Test
  public void shouldFailWithParseError(@TempDir final Path tempDir)
      throws URISyntaxException, IOException {
    final String errorString = loadAndGetErrorText(""minimal_invalidKey.json"", tempDir);
    assertThat(errorString).startsWith(""Failed to load data"");
  }
"
"  @Test
  public void shouldFailWithInvalidJson(@TempDir final Path tempDir)
      throws URISyntaxException, IOException {
    final String errorString = loadAndGetErrorText(""invalid_json.json"", tempDir);
    assertThat(errorString).startsWith(""Json does not appear valid"");
  }
"
"  @Test
  public void shouldFailWithVersionCheckFailure(@TempDir final Path tempDir)
      throws URISyntaxException, IOException {
    final String errorString = loadAndGetErrorText(""oldMetadata.json"", tempDir);
    assertThat(errorString)
        .contains(""Required version is "" + Metadata.INTERCHANGE_VERSION.toString());
  }
"
"  @Test
  public void shouldFailIfMetadataNotPresent(@TempDir final Path tempDir)
      throws IOException, URISyntaxException {
    final String errorString = loadAndGetErrorText(""signedBlock.json"", tempDir);
    assertThat(errorString).contains(""does not appear to have metadata"");
  }
"
"  @Test
  public void shouldImportSingleRecord(@TempDir Path tempDir)
      throws URISyntaxException, IOException {
    final File ruleFile = usingResourceFile(""slashProtection.yml"", tempDir);
    final SlashingProtectionImporter importer = new SlashingProtectionImporter(tempDir);
    importer.initialise(ruleFile);
    final Optional<String> maybeError = importer.updateSigningRecord(publicKey, (__) -> {});
    assertThat(maybeError).isEmpty();
    assertThat(tempDir.resolve(pubkey + "".yml"").toFile()).exists();
  }
"
"  @Test
  public void shouldExportAndImportFile(@TempDir Path tempDir)
      throws IOException, URISyntaxException {
    final Path exportedFile = tempDir.resolve(""exportedFile.json"").toAbsolutePath();

    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    final File ruleFile = usingResourceFile(""slashProtection.yml"", tempDir);
    final Optional<String> exportError = exporter.readSlashProtectionFile(ruleFile, LOG::debug);
    final String originalFileContent = Files.readString(ruleFile.toPath());
    assertThat(exportError).isEmpty();

    assertThat(Files.exists(ruleFile.toPath())).isTrue();
    assertThat(Files.exists(exportedFile)).isFalse();
    exporter.saveToFile(exportedFile.toString(), LOG::debug);
    ruleFile.delete();
    assertThat(Files.exists(exportedFile)).isTrue();
    assertThat(Files.exists(ruleFile.toPath())).isFalse();

    SlashingProtectionImporter importer = new SlashingProtectionImporter(tempDir);
    importer.initialise(new File(exportedFile.toString()));
    final Map<BLSPublicKey, String> errors = importer.updateLocalRecords((__) -> {});
    assertThat(errors).isEmpty();
    assertThat(Files.exists(ruleFile.toPath())).isTrue();

    assertThat(originalFileContent).isEqualTo(Files.readString(ruleFile.toPath()));
  }
"
"  @Test
  public void shouldReadMetadataFromCompleteJson() throws IOException {
    final String minimalJson =
        Resources.toString(Resources.getResource(""format1_complete.json""), StandardCharsets.UTF_8);

    JsonNode jsonNode = mapper.readTree(minimalJson);
    JsonNode metadataJson = jsonNode.get(""metadata"");
    Metadata metadata = mapper.treeToValue(metadataJson, Metadata.class);
    assertThat(metadata).isEqualTo(new Metadata(INTERCHANGE_VERSION, GENESIS_ROOT));

    List<SigningHistory> completeSigningHistories =
        Arrays.asList(mapper.readValue(jsonNode.get(""data"").toString(), SigningHistory[].class));

    assertThat(completeSigningHistories)
        .containsExactly(
            new SigningHistory(
                blsPubKey,
                List.of(
                    new SignedBlock(
                        UInt64.valueOf(81952),
                        Bytes32.fromHexString(
                            ""0x0000000000000000000000000000000000000000000000000000000000001234""))),
                List.of(
                    new SignedAttestation(
                        UInt64.valueOf(2290),
                        UInt64.valueOf(3007),
                        Bytes32.fromHexString(
                            ""0x0000000000000000000000000000000000000000000000000000000000000123"")))));
  }
"
"  @Test
  public void shouldCreate() {
    final SignedAttestation signedAttestation = new SignedAttestation(source, target, signingRoot);
    assertThat(signedAttestation.sourceEpoch).isEqualTo(source);
    assertThat(signedAttestation.targetEpoch).isEqualTo(target);
    assertThat(signedAttestation.signingRoot).isEqualTo(signingRoot);
  }
"
"  @Test
  public void shouldSerialize() throws JsonProcessingException {
    final SignedAttestation signedAttestation = new SignedAttestation(source, target, signingRoot);
    String str = jsonProvider.objectToPrettyJSON(signedAttestation);
    assertThat(str).isEqualToNormalizingNewlines(jsonData);
  }
"
"  @Test
  public void shouldDeserialize() throws JsonProcessingException {
    final SignedAttestation signedAttestation =
        jsonProvider.jsonToObject(jsonData, SignedAttestation.class);
    assertThat(signedAttestation.sourceEpoch).isEqualTo(source);
    assertThat(signedAttestation.targetEpoch).isEqualTo(target);
    assertThat(signedAttestation.signingRoot).isEqualTo(signingRoot);
  }
"
"  @Test
  public void shouldReadMetadataFromMinimalJson() throws IOException {
    final String minimalJson =
        Resources.toString(Resources.getResource(""format2_minimal.json""), StandardCharsets.UTF_8);

    JsonNode jsonNode = mapper.readTree(minimalJson);
    JsonNode metadataJson = jsonNode.get(""metadata"");
    Metadata metadata = mapper.treeToValue(metadataJson, Metadata.class);
    assertThat(metadata).isEqualTo(new Metadata(INTERCHANGE_VERSION, GENESIS_ROOT));

    List<SigningHistory> minimalSigningHistoryList =
        Arrays.asList(mapper.readValue(jsonNode.get(""data"").toString(), SigningHistory[].class));

    SigningHistory element =
        new SigningHistory(
            blsPubKey,
            new ValidatorSigningRecord(
                GENESIS_ROOT, UInt64.valueOf(81952), UInt64.valueOf(2290), UInt64.valueOf(3007)));
    assertThat(minimalSigningHistoryList).containsExactly(element);
  }
"
"  @Test
  public void shouldSerializeMinimalFormat() throws JsonProcessingException {
    final Metadata metadata = new Metadata(INTERCHANGE_VERSION, root);
    assertThat(jsonProvider.objectToPrettyJSON(metadata)).isEqualToNormalizingNewlines(jsonData);
  }
"
"  @Test
  public void shouldSerializeWithoutRoot() throws JsonProcessingException {
    final Metadata metadata = new Metadata(INTERCHANGE_VERSION, null);
    assertThat(jsonProvider.objectToPrettyJSON(metadata))
        .isEqualToIgnoringWhitespace(""{\""interchange_format_version\"":\""5\""}"");
  }
"
"  @Test
  public void shouldSerializeCompleteFormat() throws JsonProcessingException {
    final Metadata metadata = new Metadata(INTERCHANGE_VERSION, root);
    assertThat(jsonProvider.objectToPrettyJSON(metadata)).isEqualToNormalizingNewlines(jsonData);
  }
"
"  @Test
  public void shouldDeserialize() throws JsonProcessingException {
    final Metadata metadata = jsonProvider.jsonToObject(jsonData, Metadata.class);
    assertThat(metadata.interchangeFormatVersion).isEqualTo(INTERCHANGE_VERSION);
    assertThat(metadata.genesisValidatorsRoot).isEqualTo(root);
  }
"
"  @Test
  public void shouldReadMetadataFromCompleteJson() throws IOException {
    final String completeJson =
        Resources.toString(Resources.getResource(""format1_complete.json""), StandardCharsets.UTF_8);

    JsonNode metadataJson = mapper.readTree(completeJson).get(""metadata"");
    Metadata metadata = mapper.treeToValue(metadataJson, Metadata.class);

    assertThat(metadata).isEqualTo(expectedMetadata);
  }
"
"  @Test
  public void shouldReadMetadataFromJson() throws IOException {
    final String minimalJson =
        Resources.toString(Resources.getResource(""format2_minimal.json""), StandardCharsets.UTF_8);

    JsonNode metadataJson = mapper.readTree(minimalJson).get(""metadata"");
    Metadata metadata = mapper.treeToValue(metadataJson, Metadata.class);
    assertThat(metadata).isEqualTo(expectedMetadata);
  }
"
"  @Test
  public void shouldSerialize() throws JsonProcessingException {
    final SignedBlock signedBlock = new SignedBlock(slot, signingRoot);
    String str = jsonProvider.objectToPrettyJSON(signedBlock);
    assertThat(str).isEqualToNormalizingNewlines(jsonData);
  }
"
"  @Test
  public void shouldDeserialize() throws JsonProcessingException {
    final SignedBlock signedBlock = jsonProvider.jsonToObject(jsonData, SignedBlock.class);
    assertThat(signedBlock.slot).isEqualTo(slot);
    assertThat(signedBlock.signingRoot).isEqualTo(signingRoot);
  }
"
"  @BeforeEach
  public void setup() {
    slot = UInt64.valueOf(specConfig.getSlotsPerEpoch() * 3L);
    actualBalance = specConfig.getMaxEffectiveBalance().plus(100000);
    storageSystem.chainUpdater().initializeGenesis(true, actualBalance, Optional.empty());
    bestBlock = storageSystem.chainUpdater().advanceChain(slot);
    storageSystem.chainUpdater().updateBestBlock(bestBlock);

    recentChainData = storageSystem.recentChainData();
    beaconStateInternal = bestBlock.getState();

    combinedChainDataClient = storageSystem.combinedChainDataClient();
    blockRoot = bestBlock.getRoot();
  }
"
"  @Test
  public void getChainHeads_shouldReturnChainHeads()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final SafeFuture<Optional<List<ChainHead>>> future = provider.getChainHeads();
    final Optional<List<ChainHead>> maybeResult = future.get();
    assertThat(maybeResult.orElse(emptyList()))
        .containsExactly(new ChainHead(bestBlock.getSlot(), blockRoot));
  }
"
"  @Test
  public void getGenesisTime_shouldThrowIfStoreNotAvailable() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, null, mockCombinedChainDataClient);
    when(mockCombinedChainDataClient.isStoreAvailable()).thenReturn(false);
    assertThatThrownBy(provider::getGenesisTime).isInstanceOf(ChainDataUnavailableException.class);
  }
"
"  @Test
  public void getGenesisTime_shouldReturnValueIfStoreAvailable() {
    final UInt64 genesis = beaconStateInternal.getGenesis_time();
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    final UInt64 result = provider.getGenesisTime();
    assertEquals(genesis, result);
  }
"
"  @Test
  public void getGenesisData_shouldThrowIfStoreNotAvailable() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, null, mockCombinedChainDataClient);
    when(mockCombinedChainDataClient.isStoreAvailable()).thenReturn(false);
    assertThatThrownBy(provider::getGenesisData).isInstanceOf(ChainDataUnavailableException.class);
  }
"
"  @Test
  public void getGenesisData_shouldReturnValueIfStoreAvailable() {
    final UInt64 genesisTime = beaconStateInternal.getGenesis_time();
    final Bytes32 genesisValidatorsRoot = beaconStateInternal.getGenesis_validators_root();
    final Bytes4 genesisForkVersion = spec.atEpoch(ZERO).getConfig().getGenesisForkVersion();

    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    final GenesisData result = provider.getGenesisData();
    assertThat(result)
        .isEqualTo(new GenesisData(genesisTime, genesisValidatorsRoot, genesisForkVersion));
  }
"
"  @Test
  public void getBeaconState_shouldReturnEmptyWhenRootNotFound()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    SafeFuture<Optional<BeaconState>> future =
        provider.getBeaconState(data.randomBytes32().toHexString());
    final Optional<BeaconState> maybeState = future.get();
    assertThat(maybeState).isEmpty();
  }
"
"  @Test
  public void getBeaconState_shouldFindHeadState() throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    SafeFuture<Optional<BeaconState>> future = provider.getBeaconState(""head"");
    final Optional<BeaconState> maybeState = future.get();
    assertThat(maybeState.get().asInternalBeaconState(spec).hashTreeRoot())
        .isEqualTo(beaconStateInternal.hashTreeRoot());
  }
"
"  @Test
  public void validatorParameterToIndex_shouldThrowWhenStoreNotFound() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, null, mockCombinedChainDataClient);
    assertThrows(
        ChainDataUnavailableException.class, () -> provider.validatorParameterToIndex(""1""));
  }
"
"  @Test
  public void validatorParameterToIndex_shouldAcceptValidatorRoot() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    Validator validator =
        new Validator(recentChainData.getBestState().get().getValidators().get(1));

    assertThat(provider.validatorParameterToIndex(validator.pubkey.toHexString()))
        .isEqualTo(Optional.of(1));
  }
"
"  @Test
  public void validatorParameterToIndex_shouldAcceptValidatorId() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThat(provider.validatorParameterToIndex(""2"")).isEqualTo(Optional.of(2));
  }
"
"  @Test
  public void validatorParameterToIndex_shouldThrowException() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThrows(BadRequestException.class, () -> provider.validatorParameterToIndex(""2a""));
  }
"
"  @Test
  public void validatorParameterToIndex_shouldDetectAboveMaxInt() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThrows(
        BadRequestException.class,
        () ->
            provider.validatorParameterToIndex(
                UInt64.valueOf(Integer.MAX_VALUE).increment().toString()));
  }
"
"  @Test
  public void validatorParameterToIndex_shouldThrowExceptionWithInvalidPublicKey() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThrows(
        BadRequestException.class,
        () -> provider.validatorParameterToIndex(Bytes32.EMPTY.toHexString()));
  }
"
"  @Test
  public void getBlockHeaderByBlockId_shouldGetHeadBlock()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final tech.pegasys.teku.spec.datastructures.blocks.SignedBeaconBlock block =
        combinedChainDataClient.getBestBlock().get();
    BlockHeader result = provider.getBlockHeader(""head"").get().get();
    final BeaconBlockHeader beaconBlockHeader =
        new BeaconBlockHeader(
            block.getSlot(),
            block.getMessage().getProposerIndex(),
            block.getParentRoot(),
            block.getStateRoot(),
            block.getRoot());
    final BlockHeader expected =
        new BlockHeader(
            block.getRoot(),
            true,
            new SignedBeaconBlockHeader(beaconBlockHeader, new BLSSignature(block.getSignature())));

    assertThat(result).isEqualTo(expected);
  }
"
"  @Test
  public void getStateRoot_shouldGetRootAtGenesis()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    final Optional<tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState> state =
        combinedChainDataClient.getStateAtSlotExact(ZERO).get();
    final Optional<Root> maybeStateRoot = provider.getStateRoot(""genesis"").get();
    assertThat(maybeStateRoot).isPresent();
    assertThat(maybeStateRoot.orElseThrow().root).isEqualTo(state.orElseThrow().hashTreeRoot());
  }
"
"  @Test
  public void getBlockHeaders_shouldGetHeadBlockIfNoParameters()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final tech.pegasys.teku.spec.datastructures.blocks.SignedBeaconBlock block =
        combinedChainDataClient.getBestBlock().get();
    List<BlockHeader> results = provider.getBlockHeaders(Optional.empty(), Optional.empty()).get();
    assertThat(results.get(0).root).isEqualTo(block.getRoot());
  }
"
"  @Test
  public void getBlockHeaders_shouldGetBlockGivenSlot()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final UInt64 slot = combinedChainDataClient.getCurrentSlot();
    List<BlockHeader> results = provider.getBlockHeaders(Optional.empty(), Optional.of(slot)).get();
    assertThat(results.get(0).header.message.slot).isEqualTo(slot);
  }
"
"  @Test
  public void shouldGetBlockHeadersOnEmptyChainHeadSlot() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    final UInt64 headSlot = recentChainData.getHeadSlot();
    storageSystem.chainUpdater().advanceChain(headSlot.plus(1));

    final SafeFuture<List<BlockHeader>> future =
        provider.getBlockHeaders(Optional.empty(), Optional.empty());
    final BlockHeader header = future.join().get(0);
    assertThat(header.header.message.slot).isEqualTo(headSlot);
  }
"
"  @Test
  public void filteredValidatorsList_shouldFilterByValidatorIndex() {

    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(1024);
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    List<Integer> indexes =
        provider.getFilteredValidatorList(internalState, List.of(""1"", ""33""), emptySet()).stream()
            .map(v -> v.index.intValue())
            .collect(toList());
    assertThat(indexes).containsExactly(1, 33);
  }
"
"  @Test
  public void filteredValidatorsList_shouldFilterByValidatorPubkey() {
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(1024);
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final String key = internalState.getValidators().get(12).getPubkeyBytes().toString();
    final String missingKey = data.randomPublicKey().toString();
    List<String> pubkeys =
        provider
            .getFilteredValidatorList(internalState, List.of(key, missingKey), emptySet())
            .stream()
            .map(v -> v.validator.pubkey.toHexString())
            .collect(toList());
    assertThat(pubkeys).containsExactly(key);
  }
"
"  @Test
  public void validatorParameterToIndex_shouldThrowBadRequestExceptionWhenIndexInvalid() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    assertThrows(BadRequestException.class, () -> provider.validatorParameterToIndex(""a""));
  }
"
"  @Test
  public void validatorParameterToIndex_shouldReturnEmptyIfIndexOutOfBounds() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    assertThat(provider.validatorParameterToIndex(""1024000"")).isEmpty();
  }
"
"  @Test
  public void validatorParameterToIndex_shouldThrowBadRequestExceptionWhenKeyNotFound() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    assertThrows(
        BadRequestException.class,
        () -> provider.validatorParameterToIndex(Bytes32.fromHexString(""0x00"").toHexString()));
  }
"
"  @Test
  public void filteredValidatorsList_shouldFilterByValidatorStatus() {
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(11);
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThat(
            provider.getFilteredValidatorList(
                internalState, emptyList(), Set.of(ValidatorStatus.pending_initialized)))
        .hasSize(11);
    assertThat(
            provider.getFilteredValidatorList(
                internalState, emptyList(), Set.of(ValidatorStatus.active_ongoing)))
        .hasSize(0);
  }
"
"  @Test
  public void getStateCommittees_shouldReturnEmptyIfStateNotFound()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    assertThat(
            provider
                .getStateCommittees(
                    data.randomBytes32().toHexString(),
                    Optional.empty(),
                    Optional.empty(),
                    Optional.empty())
                .get())
        .isEmpty();
  }
"
"  @Test
  public void getCommitteesFromState_shouldNotRequireFilters() {
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(64);
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThat(
            provider
                .getCommitteesFromState(
                    internalState, Optional.empty(), Optional.empty(), Optional.empty())
                .size())
        .isEqualTo(specConfig.getSlotsPerEpoch());
  }
"
"  @Test
  public void getCommitteesFromState_shouldFilterOnSlot() {
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(64);
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThat(
            provider
                .getCommitteesFromState(
                    internalState,
                    Optional.empty(),
                    Optional.empty(),
                    Optional.of(internalState.getSlot()))
                .size())
        .isEqualTo(1);
  }
"
"  @Test
  public void getStateFinalityCheckpoints_shouldGetEmptyCheckpointsBeforeFinalized()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThat(provider.getStateFinalityCheckpoints(""genesis"").get().get())
        .isEqualTo(
            new FinalityCheckpointsResponse(
                tech.pegasys.teku.api.schema.Checkpoint.EMPTY,
                tech.pegasys.teku.api.schema.Checkpoint.EMPTY,
                tech.pegasys.teku.api.schema.Checkpoint.EMPTY));
  }
"
"  @Test
  public void getStateFinalityCheckpoints_shouldGetCheckpointsAfterFinalized()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, mockCombinedChainDataClient);
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(UInt64.valueOf(42));
    final FinalityCheckpointsResponse expected =
        new FinalityCheckpointsResponse(
            new tech.pegasys.teku.api.schema.Checkpoint(
                internalState.getPrevious_justified_checkpoint()),
            new tech.pegasys.teku.api.schema.Checkpoint(
                internalState.getCurrent_justified_checkpoint()),
            new tech.pegasys.teku.api.schema.Checkpoint(internalState.getFinalized_checkpoint()));

    when(mockCombinedChainDataClient.getBestState()).thenReturn(Optional.of(internalState));
    assertThat(provider.getStateFinalityCheckpoints(""head"").get().get()).isEqualTo(expected);
    verify(mockCombinedChainDataClient).getBestState();
  }
"
"  @Test
  public void getStateSyncCommittees_shouldGetCommittees()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider = setupAltairState();
    final List<UInt64> committeeIndices =
        List.of(UInt64.valueOf(6), UInt64.valueOf(9), UInt64.valueOf(0));

    final SafeFuture<Optional<StateSyncCommittees>> future =
        provider.getStateSyncCommittees(""head"", Optional.empty());
    assertThat(future).isCompleted();
    assertThat(future.get().get())
        .isEqualTo(new StateSyncCommittees(committeeIndices, List.of(committeeIndices)));
  }
"
"  @Test
  public void getStateSyncCommittees_shouldReturnEmptyListBeforeAltair()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState();
    when(mockCombinedChainDataClient.getBestState()).thenReturn(Optional.of(internalState));

    final SafeFuture<Optional<StateSyncCommittees>> future =
        provider.getStateSyncCommittees(""head"", Optional.empty());
    assertThat(future.get().get()).isEqualTo(new StateSyncCommittees(List.of(), List.of()));
  }
"
"  @Test
  public void getStateSyncCommittees_shouldRejectFarFutureEpoch() {
    final ChainDataProvider provider = setupAltairState();
    final SafeFuture<Optional<StateSyncCommittees>> future =
        provider.getStateSyncCommittees(""head"", Optional.of(UInt64.valueOf(""1024000"")));
    SafeFutureAssert.assertThatSafeFuture(future)
        .isCompletedExceptionallyWith(IllegalArgumentException.class);
  }
"
"  @Test
  public void getStateFork_shouldGetForkAtGenesis()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    final Bytes4 bytes4 = Bytes4.fromHexString(""0x00000001"");
    final Optional<Fork> response = provider.getStateFork(""genesis"").get();
    assertThat(response).isPresent();
    assertThat(response.get()).isEqualTo(new Fork(bytes4, bytes4, ZERO));
  }
"
"  @Test
  public void getValidatorBalancesFromState_shouldGetBalances() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(1024);
    assertThat(provider.getValidatorBalancesFromState(internalState, emptyList())).hasSize(1024);

    assertThat(
            provider.getValidatorBalancesFromState(
                internalState, List.of(""0"", ""100"", ""1023"", ""1024"", ""1024000"")))
        .hasSize(3);
  }
"
"  @Test
  public void getBlockRoot_shouldReturnRootOfBlock() throws Exception {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final Optional<Root> response = provider.getBlockRoot(""head"").get();
    assertThat(response).isPresent();
    assertThat(response.get()).isEqualTo(new Root(bestBlock.getRoot()));
  }
"
"  @Test
  public void getBlockAttestations_shouldReturnAttestationsOfBlock() throws Exception {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    ChainBuilder chainBuilder = storageSystem.chainBuilder();

    ChainBuilder.BlockOptions blockOptions = ChainBuilder.BlockOptions.create();
    AttestationGenerator attestationGenerator =
        new AttestationGenerator(spec, chainBuilder.getValidatorKeys());
    tech.pegasys.teku.spec.datastructures.operations.Attestation attestation1 =
        attestationGenerator.validAttestation(bestBlock.toUnsigned(), bestBlock.getSlot());
    tech.pegasys.teku.spec.datastructures.operations.Attestation attestation2 =
        attestationGenerator.validAttestation(
            bestBlock.toUnsigned(), bestBlock.getSlot().increment());
    blockOptions.addAttestation(attestation1);
    blockOptions.addAttestation(attestation2);
    SignedBlockAndState newHead =
        storageSystem
            .chainBuilder()
            .generateBlockAtSlot(bestBlock.getSlot().plus(10), blockOptions);
    storageSystem.chainUpdater().saveBlock(newHead);
    storageSystem.chainUpdater().updateBestBlock(newHead);

    final Optional<List<Attestation>> response = provider.getBlockAttestations(""head"").get();
    assertThat(response).isPresent();
    assertThat(response.get())
        .containsExactly(new Attestation(attestation1), new Attestation(attestation2));
  }
"
"  @Test
  public void headSelector_shouldGetBestBlock() throws ExecutionException, InterruptedException {
    when(client.getBestBlock()).thenReturn(Optional.of(block));
    List<SignedBeaconBlock> blockList = blockSelectorFactory.headSelector().getBlock().get();
    verify(client).getBestBlock();
    assertThat(blockList).containsExactly(block);
  }
"
"  @Test
  public void finalizedSelector_shouldGetFinalizedBlock()
      throws ExecutionException, InterruptedException {
    when(client.getFinalizedBlock()).thenReturn(Optional.of(block));
    List<SignedBeaconBlock> blockList = blockSelectorFactory.finalizedSelector().getBlock().get();
    verify(client).getFinalizedBlock();
    assertThat(blockList).containsExactly(block);
  }
"
"  @Test
  public void genesisSelector_shouldGetSlotZero() throws ExecutionException, InterruptedException {
    when(client.getBlockAtSlotExact(UInt64.ZERO))
        .thenReturn(SafeFuture.completedFuture(Optional.of(block)));
    List<SignedBeaconBlock> blockList = blockSelectorFactory.genesisSelector().getBlock().get();
    verify(client).getBlockAtSlotExact(UInt64.ZERO);
    assertThat(blockList).containsExactly(block);
  }
"
"  @Test
  public void blockRootSelector_shouldGetBlockByBlockRoot()
      throws ExecutionException, InterruptedException {
    when(client.getBlockByBlockRoot(any()))
        .thenReturn(SafeFuture.completedFuture(Optional.of(block)));
    List<SignedBeaconBlock> blockList =
        blockSelectorFactory.forBlockRoot(block.getRoot()).getBlock().get();
    verify(client).getBlockByBlockRoot(block.getRoot());
    assertThat(blockList).containsExactly(block);
  }
"
"  @Test
  public void slotSelector_shouldGetBlockAtSlotExact()
      throws ExecutionException, InterruptedException {
    when(client.getBlockAtSlotExact(block.getSlot()))
        .thenReturn(SafeFuture.completedFuture(Optional.of(block)));
    List<SignedBeaconBlock> blockList =
        blockSelectorFactory.forSlot(block.getSlot()).getBlock().get();
    verify(client).getBlockAtSlotExact(block.getSlot());
    assertThat(blockList).containsExactly(block);
  }
"
"  @Test
  public void defaultBlockSelector_shouldThrowBadRequestException() {
    assertThrows(BadRequestException.class, () -> blockSelectorFactory.defaultBlockSelector(""a""));
  }
"
"  @TestTemplate
  public void setup(SpecContext specContext) {
    spec = specContext.getSpec();
    dataStructureUtil = specContext.getDataStructureUtil();
    schemaProvider = new SchemaObjectProvider(spec);
    provider = new ValidatorDataProvider(spec, validatorApiChannel, combinedChainDataClient);
    blockInternal = dataStructureUtil.randomBeaconBlock(123);
    block = schemaProvider.getBeaconBlock(blockInternal);
  }
"
"  @TestTemplate
  public void submitSignedBlock_shouldReturn200ForSuccess()
      throws ExecutionException, InterruptedException {
    final SignedBeaconBlock internalSignedBeaconBlock =
        dataStructureUtil.randomSignedBeaconBlock(1);
    final tech.pegasys.teku.api.schema.SignedBeaconBlock signedBeaconBlock =
        tech.pegasys.teku.api.schema.SignedBeaconBlock.create(internalSignedBeaconBlock);

    final SafeFuture<SendSignedBlockResult> successImportResult =
        completedFuture(SendSignedBlockResult.success(internalSignedBeaconBlock.getRoot()));

    when(validatorApiChannel.sendSignedBlock(any())).thenReturn(successImportResult);

    final SafeFuture<ValidatorBlockResult> validatorBlockResultSafeFuture =
        provider.submitSignedBlock(signedBeaconBlock);

    assertThat(validatorBlockResultSafeFuture.get().getResponseCode()).isEqualTo(200);
  }
"
"  @TestTemplate
  public void submitSignedBlock_shouldReturn202ForInvalidBlock() {
    final SignedBeaconBlock internalSignedBeaconBlock =
        dataStructureUtil.randomSignedBeaconBlock(1);
    final tech.pegasys.teku.api.schema.SignedBeaconBlock signedBeaconBlock =
        tech.pegasys.teku.api.schema.SignedBeaconBlock.create(internalSignedBeaconBlock);
    final AtomicInteger failReasonCount = new AtomicInteger();

    Stream.of(FailureReason.values())
        .filter(failureReason -> !failureReason.equals(FailureReason.INTERNAL_ERROR))
        .forEach(
            failureReason -> {
              failReasonCount.getAndIncrement();

              final SafeFuture<SendSignedBlockResult> failImportResult =
                  completedFuture(SendSignedBlockResult.notImported(failureReason.name()));

              when(validatorApiChannel.sendSignedBlock(any())).thenReturn(failImportResult);

              final SafeFuture<ValidatorBlockResult> validatorBlockResultSafeFuture =
                  provider.submitSignedBlock(signedBeaconBlock);

              try {
                assertThat(validatorBlockResultSafeFuture.get().getResponseCode()).isEqualTo(202);
              } catch (final Exception e) {
                fail(""Exception while executing test."");
              }
            });

    // Assert that the check has run over each FailureReason except the 500.
    assertThat(failReasonCount.get()).isEqualTo(FailureReason.values().length - 1);
  }
"
"  @TestTemplate
  public void submitSignedBlock_shouldReturn500ForInternalError()
      throws ExecutionException, InterruptedException {
    final SignedBeaconBlock internalSignedBeaconBlock =
        dataStructureUtil.randomSignedBeaconBlock(1);
    final tech.pegasys.teku.api.schema.SignedBeaconBlock signedBeaconBlock =
        tech.pegasys.teku.api.schema.SignedBeaconBlock.create(internalSignedBeaconBlock);

    final SafeFuture<SendSignedBlockResult> failImportResult =
        completedFuture(SendSignedBlockResult.rejected(FailureReason.INTERNAL_ERROR.name()));

    when(validatorApiChannel.sendSignedBlock(any())).thenReturn(failImportResult);

    final SafeFuture<ValidatorBlockResult> validatorBlockResultSafeFuture =
        provider.submitSignedBlock(signedBeaconBlock);

    assertThat(validatorBlockResultSafeFuture.get().getResponseCode()).isEqualTo(500);
  }
"
"  @TestTemplate
  public void getAttesterDuties_shouldHandleEmptyIndexesList() {
    final Bytes32 previousTargetRoot = dataStructureUtil.randomBytes32();
    when(validatorApiChannel.getAttestationDuties(eq(ONE), any()))
        .thenReturn(
            completedFuture(
                Optional.of(
                    new tech.pegasys.teku.validator.api.AttesterDuties(
                        previousTargetRoot, emptyList()))));
    final SafeFuture<Optional<PostAttesterDutiesResponse>> future =
        provider.getAttesterDuties(UInt64.ONE, List.of());
    assertThat(future).isCompleted();
    Optional<PostAttesterDutiesResponse> maybeData = future.join();
    assertThat(maybeData.isPresent()).isTrue();
    assertThat(maybeData.get().data).isEmpty();
  }
"
"  @TestTemplate
  public void getAttesterDuties_shouldReturnDutiesForKnownValidator() {
    AttesterDuty v1 = new AttesterDuty(BLSTestUtil.randomPublicKey(0), 1, 2, 3, 15, 4, ONE);
    AttesterDuty v2 = new AttesterDuty(BLSTestUtil.randomPublicKey(1), 11, 12, 13, 15, 14, ZERO);
    when(validatorApiChannel.getAttestationDuties(eq(ONE), any()))
        .thenReturn(
            completedFuture(
                Optional.of(
                    new AttesterDuties(dataStructureUtil.randomBytes32(), List.of(v1, v2)))));

    final SafeFuture<Optional<PostAttesterDutiesResponse>> future =
        provider.getAttesterDuties(ONE, List.of(1, 11));
    assertThat(future).isCompleted();
    final Optional<PostAttesterDutiesResponse> maybeList = future.join();
    final PostAttesterDutiesResponse list = maybeList.orElseThrow();
    assertThat(list.data).containsExactlyInAnyOrder(asAttesterDuty(v1), asAttesterDuty(v2));
  }
"
"  @Test
  public void headSelector_shouldGetBestState() throws ExecutionException, InterruptedException {
    when(client.getBestState()).thenReturn(Optional.of(state));
    Optional<BeaconState> result = factory.headSelector().getState().get();
    assertThat(result).isEqualTo(Optional.of(state));
    verify(client).getBestState();
  }
"
"  @Test
  public void finalizedSelector_shouldGetFinalizedState()
      throws ExecutionException, InterruptedException {
    when(client.getFinalizedState()).thenReturn(Optional.of(state));
    Optional<BeaconState> result = factory.finalizedSelector().getState().get();
    assertThat(result).isEqualTo(Optional.of(state));
    verify(client).getFinalizedState();
  }
"
"  @Test
  public void justifiedSelector_shouldGetJustifiedState()
      throws ExecutionException, InterruptedException {
    when(client.getJustifiedState()).thenReturn(SafeFuture.completedFuture(Optional.of(state)));
    Optional<BeaconState> result = factory.justifiedSelector().getState().get();
    assertThat(result).isEqualTo(Optional.of(state));
    verify(client).getJustifiedState();
  }
"
"  @Test
  public void genesisSelector_shouldGetStateAtSlotExact()
      throws ExecutionException, InterruptedException {
    when(client.getStateAtSlotExact(ZERO))
        .thenReturn(SafeFuture.completedFuture(Optional.of(state)));
    Optional<BeaconState> result = factory.genesisSelector().getState().get();
    assertThat(result).isEqualTo(Optional.of(state));
    verify(client).getStateAtSlotExact(ZERO);
  }
"
"  @Test
  public void forSlot_shouldGetStateAtSlotExact() throws ExecutionException, InterruptedException {
    when(client.getStateAtSlotExact(state.getSlot()))
        .thenReturn(SafeFuture.completedFuture(Optional.of(state)));
    Optional<BeaconState> result = factory.forSlot(state.getSlot()).getState().get();
    assertThat(result).isEqualTo(Optional.of(state));
    verify(client).getStateAtSlotExact(state.getSlot());
  }
"
"  @Test
  public void forStateRoot_shouldGetStateAtSlotExact()
      throws ExecutionException, InterruptedException {
    when(client.getStateByStateRoot(state.hashTreeRoot()))
        .thenReturn(SafeFuture.completedFuture(Optional.of(state)));
    Optional<BeaconState> result = factory.forStateRoot(state.hashTreeRoot()).getState().get();
    assertThat(result).isEqualTo(Optional.of(state));
    verify(client).getStateByStateRoot(state.hashTreeRoot());
  }
"
"  @Test
  public void defaultStateSelector_shouldThrowBadRequestException() {
    assertThrows(BadRequestException.class, () -> factory.defaultStateSelector(""a""));
  }
"
"  @Test
  public void byBlockRootSelector_shouldThrowBadRequestException() {
    assertThrows(BadRequestException.class, () -> factory.byBlockRootStateSelector(""a""));
  }
"
"  @Test
  public void stateSelector_shouldReturnEmptyWhenPreForkChoice()
      throws ExecutionException, InterruptedException {
    final StorageQueryChannel historicalChainData = mock(StorageQueryChannel.class);
    final RecentChainData recentChainData = mock(RecentChainData.class);
    final CombinedChainDataClient client1 =
        new CombinedChainDataClient(recentChainData, historicalChainData, spec);
    final StateSelectorFactory factory = new StateSelectorFactory(client1);
    when(recentChainData.isPreGenesis()).thenReturn(false);
    when(recentChainData.isPreForkChoice()).thenReturn(true);
    final SafeFuture<Optional<BeaconState>> future =
        factory.defaultStateSelector(ZERO.toString()).getState();
    assertThat(future.get()).isEmpty();
  }
"
"  @Test
  public void defaultBlockSelector_shouldThrowBadRequestForBadHexState() {
    assertThrows(BadRequestException.class, () -> factory.defaultStateSelector(""0xzz""));
  }
"
"  @TestTemplate
  public void validatorsResponseShouldConformToDefaults(SpecContext ctx) {
    BeaconState beaconState = ctx.getDataStructureUtil().randomBeaconState();
    SszList<Validator> validatorList = beaconState.getValidators();
    BeaconValidators response = new BeaconValidators(beaconState, FAR_FUTURE_EPOCH);
    assertThat(response.total_size).isEqualTo(beaconState.getValidators().size());
    assertThat(response.validators.size())
        .isEqualTo(Math.min(validatorList.size(), PAGE_SIZE_DEFAULT));
    int expectedNextPageToken =
        validatorList.size() < PAGE_SIZE_DEFAULT ? 0 : PAGE_TOKEN_DEFAULT + 1;
    assertThat(response.next_page_token).isEqualTo(expectedNextPageToken);
    assertThat(response.validators.get(0).validator.activation_eligibility_epoch)
        .isEqualToComparingFieldByField(validatorList.get(0).getActivation_eligibility_epoch());
    assertThat(response.validators.get(0).validator_index).isEqualTo(0);
  }
"
"    @Test
    public void testUnionSource() {
        DatasetAccessor accessor = source.getAccessor();
        accessor.add(TEST + ""g1"", createGraph(""graph1""));
        accessor.add(TEST + ""g2"", createGraph(""graph2""));
        TestUtil.testArray(checkGraphs(), new String[]{""graph1"", ""graph2""});
        
        accessor.putModel(TEST + ""g1"", createGraph(""graph1-b""));
        TestUtil.testArray(checkGraphs(), new String[]{""graph1-b"", ""graph2""});
        
        accessor.deleteModel(TEST + ""g2"");
        TestUtil.testArray(checkGraphs(), new String[]{""graph1-b""});
    }
"
"    @Test
    public void testAll() {
        assertEquals(5, numMatches(""'Somerset'""));
        
        // These options would require per-predicate text index
//        assertEquals(2, numMatches(""(rdfs:label 'Somerset')""));
//        assertEquals(3, numMatches(""(eg:label   'Somerset')""));
    }
"
"    @Test
    public void testWrapper() {
        // Labels
        assertEquals(""Pref label"", getNode(""test:i1"").getLabel());
        assertEquals(""Alt label"",  getNode(""test:i2"").getLabel());
        assertEquals(""rdfs label"", getNode(""test:i3"").getLabel());
        assertEquals(""name"",       getNode(""test:i4"").getLabel());
        
        WNode node = getNode(""test:i5"");
        assertEquals(""en label"", node.getLabel(""en""));
        assertEquals(""plain label"", node.getLabel(""cy""));
        
        assertTrue(node.isResource());
        assertTrue(node.isURIResource());
        assertFalse(node.isLiteral());
        assertEquals(""http://www.epimorphics.com/vocabs/test/i5"", node.getURI());
        
        DatasetGraph dsg = source.constructViews(""?uri skos:altLabel ?rdfs_label"", TEST_NS + ""i1"", TEST_NS + ""i2"");
        checkLabel(dsg, ""i1"", ""Alt label"");
        checkLabel(dsg, ""i2"", ""Alt label"");
        
        // General accessors
        WNode test = getNode(""test:test"");
        WNode v = test.getPropertyValue(""test:num"");
        assertNotNull(v);
        assertTrue(v.isLiteral());
        assertTrue(v.isNumber());
        assertEquals(42, v.asInt());
        
        v = test.getPropertyValue(""test:float"");
        assertNotNull(v);
        assertTrue(v.isLiteral());
        assertTrue(v.isNumber());
        assertEquals(3.14, v.asFloat(), 0.001);
        
        v = test.getPropertyValue(""test:string"");
        assertNotNull(v);
        assertEquals(""a string"", v.getLabel());
        
        List<WNode> values = test.listPropertyValues(""test:resource"");
        assertEquals(2, values.size());
        TestUtil.testArray(values, new WNode[]{ getNode(""test:i1""), getNode(""test:i2"")});
        
        // Lists
        WNode list = test.getPropertyValue(""test:list"");
        assertNotNull(list);
        assertTrue(list.isList());
        List<WNode> elts = list.asList();
        assertEquals(3,  elts.size());
        assertEquals(1, elts.get(0).asInt());
        assertEquals(3, elts.get(1).asInt());
        assertEquals(5, elts.get(2).asInt());
        
        // Connections
        checkConnections( getNode(""test:c"").listInLinks(""test:p""), new String[]{""test:a"", ""test:b""} );
        checkConnections( getNode(""test:d"").listInLinks(""test:p""), new String[]{""test:c""} );
        checkConnections( getNode(""test:c"").listInLinks(""test:q""), new String[]{""test:f""} );

        checkConnections( getNode(""test:c"").connectedNodes(""test:p / test:p""), new String[]{""test:e""} );
        
        List<PropertyValue> connections = getNode(""test:c"").listInLinks();
        assertEquals(2, connections.size());
        assertEquals(getNode(""test:p""), connections.get(0).getProp());
        checkConnections( connections.get(0).getValues(), new String[]{""test:a"", ""test:b""});
        assertEquals(getNode(""test:q""), connections.get(1).getProp());
        checkConnections( connections.get(1).getValues(), new String[]{""test:f""});
        
        // Text search
        List<WNode> matches = source.search(""aa"");
        assertEquals(1, matches.size());
        checkConnections(matches, new String[]{""test:a""});

        matches = source.search(""label"");
        assertEquals(4, matches.size());
        checkConnections(matches, new String[]{""test:i1"", ""test:i2"", ""test:i3"", ""test:i5""});
        
        matches = source.search(""label"", 2);
        assertEquals(2, matches.size());
        
        matches = source.search(""pref"");
        assertEquals(1, matches.size());
        checkConnections(matches, new String[]{""test:i1""});
    }
"
"    @Test
    public void testQuery() {
        List<Literal> literals = SQueryUtil.selectLiteralVar(""x"", ""SELECT ?x WHERE {test:i1 ?p ?x}"", ssource, app.getPrefixes());
        TestUtil.testArray(literals, new Literal[]{
                ResourceFactory.createPlainLiteral(""name""),
                ResourceFactory.createPlainLiteral(""rdfs label""),
                ResourceFactory.createPlainLiteral(""Alt label""),
                ResourceFactory.createPlainLiteral(""Pref label""),
        });
        
        List<Resource> resources = SQueryUtil.selectResourceVar(""x"", ""SELECT ?x WHERE {test:i1 ?p ?x}"", ssource, app.getPrefixes());
        TestUtil.testArray(resources, new Resource[]{
                ResourceFactory.createResource(TEST_NS + ""Sample"")
        });
    }
"
"    @Test
    public void testStreamableSelect() {
        String query = PrefixUtils.expandQuery(""SELECT ?x WHERE {test:i1 a ?x}"", app.getPrefixes());
        ClosableResultSet results = ssource.streamableSelect(query);
        try {
            assertTrue(results.hasNext());
            assertEquals(ResourceFactory.createResource(TEST_NS + ""Sample""), results.next().getResource(""x""));
            assertFalse(results.hasNext());
        } finally {
            results.close();
        }
    }
"
"    @Test
    public void testUpdate() {
        assertTrue( ssource.isUpdateable() );
        String update = """" +
        		""PREFIX test: <http://www.epimorphics.com/vocabs/test/> \n"" +
        		""DELETE {?x test:string ?s}\n"" +
        		""INSERT {?x test:string 'new string'}\n"" +
        		""WHERE {?x test:num 42}"";
        ssource.update( UpdateFactory.create(update) );
        
        WNode v = getNode(""test:test"").getPropertyValue(""test:string"");
        assertNotNull(v);
        assertEquals(""new string"", v.getLabel());
    }
"
"    @Ignore @Test
    public void testRemoveSource() {
        setup();
        
        assertTrue(source.isUpdateable());
        
        DatasetAccessor accessor = source.getAccessor();
        for (int i = 0; i < 2; i++) {
            Model m = ModelFactory.createDefaultModel();
            m.createResource(TEST + ""i"" + i)
                .addProperty(RDFS.label, ""In graph "" + i);
            accessor.putModel(TEST + ""g"" + i, m);
        }
        
        checkLabels(new String[]{""In graph 0"", ""In graph 1""});

        String update = """" +
                ""PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \n"" +
                ""WITH <http://localhost/test/def#g1> \n"" +
                ""DELETE {?x rdfs:label ?l} \n"" +
                ""INSERT {?x rdfs:label 'new string'} \n"" +
                ""WHERE {?x rdfs:label ?l}"";
        source.update( UpdateFactory.create(update) );

        checkLabels(new String[]{""In graph 0"", ""new string""});

        // clean up
        for (int i = 0; i < 2; i++) {
            accessor.deleteModel(TEST + ""g"" + i);
        }
        app.shutdown();
    }
"
"    @Test
    public void testSimpleActions() {
        ActionExecution ae = runAction(""messageThrice"", ""message=test"");
        ProgressMonitorReporter pm = ae.getMonitor();
        assertTrue(pm.succeeded());
        assertEquals(5, pm.getMessages().size());
        assertTrue( pm.getMessages().get(0).getMessage().startsWith(""messageThrice"") );
        assertEquals( ""test"", pm.getMessages().get(1).getMessage() );
        
        pm = runAction(""helloThrice"", """").getMonitor();
        assertTrue(pm.succeeded());
        assertEquals(5, pm.getMessages().size());
        assertTrue( pm.getMessages().get(0).getMessage().startsWith(""helloThrice"") );
        assertEquals( ""Hello"", pm.getMessages().get(1).getMessage() );
        
    }
"
"    @Test
    public void testErrorHander() throws InterruptedException {
        ActionExecution ae = runAction(""testErrorHandler"", """");
//        dumpState(ae);
        ProgressMonitorReporter pm = ae.getMonitor();
        assertFalse(pm.succeeded());
        assertEquals(2, pm.getMessages().size());
        assertTrue( pm.getMessages().get(0).getMessage().contains(""Forcing error from CreateErrorAction"") );
        assertEquals( ""Error detected"", pm.getMessages().get(1).getMessage() );

        ae = runAction(""testErrorTimeout"", """");
        Thread.sleep(10);  // Allow time out processing to complete, more robust way?
        pm = ae.getMonitor();
        assertFalse(pm.succeeded());
        List<ProgressMessage> messages = pm.getMessages();
        assertEquals( ""Timeout detected"", messages.get(messages.size() - 1).getMessage());
    }
"
"    @Test
    public void testCompoundflows() throws InterruptedException {
        ActionExecution ae = runAction(""sequenceTest"", """");
        ProgressMonitorReporter pm = ae.getMonitor();
        assertTrue(pm.succeeded());
        List<ProgressMessage> messages = pm.getMessages();
        assertEquals(3, messages.size());
        assertEquals(""sequence 1"", messages.get(0).getMessage());
        assertEquals(""sequence 2"", messages.get(1).getMessage());
        assertEquals(""sequence 3"", messages.get(2).getMessage());

        ae = runAction(""parTest"", """");
//        dumpState(ae);
        pm = ae.getMonitor();
        assertTrue(pm.succeeded());
        messages = pm.getMessages();
        assertEquals(3, messages.size());
        for (int i = 0; i < 3; i++) {
            assertTrue( messages.get(i).getMessage().matches(""par [123]"") );
        }
    }
"
"    @Test
    public void testEvents() {
        RecordingAction.reset();
        List<ActionExecution> aes = new ArrayList<>();
        aes.addAll( am.fireEvent(""test/foo"", createParams("""")) );
        aes.addAll( am.fireEvent(""miss/foo"", createParams("""")) );
        aes.addAll( am.fireEvent(""test/bar"", createParams("""")) );
        for (ActionExecution ae : aes) {
            ae.waitForCompletion();
        }
        List<String> firings = RecordingAction.getMessages();
        assertEquals(2, firings.size());
        assertTrue( 
                (firings.get(0).equals(""fired - test/foo"") && firings.get(1).equals(""fired - test/bar"")) 
                ||
                (firings.get(0).equals(""fired - test/bar"") && firings.get(1).equals(""fired - test/foo"")) 
                );
        RecordingAction.reset();
    }
"
"    @Test
    public void testJSONSerialize() throws IOException {
        SimpleProgressMonitor monitor = new SimpleProgressMonitor();
        monitor.setState(TaskState.Running);
        monitor.setProgress(42);
//        monitor.setSuccess(true);
        monitor.report(""message 1"");
        monitor.report(""message 2"");
        
        ByteArrayOutputStream bos = new ByteArrayOutputStream();
        JSFullWriter out = new JSFullWriter(bos);
        monitor.writeTo(out);
        out.finishOutput();
        
        String serialization = bos.toString();
//        System.out.println(serialization);
        
        JsonObject object = JSON.parse( serialization );
        assertEquals( 42,       object.get(""progress"").getAsNumber().value().intValue());
        assertEquals(""Running"", object.get(""state"").getAsString().value());
        assertEquals( true,     object.get(""succeeded"").getAsBoolean().value());
        JsonArray messages = object.get(""messages"").getAsArray();
        assertEquals( 2,        messages.size());
        JsonObject m = messages.get(1).getAsObject();
        assertEquals( ""message 2"",   m.get(""message"").getAsString().value());
    }
"
"    @Test
    public void testSimpleActions() throws InterruptedException, ExecutionException {
        Action action = new DummyAction();
        ActionManager am = new ActionManager();
        am.register(action);
        
        ActionManager.ActionExecution ae1 = am.runAction(action, createParams(""message=Test message,count=2""));
        ActionManager.ActionExecution ae2 = am.runAction(action, createParams(""message=Test message long,count=50""));

        assertEquals(2, am.listActiveExecutions().size());
        
        ae1.waitForCompletion();
//        dumpState(ae1);
        List<ProgressMessage> messages = ae1.getMonitor().getMessages();
        assertEquals(4, messages.size());
        assertTrue(messages.get(messages.size() - 1).toString().endsWith(""finished""));
        assertEquals(1, am.listActiveExecutions().size());
        assertTrue(ae1.getMonitor().succeeded());
        
        ae2.waitForCompletion();
//        dumpState(ae2);
        Thread.sleep(10);  // Allow ActionManager to see the timeout and update the action state list, more robust method?
        messages = ae2.getMonitor().getMessages();
        assertTrue(messages.size() < 50);
        assertTrue(messages.get(messages.size() - 1).toString().endsWith(""timeout""));
        assertFalse(ae2.getMonitor().succeeded());
            
        assertEquals(0, am.listActiveExecutions().size());

        assertEquals(ae1, am.getExecution(ae1.getId()));
        assertEquals(ae2, am.getExecution(ae2.getId()));
    }
"
"    @Test
    public void testRender() {
        ClientResponse response = getResponse(BASE_URL + ""/test?arg=foo"", ""text/hml"");
        assertEquals(200, response.getStatus());
        
        // Should do testing base on HTML structure if can figure the right library for that, in the meantime ...
        List<String> paras = findmatches(response.getEntity(String.class), ""<p>([^<]*)</p>"");
        assertEquals(""Hello there from myapp (parameter = This is a string)"", paras.get(0));
        assertEquals(""Query param arg = foo"", paras.get(1));
        assertEquals(""Component1.prop1 = Component 1 name"", paras.get(2));
        assertEquals(""Library plugin: Hello from lib plugin - myplugin in application myapp"", paras.get(3));
    }
"
"    @Test
    public void testConfig() {
        App app = AppConfig.getApp();
        assertEquals(""This is a string"", app.getParam(""stringParam""));
        assertEquals(new Long(42), app.getParam(""intParam""));
        
        TrialBean component1 = app.getComponentAs(""component1"", TrialBean.class);
        assertEquals(""name 1"", component1.getProp1());
        assertEquals(1, component1.getProplong());
        assertEquals(true, component1.isProp());
        
        TrialBean component2 = app.getComponentAs(""component2"", TrialBean.class);
        assertEquals(""name 2"", component2.getProp1());
        assertEquals(component1, component2.getRef());
        assertEquals(false, component2.isProp());
        
        TrialBean component3 = app.getComponentAs(""component3"", TrialBean.class);
        List<Object> xref = component3.getXref();
        assertNotNull(xref);
        assertEquals(2, xref.size());
        assertEquals(component1, xref.get(0));
        assertEquals(component2, xref.get(1));
    }
"
"    @Test
    public void testSuperClass() {
        assertThat(classNode.superName)
                .doesNotStartWith(SHADED_PACKAGE_PATH);
    }
"
"    @Test
    public void testInterfaces() {
        assertThat(classNode.interfaces)
                .allSatisfy(it -> assertThat(it).doesNotStartWith(SHADED_PACKAGE_PATH));
    }
"
"    @Test
    public void testMethodReturnTypes() {
        assertThat(classNode.methods)
                .filteredOn(it -> (it.access & (Opcodes.ACC_PUBLIC | Opcodes.ACC_PROTECTED)) != 0)
                .allSatisfy(it -> assertThat(Type.getReturnType(it.desc).getClassName()).doesNotStartWith(SHADED_PACKAGE));
    }
"
"    @Test
    public void testMethodArguments() {
        assertThat(classNode.methods)
                .filteredOn(it -> (it.access & (Opcodes.ACC_PUBLIC | Opcodes.ACC_PROTECTED)) != 0)
                .allSatisfy(method -> assertThat(Arrays.asList(Type.getArgumentTypes(method.desc)))
                        .extracting(Type::getClassName)
                        .allSatisfy(it -> assertThat(it).doesNotStartWith(SHADED_PACKAGE))
                );
    }
"
"    @Test
    public void testFields() {
        assertThat(classNode.fields)
                .filteredOn(it -> (it.access & (Opcodes.ACC_PUBLIC | Opcodes.ACC_PROTECTED)) != 0)
                .allSatisfy(it -> assertThat(Type.getType(it.desc).getClassName())
                        .doesNotStartWith(SHADED_PACKAGE)
                );
    }
"
"    @Test
    public void testPackages() throws Exception {
        assertThatFileList(root).containsOnly(
                ""docker-java.properties"",
                ""org"",
                ""META-INF"",
                ""com""
        );

        assertThatFileList(root.resolve(""org"")).containsOnly(
                ""testcontainers""
        );

        assertThatFileList(root.resolve(""com"")).containsOnly(
                ""github""
        );

        assertThatFileList(root.resolve(""com"").resolve(""github"")).containsOnly(
                ""dockerjava""
        );
    }
"
"    @Test
    public void testMetaInf() throws Exception {
        assertThatFileList(root.resolve(""META-INF"")).containsOnly(
                ""MANIFEST.MF"",
                ""services"",
                ""native""
        );

        assertThatFileList(root.resolve(""META-INF"").resolve(""native"")).containsOnly(
                ""liborg-testcontainers-shaded-netty-transport-native-epoll.so"",
                ""liborg-testcontainers-shaded-netty-transport-native-kqueue.jnilib""
        );
    }
"
"    @Test
    public void testMetaInfServices() throws Exception {
        assertThatFileList(root.resolve(""META-INF"").resolve(""services""))
                .allMatch(it -> it.startsWith(""org.testcontainers.""));
    }
"
"    @Test
    public void testForExistingNames() {
        LicenseAcceptance.assertLicenseAccepted(""a"");
        LicenseAcceptance.assertLicenseAccepted(""b"");
    }
"
"    @Test(expected = IllegalStateException.class)
    public void testForMissingNames() {
        LicenseAcceptance.assertLicenseAccepted(""c"");
    }
"
"    @Test
    public void validNames() {
        testValid(""myname:latest"");
        testValid(""myname:latest"");
        testValid(""repo/my-name:1.0"");
        testValid(""repo.foo.com:1234/my-name:1.0"");
        testValid(""repo.foo.com/my-name:1.0"");
        testValid(""repo.foo.com:1234/repo_here/my-name:1.0"");
        testValid(""repo.foo.com:1234/repo-here/my-name@sha256:1234abcd1234abcd1234abcd1234abcd"");
        testValid(""repo.foo.com:1234/my-name@sha256:1234abcd1234abcd1234abcd1234abcd"");
        testValid(""1.2.3.4/my-name:1.0"");
        testValid(""1.2.3.4:1234/my-name:1.0"");
        testValid(""1.2.3.4/repo-here/my-name:1.0"");
        testValid(""1.2.3.4:1234/repo-here/my-name:1.0"");
    }
"
"    @Test
    public void invalidNames() {
        testInvalid(""myname"");
        testInvalid("":latest"");
        testInvalid(""/myname:latest"");
        testInvalid(""/myname@sha256:latest"");
        testInvalid(""/myname@sha256:gggggggggggggggggggggggggggggggg"");
        testInvalid(""repo:notaport/myname:latest"");
    }
"
"    @Test
    public void testLazyness() throws Exception {
        AtomicInteger counter = new AtomicInteger();

        Future<Integer> lazyFuture = new LazyFuture<Integer>() {
            @Override
            protected Integer resolve() {
                return counter.incrementAndGet();
            }
        };

        assertEquals(""No resolve() invocations before get()"", 0, counter.get());
        assertEquals(""get() call returns proper result"", 1, lazyFuture.get());
        assertEquals(""resolve() was called only once after single get() call"", 1, counter.get());

        counter.incrementAndGet();
        assertEquals(""result of resolve() must be cached"", 1, lazyFuture.get());
    }
"
"    @Test(timeout = 5_000)
    public void timeoutWorks() throws Exception {
        Future<Void> lazyFuture = new LazyFuture<Void>() {
            @Override
            @SneakyThrows(InterruptedException.class)
            protected Void resolve() {
                TimeUnit.MINUTES.sleep(1);
                return null;
            }
        };

        assertThrows(""Should timeout"", TimeoutException.class, () -> lazyFuture.get(10, TimeUnit.MILLISECONDS));
        pass(""timeout works"");
    }
"
"    @Test(timeout = 5_000)
    public void testThreadSafety() throws Exception {
        final int numOfThreads = 3;
        CountDownLatch latch = new CountDownLatch(numOfThreads);
        AtomicInteger counter = new AtomicInteger();

        Future<Integer> lazyFuture = new LazyFuture<Integer>() {
            @Override
            @SneakyThrows(InterruptedException.class)
            protected Integer resolve() {
                latch.await();
                return counter.incrementAndGet();
            }
        };

        Future<List<Integer>> task = new ForkJoinPool(numOfThreads).submit(() -> {
            return IntStream.rangeClosed(1, numOfThreads).parallel().mapToObj(i -> Futures.getUnchecked(lazyFuture)).collect(toList());
        });

        while (latch.getCount() > 0) {
            latch.countDown();
        }

        assertEquals(""All threads receives the same result"", Collections.nCopies(numOfThreads, 1), task.get());
    }
"
"    @Test
    public void testRunning() throws Exception {
        assertTrue(DockerStatus.isContainerRunning(running, minimumDuration, now));
        assertTrue(DockerStatus.isContainerRunning(runningVariant, minimumDuration, now));
        assertFalse(DockerStatus.isContainerRunning(shortRunning, minimumDuration, now));
        assertFalse(DockerStatus.isContainerRunning(created, minimumDuration, now));
        assertFalse(DockerStatus.isContainerRunning(createdVariant, minimumDuration, now));
        assertFalse(DockerStatus.isContainerRunning(exited, minimumDuration, now));
        assertFalse(DockerStatus.isContainerRunning(paused, minimumDuration, now));
    }
"
"    @Test
    public void testStopped() throws Exception {
        assertFalse(DockerStatus.isContainerStopped(running));
        assertFalse(DockerStatus.isContainerStopped(runningVariant));
        assertFalse(DockerStatus.isContainerStopped(shortRunning));
        assertFalse(DockerStatus.isContainerStopped(created));
        assertFalse(DockerStatus.isContainerStopped(createdVariant));
        assertTrue(DockerStatus.isContainerStopped(exited));
        assertFalse(DockerStatus.isContainerStopped(paused));
    }
"
"    @Test
    public void testCompareVersionGreaterThanSameMajor() {
        assertTrue(""1.22 > 1.20"", new ComparableVersion(""1.22"").compareTo(new ComparableVersion(""1.20"")) == 1);
    }
"
"    @Test
    public void testCompareVersionEqual() {
        assertTrue(""1.20 == 1.20"", new ComparableVersion(""1.20"").compareTo(new ComparableVersion(""1.20"")) == 0);
    }
"
"    @Test
    public void testCompareVersionGreaterThan() {
        assertTrue(""2.10 > 1.20"", new ComparableVersion(""2.10"").compareTo(new ComparableVersion(""1.20"")) == 1);
    }
"
"    @Test
    public void testCompareVersionIgnoresExcessLength() {
        assertTrue(""1.20 == 1.20.3"", new ComparableVersion(""1.20"").compareTo(new ComparableVersion(""1.20.3"")) == 0);
    }
"
"    @Test
    public void forClasspathResource() throws Exception {
        final MountableFile mountableFile = MountableFile.forClasspathResource(""mappable-resource/test-resource.txt"");

        performChecks(mountableFile);
    }
"
"    @Test
    public void forClasspathResourceWithAbsolutePath() throws Exception {
        final MountableFile mountableFile = MountableFile.forClasspathResource(""/mappable-resource/test-resource.txt"");

        performChecks(mountableFile);
    }
"
"    @Test
    public void forClasspathResourceFromJar() throws Exception {
        final MountableFile mountableFile = MountableFile.forClasspathResource(""META-INF/dummy_unique_name.txt"");

        performChecks(mountableFile);
    }
"
"    @Test
    public void forClasspathResourceFromJarWithAbsolutePath() throws Exception {
        final MountableFile mountableFile = MountableFile.forClasspathResource(""/META-INF/dummy_unique_name.txt"");

        performChecks(mountableFile);
    }
"
"    @Test
    public void forHostPath() throws Exception {
        final Path file = createTempFile(""somepath"");
        final MountableFile mountableFile = MountableFile.forHostPath(file.toString());

        performChecks(mountableFile);
    }
"
"    @Test
    public void forHostPathWithSpaces() throws Exception {
        final Path file = createTempFile(""some path"");
        final MountableFile mountableFile = MountableFile.forHostPath(file.toString());

        performChecks(mountableFile);

        assertTrue(""The resolved path contains the original space"", mountableFile.getResolvedPath().contains("" ""));
        assertFalse(""The resolved path does not contain an escaped space"", mountableFile.getResolvedPath().contains(""\\ ""));
    }
"
"    @Test
    public void forHostPathWithPlus() throws Exception {
        final Path file = createTempFile(""some+path"");
        final MountableFile mountableFile = MountableFile.forHostPath(file.toString());

        performChecks(mountableFile);

        assertTrue(""The resolved path contains the original space"", mountableFile.getResolvedPath().contains(""+""));
        assertFalse(""The resolved path does not contain an escaped space"", mountableFile.getResolvedPath().contains("" ""));
    }
"
"    @Test
    public void forClasspathResourceWithPermission() throws Exception {
        final MountableFile mountableFile = MountableFile.forClasspathResource(""mappable-resource/test-resource.txt"",
                TEST_FILE_MODE);

        performChecks(mountableFile);
        assertEquals(""Valid file mode."", BASE_FILE_MODE | TEST_FILE_MODE, mountableFile.getFileMode());
    }
"
"    @Test
    public void forHostFilePathWithPermission() throws Exception {
        final Path file = createTempFile(""somepath"");
        final MountableFile mountableFile = MountableFile.forHostPath(file.toString(), TEST_FILE_MODE);
        performChecks(mountableFile);
        assertEquals(""Valid file mode."", BASE_FILE_MODE | TEST_FILE_MODE, mountableFile.getFileMode());
    }
"
"    @Test
    public void forHostDirPathWithPermission() throws Exception {
        final Path dir = createTempDir();
        final MountableFile mountableFile = MountableFile.forHostPath(dir.toString(), TEST_FILE_MODE);
        performChecks(mountableFile);
        assertEquals(""Valid dir mode."", BASE_DIR_MODE | TEST_FILE_MODE, mountableFile.getFileMode());
    }
"
"    @Test
    public void simpleRecursiveFileTest() throws TimeoutException {

        WaitingConsumer wait = new WaitingConsumer();

        final ToStringConsumer toString = new ToStringConsumer();

        GenericContainer container = new GenericContainer(
                new ImageFromDockerfile()
                        .withDockerfileFromBuilder(builder ->
                                builder.from(""alpine:3.3"")
                                        .copy(""/tmp/foo"", ""/foo"")
                                        .cmd(""cat /foo/src/test/resources/test-recursive-file.txt"")
                                        .build()
                        ).withFileFromFile(""/tmp/foo"", new File(""."")))  // '.' is expected to be the project base directory, so all source code/resources should be copied in
                .withStartupCheckStrategy(new OneShotStartupCheckStrategy())
                .withLogConsumer(wait.andThen(toString));

        container.start();
        wait.waitUntilEnd(60, TimeUnit.SECONDS);

        final String results = toString.toUtf8String();

        assertTrue(""The container has a file that was copied in via a recursive copy"", results.contains(""Used for DirectoryTarResourceTest""));
    }
"
"    @Test
    public void simpleRecursiveFileWithPermissionTest() throws TimeoutException {

        WaitingConsumer wait = new WaitingConsumer();

        final ToStringConsumer toString = new ToStringConsumer();

        GenericContainer container = new GenericContainer(
                new ImageFromDockerfile()
                        .withDockerfileFromBuilder(builder ->
                                builder.from(""alpine:3.3"")
                                        .copy(""/tmp/foo"", ""/foo"")
                                        .cmd(""ls"", ""-al"", ""/"")
                                        .build()
                        ).withFileFromFile(""/tmp/foo"", new File(""/mappable-resource/test-resource.txt""),
                        0754))
                .withStartupCheckStrategy(new OneShotStartupCheckStrategy())
                .withLogConsumer(wait.andThen(toString));

        container.start();
        wait.waitUntilEnd(60, TimeUnit.SECONDS);

        String listing = toString.toUtf8String();

        assertThat(""Listing shows that file is copied with mode requested."",
                Arrays.asList(listing.split(""\\n"")),
                exactlyNItems(1, allOf(containsString(""-rwxr-xr--""), containsString(""foo""))));
    }
"
"    @Test
    public void simpleRecursiveClasspathResourceTest() throws TimeoutException {
        // This test combines the copying of classpath resources from JAR files with the recursive TAR approach, to allow JARed classpath resources to be copied in to an image

        WaitingConsumer wait = new WaitingConsumer();

        final ToStringConsumer toString = new ToStringConsumer();

        GenericContainer container = new GenericContainer(
                new ImageFromDockerfile()
                        .withDockerfileFromBuilder(builder ->
                                builder.from(""alpine:3.3"")
                                        .copy(""/tmp/foo"", ""/foo"")
                                        .cmd(""ls -lRt /foo"")
                                        .build()
                        ).withFileFromClasspath(""/tmp/foo"", ""/recursive/dir""))          // here we use /org/junit as a directory that really should exist on the classpath
                .withStartupCheckStrategy(new OneShotStartupCheckStrategy())
                .withLogConsumer(wait.andThen(toString));

        container.start();
        wait.waitUntilEnd(60, TimeUnit.SECONDS);

        final String results = toString.toUtf8String();

        // ExternalResource.class is known to exist in a subdirectory of /org/junit so should be successfully copied in
        assertTrue(""The container has a file that was copied in via a recursive copy from a JAR resource"", results.contains(""content.txt""));
    }
"
"    @Test
    public void testWaitOnListeningPort() {
        final DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/compose-test.yml""))
            .withExposedService(""redis_1"", REDIS_PORT, Wait.forListeningPort());

        try {
            environment.starting(Description.createTestDescription(Object.class, ""name""));
            VisibleAssertions.pass(""Docker compose should start after waiting for listening port"");
        } catch (RuntimeException e) {
            VisibleAssertions.fail(""Docker compose should start after waiting for listening port with failed with: "" + e);
        }
    }
"
"    @Test
    public void testWaitOnMultipleStrategiesPassing() {
        final DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/compose-test.yml""))
            .withExposedService(""redis_1"", REDIS_PORT, Wait.forListeningPort())
            .withExposedService(""db_1"", 3306, Wait.forLogMessage("".*ready for connections.*\\s"", 1))
            .withTailChildContainers(true);

        try {
            environment.starting(Description.createTestDescription(Object.class, ""name""));
            VisibleAssertions.pass(""Docker compose should start after waiting for listening port"");
        } catch (RuntimeException e) {
            VisibleAssertions.fail(""Docker compose should start after waiting for listening port with failed with: "" + e);
        }
    }
"
"    @Test
    public void testWaitingFails() {
        final DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/compose-test.yml""))
            .withExposedService(""redis_1"", REDIS_PORT, Wait.forHttp(""/test"").withStartupTimeout(Duration.ofSeconds(10)));
        VisibleAssertions.assertThrows(""waiting on an invalid http path times out"",
            RuntimeException.class,
            () -> environment.starting(Description.createTestDescription(Object.class, ""name"")));
    }
"
"    @Test
    public void testWaitOnOneOfMultipleStrategiesFailing() {
        final DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/compose-test.yml""))
            .withExposedService(""redis_1"", REDIS_PORT, Wait.forListeningPort().withStartupTimeout(Duration.ofSeconds(10)))
            .waitingFor(""db_1"", Wait.forLogMessage("".*test test test.*\\s"", 1).withStartupTimeout(Duration.ofSeconds(10)))
            .withTailChildContainers(true);

        VisibleAssertions.assertThrows(""waiting on one failing strategy to time out"",
            RuntimeException.class,
            () -> environment.starting(Description.createTestDescription(Object.class, ""name"")));
    }
"
"    @Test
    public void checkOutput() {
        String listing = toStringConsumer.toUtf8String();

        assertTrue(""Directory listing contains expected /etc content"", listing.contains(""hostname""));
        assertTrue(""Directory listing contains expected /etc content"", listing.contains(""init.d""));
        assertTrue(""Directory listing contains expected /etc content"", listing.contains(""passwd""));
    }
"
"    @Test(timeout = 60_000L)
    public void pullingNonExistentImageFailsGracefully() {

        assertThrows(""Pulling a nonexistent container will cause an exception to be thrown"",
                ContainerFetchException.class, () -> {
                    return new GenericContainer(""richnorth/nonexistent:latest"");
                });
    }
"
"    @Test
    public void simpleTest() {
        Jedis jedis = new Jedis(getEnvironment().getServiceHost(""redis_1"", REDIS_PORT), getEnvironment().getServicePort(""redis_1"", REDIS_PORT));

        jedis.incr(""test"");
        jedis.incr(""test"");
        jedis.incr(""test"");

        assertEquals(""A redis instance defined in compose can be used in isolation"", ""3"", jedis.get(""test""));
    }
"
"    @Test
    public void secondTest() {
        // used in manual checking for cleanup in between tests
        Jedis jedis = new Jedis(getEnvironment().getServiceHost(""redis_1"", REDIS_PORT), getEnvironment().getServicePort(""redis_1"", REDIS_PORT));

        jedis.incr(""test"");
        jedis.incr(""test"");
        jedis.incr(""test"");

        assertEquals(""Tests use fresh container instances"", ""3"", jedis.get(""test""));
        // if these end up using the same container one of the test methods will fail.
        // However, @Rule creates a separate DockerComposeContainer instance per test, so this just shouldn't happen
    }
"
"    @Test
    public void simpleTest() {

        for (int i = 0; i < 3; i++) {
            clients[i].incr(""somekey"");

            assertEquals(""Each redis instance is separate"", ""1"", clients[i].get(""somekey""));
        }
    }
"
"    @Test
    public void testGetServicePort() {
        int serviceWithInstancePort = environment.getServicePort(""redis_1"", REDIS_PORT);
        assertNotNull(""Port is set for service with instance number"", serviceWithInstancePort);
        int serviceWithoutInstancePort = environment.getServicePort(""redis"", REDIS_PORT);
        assertNotNull(""Port is set for service with instance number"", serviceWithoutInstancePort);
        assertEquals(""Service ports are the same"", serviceWithInstancePort, serviceWithoutInstancePort);
    }
"
"    @Test
    public void testFetchStdout() throws TimeoutException {

        WaitingConsumer consumer = new WaitingConsumer();

        container.followOutput(consumer, STDOUT);

        consumer.waitUntil(frame -> frame.getType() == STDOUT && frame.getUtf8String().contains(""seq=2""),
                30, TimeUnit.SECONDS);
    }
"
"    @Test
    public void testFetchStdoutWithTimeout() throws TimeoutException {

        WaitingConsumer consumer = new WaitingConsumer();

        container.followOutput(consumer, STDOUT);

        assertThrows(""a TimeoutException should be thrown"", TimeoutException.class, () -> {
            consumer.waitUntil(frame -> frame.getType() == STDOUT && frame.getUtf8String().contains(""seq=5""),
                    2, TimeUnit.SECONDS);
            return true;
        });
    }
"
"    @Test
    public void testFetchStdoutWithNoLimit() throws TimeoutException {

        WaitingConsumer consumer = new WaitingConsumer();

        container.followOutput(consumer, STDOUT);

        consumer.waitUntil(frame -> frame.getType() == STDOUT && frame.getUtf8String().contains(""seq=2""));
    }
"
"    @Test
    public void testLogConsumer() throws TimeoutException {

        WaitingConsumer waitingConsumer = new WaitingConsumer();
        Slf4jLogConsumer logConsumer = new Slf4jLogConsumer(LOGGER);

        Consumer<OutputFrame> composedConsumer = logConsumer.andThen(waitingConsumer);
        container.followOutput(composedConsumer);

        waitingConsumer.waitUntil(frame -> frame.getType() == STDOUT && frame.getUtf8String().contains(""seq=2""));
    }
"
"    @Test
    public void testToStringConsumer() throws TimeoutException {

        WaitingConsumer waitingConsumer = new WaitingConsumer();
        ToStringConsumer toStringConsumer = new ToStringConsumer();

        Consumer<OutputFrame> composedConsumer = toStringConsumer.andThen(waitingConsumer);
        container.followOutput(composedConsumer);

        waitingConsumer.waitUntilEnd(30, TimeUnit.SECONDS);

        String utf8String = toStringConsumer.toUtf8String();
        assertTrue(""the expected first value was found"", utf8String.contains(""seq=1""));
        assertTrue(""the expected last value was found"", utf8String.contains(""seq=4""));
        assertFalse(""a non-expected value was found"", utf8String.contains(""seq=42""));
    }
"
"    @Test
    public void testFixedHostPortMapping() throws IOException {
        // first find a free port on the docker host that will work for testing
        GenericContainer portDiscoveryRedis = new GenericContainer(""redis:3.0.2"").withExposedPorts(REDIS_PORT);
        portDiscoveryRedis.start();
        Integer freePort = portDiscoveryRedis.getMappedPort(REDIS_PORT);
        portDiscoveryRedis.stop();


        // Set up a FixedHostPortGenericContainer as if this were a @Rule
        FixedHostPortGenericContainer redis = new FixedHostPortGenericContainer(""redis:3.0.2"").withFixedExposedPort(freePort, REDIS_PORT);
        redis.start();

//        Config redisConfig = new Config();
//        redisConfig.useSingleServer().setAddress(redis.getContainerIpAddress() + "":"" + freePort);
//        Redisson redisson = Redisson.create(redisConfig);
//
//        redisson.getBucket(""test"").set(""foo"");
//
//        assertEquals(""The bucket content was successfully set"", ""foo"", redisson.getBucket(""test"").get());
//        assertEquals(""The container returns the fixed port from getMappedPort(...)"", freePort, redis.getMappedPort(REDIS_PORT));
    }
"
"    @Test(timeout = 30_000)
    public void testEnvVar() throws IOException {
        BufferedReader br = Unreliables.retryUntilSuccess(10, TimeUnit.SECONDS, () -> {
            Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS);

            Socket socket = new Socket(compose.getServiceHost(""alpine_1"", 3000), compose.getServicePort(""alpine_1"", 3000));
            return new BufferedReader(new InputStreamReader(socket.getInputStream()));
        });

        Unreliables.retryUntilTrue(10, TimeUnit.SECONDS, () -> {
            while (br.ready()) {
                String line = br.readLine();
                if (line.contains(DOCKER_COMPOSE_OVERRIDE_TEST_OVERRIDE_ENV)) {
                    pass(""Mapped environment variable was found"");
                    return true;
                }
            }
            info(""Mapped environment variable was not found yet - process probably not ready"");
            Uninterruptibles.sleepUninterruptibly(100, TimeUnit.MILLISECONDS);
            return false;
        });

    }
"
"    @Test
    public void testContainerInstanceProperties() {
        final ContainerState container = waitStrategy.getContainer();

        //check environment variable was set
        assertThat(""Environment variable set correctly"", Arrays.asList(Objects.requireNonNull(container.getContainerInfo()
            .getConfig().getEnv())), hasItem(""bar=bar""));

        //check other container properties
        assertNotNull(""Container id is not null"", container.getContainerId());
        assertNotNull(""Port mapped"", container.getMappedPort(3000));
        assertThat(""Exposed Ports"", container.getExposedPorts(), hasItem(3000));

    }
"
"    @Test(timeout = 30_000)
    public void testEnvVar() throws IOException {
        BufferedReader br = Unreliables.retryUntilSuccess(10, TimeUnit.SECONDS, () -> {
            Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS);

            Socket socket = new Socket(compose.getServiceHost(""alpine_1"", 3000), compose.getServicePort(""alpine_1"", 3000));
            return new BufferedReader(new InputStreamReader(socket.getInputStream()));
        });

        Unreliables.retryUntilTrue(10, TimeUnit.SECONDS, () -> {
            while (br.ready()) {
                String line = br.readLine();
                if (line.contains(DOCKER_COMPOSE_OVERRIDE_TEST_BASE_ENV)) {
                    pass(""Mapped environment variable was found"");
                    return true;
                }
            }
            info(""Mapped environment variable was not found yet - process probably not ready"");
            Uninterruptibles.sleepUninterruptibly(100, TimeUnit.MILLISECONDS);
            return false;
        });

    }
"
"    @Test
    public void testNoNetworkContainer() throws TimeoutException {
        String output = getContainerOutput(noNetwork);

        assertTrue(""'none' network causes a network access error"", output.contains(""bad address""));
    }
"
"    @Test
    public void testHostNetworkContainer() throws TimeoutException {
        String output = getContainerOutput(hostNetwork);

        assertTrue(""'host' network can access the internet"", output.contains(""seq=1""));
    }
"
"    @Test
    public void testBridgedNetworkContainer() throws TimeoutException {
        String output = getContainerOutput(bridgedNetwork);

        assertTrue(""'bridge' network can access the internet"", output.contains(""seq=1""));
    }
"
"    @Test
    public void testLogConsumer() throws TimeoutException {
        WaitingConsumer logConsumer = new WaitingConsumer();
        DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/v2-compose-test.yml""))
            .withExposedService(""redis_1"", 6379)
            .withLogConsumer(""redis_1"", logConsumer);

        try {
            environment.starting(Description.EMPTY);
            logConsumer.waitUntil(frame -> frame.getType() == STDOUT && frame.getUtf8String().contains(""Ready to accept connections""), 5, TimeUnit.SECONDS);
        } finally {
            environment.finished(Description.EMPTY);
        }
    }
"
"    @Test
    public void simpleDockerfileWorks() {
        ImageFromDockerfile image = new ImageFromDockerfile()
                .withFileFromString(""folder/someFile.txt"", ""hello"")
                .withFileFromClasspath(""test.txt"", ""mappable-resource/test-resource.txt"")
                .withFileFromClasspath(""Dockerfile"", ""mappable-dockerfile/Dockerfile"");

        verifyImage(image);
    }
"
"    @Test
    public void customizableImage() {
        ImageFromDockerfile image = new ImageFromDockerfile() {
            @Override
            protected void configure(BuildImageCmd buildImageCmd) {
                super.configure(buildImageCmd);

                List<String> dockerfile = Arrays.asList(
                        ""FROM alpine:3.2"",
                        ""RUN echo 'hello from Docker build process'"",
                        ""CMD yes""
                );
                withFileFromString(""Dockerfile"", String.join(""\n"", dockerfile));

                buildImageCmd.withNoCache(true);
            }
        };

        verifyImage(image);
    }
"
"    @Test
    public void dockerfileBuilderWorks() {
        ImageFromDockerfile image = new ImageFromDockerfile()
                .withFileFromClasspath(""test.txt"", ""mappable-resource/test-resource.txt"")
                .withFileFromString(""folder/someFile.txt"", ""hello"")
                .withDockerfileFromBuilder(builder -> builder
                        .from(""alpine:3.2"")
                        .workDir(""/app"")
                        .add(""test.txt"", ""test file.txt"")
                        .run(""ls"", ""-la"", ""/app/test file.txt"")
                        .copy(""folder/someFile.txt"", ""/someFile.txt"")
                        .expose(80, 8080)
                        .cmd(""while true; do cat /someFile.txt | nc -l -p 80; done"")
                );

        verifyImage(image);
    }
"
"    @Test
    public void filePermissions() throws TimeoutException {

        WaitingConsumer consumer = new WaitingConsumer();

        ImageFromDockerfile image = new ImageFromDockerfile()
                .withFileFromTransferable(""/someFile.txt"", new Transferable() {
                    @Override
                    public long getSize() {
                        return 0;
                    }
"
"//    @Test
//    public void simpleRedisTest() {
//        String ipAddress = redis.getContainerIpAddress();
//        Integer port = redis.getMappedPort(REDIS_PORT);
//
//        // Use Redisson to obtain a List that is backed by Redis
//        Config redisConfig = new Config();
//        redisConfig.useSingleServer().setAddress(ipAddress + "":"" + port);
//
//        Redisson redisson = Redisson.create(redisConfig);
//
//        List<String> testList = redisson.getList(""test"");
//        testList.add(""foo"");
//        testList.add(""bar"");
//        testList.add(""baz"");
//
//        List<String> testList2 = redisson.getList(""test"");
//        assertEquals(""The list contains the expected number of items (redis is working!)"", 3, testList2.size());
//        assertTrue(""The list contains an item that was put in (redis is working!)"", testList2.contains(""foo""));
//        assertTrue(""The list contains an item that was put in (redis is working!)"", testList2.contains(""bar""));
//        assertTrue(""The list contains an item that was put in (redis is working!)"", testList2.contains(""baz""));
//    }
"
"    @Test
    public void testIsRunning() {
        try (GenericContainer container = new GenericContainer().withCommand(""top"")) {
            assertFalse(""Container is not started and not running"", container.isRunning());
            container.start();
            assertTrue(""Container is started and running"", container.isRunning());
        }
    }
"
"    @Test
    public void simpleRabbitMqTest() throws IOException, TimeoutException {
        ConnectionFactory factory = new ConnectionFactory();
        factory.setHost(rabbitMq.getContainerIpAddress());
        factory.setPort(rabbitMq.getMappedPort(RABBITMQ_PORT));
        Connection connection = factory.newConnection();

        Channel channel = connection.createChannel();
        channel.exchangeDeclare(RABBIQMQ_TEST_EXCHANGE, ""direct"", true);
        String queueName = channel.queueDeclare().getQueue();
        channel.queueBind(queueName, RABBIQMQ_TEST_EXCHANGE, RABBITMQ_TEST_ROUTING_KEY);

        // Set up a consumer on the queue
        final boolean[] messageWasReceived = new boolean[1];
        channel.basicConsume(queueName, false, new DefaultConsumer(channel) {
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
                messageWasReceived[0] = Arrays.equals(body, RABBITMQ_TEST_MESSAGE.getBytes());
            }
"
"    @Test
    public void simpleMongoDbTest() {
        MongoClient mongoClient = new MongoClient(mongo.getContainerIpAddress(), mongo.getMappedPort(MONGO_PORT));
        MongoDatabase database = mongoClient.getDatabase(""test"");
        MongoCollection<Document> collection = database.getCollection(""testCollection"");

        Document doc = new Document(""name"", ""foo"")
                .append(""value"", 1);
        collection.insertOne(doc);

        Document doc2 = collection.find(new Document(""name"", ""foo"")).first();
        assertEquals(""A record can be inserted into and retrieved from MongoDB"", 1, doc2.get(""value""));
    }
"
"    @Test
    public void environmentAndCustomCommandTest() throws IOException {
        String line = getReaderForContainerPort80(alpineEnvVar).readLine();

        assertEquals(""An environment variable can be passed into a command"", ""42"", line);
    }
"
"    @Test
    public void environmentFromMapTest() throws IOException {
        String line = getReaderForContainerPort80(alpineEnvVarFromMap).readLine();

        assertEquals(""Environment variables can be passed into a command from a map"", ""42 and 50"", line);
    }
"
"    @Test
    public void customLabelTest() {
        try (final GenericContainer alpineCustomLabel = new GenericContainer(""alpine:3.2"")
            .withLabel(""our.custom"", ""label"")
            .withCommand(""top"")) {

            alpineCustomLabel.start();

            Map<String, String> labels = alpineCustomLabel.getCurrentContainerInfo().getConfig().getLabels();
            assertTrue(""org.testcontainers label is present"", labels.containsKey(""org.testcontainers""));
            assertTrue(""our.custom label is present"", labels.containsKey(""our.custom""));
            assertEquals(""our.custom label value is label"", labels.get(""our.custom""), ""label"");
        }
    }
"
"    @Test
    public void exceptionThrownWhenTryingToOverrideTestcontainersLabels() {
        assertThrows(""When trying to overwrite an 'org.testcontainers' label, withLabel() throws an exception"",
            IllegalArgumentException.class,
            () -> {
                new GenericContainer(""alpine:3.2"")
                    .withLabel(""org.testcontainers.foo"", ""false"");
            }
        );
    }
"
"    @Test
    public void customClasspathResourceMappingTest() throws IOException {
        // Note: This functionality doesn't work if you are running your build inside a Docker container;
        // in that case this test will fail.
        String line = getReaderForContainerPort80(alpineClasspathResource).readLine();

        assertEquals(""Resource on the classpath can be mapped using calls to withClasspathResourceMapping"", ""FOOBAR"", line);
    }
"
"    @Test
    public void customClasspathResourceMappingWithSelinuxTest() throws IOException {
        String line = getReaderForContainerPort80(alpineClasspathResourceSelinux).readLine();
        assertEquals(""Resource on the classpath can be mapped using calls to withClasspathResourceMappingSelinux"", ""FOOBAR"", line);
    }
"
"    @Test
    public void exceptionThrownWhenMappedPortNotFound() throws IOException {
        assertThrows(""When the requested port is not mapped, getMappedPort() throws an exception"",
                IllegalArgumentException.class,
                () -> {
                    return redis.getMappedPort(666);
                });
    }
"
"    @Test @Ignore //TODO investigate intermittent failures
    public void failFastWhenContainerHaltsImmediately() throws Exception {

        long startingTimeMs = System.currentTimeMillis();
        final GenericContainer failsImmediately = new GenericContainer(""alpine:3.2"")
              .withCommand(""/bin/sh"", ""-c"", ""return false"")
              .withMinimumRunningDuration(Duration.ofMillis(100));

        try {
            assertThrows(
                  ""When we start a container that halts immediately, an exception is thrown"",
                  RetryCountExceededException.class,
                  () -> {
                      failsImmediately.start();
                      return null;
                  });

            // Check how long it took, to verify that we ARE bailing out early.
            // Want to strike a balance here; too short and this test will fail intermittently
            // on slow systems and/or due to GC variation, too long and we won't properly test
            // what we're intending to test.
            int allowedSecondsToFailure =
                GenericContainer.CONTAINER_RUNNING_TIMEOUT_SEC / 2;
            long completedTimeMs = System.currentTimeMillis();
            assertTrue(""container should not take long to start up"",
                  completedTimeMs - startingTimeMs < 1000L * allowedSecondsToFailure);
        } finally {
            failsImmediately.stop();
        }
    }
"
"    @Test
    public void testExecInContainer() throws Exception {

        // The older ""lxc"" execution driver doesn't support ""exec"". At the time of writing (2016/03/29),
        // that's the case for CircleCI.
        // Once they resolve the issue, this clause can be removed.
        Assume.assumeTrue(TestEnvironment.dockerExecutionDriverSupportsExec());

        final GenericContainer.ExecResult result = redis.execInContainer(""redis-cli"", ""role"");
        assertTrue(""Output for \""redis-cli role\"" command should start with \""master\"""", result.getStdout().startsWith(""master""));
        assertEquals(""Stderr for \""redis-cli role\"" command should be empty"", """", result.getStderr());
        // We expect to reach this point for modern Docker versions.
    }
"
"    @Test
    public void extraHostTest() throws IOException {
        BufferedReader br = getReaderForContainerPort80(alpineExtrahost);

        // read hosts file from container
        StringBuffer hosts = new StringBuffer();
        String line = br.readLine();
        while (line != null) {
            hosts.append(line);
            hosts.append(""\n"");
            line = br.readLine();
        }

        Matcher matcher = Pattern.compile(""^192.168.1.10\\s.*somehost"", Pattern.MULTILINE).matcher(hosts.toString());
        assertTrue(""The hosts file of container contains extra host"", matcher.find());
    }
"
"    @Test
    public void createContainerCmdHookTest() {
        // Use random name to avoid the conflicts between the tests
        String randomName = Base58.randomString(5);
        try(
                GenericContainer container = new GenericContainer<>(""redis:3.0.2"")
                        .withCommand(""redis-server"", ""--help"")
                        .withCreateContainerCmdModifier(cmd -> cmd.withName(""overrideMe""))
                        // Preserves the order
                        .withCreateContainerCmdModifier(cmd -> cmd.withName(randomName))
                        // Allows to override pre-configured values by GenericContainer
                        .withCreateContainerCmdModifier(cmd -> cmd.withCmd(""redis-server"", ""--port"", ""6379""))
        ) {
            container.start();

            assertEquals(""Name is configured"", ""/"" + randomName, container.getContainerInfo().getName());
            assertEquals(""Command is configured"", ""[redis-server, --port, 6379]"", Arrays.toString(container.getContainerInfo().getConfig().getCmd()));
        }
    }
"
"    @Test
    public void copyToContainerTest() throws Exception {
        final File tempResultFolder = Files.createTempDir();

        try (final GenericContainer alpineCopyToContainer = new GenericContainer(""alpine:3.2"")
                    .withCommand(""top"")){

            alpineCopyToContainer.start();
            final MountableFile mountableFile = MountableFile.forClasspathResource(""test_copy_to_container.txt"");
            alpineCopyToContainer.copyFileToContainer(mountableFile, ""/home/"");
            alpineCopyToContainer.copyFileFromContainer(""/home/test_copy_to_container.txt"",
                    tempResultFolder.getAbsolutePath() + ""/test_copy_to_container.txt"");

            File expectedFile = new File(mountableFile.getResolvedPath());
            File actualFile = new File(tempResultFolder.getAbsolutePath() + ""/test_copy_to_container.txt"");
            assertTrue(""Files aren't same "", FileUtils.contentEquals(expectedFile,actualFile));
        }
    }
"
"    @Test(expected = NotFoundException.class)
    public void copyFromContainerShouldFailBecauseNoFileTest() throws NotFoundException, IOException, InterruptedException {

        try (final GenericContainer alpineCopyToContainer = new GenericContainer(""alpine:3.2"")
                        .withCommand(""top"")) {
            alpineCopyToContainer.start();
            alpineCopyToContainer.copyFileFromContainer(""/home/test.txt"", ""src/test/resources/copy-from/test.txt"");
        }
    }
"
"    @Test
    public void shouldCopyFileFromContainerTest() throws IOException, InterruptedException {
        final File tempResultFolder = Files.createTempDir();

        try (final GenericContainer alpineCopyToContainer = new GenericContainer(""alpine:3.2"")
                .withCommand(""top"")) {

            alpineCopyToContainer.start();
            final MountableFile mountableFile = MountableFile.forClasspathResource(""test_copy_to_container.txt"");
            alpineCopyToContainer.copyFileToContainer(mountableFile, ""/home/"");
            alpineCopyToContainer.copyFileFromContainer(""/home/test_copy_to_container.txt"",
                    tempResultFolder.getAbsolutePath() + ""/test_copy_from_container.txt"");

            File expectedFile = new File(mountableFile.getResolvedPath());
            File actualFile = new File(tempResultFolder.getAbsolutePath() + ""/test_copy_from_container.txt"");
            assertTrue(""Files aren't same "", FileUtils.contentEquals(expectedFile,actualFile));
        }
    }
"
"    @Test
    public void addExposedPortAfterWithExposedPortsTest() {
        redis.addExposedPort(8987);
        assertThat(""Both ports should be exposed"", redis.getExposedPorts().size(), equalTo(2));
        assertTrue(""withExposedPort should be exposed"", redis.getExposedPorts().contains(REDIS_PORT));
        assertTrue(""addExposedPort should be exposed"", redis.getExposedPorts().contains(8987));
    }
"
"    @Test
    public void simpleDslTest() throws IOException {
        String address = String.format(""http://%s:%s"", dslContainer.getContainerIpAddress(), dslContainer.getMappedPort(80));

        CloseableHttpClient httpClient = HttpClientBuilder.create().build();
        HttpGet get = new HttpGet(address);

        try (CloseableHttpResponse response = httpClient.execute(get)) {
            assertEquals(""A container built from a dockerfile can run nginx as expected, and returns a good status code"",
                            200,
                            response.getStatusLine().getStatusCode());
            assertTrue(""A container built from a dockerfile can run nginx as expected, and returns an expected Server header"",
                            response.getHeaders(""Server"")[0].getValue().contains(""nginx""));
        }
    }
"
"    @Test
    public void simpleTest() throws Exception {
        final String release = container.execInContainer(""cat"", ""/etc/alpine-release"").getStdout();

        assertTrue(""/etc/alpine-release starts with "" + expectedVersion,
                release.startsWith(expectedVersion));
    }
"
"    @Test
    public void simpleTest() {

        DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/invalid-compose.yml""))
                    .withExposedService(""something"", 123);

        VisibleAssertions.assertThrows(""starting with an invalid docker-compose file throws an exception"",
                ContainerLaunchException.class,
                () -> {
                    environment.starting(Description.createTestDescription(Object.class, ""name""));
                });
    }
"
"    @Test
    public void testWaitUntilReadyWithSuccess() {
        waitUntilReadyAndSucceed(createShellCommand(""200 OK"", GOOD_RESPONSE_BODY));
    }
"
"    @Test
    public void testWaitUntilReadyWithUnauthorizedWithLambda() {
        waitUntilReadyAndSucceed(startContainerWithCommand(createShellCommand(""401 UNAUTHORIZED"", GOOD_RESPONSE_BODY),
            createHttpWaitStrategy(ready)
                .forStatusCodeMatching(it -> it >= 200 && it < 300 || it == 401)
        ));
    }
"
"    @Test
    public void testWaitUntilReadyWithManyStatusCodes() {
        waitUntilReadyAndSucceed(startContainerWithCommand(createShellCommand(""401 UNAUTHORIZED"", GOOD_RESPONSE_BODY),
            createHttpWaitStrategy(ready)
                .forStatusCode(300)
                .forStatusCode(401)
                .forStatusCode(500)
        ));
    }
"
"    @Test
    public void testWaitUntilReadyWithManyStatusCodesAndLambda() {
        waitUntilReadyAndSucceed(startContainerWithCommand(createShellCommand(""401 UNAUTHORIZED"", GOOD_RESPONSE_BODY),
            createHttpWaitStrategy(ready)
                .forStatusCode(300)
                .forStatusCode(500)
                .forStatusCodeMatching(it -> it == 401)
        ));
    }
"
"    @Test
    public void testWaitUntilReadyWithTimeoutAndWithManyStatusCodesAndLambda() {
        waitUntilReadyAndTimeout(startContainerWithCommand(createShellCommand(""401 UNAUTHORIZED"", GOOD_RESPONSE_BODY),
            createHttpWaitStrategy(ready)
                .forStatusCode(300)
                .forStatusCodeMatching(it -> it == 500)
        ));
    }
"
"    @Test
    public void testWaitUntilReadyWithTimeout() {
        waitUntilReadyAndTimeout(createShellCommand(""400 Bad Request"", GOOD_RESPONSE_BODY));
    }
"
"    @Test
    public void testWaitUntilReadyWithTimeoutAndBadResponseBody() {
        waitUntilReadyAndTimeout(createShellCommand(""200 OK"", ""Bad Response""));
    }
"
"    @Test
    public void testWaitUntilReadyWithSpecificPort() {
        waitUntilReadyAndSucceed(startContainerWithCommand(
            createShellCommand(""200 OK"", GOOD_RESPONSE_BODY, 9090),
            createHttpWaitStrategy(ready)
                .forPort(9090),
            7070, 8080, 9090
        ));
    }
"
"    @Test
    public void testWaitUntilReady_Success() {
        waitUntilReadyAndSucceed(""echo -e \"""" + READY_MESSAGE + ""\"";"" +
                ""echo -e \""foobar\"";"" +
                ""echo -e \"""" + READY_MESSAGE + ""\"";"" +
                ""sleep 300"");
    }
"
"    @Test
    public void testWaitUntilReady_Timeout() {
        waitUntilReadyAndTimeout(""echo -e \"""" + READY_MESSAGE + ""\"";"" +
                ""echo -e \""foobar\"";"" +
                ""sleep 300"");
    }
"
"    @Test
    public void testWaiting() {
        pass(""Container starts after waiting"");
    }
"
"    @Test
    public void multilineTest() throws Exception {
        ImmutableMap<String, String> pairs = ImmutableMap.<String, String>builder()
                .put(""line1"", ""1"")
                .put(""line2"", ""2"")
                .put(""line3"", ""3"")
                .build();

        assertStatement(new KeyValuesStatement(""TEST"", pairs));
    }
"
"    @Test
    public void keyWithSpacesTest() throws Exception {
        assertStatement(new KeyValuesStatement(""TEST"", Collections.singletonMap(""key with spaces"", ""1"")));
    }
"
"    @Test
    public void keyWithNewLinesTest() throws Exception {
        assertStatement(new KeyValuesStatement(""TEST"", Collections.singletonMap(""key\nwith\nnewlines"", ""1"")));
    }
"
"    @Test
    public void keyWithTabsTest() throws Exception {
        assertStatement(new KeyValuesStatement(""TEST"", Collections.singletonMap(""key\twith\ttab"", ""1"")));
    }
"
"    @Test
    public void valueIsEscapedTest() throws Exception {
        ImmutableMap<String, String> pairs = ImmutableMap.<String, String>builder()
                .put(""1"", ""value with spaces"")
                .put(""2"", ""value\nwith\nnewlines"")
                .put(""3"", ""value\twith\ttab"")
                .build();

        assertStatement(new KeyValuesStatement(""TEST"", pairs));
    }
"
"    @Test
    public void simpleTest() throws Exception {
        assertStatement(new MultiArgsStatement(""TEST"", ""a"", ""b"", ""c""));
    }
"
"    @Test
    public void name() throws Exception {
        System.out.println(""aaaa"");
    }
"
"    @Test(expected = IllegalStateException.class)
    public void shouldThrowExceptionWhenAlreadyUsed() throws Exception {
        // simulate cucumber scenario start
        simulateCucumberScenarioStart();

        instance.addModule(binder -> {
        });
    }
"
"    @Test
    public void shouldSupportScenarioScope() {
        simulateCucumberScenarioStart();

        final ScenarioScopedClass a = instance.getInstance(ScenarioScopedClass.class);
        a.value = 10;
        assertEquals(10, a.value);

        final ScenarioScopedClass b = instance.getInstance(ScenarioScopedClass.class);
        assertEquals(10, b.value);

        simulateCucumberScenarioStop();
        simulateCucumberScenarioStart();

        final ScenarioScopedClass c = instance.getInstance(ScenarioScopedClass.class);
        assertEquals(0, c.value);

        simulateCucumberScenarioStop();
    }
"
"    @Test(expected = CukesRuntimeException.class)
    public void byInvalidPattern() throws Exception {
        generator.byPattern(""b"");
    }
"
"    @Test
    public void byPattern1() throws Exception {
        assertThat(generator.byPattern(""A""), ContainsPattern.matchesPattern(""[A-Z]""));
        assertThat(generator.byPattern(""a""), ContainsPattern.matchesPattern(""[a-z]""));
        assertThat(generator.byPattern(""0""), ContainsPattern.matchesPattern(""[0-9]""));

        assertThat(generator.byPattern(""0Aa""), ContainsPattern.matchesPattern(Pattern.compile(""[0-9][A-Z][a-z]"")));
    }
"
"    @Test
    public void withLength() throws Exception {
        assertThat(generator.withLength(5), ContainsPattern.matchesPattern(Pattern.compile(""[A-Za-z0-9]{5}"")));
    }
"
"    @Test
    public void shouldExtractNoGroupsInPattern() throws Exception {
        List<String> groups = capturer.extractGroups(""(hello)"");
        assertThat(groups, is(empty()));
    }
"
"    @Test
    public void shouldExtractSingleGroupInPattern() throws Exception {
        List<String> groups = capturer.extractGroups(""{(hello)}"");
        assertThat(groups, contains(""hello""));
    }
"
"    @Test
    public void shouldExtractTwoGroupsInPattern() throws Exception {
        List<String> groups = capturer.extractGroups(""{(hello)}, {(world)}"");
        assertThat(groups, contains(""hello"", ""world""));
    }
"
"    @Test
    public void shouldNotExtractGroupsInPatternWithSpacesInName() throws Exception {
        List<String> groups = capturer.extractGroups(""{(hello world)}"");
        assertThat(groups, is(empty()));
    }
"
"    @Test
    public void shouldExtractGroupsInPatternWithUnderscoreInName() throws Exception {
        List<String> groups = capturer.extractGroups(""{(hello_world)}"");
        assertThat(groups, contains(""hello_world""));
    }
"
"    @Test
    public void shouldExtractDotSeparatedName() throws Exception {
        List<String> groups = capturer.extractGroups(""{(hello.world)}"");
        assertThat(groups, contains(""hello.world""));
    }
"
"    @Test
    public void testInflateGroups() throws Exception {
        doReturn(Optional.of(""foo"")).when(world).get(""foo"");
        String value = inflater.inflateGroups(""{(foo)} bar"", Sets.newHashSet(""foo""));
        assertThat(value, equalTo(""foo bar""));
    }
"
"    @Test
    public void testInflateGroups_emptyWorld() throws Exception {
        String value = inflater.inflateGroups(""{(foo)} bar"", Sets.newHashSet(""foo""));
        assertThat(value, equalTo(""{(foo)} bar""));
    }
"
"    @Test
    public void testInflateGroups_multipleEmpty() throws Exception {
        String value = inflater.inflateGroups(""{(foo)} {(bar)}"", Sets.newHashSet(""foo"", ""bar""));
        assertThat(value, equalTo(""{(foo)} {(bar)}""));
    }
"
"    @Test
    public void testInflateGroups_halfEmpty() throws Exception {
        doReturn(Optional.of(""foo"")).when(world).get(""foo"");
        String value = inflater.inflateGroups(""{(foo)} {(bar)}"", Sets.newHashSet(""foo"", ""bar""));
        assertThat(value, equalTo(""foo {(bar)}""));
    }
"
"    @Test
    public void testInflateGroups_withPlainText() throws Exception {
        doReturn(Optional.of(""foo"")).when(world).get(""foo"");
        String value = inflater.inflateGroups(""my {(foo)} is very {(bar)} !"", Sets.newHashSet(""foo"", ""bar""));
        assertThat(value, equalTo(""my foo is very {(bar)} !""));
    }
"
"    @Test
    public void testInflateGroups_multipleExist() throws Exception {
        doReturn(Optional.of(""foo"")).when(world).get(""foo"");
        doReturn(Optional.of(""bar"")).when(world).get(""bar"");
        String value = inflater.inflateGroups(""{(foo)} {(bar)}"", Sets.newHashSet(""foo"", ""bar""));
        assertThat(value, equalTo(""foo bar""));
    }
"
"    @Test
    public void testInflateGroups_multipleSameExist() throws Exception {
        doReturn(Optional.of(""foo"")).when(world).get(""foo"");
        String value = inflater.inflateGroups(""{(foo)} {(foo)}"", Sets.newHashSet(""foo""));
        assertThat(value, equalTo(""foo foo""));
    }
"
"    @Test
    public void testInflateGroups_multipleSameEmpty() throws Exception {
        String value = inflater.inflateGroups(""{(foo)} {(foo)}"", Sets.newHashSet(""foo""));
        assertThat(value, equalTo(""{(foo)} {(foo)}""));
    }
"
"    @Test
    public void shouldTransformPatternToValidRegex() throws Exception {
        String regex = capturer.transformToRegex(""{(hello)} world"");
        assertThat(regex, equalTo(""(.*) world""));
    }
"
"    @Test
    public void shouldTransformMultiplePatternToValidRegex() throws Exception {
        String regex = capturer.transformToRegex(""{(hello)} {(world)}"");
        assertThat(regex, equalTo(""(.*) (.*)""));
    }
"
"    @Test
    public void shouldCaptureValuesFromSimplePattern() throws Exception {
        capturer.captureValuesFromPattern(""(.*) world"", Lists.newArrayList(""hello""), ""Hi world"");
        verify(world).put(""hello"", ""Hi"");
    }
"
"    @Test
    public void shouldCaptureValuesFromMinimalPattern() throws Exception {
        capturer.captureValuesFromPattern(""(.*)"", Lists.newArrayList(""hello""), ""world"");
        verify(world).put(""hello"", ""world"");
    }
"
"    @Test
    public void shouldNotInvokeCaptureValuesFromPatternIfNoGroupsFound() throws Exception {
        capturer.capture(""hello"", ""world"");
        verify(capturer, never()).captureValuesFromPattern(anyString(), anyListOf(String.class), anyString());
    }
"
"    @Test
    public void shouldInvokeCaptureValuesFromPatternIfAtLeastOneGroupFound() throws Exception {
        capturer.capture(""{(hello)}"", ""world"");
        verify(capturer).captureValuesFromPattern(anyString(), anyListOf(String.class), anyString());
    }
"
"    @Test
    public void shouldNotInvokeCaptureValuesFromPatternIfRegexDoesNotMatchValue() throws Exception {
        capturer.capture(""{(hello)} Riga"", ""hello world"");
        verify(capturer, never()).captureValuesFromPattern(anyString(), anyListOf(String.class), anyString());
    }
"
"    @Test
    public void testBody() {
        String body = ""{\n"" +
            "" \""business\"": {\n"" +
            "" \""businessDirection\"": 1006415,\n"" +
            "" \""transactionType\"": 101759,\n"" +
            "" \""businessSegment\"": 1022645\n"" +
            "" },\n"" +
            "" \""contractName\"": \""@contractName\"",\n"" +
            "" \""underwritingYear\"": 2015,\n"" +
            "" \""businessAndParticipationType\"": 1001011,\n"" +
            "" \""agreementType\"": \""@agreementType\"",\n"" +
            "" \""fasClassification\"": \""@fasClassification\"",\n"" +
            "" \""accountingBasis\"": 100003,\n"" +
            "" \""underwritingObjectStatus\"": 1003797,\n"" +
            "" \""inceptionDate\"": \""2015-01-01T00:00:00.000+0000\"",\n"" +
            "" \""expirationDate\"": \""2015-12-31T00:00:00.000+0000\"",\n"" +
            "" \""contractCurrency\"": \""EUR\"",\n"" +
            "" \""profitCentre\"": @profitCentre,\n"" +
            "" \""involvedParties\"": [\n"" +
            "" {\n"" +
            "" \""partnerId\"": \""@partnerId_1\"",\n"" +
            "" \""partnerRole\"": @partnerRole\n"" +
            "" },\n"" +
            "" {\n"" +
            "" \""partnerId\"": @partnerId_2,\n"" +
            "" \""partnerRole\"": 2173\n"" +
            "" }\n"" +
            "" ]\n"" +
            ""}"";

        String processBody = TemplatingEngine.processBody(body);

        assertTrue(processBody.contains(""\""contractName\"": \""test1\""""));
        assertTrue(processBody.contains(""\""profitCentre\"": 24342""));
    }
"
"    @Test
    public void testOutputStream() throws UnsupportedEncodingException {
        when(world.get(LOGGING_REQUEST_INCLUDES, """")).thenReturn(""all"");

        RequestSpecification specification = RestAssured.given()
            .config(config.getConfig())
            .baseUri(""http://google.com"")
            .param(""q"", ""hi"");

        plugin.beforeRequest(specification);

        specification.get();

        String requestLog = testOut.toString(""UTF-8"");
        assertThat(requestLog, is(EXPECTED_RESULT));
    }
"
"    @Test
    public void shouldNotInflateVarName() throws Exception {
        String headerName = ""name"";
        HttpResponseFacade mock = mock(HttpResponseFacade.class);
        Response response = mock(Response.class);
        when(response.getHeader(anyString())).thenReturn(headerName);
        when(mock.response()).thenReturn(response);
        ((HttpAssertionFacadeImpl) facade).facade = mock;

        world.put(""id"", ""1"");
        facade.varAssignedFromHeader(""{(id)}"", headerName);
        Optional<String> value = world.get(""id"");
        assertThat(value, CustomMatchers.equalToOptional(headerName));
    }
"
"    @Test
    public void shouldReturnBodyWhenEnabledWithMax() {
        String body = ""{\n"" +
            ""  \""error\"": \""not found\""\n"" +
            ""}"";

        HttpResponseFacade mock = mock(HttpResponseFacade.class);
        when(mock.response()).thenReturn(generateResponse(
            ""application/json"",
            404,
            body.getBytes()));

        ((HttpAssertionFacadeImpl) facade).facade = mock;
        world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true"");
        world.put(ASSERTS_STATUS_CODE_MAX_SIZE, ""100"");

        validateException(
            200,
            ""1 expectation failed.\n"" +
                ""Expected status code \""200\"" but was \""404\"" with body:\n"" +
                ""\""\""\""\n"" +
                body +
                ""\n\""\""\"".\n"");
    }
"
"    @Test
    public void shouldReturnBodyWhenEnabledAndNoMax() {
        String body = ""{\n"" +
            ""  \""error\"": \""not found\""\n"" +
            ""}"";

        HttpResponseFacade mock = mock(HttpResponseFacade.class);
        when(mock.response()).thenReturn(generateResponse(
            ""application/json"",
            404,
            body.getBytes()));

        ((HttpAssertionFacadeImpl) facade).facade = mock;
        world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true"");

        validateException(
            200,
            ""1 expectation failed.\n"" +
                ""Expected status code \""200\"" but was \""404\"" with body:\n"" +
                ""\""\""\""\n"" +
                body +
                ""\n\""\""\"".\n"");
    }
"
"    @Test
    public void shouldNotReturnBodyWhenDisabled() {
        String body = ""{\n"" +
            ""  \""error\"": \""not found\""\n"" +
            ""}"";

        HttpResponseFacade mock = mock(HttpResponseFacade.class);
        when(mock.response()).thenReturn(generateResponse(
            ""application/json"",
            404,
            body.getBytes()));

        ((HttpAssertionFacadeImpl) facade).facade = mock;
        world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""false"");
        world.put(ASSERTS_STATUS_CODE_MAX_SIZE, ""100"");

        validateException(
            200,
            ""1 expectation failed.\n"" +
                ""Expected status code \""200\"" but was \""404\"".\n"");
    }
"
"    @Test
    public void shouldNotReturnBodyWhenEnabledButLongerThanMaxSize() {
        String body = ""{\n"" +
            ""  \""error\"": \""not found\""\n"" +
            ""}"";

        HttpResponseFacade mock = mock(HttpResponseFacade.class);
        when(mock.response()).thenReturn(generateResponse(
            ""application/json"",
            404,
            body.getBytes()));

        ((HttpAssertionFacadeImpl) facade).facade = mock;
        world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true"");
        world.put(ASSERTS_STATUS_CODE_MAX_SIZE, ""5"");


        validateException(
            200,
            ""1 expectation failed.\n"" +
                ""Expected status code \""200\"" but was \""404\"" with body <exceeding max size to show>.\n"");
    }
"
"    @Test
    public void shouldNotReturnBodyWhenEnabledButContentTypeOctet() {
        byte[] body = RandomUtils.nextBytes(20);

        HttpResponseFacade mock = mock(HttpResponseFacade.class);
        when(mock.response()).thenReturn(generateResponse(
            ""application/octet-stream"",
            404,
            body));

        ((HttpAssertionFacadeImpl) facade).facade = mock;
        world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true"");
        world.put(ASSERTS_STATUS_CODE_MAX_SIZE, ""5000"");

        validateException(
            200,
            ""1 expectation failed.\n"" +
                ""Expected status code \""200\"" but was \""404\"" with body <binary>.\n"");
    }
"
"    @Test
    public void matchesDirectMatch() throws Exception {
        assertThat(""hello"", EndsWithRegexp.endsWithRegexp(""hello""));
    }
"
"    @Test
    public void matchesEndWith() throws Exception {
        assertThat(""hello world"", EndsWithRegexp.endsWithRegexp(""world""));
    }
"
"    @Test
    public void matchesEndWithRegexp() throws Exception {
        assertThat(""hello world"", EndsWithRegexp.endsWithRegexp(""el.*world""));
    }
"
"    @Test
    public void matchesNotEndWith() throws Exception {
        assertThat(""hello world"", Matchers.not(EndsWithRegexp.endsWithRegexp(""hello"")));
    }
"
"    @Test
    public void matchesNotEndWithRegexp() throws Exception {
        assertThat(""hello world"", Matchers.not(EndsWithRegexp.endsWithRegexp(""h.*o"")));
    }
"
"    @Test
    public void matchesLocationUrl() throws Exception {
        assertThat(""http://company.com:80/webapp/orx/rest/index/types/CLIENT/nodes/6f1155df-644b-4228-89af"" +
                ""-7d24b8fe1a8d"", EndsWithRegexp.endsWithRegexp(""/index/types/CLIENT/nodes/.+""));
    }
"
"    @Test
    public void shouldCheckFileNameGeneration() throws Exception {
        String filename = ""My feature"";
        String refactoredName = loadRunnerFeature.createName(filename);
        assertThat(refactoredName, is(""My_feature""));
    }
"
"    @Test
    public void formatShouldEscapeWhitespaces() throws Exception {
        LoadRunnerTransaction trx = new LoadRunnerTransaction() {{
            setName(""hello world"");
            setTrxFlag(""LR_AUTO"");
        }};
        assertThat(trx.format(), containsString(""hello_world""));
    }
"
"    @Test
    public void formatShouldEscapeDoubleQuotes() throws Exception {
        WebCustomRequest request = new WebCustomRequest() {{
            setBody(""hello \""world\"""");
        }};
        assertThat(request.format(), containsString(""hello \\\""world\\\""""));
    }
"
"    @Test
    public void snapshotNumberShouldBeLessThan10Digits() {
        FilterableRequestSpecification requestSpec = mock(FilterableRequestSpecification.class);
        when(requestSpec.getURI()).thenReturn(""http://www.google.com"");
        when(requestSpec.getHeaders()).thenReturn(new Headers());

        WebCustomRequest request = mapper.map(requestSpec);
        assertThat(request, hasProperty(""snapshot"", CustomMatchers.stringWithLength(lessThanOrEqualTo(15)))); //10 digits + t + .inf
    }
"
"    @Test
    public void byteArrayValueIsCheckedAsString() throws Exception {
        BasicAttributes entity = new BasicAttributes(true);
        entity.put(""userPassword"", new byte[]{50, 82, 115, 48, 67, 99, 54, 74});

        Whitebox.setInternalState(entityFacade, ""entity"", entity);

        entityFacade.entityHasAttributeWithValue(""userpassword"", ""2Rs0Cc6J"");
    }
"
"    @Test
    public void charArrayValueIsCheckedAsString() throws Exception {
        BasicAttributes entity = new BasicAttributes(true);
        entity.put(""userPassword"", new char[]{'h', 'e', 'l', 'l', 'o'});

        Whitebox.setInternalState(entityFacade, ""entity"", entity);

        entityFacade.entityHasAttributeWithValue(""userpassword"", ""hello"");
    }
"
"    @Test
    public void stringValueIsCheckedAsString() throws Exception {
        BasicAttributes entity = new BasicAttributes(true);
        entity.put(""userPassword"", ""hello"");

        Whitebox.setInternalState(entityFacade, ""entity"", entity);

        entityFacade.entityHasAttributeWithValue(""userpassword"", ""hello"");
    }
"
"    @Test
    public void intArrayValueIsCheckedAsString() throws Exception {
        BasicAttributes entity = new BasicAttributes(true);
        entity.put(""userPassword"", new int[]{1, 2, 3});

        Whitebox.setInternalState(entityFacade, ""entity"", entity);

        entityFacade.entityHasAttributeWithValue(""userpassword"", ""{1,2,3}"");
    }
"
"    @Test
    public void intValueIsCheckedAsString() throws Exception {
        BasicAttributes entity = new BasicAttributes(true);
        entity.put(""userPassword"", 3);

        Whitebox.setInternalState(entityFacade, ""entity"", entity);

        entityFacade.entityHasAttributeWithValue(""userpassword"", ""3"");
    }
"
"    @Test
    public void compare_sameTree() throws Exception {
        assertThat(comparator.compare(""cn=root"", ""cn=b,cn=root""), is(more()));
        assertThat(comparator.compare(""cn=a,cn=root"", ""cn=root""), is(less()));
        assertThat(comparator.compare(""cn=a,cn=root"", ""cn=a,cn=root""), is(same()));
    }
"
"    @Test
    public void compare_differentTrees() throws Exception {
        assertThat(comparator.compare(""cn=a,cn=root"", ""cn=b,cn=root""), is(more()));
        assertThat(comparator.compare(""cn=b,cn=root"", ""cn=a,cn=root""), is(less()));
    }
"
"    @Test
    public void sort() throws Exception {
        List<String> dns = new ArrayList<>(Arrays.asList(
            ""cn=root"",
            ""cn=a,cn=root"",
            ""cn=b,cn=root"",
            ""cn=c,cn=a,cn=root""
        ));
        Collections.sort(dns, comparator);
        assertThat(dns.get(0), is(""cn=root""));
        assertThat(dns.get(1), is(""cn=a,cn=root""));
        assertThat(dns.get(2), is(""cn=c,cn=a,cn=root""));
        assertThat(dns.get(3), is(""cn=b,cn=root""));
    }
"
"    @Test
    public void read() throws Exception {
        Map<String, Attributes> entities = LDIFUtils.read(getClass().getResourceAsStream(""/example.ldif""));
        assertThat(entities.size(), is(4));
    }
"
"    @Test
    public void readSingleEntity() throws Exception {
        String ldif = ""dn: dc=example,dc=com\n"" +
            ""objectClass: domain\n"" +
            ""objectClass: top\n"" +
            ""dc: example\n"";
        Map<String, Attributes> entities = LDIFUtils.read(new ByteArrayInputStream(ldif.getBytes()));
        assertThat(entities.size(), is(1));
        String dn = ""dc=example,dc=com"";
        Attributes entity = entities.get(dn);
        assertThat(entity, notNullValue());

        assertThat(entity.get(""dn""), nullValue());
        assertThat(entity.get(""dc"").get(), is(""example""));
        assertThat(entity.get(""objectClass"").contains(""domain""), is(true));
        assertThat(entity.get(""objectClass"").contains(""top""), is(true));
    }
"
"    @Test
    public void readMultipleEntities() throws Exception {
        String ldif = ""dn: dc=example,dc=com\n"" +
            ""objectClass: domain\n"" +
            ""objectClass: top\n"" +
            ""dc: example\n"" +
            ""\n"" +
            ""dn: ou=Users,dc=example,dc=com\n"" +
            ""objectClass: organizationalUnit\n"" +
            ""objectClass: top\n"" +
            ""ou: Users\n"";

        Map<String, Attributes> entities = LDIFUtils.read(new ByteArrayInputStream(ldif.getBytes()));
        assertThat(entities.size(), is(2));
        assertThat(entities.containsKey(""dc=example,dc=com""), is(true));
        assertThat(entities.containsKey(""ou=Users,dc=example,dc=com""), is(true));
    }
"
"    @Test
    public void readWithLineBreaks() throws Exception {
        String ldif = ""dn: dc=example,dc=com\n"" +
            ""objectClass: top\n"" +
            ""test: this is\n"" +
            "" multi-line text\n"" +
            ""dc: example\n"";
        Map<String, Attributes> entities = LDIFUtils.read(new ByteArrayInputStream(ldif.getBytes()));
        assertThat(entities.size(), is(1));
        Attributes entity = entities.get(""dc=example,dc=com"");
        assertThat(entity.get(""test"").get(), is(""this is multi-line text""));

    }
"
"    @Test
    public void serve1() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response = client.get(""/http-serve"").aggregate().get();
        assertThat(response.status()).isEqualTo(HttpStatus.OK);

        assertThat(response.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response.headers().contains(""RateLimit-Reset"")).isFalse();
        assertThat(response.headers().contains(""X-RateLimit-Reset"")).isFalse();
        assertThat(response.headers().contains(""X-Rate-Limit-Reset"")).isFalse();
        assertThat(response.headers().contains(""RateLimit-Limit"")).isFalse();
        assertThat(response.headers().contains(""X-RateLimit-Limit"")).isFalse();
        assertThat(response.headers().contains(""X-Rate-Limit-Limit"")).isFalse();
    }
"
"    @Test
    public void throttle1() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle1"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isTrue();
        final long reset1 = Long.parseLong(response1.headers().get(""X-RateLimit-Reset""));
        assertThat(reset1).isBetween(0L, 10L);
        assertThat(response1.headers().contains(""X-RateLimit-Limit"")).isFalse();

        final AggregatedHttpResponse response2 = client.get(""/http-throttle1"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.TOO_MANY_REQUESTS);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER)).isTrue();
        final long retryAfter2 = Long.parseLong(response2.headers().get(HttpHeaderNames.RETRY_AFTER));
        assertThat(retryAfter2).isBetween(0L, 10L);
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"")).isTrue();
        final long reset = Long.parseLong(response2.headers().get(""X-RateLimit-Reset""));
        assertThat(reset).isEqualTo(retryAfter2);
        assertThat(response2.headers().contains(""X-RateLimit-Limit"")).isFalse();
    }
"
"    @Test
    public void throttle2() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle2"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isTrue();
        final long reset1 = Long.parseLong(response1.headers().get(""X-RateLimit-Reset""));
        assertThat(reset1).isBetween(0L, 10L);
        assertThat(response1.headers().get(""X-RateLimit-Limit"")).isEqualTo(""1, 1;window=10"");

        final AggregatedHttpResponse response2 = client.get(""/http-throttle2"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.TOO_MANY_REQUESTS);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER, ""15"")).isTrue();
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"", ""15"")).isTrue();
        assertThat(response1.headers().get(""X-RateLimit-Limit"")).isEqualTo(""1, 1;window=10"");
    }
"
"    @Test
    public void throttle3() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle3"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isFalse();

        final AggregatedHttpResponse response2 = client.get(""/http-throttle3"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.TOO_MANY_REQUESTS);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER)).isTrue();
        final long retryAfter2 = Long.parseLong(response2.headers().get(HttpHeaderNames.RETRY_AFTER));
        assertThat(retryAfter2).isBetween(0L, 10L);
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"")).isFalse();
    }
"
"    @Test
    public void throttle4() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle4"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isFalse();

        final AggregatedHttpResponse response2 = client.get(""/http-throttle4"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.SERVICE_UNAVAILABLE);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER)).isTrue();
        final long retryAfter2 = Long.parseLong(response2.headers().get(HttpHeaderNames.RETRY_AFTER));
        assertThat(retryAfter2).isBetween(5L, 10L);
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"")).isFalse();
    }
"
"    @Test
    public void shouldBeDifferentToEachOther() throws UnsupportedEncodingException {
        final SamlRequestIdManager manager =
                SamlRequestIdManager.ofJwt(""me"", ""test"", 60, 5);

        final String id1 = manager.newId();
        final String id2 = manager.newId();
        final String id3 = manager.newId();

        assertThat(id1).isNotEqualTo(id2).isNotEqualTo(id3);
        assertThat(id2).isNotEqualTo(id3);
    }
"
"    @Test
    public void shouldMatchJWTPattern() throws UnsupportedEncodingException {
        final Pattern p = Pattern.compile(""[a-zA-Z0-9-_]+\\.[a-zA-Z0-9-_]+\\.[a-zA-Z0-9-_]+"");
        final SamlRequestIdManager manager =
                SamlRequestIdManager.ofJwt(""me"", ""test"", 60, 5);
        final String id = manager.newId();
        assertThat(p.matcher(id).matches()).isTrue();
        assertThat(manager.validateId(id)).isTrue();
    }
"
"    @Test
    public void shouldBeExpired() throws InterruptedException, UnsupportedEncodingException {
        final SamlRequestIdManager manager =
                SamlRequestIdManager.ofJwt(""me"", ""test"", 1, 0);

        final Instant started = Instant.now();
        final String id = manager.newId();
        assertThat(manager.validateId(id)).isTrue();

        await().pollDelay(Durations.TWO_HUNDRED_MILLISECONDS)
               .atMost(Durations.FIVE_SECONDS)
               .untilAsserted(() -> assertThat(manager.validateId(id)).isFalse());

        assertThat(java.time.Duration.between(started, Instant.now()).toMillis())
                .isGreaterThan(TimeUnit.SECONDS.toMillis(1));
    }
"
"    @Test
    public void shouldBeAcceptedBecauseOfLeeway() throws InterruptedException, UnsupportedEncodingException {
        final SamlRequestIdManager manager =
                SamlRequestIdManager.ofJwt(""me"", ""test"", 1, 1);

        final Instant started = Instant.now();
        final String id = manager.newId();
        assertThat(manager.validateId(id)).isTrue();

        await().pollDelay(Durations.TWO_HUNDRED_MILLISECONDS)
               .atMost(Durations.FIVE_SECONDS)
               .untilAsserted(() -> assertThat(manager.validateId(id)).isFalse());

        assertThat(java.time.Duration.between(started, Instant.now()).toMillis())
                .isGreaterThan(TimeUnit.SECONDS.toMillis(2));
    }
"
"    @Test
    public void shouldFail() {
        assertThatThrownBy(() -> SamlRequestIdManager.ofJwt(""me"", ""test"", 0, 0))
                .isInstanceOf(IllegalArgumentException.class);
        assertThatThrownBy(() -> SamlRequestIdManager.ofJwt(""me"", ""test"", -1, 0))
                .isInstanceOf(IllegalArgumentException.class);
        assertThatThrownBy(() -> SamlRequestIdManager.ofJwt(""me"", ""test"", 1, -1))
                .isInstanceOf(IllegalArgumentException.class);
    }
"
"    @Test
    public void shouldRespondAuthnRequest_HttpRedirect() throws Exception {
        final AggregatedHttpResponse resp = client.get(""/redirect"").aggregate().join();
        assertThat(resp.status()).isEqualTo(HttpStatus.FOUND);

        // Check the order of the parameters in the quest string.
        final String location = resp.headers().get(HttpHeaderNames.LOCATION);
        final Pattern p = Pattern.compile(
                ""http://idp\\.example\\.com/saml/sso/redirect\\?"" +
                ""SAMLRequest=([^&]+)&RelayState=([^&]+)&SigAlg=([^&]+)&Signature=(.+)$"");
        assertThat(location).isNotNull();
        assertThat(p.matcher(location).matches()).isTrue();

        assertThat(QueryParams.fromQueryString(location)
                              .get(SIGNATURE_ALGORITHM)).isEqualTo(signatureAlgorithm);
    }
"
"    @Test
    public void shouldRespondAuthnRequest_HttpPost() throws Exception {
        final AggregatedHttpResponse resp = client.get(""/post"").aggregate().join();
        assertThat(resp.status()).isEqualTo(HttpStatus.OK);
        assertThat(resp.contentType()).isEqualTo(MediaType.HTML_UTF_8);

        final Document doc = Jsoup.parse(resp.contentUtf8());
        assertThat(doc.body().attr(""onLoad"")).isEqualTo(""document.forms[0].submit()"");

        // SAMLRequest will be posted to the IdP's SSO URL.
        final Element form = doc.body().child(0);
        assertThat(form.attr(""method"")).isEqualTo(""post"");
        assertThat(form.attr(""action"")).isEqualTo(""http://idp.example.com/saml/sso/post"");
        assertThat(form.child(0).attr(""name"")).isEqualTo(SAML_REQUEST);
        assertThat(form.child(1).attr(""name"")).isEqualTo(RELAY_STATE);
    }
"
"    @Test
    public void shouldBeAlreadyAuthenticated() throws Exception {
        final RequestHeaders req = RequestHeaders.of(HttpMethod.GET, ""/redirect"",
                                                     HttpHeaderNames.COOKIE, ""test=test"");
        final AggregatedHttpResponse resp = client.execute(req).aggregate().join();
        assertThat(resp.status()).isEqualTo(HttpStatus.OK);
        assertThat(resp.contentUtf8()).isEqualTo(""authenticated"");
    }
"
"    @Test
    public void shouldRespondMetadataWithoutAuthentication() throws Exception {
        final AggregatedHttpResponse resp = client.get(""/saml/metadata"").aggregate().join();
        assertThat(resp.status()).isEqualTo(HttpStatus.OK);
        assertThat(resp.contentType()).isEqualTo(CONTENT_TYPE_SAML_METADATA);

        final EntityDescriptor metadata =
                (EntityDescriptor) deserialize(resp.contentUtf8().getBytes());
        assertThat(metadata).isNotNull();

        final SPSSODescriptor sp = metadata.getSPSSODescriptor(SAMLConstants.SAML20P_NS);
        assertThat(sp.isAuthnRequestsSigned()).isTrue();
        assertThat(sp.getWantAssertionsSigned()).isTrue();

        final List<KeyDescriptor> kd = sp.getKeyDescriptors();
        assertThat(kd.get(0).getUse().name()).isEqualToIgnoringCase(""signing"");
        assertThat(kd.get(1).getUse().name()).isEqualToIgnoringCase(""encryption"");

        final List<SingleLogoutService> slo = sp.getSingleLogoutServices();
        assertThat(slo.get(0).getLocation())
                .isEqualTo(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/slo/post"");
        assertThat(slo.get(0).getBinding()).isEqualTo(SAMLConstants.SAML2_POST_BINDING_URI);
        assertThat(slo.get(1).getLocation())
                .isEqualTo(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/slo/redirect"");
        assertThat(slo.get(1).getBinding()).isEqualTo(SAMLConstants.SAML2_REDIRECT_BINDING_URI);

        final List<AssertionConsumerService> acs = sp.getAssertionConsumerServices();
        // index 0 (default)
        assertThat(acs.get(0).getIndex()).isEqualTo(0);
        assertThat(acs.get(0).isDefault()).isTrue();
        assertThat(acs.get(0).getLocation())
                .isEqualTo(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/acs/post"");
        assertThat(acs.get(0).getBinding()).isEqualTo(SAMLConstants.SAML2_POST_BINDING_URI);
        // index 1
        assertThat(acs.get(1).getIndex()).isEqualTo(1);
        assertThat(acs.get(1).isDefault()).isFalse();
        assertThat(acs.get(1).getLocation())
                .isEqualTo(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/acs/redirect"");
        assertThat(acs.get(1).getBinding()).isEqualTo(SAMLConstants.SAML2_REDIRECT_BINDING_URI);
    }
"
"    @Test
    public void shouldConsumeAssertion_HttpPost() throws Exception {
        final Response response =
                getAuthResponse(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/acs/post"");
        final AggregatedHttpResponse res = sendViaHttpPostBindingProtocol(""/saml/acs/post"",
                                                                          SAML_RESPONSE, response);

        assertThat(res.status()).isEqualTo(HttpStatus.FOUND);
        assertThat(res.headers().get(HttpHeaderNames.LOCATION)).isEqualTo(""/"");
    }
"
"    @Test
    public void shouldConsumeAssertion_HttpRedirect() throws Exception {
        final Response response =
                getAuthResponse(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/acs/redirect"");
        final AggregatedHttpResponse res = sendViaHttpRedirectBindingProtocol(""/saml/acs/redirect"",
                                                                              SAML_RESPONSE, response);

        assertThat(res.status()).isEqualTo(HttpStatus.FOUND);
        assertThat(res.headers().get(HttpHeaderNames.LOCATION)).isEqualTo(""/"");
    }
"
"    @Test
    public void shouldConsumeLogoutRequest_HttpPost() throws Exception {
        final LogoutRequest logoutRequest =
                getLogoutRequest(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/slo/post"",
                                 ""http://idp.example.com/post"");

        final AggregatedHttpResponse res = sendViaHttpPostBindingProtocol(""/saml/slo/post"",
                                                                          SAML_REQUEST, logoutRequest);

        assertThat(res.status()).isEqualTo(HttpStatus.OK);
        assertThat(res.contentType()).isEqualTo(MediaType.HTML_UTF_8);

        final Document doc = Jsoup.parse(res.contentUtf8());
        assertThat(doc.body().attr(""onLoad"")).isEqualTo(""document.forms[0].submit()"");

        // SAMLResponse will be posted to the IdP's logout response URL.
        final Element form = doc.body().child(0);
        assertThat(form.attr(""method"")).isEqualTo(""post"");
        assertThat(form.attr(""action"")).isEqualTo(""http://idp.example.com/saml/slo/post"");
        assertThat(form.child(0).attr(""name"")).isEqualTo(SAML_RESPONSE);
    }
"
"    @Test
    public void shouldConsumeLogoutRequest_HttpRedirect() throws Exception {
        final LogoutRequest logoutRequest =
                getLogoutRequest(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/slo/redirect"",
                                 ""http://idp.example.com/redirect"");

        final AggregatedHttpResponse res =
                sendViaHttpRedirectBindingProtocol(""/saml/slo/redirect"", SAML_REQUEST, logoutRequest);

        assertThat(res.status()).isEqualTo(HttpStatus.FOUND);

        // Check the order of the parameters in the quest string.
        final String location = res.headers().get(HttpHeaderNames.LOCATION);
        final Pattern p = Pattern.compile(
                ""http://idp\\.example\\.com/saml/slo/redirect\\?"" +
                ""SAMLResponse=([^&]+)&SigAlg=([^&]+)&Signature=(.+)$"");
        assertThat(location).isNotNull();
        assertThat(p.matcher(location).matches()).isTrue();
    }
"
"    @Test
    public void expectSuccessWithFile() throws Exception {
        final File file = folder.newFile();

        assertThat(file.length()).isZero();

        final KeyStore keyStore = KeyStore.getInstance(""JKS"");
        keyStore.load(null, null);
        keyStore.store(new FileOutputStream(file), """".toCharArray());

        assertThat(file.length()).isGreaterThan(0);
        assertThat(file.canRead()).isTrue();
        assertThat(file.exists()).isTrue();

        new KeyStoreCredentialResolverBuilder(file).build();
    }
"
"    @Test
    public void expectSuccessWithResource() throws Exception {
        new KeyStoreCredentialResolverBuilder(getClass().getClassLoader(), ""keystore/test.jks"").build();
    }
"
"    @Test
    public void expectNotFound() throws Exception {
        assertThatThrownBy(
                () -> new KeyStoreCredentialResolverBuilder(new File(""/not_exist"")).build())
                .isInstanceOf(FileNotFoundException.class);
        assertThatThrownBy(
                () -> new KeyStoreCredentialResolverBuilder(getClass().getClassLoader(), ""not_exist"").build())
                .isInstanceOf(FileNotFoundException.class)
                .hasMessageContaining(""Resource not found"");
    }
"
"    @Test
        public void onComplete(String response) {
            resultHandler.onComplete(response);
        }
"
"    @Test
    public void callbackContextIsFromInvocationTime_root() {
        try (SafeCloseable ignored = serverContext().push()) {
            super.callbackContextIsFromInvocationTime_root();
        }
    }
"
"    @Test
    public void addsStatusCodeWhenNotOk_async() {
        try (SafeCloseable ignored = serverContext().push()) {
            super.addsStatusCodeWhenNotOk_async();
        }
    }
"
"    @Test
    public void usesParentFromInvocationTime() {
        try (SafeCloseable ignored = serverContext().push()) {
            super.usesParentFromInvocationTime();
        }
    }
"
"    @Test
    public void clientTimestampAndDurationEnclosedByParent() {
    }
"
"    @Test
    public void callbackContextIsFromInvocationTime() {
        // TODO(trustin): Can't make this pass because span is updated *after* we invoke the callback
        //                ITHttpAsyncClient gave us.
    }
"
"    @Test
    public void redirect() {
        throw new AssumptionViolatedException(""Armeria does not support client redirect."");
    }
"
"    @Test
    public void get_returnsNullWhenNoCurrentRequestContext() {
        assertThat(currentTraceContext.get()).isNull();
    }
"
"    @Test
    public void get_returnsNullWhenCurrentRequestContext_hasNoTraceAttribute() {
        try (SafeCloseable requestContextScope = ctx.push()) {
            assertThat(currentTraceContext.get()).isNull();
        }
    }
"
"    @Test
    public void newScope_appliesWhenNoCurrentRequestContext() {
        try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
            assertThat(traceContextScope).hasToString(""ThreadLocalScope"");
            assertThat(currentTraceContext.get()).isEqualTo(traceContext);
        }
    }
"
"    @Test
    public void newScope_appliesWhenCurrentRequestContext() {
        try (SafeCloseable requestContextScope = ctx.push()) {
            try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
                assertThat(traceContextScope).hasToString(""InitialRequestScope"");
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);
            }
        }
    }
"
"    @Test
    public void newScope_closeDoesntClearFirstScope() {
        final TraceContext traceContext2 = TraceContext.newBuilder().traceId(1).spanId(2).build();

        try (SafeCloseable requestContextScope = ctx.push()) {
            try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
                assertThat(traceContextScope).hasToString(""InitialRequestScope"");
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);

                try (Scope traceContextScope2 = currentTraceContext.newScope(traceContext2)) {
                    assertThat(traceContextScope2).hasToString(""RequestContextTraceContextScope"");
                    assertThat(currentTraceContext.get()).isEqualTo(traceContext2);
                }
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);
            }
            // the first scope is attached to the request context and cleared when that's destroyed
            assertThat(currentTraceContext.get()).isEqualTo(traceContext);
        }
    }
"
"    @Test
    public void newScope_notOnEventLoop() {
        final TraceContext traceContext2 = TraceContext.newBuilder().traceId(1).spanId(2).build();

        try (SafeCloseable requestContextScope = ctx.push()) {
            try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
                assertThat(traceContextScope).hasToString(""InitialRequestScope"");
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);

                when(eventLoop.inEventLoop()).thenReturn(false);
                try (Scope traceContextScope2 = currentTraceContext.newScope(traceContext2)) {
                    assertThat(traceContextScope2).hasToString(""ThreadLocalScope"");
                    assertThat(currentTraceContext.get()).isEqualTo(traceContext2);
                }
                when(eventLoop.inEventLoop()).thenReturn(true);
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);
            }
            // the first scope is attached to the request context and cleared when that's destroyed
            assertThat(currentTraceContext.get()).isEqualTo(traceContext);
        }
    }
"
"    @Test
    public void newScope_canClearScope() {
        try (SafeCloseable requestContextScope = ctx.push()) {
            try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
                try (Scope traceContextScope2 = currentTraceContext.newScope(null)) {
                    assertThat(currentTraceContext.get()).isNull();
                }
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);
            }
        }
    }
"
"    @Test
    public void newScope_respondsToPing() {
        final PingPongExtra extra = new PingPongExtra();
        final TraceContext extraContext = TraceContext.newBuilder().traceId(1).spanId(1)
                                                      .addExtra(extra).build();

        try (Scope traceContextScope = currentTraceContext.newScope(extraContext)) {
            assertThat(traceContextScope).hasToString(""NoopScope"");
            assertThat(extra.isPong()).isTrue();
        }
    }
"
"    @Test
    public void shouldSetPongIfOnlyExtra() {
        final PingPongExtra extra = new PingPongExtra();

        final TraceContext context = TraceContext.newBuilder().traceId(1).spanId(1)
                                                 .addExtra(extra).build();

        TraceContextUtil.PingPongExtra.maybeSetPong(context);

        assertThat(extra.isPong()).isTrue();
    }
"
"    @Test
    public void notFound() {
        throw new AssumptionViolatedException(
                ""Armeria yields 'get /*' as a span name for a non-existent mapping."");
    }
"
"    @Test
    public void httpStatusCodeSettable_onUncaughtException() {
        throw new AssumptionViolatedException(
            ""Can't currently control the HTTP status code on uncaught exception. #2656"");
    }
"
"    @Test
    public void httpStatusCodeSettable_onUncaughtException_async() {
        throw new AssumptionViolatedException(
            ""Can't currently control the HTTP status code on uncaught exception. #2656"");
    }
"
"    @AfterEach
    public void tearDown() {
        Tracing.current().close();
    }
"
"    @Test
            public HttpResponse serve(ServiceRequestContext ctx, HttpRequest req) throws Exception {
                return HttpResponse.of(HttpStatus.OK);
            }
"
"    @Test
            public void pop(RequestContext current, @Nullable RequestContext toRestore) {
                popped.set(true);
                super.pop(current, toRestore);
            }
"
"    @Test
    public void contextLoads() {
        assertThat(greetingController).isNotNull();
    }
"
"    @Test
    public void verifyTomcatVersion() {
        assertThat(TomcatVersion.major()).isEqualTo(tomcatMajorVersion);
        assertThat(TomcatVersion.minor()).isEqualTo(tomcatMinorVersion);
    }
"
"    @Test
    public void verifySingleConnector() {
        // Relevant to Tomcat 9.0
        assertThat(applicationContext).isInstanceOf(WebServerApplicationContext.class);
        final WebServer webServer = ((WebServerApplicationContext) applicationContext).getWebServer();
        assertThat(webServer).isInstanceOf(TomcatWebServer.class);
        assertThat(((TomcatWebServer) webServer).getTomcat()
                                                .getEngine()
                                                .getService()
                                                .findConnectors()).hasSize(1);
    }
"
"    @Test
    public void greetingShouldReturnDefaultMessage() throws Exception {
        assertThat(restTemplate.getForObject(""http://localhost:"" +
                                             httpPort +
                                             ""/tomcat/api/rest/v1/greeting"",
                                             String.class))
                .contains(""Hello, World!"");
    }
"
"    @Test
    public void greetingShouldReturnUsersMessage() throws Exception {
        assertThat(restTemplate.getForObject(""http://localhost:"" +
                                             httpPort +
                                             ""/tomcat/api/rest/v1/greeting?name=Armeria"",
                                             String.class))
                .contains(""Hello, Armeria!"");
    }
"
"    @Test
    public void greetingShouldReturn404() throws Exception {
        assertThat(restTemplate.getForEntity(""http://localhost:"" +
                                             httpPort +
                                             ""/tomcat/api/rest/v1/greet"",
                                             Void.class)
                               .getStatusCode()).isEqualByComparingTo(HttpStatus.NOT_FOUND);
    }
"
"    @Test
    public void contextLoads() {
        assertThat(applicationContext.getBean(ArmeriaAutoConfiguration.class)).isNotNull();
        assertThatThrownBy(() -> {
            applicationContext.getBean(ArmeriaReactiveWebServerFactory.class);
        }).isInstanceOf(BeansException.class);
    }
"
"    @Test
    public void contextLoads() {
        assertThat(applicationContext.getBean(ArmeriaReactiveWebServerFactory.class)).isNotNull();
        assertThatThrownBy(() -> {
            applicationContext.getBean(ArmeriaAutoConfiguration.class);
        }).isInstanceOf(BeansException.class);
    }
"
"    @Test(expected = NotAllMetaRegionsOnlineException.class)
    public void testGuavaConflict() throws Exception {
        // Make sure Armeria is available in the class path.
        assertThat(Version.getAll(Server.class.getClassLoader())).isNotNull();
        // Make sure newer Guava is available in the class path.
        assertThat(Stopwatch.class.getDeclaredConstructor().getModifiers()).is(new Condition<>(
                value -> !Modifier.isPublic(value),
                ""Recent Guava Stopwatch should have non-public default constructor.""));

        final MetaTableLocator locator = new MetaTableLocator();
        final ZooKeeperWatcher zkw = mock(ZooKeeperWatcher.class);
        final RecoverableZooKeeper zk = mock(RecoverableZooKeeper.class);
        when(zkw.getRecoverableZooKeeper()).thenReturn(zk);
        when(zk.exists(any(), any())).thenReturn(new Stat(0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0));

        locator.waitMetaRegionLocation(zkw, 100);
    }
"
"    @Test
    public void normal() {
        try (ClientFactory clientFactory =
                     ClientFactory.builder()
                                  .tlsCustomizer(ctx -> ctx.keyManager(clientCert.certificateFile(),
                                                                       clientCert.privateKeyFile()))
                                  .tlsNoVerify()
                                  .build()) {
            final WebClient client = WebClient.builder(rule.httpsUri())
                                              .factory(clientFactory)
                                              .decorator(LoggingClient.builder().newDecorator())
                                              .build();
            assertThat(client.get(""/"").aggregate().join().status()).isEqualTo(HttpStatus.OK);
        }
    }
"
"    @Test
    public void proxyWithTrailers() throws Throwable {
        final WebClient client = WebClient.of(frontendServer.httpUri());

        final AtomicBoolean headersReceived = new AtomicBoolean();
        final AtomicBoolean complete = new AtomicBoolean();
        final AtomicReference<Throwable> error = new AtomicReference<>();

        client.get(""/trailers"").subscribe(new Subscriber<HttpObject>() {
            @Override
            public void onSubscribe(Subscription s) {
                s.request(Long.MAX_VALUE);
            }
"
"    @Test
    public void proxyWithTrailersOnly() throws Throwable {
        final WebClient client = WebClient.of(frontendServer.httpUri());

        final AtomicBoolean complete = new AtomicBoolean();
        final AtomicReference<Throwable> error = new AtomicReference<>();

        client.get(""/trailers-only"").subscribe(new Subscriber<HttpObject>() {
            @Override
            public void onSubscribe(Subscription s) {
                s.request(Long.MAX_VALUE);
            }
"
"    @Test
        public void onSettingsRead(ChannelHandlerContext ctx, Http2Settings settings) {
            assertThat(settings.pushEnabled()).isFalse();
        }
"
"    @Test
    public void testExtractHost() {
        // additionalRequestHeaders has the highest precedence.
        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, ""foo"")),
                               HttpRequest.of(RequestHeaders.of(HttpMethod.GET, ""/"",
                                                                HttpHeaderNames.AUTHORITY, ""bar:8080"")),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""foo"");

        // Request header
        assertThat(extractHost(context(HttpHeaders.of()),
                               HttpRequest.of(RequestHeaders.of(HttpMethod.GET, ""/"",
                                                                HttpHeaderNames.AUTHORITY, ""bar:8080"")),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""bar"");

        // Endpoint.host() has the lowest precedence.
        assertThat(extractHost(context(HttpHeaders.of()),
                               HttpRequest.of(HttpMethod.GET, ""/""),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""baz"");

        // IPv6 address authority
        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, ""[::1]:8443"")),
                               HttpRequest.of(HttpMethod.GET, ""/""),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""::1"");

        // An invalid authority should be ignored.
        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, ""[::1"")),
                               HttpRequest.of(HttpMethod.GET, ""/""),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""baz"");

        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, "":8080"")),
                               HttpRequest.of(HttpMethod.GET, ""/""),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""baz"");

        // If additionalRequestHeader's authority is invalid but req.authority() is valid,
        // use the authority from 'req'.
        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, ""[::1"")),
                               HttpRequest.of(RequestHeaders.of(HttpMethod.GET, ""/"",
                                                                HttpHeaderNames.AUTHORITY, ""bar"")),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""bar"");

        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, "":8080"")),
                               HttpRequest.of(RequestHeaders.of(HttpMethod.GET, ""/"",
                                                                HttpHeaderNames.AUTHORITY, ""bar"")),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""bar"");
    }
"
"    @Test
            public void connectionOpen(SessionProtocol protocol, InetSocketAddress remoteAddr,
                                       InetSocketAddress localAddr, AttributeMap attrs) throws Exception {
                openRunnable.run();
            }
"
"    @Test
        public HttpResponse execute(ClientRequestContext ctx, HttpRequest req) throws Exception {
            // Will never reach here.
            throw new Error();
        }
"
"    @Test
            public void onSubscribe(Subscription s) {
                s.request(Long.MAX_VALUE);
            }
"
"    @Test
    public void notEmpty() {
        final StreamDecoder decoder = newDecoder();
        final ByteBuf buf = ByteBufAllocator.DEFAULT.buffer();
        buf.writeBytes(PAYLOAD);
        final HttpData data = decoder.decode(HttpData.wrap(buf));
        assertThat(buf.refCnt()).isZero();
        assertThat(data.byteBuf().refCnt()).isOne();
        data.close();
    }
"
"    @Test
    public void empty_unpooled() {
        final StreamDecoder decoder = newDecoder();
        final HttpData data = decoder.decode(HttpData.empty());
        assertThat(data.isPooled()).isFalse();
    }
"
"    @Test
    public void empty_pooled() {
        final StreamDecoder decoder = newDecoder();
        final ByteBuf buf = ByteBufAllocator.DEFAULT.buffer();
        final HttpData data = decoder.decode(HttpData.wrap(buf));
        assertThat(buf.refCnt()).isZero();

        // Even for a pooled empty input, the result is unpooled since there's no point in pooling empty
        // buffers.
        assertThat(data.isPooled()).isFalse();
    }
"
"    @Test
    public void testPropertyFileWatcherRunnableExitsOnInterrupt() throws InterruptedException {
        final WatchService watchService = mock(WatchService.class);
        final FileWatcherRunnable fileWatcherRunnable = new FileWatcherRunnable(watchService, mock(
                FileSystemWatchContext.class));
        when(watchService.take()).then(invocation -> {
            while (!Thread.currentThread().isInterrupted()) {
                Thread.yield();
            }
            return null;
        });
        final Thread thread = new Thread(fileWatcherRunnable);
        thread.start();
        thread.interrupt();
        await().untilAsserted(() -> assertThat(thread.isAlive()).isFalse());
    }
"
"    @Test
            public Endpoint selectNow(ClientRequestContext ctx) {
                final List<Endpoint> endpoints = endpointGroup.endpoints();
                return endpoints.isEmpty() ? null : endpoints.get(0);
            }
"
"    @Test
    public void testGetEndpointGroupName() throws Exception {
        assertNull(getEndpointGroupName(""http://myGroupName/""));
        assertNull(getEndpointGroupName(""http://myGroupName:8080/xxx""));
        assertNull(getEndpointGroupName(""http://group1:myGroupName:8080/""));
        assertNull(getEndpointGroupName(""http://username:password@myGroupName:8080/""));

        assertEquals(""myGroupName"", getEndpointGroupName(""http://"" + endpointGroupMark + ""myGroupName/""));
        assertEquals(""myGroupName"", getEndpointGroupName(""http://"" + endpointGroupMark + ""myGroupName:8080/""));
        assertEquals(""myGroupName"", getEndpointGroupName(""http://"" + endpointGroupMark + ""myGroupName:8080/""));
        assertEquals(""myGroupName"", getEndpointGroupName(""http://username:password@"" + endpointGroupMark +
                                                         ""myGroupName:8080/""));
    }
"
"    @Test
    public void testReplace() throws Exception {
        final String replacement = ""127.0.0.1:1234"";
        assertEquals(""http://myGroupName/"",
                     replaceEndpointGroup(""http://myGroupName/"", replacement));
        assertEquals(""http://myGroupName:8080/xxx"",
                     replaceEndpointGroup(""http://myGroupName:8080/xxx"", replacement));
        assertEquals(""http://group1:myGroupName:8080/"",
                     replaceEndpointGroup(""http://group1:myGroupName:8080/"", replacement));
        assertEquals(""http://username:password@myGroupName:8080/"",
                     replaceEndpointGroup(""http://username:password@myGroupName:8080/"", replacement));

        assertEquals(""http://127.0.0.1:1234/"",
                     replaceEndpointGroup(""http://"" + endpointGroupMark + ""myGroupName/"", replacement));
        assertEquals(""http://127.0.0.1:1234/"",
                     replaceEndpointGroup(""http://"" + endpointGroupMark + ""myGroupName:8080/"", replacement));
        assertEquals(""http://127.0.0.1:1234/xxx"",
                     replaceEndpointGroup(""http://"" + endpointGroupMark + ""myGroupName:8080/xxx"", replacement));
        assertEquals(""http://username:password@127.0.0.1:1234/xxx"",
                     replaceEndpointGroup(""http://username:password@"" + endpointGroupMark +
                                          ""myGroupName:8080/xxx"", replacement));
    }
"
"    @Test
        public int compare(Endpoint o1, Endpoint o2) {
            if (o1.equals(o2) && o1.weight() == o2.weight()) {
                return 0;
            }
            return -1;
        }
"
"    @Test
    public void testRestartableThreadRestartBehavior() {
        final RestartableThread restartableThread =
                new RestartableThread(testName.getMethodName(), () -> () -> {
                    while (!Thread.currentThread().isInterrupted()) {
                        Thread.yield();
                    }
                });

        restartableThread.start();
        assertThat(restartableThread.isRunning()).isTrue();
        restartableThread.stop();
        assertThat(restartableThread.isRunning()).isFalse();
        restartableThread.start();
        assertThat(restartableThread.isRunning()).isTrue();
        restartableThread.stop();
        assertThat(restartableThread.isRunning()).isFalse();
    }
"
"    @Test
    public void emptyGroupStopsBackgroundThread() throws Exception {

        final File file = folder.newFile(""temp-file.properties"");
        final File file2 = folder.newFile(""temp-file2.properties"");

        final FileWatcherRegistry fileWatcherRegistry =
                new FileWatcherRegistry();
        final FileWatchRegisterKey key1 = fileWatcherRegistry.register(file.toPath(), () -> {});
        final FileWatchRegisterKey key2 = fileWatcherRegistry.register(file2.toPath(), () -> {});

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key1);

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key2);

        assertThat(fileWatcherRegistry.isRunning()).isFalse();
    }
"
"    @Test
    public void closeEndpointGroupStopsRegistry() throws Exception {

        final File file = folder.newFile(""temp-file.properties"");

        final FileWatcherRegistry fileWatcherRegistry = new FileWatcherRegistry();
        fileWatcherRegistry.register(file.toPath(), () -> {});

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.close();

        assertThat(fileWatcherRegistry.isRunning()).isFalse();
    }
"
"    @Test
    public void runnableWithExceptionContinuesRun() throws Exception {

        final File file = folder.newFile(""temp-file.properties"");
        final FileWatcherRegistry fileWatcherRegistry = new FileWatcherRegistry();

        final AtomicInteger val = new AtomicInteger(0);
        final FileWatchRegisterKey key = fileWatcherRegistry.register(file.toPath(), () -> {
            try {
                final BufferedReader bufferedReader = new BufferedReader(new FileReader(file));
                val.set(Integer.valueOf(bufferedReader.readLine()));
            } catch (IOException e) {
                // do nothing
            }
            throw new RuntimeException();
        });

        PrintWriter printWriter = new PrintWriter(file);
        printWriter.print(1);
        printWriter.close();

        await().untilAsserted(() -> assertThat(val.get()).isEqualTo(1));

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        printWriter = new PrintWriter(file);
        printWriter.print(2);
        printWriter.close();

        await().untilAsserted(() -> assertThat(val.get()).isEqualTo(2));

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key);

        assertThat(fileWatcherRegistry.isRunning()).isFalse();

        fileWatcherRegistry.close();
    }
"
"    @Test
    public void testMultipleFileSystems() throws Exception {

        final FileWatcherRegistry fileWatcherRegistry = new FileWatcherRegistry();

        final Path path1 = createMockedPath();
        final Path path2 = createMockedPath();

        final FileWatchRegisterKey key1 = fileWatcherRegistry.register(path1, () -> {});
        final FileWatchRegisterKey key2 = fileWatcherRegistry.register(path2, () -> {});
        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key1);
        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key2);
        assertThat(fileWatcherRegistry.isRunning()).isFalse();
    }
"
"    @Test
        public void updateCandidates(List<Endpoint> candidates) {
            this.candidates = candidates;
            selectedCandidates = ImmutableList.copyOf(candidates);
        }
"
"    @Test
    public void propertiesWithoutDefaultPort() {
        final PropertiesEndpointGroup endpointGroup = PropertiesEndpointGroup.of(PROPS, ""serverA.hosts"");

        assertThat(endpointGroup.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                        Endpoint.parse(""127.0.0.1:8081""),
                                                                        Endpoint.parse(""127.0.0.1""));
    }
"
"    @Test
    public void propertiesWithDefaultPort() {
        final PropertiesEndpointGroup endpointGroupA = PropertiesEndpointGroup.builder(PROPS, ""serverA.hosts"")
                                                                              .defaultPort(80)
                                                                              .build();
        final PropertiesEndpointGroup endpointGroupB = PropertiesEndpointGroup.builder(PROPS, ""serverB.hosts"")
                                                                              .defaultPort(8080)
                                                                              .build();

        assertThat(endpointGroupA.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                         Endpoint.parse(""127.0.0.1:8081""),
                                                                         Endpoint.parse(""127.0.0.1:80""));
        assertThat(endpointGroupB.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8082""),
                                                                         Endpoint.parse(""127.0.0.1:8083""));
    }
"
"    @Test
    public void resourceWithoutDefaultPort() {
        final PropertiesEndpointGroup endpointGroup = PropertiesEndpointGroup.of(
                getClass().getClassLoader(), ""server-list.properties"", ""serverA.hosts"");

        assertThat(endpointGroup.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                        Endpoint.parse(""127.0.0.1:8081""),
                                                                        Endpoint.parse(""127.0.0.1""));
    }
"
"    @Test
    public void resourceWithDefaultPort() {
        final PropertiesEndpointGroup endpointGroupA =
                PropertiesEndpointGroup.builder(getClass().getClassLoader(),
                                                ""server-list.properties"",
                                                ""serverA.hosts"")
                                       .defaultPort(80)
                                       .build();

        final PropertiesEndpointGroup endpointGroupB =
                PropertiesEndpointGroup.builder(getClass().getClassLoader(),
                                                ""server-list.properties"",
                                                ""serverB.hosts"")
                                       .defaultPort(8080)
                                       .build();

        assertThat(endpointGroupA.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                         Endpoint.parse(""127.0.0.1:8081""),
                                                                         Endpoint.parse(""127.0.0.1:80""));
        assertThat(endpointGroupB.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8082""),
                                                                         Endpoint.parse(""127.0.0.1:8083""));
    }
"
"    @Test
    public void pathWithDefaultPort() throws Exception {
        final URL resourceUrl = getClass().getClassLoader().getResource(""server-list.properties"");
        assert resourceUrl != null;
        final Path resourcePath = new File(resourceUrl.getFile()).toPath();
        final PropertiesEndpointGroup endpointGroupA = PropertiesEndpointGroup.builder(
                resourcePath, ""serverA.hosts"").defaultPort(80).build();
        assertThat(endpointGroupA.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                         Endpoint.parse(""127.0.0.1:8081""),
                                                                         Endpoint.parse(""127.0.0.1:80""));
        endpointGroupA.close();
    }
"
"    @Test
    public void pathWithoutDefaultPort() {
        final URL resourceUrl = getClass().getClassLoader().getResource(""server-list.properties"");
        assert resourceUrl != null;
        final Path resourcePath = new File(resourceUrl.getFile()).toPath();
        final PropertiesEndpointGroup endpointGroup = PropertiesEndpointGroup.of(
                resourcePath, ""serverA.hosts"");
        assertThat(endpointGroup.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                        Endpoint.parse(""127.0.0.1:8081""),
                                                                        Endpoint.parse(""127.0.0.1""));
        endpointGroup.close();
    }
"
"    @Test
    public void testWithPrefixThatEndsWithDot() {
        final PropertiesEndpointGroup endpointGroup = PropertiesEndpointGroup.of(
                getClass().getClassLoader(), ""server-list.properties"", ""serverA.hosts."");

        assertThat(endpointGroup.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                        Endpoint.parse(""127.0.0.1:8081""),
                                                                        Endpoint.parse(""127.0.0.1""));
    }
"
"    @Test
    public void containsNoHosts() {
        assertThat(PropertiesEndpointGroup.builder(getClass().getClassLoader(),
                                                   ""server-list.properties"", ""serverC.hosts"")
                                          .defaultPort(8080)
                                          .build()
                                          .endpoints()).isEmpty();
    }
"
"    @Test
    public void illegalDefaultPort() {
        assertThatThrownBy(() -> PropertiesEndpointGroup.builder(getClass().getClassLoader(),
                                                                 ""server-list.properties"", ""serverA.hosts"")
                                                        .defaultPort(0))
                .isInstanceOf(IllegalArgumentException.class)
                .hasMessageContaining(""defaultPort"");
    }
"
"    @Test
    public void propertiesFileUpdatesCorrectly() throws Exception {
        final File file = folder.newFile(""temp-file.properties"");

        PrintWriter printWriter = new PrintWriter(file);
        Properties props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.store(printWriter, """");
        printWriter.close();

        final PropertiesEndpointGroup endpointGroupA = PropertiesEndpointGroup.of(
                file.toPath(), ""serverA.hosts"");

        await().untilAsserted(() -> assertThat(endpointGroupA.endpoints()).hasSize(1));

        // Update resource
        printWriter = new PrintWriter(file);
        props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.setProperty(""serverA.hosts.1"", ""127.0.0.1:8081"");
        props.store(printWriter, """");
        printWriter.close();

        await().untilAsserted(() -> assertThat(endpointGroupA.endpoints()).hasSize(2));

        endpointGroupA.close();
    }
"
"    @Test
    public void duplicateResourceUrl() throws IOException {
        final File file = folder.newFile(""temp-file.properties"");
        final PropertiesEndpointGroup propertiesEndpointGroupA =
                PropertiesEndpointGroup.of(file.toPath(), ""serverA.hosts"");
        final PropertiesEndpointGroup propertiesEndpointGroupB =
                PropertiesEndpointGroup.of(file.toPath(), ""serverA.hosts"");
        propertiesEndpointGroupA.close();
        propertiesEndpointGroupB.close();
    }
"
"    @Test
    public void propertiesFileRestart() throws Exception {
        final File file = folder.newFile(""temp-file.properties"");

        PrintWriter printWriter = new PrintWriter(file);
        Properties props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.store(printWriter, """");
        printWriter.close();

        final PropertiesEndpointGroup endpointGroupA = PropertiesEndpointGroup.of(
                file.toPath(), ""serverA.hosts"");
        await().untilAsserted(() -> assertThat(endpointGroupA.endpoints()).hasSize(1));
        endpointGroupA.close();

        final PropertiesEndpointGroup endpointGroupB = PropertiesEndpointGroup.of(
                file.toPath(), ""serverB.hosts"");
        await().untilAsserted(() -> assertThat(endpointGroupB.endpoints()).isEmpty());

        printWriter = new PrintWriter(file);
        props = new Properties();
        props.setProperty(""serverB.hosts.0"", ""127.0.0.1:8080"");
        props.setProperty(""serverB.hosts.1"", ""127.0.0.1:8081"");
        props.store(printWriter, """");
        printWriter.close();

        await().untilAsserted(() -> assertThat(endpointGroupB.endpoints()).hasSize(2));
        endpointGroupB.close();
    }
"
"    @Test
    public void endpointChangePropagatesToListeners() throws Exception {
        final File file = folder.newFile(""temp-file.properties"");

        PrintWriter printWriter = new PrintWriter(file);
        Properties props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.setProperty(""serverA.hosts.1"", ""127.0.0.1:8081"");
        props.store(printWriter, """");
        printWriter.close();

        final PropertiesEndpointGroup propertiesEndpointGroup = PropertiesEndpointGroup.of(
                file.toPath(), ""serverA.hosts"");
        final EndpointGroup fallbackEndpointGroup = Endpoint.of(""127.0.0.1"", 8081);
        final EndpointGroup endpointGroup = propertiesEndpointGroup.orElse(fallbackEndpointGroup);

        await().untilAsserted(() -> assertThat(endpointGroup.endpoints()).hasSize(2));

        printWriter = new PrintWriter(file);
        props = new Properties();
        props.store(printWriter, """");
        printWriter.close();

        await().untilAsserted(() -> assertThat(endpointGroup.endpoints()).hasSize(1));

        printWriter = new PrintWriter(file);
        props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.setProperty(""serverA.hosts.1"", ""127.0.0.1:8081"");
        props.setProperty(""serverA.hosts.2"", ""127.0.0.1:8082"");
        props.store(printWriter, """");
        printWriter.close();

        await().untilAsserted(() -> assertThat(endpointGroup.endpoints()).hasSize(3));
        propertiesEndpointGroup.close();
    }
"
"    @Test
    public void ipV4Only() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""foo.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""foo.com."", ""1.1.1.1""))
                                         .addRecord(ANSWER, newAddressRecord(""unrelated.com"", ""1.2.3.4"")),
                new DefaultDnsQuestion(""foo.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""foo.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""foo.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_ONLY)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""foo.com"", 8080).withIpAddr(""1.1.1.1""));
            }
        }
    }
"
"    @Test
    public void ipV6Only() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""bar.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""bar.com."", ""1.1.1.1"")),
                new DefaultDnsQuestion(""bar.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""bar.com."", ""::1""))
                                         .addRecord(ANSWER, newAddressRecord(""bar.com."", ""::1234:5678:90ab""))
                                         .addRecord(ANSWER, newAddressRecord(""bar.com."",
                                                                             ""2404:6800:4004:806::2013""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""bar.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV6_ONLY)
                                                .build()) {

                assertThat(group.whenReady().get(10, TimeUnit.SECONDS)).containsExactly(
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""2404:6800:4004:806::2013""),
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""::1""),
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""::1234:5678:90ab""));
            }
        }
    }
"
"    @Test
    public void ipV4AndIpV6() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""baz.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""baz.com."", ""1.1.1.1"")),
                new DefaultDnsQuestion(""baz.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""baz.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""baz.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""baz.com"", 8080).withIpAddr(""1.1.1.1""),
                        Endpoint.of(""baz.com"", 8080).withIpAddr(""::1""));
            }
        }
    }
"
"    @Test
    public void platformDefault() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""baz.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""baz.com."", ""1.1.1.1"")),
                new DefaultDnsQuestion(""baz.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""baz.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""baz.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .build()) {

                assertThat(group.whenReady().get()).contains(
                        Endpoint.of(""baz.com"", 8080).withIpAddr(""1.1.1.1""));
            }
        }
    }
"
"    @Test
    public void cname() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""a.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newBadAddressRecord(""a.com."", true))
                                         .addRecord(ANSWER, newCnameRecord(""a.com."", ""b.com.""))
                                         .addRecord(ANSWER, newAddressRecord(""b.com."", ""1.1.1.1"")),
                new DefaultDnsQuestion(""a.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newBadAddressRecord(""a.com."", false))
                                         .addRecord(ANSWER, newCnameRecord(""a.com."", ""b.com.""))
                                         .addRecord(ANSWER, newAddressRecord(""b.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""a.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""a.com"", 8080).withIpAddr(""1.1.1.1""),
                        Endpoint.of(""a.com"", 8080).withIpAddr(""::1""));
            }
        }
    }
"
"    @Test
    public void mixedLoopbackAddresses() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""foo.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""foo.com."", ""127.0.0.1"")),
                new DefaultDnsQuestion(""foo.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""foo.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""foo.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""foo.com"", 8080).withIpAddr(""127.0.0.1""));
            }
        }
    }
"
"    @Test
    public void ipV4MappedOrCompatibleAddresses() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""bar.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newCompatibleAddressRecord(""bar.com."", ""1.1.1.1""))
                                         .addRecord(ANSWER, newCompatibleAddressRecord(""bar.com."", ""1.1.1.2""))
                                         .addRecord(ANSWER, newMappedAddressRecord(""bar.com."", ""1.1.1.1""))
                                         .addRecord(ANSWER, newMappedAddressRecord(""bar.com."", ""1.1.1.3""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""bar.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV6_ONLY)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""1.1.1.1""),
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""1.1.1.2""),
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""1.1.1.3""));
            }
        }
    }
"
"    @Test
    public void noPort() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""no-port.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""no-port.com"", ""1.1.1.1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""no-port.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_ONLY)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""no-port.com"").withIpAddr(""1.1.1.1""));
            }
        }
    }
"
"    @Test
    public void backoff() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of())) { // Respond nothing.
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""backoff.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .backoff(Backoff.fixed(500))
                                                .build()) {

                await().untilAsserted(() -> assertThat(group.attemptsSoFar).isGreaterThan(2));
                assertThat(group.endpoints()).isEmpty();

                // Start to respond correctly.
                server.setResponses(ImmutableMap.of(
                        new DefaultDnsQuestion(""backoff.com."", A),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""backoff.com"", ""1.1.1.1"", 1)),
                        new DefaultDnsQuestion(""backoff.com."", AAAA),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""backoff.com"", ""::1"", 1))));

                await().untilAsserted(() -> assertThat(group.endpoints()).containsExactly(
                        Endpoint.of(""backoff.com"").withIpAddr(""1.1.1.1""),
                        Endpoint.of(""backoff.com"").withIpAddr(""::1"")));
            }
        }
    }
"
"    @Test
    public void backoffOnEmptyResponse() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                // Respond with empty records.
                new DefaultDnsQuestion(""empty.com."", A), new DefaultDnsResponse(0),
                new DefaultDnsQuestion(""empty.com."", AAAA), new DefaultDnsResponse(0)
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""empty.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .backoff(Backoff.fixed(500))
                                                .build()) {

                await().untilAsserted(() -> assertThat(group.attemptsSoFar).isGreaterThan(2));
                assertThat(group.endpoints()).isEmpty();

                // Start to respond correctly.
                server.setResponses(ImmutableMap.of(
                        new DefaultDnsQuestion(""empty.com."", A),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""empty.com"", ""1.1.1.1"", 1)),
                        new DefaultDnsQuestion(""empty.com."", AAAA),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""empty.com"", ""::1"", 1))));

                await().untilAsserted(() -> assertThat(group.endpoints()).containsExactly(
                        Endpoint.of(""empty.com"").withIpAddr(""1.1.1.1""),
                        Endpoint.of(""empty.com"").withIpAddr(""::1"")));
            }
        }
    }
"
"    @ParameterizedTest
    public void partialIpV4Response(ResolvedAddressTypes resolvedAddressTypes) throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                // Respond A record only.
                // Respond with NXDOMAIN for AAAA.
                new DefaultDnsQuestion(""partial.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""partial.com"", ""1.1.1.1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""partial.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(resolvedAddressTypes)
                                                .backoff(Backoff.fixed(500))
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""partial.com"").withIpAddr(""1.1.1.1""));
            }
        }
    }
"
"    @ParameterizedTest
    public void partialIpV6Response(ResolvedAddressTypes resolvedAddressTypes) throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                // Respond AAAA record only.
                // Respond with NXDOMAIN for A.
                new DefaultDnsQuestion(""partial.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""partial.com"", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""partial.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(resolvedAddressTypes)
                                                .backoff(Backoff.fixed(500))
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""partial.com"").withIpAddr(""::1""));
            }
        }
    }
"
"    @Test
    public void srv() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""foo.com."", SRV),
                new DefaultDnsResponse(0).addRecord(ANSWER, newSrvRecord(""foo.com."", 1, 2, ""a.foo.com.""))
                                         .addRecord(ANSWER, newSrvRecord(""foo.com."", 3, 4, ""b.foo.com.""))
                                         .addRecord(ANSWER, newSrvRecord(""unrelated.com."", 0, 0, ""asdf.com.""))
                                         .addRecord(ANSWER, newTooShortSrvRecord(""foo.com.""))
                                         .addRecord(ANSWER, newBadNameSrvRecord(""foo.com.""))
        ))) {
            try (DnsServiceEndpointGroup group =
                         DnsServiceEndpointGroup.builder(""foo.com"")
                                                .serverAddresses(server.addr())
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""a.foo.com"", 2).withWeight(1),
                        Endpoint.of(""b.foo.com"", 4).withWeight(3));
            }
        }
    }
"
"    @Test
    public void testUseGeneratedKeys(){
        EntityHelper.initEntityNameMap(UserJDBC.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserJDBC.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""JDBC"", column.getGenerator());
            Assert.assertTrue(column.isIdentity());
        }
    }
"
"    @Test
    public void testDialect(){
        EntityHelper.initEntityNameMap(UserDialect.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserDialect.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""SELECT LAST_INSERT_ID()"", column.getGenerator());
            Assert.assertEquals(ORDER.AFTER, column.getOrder());
            Assert.assertTrue(column.isIdentity());
        }
    }
"
"    @Test
    public void testSql(){
        EntityHelper.initEntityNameMap(UserSql.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserSql.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""select seq.nextval from dual"", column.getGenerator());
            Assert.assertEquals(ORDER.BEFORE, column.getOrder());
            Assert.assertTrue(column.isIdentity());
        }
    }
"
"    @Test
    public void testAll(){
        EntityHelper.initEntityNameMap(UserAll.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserAll.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""JDBC"", column.getGenerator());
            Assert.assertTrue(column.isIdentity());
        }
    }
"
"    @Test
    public void testAll2(){
        EntityHelper.initEntityNameMap(UserAll2.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserAll2.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""SELECT LAST_INSERT_ID()"", column.getGenerator());
            Assert.assertEquals(ORDER.AFTER, column.getOrder());
            Assert.assertTrue(column.isIdentity());
        }
    }
"
"    @Test
    public void testVersion(){
        EntityHelper.initEntityNameMap(UserVersion.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserVersion.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertTrue(column.getEntityField().isAnnotationPresent(Version.class));
        }
    }
"
"    @Test(expected = VersionException.class)
    public void testVersionError(){
        EntityHelper.initEntityNameMap(UserVersionError.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserVersionError.class);
        Assert.assertNotNull(entityTable);
        SqlHelper.wherePKColumns(UserVersionError.class, true);
    }
"
"    @Test
    public void testColumn(){
        EntityHelper.initEntityNameMap(UserColumn.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserColumn.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""user_name"", column.getColumn());
            Assert.assertEquals(""name"", column.getProperty());

            Assert.assertEquals(""user_name = #{name}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""user_name = #{record.name}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{name}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.name}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.name}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.namesuffix},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[USER_NAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""user_name"", resultMapping.getColumn());
        Assert.assertEquals(""name"", resultMapping.getProperty());
        Assert.assertNull(resultMapping.getJdbcType());
        Assert.assertEquals(StringTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
"
"    @Test
    public void testCamelhump(){
        EntityHelper.initEntityNameMap(UserCamelhump.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserCamelhump.class);
        Assert.assertNotNull(entityTable);
        Assert.assertEquals(""user_camelhump"", entityTable.getName());

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""user_name"", column.getColumn());
            Assert.assertEquals(""userName"", column.getProperty());

            Assert.assertEquals(""user_name = #{userName}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""user_name = #{record.userName}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{userName}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.userNamesuffix},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[USER_NAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""user_name"", resultMapping.getColumn());
        Assert.assertEquals(""userName"", resultMapping.getProperty());
        Assert.assertNull(resultMapping.getJdbcType());
        Assert.assertEquals(StringTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
"
"    @Test
    public void testCamelhumpAndUppercase(){
        EntityHelper.initEntityNameMap(UserCamelhumpAndUppercase.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserCamelhumpAndUppercase.class);
        Assert.assertNotNull(entityTable);
        Assert.assertEquals(""USER_CAMELHUMP_AND_UPPERCASE"", entityTable.getName());

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""USER_NAME"", column.getColumn());
            Assert.assertEquals(""userName"", column.getProperty());

            Assert.assertEquals(""USER_NAME = #{userName}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""USER_NAME = #{record.userName}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{userName}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.userNamesuffix},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[USER_NAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""USER_NAME"", resultMapping.getColumn());
        Assert.assertEquals(""userName"", resultMapping.getProperty());
        Assert.assertNull(resultMapping.getJdbcType());
        Assert.assertEquals(StringTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
"
"    @Test
    public void testCamelhumpAndLowercase(){
        EntityHelper.initEntityNameMap(UserCamelhumpAndLowercase.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserCamelhumpAndLowercase.class);
        Assert.assertNotNull(entityTable);
        Assert.assertEquals(""user_camelhump_and_lowercase"", entityTable.getName());

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""user_name"", column.getColumn());
            Assert.assertEquals(""userName"", column.getProperty());

            Assert.assertEquals(""user_name = #{userName}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""user_name = #{record.userName}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{userName}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.userNamesuffix},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[USER_NAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""user_name"", resultMapping.getColumn());
        Assert.assertEquals(""userName"", resultMapping.getProperty());
        Assert.assertNull(resultMapping.getJdbcType());
        Assert.assertEquals(StringTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
"
"    @Test
    public void testNormal(){
        EntityHelper.initEntityNameMap(UserNormal.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserNormal.class);
        Assert.assertNotNull(entityTable);
        Assert.assertEquals(""UserNormal"", entityTable.getName());

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""userName"", column.getColumn());
            Assert.assertEquals(""userName"", column.getProperty());

            Assert.assertEquals(""userName = #{userName}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""userName = #{record.userName}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{userName}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.userNamesuffix},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[USERNAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""userName"", resultMapping.getColumn());
        Assert.assertEquals(""userName"", resultMapping.getProperty());
        Assert.assertNull(resultMapping.getJdbcType());
        Assert.assertEquals(StringTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
"
"    @Test
    public void testUppercase(){
        EntityHelper.initEntityNameMap(UserUppercase.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserUppercase.class);
        Assert.assertNotNull(entityTable);
        Assert.assertEquals(""USERUPPERCASE"", entityTable.getName());

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""USERNAME"", column.getColumn());
            Assert.assertEquals(""userName"", column.getProperty());

            Assert.assertEquals(""USERNAME = #{userName}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""USERNAME = #{record.userName}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{userName}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.userNamesuffix},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[USERNAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""USERNAME"", resultMapping.getColumn());
        Assert.assertEquals(""userName"", resultMapping.getProperty());
        Assert.assertNull(resultMapping.getJdbcType());
        Assert.assertEquals(StringTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
"
"    @Test
    public void testLowercase(){
        EntityHelper.initEntityNameMap(UserLowercase.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserLowercase.class);
        Assert.assertNotNull(entityTable);
        Assert.assertEquals(""userlowercase"", entityTable.getName());

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""username"", column.getColumn());
            Assert.assertEquals(""userName"", column.getProperty());

            Assert.assertEquals(""username = #{userName}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""username = #{record.userName}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{userName}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.userNamesuffix},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[USERNAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""username"", resultMapping.getColumn());
        Assert.assertEquals(""userName"", resultMapping.getProperty());
        Assert.assertNull(resultMapping.getJdbcType());
        Assert.assertEquals(StringTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
"
"    @Test
    public void testColumn(){
        EntityHelper.initEntityNameMap(UserColumn.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserColumn.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""user_name"", column.getColumn());
            Assert.assertEquals(""name"", column.getProperty());

            Assert.assertEquals(""user_name = #{name}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""user_name = #{record.name}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{name}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.name}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.name}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.namesuffix},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[USER_NAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""user_name"", resultMapping.getColumn());
        Assert.assertEquals(""name"", resultMapping.getProperty());
        Assert.assertNull(resultMapping.getJdbcType());
        Assert.assertEquals(StringTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
"
"    @Test
    public void testJdbcTypeVarchar(){
        EntityHelper.initEntityNameMap(UserJdbcTypeVarchar.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserJdbcTypeVarchar.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""name"", column.getColumn());
            Assert.assertEquals(""name"", column.getProperty());

            Assert.assertEquals(""name = #{name, jdbcType=VARCHAR}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""name = #{record.name, jdbcType=VARCHAR}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{name, jdbcType=VARCHAR}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.name, jdbcType=VARCHAR}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.name, jdbcType=VARCHAR}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.namesuffix, jdbcType=VARCHAR},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[NAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""name"", resultMapping.getColumn());
        Assert.assertEquals(""name"", resultMapping.getProperty());
        Assert.assertNotNull(resultMapping.getJdbcType());
        Assert.assertEquals(JdbcType.VARCHAR, resultMapping.getJdbcType());
        Assert.assertEquals(StringTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
"
"    @Test
    public void testJdbcTypeBlob(){
        EntityHelper.initEntityNameMap(UserJdbcTypeBlob.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserJdbcTypeBlob.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""name"", column.getColumn());
            Assert.assertEquals(""name"", column.getProperty());

            Assert.assertEquals(""name = #{name, jdbcType=BLOB}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""name = #{record.name, jdbcType=BLOB}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{name, jdbcType=BLOB}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.name, jdbcType=BLOB}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.name, jdbcType=BLOB}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.namesuffix, jdbcType=BLOB},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[NAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""name"", resultMapping.getColumn());
        Assert.assertEquals(""name"", resultMapping.getProperty());
        Assert.assertNotNull(resultMapping.getJdbcType());
        Assert.assertEquals(JdbcType.BLOB, resultMapping.getJdbcType());
        Assert.assertEquals(StringTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
"
"    @Test
    public void testTypehandler(){
        EntityHelper.initEntityNameMap(UserTypehandler.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserTypehandler.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""name"", column.getColumn());
            Assert.assertEquals(""name"", column.getProperty());

            Assert.assertEquals(""name = #{name, typeHandler=org.apache.ibatis.type.BlobTypeHandler}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""name = #{record.name, typeHandler=org.apache.ibatis.type.BlobTypeHandler}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{name, typeHandler=org.apache.ibatis.type.BlobTypeHandler}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.name, typeHandler=org.apache.ibatis.type.BlobTypeHandler}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.name, typeHandler=org.apache.ibatis.type.BlobTypeHandler}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.namesuffix, typeHandler=org.apache.ibatis.type.BlobTypeHandler},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNotNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[NAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""name"", resultMapping.getColumn());
        Assert.assertEquals(""name"", resultMapping.getProperty());
        Assert.assertNull(resultMapping.getJdbcType());
        Assert.assertEquals(BlobTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
"
"    @Test
    public void testAll(){
        EntityHelper.initEntityNameMap(UserAll.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserAll.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""user_name"", column.getColumn());
            Assert.assertEquals(""name"", column.getProperty());

            Assert.assertEquals(""user_name = #{name, jdbcType=BLOB, typeHandler=org.apache.ibatis.type.BlobTypeHandler}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""user_name = #{record.name, jdbcType=BLOB, typeHandler=org.apache.ibatis.type.BlobTypeHandler}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{name, jdbcType=BLOB, typeHandler=org.apache.ibatis.type.BlobTypeHandler}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.name, jdbcType=BLOB, typeHandler=org.apache.ibatis.type.BlobTypeHandler}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.name, jdbcType=BLOB, typeHandler=org.apache.ibatis.type.BlobTypeHandler}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.namesuffix, jdbcType=BLOB, typeHandler=org.apache.ibatis.type.BlobTypeHandler},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNotNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[USER_NAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""user_name"", resultMapping.getColumn());
        Assert.assertEquals(""name"", resultMapping.getProperty());
        Assert.assertNotNull(resultMapping.getJdbcType());
        Assert.assertEquals(BlobTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
"
"    @Test
    public void testHashRegisterMapper(){
        MapperHelper mapperHelper = new MapperHelper();
        Assert.assertTrue(mapperHelper.isExtendCommonMapper(UserMapper.class));
    }
"
"    @Test
    public void testRoleMapper(){
        MapperHelper mapperHelper = new MapperHelper();
        Assert.assertFalse(mapperHelper.isExtendCommonMapper(RoleMapper.class));
    }
"
"    @Test
    public void testRoleMapper2(){
        MapperHelper mapperHelper = new MapperHelper();
        Assert.assertFalse(mapperHelper.isExtendCommonMapper(RoleMapper2.class));
    }
"
"    @Test
    public void testColumn() {
        EntityHelper.initEntityNameMap(User.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(User.class);
        Assert.assertNotNull(entityTable);
        Assert.assertEquals(""sys_user"", entityTable.getName());
    }
"
"    @Test
    public void test() {
        Class<?> entityClass = User.class;
        EntityHelper.initEntityNameMap(entityClass, config);
        StringBuilder sqlBuilder = new StringBuilder();
        sqlBuilder.append(SqlHelper.selectAllColumns(entityClass));
        final EntityTable entityTable = EntityHelper.getEntityTable(entityClass);
        sqlBuilder.append(SqlHelper.fromTable(entityClass, entityTable.getName()));
        sqlBuilder.append(SqlHelper.whereAllIfColumns(entityClass, config.isNotEmpty()));
        final String sql = sqlBuilder.toString();
        Assert.assertEquals(""SELECT id,user_name,address,state  FROM user "" +
                ""<where>"" +
                ""<if test=\""id != null\""> AND id = #{id}</if>"" +
                ""<if test=\""userName != null\""> AND user_name = #{userName}</if>"" +
                ""<if test=\""address != null\""> AND address = #{address, typeHandler=tk.mybatis.mapper.mapperhelper.ComplexEntityTest.AddressHandler}</if>"" +
                ""<if test=\""state != null\""> AND state = #{state}</if></where>"", sql);

        final ResultMap resultMap = entityTable.getResultMap(configuration);
        final List<ResultMapping> resultMappings = resultMap.getResultMappings();
        final ResultMapping idMapping = resultMappings.get(0);
        final ResultMapping userNameMapping = resultMappings.get(1);
        final ResultMapping addressMapping = resultMappings.get(2);
        final ResultMapping stateMapping = resultMappings.get(3);

        Assert.assertEquals(""id"", idMapping.getColumn());
        Assert.assertEquals(""id"", idMapping.getProperty());
        Assert.assertTrue(idMapping.getFlags().contains(ResultFlag.ID));

        Assert.assertEquals(""user_name"", userNameMapping.getColumn());
        Assert.assertEquals(""userName"", userNameMapping.getProperty());

        Assert.assertEquals(""address"", addressMapping.getColumn());
        Assert.assertEquals(""address"", addressMapping.getProperty());
        Assert.assertEquals(AddressHandler.class, addressMapping.getTypeHandler().getClass());

        Assert.assertEquals(""state"", stateMapping.getColumn());
        Assert.assertEquals(""state"", stateMapping.getProperty());
        Assert.assertEquals(EnumTypeHandler.class, stateMapping.getTypeHandler().getClass());


    }
"
"    @Test
    public void testUser(){
        List<EntityField> fieldList = FieldHelper.getFields(User.class);
        Assert.assertEquals(2, fieldList.size());
        Assert.assertEquals(""id"", fieldList.get(0).getName());
        Assert.assertEquals(""name"", fieldList.get(1).getName());
    }
"
"    @Test
    public void testComplex(){
        List<EntityField> fieldList = FieldHelper.getFields(Admin.class);
        Assert.assertEquals(2, fieldList.size());
        Assert.assertEquals(""admin"", fieldList.get(0).getName());
        Assert.assertEquals(""user"", fieldList.get(1).getName());
    }
"
"    @Test
    public void testLogicDeleteSql() {
        String wherePKColumns = SqlHelper.wherePKColumns(User.class);
        Assert.assertEquals(""<where> AND id = #{id} AND is_valid = 1</where>"", wherePKColumns);

        String whereAllIfColumns = SqlHelper.whereAllIfColumns(User.class, false);
        Assert.assertEquals(""<where><if test=\""id != null\""> AND id = #{id}</if><if test=\""username != null\""> AND username = #{username}</if> AND is_valid = 1</where>"", whereAllIfColumns);

        String isLogicDeletedColumn = SqlHelper.whereLogicDelete(User.class, true);
        Assert.assertEquals("" AND is_valid = 0"", isLogicDeletedColumn);

        String notLogicDeletedColumn = SqlHelper.whereLogicDelete(User.class, false);
        Assert.assertEquals("" AND is_valid = 1"", notLogicDeletedColumn);

        String updateSetColumns = SqlHelper.updateSetColumns(User.class, null, false, false);
        Assert.assertEquals(""<set>username = #{username},is_valid = 1,</set>"", updateSetColumns);
    }
"
"    @Test
    public void testUpdateByDiffer() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            Country old = mapper.selectByPrimaryKey(1L);
            //(1, 'Angola', 'AO', 1)
            Country newer = new Country();
            newer.setId(1L);
            newer.setCountryname(""Newer"");
            newer.setCountrycode(""AO"");
            int count = mapper.updateByDiffer(old, newer);
            Assert.assertEquals(1, count);
            old = mapper.selectByPrimaryKey(1L);
            Assert.assertEquals(1L, old.getId().longValue());
            Assert.assertEquals(""Newer"", old.getCountryname());
            Assert.assertEquals(""AO"", old.getCountrycode());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testUpdateByPrimaryKeySelectiveForceByNull() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryIntMapper mapper = sqlSession.getMapper(CountryIntMapper.class);
            CountryInt country = new CountryInt();
            country.setId(174);
            country.setCountryname(""è±å½"");
            mapper.updateByPrimaryKeySelectiveForce(country, null);

            country = mapper.selectByPrimaryKey(174);
            Assert.assertNotNull(country.getCountrycode());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testUpdateByPrimaryKeySelectiveForce() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryIntMapper mapper = sqlSession.getMapper(CountryIntMapper.class);
            CountryInt country = new CountryInt();
            country.setId(174);
            mapper.updateByPrimaryKeySelectiveForce(country, Arrays.asList(""countrycode"", ""countryname""));

            country = mapper.selectByPrimaryKey(174);
            Assert.assertNull(country.getCountrycode());
            Assert.assertNull(country.getCountryname());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testCount() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper mapper = sqlSession.getMapper(UserMapper.class);
            AggregateCondition aggregateCondition = AggregateCondition.builder().
                    aggregateBy(""id"").aliasName(""total"").aggregateType(AggregateType.COUNT).groupBy(""role"");
            Example example = new Example(User.class);
            List<User> m = mapper.selectAggregationByExample(example, aggregateCondition);
            Assert.assertEquals(2, m.size());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testAvg() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper mapper = sqlSession.getMapper(UserMapper.class);
            AggregateCondition aggregateCondition = AggregateCondition.builder().
                    aggregateBy(""id"").aggregateType(AggregateType.AVG);
            Example example = new Example(User.class);
            List<User> m = mapper.selectAggregationByExample(example, aggregateCondition);
            Assert.assertEquals(1, m.size());
            Assert.assertEquals(new Long(3), m.get(0).getId());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testSum() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper mapper = sqlSession.getMapper(UserMapper.class);
            AggregateCondition aggregateCondition = AggregateCondition.builder().
                    aggregateBy(""id"").aliasName(""aggregation"").aggregateType(AggregateType.SUM);
            Example example = new Example(User.class);
            List<User> m = mapper.selectAggregationByExample(example, aggregateCondition);
            Assert.assertEquals(1, m.size());
            Assert.assertEquals(new Long(21), m.get(0).getAggregation());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testMax() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper mapper = sqlSession.getMapper(UserMapper.class);
            AggregateCondition aggregateCondition = AggregateCondition.builder().
                    aggregateBy(""id"").aliasName(""aggregation"").aggregateType(AggregateType.MAX).groupBy(""role"");
            Example example = new Example(User.class);
            example.setOrderByClause(""role desc"");
            List<User> m = mapper.selectAggregationByExample(example, aggregateCondition);
            Assert.assertEquals(2, m.size());
            Assert.assertEquals(new Long(6), m.get(0).getAggregation());
            Assert.assertEquals(new Long(3), m.get(1).getAggregation());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testMin() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper mapper = sqlSession.getMapper(UserMapper.class);
            AggregateCondition aggregateCondition = AggregateCondition.builder().
                    aggregateBy(""id"").aliasName(""aggregation"").aggregateType(AggregateType.MIN);
            Example example = new Example(User.class);
            List<User> m = mapper.selectAggregationByExample(example, aggregateCondition);
            Assert.assertEquals(1, m.size());
            Assert.assertEquals(new Long(1), m.get(0).getAggregation());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testSelect() {
        SqlSession sqlSession = getSqlSession();
        try {
            DemoCountryMapper mapper = sqlSession.getMapper(DemoCountryMapper.class);
            List<DemoCountry> countries = mapper.selectAll();
            System.out.println(countries.size());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testInsertList() {
        SqlSession sqlSession = getSqlSession();
        try {
            DemoCountryMapper mapper = sqlSession.getMapper(DemoCountryMapper.class);
            List<DemoCountry> countryList = new ArrayList<DemoCountry>();
            countryList.add(new DemoCountry(""20"", ""Zimbabwe"",""ZW""));
            countryList.add(new DemoCountry(""21"", ""Zaire"",""ZR""));
            countryList.add(new DemoCountry(""22"", ""Zambia"",""ZM""));
            int updates = mapper.insertList(countryList);
            Assert.assertEquals(3, updates);
        } finally {
            //sqlSession.commit();
            sqlSession.close();
        }
    }
"
"    @Test
    public void testInsertList() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper mapper = sqlSession.getMapper(UserMapper.class);
            List<User> userList = new ArrayList<User>(countries.length);
            for (int i = 0; i < countries.length; i++) {
                userList.add(new User(countries[i][0], countries[i][1]));
            }
            Assert.assertEquals(countries.length, mapper.insertList(userList));
            for (User user : userList) {
                Assert.assertNotNull(user.getId());
                System.out.println(user.getId());
            }
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testByIdList() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            List<Long> idList = Arrays.asList(1L, 2L, 3L);
            List<Country> countryList = mapper.selectByIdList(idList);
            Assert.assertEquals(3, countryList.size());
            Assert.assertEquals(1L, (long) countryList.get(0).getId());
            Assert.assertEquals(2L, (long) countryList.get(1).getId());
            Assert.assertEquals(3L, (long) countryList.get(2).getId());
            //å é¤
            Assert.assertEquals(3, mapper.deleteByIdList(idList));
            //æ¥è¯¢ç»æ0
            Assert.assertEquals(0, mapper.selectByIdList(idList).size());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = Exception.class)
    public void testDeleteByEmptyIdList() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.deleteByIdList(new ArrayList<Long>());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testSelectByEmptyIdList() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            Assert.assertEquals(183, mapper.selectByIdList(new ArrayList<Long>()).size());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testInsert() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserTimestampMapper mapper = sqlSession.getMapper(UserTimestampMapper.class);
            UserTimestamp user = new UserTimestamp();
            user.setId(1);
            user.setJoinDate(new Timestamp(System.currentTimeMillis()));
            int count = mapper.insert(user);
            assertEquals(1, count);
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testUpdate() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserTimestampMapper mapper = sqlSession.getMapper(UserTimestampMapper.class);
            UserTimestamp user = mapper.selectByPrimaryKey(999);
            assertNotNull(user);
            Timestamp joinDate = user.getJoinDate();
            int count = mapper.updateByPrimaryKey(user);
            assertEquals(1, count);

            user = mapper.selectByPrimaryKey(999);
            assertFalse(joinDate.equals(user.getJoinDate()));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testUpdateByPrimaryKeySelective() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserTimestampMapper mapper = sqlSession.getMapper(UserTimestampMapper.class);
            UserTimestamp user = mapper.selectByPrimaryKey(999);
            assertNotNull(user);
            Timestamp joinDate = user.getJoinDate();
            int count = mapper.updateByPrimaryKeySelective(user);
            assertEquals(1, count);

            user = mapper.selectByPrimaryKey(999);
            assertFalse(joinDate.equals(user.getJoinDate()));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testUpdateInt() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserIntMapper mapper = sqlSession.getMapper(UserIntMapper.class);
            UserInt user = mapper.selectByPrimaryKey(999);
            assertNotNull(user);
            Integer age = user.getAge();
            int count = mapper.updateByPrimaryKey(user);
            assertEquals(1, count);

            user = mapper.selectByPrimaryKey(999);
            assertFalse(age.equals(user.getAge()));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testUpdateIntByPrimaryKeySelective() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserIntMapper mapper = sqlSession.getMapper(UserIntMapper.class);
            UserInt user = mapper.selectByPrimaryKey(999);
            assertNotNull(user);
            Integer age = user.getAge();
            int count = mapper.updateByPrimaryKeySelective(user);
            assertEquals(1, count);

            user = mapper.selectByPrimaryKey(999);
            assertFalse(age.equals(user.getAge()));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testCamelhumpToUnderline() {
        Assert.assertEquals(""user_id"", StringUtil.camelhumpToUnderline(""userId""));
        Assert.assertEquals(""sys_user"", StringUtil.camelhumpToUnderline(""sysUser""));
        Assert.assertEquals(""sys_user_role"", StringUtil.camelhumpToUnderline(""sysUserRole""));
        Assert.assertEquals(""s_function"", StringUtil.camelhumpToUnderline(""sFunction""));
    }
"
"    @Test
    public void test1() throws IntrospectionException {
        List<EntityField> fields = FieldHelper.getFields(Country.class);
        for (EntityField field : fields) {
            System.out.println(field.getName() + ""  -  @Id:"" + field.isAnnotationPresent(Id.class) + ""  -  javaType:"" + field.getJavaType());
        }
        System.out.println(""======================================"");

        fields = FieldHelper.getAll(Country.class);
        for (EntityField field : fields) {
            System.out.println(field.getName() + ""  -  @Id:"" + field.isAnnotationPresent(Id.class) + ""  -  javaType:"" + field.getJavaType());
        }
        System.out.println(""======================================"");
    }
"
"    @Test
    public void test2() throws IntrospectionException {
        Thread t1 = new Thread(new Runnable() {
            @Override
            public void run() {
                FieldHelper.getFields(Country.class);
            }
"
"    //    @Test
    public void test1() throws IntrospectionException {
        List<EntityField> fields = null;// = new ArrayList<EntityField>();
        processAllColumns(Country.class, fields, null);
        for (EntityField field : fields) {
            System.out.println(field.getName() + ""  -  @Id:"" + field.isAnnotationPresent(Id.class) + ""  -  javaType:"" + field.getJavaType());
        }
        System.out.println(""======================================"");

        fields = FieldHelper.getAll(Country.class);
        for (EntityField field : fields) {
            System.out.println(field.getName() + ""  -  @Id:"" + field.isAnnotationPresent(Id.class) + ""  -  javaType:"" + field.getJavaType());
        }
        System.out.println(""======================================"");
    }
"
"    @Test
    public void test2() {
        List<EntityField> fields = _getProperties(Country.class);
        for (EntityField field : fields) {
            System.out.println(field.getName() + ""  -  @Id:"" + field.isAnnotationPresent(Id.class) + ""  -  javaType:"" + field.getJavaType());
        }
        System.out.println(""======================================"");
    }
"
"    @Test
    public void testUserAutoIncrement() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserAutoIncrementMapper mapper = sqlSession.getMapper(UserAutoIncrementMapper.class);

            UserAutoIncrement user = new UserAutoIncrement();
            user.setName(""liuzh"");
            Assert.assertEquals(1, mapper.insert(user));
            Assert.assertNotNull(user.getId());

            user = mapper.selectByPrimaryKey(user.getId());
            Assert.assertEquals(""liuzh"", user.getName());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testUserAutoIncrementIdentity() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserAutoIncrementIdentityMapper mapper = sqlSession.getMapper(UserAutoIncrementIdentityMapper.class);

            UserAutoIncrementIdentity user = new UserAutoIncrementIdentity();
            user.setName(""liuzh"");
            Assert.assertEquals(1, mapper.insert(user));
            Assert.assertNotNull(user.getId());

            user = mapper.selectByPrimaryKey(user.getId());
            Assert.assertEquals(""liuzh"", user.getName());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testUserSqlAfter() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserSqlAfterMapper mapper = sqlSession.getMapper(UserSqlAfterMapper.class);

            UserSqlAfter user = new UserSqlAfter();
            user.setName(""liuzh"");
            Assert.assertEquals(1, mapper.insert(user));
            Assert.assertNotNull(user.getId());

            user = mapper.selectByPrimaryKey(user.getId());
            Assert.assertEquals(""liuzh"", user.getName());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testUserSqlBefore() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserSqlBeforeMapper mapper = sqlSession.getMapper(UserSqlBeforeMapper.class);

            UserSqlBefore user = new UserSqlBefore();
            user.setName(""liuzh"");
            Assert.assertEquals(1, mapper.insert(user));
            Assert.assertEquals(new Integer(12345), user.getId());

            user = mapper.selectByPrimaryKey(12345);
            Assert.assertEquals(""liuzh"", user.getName());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testSelect() {
        SqlSession sqlSession = getSqlSession();
        try {
            TimeModelMapper mapper = sqlSession.getMapper(TimeModelMapper.class);
            List<TimeModel> list = mapper.selectAll();
            Assert.assertEquals(2, list.size());

            Assert.assertEquals(""2018-01-01"", toDate(list.get(0).getTestDate()));
            Assert.assertEquals(""12:11:00"", toTime(list.get(0).getTestTime()));
            Assert.assertEquals(""2018-01-01 12:00:00"", toDatetime(list.get(0).getTestDatetime()));

            Assert.assertEquals(""2018-11-11"", toDate(list.get(1).getTestDate()));
            Assert.assertEquals(""01:59:11"", toTime(list.get(1).getTestTime()));
            Assert.assertEquals(""2018-02-12 17:58:12"", toDatetime(list.get(1).getTestDatetime()));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testInsert() {
        SqlSession sqlSession = getSqlSession();
        try {
            TimeModelMapper mapper = sqlSession.getMapper(TimeModelMapper.class);
            TimeModel timeModel = new TimeModel();
            timeModel.setId(3);
            Date now = new Date();
            timeModel.setTestDate(now);
            timeModel.setTestTime(now);
            timeModel.setTestDatetime(now);
            Assert.assertEquals(1, mapper.insert(timeModel));

            timeModel = mapper.selectByPrimaryKey(3);

            //ä¿å­åæ°æ®åºä¸­ä¸å­å¨æ¶é´é¨å
            Assert.assertEquals(toDate(now), toDate(timeModel.getTestDate()));
            Assert.assertEquals(toDate(now) + "" 00:00:00"", toDatetime(timeModel.getTestDate()));

            //æ¥æåæ¶é´é½æ
            Assert.assertEquals(toTime(now), toTime(timeModel.getTestTime()));
            Assert.assertEquals(toDatetime(now), toDatetime(timeModel.getTestTime()));

            Assert.assertEquals(toDatetime(now), toDatetime(timeModel.getTestDatetime()));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testSelect2() {
        SqlSession sqlSession = getSqlSession();
        try {
            TimeModel2Mapper mapper = sqlSession.getMapper(TimeModel2Mapper.class);
            List<TimeModel2> list = mapper.selectAll();
            Assert.assertEquals(2, list.size());

            Assert.assertEquals(""2018-01-01"", toDate(list.get(0).getTestDate()));
            Assert.assertEquals(""12:11:00"", toTime(list.get(0).getTestTime()));
            Assert.assertEquals(""2018-01-01 12:00:00"", toDatetime(list.get(0).getTestDatetime()));

            Assert.assertEquals(""2018-11-11"", toDate(list.get(1).getTestDate()));
            Assert.assertEquals(""01:59:11"", toTime(list.get(1).getTestTime()));
            Assert.assertEquals(""2018-02-12 17:58:12"", toDatetime(list.get(1).getTestDatetime()));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testInsert2() {
        SqlSession sqlSession = getSqlSession();
        try {
            TimeModel2Mapper mapper = sqlSession.getMapper(TimeModel2Mapper.class);
            TimeModel2 timeModel = new TimeModel2();
            timeModel.setId(3);
            Date now = new Date();
            Timestamp now2 = new Timestamp(now.getTime());
            timeModel.setTestDate(now);
            timeModel.setTestTime(now);
            timeModel.setTestDatetime(now2);
            Assert.assertEquals(1, mapper.insert(timeModel));

            timeModel = mapper.selectByPrimaryKey(3);

            //ä¿å­åæ°æ®åºä¸­ä¸å­å¨æ¶é´é¨å
            Assert.assertEquals(toDate(now), toDate(timeModel.getTestDate()));
            Assert.assertEquals(toDate(now) + "" 00:00:00"", toDatetime(timeModel.getTestDate()));

            //æ¥æåæ¶é´é½æ
            Assert.assertEquals(toTime(now), toTime(timeModel.getTestTime()));
            Assert.assertEquals(toDatetime(now), toDatetime(timeModel.getTestTime()));

            Assert.assertEquals(toDatetime(now), toDatetime(timeModel.getTestDatetime()));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testSelect3() {
        SqlSession sqlSession = getSqlSession();
        try {
            TimeModel3Mapper mapper = sqlSession.getMapper(TimeModel3Mapper.class);
            List<TimeModel3> list = mapper.selectAll();
            Assert.assertEquals(2, list.size());

            Assert.assertEquals(""2018-01-01"", toDate(list.get(0).getTestDate()));
            Assert.assertEquals(""12:11:00"", toTime(list.get(0).getTestTime()));
            Assert.assertEquals(""2018-01-01 12:00:00"", toDatetime(list.get(0).getTestDatetime()));

            Assert.assertEquals(""2018-11-11"", toDate(list.get(1).getTestDate()));
            Assert.assertEquals(""01:59:11"", toTime(list.get(1).getTestTime()));
            Assert.assertEquals(""2018-02-12 17:58:12"", toDatetime(list.get(1).getTestDatetime()));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testInsert3() {
        SqlSession sqlSession = getSqlSession();
        try {
            TimeModel3Mapper mapper = sqlSession.getMapper(TimeModel3Mapper.class);
            TimeModel3 timeModel = new TimeModel3();
            timeModel.setId(3);
            Date now = new Date();
            timeModel.setTestDate(now);
            timeModel.setTestTime(now);
            timeModel.setTestDatetime(now);
            /*
                insert æ¥å¿è½ææ¾çå°å¶å® jdbcType åçåºå«

                DEBUG [main] - ==>  Preparing: INSERT INTO test_timestamp ( id,test_date,test_time,test_datetime ) VALUES( ?,?,?,? )
                DEBUG [main] - ==> Parameters: 3(Integer), 2018-02-25(Date), 11:50:18(Time), 2018-02-25 11:50:18.263(Timestamp)
             */
            Assert.assertEquals(1, mapper.insert(timeModel));

            timeModel = mapper.selectByPrimaryKey(3);

            //ä¿å­åæ°æ®åºä¸­ä¸å­å¨æ¶é´é¨å
            Assert.assertEquals(toDate(now), toDate(timeModel.getTestDate()));
            Assert.assertEquals(toDate(now) + "" 00:00:00"", toDatetime(timeModel.getTestDate()));

            //æ¶é´
            Assert.assertEquals(toTime(now), toTime(timeModel.getTestTime()));
            //ç±äºæå¥æ°æ®åºæ¶æå®ç jdbcType=TIMEï¼æä»¥ä¸é¢æ¯æ²¡ææ¥æé¨åç
            Assert.assertEquals(""1970-01-01 "" + toTime(now), toDatetime(timeModel.getTestTime()));

            Assert.assertEquals(toDatetime(now), toDatetime(timeModel.getTestDatetime()));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testSelect(){
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
            List<User> users = userMapper.selectAll();
            Assert.assertNotNull(users);
            Assert.assertEquals(2, users.size());

            Assert.assertEquals(""abel533"", users.get(0).getName());
            Assert.assertEquals(LockDictEnum.unlocked, users.get(0).getLock());
            Assert.assertEquals(StateDictEnum.enabled, users.get(0).getState());

            Assert.assertEquals(""isea533"", users.get(1).getName());
            Assert.assertEquals(LockDictEnum.locked, users.get(1).getLock());
            Assert.assertEquals(StateDictEnum.disabled, users.get(1).getState());

            User user = userMapper.selectByPrimaryKey(1);
            Assert.assertEquals(""abel533"", user.getName());
            Assert.assertEquals(LockDictEnum.unlocked, users.get(0).getLock());
            Assert.assertEquals(StateDictEnum.enabled, user.getState());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testInsert(){
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper userMapper = sqlSession.getMapper(UserMapper.class);

            User user = new User();
            user.setId(3);
            user.setName(""liuzh"");
            user.setLock(LockDictEnum.unlocked);
            user.setState(StateDictEnum.enabled);

            Assert.assertEquals(1, userMapper.insert(user));

            user = userMapper.selectByPrimaryKey(3);
            Assert.assertEquals(""liuzh"", user.getName());
            Assert.assertEquals(LockDictEnum.unlocked, user.getLock());
            Assert.assertEquals(StateDictEnum.enabled, user.getState());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testUpdate(){
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
            User user = userMapper.selectByPrimaryKey(1);
            Assert.assertEquals(""abel533"", user.getName());
            Assert.assertEquals(LockDictEnum.unlocked, user.getLock());
            Assert.assertEquals(StateDictEnum.enabled, user.getState());

            user.setLock(LockDictEnum.locked);
            user.setState(StateDictEnum.disabled);
            Assert.assertEquals(1, userMapper.updateByPrimaryKey(user));

            user = userMapper.selectByPrimaryKey(1);
            Assert.assertEquals(""abel533"", user.getName());
            Assert.assertEquals(LockDictEnum.locked, user.getLock());
            Assert.assertEquals(StateDictEnum.disabled, user.getState());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testDelete(){
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
            Assert.assertEquals(1, userMapper.deleteByPrimaryKey(1));

            User user = new User();
            user.setState(StateDictEnum.enabled);
            Assert.assertEquals(0, userMapper.delete(user));

            user = new User();
            user.setLock(LockDictEnum.unlocked);
            Assert.assertEquals(0, userMapper.delete(user));

            user = new User();
            user.setLock(LockDictEnum.locked);
            user.setState(StateDictEnum.disabled);
            Assert.assertEquals(1, userMapper.delete(user));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeUpdate() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.updateByExample(new Country(), new Example(Country.class));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeUpdateNull() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.updateByExample(new Country(), null);
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeUpdateNull2() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.updateByExample(null, null);
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeUpdateByExample() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.updateByExampleSelective(new Country(), new Example(Country.class));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeUpdateByExampleNull() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.updateByExampleSelective(new Country(), null);
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeUpdate() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.updateByExample(new Country(), new Example(Country.class));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeUpdateNull() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.updateByExample(new Country(), null);
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeUpdateNull2() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.updateByExample(null, null);
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeUpdateByExample() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.updateByExampleSelective(new Country(), new Example(Country.class));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeUpdateByExampleNull() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.updateByExampleSelective(new Country(), null);
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeDelete() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.delete(new Country());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeDeleteNull() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.delete(null);
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeDeleteByExample() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.deleteByExample(new Example(Country.class));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeDeleteByExampleNull() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.deleteByExample(null);
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeDelete() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.delete(new Country());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeDeleteNull() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.delete(null);
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeDeleteByExample() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.deleteByExample(new Example(Country.class));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test(expected = PersistenceException.class)
    public void testSafeDeleteByExampleNull() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.deleteByExample(null);
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testDeleteByPrimaryKey(){
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            Assert.assertEquals(183, mapper.selectAll().size());
            Assert.assertEquals(1, mapper.deleteByPrimaryKey(1L));
            Assert.assertEquals(182, mapper.selectAll().size());

            Assert.assertEquals(1, mapper.deleteByPrimaryKey(2));
            Assert.assertEquals(181, mapper.selectAll().size());

            Assert.assertEquals(1, mapper.deleteByPrimaryKey(""3""));
            Assert.assertEquals(180, mapper.selectAll().size());

            Assert.assertEquals(0, mapper.deleteByPrimaryKey(1));
            Assert.assertEquals(180, mapper.selectAll().size());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testSelect(){
        SqlSession sqlSession = getSqlSession();
        try {
            User2Mapper userMapper = sqlSession.getMapper(User2Mapper.class);
            List<User2> users = userMapper.selectAll();
            Assert.assertNotNull(users);
            Assert.assertEquals(2, users.size());

            Assert.assertEquals(""abel533"", users.get(0).getName());
            Assert.assertEquals(""Hebei"", users.get(0).getAddress().getProvince());
            Assert.assertEquals(""Shijiazhuang"", users.get(0).getAddress().getCity());
            Assert.assertEquals(StateEnum.enabled, users.get(0).getState());

            Assert.assertEquals(""isea533"", users.get(1).getName());
            Assert.assertEquals(""Hebei/Handan"", users.get(1).getAddress().toString());
            Assert.assertEquals(StateEnum.disabled, users.get(1).getState());

            User2 user = userMapper.selectByPrimaryKey(1);
            Assert.assertEquals(""abel533"", user.getName());
            Assert.assertEquals(""Hebei"", user.getAddress().getProvince());
            Assert.assertEquals(""Shijiazhuang"", user.getAddress().getCity());
            Assert.assertEquals(StateEnum.enabled, user.getState());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testInsert(){
        SqlSession sqlSession = getSqlSession();
        try {
            User2Mapper userMapper = sqlSession.getMapper(User2Mapper.class);

            User2 user = new User2();
            user.setId(3);
            user.setName(""liuzh"");
            Address address = new Address();
            address.setProvince(""Hebei"");
            address.setCity(""Qinhuangdao"");
            user.setAddress(address);
            user.setState(StateEnum.enabled);

            Assert.assertEquals(1, userMapper.insert(user));

            user = userMapper.selectByPrimaryKey(3);
            Assert.assertEquals(""liuzh"", user.getName());
            Assert.assertEquals(""Hebei"", user.getAddress().getProvince());
            Assert.assertEquals(""Qinhuangdao"", user.getAddress().getCity());
            Assert.assertEquals(StateEnum.enabled, user.getState());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testUpdate(){
        SqlSession sqlSession = getSqlSession();
        try {
            User2Mapper userMapper = sqlSession.getMapper(User2Mapper.class);
            User2 user = userMapper.selectByPrimaryKey(1);
            Assert.assertEquals(""abel533"", user.getName());
            Assert.assertEquals(""Hebei"", user.getAddress().getProvince());
            Assert.assertEquals(""Shijiazhuang"", user.getAddress().getCity());
            Assert.assertEquals(StateEnum.enabled, user.getState());

            user.setState(StateEnum.disabled);
            user.getAddress().setCity(""Handan"");
            Assert.assertEquals(1, userMapper.updateByPrimaryKey(user));

            user = userMapper.selectByPrimaryKey(1);
            Assert.assertEquals(""abel533"", user.getName());
            Assert.assertEquals(""Hebei"", user.getAddress().getProvince());
            Assert.assertEquals(""Handan"", user.getAddress().getCity());
            Assert.assertEquals(StateEnum.disabled, user.getState());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testDelete(){
        SqlSession sqlSession = getSqlSession();
        try {
            User2Mapper userMapper = sqlSession.getMapper(User2Mapper.class);
            Assert.assertEquals(1, userMapper.deleteByPrimaryKey(1));

            User2 user = new User2();
            Address address = new Address();
            address.setProvince(""Hebei"");
            address.setCity(""Handan"");
            user.setAddress(address);
            user.setState(StateEnum.enabled);
            Assert.assertEquals(0, userMapper.delete(user));

            user.setState(StateEnum.disabled);
            Assert.assertEquals(1, userMapper.delete(user));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testSelect(){
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
            List<User> users = userMapper.selectAll();
            Assert.assertNotNull(users);
            Assert.assertEquals(2, users.size());

            Assert.assertEquals(""abel533"", users.get(0).getName());
            Assert.assertEquals(""Hebei"", users.get(0).getAddress().getProvince());
            Assert.assertEquals(""Shijiazhuang"", users.get(0).getAddress().getCity());
            Assert.assertEquals(StateEnum.enabled, users.get(0).getState());

            Assert.assertEquals(""isea533"", users.get(1).getName());
            Assert.assertEquals(""Hebei/Handan"", users.get(1).getAddress().toString());
            Assert.assertEquals(StateEnum.disabled, users.get(1).getState());

            User user = userMapper.selectByPrimaryKey(1);
            Assert.assertEquals(""abel533"", user.getName());
            Assert.assertEquals(""Hebei"", user.getAddress().getProvince());
            Assert.assertEquals(""Shijiazhuang"", user.getAddress().getCity());
            Assert.assertEquals(StateEnum.enabled, user.getState());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testInsert(){
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper userMapper = sqlSession.getMapper(UserMapper.class);

            User user = new User();
            user.setId(3);
            user.setName(""liuzh"");
            Address address = new Address();
            address.setProvince(""Hebei"");
            address.setCity(""Qinhuangdao"");
            user.setAddress(address);
            user.setState(StateEnum.enabled);

            Assert.assertEquals(1, userMapper.insert(user));

            user = userMapper.selectByPrimaryKey(3);
            Assert.assertEquals(""liuzh"", user.getName());
            Assert.assertEquals(""Hebei"", user.getAddress().getProvince());
            Assert.assertEquals(""Qinhuangdao"", user.getAddress().getCity());
            Assert.assertEquals(StateEnum.enabled, user.getState());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testUpdate(){
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
            User user = userMapper.selectByPrimaryKey(1);
            Assert.assertEquals(""abel533"", user.getName());
            Assert.assertEquals(""Hebei"", user.getAddress().getProvince());
            Assert.assertEquals(""Shijiazhuang"", user.getAddress().getCity());
            Assert.assertEquals(StateEnum.enabled, user.getState());

            user.setState(StateEnum.disabled);
            user.getAddress().setCity(""Handan"");
            Assert.assertEquals(1, userMapper.updateByPrimaryKey(user));

            user = userMapper.selectByPrimaryKey(1);
            Assert.assertEquals(""abel533"", user.getName());
            Assert.assertEquals(""Hebei"", user.getAddress().getProvince());
            Assert.assertEquals(""Handan"", user.getAddress().getCity());
            Assert.assertEquals(StateEnum.disabled, user.getState());
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testDelete(){
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
            Assert.assertEquals(1, userMapper.deleteByPrimaryKey(1));

            User user = new User();
            Address address = new Address();
            address.setProvince(""Hebei"");
            address.setCity(""Handan"");
            user.setAddress(address);
            user.setState(StateEnum.enabled);
            Assert.assertEquals(0, userMapper.delete(user));

            user.setState(StateEnum.disabled);
            Assert.assertEquals(1, userMapper.delete(user));
        } finally {
            sqlSession.close();
        }
    }
"
"    @Test
    public void testNormal() {
        for (String field : fields) {
            Assert.assertEquals(field, StringUtil.convertByStyle(field, Style.normal));
        }
    }
"
"    @Test
    public void testUppercase() {
        for (String field : fields) {
            Assert.assertEquals(field.toUpperCase(), StringUtil.convertByStyle(field, Style.uppercase));
        }
    }
"
"    @Test
    public void testLowercase() {
        for (String field : fields) {
            Assert.assertEquals(field.toLowerCase(), StringUtil.convertByStyle(field, Style.lowercase));
        }
    }
"
"    @Test
    public void testCamelhump() {
        for (String field : fields) {
            System.out.println(field + "" - "" + StringUtil.convertByStyle(field, Style.camelhump));
        }
    }
"
"    @Test
    public void testCamelhumpUppercase() {
        for (String field : fields) {
            System.out.println(field + "" - "" + StringUtil.convertByStyle(field, Style.camelhumpAndUppercase));
        }
    }
"
"    @Test
    public void testCamelhumpLowercase() {
        for (String field : fields) {
            System.out.println(field + "" - "" + StringUtil.convertByStyle(field, Style.camelhumpAndLowercase));
        }
    }
"
"    @Test
    public void test(){
        Matcher matcher = DELIMITER.matcher(""normal"");
        if(matcher.find()){
            Assert.assertEquals(""normal"", matcher.group(1));
        }

        matcher = DELIMITER.matcher(""`mysql`"");
        if(matcher.find()){
            Assert.assertEquals(""mysql"", matcher.group(1));
        }

        matcher = DELIMITER.matcher(""[sqlserver]"");
        if(matcher.find()){
            Assert.assertEquals(""sqlserver"", matcher.group(1));
        }

        matcher = DELIMITER.matcher(""\""oracle\"""");
        if(matcher.find()){
            Assert.assertEquals(""oracle"", matcher.group(1));
        }
    }
"
"    @Test
    public void testDynamicSelectAll() {
        SqlSession sqlSession = MybatisHelper.getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            Country country = new Country();
            List<Country> countryList;
            //country.setDynamicTableName123(""country_123"");
            //countryList = mapper.select(country);
            //æ¥è¯¢æ»æ°
            //Assert.assertEquals(2, countryList.size());

            country.setDynamicTableName123(null);
            countryList = mapper.select(country);
            //æ¥è¯¢æ»æ°
            Assert.assertEquals(183, countryList.size());
        } finally {
            sqlSession.close();
        }
    }
"
