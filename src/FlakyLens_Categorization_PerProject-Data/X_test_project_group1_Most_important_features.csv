full_code
"@Test
public void testAddRemoveRenewAction() throws IOException, InterruptedException {
    TestFileSystem tfs = new TestFileSystem();
    renewer.addRenewAction(tfs);
    for (int i = 0; i < 60; i++) {
        Thread.sleep(RENEW_CYCLE);
        if (tfs.testToken.renewCount > 0) {
            renewer.removeRenewAction(tfs);
            break;
        }
    }
    assertTrue(""Token not renewed even after 1 minute"", tfs.testToken.renewCount > 0);
    assertTrue(""Token not removed"", tfs.testToken.renewCount < MAX_RENEWALS);
    assertTrue(""Token not cancelled"", tfs.testToken.cancelled);
}"
"@Test
public void testRunWriteAfterRead() {
    final Function1<CancelIndicator, Integer> _function = (CancelIndicator it) -> {
        return Integer.valueOf(this.sharedState.incrementAndGet());
    };
    this.requestManager.<Integer>runRead(_function);
    final Function0<Object> _function_1 = () -> {
        return null;
    };
    final Function2<CancelIndicator, Object, Integer> _function_2 = (CancelIndicator $0,Object $1) -> {
        int _xblockexpression = ((int) (0));
        {
            Assert.assertEquals(1, this.sharedState.get());
            _xblockexpression = this.sharedState.incrementAndGet();
        }
        return Integer.valueOf(_xblockexpression);
    };
    this.requestManager.<Object, Integer>runWrite(_function_1, _function_2).join();
    Assert.assertEquals(2, this.sharedState.get());
}"
"@Test
public void testToMetricResponse() throws Exception {
    String subscriptionId = ""12345"";
    long ts = 1000L;
    List<Tag> tags = new ArrayList<>();
    tags.add(new Tag(""tag1"", ""value1""));
    Metric m = Metric.newBuilder().name(""sys.cpu.user"").value(ts, 2.0).tags(tags).tag(VISIBILITY_TAG, ""(a&b)|(c&d)"").build();
    String json = JsonUtil.getObjectMapper().writeValueAsString(MetricResponse.fromMetric(m, subscriptionId));
    String expected = ""{\""metric\"":\""sys.cpu.user\"",\""timestamp\"":1000,\""value\"":2.0,\""tags\"":[{\""tag1\"":\""value1\""},{\""viz\"":\""(a&b)|(c&d)\""}],\""subscriptionId\"":\""12345\"",\""complete\"":false}"";
    Assert.assertEquals(expected, json);
}"
"@Test
public void testToFile() throws Exception {
    item = new PathData(""."", conf);
    assertEquals(new File(testDir.toString()), item.toFile());
    item = new PathData(""d1/f1"", conf);
    assertEquals(new File(testDir + ""/d1/f1""), item.toFile());
    item = new PathData(testDir + ""/d1/f1"", conf);
    assertEquals(new File(testDir + ""/d1/f1""), item.toFile());
}"
"@Test
public void test_parseLString() throws Exception {
    DateFormat format = DateFormat.getDateTimeInstance(DateFormat.FULL, DateFormat.FULL, Locale.US);
    try {
        Date date = format.parse(format.format(current).toString());
        assertEquals(current.getDate(), date.getDate());
        assertEquals(current.getDay(), date.getDay());
        assertEquals(current.getMonth(), date.getMonth());
        assertEquals(current.getYear(), date.getYear());
        assertEquals(current.getHours(), date.getHours());
        assertEquals(current.getMinutes(), date.getMinutes());
    } catch(ParseException pe) {
    fail(""ParseException was thrown for current Date.""); }
    try {
        format.parse(""January 16, 1970 8:03:52 PM CET"");
        fail(""ParseException was not thrown."");
    } catch(ParseException pe) { }
}"
"@Test
public void testRemoveContext() throws IOException {
    String dir = buildBufferDir(ROOT, 0);
    String contextCfgItemName = ""application_1340842292563_0004.app.cache.dirs"";
    conf.set(contextCfgItemName, dir);
    LocalDirAllocator localDirAllocator = new LocalDirAllocator(contextCfgItemName);
    localDirAllocator.getLocalPathForWrite(""p1/x"", SMALL_FILE_SIZE, conf);
    assertTrue(LocalDirAllocator.isContextValid(contextCfgItemName));
    LocalDirAllocator.removeContext(contextCfgItemName);
    assertFalse(LocalDirAllocator.isContextValid(contextCfgItemName));
}"
"@Test
public void testSimple() throws Exception {
    Configuration conf = new Configuration();
    MyResourceManager rm = new MyResourceManager(conf);
    rm.start();
    DrainDispatcher dispatcher = ((DrainDispatcher) (rm.getRMContext().getDispatcher()));
    RMApp app = rm.submitApp(1024);
    dispatcher.await();
    MockNM amNodeManager = rm.registerNode(""amNM:1234"", 2048);
    amNodeManager.nodeHeartbeat(true);
    dispatcher.await();
    ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt().getAppAttemptId();
    rm.sendAMLaunched(appAttemptId);
    dispatcher.await();
    JobId jobId = MRBuilderUtils.newJobId(appAttemptId.getApplicationId(), 0);
    Job mockJob = mock(Job.class);
    when(mockJob.getReport()).thenReturn(MRBuilderUtils.newJobReport(jobId, ""job"", ""user"", RUNNING, 0, 0, 0, 0, 0, 0, ""jobfile""));
    MyContainerAllocator allocator = new MyContainerAllocator(rm, conf, appAttemptId, mockJob);
    MockNM nodeManager1 = rm.registerNode(""h1:1234"", 10240);
    MockNM nodeManager2 = rm.registerNode(""h2:1234"", 10240);
    MockNM nodeManager3 = rm.registerNode(""h3:1234"", 10240);
    dispatcher.await();
    ContainerRequestEvent event1 = createReq(jobId, 1, 1024, new String[]{ ""h1"" });
    allocator.sendRequest(event1);
    ContainerRequestEvent event2 = createReq(jobId, 2, 1024, new String[]{ ""h2"" });
    allocator.sendRequest(event2);
    List<TaskAttemptContainerAssignedEvent> assigned = allocator.schedule();
    dispatcher.await();
    Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size());
    ContainerRequestEvent event3 = createReq(jobId, 3, 1024, new String[]{ ""h3"" });
    allocator.sendRequest(event3);
    assigned = allocator.schedule();
    dispatcher.await();
    Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size());
    nodeManager1.nodeHeartbeat(true);
    nodeManager2.nodeHeartbeat(true);
    nodeManager3.nodeHeartbeat(true);
    dispatcher.await();
    assigned = allocator.schedule();
    dispatcher.await();
    checkAssignments(new ContainerRequestEvent[]{ event1, event2, event3 }, assigned, false);
}"
"@Test
public void shouldHighPriorityNodeStartElectionFirst() {
    final AtomicBoolean highPrioElectionTriggered = spy(new AtomicBoolean());
    final AtomicBoolean lowPrioElectionTriggered = spy(new AtomicBoolean());
    final int targetPriority = 4;
    final PriorityElectionTimer timerHighPrio = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> highPrioElectionTriggered.set(true), log, targetPriority, targetPriority);
    final PriorityElectionTimer timerLowPrio = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> lowPrioElectionTriggered.set(true), log, targetPriority, 1);
    timerLowPrio.reset();
    timerHighPrio.reset();
    Awaitility.await().until(highPrioElectionTriggered::get);
    Awaitility.await().until(lowPrioElectionTriggered::get);
    final var inorder = Mockito.inOrder(highPrioElectionTriggered, lowPrioElectionTriggered);
    inorder.verify(highPrioElectionTriggered).set(true);
    inorder.verify(lowPrioElectionTriggered).set(true);
}"
"@Test
public void testApiAuthToken() {
    ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>>newHashSet(Controller.class), URI).iterator().next();
    Assert.assertEquals(""TOKEN"", apiDoc.getAuth().getType());
    Assert.assertEquals("""", apiDoc.getAuth().getScheme());
    Assert.assertEquals(""abc"", apiDoc.getAuth().getTesttokens().iterator().next());
    for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
        if (apiMethodDoc.getPath().contains(""/inherit"")) {
            Assert.assertEquals(""TOKEN"", apiMethodDoc.getAuth().getType());
            Assert.assertEquals("""", apiMethodDoc.getAuth().getScheme());
            Assert.assertEquals(""abc"", apiMethodDoc.getAuth().getTesttokens().iterator().next());
        }
        if (apiMethodDoc.getPath().contains(""/override"")) {
            Assert.assertEquals(""TOKEN"", apiMethodDoc.getAuth().getType());
            Assert.assertEquals(""Bearer"", apiMethodDoc.getAuth().getScheme());
            Assert.assertEquals(""xyz"", apiMethodDoc.getAuth().getTesttokens().iterator().next());
        }
    }
}"
"@Test
public void testDelegationTokenSecretManager() throws Exception {
    DelegationTokenSecretManager dtSecretManager = cluster.getNameNode().getNamesystem().getDelegationTokenSecretManager();
    Token<DelegationTokenIdentifier> token = generateDelegationToken(""SomeUser"", ""JobTracker"");
    try {
        dtSecretManager.renewToken(token, ""FakeRenewer"");
        Assert.fail(""should have failed"");
    } catch (AccessControlException ace) {
    }
    dtSecretManager.renewToken(token, ""JobTracker"");
    DelegationTokenIdentifier identifier = new DelegationTokenIdentifier();
    byte[] tokenId = token.getIdentifier();
    identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId)));
    Assert.assertTrue(null != dtSecretManager.retrievePassword(identifier));
    LOG.info(""Sleep to expire the token"");
    Thread.sleep(6000);
    try {
        dtSecretManager.retrievePassword(identifier);
        Assert.fail(""Token should have expired"");
    } catch (InvalidToken e) {
    }
    dtSecretManager.renewToken(token, ""JobTracker"");
    LOG.info(""Sleep beyond the max lifetime"");
    Thread.sleep(5000);
    try {
        dtSecretManager.renewToken(token, ""JobTracker"");
        Assert.fail(""should have been expired"");
    } catch (InvalidToken it) {
    }
}"
"@Test
public void testClientUpdateWithDelayedRevoke() throws Exception {
    OzoneConfiguration conf = new OzoneConfiguration();
    SCMUpdateServiceGrpcServer server = new SCMUpdateServiceGrpcServer(getUpdateServiceConfig(conf), mockCRLStore);
    ClientCRLStore clientCRLStore = new ClientCRLStore();
    SCMUpdateClientConfiguration updateClientConfiguration = conf.getObject(SCMUpdateClientConfiguration.class);
    updateClientConfiguration.setClientCrlCheckInterval(Duration.ofSeconds(2));
    conf.setFromObject(updateClientConfiguration);
    SCMUpdateServiceGrpcClient client = new SCMUpdateServiceGrpcClient(""localhost"", conf, clientCRLStore);
    server.start();
    client.start();
    try {
        List<BigInteger> certIds = new ArrayList<>();
        for (int i = 0; i < 10; i++) {
            BigInteger certId = mockCRLStore.issueCert();
            certIds.add(certId);
        }
        revokeCertNow(certIds.get(0));
        server.notifyCrlUpdate();
        GenericTestUtils.waitFor(() -> client.getUpdateCount() == 1, 100, 2000);
        Assert.assertEquals(1, client.getUpdateCount());
        Assert.assertEquals(0, client.getErrorCount());
        revokeCert(certIds.get(5), Instant.now().plus(Duration.ofSeconds(5)));
        server.notifyCrlUpdate();
        GenericTestUtils.waitFor(() -> client.getUpdateCount() > 1, 100, 2000);
        Assert.assertEquals(2, client.getUpdateCount());
        Assert.assertEquals(0, client.getErrorCount());
        Assert.assertEquals(1, client.getClientCRLStore().getPendingCrlIds().size());
        GenericTestUtils.waitFor(() -> client.getPendingCrlRemoveCount() == 1, 100, 20000);
        Assert.assertTrue(client.getClientCRLStore().getPendingCrlIds().isEmpty());
    } catch (Exception e) {
        e.printStackTrace();
    } finally {
        client.stop(true);
        server.stop();
    }
}"
"@Test
public void testReadSkip() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.getConf().setLong(""test.io.skip.size"", 1);
    bench.randomReadTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_READ_SKIP, execTime);
}"
"@Test
public void getFieldNamesTest() {
    List<String> names = EnumUtil.getFieldNames(TestEnum.class);
    Assert.assertEquals(CollUtil.newArrayList(""type"", ""name""), names);
}"
"@Test
public void testReadBackward() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.getConf().setLong(""test.io.skip.size"", -DEFAULT_BUFFER_SIZE);
    bench.randomReadTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_READ_BACKWARD, execTime);
}"
"@Test
public void testReadRandom() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.getConf().setLong(""test.io.skip.size"", 0);
    bench.randomReadTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_READ_RANDOM, execTime);
}"
"@Test
public void testEviction() throws Exception {
    final int CAPACITY = 3;
    PeerCache cache = PeerCache.getInstance(CAPACITY, 100000);
    DatanodeID dnIds[] = new DatanodeID[CAPACITY + 1];
    FakePeer peers[] = new FakePeer[CAPACITY + 1];
    for (int i = 0; i < dnIds.length; ++i) {
        dnIds[i] = new DatanodeID(""192.168.0.1"",
        ""fakehostname_"" + i, ""fake_storage_id_"" + i,
        100, 101, 102);
        peers[i] = new FakePeer(dnIds[i], false);
    }
    for (int i = 0; i < CAPACITY; ++i) {
        cache.put(dnIds[i], peers[i]);
    }
    assertEquals(CAPACITY, cache.size());
    cache.put(dnIds[CAPACITY], peers[CAPACITY]);
    assertEquals(CAPACITY, cache.size());
    assertSame(null, cache.get(dnIds[0], false));
    for (int i = 1; i < CAPACITY; ++i) {
        Peer peer = cache.get(dnIds[i], false);
        assertSame(peers[i], peer);
        assertTrue(!peer.isClosed());
        peer.close();
    }
    assertEquals(1, cache.size());
    cache.close();
}"
"@Test
public void testHftpDefaultPorts() throws IOException {
    resetFileSystem();
    Configuration conf = new Configuration();
    URI uri = URI.create();
    HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf)));
    assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, fs.getDefaultPort());
    assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getDefaultSecurePort());
    assertEquals(uri, fs.getUri());
    assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getCanonicalServiceName());
}"
"@Test
public void testExpiredRequestAllocationOnAnyHost() throws Exception {
    MockClusterResourceManager spyManager = spy(new MockClusterResourceManager(callback, state));
    ContainerManager spyContainerManager = spy(new ContainerManager(containerPlacementMetadataStore, state, spyManager, true, false, mock(LocalityManager.class), faultDomainManager, config));
    spyAllocator = Mockito.spy(new ContainerAllocator(spyManager, config, state, true, spyContainerManager));
    spyAllocator.requestResources(new HashMap<String, String>() {
        {
            put(""0"", ""hostname-0"");
            put(""1"", ""hostname-1"");
        }
    });
    spyAllocatorThread = new Thread(spyAllocator);
    spyAllocatorThread.start();
    Thread.sleep(1000);
    assertTrue(state.preferredHostRequests.get() == 2);
    assertTrue(state.expiredPreferredHostRequests.get() == 2);
    verify(spyContainerManager, times(1)).handleExpiredRequest(eq(""0""), eq(""hostname-0""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class));
    verify(spyContainerManager, times(1)).handleExpiredRequest(eq(""1""), eq(""hostname-1""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class));
    ArgumentCaptor<SamzaResourceRequest> cancelledRequestCaptor = ArgumentCaptor.forClass(SamzaResourceRequest.class);
    verify(spyManager, atLeast(2)).cancelResourceRequest(cancelledRequestCaptor.capture());
    assertTrue(cancelledRequestCaptor.getAllValues().stream().map(( resourceRequest) -> resourceRequest.getPreferredHost()).collect(Collectors.toSet()).size() > 2);
    assertTrue(state.matchedResourceRequests.get() == 0);
    assertTrue(state.anyHostRequests.get() > 2);
    spyAllocator.stop();
}"
"@Test
public void testUnqualifiedUriContents() throws Exception {
    dirString = ""d1"";
    item = new PathData(dirString, conf);
    PathData[] items = item.getDirectoryContents();
    assertEquals(sortedString(""d1/f1"", ""d1/f1.1"", ""d1/f2""), sortedString(items));
}"
"@Test
public void assertDurationIsInRange(long expectedMillis) {
    long minimum = (long) ((double) expectedMillis * 0.90);
    long maximum =
    Math.max((long) ((double) expectedMillis * 1.10), 10);
    long waitMillis = Math.max(expectedMillis * 10, 10);
    long duration = getDurationMillis(waitMillis);
    if (duration < minimum) {
        Assert.fail(""expected duration: "" + expectedMillis +
        "" minimum duration: "" + minimum +
        "" actual duration too short: "" + duration);
    } else if (duration > maximum) {
        Assert.fail(""expected duration: "" + expectedMillis +
        "" maximum duration: "" + maximum +
        "" actual duration too long: "" + duration);
    }
}"
"@Test
public void testGeneratedBlock() throws Exception {
    LOG.info(""Test testGeneratedBlock started."");
    long blockSize = 8192L;
    int stripeLength = 3;
    mySetup(stripeLength, -1);
    Path file1 = new Path(""/user/dhruba/raidtest/file1"");
    Path destPath = new Path(""/destraid/user/dhruba/raidtest"");
    long crc1 = TestRaidDfs.createTestFile(fileSys, file1, 1, 7, blockSize);
    long file1Len = fileSys.getFileStatus(file1).getLen();
    LOG.info(""Test testGeneratedBlock created test files"");
    Configuration localConf = new Configuration(conf);
    localConf.set(RAID_LOCATION_KEY, ""/destraid"");
    localConf.setInt(""raid.blockfix.interval"", 1000);
    localConf.setLong(""raid.blockfix.filespertask"", 2L);
    try {
        cnode = RaidNode.createRaidNode(null, localConf);
        TestRaidDfs.waitForFileRaided(LOG, fileSys, file1, destPath);
        cnode.stop();
        cnode.join();
        FileStatus srcStat = fileSys.getFileStatus(file1);
        DistributedFileSystem dfs = ((DistributedFileSystem) (fileSys));
        LocatedBlocks locs = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, srcStat.getLen());
        String[] corruptFiles = RaidDFSUtil.getCorruptFiles(conf);
        assertEquals(corruptFiles.length, 0);
        assertEquals(0, cnode.blockFixer.filesFixed());
        corruptBlock(locs.get(0).getBlock().getBlockName());
        reportCorruptBlocks(dfs, file1, new int[]{ 0 }, blockSize);
        corruptFiles = RaidDFSUtil.getCorruptFiles(conf);
        assertEquals(corruptFiles.length, 1);
        assertEquals(corruptFiles[0], file1.toUri().getPath());
        cnode = RaidNode.createRaidNode(null, localConf);
        long start = System.currentTimeMillis();
        while ((cnode.blockFixer.filesFixed() < 1) && ((System.currentTimeMillis() - start) < 120000)) {
            LOG.info(""Test testGeneratedBlock waiting for files to be fixed."");
            Thread.sleep(1000);
        }
        assertEquals(1, cnode.blockFixer.filesFixed());
        cnode.stop();
        cnode.join();
        cnode = null;
        dfs = getDFS(conf, dfs);
        assertTrue(TestRaidDfs.validateFile(dfs, file1, file1Len, crc1));
        locs = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, srcStat.getLen());
        corruptBlock(locs.get(0).getBlock().getBlockName());
        reportCorruptBlocks(dfs, file1, new int[]{ 0 }, blockSize);
        try {
            Thread.sleep(5 * 1000);
        } catch (InterruptedException ignore) {
        }
        try {
            TestRaidDfs.validateFile(dfs, file1, file1Len, crc1);
            fail(""Expected exception not thrown"");
        } catch (ChecksumException ce) {
        } catch (BlockMissingException bme) {
        }
    } catch (Exception e) {
        LOG.info((""Test testGeneratedBlock Exception "" + e) + StringUtils.stringifyException(e));
        throw e;
    } finally {
        myTearDown();
    }
    LOG.info(""Test testGeneratedBlock completed."");
}"
"@Test
public void testVersion2ClientVersion2Server() throws Exception {
    ProtocolSignature.resetCache();
    TestImpl2 impl = new TestImpl2();
    server = new RPC.Builder(conf).setProtocol(TestProtocol2.class).setInstance(impl).setBindAddress(ADDRESS).setPort(0).setNumHandlers(2).setVerbose(false).build();
    server.addProtocol(RPC_WRITABLE, TestProtocol0.class, impl);
    server.start();
    addr = NetUtils.getConnectAddress(server);
    Version2Client client = new Version2Client();
    client.ping();
    assertEquals(""hello"", client.echo(""hello""));
    assertEquals(-3, client.echo(3));
}"
"@Test
public void testDelegationTokenWithRealUser() throws IOException {
    UserGroupInformation ugi = UserGroupInformation.createRemoteUser(REAL_USER);
    final UserGroupInformation proxyUgi = UserGroupInformation.createProxyUserForTesting(PROXY_USER, ugi, GROUP_NAMES);
    try {
        Token<?>[] tokens = proxyUgi.doAs(new PrivilegedExceptionAction<Token<?>[]>() {
            @Override
            public Token<?>[] run() throws IOException {
                return cluster.getFileSystem().addDelegationTokens(""RenewerUser"", null);
            }
        });
        DelegationTokenIdentifier identifier = new DelegationTokenIdentifier();
        byte[] tokenId = tokens[0].getIdentifier();
        identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId)));
        Assert.assertEquals(identifier.getUser().getUserName(), PROXY_USER);
        Assert.assertEquals(identifier.getUser().getRealUser().getUserName(), REAL_USER);
    } catch (InterruptedException e) {
    }
}"
"@Test
public void testWithStringAndConfForBuggyPath() throws Exception {
    dirString = ""file"" ;
    testDir = new Path(dirString);
    item = new PathData(dirString, conf);
    assertEquals(""file:/tmp"", testDir.toString());
    checkPathData();
}"
"@Test
void canOffsetMutableClock() {
    final var offset = Duration.ofMinutes(10);
    final var response = endpoint.modify(""add"", null, offset.toMillis());
    final var offsetMinimum = Instant.now().plus(offset).truncatedTo(ChronoUnit.MILLIS);
    final var offsetMaximum = Instant.now().plus(offset.plus(Duration.ofMinutes(1)));
    assertThat(response.getStatus()).isEqualTo(200);
    assertThat(response.getBody()).isNotNull().asInstanceOf(instanceOfRecord).satisfies(( body) -> assertThat(body.instant).isBetween(offsetMinimum, offsetMaximum));
}"
"@Test
public void testModTime() throws IOException {
    Configuration conf = new Configuration();
    MiniDFSCluster cluster = new MiniDFSCluster(conf, numDatanodes, true, null);
    cluster.waitActive();
    InetSocketAddress addr = new InetSocketAddress(""localhost"", cluster.getNameNodePort());
    DFSClient client = new DFSClient(addr, conf);
    DatanodeInfo[] info = client.datanodeReport(LIVE);
    assertEquals(""Number of Datanodes "", numDatanodes, info.length);
    FileSystem fileSys = cluster.getFileSystem();
    int replicas = numDatanodes - 1;
    assertTrue(fileSys instanceof DistributedFileSystem);
    try {
        System.out.println(""Creating testdir1 and testdir1/test1.dat."");
        Path dir1 = new Path(""testdir1"");
        Path file1 = new Path(dir1, ""test1.dat"");
        writeFile(fileSys, file1, replicas);
        FileStatus stat = fileSys.getFileStatus(file1);
        long mtime1 = stat.getModificationTime();
        assertTrue(mtime1 != 0);
        stat = fileSys.getFileStatus(dir1);
        long mdir1 = stat.getModificationTime();
        System.out.println(""Creating testdir1/test2.dat."");
        Path file2 = new Path(dir1, ""test2.dat"");
        writeFile(fileSys, file2, replicas);
        stat = fileSys.getFileStatus(file2);
        stat = fileSys.getFileStatus(dir1);
        assertTrue(stat.getModificationTime() >= mdir1);
        mdir1 = stat.getModificationTime();
        Path dir2 = new Path(""testdir2/"").makeQualified(fileSys);
        System.out.println(""Creating testdir2 "" + dir2);
        assertTrue(fileSys.mkdirs(dir2));
        stat = fileSys.getFileStatus(dir2);
        long mdir2 = stat.getModificationTime();
        Path newfile = new Path(dir2, ""testnew.dat"");
        System.out.println(((""Moving "" + file1) + "" to "") + newfile);
        fileSys.rename(file1, newfile);
        stat = fileSys.getFileStatus(newfile);
        assertTrue(stat.getModificationTime() == mtime1);
        stat = fileSys.getFileStatus(dir1);
        assertTrue(stat.getModificationTime() != mdir1);
        mdir1 = stat.getModificationTime();
        stat = fileSys.getFileStatus(dir2);
        assertTrue(stat.getModificationTime() != mdir2);
        mdir2 = stat.getModificationTime();
        System.out.println(""Deleting testdir2/testnew.dat."");
        assertTrue(fileSys.delete(newfile, true));
        stat = fileSys.getFileStatus(dir1);
        assertTrue(stat.getModificationTime() == mdir1);
        stat = fileSys.getFileStatus(dir2);
        assertTrue(stat.getModificationTime() != mdir2);
        mdir2 = stat.getModificationTime();
        cleanupFile(fileSys, file2);
        cleanupFile(fileSys, dir1);
        cleanupFile(fileSys, dir2);
    } catch (IOException e) {
        info = client.datanodeReport(ALL);
        printDatanodeReport(info);
        throw e;
    } finally {
        fileSys.close();
        cluster.shutdown();
    }
}"
"@Test
public void testWithDirStringAndConf() throws Exception {
    dirString = ""d1"";
    item = new PathData(dirString, conf);
    checkPathData();
    dirString = ""d1/"";
    item = new PathData(dirString, conf);
    checkPathData();
}"
"@Test
public void testActivateSamples() throws Exception {
    UUID collectionExerciseId = UUID.randomUUID();
    UUID surveyId = UUID.randomUUID();
    UUID sampleSummaryId = UUID.randomUUID();
    SampleLink sampleLink = new SampleLink();
    sampleLink.setSampleSummaryId(sampleSummaryId);
    sampleLink.setCollectionExerciseId(collectionExerciseId);
    List<SampleLink> sampleLinks = new ArrayList<>();
    sampleLinks.add(sampleLink);
    CollectionExercise collectionExercise = new CollectionExercise();
    collectionExercise.setId(collectionExerciseId);
    collectionExercise.setSurveyId(surveyId);
    Event event = new Event();
    event.setTimestamp(new Timestamp(System.currentTimeMillis()));
    when(collectionExerciseRepository.findOneById(collectionExerciseId)).thenReturn(collectionExercise);
    when(sampleLinkRepository.findByCollectionExerciseId(collectionExerciseId)).thenReturn(sampleLinks);
    when(eventRepository.findOneByCollectionExerciseAndTag(collectionExercise, go_live.name())).thenReturn(event);
    sampleSummaryService.activateSamples(collectionExerciseId);
    sampleSummaryService.sampleSummaryValidated(true, collectionExerciseId);
    sampleSummaryService.sampleSummaryDistributed(true, collectionExerciseId);
    verify(collectionExerciseRepository, times(3)).findOneById(collectionExerciseId);
    verify(sampleSummaryActivationPublisher, times(1)).sendSampleSummaryActivation(collectionExerciseId, sampleSummaryId, surveyId);
    verify(collectionExerciseService, times(1)).transitionCollectionExercise(collectionExercise, EXECUTE);
    verify(collectionExerciseService, times(1)).transitionCollectionExercise(collectionExercise, VALIDATE);
    verify(collectionExerciseService, times(1)).transitionCollectionExercise(collectionExercise, EXECUTION_COMPLETE);
    verify(collectionExerciseService, times(1)).transitionCollectionExercise(collectionExercise, GO_LIVE);
}"
"@Test
public class Test {
    public void testPendingAndInvalidate() throws Exception {
        final Configuration CONF = new HdfsConfiguration();
        MiniDFSCluster cluster = new MiniDFSCluster.Builder(CONF).numDataNodes(DATANODE_COUNT).build();
        cluster.waitActive();
        FSNamesystem namesystem = cluster.getNamesystem();
        BlockManager bm = namesystem.getBlockManager();
        DistributedFileSystem fs = cluster.getFileSystem();
        try {
            Path filePath = new Path(""/tmp.txt"");
            DFSTestUtil.createFile(fs, filePath, 1024, (short) 3, 0L);
            for (DataNode dn : cluster.getDataNodes()) {
                DataNodeTestUtils.setHeartbeatsDisabledForTests(dn, true);
            }
            LocatedBlock block = NameNodeAdapter.getBlockLocations(
            cluster.getNameNode(), filePath.toString(), 0, 1).get(0);
            cluster.getNamesystem().writeLock();
            try {
                bm.findAndMarkBlockAsCorrupt(block.getBlock(), block.getLocations()[0],
                ""STORAGE_ID"", ""TEST"");
            } finally {
                cluster.getNamesystem().writeUnlock();
            }
            BlockManagerTestUtil.computeAllPendingWork(bm);
            BlockManagerTestUtil.updateState(bm);
            assertEquals(bm.getPendingReconstructionBlocksCount(), 1L);
            BlockInfo storedBlock = bm.getStoredBlock(block.getBlock().getLocalBlock());
            assertEquals(bm.pendingReconstruction.getNumReplicas(storedBlock), 2);
            fs.delete(filePath, true);
            int retries = 10;
            long pendingNum = bm.getPendingReconstructionBlocksCount();
            while (pendingNum != 0 && retries-- > 0) {
                Thread.sleep(1000);
                BlockManagerTestUtil.updateState(bm);
                pendingNum = bm.getPendingReconstructionBlocksCount();
            }
            assertEquals(pendingNum, 0L);
        } finally {
            cluster.shutdown();
        }
    }
}"
"@Test
public void testMinAllowedValue() {
    long millis = _validMinTime;
    DateTime dateTime = new DateTime(millis, DateTimeZone.UTC);
    LocalDateTime localDateTime = dateTime.toLocalDateTime();
    int year = localDateTime.getYear();
    int month = localDateTime.getMonthOfYear();
    int day = localDateTime.getDayOfMonth();
    Assert.assertEquals(year, 1971);
    Assert.assertEquals(month, 1);
    Assert.assertEquals(day, 1);
}"
"@Test
public void createDefaultDirectoryManagerPath() throws IOException {
    Path path = Paths.get(System.getProperty(""user.dir""));
    DirectoryManager dm = DirectoryManagerFactory.createDirectoryManager(
    path, true);
    assertTrue(dm instanceof DirectoryManagerImpl);
    DirectoryManagerImpl dmi = (DirectoryManagerImpl) dm;
    assertTrue(dmi.readOnly);
    assertEquals(path, dmi.directory);
}"
"@Test
void testBytes() throws InterruptedException {
    final CountDownLatch countDownLatch = new CountDownLatch(1);
    final Metrics metrics = new Metrics();
    final LongAdder longAdder = new LongAdder();
    final long input = 100;
    final int loopCount = 10000;
    Thread adder = new Thread(() -> {
        try {
            countDownLatch.await();
        } catch (InterruptedException ignore) {
        }
        for (int i = 0; i < loopCount; ++i) {
            metrics.addBytes(input);
        }
    });
    Thread getter = new Thread(() -> {
        try {
            countDownLatch.await();
        } catch (InterruptedException ignore) {
        }
        for (int i = 0; i < loopCount; ++i) {
            longAdder.add(metrics.bytesThenReset());
        }
    });
    adder.start();
    getter.start();
    countDownLatch.countDown();
    adder.join();
    longAdder.add(metrics.bytesThenReset());
    Assertions.assertEquals(loopCount * input, longAdder.sum());
}"
"@Test
public void shouldOnlyHandleRequestsOfSubscribedTypes() {
    serverTransport.subscribe(0, COMMAND, new DirectlyResponder());
    serverTransport.subscribe(0, UNKNOWN, new FailingResponder());
    final var requestFuture = clientTransport.sendRequest(() -> AtomixTransportTest.serverAddress, new Request(""messageABC""), REQUEST_TIMEOUT);
    final var response = requestFuture.join();
    assertThat(response.byteArray()).isEqualTo(""messageABC"".getBytes());
}"
"@Test
public void testQualifiedUriContents() throws Exception {
    dirString = fs.makeQualified(new Path(""d1"")).toString();
    item = new PathData(dirString, conf);
    PathData[] items = item.getDirectoryContents();
    assertEquals(sortedString(dirString + ""/f1"", dirString + ""/f1.1"", dirString + ""/f2""), sortedString(items));
}"
"@Test
public void servicesCanCallOtherServices() throws InterruptedException {
    ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
    Mono<String> chain =
    Mono.just(request(""X"")).compose(stub::sayHello).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).as(stub::sayHelloRespStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).compose(stub::sayHelloBothStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).as(stub::sayHelloReqStream).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).compose(stub::sayHello).map(HelloResponse::getMessage).doOnSuccess(System.out::println);
    StepVerifier.create(chain).expectNext(""[<{[X]}> :: </[X]/> :: <\\[X]\\> :: <([X])>]"").expectComplete().verify(Duration.ofSeconds(2));
}"
"@Test
void writesAndReadsCustomFieldsConvertedClass() {
    List<Object> converters = new ArrayList<>();
    converters.add(BigDecimalToStringConverter.INSTANCE);
    converters.add(StringToBigDecimalConverter.INSTANCE);
    CustomConversions customConversions = new CouchbaseCustomConversions(converters);
    converter.setCustomConversions(customConversions);
    converter.afterPropertiesSet();
    ((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(customConversions.getSimpleTypeHolder());
    CouchbaseDocument converted = new CouchbaseDocument();
    final String valueStr = ""12.345"";
    final BigDecimal value = new BigDecimal(valueStr);
    final String value2Str = ""0.6789"";
    final BigDecimal value2 = new BigDecimal(value2Str);
    List<BigDecimal> listOfValues = new ArrayList<>();
    listOfValues.add(value);
    listOfValues.add(value2);
    Map<String, BigDecimal> mapOfValues = new HashMap<>();
    mapOfValues.put(""val1"", value);
    mapOfValues.put(""val2"", value2);
    CustomFieldsEntity entity = new CustomFieldsEntity(value, listOfValues, mapOfValues);
    converter.write(entity, converted);
    CouchbaseDocument source = new CouchbaseDocument();
    source.put(""_class"", CustomFieldsEntity.class.getName());
    source.put(""decimalValue"", valueStr);
    CouchbaseList listOfValuesDoc = new CouchbaseList();
    listOfValuesDoc.put(valueStr);
    listOfValuesDoc.put(value2Str);
    source.put(""listOfDecimalValues"", listOfValuesDoc);
    CouchbaseDocument mapOfValuesDoc = new CouchbaseDocument();
    mapOfValuesDoc.put(""val1"", valueStr);
    mapOfValuesDoc.put(""val2"", value2Str);
    source.put(""mapOfDecimalValues"", mapOfValuesDoc);
    assertThat(valueStr).isEqualTo(((CouchbaseList) (converted.getContent().get(""listOfDecimalValues""))).get(0));
    assertThat(value2Str).isEqualTo(((CouchbaseList) (converted.getContent().get(""listOfDecimalValues""))).get(1));
    assertThat(converted.export().toString()).isEqualTo(source.export().toString());
    CustomFieldsEntity readConverted = converter.read(CustomFieldsEntity.class, source);
    assertThat(readConverted.value).isEqualTo(value);
    assertThat(readConverted.listOfValues.get(0)).isEqualTo(listOfValues.get(0));
    assertThat(readConverted.listOfValues.get(1)).isEqualTo(listOfValues.get(1));
    assertThat(readConverted.mapOfValues.get(""val1"")).isEqualTo(mapOfValues.get(""val1""));
    assertThat(readConverted.mapOfValues.get(""val2"")).isEqualTo(mapOfValues.get(""val2""));
}"
"@Test
public void testProcessAction_ok() {
    final Mock mockResponse = mock(ActionResponse.class);
    PortletMode mode = PortletMode.VIEW;
    Map<String, String> initParams = new HashMap<String, String>();
    initParams.put(""viewNamespace"", ""/view"");
    Map<String, String[]> requestParams = new HashMap<String, String[]>();
    requestParams.put(ACTION_PARAM, new String[] { ""/view/testAction"" });
    requestParams.put(MODE_PARAM, new String[] { mode.toString() });
    initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE,
    ""true"");
    initPortletConfig(initParams, new HashMap<String, Object>());
    initRequest(requestParams, new HashMap<String, Object>(),
    new HashMap<String, Object>(), PortletMode.VIEW,
    WindowState.NORMAL, true, null);
    setupActionFactory(""/view"", ""testAction"", ""success"",
    EasyMock.createNiceMock(ValueStack.class));
    try {
        dispatcher
        .setActionProxyFactory((ActionProxyFactory) mockActionFactory
        .proxy());
        dispatcher.init((PortletConfig) mockConfig.proxy());
        dispatcher.processAction((ActionRequest) mockRequest.proxy(),
        (ActionResponse) mockResponse.proxy());
    } catch (Exception e) {
        e.printStackTrace();
        fail(""Error occured"");
    }
}"
"@Test
public void testRender_ok() {
    final Mock mockResponse = mock(RenderResponse.class);
    mockResponse.stubs().method(ANYTHING);
    PortletMode mode = PortletMode.VIEW;
    Map<String, String[]> requestParams = new HashMap<String, String[]>();
    requestParams.put(ACTION_PARAM, new String[]{""/view/testAction""});
    requestParams.put(EVENT_ACTION, new String[]{""true""});
    requestParams.put(MODE_PARAM, new String[]{mode.toString()});
    Map<String, Object> sessionMap = new HashMap<String, Object>();
    Map<String, String> initParams = new HashMap<String, String>();
    initParams.put(""viewNamespace"", ""/view"");
    initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true"");
    initPortletConfig(initParams, new HashMap<String, Object>());
    initRequest(requestParams, new HashMap<String, Object>(), sessionMap, PortletMode.VIEW, WindowState.NORMAL, false, null);
    setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class));
    mockInvocation.expects(once()).method(""getStack"").will(
    returnValue(null));
    try {
        dispatcher
        .setActionProxyFactory((ActionProxyFactory) mockActionFactory
        .proxy());
        dispatcher.init((PortletConfig) mockConfig.proxy());
        dispatcher.render((RenderRequest) mockRequest.proxy(),
        (RenderResponse) mockResponse.proxy());
    } catch (Exception e) {
        e.printStackTrace();
        fail(""Error occured"");
    }
}"
"@Test
public void createDirectoryManagerIoException() throws IOException {
    DirectoryManagerFactory.createDirectoryManager(
    ""/nonexisting-directory/123456789/hopefully"", true);
}"
"@Test
public void testCwdContents() throws Exception {
    dirString = Path.CUR_DIR;
    item = new PathData(dirString, conf);
    PathData[] items = item.getDirectoryContents();
    assertEquals(sortedString(""d1"", ""d2""), sortedString(items));
}"
"@Test
public void testNodeMetricsDb() {
    ManualClock clock = new ManualClock();
    NodeMetricsDb db = new NodeMetricsDb();
    List<NodeMetrics.MetricValue> values = new ArrayList<>();
    for (int i = 0; i < 40; i++) {
        values.add(new NodeMetrics.MetricValue(""host0"", ""cpu.util"", clock.instant().getEpochSecond(), 0.9f));
        clock.advance(Duration.ofHours(1));
    }
    db.add(values);
    assertEquals(29, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.cpu,    List.of(""host0"")).measurementCount());
    assertEquals( 0, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.memory, List.of(""host0"")).measurementCount());
    db.gc(clock);
    assertEquals(23, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.cpu,    List.of(""host0"")).measurementCount());
    assertEquals( 0, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.memory, List.of(""host0"")).measurementCount());
}"
"@Test
public void testHftpCustomDefaultPorts() throws IOException {
    resetFileSystem();
    Configuration conf = new Configuration();
    conf.setInt(""dfs.http.port"", 123);
    conf.setInt(""dfs.https.port"", 456);
    URI uri = URI.create();
    HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf)));
    assertEquals(123, fs.getDefaultPort());
    assertEquals(456, fs.getDefaultSecurePort());
    assertEquals(uri, fs.getUri());
    assertEquals(""127.0.0.1:456"", fs.getCanonicalServiceName());
}"
"@Test
public void testProcessAction_ok() {
    final Mock mockResponse = mock(ActionResponse.class);
    PortletMode mode = PortletMode.VIEW;
    Map<String, String> initParams = new HashMap<String, String>();
    initParams.put(""viewNamespace"", ""/view"");
    Map<String, String[]> requestParams = new HashMap<String, String[]>();
    requestParams.put(ACTION_PARAM, new String[]{""/view/testAction""});
    requestParams.put(MODE_PARAM, new String[]{mode.toString()});
    initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true"");
    initPortletConfig(initParams, new HashMap<String, Object>());
    initRequest(requestParams, new HashMap<String, Object>(), new HashMap<String, Object>(), PortletMode.VIEW, WindowState.NORMAL, true, null);
    setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class));
    try {
        dispatcher
        .setActionProxyFactory((ActionProxyFactory) mockActionFactory
        .proxy());
        dispatcher.init((PortletConfig) mockConfig.proxy());
        dispatcher.processAction((ActionRequest) mockRequest.proxy(),
        (ActionResponse) mockResponse.proxy());
    } catch (Exception e) {
        e.printStackTrace();
        fail(""Error occured"");
    }
}"
"@Test
public void testShortCircuited() {
    HystrixCommandKey key = Factory.asKey(""CMD-Health-G"");
    stream = HealthCountsStream.getInstance(key, 10, 100);
    final CountDownLatch latch = new CountDownLatch(1);
    stream.observe().take(10).subscribe(getSubscriber(latch));
    CommandStreamTest.Command failure1 = Command.from(groupKey, key, FAILURE, 20);
    CommandStreamTest.Command failure2 = Command.from(groupKey, key, FAILURE, 20);
    CommandStreamTest.Command failure3 = Command.from(groupKey, key, FAILURE, 20);
    CommandStreamTest.Command shortCircuit1 = Command.from(groupKey, key, SUCCESS);
    CommandStreamTest.Command shortCircuit2 = Command.from(groupKey, key, SUCCESS);
    failure1.observe();
    failure2.observe();
    failure3.observe();
    try {
        Thread.sleep(100);
    } catch (InterruptedException ie) {
        fail(ie.getMessage());
    }
    shortCircuit1.observe();
    shortCircuit2.observe();
    try {
        assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
    } catch (InterruptedException ex) {
        fail(""Interrupted ex"");
    }
    assertTrue(shortCircuit1.isResponseShortCircuited());
    assertTrue(shortCircuit2.isResponseShortCircuited());
    System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
    assertEquals(3L, stream.getLatest().getErrorCount());
    assertEquals(3L, stream.getLatest().getTotalRequests());
}"
"@Test
public void testBuildDTServiceName() {
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create()));
}"
"@Test
public void testSetrepIncWithUnderReplicatedBlocks() throws Exception {
    Configuration conf = new HdfsConfiguration();
    final short REPLICATION_FACTOR = 2;
    final String FILE_NAME = ""/testFile"";
    final Path FILE_PATH = new Path(FILE_NAME);
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(REPLICATION_FACTOR + 1).build();
    try {
        final FileSystem fs = cluster.getFileSystem();
        DFSTestUtil.createFile(fs, FILE_PATH, 1L, REPLICATION_FACTOR, 1L);
        DFSTestUtil.waitReplication(fs, FILE_PATH, REPLICATION_FACTOR);
        final BlockManager bm = cluster.getNamesystem().getBlockManager();
        ExtendedBlock b = DFSTestUtil.getFirstBlock(fs, FILE_PATH);
        DatanodeDescriptor dn = bm.blocksMap.nodeIterator(b.getLocalBlock()).next();
        bm.addToInvalidates(b.getLocalBlock(), dn);
        bm.blocksMap.removeNode(b.getLocalBlock(), dn);
        FsShell shell = new FsShell(conf);
        assertEquals(0, shell.run(new String[]{ ""-setrep"", ""-w"", Integer.toString(1 + REPLICATION_FACTOR), FILE_NAME }));
    } finally {
        cluster.shutdown();
    }
}"
"@Test
public void testWebHdfsDoAs() throws Exception {
    LOG.info(""START: testWebHdfsDoAs()"");
    ((Log4JLogger) (LOG)).getLogger().setLevel(ALL);
    ((Log4JLogger) (LOG)).getLogger().setLevel(ALL);
    final UserGroupInformation ugi = UserGroupInformation.createRemoteUser(REAL_USER);
    LOG.info(""ugi.getShortUserName()="" + ugi.getShortUserName());
    final WebHdfsFileSystem webhdfs = WebHdfsTestUtil.getWebHdfsFileSystemAs(ugi, config);
    final Path root = new Path(""/"");
    cluster.getFileSystem().setPermission(root, new FsPermission(((short) (0777))));
    {
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, GETHOMEDIRECTORY, root, new DoAsParam(PROXY_USER));
        final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK);
        conn.disconnect();
        final Object responsePath = m.get(Path.class.getSimpleName());
        LOG.info(""responsePath="" + responsePath);
        Assert.assertEquals(""/user/"" + PROXY_USER, responsePath);
    }
    {
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, GETHOMEDIRECTORY, root, new DoAsParam(PROXY_USER) {
            @Override
            public String getName() {
                return ""DOas"";
            }
        });
        final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK);
        conn.disconnect();
        final Object responsePath = m.get(Path.class.getSimpleName());
        LOG.info(""responsePath="" + responsePath);
        Assert.assertEquals(""/user/"" + PROXY_USER, responsePath);
    }
    final Path f = new Path(""/testWebHdfsDoAs/a.txt"");
    {
        final PutOpParam.Op op = Op.CREATE;
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, op, f, new DoAsParam(PROXY_USER));
        HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        conn = WebHdfsTestUtil.twoStepWrite(webhdfs, op, conn);
        final FSDataOutputStream out = WebHdfsTestUtil.write(webhdfs, op, conn, 4096);
        out.write(""Hello, webhdfs user!"".getBytes());
        out.close();
        final FileStatus status = webhdfs.getFileStatus(f);
        LOG.info(""status.getOwner()="" + status.getOwner());
        Assert.assertEquals(PROXY_USER, status.getOwner());
    }
    {
        final PostOpParam.Op op = Op.APPEND;
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, op, f, new DoAsParam(PROXY_USER));
        HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        conn = WebHdfsTestUtil.twoStepWrite(webhdfs, op, conn);
        final FSDataOutputStream out = WebHdfsTestUtil.write(webhdfs, op, conn, 4096);
        out.write(""\nHello again!"".getBytes());
        out.close();
        final FileStatus status = webhdfs.getFileStatus(f);
        LOG.info(""status.getOwner()="" + status.getOwner());
        LOG.info(""status.getLen()  ="" + status.getLen());
        Assert.assertEquals(PROXY_USER, status.getOwner());
    }
}"
"@Test
public void testInitFirstVerifyCallBacks() throws Exception {
    DefaultMetricsSystem.shutdown();
    new ConfigBuilder().add(""*.period"", 8).add(""test.sink.test.class"", TestSink.class.getName()).add(""test.*.source.filter.exclude"", ""s0"").add(""test.source.s1.metric.filter.exclude"", ""X*"").add(""test.sink.sink1.metric.filter.exclude"", ""Y*"").add(""test.sink.sink2.metric.filter.exclude"", ""Y*"").save(TestMetricsConfig.getTestFilename(""hadoop-metrics2-test""));
    MetricsSystemImpl ms = new MetricsSystemImpl(""Test"");
    ms.start();
    ms.register(""s0"", ""s0 desc"", new TestSource(""s0rec""));
    TestSource s1 = ms.register(""s1"", ""s1 desc"", new TestSource(""s1rec""));
    s1.c1.incr();
    s1.xxx.incr();
    s1.g1.set(2);
    s1.yyy.incr(2);
    s1.s1.add(0);
    MetricsSink sink1 = mock(MetricsSink.class);
    MetricsSink sink2 = mock(MetricsSink.class);
    ms.registerSink(""sink1"", ""sink1 desc"", sink1);
    ms.registerSink(""sink2"", ""sink2 desc"", sink2);
    ms.publishMetricsNow();
    try {
        verify(sink1, timeout(200).times(2)).putMetrics(r1.capture());
        verify(sink2, timeout(200).times(2)).putMetrics(r2.capture());
    } finally {
        ms.stop();
        ms.shutdown();
    }
    List<MetricsRecord> mr1 = r1.getAllValues();
    List<MetricsRecord> mr2 = r2.getAllValues();
    checkMetricsRecords(mr1);
    assertEquals(""output"", mr1, mr2);
}"
"@Test
public void canSerializeAdditionalProperties() throws Exception {
    Foo foo = new Foo();
    foo.bar = ""hello.world"";
    foo.baz = new ArrayList<>();
    foo.baz.add(""hello"");
    foo.baz.add(""hello.world"");
    foo.qux = new HashMap<>();
    foo.qux.put(""hello"", ""world"");
    foo.qux.put(""a.b"", ""c.d"");
    foo.qux.put(""bar.a"", ""ttyy"");
    foo.qux.put(""bar.b"", ""uuzz"");
    foo.additionalProperties = new HashMap<>();
    foo.additionalProperties.put(""bar"", ""baz"");
    foo.additionalProperties.put(""a.b"", ""c.d"");
    foo.additionalProperties.put(""properties.bar"", ""barbar"");
    String serialized = new JacksonAdapter().serialize(foo);
    Assert.assertEquals(""{\""$type\"":\""foo\"",\""properties\"":{\""bar\"":\""hello.world\"",\""props\"":{\""baz\"":[\""hello\"",\""hello.world\""],\""q\"":{\""qux\"":{\""hello\"":\""world\"",\""a.b\"":\""c.d\"",\""bar.b\"":\""uuzz\"",\""bar.a\"":\""ttyy\""}}}},\""bar\"":\""baz\"",\""a.b\"":\""c.d\"",\""properties.bar\"":\""barbar\""}"", serialized);
}"
"@Test
public void testFormatMultipleUTF8() {
    HashMap<String, String> params = new HashMap<String, String>();
    params.put(""a "", ""b, "");
    params.put(""c"", ""32626&"");
    Assert.assertTrue(""a =b%2C+&c=32626%26"".equals(KeyValueFormatter.format(params, true)) || ""c=32626%26&a =b%2C+"".equals(KeyValueFormatter.format(params, true)));
}"
"@Test
public void TestSimpleDiamond() {
    Node x = new Node(4);
    Node n = new Node(1).addkid(new Node(2).addkid(x)).addkid(new Node(3).addkid(x));
    Graph g = new Graph(n);
    MHGDominatorsFinder<Node> finder = new MHGDominatorsFinder<Node>(g);
    DominatorTree<Node> tree = new DominatorTree<Node>(finder);
    assertThat(tree.getHeads().size(), is(1));
    DominatorNode<Node> head = tree.getHeads().get(0);
    assertThat(head.getGode().id, is(1));
    Set<Integer> kids = kid_ids(head);
    assertThat(kids.size(), is(3));
    assertThat(kids, contains(2, 3, 4));
}"
"@Test
public void testContinuousScheduling() throws Exception {
    FairScheduler fs = new FairScheduler();
    Configuration conf = createConfiguration();
    conf.setBoolean(CONTINUOUS_SCHEDULING_ENABLED, true);
    fs.reinitialize(conf, resourceManager.getRMContext());
    Assert.assertTrue(""Continuous scheduling should be enabled."", fs.isContinuousSchedulingEnabled());
    RMNode node1 = MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1, ""127.0.0.1"");
    NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
    fs.handle(nodeEvent1);
    Assert.assertEquals(fs.getClusterCapacity().getMemory(), 8 * 1024);
    Assert.assertEquals(fs.getClusterCapacity().getVirtualCores(), 8);
    ApplicationAttemptId appAttemptId = createAppAttemptId(this.APP_ID++, this.ATTEMPT_ID++);
    fs.addApplication(appAttemptId, ""queue11"", ""user11"");
    List<ResourceRequest> ask = new ArrayList<ResourceRequest>();
    ResourceRequest request = createResourceRequest(1024, 1, ANY, 1, 1, true);
    ask.add(request);
    fs.allocate(appAttemptId, ask, new ArrayList<ContainerId>(), null, null);
    Thread.sleep(fs.getConf().getContinuousSchedulingSleepMs() + 500);
    Resource consumption = fs.applications.get(appAttemptId).getCurrentConsumption();
    Assert.assertEquals(1024, consumption.getMemory());
    Assert.assertEquals(1, consumption.getVirtualCores());
}"
"@Test
public void testSetName() throws Exception {
    Configuration conf = new Configuration();
    WritableName.setName(SimpleWritable.class, testName);
    Class<?> test = WritableName.getClass(testName, conf);
    assertTrue(test.equals(SimpleWritable.class));
}"
"@Test
public void testAddAndRetrieve() throws Exception {
    PeerCache cache = PeerCache.getInstance(3, 100000);
    DatanodeID dnId = new DatanodeID(""192.168.0.1"",
    ""fakehostname"", ""fake_storage_id"",
    100, 101, 102);
    FakePeer peer = new FakePeer(dnId, false);
    cache.put(dnId, peer);
    assertTrue(!peer.isClosed());
    assertEquals(1, cache.size());
    assertEquals(peer, cache.get(dnId, false));
    assertEquals(0, cache.size());
    cache.close();
}"
"@Test
public void testRead() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.readTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_READ, execTime);
}"
"@Test
void writesAndReadsClassContainingCustomConvertedObjects() {
    List<Object> converters = new ArrayList<>();
    converters.add(BigDecimalToStringConverter.INSTANCE);
    converters.add(StringToBigDecimalConverter.INSTANCE);
    CustomConversions customConversions = new CouchbaseCustomConversions(converters);
    converter.setCustomConversions(customConversions);
    converter.afterPropertiesSet();
    ((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(customConversions.getSimpleTypeHolder());
    CouchbaseDocument converted = new CouchbaseDocument();
    final String weightStr = ""12.34"";
    final BigDecimal weight = new BigDecimal(weightStr);
    final CustomObject addy = new CustomObject(weight);
    List<CustomObject> listOfObjects = new ArrayList<>();
    listOfObjects.add(addy);
    Map<String, CustomObject> mapOfObjects = new HashMap<>();
    mapOfObjects.put(""obj0"", addy);
    mapOfObjects.put(""obj1"", addy);
    CustomObjectEntity entity = new CustomObjectEntity(addy, listOfObjects, mapOfObjects);
    converter.write(entity, converted);
    CouchbaseDocument source = new CouchbaseDocument();
    source.put(""_class"", CustomObjectEntity.class.getName());
    CouchbaseDocument objectDoc = new CouchbaseDocument();
    objectDoc.put(""weight"", weightStr);
    source.put(""object"", objectDoc);
    CouchbaseList listOfObjectsDoc = new CouchbaseList();
    listOfObjectsDoc.put(objectDoc);
    source.put(""listOfObjects"", listOfObjectsDoc);
    CouchbaseDocument mapOfObjectsDoc = new CouchbaseDocument();
    mapOfObjectsDoc.put(""obj0"", objectDoc);
    mapOfObjectsDoc.put(""obj1"", objectDoc);
    source.put(""mapOfObjects"", mapOfObjectsDoc);
    assertThat(converted.export().toString()).isEqualTo(source.export().toString());
    CustomObjectEntity readConverted = converter.read(CustomObjectEntity.class, source);
    assertThat(readConverted.object.weight).isEqualTo(addy.weight);
    assertThat(readConverted.listOfObjects.get(0).weight).isEqualTo(listOfObjects.get(0).weight);
    assertThat(readConverted.mapOfObjects.get(""obj0"").weight).isEqualTo(mapOfObjects.get(""obj0"").weight);
    assertThat(readConverted.mapOfObjects.get(""obj1"").weight).isEqualTo(mapOfObjects.get(""obj1"").weight);
}"
"@Test
public void shouldContainSyncCommitteeAggregates() throws Exception {
    primaryNode.start();
    primaryNode.startEventListener(List.of(contribution_and_proof));
    secondaryNode.start();
    secondaryNode.startEventListener(List.of(contribution_and_proof));
    validatorClient.start();
    primaryNode.waitForEpoch(1);
    secondaryNode.waitForFullSyncCommitteeAggregate();
    validatorClient.stop();
    secondaryNode.stop();
    primaryNode.stop();
    assertThat(primaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isGreaterThanOrEqualTo(8)).count()).isGreaterThan(0);
    assertThat(secondaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isLessThan(8)).count()).isGreaterThan(0);
}"
"@Test
public void testHftpCustomUriPortWithDefaultPorts() throws IOException {
    resetFileSystem();
    Configuration conf = new Configuration();
    URI uri = URI.create() ;
    HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf)));
    assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, fs.getDefaultPort());
    assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getDefaultSecurePort());
    assertEquals(uri, fs.getUri());
    assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getCanonicalServiceName());
}"
"@Test
public void appliesOuterTimeout() {
    final WaitStrategy underTest = new WaitAllStrategy()
    .withStrategy(strategy1)
    .withStartupTimeout(Duration.ofMillis(10));
    doAnswer(invocation -> {
        Uninterruptibles.sleepUninterruptibly(20, TimeUnit.MILLISECONDS);
        return null;
    }).when(strategy1).waitUntilReady(eq(container));
    assertThrows(""The outer strategy timeout applies"", TimeoutException.class, () -> {
        underTest.waitUntilReady(container);
    });
}"
"@Test
void logWithExtras() {
    Instant start = Instant.now();
    List<LogData> logDataList = logExporter.getFinishedLogItems();
    assertThat(logDataList).hasSize(1);
    LogData logData = logDataList.get(0);
    assertThat(logData.getResource()).isEqualTo(resource);
    assertThat(logData.getInstrumentationLibraryInfo()).isEqualTo(instrumentationLibraryInfo);
    assertThat(logData.getBody().asString()).isEqualTo(""log message 1"");
    assertThat(logData.getEpochNanos()).isGreaterThanOrEqualTo(TimeUnit.MILLISECONDS.toNanos(start.toEpochMilli())).isLessThanOrEqualTo(TimeUnit.MILLISECONDS.toNanos(Instant.now().toEpochMilli()));
    assertThat(logData.getSeverity()).isEqualTo(INFO);
    assertThat(logData.getSeverityText()).isEqualTo(""INFO"");
    assertThat(logData.getAttributes().size()).isEqualTo(3);
    assertThat(logData.getAttributes().get(EXCEPTION_TYPE)).isEqualTo(IllegalStateException.class.getName());
    assertThat(logData.getAttributes().get(EXCEPTION_MESSAGE)).isEqualTo(""Error!"");
    assertThat(logData.getAttributes().get(EXCEPTION_STACKTRACE)).contains(""logWithExtras"");
}"
"@Test
public void testRender_ok() {
    final Mock mockResponse = mock(RenderResponse.class);
    mockResponse.stubs().method(ANYTHING);
    PortletMode mode = PortletMode.VIEW;
    Map<String, String[]> requestParams = new HashMap<String, String[]>();
    requestParams.put(ACTION_PARAM, new String[] { ""/view/testAction"" });
    requestParams.put(EVENT_ACTION, new String[] { ""true"" });
    requestParams.put(MODE_PARAM, new String[] { mode.toString() });
    Map<String, Object> sessionMap = new HashMap<String, Object>();
    Map<String, String> initParams = new HashMap<String, String>();
    initParams.put(""viewNamespace"", ""/view"");
    initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE,
    ""true"");
    initPortletConfig(initParams, new HashMap<String, Object>());
    initRequest(requestParams, new HashMap<String, Object>(), sessionMap,
    PortletMode.VIEW, WindowState.NORMAL, false, null);
    setupActionFactory(""/view"", ""testAction"", ""success"",
    EasyMock.createNiceMock(ValueStack.class));
    mockInvocation.expects(once()).method(""getStack"")
    .will(returnValue(null));
    try {
        dispatcher
        .setActionProxyFactory((ActionProxyFactory) mockActionFactory
        .proxy());
        dispatcher.init((PortletConfig) mockConfig.proxy());
        dispatcher.render((RenderRequest) mockRequest.proxy(),
        (RenderResponse) mockResponse.proxy());
    } catch (Exception e) {
        e.printStackTrace();
        fail(""Error occured"");
    }
}"
"@Test
public void testExpiry() throws Exception {
    final int CAPACITY = 3;
    final int EXPIRY_PERIOD = 10;
    PeerCache cache = PeerCache.getInstance(CAPACITY, EXPIRY_PERIOD);
    DatanodeID dnIds[] = new DatanodeID[CAPACITY];
    FakePeer peers[] = new FakePeer[CAPACITY];
    for (int i = 0; i < CAPACITY; ++i) {
        dnIds[i] = new DatanodeID(""192.168.0.1"",
        ""fakehostname_"" + i, ""fake_storage_id"",
        100, 101, 102);
        peers[i] = new FakePeer(dnIds[i], false);
    }
    for (int i = 0; i < CAPACITY; ++i) {
        cache.put(dnIds[i], peers[i]);
    }
    Thread.sleep(EXPIRY_PERIOD * 50);
    assertEquals(0, cache.size());
    for (int i = 0; i < CAPACITY; ++i) {
        assertTrue(peers[i].isClosed());
    }
    Thread.sleep(EXPIRY_PERIOD * 50);
    cache.close();
}"
"@Test
void shouldCompleteLogWhenCancelledByClient(SessionProtocol protocol) {
    final ClientFactory factory = ClientFactory.builder().build();
    final WebClient client = WebClient.builder(server.uri(protocol)).factory(factory).build();
    final CompletableFuture<AggregatedHttpResponse> responseFuture = client.get(""/reset"").aggregate();
    await().untilAtomic(ctxRef, Matchers.notNullValue());
    factory.close();
    final RequestLog log = ctxRef.get().log().whenComplete().join();
    if (protocol.isMultiplex()) {
        assertThat(log.responseCause()).isInstanceOf(ClosedStreamException.class).hasMessageContaining(""received a RST_STREAM frame: CANCEL"");
        assertThatThrownBy(responseFuture::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedStreamException.class);
    } else {
        assertThat(log.responseCause()).isInstanceOf(ClosedSessionException.class);
        assertThatThrownBy(responseFuture::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedSessionException.class);
    }
}"
"@Test
public void testBuildTokenServiceSockAddr() {
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""LocalHost"", 123)).toString());
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""127.0.0.1"", 123)).toString());
    assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(NetUtils.createSocketAddr(""127.0.0.1"", 123)).toString());
}"
"@Test
public void testWrite() throws Exception {
    FileSystem fs = cluster.getFileSystem();
    long tStart = System.currentTimeMillis();
    bench.writeTest(fs);
    long execTime = System.currentTimeMillis() - tStart;
    bench.analyzeResult(fs, TestType.TEST_TYPE_WRITE, execTime);
}"
"  @Test(expected = IllegalArgumentException.class)
  public void testConstructor1() throws IOException {
    new OffsetRange(0, 0);
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testConstructor2() throws IOException {
    new OffsetRange(-1, 0);
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testConstructor3() throws IOException {
    new OffsetRange(-3, -1);
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testConstructor4() throws IOException {
    new OffsetRange(-3, 100);
  }
"
"  @Test
  public void testCompare() throws IOException {
    OffsetRange r1 = new OffsetRange(0, 1);
    OffsetRange r2 = new OffsetRange(1, 3);
    OffsetRange r3 = new OffsetRange(1, 3);
    OffsetRange r4 = new OffsetRange(3, 4);

    assertEquals(0, OffsetRange.ReverseComparatorOnMin.compare(r2, r3));
    assertEquals(0, OffsetRange.ReverseComparatorOnMin.compare(r2, r2));
    assertTrue(OffsetRange.ReverseComparatorOnMin.compare(r2, r1) < 0);
    assertTrue(OffsetRange.ReverseComparatorOnMin.compare(r2, r4) > 0);
  }
"
"  @Test
  public void testReaddirBasic() throws IOException {
    // Get inodeId of /tmp
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);

    // Create related part of the XDR request
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeLongAsHyper(0); // cookie
    xdr_req.writeLongAsHyper(0); // verifier
    xdr_req.writeInt(100); // count

    READDIR3Response response = nfsd.readdir(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    List<Entry3> dirents = response.getDirList().getEntries();
    assertTrue(dirents.size() == 5); // inculding dot, dotdot

    // Test start listing from f2
    status = nn.getRpcServer().getFileInfo(testdir + ""/f2"");
    long f2Id = status.getFileId();

    // Create related part of the XDR request
    xdr_req = new XDR();
    handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeLongAsHyper(f2Id); // cookie
    xdr_req.writeLongAsHyper(0); // verifier
    xdr_req.writeInt(100); // count

    response = nfsd.readdir(xdr_req.asReadOnlyWrap(), securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    dirents = response.getDirList().getEntries();
    assertTrue(dirents.size() == 1);
    Entry3 entry = dirents.get(0);
    assertTrue(entry.getName().equals(""f3""));

    // When the cookie is deleted, list starts over no including dot, dotdot
    hdfs.delete(new Path(testdir + ""/f2""), false);

    response = nfsd.readdir(xdr_req.asReadOnlyWrap(), securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    dirents = response.getDirList().getEntries();
    assertTrue(dirents.size() == 2); // No dot, dotdot
  }
"
"  @Test
  public void testReaddirPlus() throws IOException {
    // Get inodeId of /tmp
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    
    // Create related part of the XDR request
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeLongAsHyper(0); // cookie
    xdr_req.writeLongAsHyper(0); // verifier
    xdr_req.writeInt(100); // dirCount
    xdr_req.writeInt(1000); // maxCount

    READDIRPLUS3Response responsePlus = nfsd.readdirplus(xdr_req
        .asReadOnlyWrap(), securityHandler, new InetSocketAddress(""localhost"",
        1234));
    List<EntryPlus3> direntPlus = responsePlus.getDirListPlus().getEntries();
    assertTrue(direntPlus.size() == 5); // including dot, dotdot

    // Test start listing from f2
    status = nn.getRpcServer().getFileInfo(testdir + ""/f2"");
    long f2Id = status.getFileId();

    // Create related part of the XDR request
    xdr_req = new XDR();
    handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeLongAsHyper(f2Id); // cookie
    xdr_req.writeLongAsHyper(0); // verifier
    xdr_req.writeInt(100); // dirCount
    xdr_req.writeInt(1000); // maxCount

    responsePlus = nfsd.readdirplus(xdr_req.asReadOnlyWrap(), securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    direntPlus = responsePlus.getDirListPlus().getEntries();
    assertTrue(direntPlus.size() == 1);
    EntryPlus3 entryPlus = direntPlus.get(0);
    assertTrue(entryPlus.getName().equals(""f3""));

    // When the cookie is deleted, list starts over no including dot, dotdot
    hdfs.delete(new Path(testdir + ""/f2""), false);

    responsePlus = nfsd.readdirplus(xdr_req.asReadOnlyWrap(), securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    direntPlus = responsePlus.getDirListPlus().getEntries();
    assertTrue(direntPlus.size() == 2); // No dot, dotdot
  }
"
"  @Test
  public void testAlterWriteRequest() throws IOException {
    int len = 20;
    byte[] data = new byte[len];
    ByteBuffer buffer = ByteBuffer.wrap(data);

    for (int i = 0; i < len; i++) {
      buffer.put((byte) i);
    }
    buffer.flip();
    int originalCount = buffer.array().length;
    WRITE3Request request = new WRITE3Request(new FileHandle(), 0, data.length,
        WriteStableHow.UNSTABLE, buffer);

    WriteCtx writeCtx1 = new WriteCtx(request.getHandle(), request.getOffset(),
        request.getCount(), WriteCtx.INVALID_ORIGINAL_COUNT,
        request.getStableHow(), request.getData(), null, 1, false,
        WriteCtx.DataState.NO_DUMP);

    Assert.assertTrue(writeCtx1.getData().array().length == originalCount);

    // Now change the write request
    OpenFileCtx.alterWriteRequest(request, 12);

    WriteCtx writeCtx2 = new WriteCtx(request.getHandle(), request.getOffset(),
        request.getCount(), originalCount, request.getStableHow(),
        request.getData(), null, 2, false, WriteCtx.DataState.NO_DUMP);
    ByteBuffer appendedData = writeCtx2.getData();

    int position = appendedData.position();
    int limit = appendedData.limit();
    Assert.assertTrue(position == 12);
    Assert.assertTrue(limit - position == 8);
    Assert.assertTrue(appendedData.get(position) == (byte) 12);
    Assert.assertTrue(appendedData.get(position + 1) == (byte) 13);
    Assert.assertTrue(appendedData.get(position + 2) == (byte) 14);
    Assert.assertTrue(appendedData.get(position + 7) == (byte) 19);

    // Test current file write offset is at boundaries
    buffer.position(0);
    request = new WRITE3Request(new FileHandle(), 0, data.length,
        WriteStableHow.UNSTABLE, buffer);
    OpenFileCtx.alterWriteRequest(request, 1);
    WriteCtx writeCtx3 = new WriteCtx(request.getHandle(), request.getOffset(),
        request.getCount(), originalCount, request.getStableHow(),
        request.getData(), null, 2, false, WriteCtx.DataState.NO_DUMP);
    appendedData = writeCtx3.getData();
    position = appendedData.position();
    limit = appendedData.limit();
    Assert.assertTrue(position == 1);
    Assert.assertTrue(limit - position == 19);
    Assert.assertTrue(appendedData.get(position) == (byte) 1);
    Assert.assertTrue(appendedData.get(position + 18) == (byte) 19);

    // Reset buffer position before test another boundary
    buffer.position(0);
    request = new WRITE3Request(new FileHandle(), 0, data.length,
        WriteStableHow.UNSTABLE, buffer);
    OpenFileCtx.alterWriteRequest(request, 19);
    WriteCtx writeCtx4 = new WriteCtx(request.getHandle(), request.getOffset(),
        request.getCount(), originalCount, request.getStableHow(),
        request.getData(), null, 2, false, WriteCtx.DataState.NO_DUMP);
    appendedData = writeCtx4.getData();
    position = appendedData.position();
    limit = appendedData.limit();
    Assert.assertTrue(position == 19);
    Assert.assertTrue(limit - position == 1);
    Assert.assertTrue(appendedData.get(position) == (byte) 19);
  }
"
"  @Test
  public void testCheckCommit() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);

    NfsConfiguration conf = new NfsConfiguration();
    conf.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, false);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(conf), false, conf);

    COMMIT_STATUS ret;

    // Test inactive open file context
    ctx.setActiveStatusForTest(false);
    Channel ch = Mockito.mock(Channel.class);
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_INACTIVE_CTX);

    ctx.getPendingWritesForTest().put(new OffsetRange(5, 10),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_INACTIVE_WITH_PENDING_WRITE);

    // Test request with non zero commit offset
    ctx.setActiveStatusForTest(true);
    Mockito.when(fos.getPos()).thenReturn((long) 10);
    ctx.setNextOffsetForTest(10);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
    // Do_SYNC state will be updated to FINISHED after data sync
    ret = ctx.checkCommit(dfsClient, 5, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);
    
    status = ctx.checkCommitInternal(10, ch, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
    ret = ctx.checkCommit(dfsClient, 10, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);

    ConcurrentNavigableMap<Long, CommitCtx> commits = ctx
        .getPendingCommitsForTest();
    Assert.assertTrue(commits.size() == 0);
    ret = ctx.checkCommit(dfsClient, 11, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_WAIT);
    Assert.assertTrue(commits.size() == 1);
    long key = commits.firstKey();
    Assert.assertTrue(key == 11);

    // Test request with zero commit offset
    commits.remove(new Long(11));
    // There is one pending write [5,10]
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_WAIT);
    Assert.assertTrue(commits.size() == 1);
    key = commits.firstKey();
    Assert.assertTrue(key == 9);

    // Empty pending writes
    ctx.getPendingWritesForTest().remove(new OffsetRange(5, 10));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);
  }
"
"  @Test
  public void testCheckCommitLargeFileUpload() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);

    NfsConfiguration conf = new NfsConfiguration();
    conf.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, true);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(conf), false, conf);

    COMMIT_STATUS ret;

    // Test inactive open file context
    ctx.setActiveStatusForTest(false);
    Channel ch = Mockito.mock(Channel.class);
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_INACTIVE_CTX);

    ctx.getPendingWritesForTest().put(new OffsetRange(10, 15),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_INACTIVE_WITH_PENDING_WRITE);

    // Test request with non zero commit offset
    ctx.setActiveStatusForTest(true);
    Mockito.when(fos.getPos()).thenReturn((long) 8);
    ctx.setNextOffsetForTest(10);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
    // Do_SYNC state will be updated to FINISHED after data sync
    ret = ctx.checkCommit(dfsClient, 5, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);
    
    // Test commit sequential writes
    status = ctx.checkCommitInternal(10, ch, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    ret = ctx.checkCommit(dfsClient, 10, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);

    // Test commit non-sequential writes
    ConcurrentNavigableMap<Long, CommitCtx> commits = ctx
        .getPendingCommitsForTest();
    Assert.assertTrue(commits.size() == 1);
    ret = ctx.checkCommit(dfsClient, 16, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_SUCCESS);
    Assert.assertTrue(commits.size() == 1);
    
    // Test request with zero commit offset
    commits.remove(new Long(10));
    // There is one pending write [10,15]
    ret = ctx.checkCommitInternal(0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    
    ret = ctx.checkCommitInternal(9, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    Assert.assertTrue(commits.size() == 2);

    // Empty pending writes. nextOffset=10, flushed pos=8
    ctx.getPendingWritesForTest().remove(new OffsetRange(10, 15));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    
    // Empty pending writes
    ctx.setNextOffsetForTest((long) 8); // flushed pos = 8
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, false);
    Assert.assertTrue(ret == COMMIT_STATUS.COMMIT_FINISHED);
    
  }
"
"  @Test
  public void testCheckCommitAixCompatMode() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);

    NfsConfiguration conf = new NfsConfiguration();
    conf.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, false);
    // Enable AIX compatibility mode.
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(new NfsConfiguration()), true, conf);
    
    // Test fall-through to pendingWrites check in the event that commitOffset
    // is greater than the number of bytes we've so far flushed.
    Mockito.when(fos.getPos()).thenReturn((long) 2);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_FINISHED);
    
    // Test the case when we actually have received more bytes than we're trying
    // to commit.
    ctx.getPendingWritesForTest().put(new OffsetRange(0, 10),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    Mockito.when(fos.getPos()).thenReturn((long) 10);
    ctx.setNextOffsetForTest((long)10);
    status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
  }
"
"  @Test
  public void testCheckCommitFromRead() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);
    NfsConfiguration config = new NfsConfiguration();

    config.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, false);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(config), false, config);

    FileHandle h = new FileHandle(1); // fake handle for ""/dumpFilePath""
    COMMIT_STATUS ret;
    WriteManager wm = new WriteManager(new ShellBasedIdMapping(config), config, false);
    assertTrue(wm.addOpenFileStream(h, ctx));
    
    // Test inactive open file context
    ctx.setActiveStatusForTest(false);
    Channel ch = Mockito.mock(Channel.class);
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals( COMMIT_STATUS.COMMIT_INACTIVE_CTX, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 0));
    
    ctx.getPendingWritesForTest().put(new OffsetRange(10, 15),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_INACTIVE_WITH_PENDING_WRITE, ret);
    assertEquals(Nfs3Status.NFS3ERR_IO, wm.commitBeforeRead(dfsClient, h, 0));
    
    // Test request with non zero commit offset
    ctx.setActiveStatusForTest(true);
    Mockito.when(fos.getPos()).thenReturn((long) 10);
    ctx.setNextOffsetForTest((long)10);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, ch, 1, attr, false);
    assertEquals(COMMIT_STATUS.COMMIT_DO_SYNC, status);
    // Do_SYNC state will be updated to FINISHED after data sync
    ret = ctx.checkCommit(dfsClient, 5, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_FINISHED, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 5));
 
    status = ctx.checkCommitInternal(10, ch, 1, attr, true);
    assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
    ret = ctx.checkCommit(dfsClient, 10, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_FINISHED, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 10));

    ConcurrentNavigableMap<Long, CommitCtx> commits = ctx
        .getPendingCommitsForTest();
    assertTrue(commits.size() == 0);
    ret = ctx.checkCommit(dfsClient, 11, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_WAIT, ret);
    assertEquals(0, commits.size()); // commit triggered by read doesn't wait
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 11));

    // Test request with zero commit offset
    // There is one pending write [5,10]
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_WAIT, ret);
    assertEquals(0, commits.size());
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 0));

    // Empty pending writes
    ctx.getPendingWritesForTest().remove(new OffsetRange(10, 15));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_FINISHED, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 0));
  }
"
"  @Test
  public void testCheckCommitFromReadLargeFileUpload() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);
    NfsConfiguration config = new NfsConfiguration();

    config.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, true);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(config), false, config);

    FileHandle h = new FileHandle(1); // fake handle for ""/dumpFilePath""
    COMMIT_STATUS ret;
    WriteManager wm = new WriteManager(new ShellBasedIdMapping(config), config, false);
    assertTrue(wm.addOpenFileStream(h, ctx));
    
    // Test inactive open file context
    ctx.setActiveStatusForTest(false);
    Channel ch = Mockito.mock(Channel.class);
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals( COMMIT_STATUS.COMMIT_INACTIVE_CTX, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 0));
    
    ctx.getPendingWritesForTest().put(new OffsetRange(10, 15),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_INACTIVE_WITH_PENDING_WRITE, ret);
    assertEquals(Nfs3Status.NFS3ERR_IO, wm.commitBeforeRead(dfsClient, h, 0));
    
    // Test request with non zero commit offset
    ctx.setActiveStatusForTest(true);
    Mockito.when(fos.getPos()).thenReturn((long) 6);
    ctx.setNextOffsetForTest((long)10);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, ch, 1, attr, false);
    assertEquals(COMMIT_STATUS.COMMIT_DO_SYNC, status);
    // Do_SYNC state will be updated to FINISHED after data sync
    ret = ctx.checkCommit(dfsClient, 5, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_FINISHED, ret);
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 5));
 
    // Test request with sequential writes
    status = ctx.checkCommitInternal(9, ch, 1, attr, true);
    assertTrue(status == COMMIT_STATUS.COMMIT_SPECIAL_WAIT);
    ret = ctx.checkCommit(dfsClient, 9, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_SPECIAL_WAIT, ret);
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 9));

    // Test request with non-sequential writes
    ConcurrentNavigableMap<Long, CommitCtx> commits = ctx
        .getPendingCommitsForTest();
    assertTrue(commits.size() == 0);
    ret = ctx.checkCommit(dfsClient, 16, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_SPECIAL_SUCCESS, ret);
    assertEquals(0, commits.size()); // commit triggered by read doesn't wait
    assertEquals(Nfs3Status.NFS3_OK, wm.commitBeforeRead(dfsClient, h, 16));

    // Test request with zero commit offset
    // There is one pending write [10,15]
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_SPECIAL_WAIT, ret);
    assertEquals(0, commits.size());
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 0));

    // Empty pending writes
    ctx.getPendingWritesForTest().remove(new OffsetRange(10, 15));
    ret = ctx.checkCommit(dfsClient, 0, ch, 1, attr, true);
    assertEquals(COMMIT_STATUS.COMMIT_SPECIAL_WAIT, ret);
    assertEquals(Nfs3Status.NFS3ERR_JUKEBOX, wm.commitBeforeRead(dfsClient, h, 0));
  }
"
"  @Test
  public void testWriteStableHow() throws IOException, InterruptedException {
    NfsConfiguration config = new NfsConfiguration();
    DFSClient client = null;
    MiniDFSCluster cluster = null;
    RpcProgramNfs3 nfsd;
    SecurityHandler securityHandler = Mockito.mock(SecurityHandler.class);
    Mockito.when(securityHandler.getUser()).thenReturn(
        System.getProperty(""user.name""));
    String currentUser = System.getProperty(""user.name"");
    config.set(
            DefaultImpersonationProvider.getTestProvider().
                getProxySuperuserGroupConfKey(currentUser),
            ""*"");
    config.set(
            DefaultImpersonationProvider.getTestProvider().
                getProxySuperuserIpConfKey(currentUser),
            ""*"");
    ProxyUsers.refreshSuperUserGroupsConfiguration(config);

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();
      client = new DFSClient(DFSUtilClient.getNNAddress(config), config);
      int namenodeId = Nfs3Utils.getNamenodeId(config);

      // Use emphral port in case tests are running in parallel
      config.setInt(""nfs3.mountd.port"", 0);
      config.setInt(""nfs3.server.port"", 0);
      
      // Start nfs
      Nfs3 nfs3 = new Nfs3(config);
      nfs3.startServiceInternal(false);
      nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();

      HdfsFileStatus status = client.getFileInfo(""/"");
      FileHandle rootHandle = new FileHandle(status.getFileId(), namenodeId);
      // Create file1
      CREATE3Request createReq = new CREATE3Request(rootHandle, ""file1"",
          Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
      XDR createXdr = new XDR();
      createReq.serialize(createXdr);
      CREATE3Response createRsp = nfsd.create(createXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));
      FileHandle handle = createRsp.getObjHandle();

      // Test DATA_SYNC
      byte[] buffer = new byte[10];
      for (int i = 0; i < 10; i++) {
        buffer[i] = (byte) i;
      }
      WRITE3Request writeReq = new WRITE3Request(handle, 0, 10,
          WriteStableHow.DATA_SYNC, ByteBuffer.wrap(buffer));
      XDR writeXdr = new XDR();
      writeReq.serialize(writeXdr);
      nfsd.write(writeXdr.asReadOnlyWrap(), null, 1, securityHandler,
          new InetSocketAddress(""localhost"", 1234));

      waitWrite(nfsd, handle, 60000);

      // Readback
      READ3Request readReq = new READ3Request(handle, 0, 10);
      XDR readXdr = new XDR();
      readReq.serialize(readXdr);
      READ3Response readRsp = nfsd.read(readXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));

      assertTrue(Arrays.equals(buffer, readRsp.getData().array()));

      // Test FILE_SYNC

      // Create file2
      CREATE3Request createReq2 = new CREATE3Request(rootHandle, ""file2"",
          Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
      XDR createXdr2 = new XDR();
      createReq2.serialize(createXdr2);
      CREATE3Response createRsp2 = nfsd.create(createXdr2.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));
      FileHandle handle2 = createRsp2.getObjHandle();

      WRITE3Request writeReq2 = new WRITE3Request(handle2, 0, 10,
          WriteStableHow.FILE_SYNC, ByteBuffer.wrap(buffer));
      XDR writeXdr2 = new XDR();
      writeReq2.serialize(writeXdr2);
      nfsd.write(writeXdr2.asReadOnlyWrap(), null, 1, securityHandler,
          new InetSocketAddress(""localhost"", 1234));

      waitWrite(nfsd, handle2, 60000);

      // Readback
      READ3Request readReq2 = new READ3Request(handle2, 0, 10);
      XDR readXdr2 = new XDR();
      readReq2.serialize(readXdr2);
      READ3Response readRsp2 = nfsd.read(readXdr2.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));

      assertTrue(Arrays.equals(buffer, readRsp2.getData().array()));
      // FILE_SYNC should sync the file size
      status = client.getFileInfo(""/file2"");
      assertTrue(status.getLen() == 10);

    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
"
"  @Test
  public void testOOOWrites() throws IOException, InterruptedException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    RpcProgramNfs3 nfsd;
    final int bufSize = 32;
    final int numOOO = 3;
    SecurityHandler securityHandler = Mockito.mock(SecurityHandler.class);
    Mockito.when(securityHandler.getUser()).thenReturn(
        System.getProperty(""user.name""));
    String currentUser = System.getProperty(""user.name"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserGroupConfKey(currentUser),
        ""*"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserIpConfKey(currentUser),
        ""*"");
    ProxyUsers.refreshSuperUserGroupsConfiguration(config);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();

      Nfs3 nfs3 = new Nfs3(config);
      nfs3.startServiceInternal(false);
      nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();

      DFSClient dfsClient = new DFSClient(DFSUtilClient.getNNAddress(config),
          config);
      int namenodeId = Nfs3Utils.getNamenodeId(config);
      HdfsFileStatus status = dfsClient.getFileInfo(""/"");
      FileHandle rootHandle = new FileHandle(status.getFileId(), namenodeId);

      CREATE3Request createReq = new CREATE3Request(rootHandle,
          ""out-of-order-write"" + System.currentTimeMillis(),
          Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
      XDR createXdr = new XDR();
      createReq.serialize(createXdr);
      CREATE3Response createRsp = nfsd.create(createXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));
      FileHandle handle = createRsp.getObjHandle();

      byte[][] oooBuf = new byte[numOOO][bufSize];
      for (int i = 0; i < numOOO; i++) {
        Arrays.fill(oooBuf[i], (byte) i);
      }

      for (int i = 0; i < numOOO; i++) {
        final long offset = (numOOO - 1 - i) * bufSize;
        WRITE3Request writeReq = new WRITE3Request(handle, offset, bufSize,
            WriteStableHow.UNSTABLE, ByteBuffer.wrap(oooBuf[i]));
        XDR writeXdr = new XDR();
        writeReq.serialize(writeXdr);
        nfsd.write(writeXdr.asReadOnlyWrap(), null, 1, securityHandler,
            new InetSocketAddress(""localhost"", 1234));
      }

      waitWrite(nfsd, handle, 60000);
      READ3Request readReq = new READ3Request(handle, bufSize, bufSize);
      XDR readXdr = new XDR();
      readReq.serialize(readXdr);
      READ3Response readRsp = nfsd.read(readXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", config.getInt(
              NfsConfigKeys.DFS_NFS_SERVER_PORT_KEY,
              NfsConfigKeys.DFS_NFS_SERVER_PORT_DEFAULT)));
      assertTrue(Arrays.equals(oooBuf[1], readRsp.getData().array()));
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
"
"  @Test
  public void testOverlappingWrites() throws IOException, InterruptedException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    RpcProgramNfs3 nfsd;
    final int bufSize = 32;
    SecurityHandler securityHandler = Mockito.mock(SecurityHandler.class);
    Mockito.when(securityHandler.getUser()).thenReturn(
        System.getProperty(""user.name""));
    String currentUser = System.getProperty(""user.name"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserGroupConfKey(currentUser),
        ""*"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserIpConfKey(currentUser),
        ""*"");
    ProxyUsers.refreshSuperUserGroupsConfiguration(config);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();

      Nfs3 nfs3 = new Nfs3(config);
      nfs3.startServiceInternal(false);
      nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();

      DFSClient dfsClient = new DFSClient(DFSUtilClient.getNNAddress(config),
          config);
      int namenodeId = Nfs3Utils.getNamenodeId(config);
      HdfsFileStatus status = dfsClient.getFileInfo(""/"");
      FileHandle rootHandle = new FileHandle(status.getFileId(), namenodeId);

      CREATE3Request createReq = new CREATE3Request(rootHandle,
          ""overlapping-writes"" + System.currentTimeMillis(),
          Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
      XDR createXdr = new XDR();
      createReq.serialize(createXdr);
      CREATE3Response createRsp = nfsd.create(createXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));
      FileHandle handle = createRsp.getObjHandle();
      byte[] buffer = new byte[bufSize];
      for (int i = 0; i < bufSize; i++) {
        buffer[i] = (byte) i;
      }
      int[][] ranges = new int[][] {
          {0, 10},
          {5, 7},
          {5, 5},
          {10, 6},
          {18, 6},
          {20, 6},
          {28, 4},
          {16, 2},
          {25, 4}
      };
      for (int i = 0; i < ranges.length; i++) {
        int x[] = ranges[i];
        byte[] tbuffer = new byte[x[1]];
        for (int j = 0; j < x[1]; j++) {
          tbuffer[j] = buffer[x[0] + j];
        }
        WRITE3Request writeReq = new WRITE3Request(handle, (long)x[0], x[1],
            WriteStableHow.UNSTABLE, ByteBuffer.wrap(tbuffer));
        XDR writeXdr = new XDR();
        writeReq.serialize(writeXdr);
        nfsd.write(writeXdr.asReadOnlyWrap(), null, 1, securityHandler,
            new InetSocketAddress(""localhost"", 1234));
      }

      waitWrite(nfsd, handle, 60000);
      READ3Request readReq = new READ3Request(handle, 0, bufSize);
      XDR readXdr = new XDR();
      readReq.serialize(readXdr);
      READ3Response readRsp = nfsd.read(readXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", config.getInt(
              NfsConfigKeys.DFS_NFS_SERVER_PORT_KEY,
              NfsConfigKeys.DFS_NFS_SERVER_PORT_DEFAULT)));

      assertTrue(Arrays.equals(buffer, readRsp.getData().array()));
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
"
"  @Test
  public void testCheckSequential() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);
    NfsConfiguration config = new NfsConfiguration();

    config.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, false);
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(config), false, config);
    
    ctx.getPendingWritesForTest().put(new OffsetRange(5, 10),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ctx.getPendingWritesForTest().put(new OffsetRange(10, 15),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    ctx.getPendingWritesForTest().put(new OffsetRange(20, 25),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));

    assertTrue(!ctx.checkSequential(5, 4));
    assertTrue(ctx.checkSequential(9, 5));
    assertTrue(ctx.checkSequential(10, 5));
    assertTrue(ctx.checkSequential(14, 5));
    assertTrue(!ctx.checkSequential(15, 5));
    assertTrue(!ctx.checkSequential(20, 5));
    assertTrue(!ctx.checkSequential(25, 5));
    assertTrue(!ctx.checkSequential(999, 5));
  }
"
"  @Test
  public void testHttpServer() throws Exception {
    Nfs3 nfs = new Nfs3(conf);
    nfs.startServiceInternal(false);
    RpcProgramNfs3 nfsd = (RpcProgramNfs3) nfs.getRpcProgram();
    Nfs3HttpServer infoServer = nfsd.getInfoServer();

    String urlRoot = infoServer.getServerURI().toString();

    // Check default servlets.
    String pageContents = DFSTestUtil.urlGet(new URL(urlRoot + ""/jmx""));
    assertTrue(""Bad contents: "" + pageContents,
        pageContents.contains(""java.lang:type=""));
    System.out.println(""pc:"" + pageContents);

    int port = infoServer.getSecurePort();
    assertTrue(""Can't get https port"", port > 0);
  }
"
"  @Test(timeout = 60000)
  public void testGetattr() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    GETATTR3Request req = new GETATTR3Request(handle);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    GETATTR3Response response1 = nfsd.getattr(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    GETATTR3Response response2 = nfsd.getattr(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testSetattr() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    SetAttr3 symAttr = new SetAttr3(0, 1, 0, 0, null, null,
        EnumSet.of(SetAttrField.UID));
    SETATTR3Request req = new SETATTR3Request(handle, symAttr, false, null);
    req.serialize(xdr_req);

    // Attempt by an unprivileged user should fail.
    SETATTR3Response response1 = nfsd.setattr(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    SETATTR3Response response2 = nfsd.setattr(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testLookup() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    LOOKUP3Request lookupReq = new LOOKUP3Request(handle, ""bar"");
    XDR xdr_req = new XDR();
    lookupReq.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    LOOKUP3Response response1 = nfsd.lookup(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    LOOKUP3Response response2 = nfsd.lookup(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testAccess() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    ACCESS3Request req = new ACCESS3Request(handle);
    req.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    ACCESS3Response response1 = nfsd.access(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    ACCESS3Response response2 = nfsd.access(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testReadlink() throws Exception {
    // Create a symlink first.
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    SYMLINK3Request req = new SYMLINK3Request(handle, ""fubar"", new SetAttr3(),
        ""bar"");
    req.serialize(xdr_req);
    
    SYMLINK3Response response = nfsd.symlink(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response.getStatus());

    // Now perform readlink operations.
    FileHandle handle2 = response.getObjFileHandle();
    XDR xdr_req2 = new XDR();
    READLINK3Request req2 = new READLINK3Request(handle2);
    req2.serialize(xdr_req2);

    // Attempt by an unpriviledged user should fail.
    READLINK3Response response1 = nfsd.readlink(xdr_req2.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    READLINK3Response response2 = nfsd.readlink(xdr_req2.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testRead() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);

    READ3Request readReq = new READ3Request(handle, 0, 5);
    XDR xdr_req = new XDR();
    readReq.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    READ3Response response1 = nfsd.read(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    READ3Response response2 = nfsd.read(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 120000)
  public void testEncryptedReadWrite() throws Exception {
    final int len = 8192;

    final Path zone = new Path(""/zone"");
    hdfs.mkdirs(zone);
    dfsAdmin.createEncryptionZone(zone, TEST_KEY, NO_TRASH);

    final byte[] buffer = new byte[len];
    for (int i = 0; i < len; i++) {
      buffer[i] = (byte) i;
    }

    final String encFile1 = ""/zone/myfile"";
    createFileUsingNfs(encFile1, buffer);
    commit(encFile1, len);
    assertArrayEquals(""encFile1 not equal"",
        getFileContentsUsingNfs(encFile1, len),
        getFileContentsUsingDfs(encFile1, len));

    /*
     * Same thing except this time create the encrypted file using DFS.
     */
    final String encFile2 = ""/zone/myfile2"";
    final Path encFile2Path = new Path(encFile2);
    DFSTestUtil.createFile(hdfs, encFile2Path, len, (short) 1, 0xFEED);
    assertArrayEquals(""encFile2 not equal"",
        getFileContentsUsingNfs(encFile2, len),
        getFileContentsUsingDfs(encFile2, len));
  }
"
"  @Test(timeout = 60000)
  public void testWrite() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);

    byte[] buffer = new byte[10];
    for (int i = 0; i < 10; i++) {
      buffer[i] = (byte) i;
    }

    WRITE3Request writeReq = new WRITE3Request(handle, 0, 10,
        WriteStableHow.DATA_SYNC, ByteBuffer.wrap(buffer));
    XDR xdr_req = new XDR();
    writeReq.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    WRITE3Response response1 = nfsd.write(xdr_req.asReadOnlyWrap(),
        null, 1, securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    WRITE3Response response2 = nfsd.write(xdr_req.asReadOnlyWrap(),
        null, 1, securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect response:"", null, response2);
  }
"
"  @Test(timeout = 60000)
  public void testCreate() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    CREATE3Request req = new CREATE3Request(handle, ""fubar"",
        Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    CREATE3Response response1 = nfsd.create(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    CREATE3Response response2 = nfsd.create(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testMkdir() throws Exception {//FixME
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    MKDIR3Request req = new MKDIR3Request(handle, ""fubar1"", new SetAttr3());
    req.serialize(xdr_req);
    
    // Attempt to mkdir by an unprivileged user should fail.
    MKDIR3Response response1 = nfsd.mkdir(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    XDR xdr_req2 = new XDR();
    MKDIR3Request req2 = new MKDIR3Request(handle, ""fubar2"", new SetAttr3());
    req2.serialize(xdr_req2);
    
    // Attempt to mkdir by a privileged user should pass.
    MKDIR3Response response2 = nfsd.mkdir(xdr_req2.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testSymlink() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    SYMLINK3Request req = new SYMLINK3Request(handle, ""fubar"", new SetAttr3(),
        ""bar"");
    req.serialize(xdr_req);

    // Attempt by an unprivileged user should fail.
    SYMLINK3Response response1 = nfsd.symlink(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a privileged user should pass.
    SYMLINK3Response response2 = nfsd.symlink(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testRemove() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    REMOVE3Request req = new REMOVE3Request(handle, ""bar"");
    req.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    REMOVE3Response response1 = nfsd.remove(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    REMOVE3Response response2 = nfsd.remove(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testRmdir() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    RMDIR3Request req = new RMDIR3Request(handle, ""foo"");
    req.serialize(xdr_req);

    // Attempt by an unprivileged user should fail.
    RMDIR3Response response1 = nfsd.rmdir(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a privileged user should pass.
    RMDIR3Response response2 = nfsd.rmdir(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testRename() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    RENAME3Request req = new RENAME3Request(handle, ""bar"", handle, ""fubar"");
    req.serialize(xdr_req);
    
    // Attempt by an unprivileged user should fail.
    RENAME3Response response1 = nfsd.rename(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a privileged user should pass.
    RENAME3Response response2 = nfsd.rename(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testReaddir() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    READDIR3Request req = new READDIR3Request(handle, 0, 0, 100);
    req.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    READDIR3Response response1 = nfsd.readdir(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    READDIR3Response response2 = nfsd.readdir(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testReaddirplus() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    READDIRPLUS3Request req = new READDIRPLUS3Request(handle, 0, 0, 3, 2);
    req.serialize(xdr_req);
    
    // Attempt by an unprivileged user should fail.
    READDIRPLUS3Response response1 = nfsd.readdirplus(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a privileged user should pass.
    READDIRPLUS3Response response2 = nfsd.readdirplus(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testFsstat() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    FSSTAT3Request req = new FSSTAT3Request(handle);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    FSSTAT3Response response1 = nfsd.fsstat(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    FSSTAT3Response response2 = nfsd.fsstat(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testFsinfo() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    FSINFO3Request req = new FSINFO3Request(handle);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    FSINFO3Response response1 = nfsd.fsinfo(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    FSINFO3Response response2 = nfsd.fsinfo(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testPathconf() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    PATHCONF3Request req = new PATHCONF3Request(handle);
    req.serialize(xdr_req);
    
    // Attempt by an unpriviledged user should fail.
    PATHCONF3Response response1 = nfsd.pathconf(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    PATHCONF3Response response2 = nfsd.pathconf(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
"
"  @Test(timeout = 60000)
  public void testCommit() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    XDR xdr_req = new XDR();
    COMMIT3Request req = new COMMIT3Request(handle, 0, 5);
    req.serialize(xdr_req);

    Channel ch = Mockito.mock(Channel.class);

    // Attempt by an unpriviledged user should fail.
    COMMIT3Response response1 = nfsd.commit(xdr_req.asReadOnlyWrap(),
        ch, 1, securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    COMMIT3Response response2 = nfsd.commit(xdr_req.asReadOnlyWrap(),
        ch, 1, securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect COMMIT3Response:"", null, response2);
  }
"
"  @Test(timeout=10000)
  public void testIdempotent() {
    Object[][] procedures = {
        { Nfs3Constant.NFSPROC3.NULL, 1 },
        { Nfs3Constant.NFSPROC3.GETATTR, 1 },
        { Nfs3Constant.NFSPROC3.SETATTR, 1 },
        { Nfs3Constant.NFSPROC3.LOOKUP, 1 },
        { Nfs3Constant.NFSPROC3.ACCESS, 1 },
        { Nfs3Constant.NFSPROC3.READLINK, 1 },
        { Nfs3Constant.NFSPROC3.READ, 1 },
        { Nfs3Constant.NFSPROC3.WRITE, 1 },
        { Nfs3Constant.NFSPROC3.CREATE, 0 },
        { Nfs3Constant.NFSPROC3.MKDIR, 0 },
        { Nfs3Constant.NFSPROC3.SYMLINK, 0 },
        { Nfs3Constant.NFSPROC3.MKNOD, 0 },
        { Nfs3Constant.NFSPROC3.REMOVE, 0 },
        { Nfs3Constant.NFSPROC3.RMDIR, 0 },
        { Nfs3Constant.NFSPROC3.RENAME, 0 },
        { Nfs3Constant.NFSPROC3.LINK, 0 },
        { Nfs3Constant.NFSPROC3.READDIR, 1 },
        { Nfs3Constant.NFSPROC3.READDIRPLUS, 1 },
        { Nfs3Constant.NFSPROC3.FSSTAT, 1 },
        { Nfs3Constant.NFSPROC3.FSINFO, 1 },
        { Nfs3Constant.NFSPROC3.PATHCONF, 1 },
        { Nfs3Constant.NFSPROC3.COMMIT, 1 } };
    for (Object[] procedure : procedures) {
      boolean idempotent = procedure[1].equals(Integer.valueOf(1));
      Nfs3Constant.NFSPROC3 proc = (Nfs3Constant.NFSPROC3)procedure[0];
      if (idempotent) {
        Assert.assertTrue((""Procedure "" + proc + "" should be idempotent""),
            proc.isIdempotent());
      } else {
        Assert.assertFalse((""Procedure "" + proc + "" should be non-idempotent""),
            proc.isIdempotent());
      }
    }
  }
"
"  @Test
  public void testDeprecatedKeys() {
    NfsConfiguration conf = new NfsConfiguration();
    conf.setInt(""nfs3.server.port"", 998);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_SERVER_PORT_KEY, 0) == 998);

    conf.setInt(""nfs3.mountd.port"", 999);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_MOUNTD_PORT_KEY, 0) == 999);

    conf.set(""dfs.nfs.exports.allowed.hosts"", ""host1"");
    assertTrue(conf.get(CommonConfigurationKeys.NFS_EXPORTS_ALLOWED_HOSTS_KEY)
        .equals(""host1""));

    conf.setInt(""dfs.nfs.exports.cache.expirytime.millis"", 1000);
    assertTrue(conf.getInt(
        Nfs3Constant.NFS_EXPORTS_CACHE_EXPIRYTIME_MILLIS_KEY, 0) == 1000);

    conf.setInt(""hadoop.nfs.userupdate.milly"", 10);
    assertTrue(conf.getInt(IdMappingConstant.USERGROUPID_UPDATE_MILLIS_KEY, 0) == 10);

    conf.set(""dfs.nfs3.dump.dir"", ""/nfs/tmp"");
    assertTrue(conf.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY).equals(
        ""/nfs/tmp""));

    conf.setBoolean(""dfs.nfs3.enableDump"", false);
    assertTrue(conf.getBoolean(NfsConfigKeys.DFS_NFS_FILE_DUMP_KEY, true) == false);

    conf.setInt(""dfs.nfs3.max.open.files"", 500);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_MAX_OPEN_FILES_KEY, 0) == 500);

    conf.setInt(""dfs.nfs3.stream.timeout"", 6000);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_KEY, 0) == 6000);

    conf.set(""dfs.nfs3.export.point"", ""/dir1"");
    assertTrue(conf.get(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY).equals(""/dir1""));
  }
"
"  @Test
  public void testGetAccessRightsForUserGroup() throws IOException {
    Nfs3FileAttributes attr = Mockito.mock(Nfs3FileAttributes.class);
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(3);
    Mockito.when(attr.getMode()).thenReturn(448); // 700
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSREG.toValue());
    assertEquals(""No access should be allowed as UID does not match attribute over mode 700"",
      0, Nfs3Utils.getAccessRightsForUserGroup(3, 3, null, attr));
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(3);
    Mockito.when(attr.getMode()).thenReturn(56); // 070
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSREG.toValue());
    assertEquals(""No access should be allowed as GID does not match attribute over mode 070"",
      0, Nfs3Utils.getAccessRightsForUserGroup(2, 4, null, attr));
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(3);
    Mockito.when(attr.getMode()).thenReturn(7); // 007
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSREG.toValue());
    assertEquals(""Access should be allowed as mode is 007 and UID/GID do not match"",
      61 /* RWX */, Nfs3Utils.getAccessRightsForUserGroup(1, 4, new int[] {5, 6}, attr));
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(10);
    Mockito.when(attr.getMode()).thenReturn(288); // 440
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSREG.toValue());
    assertEquals(""Access should be allowed as mode is 440 and Aux GID does match"",
      1 /* R */, Nfs3Utils.getAccessRightsForUserGroup(3, 4, new int[] {5, 16, 10}, attr));
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(10);
    Mockito.when(attr.getMode()).thenReturn(448); // 700
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSDIR.toValue());
    assertEquals(""Access should be allowed for dir as mode is 700 and UID does match"",
      31 /* Lookup */, Nfs3Utils.getAccessRightsForUserGroup(2, 4, new int[] {5, 16, 10}, attr));
    assertEquals(""No access should be allowed for dir as mode is 700 even though GID does match"",
      0, Nfs3Utils.getAccessRightsForUserGroup(3, 10, new int[] {5, 16, 4}, attr));
    assertEquals(""No access should be allowed for dir as mode is 700 even though AuxGID does match"",
      0, Nfs3Utils.getAccessRightsForUserGroup(3, 20, new int[] {5, 10}, attr));
    
    Mockito.when(attr.getUid()).thenReturn(2);
    Mockito.when(attr.getGid()).thenReturn(10);
    Mockito.when(attr.getMode()).thenReturn(457); // 711
    Mockito.when(attr.getType()).thenReturn(NfsFileType.NFSDIR.toValue());
    assertEquals(""Access should be allowed for dir as mode is 711 and GID matches"",
        2 /* Lookup */, Nfs3Utils.getAccessRightsForUserGroup(3, 10, new int[] {5, 16, 11}, attr));
  }
"
"  @Test
  public void testEviction() throws IOException {
    NfsConfiguration conf = new NfsConfiguration();
    conf.set(FileSystem.FS_DEFAULT_NAME_KEY, ""hdfs://localhost"");

    // Only one entry will be in the cache
    final int MAX_CACHE_SIZE = 1;

    DFSClientCache cache = new DFSClientCache(conf, MAX_CACHE_SIZE);

    int namenodeId = Nfs3Utils.getNamenodeId(conf);
    DFSClient c1 = cache.getDfsClient(""test1"", namenodeId);
    assertTrue(cache.getDfsClient(""test1"", namenodeId)
        .toString().contains(""ugi=test1""));
    assertEquals(c1, cache.getDfsClient(""test1"", namenodeId));
    assertFalse(isDfsClientClose(c1));

    cache.getDfsClient(""test2"", namenodeId);
    assertTrue(isDfsClientClose(c1));
    assertTrue(""cache size should be the max size or less"",
        cache.getClientCache().size() <= MAX_CACHE_SIZE);
  }
"
"  @Test
  public void testGetUserGroupInformationSecure() throws IOException {
    String userName = ""user1"";
    String currentUser = ""test-user"";


    NfsConfiguration conf = new NfsConfiguration();
    conf.set(FileSystem.FS_DEFAULT_NAME_KEY, ""hdfs://localhost"");
    UserGroupInformation currentUserUgi
            = UserGroupInformation.createRemoteUser(currentUser);
    currentUserUgi.setAuthenticationMethod(KERBEROS);
    UserGroupInformation.setLoginUser(currentUserUgi);

    DFSClientCache cache = new DFSClientCache(conf);
    UserGroupInformation ugiResult
            = cache.getUserGroupInformation(userName, currentUserUgi);

    assertThat(ugiResult.getUserName(), is(userName));
    assertThat(ugiResult.getRealUser(), is(currentUserUgi));
    assertThat(
            ugiResult.getAuthenticationMethod(),
            is(UserGroupInformation.AuthenticationMethod.PROXY));
  }
"
"  @Test
  public void testGetUserGroupInformation() throws IOException {
    String userName = ""user1"";
    String currentUser = ""currentUser"";

    UserGroupInformation currentUserUgi = UserGroupInformation
            .createUserForTesting(currentUser, new String[0]);
    NfsConfiguration conf = new NfsConfiguration();
    conf.set(FileSystem.FS_DEFAULT_NAME_KEY, ""hdfs://localhost"");
    DFSClientCache cache = new DFSClientCache(conf);
    UserGroupInformation ugiResult
            = cache.getUserGroupInformation(userName, currentUserUgi);

    assertThat(ugiResult.getUserName(), is(userName));
    assertThat(ugiResult.getRealUser(), is(currentUserUgi));
    assertThat(
            ugiResult.getAuthenticationMethod(),
            is(UserGroupInformation.AuthenticationMethod.PROXY));
  }
"
"  @Test
  public void testNumExports() throws Exception {
    Assert.assertEquals(mountd.getExports().size(),
        viewFs.getChildFileSystems().length);
  }
"
"  @Test
  public void testPaths() throws Exception {
    Assert.assertEquals(hdfs1.resolvePath(new Path(""/user1/file1"")),
        viewFs.resolvePath(new Path(""/hdfs1/file1"")));
    Assert.assertEquals(hdfs1.resolvePath(new Path(""/user1/file2"")),
        viewFs.resolvePath(new Path(""/hdfs1/file2"")));
    Assert.assertEquals(hdfs2.resolvePath(new Path(""/user2/dir2"")),
        viewFs.resolvePath(new Path(""/hdfs2/dir2"")));
  }
"
"  @Test
  public void testFileStatus() throws Exception {
    HdfsFileStatus status = nn1.getRpcServer().getFileInfo(""/user1/file1"");
    FileStatus st = viewFs.getFileStatus(new Path(""/hdfs1/file1""));
    Assert.assertEquals(st.isDirectory(), status.isDirectory());

    HdfsFileStatus status2 = nn2.getRpcServer().getFileInfo(""/user2/dir2"");
    FileStatus st2 = viewFs.getFileStatus(new Path(""/hdfs2/dir2""));
    Assert.assertEquals(st2.isDirectory(), status2.isDirectory());
  }
"
"  @Test (timeout = 60000)
  public void testNfsAccessNN1() throws Exception {
    HdfsFileStatus status = nn1.getRpcServer().getFileInfo(""/user1/file1"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs1.getUri());
    testNfsGetAttrResponse(status.getFileId(), namenodeId, Nfs3Status.NFS3_OK);
  }
"
"  @Test (timeout = 60000)
  public void testNfsAccessNN2() throws Exception {
    HdfsFileStatus status = nn2.getRpcServer().getFileInfo(""/user2/dir2"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs2.getUri());
    testNfsGetAttrResponse(status.getFileId(), namenodeId, Nfs3Status.NFS3_OK);
  }
"
"  @Test (timeout = 60000)
  public void testWrongNfsAccess() throws Exception {
    DFSTestUtil.createFile(viewFs, new Path(""/hdfs1/file3""), 0, (short) 1, 0);
    HdfsFileStatus status = nn1.getRpcServer().getFileInfo(""/user1/file3"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs2.getUri());
    testNfsGetAttrResponse(status.getFileId(), namenodeId,
        Nfs3Status.NFS3ERR_IO);
  }
"
"  @Test (timeout = 60000)
  public void testNfsWriteNN1() throws Exception {
    HdfsFileStatus status = nn1.getRpcServer().getFileInfo(""/user1/write1"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs1.getUri());
    testNfsWriteResponse(status.getFileId(), namenodeId);
  }
"
"  @Test (timeout = 60000)
  public void testNfsWriteNN2() throws Exception {
    HdfsFileStatus status = nn2.getRpcServer().getFileInfo(""/user2/write2"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs2.getUri());
    testNfsWriteResponse(status.getFileId(), namenodeId);
  }
"
"  @Test (timeout = 60000)
  public void testNfsRenameMultiNN() throws Exception {
    HdfsFileStatus fromFileStatus = nn1.getRpcServer().getFileInfo(""/user1"");
    int fromNNId = Nfs3Utils.getNamenodeId(config, hdfs1.getUri());
    FileHandle fromHandle =
        new FileHandle(fromFileStatus.getFileId(), fromNNId);

    HdfsFileStatus toFileStatus = nn2.getRpcServer().getFileInfo(""/user2"");
    int toNNId = Nfs3Utils.getNamenodeId(config, hdfs2.getUri());
    FileHandle toHandle = new FileHandle(toFileStatus.getFileId(), toNNId);

    HdfsFileStatus statusBeforeRename =
        nn1.getRpcServer().getFileInfo(""/user1/renameMultiNN"");
    Assert.assertEquals(statusBeforeRename.isDirectory(), false);

    testNfsRename(fromHandle, ""renameMultiNN"",
        toHandle, ""renameMultiNNFail"", Nfs3Status.NFS3ERR_INVAL);

    HdfsFileStatus statusAfterRename =
        nn2.getRpcServer().getFileInfo(""/user2/renameMultiNNFail"");
    Assert.assertEquals(statusAfterRename, null);

    statusAfterRename = nn1.getRpcServer().getFileInfo(""/user1/renameMultiNN"");
    Assert.assertEquals(statusAfterRename.isDirectory(), false);
  }
"
"  @Test (timeout = 60000)
  public void testNfsRenameSingleNN() throws Exception {
    HdfsFileStatus fromFileStatus = nn1.getRpcServer().getFileInfo(""/user1"");
    int fromNNId = Nfs3Utils.getNamenodeId(config, hdfs1.getUri());
    FileHandle fromHandle =
        new FileHandle(fromFileStatus.getFileId(), fromNNId);

    HdfsFileStatus statusBeforeRename =
        nn1.getRpcServer().getFileInfo(""/user1/renameSingleNN"");
    Assert.assertEquals(statusBeforeRename.isDirectory(), false);

    testNfsRename(fromHandle, ""renameSingleNN"",
        fromHandle, ""renameSingleNNSucess"", Nfs3Status.NFS3_OK);

    HdfsFileStatus statusAfterRename =
        nn1.getRpcServer().getFileInfo(""/user1/renameSingleNNSucess"");
    Assert.assertEquals(statusAfterRename.isDirectory(), false);

    statusAfterRename =
        nn1.getRpcServer().getFileInfo(""/user1/renameSingleNN"");
    Assert.assertEquals(statusAfterRename, null);
  }
"
"  @Test
  public void testEviction() throws IOException, InterruptedException {
    NfsConfiguration conf = new NfsConfiguration();

    // Only two entries will be in the cache
    conf.setInt(NfsConfigKeys.DFS_NFS_MAX_OPEN_FILES_KEY, 2);

    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);

    OpenFileCtx context1 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context2 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context3 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context4 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context5 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));

    OpenFileCtxCache cache = new OpenFileCtxCache(conf, 10 * 60 * 100);

    boolean ret = cache.put(new FileHandle(1), context1);
    assertTrue(ret);
    Thread.sleep(1000);
    ret = cache.put(new FileHandle(2), context2);
    assertTrue(ret);
    ret = cache.put(new FileHandle(3), context3);
    assertFalse(ret);
    assertTrue(cache.size() == 2);

    // Wait for the oldest stream to be evict-able, insert again
    Thread.sleep(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);
    assertTrue(cache.size() == 2);

    ret = cache.put(new FileHandle(3), context3);
    assertTrue(ret);
    assertTrue(cache.size() == 2);
    assertTrue(cache.get(new FileHandle(1)) == null);

    // Test inactive entry is evicted immediately
    context3.setActiveStatusForTest(false);
    ret = cache.put(new FileHandle(4), context4);
    assertTrue(ret);

    // Now the cache has context2 and context4
    // Test eviction failure if all entries have pending work.
    context2.getPendingWritesForTest().put(new OffsetRange(0, 100),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    context4.getPendingCommitsForTest().put(new Long(100),
        new CommitCtx(0, null, 0, attr));
    Thread.sleep(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);
    ret = cache.put(new FileHandle(5), context5);
    assertFalse(ret);
  }
"
"  @Test
  public void testScan() throws IOException, InterruptedException {
    NfsConfiguration conf = new NfsConfiguration();

    // Only two entries will be in the cache
    conf.setInt(NfsConfigKeys.DFS_NFS_MAX_OPEN_FILES_KEY, 2);

    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);
    Mockito.when(fos.getPos()).thenReturn((long) 0);

    OpenFileCtx context1 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context2 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context3 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));
    OpenFileCtx context4 = new OpenFileCtx(fos, attr, ""/dumpFilePath"",
        dfsClient, new ShellBasedIdMapping(new NfsConfiguration()));

    OpenFileCtxCache cache = new OpenFileCtxCache(conf, 10 * 60 * 100);

    // Test cleaning expired entry
    boolean ret = cache.put(new FileHandle(1), context1);
    assertTrue(ret);
    ret = cache.put(new FileHandle(2), context2);
    assertTrue(ret);
    Thread.sleep(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT + 1);
    cache.scan(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_MIN_DEFAULT);
    assertTrue(cache.size() == 0);

    // Test cleaning inactive entry
    ret = cache.put(new FileHandle(3), context3);
    assertTrue(ret);
    ret = cache.put(new FileHandle(4), context4);
    assertTrue(ret);
    context3.setActiveStatusForTest(false);
    cache.scan(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_DEFAULT);
    assertTrue(cache.size() == 1);
    assertTrue(cache.get(new FileHandle(3)) == null);
    assertTrue(cache.get(new FileHandle(4)) != null);
  }
"
"  @Test(timeout = 60000)
  public void testClientAccessPrivilegeForRemove() throws Exception {
    // Configure ro access for nfs1 service
    config.set(""dfs.nfs.exports.allowed.hosts"", ""* ro"");

    // Start nfs
    Nfs3 nfs = new Nfs3(config);
    nfs.startServiceInternal(false);

    RpcProgramNfs3 nfsd = (RpcProgramNfs3) nfs.getRpcProgram();

    // Create a remove request
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);

    XDR xdr_req = new XDR();
    FileHandle handle = new FileHandle(dirId, namenodeId);
    handle.serialize(xdr_req);
    xdr_req.writeString(""f1"");

    // Remove operation
    REMOVE3Response response = nfsd.remove(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));

    // Assert on return code
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response.getStatus());

  }
"
"  @Test
  public void testHdfsExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;

    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();

      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);

      Mountd mountd = nfsServer.getMountd();
      RpcProgramMountd rpcMount = (RpcProgramMountd) mountd.getRpcProgram();
      assertTrue(rpcMount.getExports().size() == 1);

      String exportInMountd = rpcMount.getExports().get(0);
      assertTrue(exportInMountd.equals(""/""));

    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
"
"  @Test
  public void testViewFsMultipleExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    String clusterName = RandomStringUtils.randomAlphabetic(10);

    String exportPoint = ""/hdfs1,/hdfs2"";
    config.setStrings(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY, exportPoint);
    config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY,
        FsConstants.VIEWFS_SCHEME + ""://"" + clusterName);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster =
          new MiniDFSCluster.Builder(config).nnTopology(
              MiniDFSNNTopology.simpleFederatedTopology(2))
              .numDataNodes(2)
              .build();
      cluster.waitActive();
      DistributedFileSystem hdfs1 = cluster.getFileSystem(0);
      DistributedFileSystem hdfs2 = cluster.getFileSystem(1);
      cluster.waitActive();
      Path base1 = new Path(""/user1"");
      Path base2 = new Path(""/user2"");
      hdfs1.delete(base1, true);
      hdfs2.delete(base2, true);
      hdfs1.mkdirs(base1);
      hdfs2.mkdirs(base2);
      ConfigUtil.addLink(config, clusterName, ""/hdfs1"",
          hdfs1.makeQualified(base1).toUri());
      ConfigUtil.addLink(config, clusterName, ""/hdfs2"",
          hdfs2.makeQualified(base2).toUri());

      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);

      Mountd mountd = nfsServer.getMountd();
      RpcProgramMountd rpcMount = (RpcProgramMountd) mountd.getRpcProgram();
      assertTrue(rpcMount.getExports().size() == 2);

      String exportInMountd1 = rpcMount.getExports().get(0);
      assertTrue(exportInMountd1.equals(""/hdfs1""));

      String exportInMountd2 = rpcMount.getExports().get(1);
      assertTrue(exportInMountd2.equals(""/hdfs2""));

    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
"
"  @Test
  public void testViewFsInternalExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    String clusterName = RandomStringUtils.randomAlphabetic(10);

    String exportPoint = ""/hdfs1/subpath"";
    config.setStrings(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY, exportPoint);
    config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY,
        FsConstants.VIEWFS_SCHEME + ""://"" + clusterName);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster =
          new MiniDFSCluster.Builder(config).nnTopology(
              MiniDFSNNTopology.simpleFederatedTopology(2))
              .numDataNodes(2)
              .build();
      cluster.waitActive();
      DistributedFileSystem hdfs1 = cluster.getFileSystem(0);
      DistributedFileSystem hdfs2 = cluster.getFileSystem(1);
      cluster.waitActive();
      Path base1 = new Path(""/user1"");
      Path base2 = new Path(""/user2"");
      hdfs1.delete(base1, true);
      hdfs2.delete(base2, true);
      hdfs1.mkdirs(base1);
      hdfs2.mkdirs(base2);
      ConfigUtil.addLink(config, clusterName, ""/hdfs1"",
          hdfs1.makeQualified(base1).toUri());
      ConfigUtil.addLink(config, clusterName, ""/hdfs2"",
          hdfs2.makeQualified(base2).toUri());
      Path subPath = new Path(base1, ""subpath"");
      hdfs1.delete(subPath, true);
      hdfs1.mkdirs(subPath);

      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);

      Mountd mountd = nfsServer.getMountd();
      RpcProgramMountd rpcMount = (RpcProgramMountd) mountd.getRpcProgram();
      assertTrue(rpcMount.getExports().size() == 1);

      String exportInMountd = rpcMount.getExports().get(0);
      assertTrue(exportInMountd.equals(exportPoint));
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
"
"  @Test
  public void testViewFsRootExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    String clusterName = RandomStringUtils.randomAlphabetic(10);

    String exportPoint = ""/"";
    config.setStrings(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY, exportPoint);
    config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY,
        FsConstants.VIEWFS_SCHEME + ""://"" + clusterName);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster =
          new MiniDFSCluster.Builder(config).nnTopology(
              MiniDFSNNTopology.simpleFederatedTopology(2))
              .numDataNodes(2)
              .build();
      cluster.waitActive();
      DistributedFileSystem hdfs1 = cluster.getFileSystem(0);
      DistributedFileSystem hdfs2 = cluster.getFileSystem(1);
      cluster.waitActive();
      Path base1 = new Path(""/user1"");
      Path base2 = new Path(""/user2"");
      hdfs1.delete(base1, true);
      hdfs2.delete(base2, true);
      hdfs1.mkdirs(base1);
      hdfs2.mkdirs(base2);
      ConfigUtil.addLink(config, clusterName, ""/hdfs1"",
          hdfs1.makeQualified(base1).toUri());
      ConfigUtil.addLink(config, clusterName, ""/hdfs2"",
          hdfs2.makeQualified(base2).toUri());

      exception.expect(FileSystemException.class);
      exception.
          expectMessage(""Only HDFS is supported as underlyingFileSystem, ""
              + ""fs scheme:viewfs"");
      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
"
"  @Test
  public void testHdfsInternalExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;

    String exportPoint = ""/myexport1"";
    config.setStrings(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY, exportPoint);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");
    Path base = new Path(exportPoint);

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();
      DistributedFileSystem hdfs = cluster.getFileSystem(0);
      hdfs.delete(base, true);
      hdfs.mkdirs(base);

      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);

      Mountd mountd = nfsServer.getMountd();
      RpcProgramMountd rpcMount = (RpcProgramMountd) mountd.getRpcProgram();
      assertTrue(rpcMount.getExports().size() == 1);

      String exportInMountd = rpcMount.getExports().get(0);
      assertTrue(exportInMountd.equals(exportPoint));

    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
"
"  @Test
  public void testInvalidFsExport() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;

    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();
      config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY,
          FsConstants.LOCAL_FS_URI.toString());

      exception.expect(FileSystemException.class);
      exception.
          expectMessage(""Only HDFS is supported as underlyingFileSystem, ""
              + ""fs scheme:file"");
      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
"
"  @Test
  public void testStart() throws IOException {
    // Start minicluster
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(config).numDataNodes(1)
        .build();
    cluster.waitActive();
    
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    
    int newTimeoutMillis = 1000; // 1s
    // Set the new portmap rpc timeout values and check
    config.setInt(NfsConfigKeys.NFS_UDP_CLIENT_PORTMAP_TIMEOUT_MILLIS_KEY,
                  newTimeoutMillis);
    assertTrue(config.getInt(
                      NfsConfigKeys.NFS_UDP_CLIENT_PORTMAP_TIMEOUT_MILLIS_KEY,
          0) == newTimeoutMillis);

    // Start nfs
    Nfs3 nfs3 = new Nfs3(config);
    nfs3.startServiceInternal(false);

    RpcProgramMountd mountd = (RpcProgramMountd) nfs3.getMountd()
        .getRpcProgram();
    mountd.nullOp(new XDR(), 1234, InetAddress.getByName(""localhost""));
    assertTrue(mountd.getPortmapUdpTimeoutMillis() == newTimeoutMillis);
    RpcProgramNfs3 nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();
    nfsd.nullProcedure();
    assertTrue(nfsd.getPortmapUdpTimeoutMillis() == newTimeoutMillis);
    
    cluster.shutdown();
  }
"
"  @Test
  public void testContains() throws Exception {
    DatanodeDescriptor nodeNotInMap = 
      DFSTestUtil.getDatanodeDescriptor(""8.8.8.8"", ""/d2/r4"");
    for (int i=0; i < dataNodes.length; i++) {
      assertTrue(cluster.contains(dataNodes[i]));
    }
    assertFalse(cluster.contains(nodeNotInMap));
  }
"
"  @Test
  public void testNumOfChildren() throws Exception {
    assertEquals(cluster.getNumOfLeaves(), dataNodes.length);
  }
"
"  @Test
  public void testCreateInvalidTopology() throws Exception {
    NetworkTopology invalCluster =
        NetworkTopology.getInstance(new Configuration());
    DatanodeDescriptor invalDataNodes[] = new DatanodeDescriptor[] {
        DFSTestUtil.getDatanodeDescriptor(""1.1.1.1"", ""/d1/r1""),
        DFSTestUtil.getDatanodeDescriptor(""2.2.2.2"", ""/d1/r1""),
        DFSTestUtil.getDatanodeDescriptor(""3.3.3.3"", ""/d1"")
    };
    invalCluster.add(invalDataNodes[0]);
    invalCluster.add(invalDataNodes[1]);
    try {
      invalCluster.add(invalDataNodes[2]);
      fail(""expected InvalidTopologyException"");
    } catch (NetworkTopology.InvalidTopologyException e) {
      assertTrue(e.getMessage().startsWith(""Failed to add ""));
      assertTrue(e.getMessage().contains(
          ""You cannot have a rack and a non-rack node at the same "" +
          ""level of the network topology.""));
    }
  }
"
"  @Test
  public void testRacks() throws Exception {
    assertEquals(cluster.getNumOfRacks(), 6);
    assertTrue(cluster.isOnSameRack(dataNodes[0], dataNodes[1]));
    assertFalse(cluster.isOnSameRack(dataNodes[1], dataNodes[2]));
    assertTrue(cluster.isOnSameRack(dataNodes[2], dataNodes[3]));
    assertTrue(cluster.isOnSameRack(dataNodes[3], dataNodes[4]));
    assertFalse(cluster.isOnSameRack(dataNodes[4], dataNodes[5]));
    assertTrue(cluster.isOnSameRack(dataNodes[5], dataNodes[6]));
  }
"
"  @Test
  public void testGetDistance() throws Exception {
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[0]), 0);
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[1]), 2);
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[3]), 4);
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[6]), 6);
    // verify the distance is zero as long as two nodes have the same path.
    // They don't need to refer to the same object.
    NodeBase node1 = new NodeBase(dataNodes[0].getHostName(),
        dataNodes[0].getNetworkLocation());
    NodeBase node2 = new NodeBase(dataNodes[0].getHostName(),
        dataNodes[0].getNetworkLocation());
    assertEquals(0, cluster.getDistance(node1, node2));
    // verify the distance can be computed by path.
    // They don't need to refer to the same object or parents.
    NodeBase node3 = new NodeBase(dataNodes[3].getHostName(),
        dataNodes[3].getNetworkLocation());
    NodeBase node4 = new NodeBase(dataNodes[6].getHostName(),
        dataNodes[6].getNetworkLocation());
    assertEquals(0, NetworkTopology.getDistanceByPath(node1, node2));
    assertEquals(4, NetworkTopology.getDistanceByPath(node2, node3));
    assertEquals(6, NetworkTopology.getDistanceByPath(node2, node4));
  }
"
"  @Test
  public void testSortByDistance() throws Exception {
    DatanodeDescriptor[] testNodes = new DatanodeDescriptor[3];
    
    // array contains both local node & local rack node
    testNodes[0] = dataNodes[1];
    testNodes[1] = dataNodes[2];
    testNodes[2] = dataNodes[0];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[0]);
    assertTrue(testNodes[1] == dataNodes[1]);
    assertTrue(testNodes[2] == dataNodes[2]);

    // array contains both local node & local rack node & decommissioned node
    DatanodeDescriptor[] dtestNodes = new DatanodeDescriptor[5];
    dtestNodes[0] = dataNodes[8];
    dtestNodes[1] = dataNodes[12];
    dtestNodes[2] = dataNodes[11];
    dtestNodes[3] = dataNodes[9];
    dtestNodes[4] = dataNodes[10];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[8], dtestNodes, dtestNodes.length - 2);
    assertTrue(dtestNodes[0] == dataNodes[8]);
    assertTrue(dtestNodes[1] == dataNodes[11]);
    assertTrue(dtestNodes[2] == dataNodes[12]);
    assertTrue(dtestNodes[3] == dataNodes[9]);
    assertTrue(dtestNodes[4] == dataNodes[10]);

    // array contains local node
    testNodes[0] = dataNodes[1];
    testNodes[1] = dataNodes[3];
    testNodes[2] = dataNodes[0];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[0]);
    assertTrue(testNodes[1] == dataNodes[1]);
    assertTrue(testNodes[2] == dataNodes[3]);

    // array contains local rack node
    testNodes[0] = dataNodes[5];
    testNodes[1] = dataNodes[3];
    testNodes[2] = dataNodes[1];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[1]);
    assertTrue(testNodes[1] == dataNodes[3]);
    assertTrue(testNodes[2] == dataNodes[5]);

    // array contains local rack node which happens to be in position 0
    testNodes[0] = dataNodes[1];
    testNodes[1] = dataNodes[5];
    testNodes[2] = dataNodes[3];
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[1]);
    assertTrue(testNodes[1] == dataNodes[3]);
    assertTrue(testNodes[2] == dataNodes[5]);

    // Same as previous, but with a different random seed to test randomization
    testNodes[0] = dataNodes[1];
    testNodes[1] = dataNodes[5];
    testNodes[2] = dataNodes[3];
    cluster.setRandomSeed(0xDEAD);
    cluster.sortByDistance(dataNodes[0], testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[1]);
    assertTrue(testNodes[1] == dataNodes[3]);
    assertTrue(testNodes[2] == dataNodes[5]);

    // Array of just rack-local nodes
    // Expect a random first node
    DatanodeDescriptor first = null;
    boolean foundRandom = false;
    for (int i=5; i<=7; i++) {
      testNodes[0] = dataNodes[5];
      testNodes[1] = dataNodes[6];
      testNodes[2] = dataNodes[7];
      cluster.sortByDistance(dataNodes[i], testNodes, testNodes.length);
      if (first == null) {
        first = testNodes[0];
      } else {
        if (first != testNodes[0]) {
          foundRandom = true;
          break;
        }
      }
    }
    assertTrue(""Expected to find a different first location"", foundRandom);

    // Array of just remote nodes
    // Expect random first node
    first = null;
    for (int i = 1; i <= 4; i++) {
      testNodes[0] = dataNodes[13];
      testNodes[1] = dataNodes[14];
      testNodes[2] = dataNodes[15];
      cluster.sortByDistance(dataNodes[i], testNodes, testNodes.length);
      if (first == null) {
        first = testNodes[0];
      } else {
        if (first != testNodes[0]) {
          foundRandom = true;
          break;
        }
      }
    }
    assertTrue(""Expected to find a different first location"", foundRandom);

    //Reader is not a datanode, but is in one of the datanode's rack.
    testNodes[0] = dataNodes[0];
    testNodes[1] = dataNodes[5];
    testNodes[2] = dataNodes[8];
    Node rackClient = new NodeBase(""/d3/r1/25.25.25"");
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(rackClient, testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[8]);
    assertTrue(testNodes[1] == dataNodes[5]);
    assertTrue(testNodes[2] == dataNodes[0]);

    //Reader is not a datanode , but is in one of the datanode's data center.
    testNodes[0] = dataNodes[8];
    testNodes[1] = dataNodes[5];
    testNodes[2] = dataNodes[0];
    Node dcClient = new NodeBase(""/d1/r2/25.25.25"");
    cluster.setRandomSeed(0xDEADBEEF);
    cluster.sortByDistance(dcClient, testNodes, testNodes.length);
    assertTrue(testNodes[0] == dataNodes[0]);
    assertTrue(testNodes[1] == dataNodes[5]);
    assertTrue(testNodes[2] == dataNodes[8]);

  }
"
"  @Test
  public void testRemove() throws Exception {
    for(int i=0; i<dataNodes.length; i++) {
      cluster.remove(dataNodes[i]);
    }
    for(int i=0; i<dataNodes.length; i++) {
      assertFalse(cluster.contains(dataNodes[i]));
    }
    assertEquals(0, cluster.getNumOfLeaves());
    assertEquals(0, cluster.clusterMap.getChildren().size());
    for(int i=0; i<dataNodes.length; i++) {
      cluster.add(dataNodes[i]);
    }
  }
"
"  @Test
  public void testChooseRandomExcludedNode() {
    String scope = ""~"" + NodeBase.getPath(dataNodes[0]);
    Map<Node, Integer> frequency = pickNodesAtRandom(100, scope, null);

    for (Node key : dataNodes) {
      // all nodes except the first should be more than zero
      assertTrue(frequency.get(key) > 0 || key == dataNodes[0]);
    }
  }
"
"  @Test
  public void testChooseRandomExcludedRack() {
    Map<Node, Integer> frequency = pickNodesAtRandom(100, ""~"" + ""/d2"", null);
    // all the nodes on the second rack should be zero
    for (int j = 0; j < dataNodes.length; j++) {
      int freq = frequency.get(dataNodes[j]);
      if (dataNodes[j].getNetworkLocation().startsWith(""/d2"")) {
        assertEquals(0, freq);
      } else {
        assertTrue(freq > 0);
      }
    }
  }
"
"  @Test
  public void testChooseRandomExcludedNodeList() {
    String scope = ""~"" + NodeBase.getPath(dataNodes[0]);
    Set<Node> excludedNodes = new HashSet<>();
    excludedNodes.add(dataNodes[3]);
    excludedNodes.add(dataNodes[5]);
    excludedNodes.add(dataNodes[7]);
    excludedNodes.add(dataNodes[9]);
    excludedNodes.add(dataNodes[13]);
    excludedNodes.add(dataNodes[18]);
    Map<Node, Integer> frequency = pickNodesAtRandom(100, scope, excludedNodes);

    assertEquals(""dn[3] should be excluded"", 0,
        frequency.get(dataNodes[3]).intValue());
    assertEquals(""dn[5] should be exclude18d"", 0,
        frequency.get(dataNodes[5]).intValue());
    assertEquals(""dn[7] should be excluded"", 0,
        frequency.get(dataNodes[7]).intValue());
    assertEquals(""dn[9] should be excluded"", 0,
        frequency.get(dataNodes[9]).intValue());
    assertEquals(""dn[13] should be excluded"", 0,
        frequency.get(dataNodes[13]).intValue());
    assertEquals(""dn[18] should be excluded"", 0,
        frequency.get(dataNodes[18]).intValue());
    for (Node key : dataNodes) {
      if (excludedNodes.contains(key)) {
        continue;
      }
      // all nodes except the first should be more than zero
      assertTrue(frequency.get(key) > 0 || key == dataNodes[0]);
    }
  }
"
"  @Test
  public void testChooseRandomExcludeAllNodes() {
    String scope = ""~"" + NodeBase.getPath(dataNodes[0]);
    Set<Node> excludedNodes = new HashSet<>();
    for (int i = 0; i < dataNodes.length; i++) {
      excludedNodes.add(dataNodes[i]);
    }
    Map<Node, Integer> frequency = pickNodesAtRandom(100, scope, excludedNodes);
    for (Node key : dataNodes) {
      // all nodes except the first should be more than zero
      assertTrue(frequency.get(key) == 0);
    }
  }
"
"  @Test(timeout=180000)
  public void testInvalidNetworkTopologiesNotCachedInHdfs() throws Exception {
    // start a cluster
    Configuration conf = new HdfsConfiguration();
    MiniDFSCluster cluster = null;
    try {
      // bad rack topology
      String racks[] = { ""/a/b"", ""/c"" };
      String hosts[] = { ""foo1.example.com"", ""foo2.example.com"" };
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).
          racks(racks).hosts(hosts).build();
      cluster.waitActive();
      
      NamenodeProtocols nn = cluster.getNameNodeRpc();
      Assert.assertNotNull(nn);
      
      // Wait for one DataNode to register.
      // The other DataNode will not be able to register up because of the rack mismatch.
      DatanodeInfo[] info;
      while (true) {
        info = nn.getDatanodeReport(DatanodeReportType.LIVE);
        Assert.assertFalse(info.length == 2);
        if (info.length == 1) {
          break;
        }
        Thread.sleep(1000);
      }
      // Set the network topology of the other node to the match the network
      // topology of the node that came up.
      int validIdx = info[0].getHostName().equals(hosts[0]) ? 0 : 1;
      int invalidIdx = validIdx == 1 ? 0 : 1;
      StaticMapping.addNodeToRack(hosts[invalidIdx], racks[validIdx]);
      LOG.info(""datanode "" + validIdx + "" came up with network location "" + 
        info[0].getNetworkLocation());

      // Restart the DN with the invalid topology and wait for it to register.
      cluster.restartDataNode(invalidIdx);
      Thread.sleep(5000);
      while (true) {
        info = nn.getDatanodeReport(DatanodeReportType.LIVE);
        if (info.length == 2) {
          break;
        }
        if (info.length == 0) {
          LOG.info(""got no valid DNs"");
        } else if (info.length == 1) {
          LOG.info(""got one valid DN: "" + info[0].getHostName() +
              "" (at "" + info[0].getNetworkLocation() + "")"");
        }
        Thread.sleep(1000);
      }
      Assert.assertEquals(info[0].getNetworkLocation(),
                          info[1].getNetworkLocation());
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
"
"  @Test
  public void testBackwardCompatibility() {
    // Test 1 - old configuration key with decimal 
    // umask value should be handled when set using 
    // FSPermission.setUMask() API
    FsPermission perm = new FsPermission((short)18);
    Configuration conf = new Configuration();
    FsPermission.setUMask(conf, perm);
    assertEquals(18, FsPermission.getUMask(conf).toShort());

    // Test 2 - new configuration key is handled
    conf = new Configuration();
    conf.set(FsPermission.UMASK_LABEL, ""022"");
    assertEquals(18, FsPermission.getUMask(conf).toShort());

    // Test 3 - equivalent valid umask
    conf = new Configuration();
    conf.set(FsPermission.UMASK_LABEL, ""0022"");
    assertEquals(18, FsPermission.getUMask(conf).toShort());

    // Test 4 - invalid umask
    conf = new Configuration();
    conf.set(FsPermission.UMASK_LABEL, ""1222"");
    try {
      FsPermission.getUMask(conf);
      fail(""expect IllegalArgumentException happen"");
    } catch (IllegalArgumentException e) {
     //pass, exception successfully trigger
    }

    // Test 5 - invalid umask
    conf = new Configuration();
    conf.set(FsPermission.UMASK_LABEL, ""01222"");
    try {
      FsPermission.getUMask(conf);
      fail(""expect IllegalArgumentException happen"");
    } catch (IllegalArgumentException e) {
     //pass, exception successfully trigger
    }
  }
"
"  @Test
  public void testCreate() throws Exception {
    Configuration conf = new HdfsConfiguration();
    conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, true);
    conf.set(FsPermission.UMASK_LABEL, ""000"");
    MiniDFSCluster cluster = null;
    FileSystem fs = null;

    try {
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
      cluster.waitActive();
      fs = FileSystem.get(conf);
      FsPermission rootPerm = checkPermission(fs, ""/"", null);
      FsPermission inheritPerm = FsPermission.createImmutable(
          (short)(rootPerm.toShort() | 0300));

      FsPermission dirPerm = new FsPermission((short)0777);
      fs.mkdirs(new Path(""/a1/a2/a3""), dirPerm);
      checkPermission(fs, ""/a1"", dirPerm);
      checkPermission(fs, ""/a1/a2"", dirPerm);
      checkPermission(fs, ""/a1/a2/a3"", dirPerm);

      dirPerm = new FsPermission((short)0123);
      FsPermission permission = FsPermission.createImmutable(
        (short)(dirPerm.toShort() | 0300));
      fs.mkdirs(new Path(""/aa/1/aa/2/aa/3""), dirPerm);
      checkPermission(fs, ""/aa/1"", permission);
      checkPermission(fs, ""/aa/1/aa/2"", permission);
      checkPermission(fs, ""/aa/1/aa/2/aa/3"", dirPerm);

      FsPermission filePerm = new FsPermission((short)0444);
      Path p = new Path(""/b1/b2/b3.txt"");
      FSDataOutputStream out = fs.create(p, filePerm,
          true, conf.getInt(CommonConfigurationKeys.IO_FILE_BUFFER_SIZE_KEY, 4096),
          fs.getDefaultReplication(p), fs.getDefaultBlockSize(p), null);
      out.write(123);
      out.close();
      checkPermission(fs, ""/b1"", inheritPerm);
      checkPermission(fs, ""/b1/b2"", inheritPerm);
      checkPermission(fs, ""/b1/b2/b3.txt"", filePerm);
      
      conf.set(FsPermission.UMASK_LABEL, ""022"");
      permission = 
        FsPermission.createImmutable((short)0666);
      FileSystem.mkdirs(fs, new Path(""/c1""), new FsPermission(permission));
      FileSystem.create(fs, new Path(""/c1/c2.txt""),
          new FsPermission(permission));
      checkPermission(fs, ""/c1"", permission);
      checkPermission(fs, ""/c1/c2.txt"", permission);
    } finally {
      try {
        if(fs != null) fs.close();
      } catch(Exception e) {
        LOG.error(StringUtils.stringifyException(e));
      }
      try {
        if(cluster != null) cluster.shutdown();
      } catch(Exception e) {
        LOG.error(StringUtils.stringifyException(e));
      }
    }
  }
"
"  @Test
  public void testFilePermission() throws Exception {
    final Configuration conf = new HdfsConfiguration();
    conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, true);
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
    cluster.waitActive();

    try {
      nnfs = FileSystem.get(conf);
      // test permissions on files that do not exist
      assertFalse(nnfs.exists(CHILD_FILE1));
      try {
        nnfs.setPermission(CHILD_FILE1, new FsPermission((short)0777));
        assertTrue(false);
      }
      catch(java.io.FileNotFoundException e) {
        LOG.info(""GOOD: got "" + e);
      }
      
      // make sure nn can take user specified permission (with default fs
      // permission umask applied)
      FSDataOutputStream out = nnfs.create(CHILD_FILE1, new FsPermission(
          (short) 0777), true, 1024, (short) 1, 1024, null);
      FileStatus status = nnfs.getFileStatus(CHILD_FILE1);
      // FS_PERMISSIONS_UMASK_DEFAULT is 0022
      assertTrue(status.getPermission().toString().equals(""rwxr-xr-x""));
      nnfs.delete(CHILD_FILE1, false);
      
      // following dir/file creations are legal
      nnfs.mkdirs(CHILD_DIR1);
      status = nnfs.getFileStatus(CHILD_DIR1);
      assertThat(""Expect 755 = 777 (default dir) - 022 (default umask)"",
          status.getPermission().toString(), is(""rwxr-xr-x""));
      out = nnfs.create(CHILD_FILE1);
      status = nnfs.getFileStatus(CHILD_FILE1);
      assertTrue(status.getPermission().toString().equals(""rw-r--r--""));
      byte data[] = new byte[FILE_LEN];
      RAN.nextBytes(data);
      out.write(data);
      out.close();
      nnfs.setPermission(CHILD_FILE1, new FsPermission(""700""));
      status = nnfs.getFileStatus(CHILD_FILE1);
      assertTrue(status.getPermission().toString().equals(""rwx------""));

      // mkdirs with null permission
      nnfs.mkdirs(CHILD_DIR3, null);
      status = nnfs.getFileStatus(CHILD_DIR3);
      assertThat(""Expect 755 = 777 (default dir) - 022 (default umask)"",
          status.getPermission().toString(), is(""rwxr-xr-x""));

      // following read is legal
      byte dataIn[] = new byte[FILE_LEN];
      FSDataInputStream fin = nnfs.open(CHILD_FILE1);
      int bytesRead = fin.read(dataIn);
      assertTrue(bytesRead == FILE_LEN);
      for(int i=0; i<FILE_LEN; i++) {
        assertEquals(data[i], dataIn[i]);
      }

      // test execution bit support for files
      nnfs.setPermission(CHILD_FILE1, new FsPermission(""755""));
      status = nnfs.getFileStatus(CHILD_FILE1);
      assertTrue(status.getPermission().toString().equals(""rwxr-xr-x""));
      nnfs.setPermission(CHILD_FILE1, new FsPermission(""744""));
      status = nnfs.getFileStatus(CHILD_FILE1);
      assertTrue(status.getPermission().toString().equals(""rwxr--r--""));
      nnfs.setPermission(CHILD_FILE1, new FsPermission(""700""));
      
      ////////////////////////////////////////////////////////////////
      // test illegal file/dir creation
      UserGroupInformation userGroupInfo = 
        UserGroupInformation.createUserForTesting(USER_NAME, GROUP_NAMES );
      
      userfs = DFSTestUtil.getFileSystemAs(userGroupInfo, conf);

      // make sure mkdir of a existing directory that is not owned by 
      // this user does not throw an exception.
      userfs.mkdirs(CHILD_DIR1);
      
      // illegal mkdir
      assertTrue(!canMkdirs(userfs, CHILD_DIR2));

      // illegal file creation
      assertTrue(!canCreate(userfs, CHILD_FILE2));

      // illegal file open
      assertTrue(!canOpen(userfs, CHILD_FILE1));

      nnfs.setPermission(ROOT_PATH, new FsPermission((short)0755));
      nnfs.setPermission(CHILD_DIR1, new FsPermission(""777""));
      nnfs.setPermission(new Path(""/""), new FsPermission((short)0777));
      final Path RENAME_PATH = new Path(""/foo/bar"");
      userfs.mkdirs(RENAME_PATH);
      assertTrue(canRename(userfs, RENAME_PATH, CHILD_DIR1));
      // test permissions on files that do not exist
      assertFalse(userfs.exists(CHILD_FILE3));
      try {
        userfs.setPermission(CHILD_FILE3, new FsPermission((short) 0777));
        fail(""setPermission should fail for non-exist file"");
      } catch (java.io.FileNotFoundException ignored) {
      }

      // Make sure any user can create file in root.
      nnfs.setPermission(ROOT_PATH, new FsPermission(""777""));

      testSuperCanChangeOwnerGroup();
      testNonSuperCanChangeToOwnGroup();
      testNonSuperCannotChangeToOtherGroup();
      testNonSuperCannotChangeGroupForOtherFile();
      testNonSuperCannotChangeGroupForNonExistentFile();
      testNonSuperCannotChangeOwner();
      testNonSuperCannotChangeOwnerForOtherFile();
      testNonSuperCannotChangeOwnerForNonExistentFile();
    } finally {
      cluster.shutdown();
    }
  }
"
"  @Test(timeout = 5000)
  public void testDelete() throws Exception {
    fs.setPermission(linkParent, new FsPermission((short) 0555));
    doDeleteLinkParentNotWritable();

    fs.setPermission(linkParent, new FsPermission((short) 0777));
    fs.setPermission(targetParent, new FsPermission((short) 0555));
    fs.setPermission(target, new FsPermission((short) 0555));
    doDeleteTargetParentAndTargetNotWritable();
  }
"
"  @Test
  public void testAclDelete() throws Exception {
    fs.setAcl(linkParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doDeleteLinkParentNotWritable();

    fs.setAcl(linkParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    fs.setAcl(targetParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doDeleteTargetParentAndTargetNotWritable();
  }
"
"  @Test(timeout = 5000)
  public void testReadWhenTargetNotReadable() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0000));
    doReadTargetNotReadable();
  }
"
"  @Test
  public void testAclReadTargetNotReadable() throws Exception {
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, READ_WRITE),
      aclEntry(ACCESS, USER, user.getUserName(), NONE),
      aclEntry(ACCESS, GROUP, READ),
      aclEntry(ACCESS, OTHER, READ)));
    doReadTargetNotReadable();
  }
"
"  @Test(timeout = 5000)
  public void testFileStatus() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0000));
    doGetFileLinkStatusTargetNotReadable();
  }
"
"  @Test
  public void testAclGetFileLinkStatusTargetNotReadable() throws Exception {
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, READ_WRITE),
      aclEntry(ACCESS, USER, user.getUserName(), NONE),
      aclEntry(ACCESS, GROUP, READ),
      aclEntry(ACCESS, OTHER, READ)));
    doGetFileLinkStatusTargetNotReadable();
  }
"
"  @Test(timeout = 5000)
  public void testRenameLinkTargetNotWritableFC() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0555));
    fs.setPermission(targetParent, new FsPermission((short) 0555));
    doRenameLinkTargetNotWritableFC();
  }
"
"  @Test
  public void testAclRenameTargetNotWritableFC() throws Exception {
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    fs.setAcl(targetParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doRenameLinkTargetNotWritableFC();
  }
"
"  @Test(timeout = 5000)
  public void testRenameSrcNotWritableFC() throws Exception {
    fs.setPermission(linkParent, new FsPermission((short) 0555));
    doRenameSrcNotWritableFC();
  }
"
"  @Test
  public void testAclRenameSrcNotWritableFC() throws Exception {
    fs.setAcl(linkParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doRenameSrcNotWritableFC();
  }
"
"  @Test(timeout = 5000)
  public void testRenameLinkTargetNotWritableFS() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0555));
    fs.setPermission(targetParent, new FsPermission((short) 0555));
    doRenameLinkTargetNotWritableFS();
  }
"
"  @Test
  public void testAclRenameTargetNotWritableFS() throws Exception {
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    fs.setAcl(targetParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doRenameLinkTargetNotWritableFS();
  }
"
"  @Test(timeout = 5000)
  public void testRenameSrcNotWritableFS() throws Exception {
    fs.setPermission(linkParent, new FsPermission((short) 0555));
    doRenameSrcNotWritableFS();
  }
"
"  @Test
  public void testAclRenameSrcNotWritableFS() throws Exception {
    fs.setAcl(linkParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doRenameSrcNotWritableFS();
  }
"
"  @Test
  public void testAccess() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0002));
    fs.setAcl(target, Arrays.asList(
        aclEntry(ACCESS, USER, ALL),
        aclEntry(ACCESS, GROUP, NONE),
        aclEntry(ACCESS, USER, user.getShortUserName(), WRITE),
        aclEntry(ACCESS, OTHER, WRITE)));
    FileContext myfc = user.doAs(new PrivilegedExceptionAction<FileContext>() {
      @Override
      public FileContext run() throws IOException {
        return FileContext.getFileContext(conf);
      }
"
"  @Test
  public void testGroupMappingRefresh() throws Exception {
    DFSAdmin admin = new DFSAdmin(config);
    String [] args =  new String[]{""-refreshUserToGroupsMappings""};
    Groups groups = Groups.getUserToGroupsMappingService(config);
    String user = UserGroupInformation.getCurrentUser().getUserName();
    System.out.println(""first attempt:"");
    List<String> g1 = groups.getGroups(user);
    String [] str_groups = new String [g1.size()];
    g1.toArray(str_groups);
    System.out.println(Arrays.toString(str_groups));
    
    System.out.println(""second attempt, should be same:"");
    List<String> g2 = groups.getGroups(user);
    g2.toArray(str_groups);
    System.out.println(Arrays.toString(str_groups));
    for(int i=0; i<g2.size(); i++) {
      assertEquals(""Should be same group "", g1.get(i), g2.get(i));
    }
    admin.run(args);
    System.out.println(""third attempt(after refresh command), should be different:"");
    List<String> g3 = groups.getGroups(user);
    g3.toArray(str_groups);
    System.out.println(Arrays.toString(str_groups));
    for(int i=0; i<g3.size(); i++) {
      assertFalse(""Should be different group: "" + g1.get(i) + "" and "" + g3.get(i), 
          g1.get(i).equals(g3.get(i)));
    }
    
    // test time out
    Thread.sleep(groupRefreshTimeoutSec*1100);
    System.out.println(""fourth attempt(after timeout), should be different:"");
    List<String> g4 = groups.getGroups(user);
    g4.toArray(str_groups);
    System.out.println(Arrays.toString(str_groups));
    for(int i=0; i<g4.size(); i++) {
      assertFalse(""Should be different group "", g3.get(i).equals(g4.get(i)));
    }
  }
"
"  @Test
  public void testRefreshSuperUserGroupsConfiguration() throws Exception {
    final String SUPER_USER = ""super_user"";
    final List<String> groupNames1 = new ArrayList<>();
    groupNames1.add(""gr1"");
    groupNames1.add(""gr2"");
    final List<String> groupNames2 = new ArrayList<>();
    groupNames2.add(""gr3"");
    groupNames2.add(""gr4"");

    //keys in conf
    String userKeyGroups = DefaultImpersonationProvider.getTestProvider().
        getProxySuperuserGroupConfKey(SUPER_USER);
    String userKeyHosts = DefaultImpersonationProvider.getTestProvider().
        getProxySuperuserIpConfKey (SUPER_USER);
    
    config.set(userKeyGroups, ""gr3,gr4,gr5""); // superuser can proxy for this group
    config.set(userKeyHosts,""127.0.0.1"");
    ProxyUsers.refreshSuperUserGroupsConfiguration(config);
    
    UserGroupInformation ugi1 = mock(UserGroupInformation.class);
    UserGroupInformation ugi2 = mock(UserGroupInformation.class);
    UserGroupInformation suUgi = mock(UserGroupInformation.class);
    when(ugi1.getRealUser()).thenReturn(suUgi);
    when(ugi2.getRealUser()).thenReturn(suUgi);

    when(suUgi.getShortUserName()).thenReturn(SUPER_USER); // super user
    when(suUgi.getUserName()).thenReturn(SUPER_USER+""L""); // super user
     
    when(ugi1.getShortUserName()).thenReturn(""user1"");
    when(ugi2.getShortUserName()).thenReturn(""user2"");
    
    when(ugi1.getUserName()).thenReturn(""userL1"");
    when(ugi2.getUserName()).thenReturn(""userL2"");

    // set groups for users
    when(ugi1.getGroups()).thenReturn(groupNames1);
    when(ugi2.getGroups()).thenReturn(groupNames2);


    // check before
    try {
      ProxyUsers.authorize(ugi1, ""127.0.0.1"");
      fail(""first auth for "" + ugi1.getShortUserName() + "" should've failed "");
    } catch (AuthorizationException e) {
      // expected
      System.err.println(""auth for "" + ugi1.getUserName() + "" failed"");
    }
    try {
      ProxyUsers.authorize(ugi2, ""127.0.0.1"");
      System.err.println(""auth for "" + ugi2.getUserName() + "" succeeded"");
      // expected
    } catch (AuthorizationException e) {
      fail(""first auth for "" + ugi2.getShortUserName() + "" should've succeeded: "" + e.getLocalizedMessage());
    }
    
    // refresh will look at configuration on the server side
    // add additional resource with the new value
    // so the server side will pick it up
    String rsrc = ""testGroupMappingRefresh_rsrc.xml"";
    addNewConfigResource(rsrc, userKeyGroups, ""gr2"", userKeyHosts, ""127.0.0.1"");  
    
    DFSAdmin admin = new DFSAdmin(config);
    String [] args = new String[]{""-refreshSuperUserGroupsConfiguration""};
    admin.run(args);
    
    try {
      ProxyUsers.authorize(ugi2, ""127.0.0.1"");
      fail(""second auth for "" + ugi2.getShortUserName() + "" should've failed "");
    } catch (AuthorizationException e) {
      // expected
      System.err.println(""auth for "" + ugi2.getUserName() + "" failed"");
    }
    try {
      ProxyUsers.authorize(ugi1, ""127.0.0.1"");
      System.err.println(""auth for "" + ugi1.getUserName() + "" succeeded"");
      // expected
    } catch (AuthorizationException e) {
      fail(""second auth for "" + ugi1.getShortUserName() + "" should've succeeded: "" + e.getLocalizedMessage());
    }
    
    
  }
"
"  @Test
  public void testMkdirWithExistingDirClear() throws IOException {
    testMkdirWithExistingDir(BLANK_TEST_UMASK, BLANK_PERMISSIONS);
  }
"
"  @Test
  public void testMkdirWithExistingDirOpen() throws IOException {
    testMkdirWithExistingDir(WIDE_OPEN_TEST_UMASK, WIDE_OPEN_PERMISSIONS);
  }
"
"  @Test
  public void testMkdirWithExistingDirMiddle() throws IOException {
    testMkdirWithExistingDir(USER_GROUP_OPEN_TEST_UMASK,
        USER_GROUP_OPEN_PERMISSIONS);
  }
"
"  @Test
  public void testMkdirRecursiveWithNonExistingDirClear() throws IOException {
    // by default parent directories have -wx------ bits set
    testMkdirRecursiveWithNonExistingDir(BLANK_TEST_UMASK, BLANK_PERMISSIONS, 
        PARENT_PERMS_FOR_BLANK_PERMISSIONS);
  }
"
"	@Test public void testQualifiedNameConverter() throws Exception {
			public String getDelimiter() {
				return ""!"";
			}
"
"	@Test public void testQualifiedNameConverter_emptyDelimiter() throws Exception {
			public String getDelimiter() {
				return """";
			}
"
"	@Test public void testQualifiedNameConverter_nullDelimiter() throws Exception {
			public String getDelimiter() {
				return null;
			}
"
"	@Test public void testCreateNull() {
	public void testAppendNull() {
		try {
			QualifiedName.create().append((String) null);
			fail(""Exception expected"");
		} catch (IllegalArgumentException e) {}
	}
"
"	@Test public void testWrapper() throws Exception {
			public String apply(String from) {
				return from;
			}
"
"	@Test public void testInstanceBinding() throws Exception {
			public Date bindDate() {
				return date;
			}
"
"	@Test public void testProviderClassDeactivation() throws Exception {
		public String get() {
			 return ""foo"";
		}
"
"	@Test public void testProviderInstanceBinding() throws Exception {
			public Date get() {
				return null;
			}
"
"	@Test public void testSingletonBinding() throws Exception {
			public Class<Foo> bindFoo() {
				return Foo.class;
			}
"
"	@Test public void testEagerSingletonBinding() throws Exception {
			public Class<Foo> bindFoo() {
				return Foo.class;
			}
"
"	@Test public void testSerialize_02() throws Exception {
	public void _testSerialize_03() throws Exception {
		model.setGenerated(GeneratedEnum.DIFFERENT_NAME);
		String result = serialize(model);
		assertEquals(""generated DifferentLiteral"", result);
	}
"
"	@Test public void testXtextGrammarUoW() throws Exception {
			public Boolean exec(EObject state) throws Exception {
				callCount[0]++;
				return false;
			}
"
"	@Test
	public void testBug322875_01() throws Exception {
		String testGrammar = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'classpath:/org/eclipse/xtext/xtext/XtextValidationTest.ecore'  "" +
				"" import 'http://www.eclipse.org/2008/Xtext' as xtext\n"" +
				""Bug322875 returns Bug322875: referencesETypeFromClasspathPackage=[xtext::Grammar];"";
		XtextResource resource = getResourceFromStringAndExpect(testGrammar,1);
		assertFalse(resource.getErrors().toString(), resource.getErrors().isEmpty());
		assertBug322875(resource);
	}
"
"	@Test
	public void testBug322875_01_b() throws Exception {
		String testGrammar = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'http://www.eclipse.org/2008/Xtext' as xtext\n"" +
				"" import 'classpath:/org/eclipse/xtext/xtext/XtextValidationTest.ecore'  "" +
				""Bug322875 returns Bug322875: referencesETypeFromClasspathPackage=[xtext::Grammar];"";
		XtextResource resource = getResourceFromStringAndExpect(testGrammar,1);
		assertFalse(resource.getErrors().toString(), resource.getErrors().isEmpty());
		assertBug322875(resource);
	}
"
"	@Test
	public void testBug322875_02() throws Exception {
		URIConverter.URI_MAP.put(URI.createURI(""platform:/plugin/org.eclipse.emf.ecore/model/Ecore.ecore""), URI.createURI(getClass().getResource(""/model/Ecore.ecore"").toExternalForm()));
		String testGrammar = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'platform:/plugin/org.eclipse.emf.ecore/model/Ecore.ecore'  "" +
				""Model returns EClass: name=ID;"";
		XtextResource resource = getResourceFromString(testGrammar);
		Diagnostic diag = Diagnostician.INSTANCE.validate(resource.getContents().get(0));
		assertNotNull(""diag"", diag);
		assertEquals(diag.toString(), 0, diag.getChildren().size());
		assertEquals(""diag.isOk"", Diagnostic.OK, diag.getSeverity());
	}
"
"	@Test
	public void testBug322875_04() throws Exception {
		String testGrammarNsURI = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'http://www.eclipse.org/emf/2002/Ecore'  "" +
				""Model returns EClass: name=ID;"";
		String testGrammarPlatformPlugin = ""grammar foo.Bar with org.eclipse.xtext.common.Terminals\n "" +
				"" import 'platform:/plugin/org.eclipse.emf.ecore/model/Ecore.ecore'  "" +
				""Model returns EClass: name=ID;"";
		XtextResource resourceOk = getResourceFromString(testGrammarNsURI);
		XtextResource resourceOk2 = (XtextResource) resourceOk.getResourceSet().createResource(URI.createURI(""unused.xtext""));
		resourceOk2.load(new StringInputStream(testGrammarPlatformPlugin), null);
		Diagnostic diagOK = Diagnostician.INSTANCE.validate(resourceOk.getContents().get(0));
		assertNotNull(""diag"", diagOK);
		assertEquals(diagOK.toString(), 0, diagOK.getChildren().size());
		diagOK = Diagnostician.INSTANCE.validate(resourceOk2.getContents().get(0));
		assertNotNull(""diag"", diagOK);
		assertEquals(diagOK.toString(), 0, diagOK.getChildren().size());
	}
"
"	@Test
	public void testBug_280413_03() throws Exception {
		XtextResource resource = getResourceFromString(
				""grammar org.foo.Bar with org.eclipse.xtext.common.Terminals\n"" +
				""import 'classpath:/org/eclipse/xtext/Xtext.ecore' as xtext\n"" +
				""ParserRule returns xtext::ParserRule: name = ID;"");
		assertTrue(resource.getErrors().toString(), resource.getErrors().isEmpty());
		assertTrue(resource.getWarnings().toString(), resource.getWarnings().isEmpty());

		Diagnostic diag = Diagnostician.INSTANCE.validate(resource.getContents().get(0));
		assertNotNull(""diag"", diag);
		assertEquals(diag.getSeverity(), Diagnostic.OK);
		assertTrue(diag.getChildren().toString(), diag.getChildren().isEmpty());
	}
"
"	@Test public void testNegatedTokenNotEOF_2() throws Exception {
		String grammarAsText =
				""grammar test with org.eclipse.xtext.common.Terminals\n"" +
						""generate test 'http://test'\n"" +
						""A: foo=DUMMY;\n"" +
						""terminal DUMMY: !(EOF | ID);"";
		Grammar grammar = (Grammar) getModel(grammarAsText);
		XtextValidator validator = get(XtextValidator.class);
		ValidatingMessageAcceptor messageAcceptor = new ValidatingMessageAcceptor(null, true, false);
		TerminalRule terminal = (TerminalRule) grammar.getRules().get(1);
		NegatedToken token = (NegatedToken)terminal.getAlternatives();
		messageAcceptor.expectedContext(((Alternatives)token.getTerminal()).getElements().get(0));
		configureValidator(validator, messageAcceptor, token);
		validator.checkNegatedTokenNotEOF(token);
		messageAcceptor.validate();
	}

	public class ValidatingMessageAcceptor extends AbstractValidationMessageAcceptor {

		private final Set<EObject> contexts;
		private boolean error;
		private boolean warning;
		private boolean info;

		public ValidatingMessageAcceptor(EObject context, boolean error, boolean warning) {
			this.contexts = Sets.newHashSet();
			if (context != null)
				contexts.add(context);
			this.error = error;
			this.warning = warning;
		}
		
		public void expectedContext(EObject... contexts) {
			this.contexts.addAll(Arrays.asList(contexts));
		}
"
"	@Test
	public void testSimpeCase01() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		b.addSupertype(a);
		c.addSupertype(a);
		addAttribute(b, INT, ""f1"");
		addAttribute(c, INT, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
	}
"
"	@Test
	public void testSimpeCase02() throws Exception {
		// no uplift for less than two children
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		b.addSupertype(a);
		addAttribute(b, INT, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
	}
"
"	@Test
	public void testRecursiveUplift01() throws Exception {
		// no uplift for less than two children
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		EClassInfo d = addClass(""d"");
		EClassInfo e = addClass(""e"");
		b.addSupertype(a);
		c.addSupertype(a);
		d.addSupertype(c);
		e.addSupertype(c);

		addAttribute(b, INT, ""f1"");
		addAttribute(d, INT, ""f1"");
		addAttribute(e, INT, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
		assertEquals(1, d.getEClass().getEStructuralFeatures().size());
		assertEquals(1, e.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
		assertEquals(0, d.getEClass().getEStructuralFeatures().size());
		assertEquals(0, e.getEClass().getEStructuralFeatures().size());
	}
"
"	@Test
	public void testNikolaus() throws Exception {
		// no uplift for less than two children
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		EClassInfo d = addClass(""d"");
		EClassInfo e = addClass(""e"");
		b.addSupertype(a);
		c.addSupertype(a);
		d.addSupertype(b);
		d.addSupertype(c);
		e.addSupertype(b);
		e.addSupertype(c);

		addAttribute(b, STRING, ""f2"");
		addAttribute(c, STRING, ""f2"");
		addAttribute(d, INT, ""f1"");
		addAttribute(e, INT, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());
		assertEquals(1, d.getEClass().getEStructuralFeatures().size());
		assertEquals(1, e.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
		assertEquals(1, d.getEClass().getEStructuralFeatures().size());
		assertEquals(1, e.getEClass().getEStructuralFeatures().size());
	}
"
"	@Test
	public void testImcompatipleFeatures() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		b.addSupertype(a);
		c.addSupertype(a);
		addAttribute(b, INT, ""f1"");
		addAttribute(c, STRING, ""f1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());
	}
"
"	@Test
	public void testReferences() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		EClassInfo d = addClass(""d"");
		b.addSupertype(a);
		c.addSupertype(a);
		addReference(b, d, ""r1"");
		addReference(c, d, ""r1"");

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
	}
"
"	@Test
	public void testConfigurationOfLiftedReference() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");

		b.addSupertype(a);
		c.addSupertype(a);
		EReference refB = addReference(b, a, ""ref"");
		refB.setContainment(true);
		EReference refC = addReference(c, a, ""ref"");
		refC.setContainment(true);

		assertEquals(0, a.getEClass().getEStructuralFeatures().size());
		assertEquals(1, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		liftUpFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());

		EReference refA = (EReference) a.getEClass().getEStructuralFeatures().get(0);
		assertTrue(refA.isContainment());
	}
"
"	@Test
	public void testDublicateDerivedFeature() throws Exception {
		EClassInfo a = addClass(""a"");
		EClassInfo b = addClass(""b"");
		EClassInfo c = addClass(""c"");
		b.addSupertype(a);
		c.addSupertype(b);
		addAttribute(a, INT, ""f"");
		addAttribute(c, INT, ""f"");

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(1, c.getEClass().getEStructuralFeatures().size());

		initializeHelper();
		helper.removeDuplicateDerivedFeatures();

		assertEquals(1, a.getEClass().getEStructuralFeatures().size());
		assertEquals(0, b.getEClass().getEStructuralFeatures().size());
		assertEquals(0, c.getEClass().getEStructuralFeatures().size());
	}
"
"	@Test public void testContainsCompatibleFeature_01() throws Exception {
	public void testChangeable(){
		EcorePackage pack = EcorePackage.eINSTANCE;
		EClass eClass = pack.getEClass();
		EClassInfo objectUnderTest = new EClassifierInfo.EClassInfo(eClass, false, Collections.<String>emptySet(), null);
		EcoreFactory fac = EcoreFactory.eINSTANCE;
		EReference reference = fac.createEReference();
		reference.setName(""newReference"");
		reference.setEType(eClass);
		reference.setChangeable(true);
		reference.setContainment(true);
		eClass.getEStructuralFeatures().add(reference);
		assertEquals(true,objectUnderTest.containsCompatibleFeature(""newReference"", false, true, eClass, new StringBuilder()));
		reference.setChangeable(false);
		assertEquals(false,objectUnderTest.containsCompatibleFeature(""newReference"", false, true, eClass, new StringBuilder()));
	}
"
"	@Test public void testEditGroupWithCardinality_03() throws Exception {
	public void performTest(String toBeDeleted) throws Exception {
		String grammarAsText = 
			""grammar TestLanguage with org.eclipse.xtext.common.Terminals\n"" +
			""generate test 'myEcoreModel'\n"" +
			""Root: value=Test;\n"" +
			""Test: ("" + toBeDeleted.trim() + "" 'foo')*;"";
		XtextResource resource = getResourceFromString(grammarAsText);
		Grammar g = (Grammar) resource.getContents().get(0);
		ParserRule rule = (ParserRule) g.getRules().get(1);
		assertEquals(""*"", rule.getAlternatives().getCardinality());
		resource.update(grammarAsText.indexOf(toBeDeleted), toBeDeleted.length(), """");
		// make sure we did a partial parse pass
		assertSame(rule, ((Grammar) resource.getContents().get(0)).getRules().get(1));
		assertEquals(""*"", rule.getAlternatives().getCardinality());
	}
"
"	@Test public void testBug285605() throws Exception {
	public void acceptWarning(String message, EObject object, EStructuralFeature feature, int index, String code,
			String... issueData) {
		if (code.equals(OverriddenValueInspector.ISSUE_CODE)) {
			String expectation = ""The assigned value of feature 'feature' will possibly override itself because it is used inside of a loop."";
			assertEquals(expectation, message);
		} else {
			super.acceptWarning(message, object, feature, index, code, issueData);
		}
	}
"
"	@Test public void testRelativeContext() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
"
"	@Test public void testRelativePath() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
"
"	@Test public void testReexports2() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
"
"	@Test public void testLocalElementsNotFromIndex() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
"
"	@Test public void testImportsWithoutWildcard() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
"
"	@Test public void testDuplicateImportsAreIgnored() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
"
"	@Test public void testUnambiguousImportAreShadowed_00() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
"
"	@Test public void testUnambiguousImportAreShadowed_01() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
"
"	@Test public void testUnambiguousImportAreShadowed_02() throws Exception {
			public Iterator<EObject> iterator() {
				return resource.getAllContents();
			}
"
"	@Test public void testMultipleFiles() throws Exception {
			public Iterator<EObject> iterator() {
				return res1.getAllContents();
			}
"
"	@Test public void testResourceSetReferencingResourceSet() throws Exception {
			public Iterator<EObject> iterator() {
				return res1.getAllContents();
			}
"
"	@Test public void testResourceSetReferencingResourceSet2() throws Exception {
			public Iterator<EObject> iterator() {
				return res2.getAllContents();
			}
"
"	@Test public void testLaziness() throws Exception {
				public Iterator<IEObjectDescription> iterator() {
					numberOfCalls++;
					return singleton(
							(IEObjectDescription) new EObjectDescription(QualifiedName.create(name),
									EcorePackage.Literals.EATTRIBUTE, null)).iterator();
				}
"
"	@Test
	public void testNoSuitableDelegate() {
		TestableDelegatingScopeProvider testMe = new TestableDelegatingScopeProvider();
		testMe.setWrapper(this);
		Assert.assertEquals(1, testMe.invocationCount);
		
		IDelegatingScopeProvider.setWrapper(testMe, null);
		Assert.assertEquals(2, testMe.invocationCount);
	}
"
"	@Test
	public void testOneSuitableDelegate_01() {
		TestableDelegatingScopeProvider root = new TestableDelegatingScopeProvider();
		TestableDelegatingScopeProvider delegating = new TestableDelegatingScopeProvider(root);
		
		delegating.setWrapper(this);
		Assert.assertEquals(1, delegating.invocationCount);
		Assert.assertEquals(1, root.invocationCount);
		
		IDelegatingScopeProvider.setWrapper(delegating, null);
		Assert.assertEquals(2, delegating.invocationCount);
		Assert.assertEquals(2, root.invocationCount);
	}
"
"	@Test
	public void testOneSuitableDelegate_02() {
		final int[] invocationCount = new int[] { 0 };
		AbstractGlobalScopeDelegatingScopeProvider root = new AbstractGlobalScopeDelegatingScopeProvider() {
			
			@Override
			public IScope getScope(EObject context, EReference reference) {
				return IScope.NULLSCOPE;
			}
"
"	@Test
	public void testTwoSuitableDelegates_02() {
		final int[] invocationCount = new int[] { 0 };
		AbstractGlobalScopeDelegatingScopeProvider first = new AbstractGlobalScopeDelegatingScopeProvider() {
			
			@Override
			public IScope getScope(EObject context, EReference reference) {
				return IScope.NULLSCOPE;
			}
"
"	@Test public void testGetByEObject_01() throws Exception {
		public EObject getEObjectOrProxy() {
			EObject element = super.getEObjectOrProxy();
			InternalEObject result = (InternalEObject) EcoreFactory.eINSTANCE.create(element.eClass());
			result.eSetProxyURI(EcoreUtil.getURI(element));
			return result;
		}
"
"	@Test public void testSimple() throws Exception {
			public Injector createInjector() {
				return Guice.createInjector(new org.eclipse.xtext.index.IndexTestLanguageRuntimeModule(){
					@Override
					public java.lang.Class<? extends org.eclipse.xtext.scoping.IScopeProvider> bindIScopeProvider() {
						return OptimizedScopeProvider.class;
					}
				}
				);
			}
"
"	@Test public void testScopeContainsNotT2() throws Exception {
	public void tearDown() throws Exception {
		resource1 = null;
		resource2 = null;
		globalScopeProvider = null;
		super.tearDown();
		
	}
"
"	@Test public void testBug236425() throws Exception {
			public Iterator<INode> iterator() {
				return Iterators.filter(node.getAsTreeIterable().iterator(), new Predicate<INode>() {
					@Override
					public boolean apply(INode input) {
						return input.getSyntaxErrorMessage() != null;
					}
"
"	@Test public void testIssuesInOtherResource() throws Exception {
			public Injector createInjector() {
				return Guice.createInjector(new org.eclipse.xtext.XtextRuntimeModule() {
					@Override
					public void configureFileExtensions(Binder binder) {
						binder.bind(String.class).annotatedWith(Names.named(Constants.FILE_EXTENSIONS)).toInstance(""xtexterror"");
					}
"
"	@Test public void testShadowingPathes() throws Exception {
			public boolean apply(EObject input) {
				return input.eResource().getURI().toString().contains(""folder%20""+uriContains);
			}
"
"	@Test
	public void testNoneExistingFile() throws Exception {
		String path = ""fileNotExists"";
		Set<URI> uris = new PathTraverser().findAllResourceUris(path, everythingButDummy);
		assertTrue(uris.isEmpty());
	}
"
"	@Test
	public void testEmptyFolder() throws Exception {
		String path = pathTo(""emptyFolder"");
		Set<URI> uris = new PathTraverser().findAllResourceUris(path, everythingButDummy);
		assertTrue(uris.isEmpty());
	}
"
"	@Test
	public void testNonEmptyFolder() throws Exception {
		String path = pathTo(""nonemptyFolder"");
		Set<URI> uris = new PathTraverser().findAllResourceUris(path, everythingButDummy);
		assertEquals(2, uris.size());
	}
"
"	@Test
	public void testArchive() throws Exception {
		String path = pathTo(""nonemptyJar.jar"");
		Set<URI> uris = new PathTraverser().findAllResourceUris(path, everythingButDummy);
		assertEquals(3, uris.size());
	}
"
"	@Test public void testLoadMatchNone() throws Exception {
			public boolean matches(URI uri) {
				return false;
			}
"
"	@Test public void testLoadMatchAll() throws Exception {
			public boolean matches(URI uri) {
				return true;
			}
"
"	@Test public void testParseClassPath() throws Exception {
	public String pathTo(String string) throws Exception {
//		URL resource = getClass().getClassLoader().getResource();
		File base = new File(""./src/""+getClass().getName().replace('.', '/') + "".java"");
		URI fileURI = URI.createFileURI(base.getAbsolutePath());
//		System.out.println(fileURI);
		// this is a hack used in order to get a file URI for a bundleresource:/ URL
//		File f = (File) get(resource,""handler.bundleEntry.file"");
//		if (f!=null)
//			fileURI = URI.createFileURI(f.getAbsolutePath());
		
		URI fileURI2 = URI.createURI(string);
		return fileURI2.resolve(fileURI).toFileString();
	}
"
"	@Test public void testGetLeafNodes_01() {
			public Iterator<INode> iterator() {
				return new AbstractIterator<INode>() {

					private BidiTreeIterator<AbstractNode> delegate = node.basicIterator();
					
					@Override
					protected INode computeNext() {
						if (delegate.hasPrevious())
							return delegate.previous();
						return endOfData();
					}
				};
			}
"
"	@Test
	public void testEmptyText() {
		assertLineAndColumn("""", 0, 1, 1);
	}
"
"	@Test(expected=IndexOutOfBoundsException.class)
	public void testExceedsOffset() {
		assertLineAndColumn("""", 1, -1, -1);
	}
"
"	@Test(expected=IndexOutOfBoundsException.class)
	public void testNegativeOffset() {
		assertLineAndColumn("""", -1, -1, -1);
	}
"
"	@Test
	public void testSingleCharText() {
		assertLineAndColumn(""a"", 0, 1, 1);
		assertLineAndColumn(""a"", 1, 1, 2);
	}
"
"	@Test
	public void testTwoCharsText() {
		assertLineAndColumn(""ab"", 0, 1, 1);
		assertLineAndColumn(""ab"", 1, 1, 2);
		assertLineAndColumn(""ab"", 2, 1, 3);
	}
"
"	@Test
	public void testPointsToLineBreak() {
		assertLineAndColumn(""\n"", 0, 1, 1);
		assertLineAndColumn(""\r\n"", 0, 1, 1);
	}
"
"	@Test
	public void testPointsToBackslashNInWindowsLineBreak() {
		assertLineAndColumn(""\r\n"", 1, 1, 2);
		assertLineAndColumn(""a\r\n"", 2, 1, 3);
		assertLineAndColumn(""a\r\n"", 3, 2, 1);
	}
"
"	@Test public void testErrors1() throws Exception {
	public void setUp() throws Exception {
		super.setUp();
		with(DummyTestLanguageStandaloneSetup.class);
	}
"
"	@Test
	public void testFillIdToEObjectMap() {
		EPackage pack = EcoreFactory.eINSTANCE.createEPackage();
		EClass root = createEClass(pack, ""Root"");
		EClass someType = createEClass(pack, ""SomeType"");

		EReference ref1 = addEReference(root, someType, ""ref1"", false);
		EReference ref2 = addEReference(root, someType, ""ref2"", true);

		EFactory factory = pack.getEFactoryInstance();
		EObject rootObject = factory.create(root);
		EObject someTypeObject1 = factory.create(someType);
		EObject someTypeObject2 = factory.create(someType);
		rootObject.eSet(ref1, someTypeObject1);
		rootObject.eSet(ref2, someTypeObject2);

		List<EObject> map = new ArrayList<>();
		SerializationUtil.fillIdToEObjectMap(rootObject, map);
		assertTrue(map.contains(rootObject));
		assertTrue(map.contains(someTypeObject1));
		assertFalse(map.contains(someTypeObject2));
		assertEquals(2, map.size());
	}
"
"	@Test
	public void testSyntaxErrorMessage() throws IOException {
		final String message = ""hi"";
		String [] issueCodes = { null, ""issue"" };
		String [][] issueDatas = { null, {null}, {""issue data""}};
		
		for (String[] issueData : issueDatas) {
			for (String issueCode : issueCodes) {
				SyntaxErrorMessage sem = new SyntaxErrorMessage(message, issueCode, issueData);
				ByteArrayOutputStream out = new ByteArrayOutputStream ();
				DataOutputStream dout = new DataOutputStream(out);
				SerializationUtil.writeSyntaxErrorMessage(dout, null, sem);
				dout.close();
				byte[] array = out.toByteArray();
				ByteArrayInputStream in = new ByteArrayInputStream(array); 
				DataInputStream din = new DataInputStream(in);
				SyntaxErrorMessage sem2 = SerializationUtil.readSyntaxErrorMessage(din, null);
				assertEquals(sem, sem2); 
			}
		}
		ByteArrayOutputStream out = new ByteArrayOutputStream ();
		DataOutputStream dout = new DataOutputStream(out);
		SerializationUtil.writeSyntaxErrorMessage(dout, null, null);
		dout.close();
		byte[] array = out.toByteArray();
		ByteArrayInputStream in = new ByteArrayInputStream(array); 
		DataInputStream din = new DataInputStream(in);
		SyntaxErrorMessage readMessage = SerializationUtil.readSyntaxErrorMessage(din, null);
		assertNull(readMessage);
	}
"
"	@Test
	public void testClone_2() throws Exception {
		ResourceSetImpl sourceSet = new DerivedStateAwareResourceSet();
		DerivedStateAwareResource resource = (DerivedStateAwareResource) sourceSet.createResource(URI
				.createURI(""http://derived.res""));
		boolean stateToCheck = !resource.isFullyInitialized();
		resource.setFullyInitialized(stateToCheck);
		
		Resource targetRes = EcoreUtil2.clone(new DerivedStateAwareResourceSet(), sourceSet).getResources().get(0);
		
		assertTrue(targetRes instanceof DerivedStateAwareResource);
		assertEquals(""FullyInitialized flag not copied "", stateToCheck, ((DerivedStateAwareResource) targetRes).isFullyInitialized());
	}
"
"	@Test public void testModifyAndRead() throws Exception {
			public void uncaughtException(Thread t, Throwable e) {
				exceptions.add(e);
			}
"
"	@Test 
	public void testValidatorExists_0() {
		assertValidatorExists();
	}
"
"	@Test 
	public void testValidatorExists_1() {
		assertValidatorExists();
	}
"
"	@Test
	public void testDirsAndFilesAreCreated() throws Exception {
		File dir = null;
		File textFile = null;
		File binFile = null;
		try {
			JavaIoFileSystemAccess fileSystemAccess = new JavaIoFileSystemAccess(
					IResourceServiceProvider.Registry.INSTANCE, new IEncodingProvider.Runtime());

			File tmpDir = configureFileSystemAccess(fileSystemAccess);
			fileSystemAccess.generateFile(""tmp/X"", ""XX"");
			fileSystemAccess.generateFile(""tmp/Y"", new StringInputStream(""\1\2\3""));

			dir = new File(tmpDir, ""tmp"");
			assertTrue(dir.exists());
			assertTrue(dir.isDirectory());

			textFile = new File(dir, ""X"");
			assertTrue(textFile.exists());
			assertTrue(textFile.isFile());
			assertEquals(""XX"", fileSystemAccess.readTextFile(""tmp/X""));

			binFile = new File(dir, ""Y"");
			assertTrue(binFile.exists());
			assertFalse(fileSystemAccess.isFile(""tmp"", IFileSystemAccess.DEFAULT_OUTPUT)); // isFile evaluates to false for directories
			assertTrue(fileSystemAccess.isFile(""tmp/Y"", IFileSystemAccess.DEFAULT_OUTPUT));
			assertTrue(binFile.isFile());
			InputStream stream = fileSystemAccess.readBinaryFile(""tmp/Y"");
			try {
				assertEquals(""\1\2\3"", new String(ByteStreams.toByteArray(stream)));
			} finally {
				stream.close();
			}

		} finally {
			try {
				if (textFile != null)
					textFile.delete();
			} finally {
				try {
					if (binFile != null)
						binFile.delete();
				} finally {
					if (dir != null)
						dir.delete();
				}
			}
		}
	}
"
"	@Test
	public void testURI() throws Exception {
		JavaIoFileSystemAccess fileSystemAccess = new JavaIoFileSystemAccess();
		fileSystemAccess.setOutputPath(""testOutput"", ""/testDir"");
		URI uri = fileSystemAccess.getURI(""testFile"", ""testOutput"");
		String expectedUri = new File(new File(File.separator + ""testDir""), ""testFile"").toURI().toString();
		assertEquals(expectedUri, uri.toString());
	}
"
"	@Test
	public void testEncoding() throws Exception {
		File file = null;
		FileInputStream fileInputStream = null;
		try {
			JavaIoFileSystemAccess fileSystemAccess = new JavaIoFileSystemAccess(
					IResourceServiceProvider.Registry.INSTANCE, new IEncodingProvider() {
						@Override
						public String getEncoding(URI uri) {
							return ""ISO-8859-1"";
						}
"
"	@Test
	public void testTraceIsCreated() throws Exception {
		File file = null;
		try {

			JavaIoFileSystemAccess fileSystemAccess = new JavaIoFileSystemAccess(
					IResourceServiceProvider.Registry.INSTANCE, new IEncodingProvider.Runtime(),
					new TraceFileNameProvider(), new TraceRegionSerializer());

			File tmpDir = configureFileSystemAccess(fileSystemAccess);
			SourceRelativeURI uri = new SourceRelativeURI(URI.createURI(""foo/bar""));
			CharSequenceTraceWrapper wrapper = new CharSequenceTraceWrapper();
			fileSystemAccess.generateFile(""tmp/X"", wrapper.wrapWithTraceData(""XX"", uri, 0, 10, 0, 1));

			file = new File(tmpDir, ""tmp/X"");
			assertTrue(file.exists());
			assertTrue(file.isFile());
			assertEquals(""XX"", fileSystemAccess.readTextFile(""tmp/X""));

			file = new File(tmpDir, ""tmp/.X._trace"");
			assertTrue(file.exists());
			assertTrue(file.isFile());

		} finally {
			if (file != null)
				file.delete();
		}
	}
"
"	@Test
	public void testConstructor() {
		TraceRegion region = new TraceRegion(0, 1, 0, 0, true, 2, 3, 0, 0, null, newURI());
		assertEquals(0, region.getMyOffset());
		assertEquals(1, region.getMyLength());
		assertEquals(2, region.getMergedAssociatedLocation().getOffset());
		assertEquals(3, region.getMergedAssociatedLocation().getLength());
		assertEquals(newURI(), region.getAssociatedSrcRelativePath());
		assertNull(region.getParent());
		assertTrue(region.getNestedRegions().isEmpty());
	}
"
"	@Test
	public void testConstructorWithParent() {
		TraceRegion parent = new TraceRegion(0, 1, 0, 0, true, 2, 3, 0, 0, null, newURI());
		TraceRegion region = new TraceRegion(0, 1, 0, 0, true, 2, 3, 0, 0, parent, null);
		assertEquals(newURI(), region.getAssociatedSrcRelativePath());
		assertEquals(parent, region.getParent());
	}
"
"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_01() {
		new TraceRegion(-1, 0, 0, 0, true, 0, 0, 0, 0, null, newURI());
	}
"
"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_02() {
		new TraceRegion(0, -1, 0, 0, true, 0, 0, 0, 0, null, newURI());
	}
"
"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_03() {
		new TraceRegion(0, 0, -1, 0, true, 0, 0, 0, 0, null, newURI());
	}
"
"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_04() {
		new TraceRegion(0, 0, 0, -1, true, 0, 0, 0, 0, null, newURI());
	}
"
"	@Test(expected = IllegalArgumentException.class)
	public void testConstructorInvalidArgs_05() {
		new TraceRegion(0, 0, 0, 0, true, 0, 0, 0, 0, null, null);
	}
"
"	@Test
	public void testLeafIterator_NoChildren() {
		TraceRegion region = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, null, newURI());
		Iterator<AbstractTraceRegion> iter = region.leafIterator();
		assertEquals(Collections.singleton(region).iterator(), iter);
	}
"
"	@Test
	public void testLeafIterator_OneChild() {
		TraceRegion parent = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion region = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Collections.singleton(region).iterator(), iter);
	}
"
"	@Test
	public void testLeafIterator_GrandChild() {
		TraceRegion root = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion parent = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, root, null);
		TraceRegion region = new TraceRegion(0, 1, 1, 2, true, 2, 3, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Collections.singleton(region).iterator(), iter);
	}
"
"	@Test
	public void testLeafIterator_TwoChildren_NoGaps() {
		TraceRegion parent = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, parent, null);
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
"
"	@Test
	public void testLeafIterator_OneChild_LeftGap() {
		final TraceRegion parent = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		AbstractTraceRegion first = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(0, 1, 0, 1), true, new LocationData(2, 3, 0, 0, null), parent) {};
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
"
"	@Test
	public void testLeafIterator_OneChild_RightGap() {
		final TraceRegion parent = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		AbstractTraceRegion first = new TraceRegion(0, 1, 0, 1, true, 3, 4, 0, 0, parent, null);
		AbstractTraceRegion second = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(1, 1, 1, 2), true, new LocationData(2, 3, 0, 0, null), parent) {};
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
"
"	@Test
	public void testLeafIterator_OneGrandChild_LeftGap() {
		final TraceRegion root = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		AbstractTraceRegion first = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(0, 1, 0, 1), true, new LocationData(2, 3, 0, 0, null), root) {};
		TraceRegion parent = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, root, null);
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
"
"	@Test
	public void testLeafIterator_OneGrandChild_RightGap() {
		final TraceRegion root = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion parent = new TraceRegion(0, 1, 0, 1, true, 3, 4, 0, 0, root, null);
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 3, 4, 0, 0, parent, null);
		AbstractTraceRegion second = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(1, 1, 1, 2), true, new LocationData(2, 3, 0, 0, null), root) {};
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
"
"	@Test
	public void testLeafIterator_TwoGrandChildren_NoGaps_01() {
		TraceRegion root = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion parent = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, root, null);
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, parent, null);
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
"
"	@Test
	public void testLeafIterator_TwoGrandChildren_NoGaps_02() {
		TraceRegion root = new TraceRegion(0, 2, 0, 2, true, 2, 3, 0, 0, null, newURI());
		TraceRegion firstParent = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, root, null);
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, firstParent, null);
		TraceRegion secondParent = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, root, null);
		TraceRegion second = new TraceRegion(1, 1, 1, 2, true, 3, 4, 0, 0, secondParent, null);
		Iterator<AbstractTraceRegion> iter = root.leafIterator();
		assertEquals(Arrays.asList(first, second).iterator(), iter);
	}
"
"	@Test
	public void testLeafIterator_TwoChildren_WithGaps() {
		final TraceRegion parent = new TraceRegion(0, 3, 0, 3, true, 2, 3, 0, 0, null, newURI());
		TraceRegion first = new TraceRegion(0, 1, 0, 1, true, 2, 3, 0, 0, parent, null);
		AbstractTraceRegion second = new AbstractStatefulTraceRegion(new TextRegionWithLineInformation(1, 1, 1, 2), true, new LocationData(2, 3, 0, 0, null), parent) {};
		AbstractTraceRegion third = new TraceRegion(2, 1, 2, 3, true, 3, 4, 0, 0, parent, null);
		Iterator<AbstractTraceRegion> iter = parent.leafIterator();
		assertEquals(Arrays.asList(first, second, third).iterator(), iter);
	}
"
"	@Test
	public void testAnnotate_01() {
		TraceRegion region = new TraceRegion(0, 1, 0, 0, true, 2, 3, 0, 0, null, newURI());
		assertEquals(""<2:3[a]"", region.getAnnotatedString(""a""));
	}
"
"	@Test
	public void testAnnotate_02() {
		TraceRegion region = new TraceRegion(1, 1, 0, 0, true, 2, 3, 0, 0, null, newURI());
		assertEquals(""a<2:3[b]c"", region.getAnnotatedString(""abc""));
	}
"
"	@Test
	public void testAnnotate_03() {
		TraceRegion parent = new TraceRegion(0, 4, 0, 0, true, 1, 2, 0, 0, null, newURI());
		new TraceRegion(0, 1, 0, 0, true, 3, 4, 0, 0, parent, null);
		new TraceRegion(2, 1, 0, 0, true, 5, 6, 0, 0, parent, null);
		new TraceRegion(3, 1, 0, 0, true, 7, 8, 0, 0, parent, null);
		assertEquals(""<1:2[<3:4[a]b<5:6[c]<7:8[d]]e"", parent.getAnnotatedString(""abcde""));
	}
"
"	@Test
	public void testAnnotate_04() {
		TraceRegion root = new TraceRegion(0, 4, 0, 0, true, 1, 2, 0, 0, null, newURI());
		TraceRegion parent = new TraceRegion(1, 2, 0, 0, true, 3, 4, 0, 0, root, null);
		new TraceRegion(2, 1, 0, 0, true, 5, 6, 0, 0, parent, null);
		assertEquals(""<1:2[a<3:4[b<5:6[c]]d]e"", root.getAnnotatedString(""abcde""));
	}
"
"    @Test
    public void testMin() throws Exception {
        Assert.assertEquals(1.0D, m.min(), 0.0D);
    }
"
"    @Test
    public void testMax() throws Exception {
        Assert.assertEquals(100.0D, m.max(), 0.0D);
    }
"
"    @Test
    public void testAvg() throws Exception {
        int sum = 0;
        for (int i = 1; i <= 100; i++) {
            sum += i;
        }
        Assert.assertEquals((sum / 100.0D), m.avg(), 0.0D);
    }
"
"    @Test
    public void testCount() throws Exception {
        Assert.assertEquals(100.0D, m.count(), 0.0D);
    }
"
"    @Test
    public void test50thPercentile() throws Exception {
        Assert.assertEquals(50.0D, m.getPercentile(50), 0.0D);
    }
"
"    @Test
    public void test75thPercentile() throws Exception {
        Assert.assertEquals(75.0D, m.getPercentile(75), 0.0D);
    }
"
"    @Test
    public void test90thPercentile() throws Exception {
        Assert.assertEquals(90.0D, m.getPercentile(90), 0.0D);
    }
"
"    @Test
    public void test99thPercentile() throws Exception {
        Assert.assertEquals(99.0D, m.getPercentile(99), 0.0D);
    }
"
"    @Test
    public void testSerialization() throws Exception {
        MetricParser metricParser = new MetricParser();
        Tag t1 = new Tag(""tag1=value1"");
        Tag t2 = new Tag(""tag2=value2"");
        Tag avg = new Tag(""sample=avg"");
        Tag min = new Tag(""sample=min"");
        Tag max = new Tag(""sample=max"");
        Tag sum = new Tag(""sample=sum"");
        Tag count = new Tag(""sample=count"");
        Tag p50 = new Tag(""sample=50p"");
        Tag p75 = new Tag(""sample=75p"");
        Tag p90 = new Tag(""sample=90p"");
        Tag p99 = new Tag(""sample=99p"");

        List<Tag> tags = new ArrayList<>();
        tags.add(t1);
        tags.add(t2);
        m.initialize(""sys.cpu.user"", tags);

        byte[] bytes = m.serialize(m);
        String puts = new String(bytes);
        for (String put : puts.split(""\n"")) {
            Metric metric = metricParser.parse(put);
            Assert.assertEquals(""sys.cpu.user_summarized"", metric.getName());
            metric.getTags().forEach(t -> {
                Assert.assertTrue(
                        t.equals(t1) || t.equals(t2) || t.equals(avg) || t.equals(min) || t.equals(max) || t.equals(sum)
                                || t.equals(count) || t.equals(p50) || t.equals(p75) || t.equals(p90) || t.equals(p99));
            });
        }
    }
"
"    @Test
    public void testWrite() throws Exception {
        Thread t = new Thread(server);
        t.start();
        setupPlugin();
        while (!server.ready()) {
            Thread.sleep(1000);
        }
        Assert.assertEquals(0, plugin.write(createMetric()));
        Thread.sleep(100);
        Assert.assertTrue(server.messageReceived());
        plugin.shutdown();
        server.shutdown();
        t.join();
    }
"
"    @Test
    public void testWriteAfterServerRestart() throws Exception {
        Thread t = new Thread(server);
        t.start();
        setupPlugin();
        while (!server.ready()) {
            Thread.sleep(1000);
        }
        Assert.assertEquals(0, plugin.write(createMetric()));
        Thread.sleep(100);
        Assert.assertTrue(server.messageReceived());
        server.shutdown();
        t.join();
        Thread.sleep(2000);

        server.create();
        Thread t2 = new Thread(server);
        t2.start();
        // Need to call this again because the server is not guaranteed to be
        // listening on the same local port as the first time that it was
        // started
        setupPlugin();
        while (!server.ready()) {
            Thread.sleep(1000);
            // Keep sending metrics to plugin to force reconnect
            int result = plugin.write(createMetric());
            System.out.println(""Wrote to client, result: "" + result);
            Assert.assertEquals(0, result);
        }
        Assert.assertEquals(0, plugin.write(createMetric()));
        Thread.sleep(1000);
        Assert.assertTrue(server.messageReceived());
        plugin.shutdown();
        server.shutdown();
        t2.join();
    }
"
"    @Test
    public void testParseWithEscapedCharacters() {

        MetricParser parser = new MetricParser();
        Metric m = parser.parse(""put mymetric 12341234 5.0 tag1=value1,value1 tag2=value2=value2"");

        Assert.assertEquals(""mymetric"", m.getName());
        Assert.assertEquals(12341234, (long) m.getValue().getTimestamp());
        Assert.assertEquals(5.0, (double) m.getValue().getMeasure(), 0);
        List<Tag> expected = new ArrayList<>();
        expected.add(new Tag(""tag1"", ""value1,value1""));
        expected.add(new Tag(""tag2"", ""value2=value2""));
        Assert.assertEquals(expected, m.getTags());
    }
"
"    @Test
    public void testParseMalformatted() {

        MetricParser parser = new MetricParser();
        try {
            // parser should throw an exception
            parser.parse(""put mymetric 12341234 5.0 tag1 tag2=value2"");
            Assert.fail();
        } catch (IllegalArgumentException e) {

        }
    }
"
"    @Test
    public void testListParse() {
        String value = ""tag1=value1,tag2=value2"";
        List<Tag> tags = new TagListParser().parse(value);
        Assert.assertEquals(2, tags.size());
        Assert.assertEquals(new Tag(""tag1"", ""value1""), tags.get(0));
        Assert.assertEquals(new Tag(""tag2"", ""value2""), tags.get(1));
    }
"
"    @Test
    public void testListCombine() {
        List<Tag> tags = new ArrayList<>();
        tags.add(new Tag(""tag1"", ""value1""));
        tags.add(new Tag(""tag2"", ""value2""));
        String combined = new TagListParser().combine(tags);
        Assert.assertEquals(""tag1=value1,tag2=value2"", combined);
    }
"
"    @Test
    public void testListCombineMap() {
        Map<String, String> map = new TreeMap<>();
        map.put(""tag1"", ""value1"");
        map.put(""tag2"", ""value2"");
        String combined = new TagListParser().combine(map);
        Assert.assertEquals(""tag1=value1,tag2=value2"", combined);
    }
"
"    @Test
    public void testParseTagsWithCommas() {

        try {
            String s = ""tag1=value1,tag2=3.4.3_(default\\,_Date\\,_Time)_"";
            new TagListParser().parse(s);
        } catch (Exception e) {
            Assert.fail(e.getMessage());
        }
    }
"
"    @Test
    public void testEquals() {
        Metric m1 = Metric.newBuilder().name(""m1"").tag(""t1"", ""v1"").tag(""t2"", ""v2"").value(1, 0.0).build();
        Metric m2 = Metric.newBuilder().name(""m1"").tag(""t2"", ""v2"").tag(""t1"", ""v1"").value(1, 0.0).build();

        assertTrue(m1.equals(m2));
        assertTrue(m2.equals(m1));

        Metric m3 = Metric.newBuilder().name(""m1"").tag(""t1"", ""v1"").value(1, 0.0).build();
        assertFalse(m1.equals(m3));

        Metric m4 = Metric.newBuilder().name(""m4"").tag(""t2"", ""v2"").tag(""t1"", ""v1"").value(1, 0.0).build();
        assertFalse(m1.equals(m4));

        Metric m5 = Metric.newBuilder().name(""m1"").tag(""t3"", ""v3"").tag(""t2"", ""v2"").tag(""t1"", ""v1"").value(1, 0.0)
                .build();
        assertFalse(m1.equals(m5));

        Metric m6 = Metric.newBuilder().name(""m1"").tag(""t2"", ""v2"").tag(""t1"", ""v1"").value(2, 0.0).build();
        assertFalse(m1.equals(m6));

        Metric m7 = Metric.newBuilder().name(""m1"").tag(""t2"", ""v2"").tag(""t1"", ""v1"").value(1, 1.0).build();
        assertFalse(m1.equals(m7));
    }
"
"    @Test
    public void testJson() throws IOException {
        ObjectMapper mapper = new ObjectMapper();

        String expectedJson = ""{\""name\"":\""m1\"",\""timestamp\"":1,\""measure\"":1.0,\""tags\"":[{\""k1\"":\""v1\""}]}"";

        Metric m1 = Metric.newBuilder().name(""m1"").tag(""k1"", ""v1"").value(1, 1.0).build();

        Metric expectedMetric = mapper.readValue(expectedJson, Metric.class);

        assertTrue(m1.equals(expectedMetric));

        expectedJson = ""{\""name\"":\""m1\"",\""tags\"":[{\""k1\"":\""v1\""}],\""timestamp\"":5,\""measure\"":5.0}"";
        expectedMetric = mapper.readValue(expectedJson, Metric.class);

        assertEquals((long) expectedMetric.getValue().getTimestamp(), 5L);
        assertEquals(expectedMetric.getValue().getMeasure(), 5.0D, 0.0);

    }
"
"    @Test
    public void testBasicAuth() throws Exception {
        BasicAuthLogin login = new BasicAuthLogin();
        login.setUsername(""test"");
        login.setPassword(""pass"");
        testSerialization(login);
    }
"
"    @Test
    public void testCreateSubscription() throws Exception {
        CreateSubscription create = new CreateSubscription();
        create.setSubscriptionId(""1234"");
        testSerialization(create);
    }
"
"    @Test
    public void testCloseSubscription() throws Exception {
        CloseSubscription close = new CloseSubscription();
        close.setSubscriptionId(""1234"");
        testSerialization(close);
    }
"
"    @Test
    public void testAddSubscription() throws Exception {
        AddSubscription add = new AddSubscription();
        add.setSubscriptionId(""1234"");
        add.setMetric(""sys.cpu.user"");
        testSerialization(add);
    }
"
"    @Test
    public void testRemoveSubscription() throws Exception {
        RemoveSubscription remove = new RemoveSubscription();
        remove.setSubscriptionId(""1234"");
        remove.setMetric(""sys.cpu.user"");
        testSerialization(remove);
    }
"
"    @Test(expected = IllegalArgumentException.class)
    public void testSessionIdNull() throws Exception {
        AuthCache.getAuthorizations("""");
    }
"
"    @Test
    public void testGetAuths() throws Exception {
        Authorizations a = AuthCache.getAuthorizations(cookie);
        Assert.assertEquals(""A,B,C"", a.toString());
    }
"
"    @Test(expected = BadCredentialsException.class)
    public void testBasicAuthenticationFailure() {
        UsernamePasswordAuthenticationToken token = new UsernamePasswordAuthenticationToken(""test"", ""test2"");
        AuthenticationService.getAuthenticationManager().authenticate(token);
    }
"
"    @Test
    public void testBasicAuthenticationLogin() {
        UsernamePasswordAuthenticationToken token = new UsernamePasswordAuthenticationToken(""test"", ""test1"");
        Authentication auth = AuthenticationService.getAuthenticationManager().authenticate(token);
        Collection<? extends GrantedAuthority> authorizations = auth.getAuthorities();
        authorizations.forEach(a -> {
            Assert.assertTrue(
                    a.getAuthority().equals(""A"") || a.getAuthority().equals(""B"") || a.getAuthority().equals(""C""));
        });
    }
"
"    @Test
    public void testX509AuthenticationLogin() {
        PreAuthenticatedAuthenticationToken token = new PreAuthenticatedAuthenticationToken(""example.com"",
                ""doesn't matter what I put here"");
        Authentication auth = AuthenticationService.getAuthenticationManager().authenticate(token);
        Collection<? extends GrantedAuthority> authorizations = auth.getAuthorities();
        authorizations.forEach(a -> {
            Assert.assertTrue(
                    a.getAuthority().equals(""D"") || a.getAuthority().equals(""E"") || a.getAuthority().equals(""F""));
        });
    }
"
"    @Test(expected = UsernameNotFoundException.class)
    public void testX509AuthenticationLoginFailed() {
        PreAuthenticatedAuthenticationToken token = new PreAuthenticatedAuthenticationToken(""bad.example.com"",
                ""doesn't matter what I put here"");
        Authentication auth = AuthenticationService.getAuthenticationManager().authenticate(token);
        Collection<? extends GrantedAuthority> authorizations = auth.getAuthorities();
        authorizations.forEach(a -> {
            Assert.assertTrue(
                    a.getAuthority().equals(""D"") || a.getAuthority().equals(""E"") || a.getAuthority().equals(""F""));
        });
    }
"
"    @Test
    public void testMovingAverage() throws Exception {
        SortedMapIterator source = new SortedMapIterator(table);
        TimeSeriesGroupingIterator iter = new TimeSeriesGroupingIterator();
        IteratorSetting settings = new IteratorSetting(100, TimeSeriesGroupingIterator.class);
        settings.addOption(TimeSeriesGroupingIterator.FILTER, ""0.20,0.20,0.20,0.20,0.20"");
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);

        for (int i = 4; i < 100; i++) {
            checkNextResult(iter, new double[] { i - 4, i - 3, i - 2, i - 1, i });
        }
        assertFalse(iter.hasTop());
    }
"
"    @Test
    public void testMultipleTimeSeriesMovingAverage() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        List<Tag> tags1 = new ArrayList<>();
        tags1.add(new Tag(""host"", ""r01n01""));
        List<Tag> tags2 = new ArrayList<>();
        tags2.add(new Tag(""host"", ""r01n02""));
        for (int i = 0; i < 100; i++) {
            ts += 1000;
            Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags1);
            byte[] row = MetricAdapter.encodeRowKey(m);
            Key k = new Key(row, tags1.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
            table.put(k, v);
            Metric m2 = new Metric(""sys.cpu.user"", ts, i * 2.0D, tags2);
            byte[] row2 = MetricAdapter.encodeRowKey(m2);
            Key k2 = new Key(row2, tags2.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v2 = new Value(MetricAdapter.encodeValue(m2.getValue().getMeasure()));
            table.put(k2, v2);
        }
        SortedMapIterator source = new SortedMapIterator(table);
        TimeSeriesGroupingIterator iter = new TimeSeriesGroupingIterator();
        IteratorSetting settings = new IteratorSetting(100, TimeSeriesGroupingIterator.class);
        settings.addOption(TimeSeriesGroupingIterator.FILTER, ""0.20,0.20,0.20,0.20,0.20"");
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);

        // this section changed when the key structure changed so that identical
        // colFam values sorted consecutively within an given time period
        for (int i = 4; i < 100; i++) {
            checkNextResult(iter, new double[] { i - 4, i - 3, i - 2, i - 1, i });
        }
        for (int i = 4; i < 100; i++) {
            checkNextResult(iter, new double[] { (i - 4) * 2, (i - 3) * 2, (i - 2) * 2, (i - 1) * 2, i * 2 });
        }
        assertFalse(iter.hasTop());

    }
"
"    @Test
    public void testTimeSeriesDropOff() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        List<Tag> tags1 = new ArrayList<>();
        tags1.add(new Tag(""host"", ""r01n01""));
        List<Tag> tags2 = new ArrayList<>();
        tags2.add(new Tag(""host"", ""r01n02""));
        for (int i = 0; i < 100; i++) {
            ts += 1000;
            Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags1);
            byte[] row = MetricAdapter.encodeRowKey(m);
            Key k = new Key(row, tags1.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
            table.put(k, v);
            if (i < 50) {
                // only populate this series 50 times
                Metric m2 = new Metric(""sys.cpu.user"", ts, i * 2.0D, tags2);
                byte[] row2 = MetricAdapter.encodeRowKey(m2);
                Key k2 = new Key(row2, tags2.get(0).join().getBytes(StandardCharsets.UTF_8),
                        MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v2 = new Value(MetricAdapter.encodeValue(m2.getValue().getMeasure()));
                table.put(k2, v2);
            }
        }

        SortedMapIterator source = new SortedMapIterator(table);
        TimeSeriesGroupingIterator iter = new TimeSeriesGroupingIterator();
        IteratorSetting settings = new IteratorSetting(100, TimeSeriesGroupingIterator.class);
        settings.addOption(TimeSeriesGroupingIterator.FILTER, ""0.20,0.20,0.20,0.20,0.20"");
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);

        // this section changed when the key structure changed so that identical
        // colFam values sorted consecutively within an given time period
        for (int i = 4; i < 100; i++) {
            System.out.println(i);
            checkNextResult(iter, new double[] { i - 4, i - 3, i - 2, i - 1, i });
        }
        for (int i = 4; i < 50; i++) {
            System.out.println(i);
            checkNextResult(iter, new double[] { (i - 4) * 2, (i - 3) * 2, (i - 2) * 2, (i - 1) * 2, i * 2 });
        }
        assertFalse(iter.hasTop());
    }
"
"    @Test
    public void testAdditionalTimeSeries() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        List<Tag> tags1 = new ArrayList<>();
        tags1.add(new Tag(""host"", ""r01n01""));
        List<Tag> tags2 = new ArrayList<>();
        tags2.add(new Tag(""host"", ""r01n02""));
        for (int i = 0; i < 100; i++) {
            ts += 1000;
            Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags1);
            byte[] row = MetricAdapter.encodeRowKey(m);
            Key k = new Key(row, tags1.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
            table.put(k, v);
            if (i > 50) {
                // only populate this series 50 times
                Metric m2 = new Metric(""sys.cpu.user"", ts, i * 2.0D, tags2);
                byte[] row2 = MetricAdapter.encodeRowKey(m2);
                Key k2 = new Key(row2, tags2.get(0).join().getBytes(StandardCharsets.UTF_8),
                        MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v2 = new Value(MetricAdapter.encodeValue(m2.getValue().getMeasure()));
                table.put(k2, v2);
            }
        }
        SortedMapIterator source = new SortedMapIterator(table);
        TimeSeriesGroupingIterator iter = new TimeSeriesGroupingIterator();
        IteratorSetting settings = new IteratorSetting(100, TimeSeriesGroupingIterator.class);
        settings.addOption(TimeSeriesGroupingIterator.FILTER, ""0.20,0.20,0.20,0.20,0.20"");
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);

        // this section changed when the key structure changed so that identical
        // colFam values sorted consecutively within an given time period
        for (int i = 4; i < 100; i++) {
            checkNextResult(iter, new double[] { i - 4, i - 3, i - 2, i - 1, i });
        }
        for (int i = 55; i < 100; i++) {
            checkNextResult(iter, new double[] { (i - 4) * 2, (i - 3) * 2, (i - 2) * 2, (i - 1) * 2, i * 2 });
        }

        assertFalse(iter.hasTop());

    }
"
"    @Test
    public void testManySparseTimeSeries() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        List<Tag> tags1 = new ArrayList<>();
        tags1.add(new Tag(""host"", ""r01n01""));
        List<Tag> tags2 = new ArrayList<>();
        tags2.add(new Tag(""host"", ""r01n02""));
        List<Tag> tags3 = new ArrayList<>();
        tags3.add(new Tag(""host"", ""r01n03""));
        for (int i = 0; i < 100; i++) {
            ts += 1000;
            Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags1);
            byte[] row = MetricAdapter.encodeRowKey(m);
            Key k = new Key(row, tags1.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
            table.put(k, v);
            // jitter the time on the second time series
            Metric m2 = new Metric(""sys.cpu.user"", ts + 50, i * 2.0D, tags2);
            byte[] row2 = MetricAdapter.encodeRowKey(m2);
            Key k2 = new Key(row2, tags2.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts + 50);
            Value v2 = new Value(MetricAdapter.encodeValue(m2.getValue().getMeasure()));
            table.put(k2, v2);
            Metric m3 = new Metric(""sys.cpu.user"", ts, i * 3.0D, tags3);
            byte[] row3 = MetricAdapter.encodeRowKey(m3);
            Key k3 = new Key(row3, tags3.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v3 = new Value(MetricAdapter.encodeValue(m3.getValue().getMeasure()));
            table.put(k3, v3);
        }

        SortedMapIterator source = new SortedMapIterator(table);
        TimeSeriesGroupingIterator iter = new TimeSeriesGroupingIterator();
        IteratorSetting settings = new IteratorSetting(100, TimeSeriesGroupingIterator.class);
        settings.addOption(TimeSeriesGroupingIterator.FILTER, ""0.20,0.20,0.20,0.20,0.20"");
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);

        LinkedList<Double> first = new LinkedList<>();
        first.add(0D);
        first.add(1D);
        first.add(2D);
        first.add(3D);
        first.add(4D);
        LinkedList<Double> second = new LinkedList<>();
        second.add(0D);
        second.add(2D);
        second.add(4D);
        second.add(6D);
        second.add(8D);
        LinkedList<Double> third = new LinkedList<>();
        third.add(0D);
        third.add(3D);
        third.add(6D);
        third.add(9D);
        third.add(12D);

        // this section changed when the key structure changed so that identical
        // colFam values sorted consecutively within an given time period
        for (int i = 4; i < 100; i++) {
            checkNextResult(iter, first);
            shiftAndAdd(first, 1);
        }
        for (int i = 4; i < 100; i++) {
            System.out.println(i);
            checkNextResult(iter, second);
            shiftAndAdd(second, 2);
        }
        for (int i = 4; i < 100; i++) {
            checkNextResult(iter, third);
            shiftAndAdd(third, 3);
        }
        assertFalse(iter.hasTop());
    }
"
"    @Test
    public void testConstantTimeRate() throws Exception {
        SortedMapIterator source = new SortedMapIterator(table);
        RateIterator iter = new RateIterator();
        IteratorSetting settings = new IteratorSetting(100, RateIterator.class);
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);
        for (int i = 0; i < 99; i++) {
            assertTrue(iter.hasTop());
            assertEquals(0.001D, MetricAdapter.decodeValue(iter.getTopValue().get()), 0.0D);
            iter.next();
        }
        assertFalse(iter.hasTop());
    }
"
"    @Test
    public void testRateWithTimeJitter() throws Exception {
        table.clear();
        Random r = new Random(111131131L);
        long ts = System.currentTimeMillis();
        for (int i = 1; i <= 100; i++) {
            ts += 1000 + r.nextInt(100);
            Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags);
            byte[] row = MetricAdapter.encodeRowKey(m);
            Key k = new Key(row, tags.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
            table.put(k, v);
        }

        SortedMapIterator source = new SortedMapIterator(table);
        source.seek(new Range(), EMPTY_COL_FAMS, true);
        long prevTs = -1L;
        Double prevValue = null;
        List<Double> expected = new ArrayList<>();
        while (source.hasTop()) {
            Key k = source.getTopKey();
            Value v = source.getTopValue();
            if (prevTs != -1L) {
                Double thisValue = MetricAdapter.decodeValue(v.get());
                expected.add((thisValue + (prevValue * -1)) / (k.getTimestamp() - prevTs));
            }
            prevTs = k.getTimestamp();
            prevValue = MetricAdapter.decodeValue(v.get());
            source.next();
        }

        assertEquals(99, expected.size());
        source = new SortedMapIterator(table);
        RateIterator iter = new RateIterator();
        IteratorSetting settings = new IteratorSetting(100, RateIterator.class);
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);
        for (int i = 0; i < 99; i++) {
            assertTrue(iter.hasTop());
            assertEquals(expected.get(i), MetricAdapter.decodeValue(iter.getTopValue().get()), 0.0D);
            iter.next();
        }
        assertFalse(iter.hasTop());
    }
"
"    @Test
    public void testCounterRate() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        for (int j = 0; j < 10; j++) {
            for (int i = 1; i <= 10; i++) {
                ts += 1000;
                Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags);
                byte[] row = MetricAdapter.encodeRowKey(m);
                Key k = new Key(row, tags.get(0).join().getBytes(StandardCharsets.UTF_8),
                        MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
                table.put(k, v);
            }
        }

        SortedMapIterator source = new SortedMapIterator(table);
        RateIterator iter = new RateIterator();
        IteratorSetting settings = new IteratorSetting(100, RateIterator.class);

        QueryRequest.RateOption option = new QueryRequest.RateOption();
        option.setCounter(true);
        option.setCounterMax(0);
        RateIterator.setRateOptions(settings, option);

        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);
        for (int i = 0; i < 99; i++) {
            assertTrue(iter.hasTop());
            assertEquals(0.001D, MetricAdapter.decodeValue(iter.getTopValue().get()), 0.0D);
            iter.next();
        }
        assertFalse(iter.hasTop());
    }
"
"    @Test
    public void testCounterRateWithMax() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        for (int j = 0; j < 10; j++) {
            for (int i = 0; i < 10; i++) {
                ts += 1000;
                Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags);
                byte[] row = MetricAdapter.encodeRowKey(m);
                Key k = new Key(row, tags.get(0).join().getBytes(StandardCharsets.UTF_8),
                        MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
                table.put(k, v);
            }
        }

        SortedMapIterator source = new SortedMapIterator(table);
        RateIterator iter = new RateIterator();
        IteratorSetting settings = new IteratorSetting(100, RateIterator.class);

        QueryRequest.RateOption option = new QueryRequest.RateOption();
        option.setCounter(true);
        option.setCounterMax(10);
        RateIterator.setRateOptions(settings, option);

        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);
        for (int i = 0; i < 99; i++) {
            assertTrue(iter.hasTop());
            assertEquals(0.001D, MetricAdapter.decodeValue(iter.getTopValue().get()), 0.0D);
            iter.next();
        }
        assertFalse(iter.hasTop());
    }
"
"    @Test
    public void testCounterRateWithReset() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        for (int j = 0; j < 10; j++) {
            for (int i = 0; i < 10; i++) {
                ts += 1000;
                Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags);
                byte[] row = MetricAdapter.encodeRowKey(m);
                Key k = new Key(row, tags.get(0).join().getBytes(StandardCharsets.UTF_8),
                        MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
                table.put(k, v);
            }
        }

        SortedMapIterator source = new SortedMapIterator(table);
        RateIterator iter = new RateIterator();
        IteratorSetting settings = new IteratorSetting(100, RateIterator.class);

        QueryRequest.RateOption option = new QueryRequest.RateOption();
        option.setCounter(true);
        option.setCounterMax(Long.MAX_VALUE);
        option.setResetValue(1);
        RateIterator.setRateOptions(settings, option);

        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);
        for (int i = 0; i < 99; i++) {
            assertTrue(iter.hasTop());
            assertEquals(((i + 1) % 10 == 0 ? 0.0D : 0.001D), MetricAdapter.decodeValue(iter.getTopValue().get()),
                    0.0D);
            iter.next();
        }
        assertFalse(iter.hasTop());
    }
"
"    @Test(expected = IllegalArgumentException.class)
    public void testDefaultMissing() throws Exception {
        SortedMap<Key, Value> table = new TreeMap<>();
        SortedKeyValueIterator<Key, Value> source = new SortedMapIterator(table);
        MetricAgeOffIterator iter = new MetricAgeOffIterator();
        HashMap<String, String> options = new HashMap<>();
        iter.init(source, options, null);
    }
"
"    @Test
    public void testDefault() throws Exception {
        SortedMap<Key, Value> table = new TreeMap<>();
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0], new byte[0], new byte[0],
                TEST_TIME), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 1), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 1), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 2), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 2), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 3), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 4), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 4), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 5), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 5), EMPTY_VALUE);

        SortedKeyValueIterator<Key, Value> source = new SortedMapIterator(table);
        MetricAgeOffIterator iter = new MetricAgeOffIterator();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffIterator.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        iter.init(source, options, null);
        iter.seek(new Range(), columnFamilies, true);
        int seen = 0;
        while (iter.hasTop()) {
            Key k = iter.getTopKey();
            Assert.assertTrue(k.getTimestamp() >= TEST_TIME && k.getTimestamp() <= TEST_TIME + 5);
            seen++;
            iter.next();
        }
        Assert.assertEquals(6, seen);
    }
"
"    @Test
    public void testMixed() throws Exception {
        SortedMap<Key, Value> table = new TreeMap<>();
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME), new byte[0], new byte[0], new byte[0],
                TEST_TIME), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 1), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 1), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 2), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 2), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 3), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 3), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 4), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 4), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 5), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 5), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0], new byte[0], new byte[0],
                TEST_TIME), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 1), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 1), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 2), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 2), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 3), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 4), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 4), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 5), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 5), EMPTY_VALUE);

        SortedKeyValueIterator<Key, Value> source = new SortedMapIterator(table);
        MetricAgeOffIterator iter = new MetricAgeOffIterator();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffIterator.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        iter.init(source, options, null);
        iter.seek(new Range(), columnFamilies, true);
        int seen = 0;
        while (iter.hasTop()) {
            Key k = iter.getTopKey();
            Assert.assertTrue(k.getTimestamp() >= TEST_TIME && k.getTimestamp() <= TEST_TIME + 5);
            seen++;
            iter.next();
        }
        Assert.assertEquals(12, seen);
    }
"
"    @Test
    public void testAgeoffMixed() throws Exception {
        SortedMap<Key, Value> table = new TreeMap<>();
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME - (3 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME - (3 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME - (2 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME - (2 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME - (1 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME - (1 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME), new byte[0], new byte[0], new byte[0],
                TEST_TIME), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + ONE_DAY), new byte[0], new byte[0],
                new byte[0], TEST_TIME + ONE_DAY), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + (2 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME + (2 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME - (3 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME - (3 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME - (2 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME - (2 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME - (1 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME - (1 * ONE_DAY)), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0], new byte[0], new byte[0],
                TEST_TIME), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + ONE_DAY), new byte[0], new byte[0],
                new byte[0], TEST_TIME + ONE_DAY), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + (2 * ONE_DAY)), new byte[0],
                new byte[0], new byte[0], TEST_TIME + (2 * ONE_DAY)), EMPTY_VALUE);

        SortedKeyValueIterator<Key, Value> source = new SortedMapIterator(table);
        MetricAgeOffIterator iter = new MetricAgeOffIterator();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffIterator.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        options.put(MetricAgeOffIterator.AGE_OFF_PREFIX + ""sys.cpu.user"", Integer.toString(2 * ONE_DAY));
        iter.init(source, options, null);
        iter.seek(new Range(), columnFamilies, true);
        int seen = 0;
        while (iter.hasTop()) {
            Key k = iter.getTopKey();
            Assert.assertTrue(
                    k.getTimestamp() >= (TEST_TIME - (2 * ONE_DAY)) && k.getTimestamp() <= TEST_TIME + (2 * ONE_DAY));
            seen++;
            iter.next();
        }
        Assert.assertEquals(7, seen);

    }
"
"    @Test
    public void testSeekPastEndKey() throws Exception {
        SortedMap<Key, Value> table = new TreeMap<>();
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0], new byte[0], new byte[0],
                TEST_TIME), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 1), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 1), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 2), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 2), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 3), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 4), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 4), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 5), new byte[0], new byte[0],
                new byte[0], TEST_TIME + 5), EMPTY_VALUE);

        SortedKeyValueIterator<Key, Value> source = new SortedMapIterator(table);
        MetricAgeOffIterator iter = new MetricAgeOffIterator();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffIterator.AGE_OFF_PREFIX + ""default"", Integer.toString(1));
        iter.init(source, options, null);
        iter.seek(new Range(new Key(""sys.cpu.user""), true,
                new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0], new byte[0],
                        new byte[0], TEST_TIME + 3),
                true), columnFamilies, true);
        int seen = 0;
        while (iter.hasTop()) {
            Key k = iter.getTopKey();
            Assert.assertTrue(k.getTimestamp() >= TEST_TIME && k.getTimestamp() <= TEST_TIME + 5);
            seen++;
            iter.next();
        }
        Assert.assertEquals(0, seen);
    }
"
"    @Test(expected = IllegalArgumentException.class)
    public void testDefaultMissing() throws Exception {
        MetricAgeOffFilter filter = new MetricAgeOffFilter();
        HashMap<String, String> options = new HashMap<>();
        filter.init(null, options, null);
    }
"
"    @Test
    public void testDefault() throws Exception {
        MetricAgeOffFilter filter = new MetricAgeOffFilter();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffFilter.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        filter.init(null, options, null);
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0],
                new byte[0], new byte[0], TEST_TIME), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 1), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 1), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 2), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 2), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 3), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 4), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 4), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 5), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 5), null));
    }
"
"    @Test
    public void testMixed() throws Exception {
        MetricAgeOffFilter filter = new MetricAgeOffFilter();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffFilter.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        filter.init(null, options, null);
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME), new byte[0],
                new byte[0], new byte[0], TEST_TIME), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 1), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 1), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 2), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 2), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 3), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 3), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 4), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 4), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 5), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 5), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0],
                new byte[0], new byte[0], TEST_TIME), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 1), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 1), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 2), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 2), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 3), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 4), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 4), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 5), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 5), null));
    }
"
"    @Test
    public void testAgeoffMixed() throws Exception {
        MetricAgeOffFilter filter = new MetricAgeOffFilter();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffFilter.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        options.put(MetricAgeOffFilter.AGE_OFF_PREFIX + ""sys.cpu.user"", Integer.toString(2 * ONE_DAY));
        filter.init(null, options, null);
        assertFalse(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME - (3 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME - (3 * ONE_DAY)), null));
        assertFalse(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME - (2 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME - (2 * ONE_DAY)), null));
        assertFalse(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME - (1 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME - (1 * ONE_DAY)), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME), new byte[0],
                new byte[0], new byte[0], TEST_TIME), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + ONE_DAY), new byte[0],
                new byte[0], new byte[0], TEST_TIME + ONE_DAY), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + (2 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME + (2 * ONE_DAY)), null));
        assertFalse(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME - (3 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME - (3 * ONE_DAY)), null));
        assertFalse(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME - (2 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME - (2 * ONE_DAY)), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME - (1 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME - (1 * ONE_DAY)), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0],
                new byte[0], new byte[0], TEST_TIME), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + ONE_DAY), new byte[0],
                new byte[0], new byte[0], TEST_TIME + ONE_DAY), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + (2 * ONE_DAY)),
                new byte[0], new byte[0], new byte[0], TEST_TIME + (2 * ONE_DAY)), null));
    }
"
"    @Test
    public void testRegex1() throws Exception {
        String tags = ""tag1=value1,tag2=value2,tag3=value3"";
        StringBuffer pattern = new StringBuffer();
        pattern.append(""(^|.*,)"");
        pattern.append(""tag2"");
        pattern.append(""="");
        pattern.append(""value2"");
        pattern.append(""(,.*|$)"");
        Pattern p = Pattern.compile(pattern.toString());
        assertTrue(p.matcher(tags).matches());
    }
"
"    @Test
    public void testRegex2() throws Exception {
        String tags = ""tag1=value1,tag2=value2,tag3=value3"";
        StringBuffer pattern = new StringBuffer();
        pattern.append(""(^|.*,)"");
        pattern.append(""tag2"");
        pattern.append(""="");
        pattern.append(""value\\d"");
        pattern.append(""(,.*|$)"");
        Pattern p = Pattern.compile(pattern.toString());
        assertTrue(p.matcher(tags).matches());
    }
"
"    @Test
    public void testRegex3() throws Exception {
        String tags = ""tag1=value1,tag2=value2,tag3=value3"";
        StringBuffer pattern = new StringBuffer();
        pattern.append(""(^|.*,)"");
        pattern.append(""tag2"");
        pattern.append(""="");
        pattern.append(""(value2|value3)"");
        pattern.append(""(,.*|$)"");
        Pattern p = Pattern.compile(pattern.toString());
        assertTrue(p.matcher(tags).matches());
    }
"
"    @Test
    public void testSerialization() throws IOException, ClassNotFoundException {

        long start = System.currentTimeMillis();
        WrappedGorillaCompressor originalCompressor = new WrappedGorillaCompressor(start);
        long t = start;

        for (int x = 1; x <= 10; x++) {
            originalCompressor.addValue(t, 10);
            t = t + 1000;
        }
        originalCompressor.close();
        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
        ObjectOutputStream oos = new ObjectOutputStream(outputStream);
        oos.writeObject(originalCompressor);
        oos.close();

        ByteArrayInputStream inputStream = new ByteArrayInputStream(outputStream.toByteArray());
        ObjectInputStream ois = new ObjectInputStream(inputStream);
        WrappedGorillaCompressor copyCompressor = (WrappedGorillaCompressor) ois.readObject();

        GorillaDecompressor d = new GorillaDecompressor(new LongArrayInput(copyCompressor.getCompressorOutput()));

        LinkedList<Pair> q = new LinkedList<>();
        Pair p = null;
        while ((p = d.readPair()) != null) {
            q.add(p);
        }

        Assert.assertEquals(10, q.size());
        Assert.assertEquals(start, q.peekFirst().getTimestamp());
        Assert.assertEquals(start + 9000, q.peekLast().getTimestamp());
    }
"
"    @Test
    public void testHDFSWrite() throws Exception {

        try {
            Configuration configuration = new Configuration();
            FileSystem fs = FileSystem.get(new URI(""hdfs://localhost:8020""), configuration);
            GorillaStore store = new GorillaStore(fs, ""mymetric"", new timely.Configuration());

            long start = System.currentTimeMillis();
            WrappedGorillaCompressor originalCompressor = new WrappedGorillaCompressor(start);
            long t = start;

            for (int x = 1; x <= 10; x++) {
                originalCompressor.addValue(t, 10);
                t = t + 1000;
            }
            originalCompressor.close();

            store.writeCompressor(""mymetric"", originalCompressor);

            List<WrappedGorillaCompressor> archived = store.readCompressors(fs, new Path(""/timely/cache/mymetric""));

            for (WrappedGorillaCompressor c : archived) {

                GorillaDecompressor d = new GorillaDecompressor(new LongArrayInput(c.getCompressorOutput()));
                LinkedList<Pair> q = new LinkedList<>();
                Pair p = null;
                while ((p = d.readPair()) != null) {
                    q.add(p);
                }
            }
        } catch (Exception e) {
            System.out.println(e.getMessage());
        }
    }
"
"    @Test
    public void testDownsampleIterator() throws TimelyException {

        long BASETIME = System.currentTimeMillis();
        // align basetime to a downsample period
        BASETIME = BASETIME - (BASETIME % (1000 * 60));
        DataStoreCache mmStore = getMetricMemoryStore1(BASETIME);

        QueryRequest query = new QueryRequest();
        query.setStart(BASETIME);
        query.setEnd(BASETIME + 1440000);
        query.setMsResolution(true);
        QueryRequest.SubQuery subQuery = new QueryRequest.SubQuery();
        subQuery.setDownsample(Optional.of(""1m-avg""));
        subQuery.setMetric(""metric.number.1"");
        subQuery.addTag(""host"", "".*"");
        query.setQueries(Collections.singleton(subQuery));

        SortedKeyValueIterator<org.apache.accumulo.core.data.Key, org.apache.accumulo.core.data.Value> itr = null;
        try {
            long firstTimestamp = -1;
            long lastTimestamp = -1;
            int numSamples = 0;
            itr = mmStore.setupIterator(query, subQuery, new Authorizations(), Long.MAX_VALUE);
            while (itr.hasTop()) {
                itr.next();
                Map<Set<Tag>, Aggregation> aggregations = AggregationIterator.decodeValue(itr.getTopValue());
                for (Map.Entry<Set<Tag>, Aggregation> entry : aggregations.entrySet()) {
                    for (Sample s : entry.getValue()) {
                        numSamples++;
                        if (firstTimestamp == -1) {
                            firstTimestamp = s.timestamp;
                        }
                        lastTimestamp = s.timestamp;
                    }
                }
            }
            Assert.assertEquals(""First timestamp incorrect"", BASETIME, firstTimestamp);
            Assert.assertEquals(""Last timestamp incorrect"", BASETIME + 1440000, lastTimestamp);
            Assert.assertEquals(""Number of samples incorrect"", 50, numSamples);
        } catch (IOException | ClassNotFoundException e) {
            LOG.error(""exception in test"", e);
        }
    }
"
"    @Test
    public void testRateIterator() throws TimelyException {

        long BASETIME = System.currentTimeMillis();
        // align basetime to a downsample period
        BASETIME = BASETIME - (BASETIME % 1000);
        DataStoreCache mmStore = getMetricMemoryStore2(BASETIME);

        QueryRequest query = new QueryRequest();
        query.setStart(BASETIME);
        query.setEnd(BASETIME + 1440000);
        query.setMsResolution(true);
        QueryRequest.SubQuery subQuery = new QueryRequest.SubQuery();
        subQuery.setDownsample(Optional.of(""1ms-avg""));
        subQuery.setMetric(""metric.number.1"");
        subQuery.addTag(""host"", "".*"");
        QueryRequest.RateOption rateOption = new QueryRequest.RateOption();
        rateOption.setCounter(false);
        subQuery.setRate(true);
        subQuery.setRateOptions(rateOption);
        query.setQueries(Collections.singleton(subQuery));

        int x = 0;
        SortedKeyValueIterator<org.apache.accumulo.core.data.Key, org.apache.accumulo.core.data.Value> itr = null;
        try {
            // long firstTimestamp = Long.MAX_VALUE;
            long firstTimestamp = -1;
            long lastTimestamp = -1;
            int numSamples = 0;
            itr = mmStore.setupIterator(query, subQuery, new Authorizations(), Long.MAX_VALUE);
            while (itr.hasTop()) {
                itr.next();
                Map<Set<Tag>, Aggregation> aggregations = AggregationIterator.decodeValue(itr.getTopValue());
                for (Map.Entry<Set<Tag>, Aggregation> entry : aggregations.entrySet()) {
                    for (Sample s : entry.getValue()) {
                        numSamples++;
                        if (firstTimestamp == -1) {
                            firstTimestamp = s.timestamp;
                        }
                        lastTimestamp = s.timestamp;
                        // if (s.timestamp < firstTimestamp) {
                        // firstTimestamp = s.timestamp;
                        // }
                        // if (s.timestamp > lastTimestamp) {
                        // lastTimestamp = s.timestamp;
                        // }
                    }
                }
            }
            Assert.assertEquals(""First timestamp incorrect"", BASETIME + 1000, firstTimestamp);
            Assert.assertEquals(""Last timestamp incorrect"", BASETIME + 1440000, lastTimestamp);
            Assert.assertEquals(""Number of samples incorrect"", 2880, numSamples);
        } catch (IOException | ClassNotFoundException e) {
            LOG.error(""exception in test"", e);
        }
    }
"
"    @Test
    public void testOne() {

        GorillaStore gStore = new GorillaStore();

        long now = System.currentTimeMillis();
        gStore.addValue(now += 100, 1.123);
        gStore.addValue(now += 100, 2.314);
        gStore.addValue(now += 100, 3.856);
        gStore.addValue(now += 100, 4.7678);
        gStore.addValue(now += 100, 5.8966);
        gStore.addValue(now += 100, 6.0976);
        gStore.addValue(now += 100, 1.2345);

        List<WrappedGorillaDecompressor> decompressorList = gStore.getDecompressors(0, Long.MAX_VALUE);
        Pair pair = null;
        for (WrappedGorillaDecompressor w : decompressorList) {
            while ((pair = w.readPair()) != null) {
                System.out.println(pair.getTimestamp() + "" --> "" + pair.getDoubleValue());
            }
        }

        System.out.println(""---------------"");

        gStore.addValue(now += 100, 2.3456);
        gStore.addValue(now += 100, 3.4567);

        decompressorList = gStore.getDecompressors(0, Long.MAX_VALUE);
        pair = null;
        for (WrappedGorillaDecompressor w : decompressorList) {
            while ((pair = w.readPair()) != null) {
                System.out.println(pair.getTimestamp() + "" --> "" + pair.getDoubleValue());
            }
        }
    }
"
"    @Test
    public void testExtentOfStorage() {

        GorillaStore gStore = new GorillaStore();

        HashMap<String, String> tags = new HashMap<>();
        tags.put(""host"", ""localhost"");

        long start = System.currentTimeMillis();
        long timestamp = start;

        for (int x = 1; x <= 100; x++) {

            System.out.println(""adding value x:"" + x);
            gStore.addValue(timestamp, 2.0);
            timestamp = timestamp + 1000;

            if (x % 10 == 0) {
                gStore.archiveCurrentCompressor();
            }
            if (x < 50) {
                continue;
            }

            System.out.println(""fetching values x:"" + x);
            long totalObservations = 0;

            List<WrappedGorillaDecompressor> decompressorList = gStore.getDecompressors(start, timestamp);
            Pair pair = null;
            for (WrappedGorillaDecompressor w : decompressorList) {
                while ((pair = w.readPair()) != null) {
                    totalObservations++;
                    // System.out.println(pair.getTimestamp() + "" --> "" +
                    // pair.getDoubleValue());
                }
            }

            Assert.assertEquals(""Unexpected number of total observations"", x, totalObservations);

        }

    }
"
"    @Test
    public void testOne() throws TimelyException {

        long now = System.currentTimeMillis();
        DataStoreCache mmStore = getMetricMemoryStore1(now);

        QueryRequest query = new QueryRequest();
        query.setStart(now);
        query.setEnd(now + 100000);
        query.setMsResolution(true);
        QueryRequest.SubQuery subQuery = new QueryRequest.SubQuery();
        subQuery.setDownsample(Optional.of(""5s-avg""));
        subQuery.setMetric(""mymetric"");
        subQuery.addTag(""host"", "".*"");
        query.setQueries(Collections.singleton(subQuery));

        try {
            List<QueryResponse> responseList = mmStore.query(query);
            for (QueryResponse response : responseList) {
                System.out.println(response.toString());
            }
        } catch (TimelyException e) {
            e.printStackTrace();
        }
    }
"
"    @Test
    public void testStorage() throws TimelyException {

        long now = System.currentTimeMillis();
        DataStoreCache mmStore = getMetricMemoryStore2(now);

        QueryRequest query = new QueryRequest();
        query.setStart(now);
        query.setEnd(now + 86400000);
        query.setMsResolution(true);
        QueryRequest.SubQuery subQuery = new QueryRequest.SubQuery();
        subQuery.setDownsample(Optional.of(""5m-avg""));
        subQuery.setMetric(""metric.number.1"");
        subQuery.addTag(""host"", "".*"");
        query.setQueries(Collections.singleton(subQuery));

        try {
            List<QueryResponse> responseList = mmStore.query(query);
            for (QueryResponse response : responseList) {
                System.out.println(response.toString());
            }
        } catch (TimelyException e) {
            e.printStackTrace();
        }
    }
"
"    @Test
    public void TestExtentOfStorage() {
        DataStoreCache mmStore = new DataStoreCache(configuration);

        HashMap<String, String> tags = new HashMap<>();
        tags.put(""host"", ""localhost"");

        long start = System.currentTimeMillis();
        long timestamp = start;

        for (int x = 1; x <= 100; x++) {

            Metric m = createMetric(""test.metric"", tags, 2.0, timestamp);
            mmStore.store(m);
            mmStore.flushCaches(-1);
            timestamp = timestamp + 60000;

            QueryRequest query = new QueryRequest();
            query.setStart(start);
            query.setEnd(start + 86400000);
            query.setMsResolution(true);
            QueryRequest.SubQuery subQuery = new QueryRequest.SubQuery();
            // subQuery.setDownsample(Optional.of(""5m-avg""));
            subQuery.setMetric(""test.metric"");
            query.setQueries(Collections.singleton(subQuery));

            try {
                List<QueryResponse> responseList = mmStore.query(query);
                long totalObservations = 0;
                for (QueryResponse r : responseList) {
                    totalObservations += r.getDps().size();
                }
                Assert.assertEquals(""Unexpected number of total observations"", x, totalObservations);

            } catch (TimelyException e) {
                e.printStackTrace();
            }

        }

    }
"
"    @Test
    public void testCreateDeserialization() throws Exception {
        // @formatter:off
		String json = ""{ ""
				       + ""\""operation\"" : \""create\"",""
				       + "" \""sessionId\"": \""1234\""""
				    + ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(CreateSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((CreateSubscription) request).getSessionId());
    }
"
"    @Test
    public void testRemoveDeserialization() throws Exception {
        // @formatter:off
		String json = ""{ ""
				       + ""\""operation\"" : \""remove\"",""
				       + "" \""sessionId\"": \""1234\"",""
				       + "" \""metric\"" : \""sys.cpu.user\""""
				    + ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(RemoveSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((RemoveSubscription) request).getSessionId());
        Assert.assertEquals(""sys.cpu.user"", ((RemoveSubscription) request).getMetric());
    }
"
"    @Test
    public void testCloseDeserialization() throws Exception {
        // @formatter:off
		String json = ""{ ""
				       + ""\""operation\"" : \""close\"",""
				       + "" \""sessionId\"": \""1234\""""
				    + ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(CloseSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((CloseSubscription) request).getSessionId());
    }
"
"    @Test
    public void testAddDeserialization() throws Exception {
        // @formatter:off
		String json = ""{"" +
						""\""operation\"" : \""add\"","" +
						""\""sessionId\"" : \""1234\"","" +
					    "" \""metric\"" : \""sys.cpu.user\"""" +
					  ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(AddSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((AddSubscription) request).getSessionId());
        Assert.assertEquals(""sys.cpu.user"", ((AddSubscription) request).getMetric());
        Assert.assertEquals(false, ((AddSubscription) request).getTags().isPresent());
        Assert.assertEquals(false, ((AddSubscription) request).getStartTime().isPresent());
    }
"
"    @Test
    public void testAddDeserializationWithTime() throws Exception {
        // @formatter:off
		String json = ""{"" +
						""\""operation\"" : \""add\"","" +
						""\""sessionId\"" : \""1234\"","" +
					    ""\""metric\"" : \""sys.cpu.user\"","" +
						""\""startTime\"" : \""1000\"""" +
					  ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(AddSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((AddSubscription) request).getSessionId());
        Assert.assertEquals(""sys.cpu.user"", ((AddSubscription) request).getMetric());
        Assert.assertEquals(false, ((AddSubscription) request).getTags().isPresent());
        Assert.assertEquals(true, ((AddSubscription) request).getStartTime().isPresent());
        long time = ((AddSubscription) request).getStartTime().get();
        Assert.assertEquals(1000L, time);
    }
"
"    @Test
    public void testAddDeserializationWithTimeAndTags() throws Exception {
        // @formatter:off
		String json = ""{"" +
						""\""operation\"" : \""add\"","" +
						""\""sessionId\"" : \""1234\"","" +
					    ""\""metric\"" : \""sys.cpu.user\"","" +
						""\""tags\"" : {"" +
					       ""\""tag2\"" : \""value2\"","" +
					       ""\""tag1\"" : \""value1\"""" +
					    ""},"" +
						""\""startTime\"" : \""1000\"","" +
					    ""\""endTime\"" : \""2000\""""+
					  ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(AddSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((AddSubscription) request).getSessionId());
        Assert.assertEquals(""sys.cpu.user"", ((AddSubscription) request).getMetric());
        Assert.assertEquals(true, ((AddSubscription) request).getTags().isPresent());
        Map<String, String> tags = ((AddSubscription) request).getTags().get();
        Assert.assertTrue(tags.containsKey(""tag1""));
        Assert.assertEquals(""value1"", tags.get(""tag1""));
        Assert.assertTrue(tags.containsKey(""tag2""));
        Assert.assertEquals(""value2"", tags.get(""tag2""));
        Assert.assertEquals(true, ((AddSubscription) request).getStartTime().isPresent());
        long start = ((AddSubscription) request).getStartTime().get();
        Assert.assertEquals(1000L, start);
        Assert.assertEquals(true, ((AddSubscription) request).getEndTime().isPresent());
        long end = ((AddSubscription) request).getEndTime().get();
        Assert.assertEquals(2000L, end);
    }
"
"    @Test
    public void testAddDeserializationWithStartAndDelayTimeAndTags() throws Exception {
        // @formatter:off
		String json = ""{"" +
						""\""operation\"" : \""add\"","" +
						""\""sessionId\"" : \""1234\"","" +
					    ""\""metric\"" : \""sys.cpu.user\"","" +
						""\""tags\"" : {"" +
					       ""\""tag2\"" : \""value2\"","" +
					       ""\""tag1\"" : \""value1\"""" +
					    ""},"" +
						""\""startTime\"" : \""1000\"","" +
					    ""\""delayTime\"" : \""500\"""" +
					  ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(AddSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((AddSubscription) request).getSessionId());
        Assert.assertEquals(""sys.cpu.user"", ((AddSubscription) request).getMetric());
        Assert.assertEquals(true, ((AddSubscription) request).getTags().isPresent());
        Map<String, String> tags = ((AddSubscription) request).getTags().get();
        Assert.assertTrue(tags.containsKey(""tag1""));
        Assert.assertEquals(""value1"", tags.get(""tag1""));
        Assert.assertTrue(tags.containsKey(""tag2""));
        Assert.assertEquals(""value2"", tags.get(""tag2""));
        Assert.assertEquals(true, ((AddSubscription) request).getStartTime().isPresent());
        long time = ((AddSubscription) request).getStartTime().get();
        Assert.assertEquals(1000L, time);
        long delay = ((AddSubscription) request).getDelayTime().get();
        Assert.assertEquals(500L, delay);
    }
"
"    @Test
    public void testToKeys() {
        Meta one = new Meta(""sys.cpu.user"", ""tag1"", ""value1"");
        List<Key> keys = one.toKeys();
        Assert.assertTrue(keys.contains(new Key(""m:sys.cpu.user"")));
        Assert.assertTrue(keys.contains(new Key(""t:sys.cpu.user"", ""tag1"")));
        Assert.assertTrue(keys.contains(new Key(""v:sys.cpu.user"", ""tag1"", ""value1"")));
    }
"
"    @Test
    public void testResponse1() throws Exception {
        SearchLookupResponse response = new SearchLookupResponse();
        response.setType(""LOOKUP"");
        response.setMetric(""sys.cpu.user"");
        response.putTag(""host"", ""localhost"");
        response.putTag(""rack"", ""r1"");
        response.setTime(1500);
        List<Result> results = new ArrayList<>();
        Result r1 = new Result();
        r1.setMetric(""sys.cpu.idle"");
        r1.setTsuid(""000011000008203D00"");
        r1.putTag(""host"", ""localhost"");
        r1.putTag(""rack"", ""r1"");
        Result r2 = new Result();
        r2.setMetric(""sys.cpu.user"");
        r2.setTsuid(""000011000008203D01"");
        r2.putTag(""host"", ""localhost"");
        r2.putTag(""rack"", ""r1"");
        results.add(r1);
        results.add(r2);
        response.setResults(results);
        response.setTotalResults(results.size());
        String r = JsonUtil.getObjectMapper().writeValueAsString(response);
        String expected = ""{\""type\"":\""LOOKUP\"",\""metric\"":\""sys.cpu.user\"",\""tags\"":{\""rack\"":\""r1\"",\""host\"":\""localhost\""},\""limit\"":0,\""time\"":1500,\""totalResults\"":2,\""results\"":[{\""tags\"":{\""rack\"":\""r1\"",\""host\"":\""localhost\""},\""metric\"":\""sys.cpu.idle\"",\""tsuid\"":\""000011000008203D00\""},{\""tags\"":{\""rack\"":\""r1\"",\""host\"":\""localhost\""},\""metric\"":\""sys.cpu.user\"",\""tsuid\"":\""000011000008203D01\""}]}"";
        Assert.assertEquals(expected, r);
        SearchLookupResponse slr = JsonUtil.getObjectMapper().readValue(r, SearchLookupResponse.class);
        Assert.assertEquals(response, slr);
    }
"
"    @Test
    public void testGenerateHtml() throws Exception {
        Configuration cfg = TestConfiguration.createMinimalConfigurationForTest();
        MetaCache cache = MetaCacheFactory.getCache(cfg);
        cache.add(new Meta(""sys.cpu.user"", ""host"", ""localhost""));
        cache.add(new Meta(""sys.cpu.user"", ""instance"", ""0""));
        cache.add(new Meta(""sys.cpu.idle"", ""host"", ""localhost""));
        cache.add(new Meta(""sys.cpu.idle"", ""instance"", ""0""));
        TestMetricsResponse r = new TestMetricsResponse(cfg);
        String html = r.generateHtml().toString();
        Assert.assertTrue(html.contains(""<td>sys.cpu.idle</td>""));
        Assert.assertTrue(html.contains(""<td>host=localhost instance=0 </td>""));
        Assert.assertTrue(html.contains(""<td>sys.cpu.user</td>""));
        Assert.assertTrue(html.contains(""<td>host=localhost instance=0 </td>""));
    }
"
"    @Test
    public void testGenerateHtmlWithIgnoredTags() throws Exception {
        Configuration cfg = TestConfiguration.createMinimalConfigurationForTest();
        cfg.getMetricsReportIgnoredTags().add(""instance"");
        MetaCache cache = MetaCacheFactory.getCache(cfg);
        cache.add(new Meta(""sys.cpu.user"", ""host"", ""localhost""));
        cache.add(new Meta(""sys.cpu.user"", ""instance"", ""0""));
        cache.add(new Meta(""sys.cpu.idle"", ""host"", ""localhost""));
        cache.add(new Meta(""sys.cpu.idle"", ""instance"", ""0""));
        TestMetricsResponse r = new TestMetricsResponse(cfg);
        String html = r.generateHtml().toString();
        Assert.assertTrue(html.contains(""<td>sys.cpu.idle</td>""));
        Assert.assertTrue(html.contains(""<td>host=localhost </td>""));
        Assert.assertTrue(html.contains(""<td>sys.cpu.user</td>""));
        Assert.assertTrue(html.contains(""<td>host=localhost </td>""));
    }
"
"    @Test
    public void testSuggestResponseEmpty() throws Exception {
        SuggestResponse response = new SuggestResponse();
        String r = JsonUtil.getObjectMapper().writeValueAsString(response);
        Assert.assertEquals(""[]"", r);
    }
"
"    @Test
    public void testSuggestResponse() throws Exception {
        SuggestResponse response = new SuggestResponse();
        response.addSuggestion(""sys.cpu.idle"");
        response.addSuggestion(""sys.cpu.user"");
        String r = JsonUtil.getObjectMapper().writeValueAsString(response);
        Assert.assertEquals(""[\""sys.cpu.idle\"",\""sys.cpu.user\""]"", r);
    }
"
"    @Test
    public void testAggregatorsResponseEmpty() throws Exception {
        AggregatorsResponse response = new AggregatorsResponse();
        String r = JsonUtil.getObjectMapper().writeValueAsString(response);
        Assert.assertEquals(""[]"", r);
    }
"
"    @Test
    public void testAggregatorsResponse() throws Exception {
        AggregatorsResponse response = new AggregatorsResponse();
        response.addAggregator(""min"");
        response.addAggregator(""max"");
        String r = JsonUtil.getObjectMapper().writeValueAsString(response);
        Assert.assertEquals(""[\""min\"",\""max\""]"", r);
    }
"
"    @Test
    public void testEmptyResponse() throws Exception {
        String r = JsonUtil.getObjectMapper().writeValueAsString(Collections.emptyList());
        Assert.assertEquals(""[]"", r);
    }
"
"    @Test
    public void testOneResponse() throws Exception {
        QueryResponse r = new QueryResponse();
        r.setMetric(""sys.cpu.user"");
        r.putTag(""host"", ""localhost"");
        r.putTag(""rack"", ""r1"");
        r.putDps(""1234567890"", 4.5);
        r.putDps(""1234567900"", 3.5);
        r.putDps(""1234567910"", 2.5);
        String result = JsonUtil.getObjectMapper().writeValueAsString(Collections.singletonList(r));
        String expected = ""[{\""metric\"":\""sys.cpu.user\"",\""tags\"":{\""rack\"":\""r1\"",\""host\"":\""localhost\""},\""aggregatedTags\"":[],\""dps\"":{\""1234567890\"":4.5,\""1234567900\"":3.5,\""1234567910\"":2.5}}]"";
        Assert.assertEquals(expected, result);
    }
"
"    @Test
    public void testNumberFormat() {
        String m = ""sys.cpu.user"";
        long time = System.currentTimeMillis();
        double value = ThreadLocalRandom.current().nextDouble(0.0D, 100.0D);
        String put = MessageFormat.format(FMT, m, time, value, ""host=localhost"", ""rack=r1"");
        NumberFormat formattedDouble = DecimalFormat.getInstance();
        formattedDouble.setMaximumFractionDigits(3);
        String newValue = formattedDouble.format(value);
        Assert.assertEquals(""put sys.cpu.user "" + time + "" "" + newValue + "" host=localhost rack=r1"", put);
    }
"
"    @Test
    public void testContents() {
        Meta one = new Meta(""sys.cpu.user"", ""tag1"", ""value1"");
        Meta two = new Meta(""sys.cpu.user"", ""tag2"", ""value2"");
        Meta three = new Meta(""sys.cpu.user"", ""tag3"", ""value3"");
        MetaKeySet mks = new MetaKeySet();
        mks.addAll(one.toKeys());
        mks.addAll(two.toKeys());
        mks.addAll(three.toKeys());
        Assert.assertEquals(7, mks.size());
        Assert.assertTrue(mks.contains(new Key(""m:sys.cpu.user"")));
        Assert.assertTrue(mks.contains(new Key(""t:sys.cpu.user"", ""tag1"")));
        Assert.assertTrue(mks.contains(new Key(""t:sys.cpu.user"", ""tag2"")));
        Assert.assertTrue(mks.contains(new Key(""t:sys.cpu.user"", ""tag3"")));
        Assert.assertTrue(mks.contains(new Key(""v:sys.cpu.user"", ""tag1"", ""value1"")));
        Assert.assertTrue(mks.contains(new Key(""v:sys.cpu.user"", ""tag2"", ""value2"")));
        Assert.assertTrue(mks.contains(new Key(""v:sys.cpu.user"", ""tag3"", ""value3"")));
    }
"
"    @Test
    public void testToMutations() {
        Meta one = new Meta(""sys.cpu.user"", ""tag1"", ""value1"");
        Meta two = new Meta(""sys.cpu.user"", ""tag2"", ""value2"");
        Meta three = new Meta(""sys.cpu.user"", ""tag3"", ""value3"");
        MetaKeySet mks = new MetaKeySet();
        mks.addAll(one.toKeys());
        mks.addAll(two.toKeys());
        mks.addAll(three.toKeys());
        List<Mutation> muts = mks.toMutations();
        Mutation e1 = new Mutation(""m:sys.cpu.user"");
        e1.put("""", """", MetaKeySet.NULL_VALUE);
        Mutation e2 = new Mutation(""t:sys.cpu.user"");
        e2.put(""tag1"", """", MetaKeySet.NULL_VALUE);
        e2.put(""tag2"", """", MetaKeySet.NULL_VALUE);
        e2.put(""tag3"", """", MetaKeySet.NULL_VALUE);
        Mutation e3 = new Mutation(""v:sys.cpu.user"");
        e3.put(""tag1"", ""value1"", MetaKeySet.NULL_VALUE);
        e3.put(""tag2"", ""value2"", MetaKeySet.NULL_VALUE);
        e3.put(""tag3"", ""value3"", MetaKeySet.NULL_VALUE);
        Assert.assertEquals(3, muts.size());
        Assert.assertTrue(muts.contains(e1));
        Assert.assertTrue(muts.contains(e2));
        Assert.assertTrue(muts.contains(e3));
    }
"
"    @Test
    public void simple() {
        Aggregation asample = new Aggregation(new Avg());
        for (int i = 10; i < 30; i++) {
            asample.add(i, i - 10);
        }
        for (int i = 10; i < 30; i++) {
            asample.add(i, i);
        }
        int i = 0;
        for (Sample sample : asample) {
            assertEquals(10 + i, sample.timestamp);
            assertTrue(sample.timestamp < 30);
            assertEquals(i + 5, (int) sample.value);
            i++;
        }
        assertEquals(20, i);
        asample = new Aggregation(new Sum());
        for (int j = 0; j < 5; j++) {
            for (int k = 10; k < 100; k++) {
                asample.add(k, j + 0.);
            }
        }
        i = 0;
        for (Sample sample : asample) {
            assertEquals(10 + i, sample.timestamp);
            assertEquals((1 + 2 + 3 + 4), sample.value, 0.0D);
            i++;
        }
        assertEquals(100 - 10, i);
    }
"
"    @Test
    public void simple() {
        Downsample dsample = new Downsample(10, 30, 1, new Avg());
        for (int i = 10; i < 30; i++) {
            dsample.add(i, i - 10);
        }
        int i = 0;
        for (Sample sample : dsample) {
            assertEquals(10 + i, sample.timestamp);
            assertTrue(sample.timestamp < 30);
            assertEquals(i, (int) sample.value);
            i++;
        }
        assertEquals(20, i);
        dsample = new Downsample(10, 100, 7, new Sum());
        for (int j = 0; j < 5; j++) {
            for (int k = 10; k < 100; k++) {
                dsample.add(k, j + 0.);
            }
        }
        i = 0;
        for (Sample sample : dsample) {
            assertEquals((1 + 2 + 3 + 4) * Math.min(7, (100 - (10 + i * 7))), sample.value, 0.0D);
            assertEquals(10 + i * 7, sample.timestamp);
            i++;
        }
        assertEquals((100 - 10) / 7 + 1, i);
        dsample = new Downsample(10, 30, 10, new Avg());
        for (int j = 10; j < 30; j++) {
            for (int k = 0; k < 10; k++) {
                dsample.add(j, k + 0.);
            }
        }
        for (int j = 0; j < 100; j++) {
            dsample.add(15, 0);
        }
        i = 0;
        for (Sample sample : dsample) {
            if (i == 0) {
                assertEquals(2.25, sample.value, 0.0D);
            } else {
                assertEquals(4.5, sample.value, 0.0D);
            }
            assertEquals(10 * i + 10, sample.timestamp);
            i++;
        }
        assertEquals(2, i);
    }
"
"    @Test
    public void testCombineTrivial() throws Exception {
        Downsample ds = new Downsample(0, 1000, 100, new Avg());
        for (int i = 0; i < 1000; i += 100) {
            ds.add(i, .2);
        }
        Downsample result = Downsample.combineDownsample(Collections.singleton(ds), null);
        int count = 0;
        for (Sample s : result) {
            assertEquals(.2, s.value, 0.0D);
            count++;
        }
        assertEquals(10, count);
    }
"
"    @Test
    public void testCombineMissingReport() throws Exception {
        Downsample ds = new Downsample(0, 1000, 100, new Avg());
        for (int i = 0; i < 1000; i += 100) {
            if (i != 700) {
                ds.add(i, .2);
            }
        }
        Downsample result = Downsample.combineDownsample(Collections.singleton(ds), null);
        int count = 0;
        for (Sample s : result) {
            assertEquals(.2, s.value, 0.0D);
            count++;
        }
        assertEquals(9, count);
    }
"
"    @Test
    public void testDownsampleStartCalculation() throws Exception {
        long queryStart = System.currentTimeMillis() - 86400000;
        long period = 60000;
        long keyTimestamp = queryStart + (86400000 / 2 + 3256);

        Set<Long> expectedStartTimes = new HashSet<>();
        for (long i = queryStart; i < queryStart + 86400000; i += period) {
            expectedStartTimes.add(i);
        }
        assertEquals(1440, expectedStartTimes.size());

        long sampleStart = keyTimestamp - ((keyTimestamp - queryStart) % period);
        assertTrue(expectedStartTimes.contains(sampleStart));

    }
"
"    @Test
    public void simpleGetOneSample() throws Exception {
        // check that data gets pulled out
        AggregationIterator iter = new AggregationIterator();
        Map<Set<Tag>, Aggregation> samples = runQuery(iter, testData1, 100);
        assertEquals(1, samples.size());
        for (Entry<Set<Tag>, Aggregation> entry : samples.entrySet()) {
            Set<Tag> tags = entry.getKey();
            assertEquals(1, tags.size());
            assertEquals(Collections.singleton(new Tag(""host"", "".*"")), tags);
            long ts = 0;
            int count = 0;
            for (Sample sample : entry.getValue()) {
                assertEquals(ts, sample.timestamp);
                ts += 100;
                assertEquals(0.2, sample.value, 0.0001);
                count++;
            }
            assertEquals(1000, ts);
            assertEquals(10, count);
        }
    }
"
"    @Test
    public void simpleAggregatedSample() throws Exception {
        AggregationIterator iter = new AggregationIterator();
        Map<Set<Tag>, Aggregation> samples = runQuery(iter, testData2, 100);
        assertEquals(1, samples.size());
        for (Entry<Set<Tag>, Aggregation> entry : samples.entrySet()) {
            Set<Tag> tags = entry.getKey();
            assertEquals(1, tags.size());
            assertEquals(Collections.singleton(new Tag(""host"", "".*"")), tags);
            long ts = 0;
            int count = 0;
            for (Sample sample : entry.getValue()) {
                assertEquals(ts, sample.timestamp);
                ts += 100;
                assertEquals(count == 0 ? 0.2 : (count == 10 ? 0.5 : 0.35), sample.value, 0.0001);
                count++;
            }
            assertEquals(11, count);
        }
    }
"
"    @Test
    public void simpleGetOneSample() throws Exception {
        // check that data gets pulled out
        DownsampleIterator iter = new DownsampleIterator();
        Map<Set<Tag>, Downsample> samples = runQuery(iter, testData1, 100, -1);
        assertEquals(1, samples.size());
        for (Entry<Set<Tag>, Downsample> entry : samples.entrySet()) {
            Set<Tag> tags = entry.getKey();
            assertEquals(1, tags.size());
            assertEquals(Collections.singleton(new Tag(""host"", ""host1"")), tags);
            long ts = 0;
            for (Sample sample : entry.getValue()) {
                assertEquals(ts, sample.timestamp);
                ts += 100;
                assertEquals(0.2, sample.value, 0.0001);
            }
            assertEquals(1000, ts);
        }
    }
"
"    @Test
    public void simpleGetTwoSamples() throws Exception {
        DownsampleIterator iter = new DownsampleIterator();
        Map<Set<Tag>, Downsample> samples = runQuery(iter, testData2, 100, -1);
        assertEquals(2, samples.size());
        for (Tag tag : new Tag[] { new Tag(""host"", ""host1""), new Tag(""host"", ""host2"") }) {
            Downsample dsample = samples.get(Collections.singleton(tag));
            assertNotNull(dsample);
            long ts = 0;
            double value = .2;
            if (tag.getValue().equals(""host2"")) {
                value = .5;
            }
            int count = 0;
            for (Sample sample : dsample) {
                assertEquals(ts, sample.timestamp);
                ts += 100;
                assertEquals(value, sample.value, 0.0001);
                count++;
            }
            assertEquals(10, count);
        }
    }
"
"    @Test
    public void simpleTestDownsampling() throws Exception {
        DownsampleIterator iter = new DownsampleIterator();
        Map<Set<Tag>, Downsample> samples = runQuery(iter, testData2, 200, -1);
        assertEquals(2, samples.size());
        for (Tag tag : new Tag[] { new Tag(""host"", ""host1""), new Tag(""host"", ""host2"") }) {
            Downsample dsample = samples.get(Collections.singleton(tag));
            assertNotNull(dsample);
            long ts = 0;
            double value = .2;
            if (tag.getValue().equals(""host2"")) {
                value = .5;
            }
            int count = 0;
            for (Sample sample : dsample) {
                assertEquals(ts, sample.timestamp);
                ts += 200;
                assertEquals(value, sample.value, 0.0001);
                count++;
            }
            assertEquals(5, count);
        }
    }
"
"    @Test
    public void memoryEstimatorTestSmallObjects() {
        long maxMemory = 1000;
        long start = System.currentTimeMillis();
        long period = 500l;
        long sizeOfObjects = 20;
        SampleObject o = new SampleObject();
        DownsampleMemoryEstimator memoryEstimator = new DownsampleMemoryEstimator(maxMemory, start, period);
        boolean shouldReturn = false;
        for (long x = 100; x <= 5000; x += 100) {
            long timestamp = start + x;
            o.setSizeInBytes(o.sizeInBytes() + sizeOfObjects);
            shouldReturn = memoryEstimator.shouldReturnBasedOnMemoryUsage(timestamp, o);
            if (memoryEstimator.isNewBucket()) {
                long memoryPercentageUsedCalculated = Math.round((double) o.sizeInBytes() / maxMemory * 100);
                long memoryPercentageUsedEstimate = Math.round(memoryEstimator.getMemoryUsedPercentage());
                long percentError = Math.round(Math.abs(memoryPercentageUsedCalculated - memoryPercentageUsedEstimate)
                        / memoryPercentageUsedCalculated * 100);
                assertTrue(percentError == 0);
            }

            if (shouldReturn) {
                o.setSizeInBytes(0);
                memoryEstimator.reset();
            }
        }
        assertTrue(shouldReturn);
    }
"
"    @Test
    public void memoryEstimatorTestLargeObjects() {
        long maxMemory = 10000;
        long start = System.currentTimeMillis();
        long period = 500l;
        long sizeOfObjects = 200;
        SampleObject o = new SampleObject();
        DownsampleMemoryEstimator memoryEstimator = new DownsampleMemoryEstimator(maxMemory, start, period);
        boolean shouldReturn = false;
        for (long x = 100; x <= 5000; x += 100) {
            long timestamp = start + x;
            o.setSizeInBytes(o.sizeInBytes() + sizeOfObjects);
            shouldReturn = memoryEstimator.shouldReturnBasedOnMemoryUsage(timestamp, o);
            if (memoryEstimator.isNewBucket()) {
                long memoryPercentageUsedCalculated = Math.round((double) o.sizeInBytes() / maxMemory * 100);
                long memoryPercentageUsedEstimate = Math.round(memoryEstimator.getMemoryUsedPercentage());
                long percentError = Math.round(Math.abs(memoryPercentageUsedCalculated - memoryPercentageUsedEstimate)
                        / memoryPercentageUsedCalculated * 100);
                assertTrue(percentError == 0);
                assertTrue(memoryEstimator.isHighVolumeBuckets());
            }

            if (shouldReturn) {
                o.setSizeInBytes(0);
                memoryEstimator.reset();
            }
        }
        assertTrue(shouldReturn);
    }
"
"    @Test
    public void testDownsampleCombining() throws Exception {

        int numTagVariations = 2;
        int sampleInterval = 50;
        int elapsedTime = 100;
        int skipInterval = 10;
        SortedMap<Key, Value> testData3 = createTestData3(elapsedTime, skipInterval, numTagVariations);
        DownsampleIterator iter = new DownsampleIterator();
        Map<Set<Tag>, Downsample> samples = runQuery(iter, testData3, sampleInterval, 1000);
        assertEquals(numTagVariations, samples.size());
        long totalBuckets = 0;
        for (Entry<Set<Tag>, Downsample> entry : samples.entrySet()) {
            totalBuckets = totalBuckets + entry.getValue().getNumBuckets();
        }
        assertEquals((elapsedTime / sampleInterval) * numTagVariations, totalBuckets);
    }
"
"    @Test
    public void testVersion() throws Exception {
        final TestServer m = new TestServer(conf);
        m.run();
        try (Socket sock = new Socket(""127.0.0.1"", 54321);
                PrintWriter writer = new PrintWriter(sock.getOutputStream(), true);) {
            writer.write(""version\n"");
            writer.flush();
            while (1 != m.getTcpRequests().getCount()) {
                Thread.sleep(5);
            }
            Assert.assertEquals(1, m.getTcpRequests().getResponses().size());
            Assert.assertEquals(VersionRequest.class, m.getTcpRequests().getResponses().get(0).getClass());
            VersionRequest v = (VersionRequest) m.getTcpRequests().getResponses().get(0);
            Assert.assertEquals(VersionRequest.VERSION, v.getVersion());
        } finally {
            m.shutdown();
        }
    }
"
"    @Test
    public void testPut() throws Exception {
        final TestServer m = new TestServer(conf);
        m.run();
        try (Socket sock = new Socket(""127.0.0.1"", 54321);
                PrintWriter writer = new PrintWriter(sock.getOutputStream(), true);) {
            writer.write(""put sys.cpu.user "" + TEST_TIME + "" 1.0 tag1=value1 tag2=value2\n"");
            writer.flush();
            while (1 != m.getTcpRequests().getCount()) {
                Thread.sleep(5);
            }
            Assert.assertEquals(1, m.getTcpRequests().getResponses().size());
            Assert.assertEquals(MetricRequest.class, m.getTcpRequests().getResponses().get(0).getClass());
            final MetricRequest actual = (MetricRequest) m.getTcpRequests().getResponses().get(0);
            // @formatter:off
            final MetricRequest expected = new MetricRequest(
                    Metric.newBuilder()
                            .name(""sys.cpu.user"")
                            .value(TEST_TIME, 1.0D)
                            .tag(new Tag(""tag1"", ""value1""))
                            .tag(new Tag(""tag2"", ""value2""))
                            .build()
            );
            // @formatter on
            Assert.assertEquals(expected, actual);
        } finally {
            m.shutdown();
        }
    }
"
"    @Test
    public void testPutMultiple() throws Exception {

        final TestServer m = new TestServer(conf);
        m.run();
        try (Socket sock = new Socket(""127.0.0.1"", 54321);
                PrintWriter writer = new PrintWriter(sock.getOutputStream(), true)) {
            // @formatter:off
            writer.write(""put sys.cpu.user "" + TEST_TIME + "" 1.0 tag1=value1 tag2=value2\n""
                       + ""put sys.cpu.idle "" + (TEST_TIME + 1) + "" 1.0 tag3=value3 tag4=value4\n"");
            writer.flush();
            while (2 != m.getTcpRequests().getCount()) {
                Thread.sleep(5);
            }
            Assert.assertEquals(2, m.getTcpRequests().getResponses().size());
            Assert.assertEquals(MetricRequest.class, m.getTcpRequests().getResponses().get(0).getClass());
            MetricRequest actual = (MetricRequest) m.getTcpRequests().getResponses().get(0);
            MetricRequest expected = new MetricRequest(
                    Metric.newBuilder()
                            .name(""sys.cpu.user"")
                            .value(TEST_TIME, 1.0D)
                            .tag(new Tag(""tag1"", ""value1""))
                            .tag(new Tag(""tag2"", ""value2""))
                            .build()
            );
            Assert.assertEquals(expected, actual);

            Assert.assertEquals(MetricRequest.class, m.getTcpRequests().getResponses().get(1).getClass());
            actual = (MetricRequest) m.getTcpRequests().getResponses().get(1);
            expected = new MetricRequest(
                    Metric.newBuilder()
                        .name(""sys.cpu.idle"")
                        .value(TEST_TIME + 1, 1.0D)
                        .tag(new Tag(""tag3"", ""value3""))
                        .tag(new Tag(""tag4"", ""value4""))
                        .build()
            );
            // @formatter:on
            Assert.assertEquals(expected, actual);

        } finally {
            m.shutdown();
        }
    }
"
"    @Test
    public void testPutMultipleBinary() throws Exception {

        FlatBufferBuilder builder = new FlatBufferBuilder(1);

        int[] metric = new int[2];
        Map<String, String> t = new HashMap<>();
        t.put(""tag1"", ""value1"");
        t.put(""tag2"", ""value2"");
        metric[0] = createMetric(builder, ""sys.cpu.user"", TEST_TIME, 1.0D, t);
        t = new HashMap<>();
        t.put(""tag3"", ""value3"");
        t.put(""tag4"", ""value4"");
        metric[1] = createMetric(builder, ""sys.cpu.idle"", TEST_TIME + 1, 1.0D, t);

        int metricVector = timely.api.flatbuffer.Metrics.createMetricsVector(builder, metric);

        timely.api.flatbuffer.Metrics.startMetrics(builder);
        timely.api.flatbuffer.Metrics.addMetrics(builder, metricVector);
        int metrics = timely.api.flatbuffer.Metrics.endMetrics(builder);
        timely.api.flatbuffer.Metrics.finishMetricsBuffer(builder, metrics);

        ByteBuffer binary = builder.dataBuffer();
        byte[] data = new byte[binary.remaining()];
        binary.get(data, 0, binary.remaining());
        LOG.debug(""Sending {} bytes"", data.length);

        final TestServer m = new TestServer(conf);
        m.run();
        try (Socket sock = new Socket(""127.0.0.1"", 54321);) {
            sock.getOutputStream().write(data);
            sock.getOutputStream().flush();
            while (2 != m.getTcpRequests().getCount()) {
                LOG.debug(""Thread sleeping"");
                Thread.sleep(5);
            }
            Assert.assertEquals(2, m.getTcpRequests().getResponses().size());
            Assert.assertEquals(MetricRequest.class, m.getTcpRequests().getResponses().get(0).getClass());
            // @formatter:off
            MetricRequest actual = (MetricRequest) m.getTcpRequests().getResponses().get(0);
            MetricRequest expected = new MetricRequest(
                    Metric.newBuilder()
                            .name(""sys.cpu.user"")
                            .value(TEST_TIME, 1.0D)
                            .tag(new Tag(""tag1"", ""value1""))
                            .tag(new Tag(""tag2"", ""value2""))
                            .build()
            );
            Assert.assertEquals(expected, actual);

            Assert.assertEquals(MetricRequest.class, m.getTcpRequests().getResponses().get(1).getClass());
            actual = (MetricRequest) m.getTcpRequests().getResponses().get(1);
            expected = new MetricRequest(
                    Metric.newBuilder()
                            .name(""sys.cpu.idle"")
                            .value(TEST_TIME + 1, 1.0D)
                            .tag(new Tag(""tag3"", ""value3""))
                            .tag(new Tag(""tag4"", ""value4""))
                            .build()
            );
            // @formatter:on
            Assert.assertEquals(expected, actual);

        } finally {
            m.shutdown();
        }
    }
"
"    @Test
    public void testPutInvalidTimestamp() throws Exception {
        final TestServer m = new TestServer(conf);
        m.run();
        try (Socket sock = new Socket(""127.0.0.1"", 54321);
                PrintWriter writer = new PrintWriter(sock.getOutputStream(), true);
                BufferedReader reader = new BufferedReader(new InputStreamReader(sock.getInputStream()));) {
            writer.write(""put sys.cpu.user "" + TEST_TIME + ""Z"" + "" 1.0 tag1=value1 tag2=value2\n"");
            writer.flush();
            sleepUninterruptibly(WAIT_SECONDS, TimeUnit.SECONDS);
            Assert.assertEquals(0, m.getTcpRequests().getCount());
        } finally {
            m.shutdown();
        }
    }
"
"    @Test
    public void testPersistence() throws Exception {
        final Server s = new Server(conf);
        s.run();
        try {
            put(""sys.cpu.user "" + TEST_TIME + "" 1.0 tag1=value1 tag2=value2"",
                    ""sys.cpu.idle "" + (TEST_TIME + 1) + "" 1.0 tag3=value3 tag4=value4"",
                    ""sys.cpu.idle "" + (TEST_TIME + 2) + "" 1.0 tag3=value3 tag4=value4"");
            sleepUninterruptibly(WAIT_SECONDS, TimeUnit.SECONDS);
        } finally {
            s.shutdown();
        }
        final ZooKeeperInstance inst = new ZooKeeperInstance(mac.getClientConfig());
        final Connector connector = inst.getConnector(""root"", new PasswordToken(""secret"".getBytes(UTF_8)));
        assertTrue(connector.namespaceOperations().exists(""timely""));
        assertTrue(connector.tableOperations().exists(""timely.metrics""));
        assertTrue(connector.tableOperations().exists(""timely.meta""));
        int count = 0;
        for (final Entry<Key, Value> entry : connector.createScanner(""timely.metrics"", Authorizations.EMPTY)) {
            LOG.info(""Entry: "" + entry);
            final double value = ByteBuffer.wrap(entry.getValue().get()).getDouble();
            assertEquals(1.0, value, 1e-9);
            count++;
        }
        assertEquals(6, count);
        count = 0;
        for (final Entry<Key, Value> entry : connector.createScanner(""timely.meta"", Authorizations.EMPTY)) {
            LOG.info(""Meta entry: "" + entry);
            count++;
        }
        assertEquals(10, count);
        // count w/out versioning iterator to make sure that the optimization
        // for writing is working
        connector.tableOperations().removeIterator(""timely.meta"", ""vers"", EnumSet.of(IteratorScope.scan));
        // wait for zookeeper propagation
        sleepUninterruptibly(WAIT_SECONDS, TimeUnit.SECONDS);
        count = 0;
        for (final Entry<Key, Value> entry : connector.createScanner(""timely.meta"", Authorizations.EMPTY)) {
            LOG.info(""Meta no vers iter: "" + entry);
            count++;
        }
        assertEquals(10, count);
    }
"
"    @TestAnnotation(""libcore.java.lang.OldClassTest$ExtendTestClass"")
        public void setCount(int value) {

        }
"
"    @TestAnnotation(""libcore.java.lang.OldClassTest$PublicTestClass"")
        public Object getLocalClass() {
            class LocalClass {}
            Object returnedObject = new LocalClass();
            return returnedObject;
        }
"
"        @TestAnno
        public void annotatedMethod(){}

"
"  @Test
  public void shouldCollectToList() {
    // given
    final RecordingExporter exporter = new RecordingExporter();
    exporter.export(new TestRecord(1));
    exporter.export(new TestRecord(2));
    exporter.export(new TestRecord(3));

    // when
    final List<Record<TestValue>> list =
        records(VALUE_TYPE, TestValue.class).collect(Collectors.toList());

    // then
    assertThat(list).extracting(Record::getPosition).containsExactly(1L, 2L, 3L);
  }
"
"  @Test
  public void shouldReadConfiguration() {
    // when
    final SampleConfiguration actual =
        sutConfigurationFactory.create(
            null,
            ""config-test"",
            ""TestConfigurationFactoryTestSample.yaml"",
            SampleConfiguration.class);

    // then
    assertThat(actual.getSetting()).isEqualTo(""test"");
    assertThat(actual.getTimeout()).isEqualTo(Duration.ofSeconds(3));
    assertThat(actual.getSize()).isEqualTo(DataSize.ofMegabytes(2));
    assertThat(actual.getArgs()).containsOnly(entry(""foo"", ""bar""));
  }
"
"  @Test
  public void shouldReadEmptyConfiguration()
      throws InvocationTargetException, NoSuchMethodException, InstantiationException,
"
"  @Test
  public void shouldOverlayEnvironmentSettingsOverConfigurationReadFromFile()
      throws InvocationTargetException, NoSuchMethodException, InstantiationException,
"
"  @Test
  public void shouldSkipElementsBasedOnPredicate() {
    // given
    final Stream<Integer> stream = Stream.of(1, 2, 3, 4, 5);
    final IntegerStream wrapper = new IntegerStream(stream);

    // when
    final List<Integer> result = wrapper.skipUntil(i -> i == 3).asList();

    // then
    assertThat(result).containsExactly(3, 4, 5);
  }
"
"  @Test
  public void shouldReadMsgPack() {
    // given
    final ByteArrayBuilder builder = new ByteArrayBuilder();
    given.accept(builder);

    final byte[] givenBytes = builder.value;
    final DirectBuffer buf = new UnsafeBuffer(givenBytes);

    final MsgPackReader reader = new MsgPackReader();
    reader.wrap(buf, 0, buf.capacity());

    // when/then
    assertion.accept(reader);
    assertThat(reader.getOffset()).isEqualTo(givenBytes.length);
  }
"
"  @Test
  public void testEncodedMapHeaderLength() {
    assertThat(MsgPackWriter.getEncodedMapHeaderLenght(0x0f)).isEqualTo(1);
    assertThat(MsgPackWriter.getEncodedMapHeaderLenght(0xffff)).isEqualTo(3);
    assertThat(MsgPackWriter.getEncodedMapHeaderLenght(0x7fff_ffff)).isEqualTo(5);
  }
"
"  @Test
  public void testEncodedArayHeaderLength() {
    assertThat(MsgPackWriter.getEncodedArrayHeaderLenght(0x0f)).isEqualTo(1);
    assertThat(MsgPackWriter.getEncodedArrayHeaderLenght(0xffff)).isEqualTo(3);
    assertThat(MsgPackWriter.getEncodedArrayHeaderLenght(0x7fff_ffff)).isEqualTo(5);
  }
"
"  @Test
  public void testEncodedBinaryValueLength() {
    assertThat(MsgPackWriter.getEncodedBinaryValueLength(0xff)).isEqualTo(2 + 0xff);
    assertThat(MsgPackWriter.getEncodedBinaryValueLength(0xffff)).isEqualTo(3 + 0xffff);
    assertThat(MsgPackWriter.getEncodedBinaryValueLength(0x7fff_fffa)).isEqualTo(5 + 0x7fff_fffa);
  }
"
"  @Test
  public void testEncodedBooleanValueLength() {
    assertThat(MsgPackWriter.getEncodedBooleanValueLength()).isEqualTo(1);
  }
"
"  @Test
  public void testEncodedLongValueLength() {
    assertThat(MsgPackWriter.getEncodedLongValueLength(0x7f)).isEqualTo(1);
    assertThat(MsgPackWriter.getEncodedLongValueLength(0xff)).isEqualTo(2);
    assertThat(MsgPackWriter.getEncodedLongValueLength(0xffff)).isEqualTo(3);
    assertThat(MsgPackWriter.getEncodedLongValueLength(0xffff_ffffL)).isEqualTo(5);
    assertThat(MsgPackWriter.getEncodedLongValueLength(0x7fff_ffff_ffff_ffffL)).isEqualTo(9);
    assertThat(MsgPackWriter.getEncodedLongValueLength(-0x20)).isEqualTo(1);
    assertThat(MsgPackWriter.getEncodedLongValueLength(Byte.MIN_VALUE)).isEqualTo(2);
    assertThat(MsgPackWriter.getEncodedLongValueLength(Short.MIN_VALUE)).isEqualTo(3);
    assertThat(MsgPackWriter.getEncodedLongValueLength(Integer.MIN_VALUE)).isEqualTo(5);
    assertThat(MsgPackWriter.getEncodedLongValueLength(Long.MIN_VALUE)).isEqualTo(9);
  }
"
"  @Test
  public void testEncodedStringHeaderLength() {
    assertThat(MsgPackWriter.getEncodedStringHeaderLength(0x1f)).isEqualTo(1);
    assertThat(MsgPackWriter.getEncodedStringHeaderLength(0xff)).isEqualTo(2);
    assertThat(MsgPackWriter.getEncodedStringHeaderLength(0xffff)).isEqualTo(3);
    assertThat(MsgPackWriter.getEncodedStringHeaderLength(0x7fff_ffff)).isEqualTo(5);
  }
"
"  @Test
  public void testEncodedStringLength() {
    assertThat(MsgPackWriter.getEncodedStringLength(0x1f)).isEqualTo(1 + 0x1f);
    assertThat(MsgPackWriter.getEncodedStringLength(0xff)).isEqualTo(2 + 0xff);
    assertThat(MsgPackWriter.getEncodedStringLength(0xffff)).isEqualTo(3 + 0xffff);
    assertThat(MsgPackWriter.getEncodedStringLength(0x7fff_fffa)).isEqualTo(5 + 0x7fff_fffa);
  }
"
"  @Test
  public void testWriteMessage() throws Exception {
    // given
    final MsgPackWriter writer = new MsgPackWriter();
    writer.wrap(actualValueBuffer, WRITE_OFFSET);

    final ByteArrayBuilder builder = new ByteArrayBuilder();
    expectedValueWriter.accept(builder);
    final byte[] expectedValue = builder.value;

    // when
    actualValueWriter.accept(writer);

    // then
    assertThat(writer.getOffset()).isEqualTo(WRITE_OFFSET + expectedValue.length);
    assertThatBuffer(actualValueBuffer).hasBytes(expectedValue, WRITE_OFFSET);
  }
"
"  @Test
  public void skipValue() {
    // given
    final ByteArrayBuilder builder = new ByteArrayBuilder();
    given.accept(builder);

    final DirectBuffer buffer = new UnsafeBuffer(builder.value);

    final MsgPackReader reader = new MsgPackReader();
    reader.wrap(buffer, 0, buffer.capacity());

    // when
    reader.skipValue();

    // then
    assertThat(reader.getOffset()).isEqualTo(buffer.capacity());
  }
"
"  @Test
  public void shouldReadToken() {
    // given
    final MsgPackReader reader = new MsgPackReader();
    final ByteArrayBuilder builder = new ByteArrayBuilder();
    given.accept(builder);
    final DirectBuffer buf = new UnsafeBuffer(builder.value);
    reader.wrap(buf, 0, buf.capacity());

    // when
    final MsgPackToken msgPackToken = reader.readToken();

    // then
    assertThat(reader.getOffset()).isEqualTo(buf.capacity());
    assertThat(msgPackToken.getType()).isEqualTo(expectedType);
    assertion.accept(msgPackToken);
  }
"
"  @Test
  public void shouldNotReadNegativeSize() throws Exception {
    // given
    final MsgPackWriter writer = new MsgPackWriter();
    writer.wrap(actualValueBuffer, WRITE_OFFSET);

    // then
    exception.expect(MsgpackWriterException.class);
    exception.expectMessage(expectedExceptionMessage);

    // when
    codeUnderTest.accept(writer);
  }
"
"  @Test
  public void shouldNotReadNegativeValue() {
    // given
    final DirectBuffer negativeTestingBuf = new UnsafeBuffer(testingBuf);
    reader.wrap(negativeTestingBuf, 0, negativeTestingBuf.capacity());

    // then
    exception.expect(MsgpackReaderException.class);
    exception.expectMessage(exceptionMessage);

    // when
    codeUnderTest.accept(reader);
  }
"
"  @Test
  public void shouldNotReadInvalidSequence() {
    // given
    reader.wrap(NEVER_USED_BUF, 0, NEVER_USED_BUF.capacity());

    // then
    exception.expect(MsgpackReaderException.class);
    exception.expectMessage(expectedExceptionMessage);

    // when
    codeUnderTest.accept(reader);
  }
"
"  @Test
  public void shouldExportJobRecordWithCustomHeaders() {
    // when
    exporterBrokerRule.deployProcess(
        Bpmn.createExecutableProcess(""process"")
            .startEvent()
            .serviceTask(
                ""task"",
                t -> t.zeebeJobType(""test"").zeebeTaskHeader(""x"", ""1"").zeebeTaskHeader(""y"", ""2""))
            .endEvent()
            .done(),
        ""process.bpmn"");

    final var processInstanceKey = exporterBrokerRule.createProcessInstance(""process"", Map.of());

    // then
    await(""index templates need to be created"").untilAsserted(this::assertIndexSettings);
    final var jobCreated =
        RecordingExporter.jobRecords(JobIntent.CREATED)
            .withProcessInstanceKey(processInstanceKey)
            .getFirst();

    assertRecordExported(jobCreated);
  }
"
"  @Test
  public void shouldExportJobRecordWithOverlappingCustomHeaders() {
    // when
    exporterBrokerRule.deployProcess(
        Bpmn.createExecutableProcess(""process"")
            .startEvent()
            .serviceTask(
                ""task"",
                t -> t.zeebeJobType(""test"").zeebeTaskHeader(""x"", ""1"").zeebeTaskHeader(""x.y"", ""2""))
            .endEvent()
            .done(),
        ""process.bpmn"");

    final var processInstanceKey = exporterBrokerRule.createProcessInstance(""process"", Map.of());

    // then
    await(""index templates need to be created"").untilAsserted(this::assertIndexSettings);
    final var jobCreated =
        RecordingExporter.jobRecords(JobIntent.CREATED)
            .withProcessInstanceKey(processInstanceKey)
            .getFirst();

    assertRecordExported(jobCreated);
  }
"
"  @Test
  public void shouldExportJobBatchRecordWithOverlappingCustomHeaders() {
    // when
    exporterBrokerRule.deployProcess(
        Bpmn.createExecutableProcess(""process"")
            .startEvent()
            .serviceTask(
                ""task"",
                t -> t.zeebeJobType(""test"").zeebeTaskHeader(""x"", ""1"").zeebeTaskHeader(""x.y"", ""2""))
            .endEvent()
            .done(),
        ""process.bpmn"");

    final var processInstanceKey = exporterBrokerRule.createProcessInstance(""process"", Map.of());

    await(""index templates need to be created"").untilAsserted(this::assertIndexSettings);
    final var jobCreated =
        RecordingExporter.jobRecords(JobIntent.CREATED)
            .withProcessInstanceKey(processInstanceKey)
            .getFirst();

    jobWorker =
        exporterBrokerRule.createJobWorker(
            ""test"", ((client, job) -> client.newCompleteCommand(job.getKey()).send()));

    // then
    final var jobBatchActivated =
        RecordingExporter.jobBatchRecords(JobBatchIntent.ACTIVATED).withType(""test"").getFirst();

    assertThat(jobBatchActivated.getValue().getJobKeys()).contains(jobCreated.getKey());
    assertRecordExported(jobBatchActivated);
  }
"
"  @Test
  public void shouldExportEvenIfElasticNotInitiallyReachable() {
    // given
    elastic.withPort(SocketUtil.getNextAddress().getPort());
    configuration = getDefaultConfiguration();
    configuration.index.prefix = ""zeebe"";
    esClient = createElasticsearchClient(configuration);

    // when
    exporterBrokerRule.configure(""es"", ElasticsearchExporter.class, configuration);
    exporterBrokerRule.start();
    exporterBrokerRule.publishMessage(""message"", ""123"");
    elastic.start();

    // then
    RecordingExporter.messageRecords()
        .withCorrelationKey(""123"")
        .withName(""message"")
        .forEach(r -> TestUtil.waitUntil(() -> wasExported(r)));
    assertIndexSettings();
  }
"
"  @Test
  public void shouldNotFailOnOpenIfElasticIsUnreachable() {
    // given
    final ElasticsearchClient client =
        Mockito.spy(new ElasticsearchClient(config, LoggerFactory.getLogger(""test"")));
    final ElasticsearchExporter exporter = createExporter(client);
    config.index.createTemplate = true;

    // when - then : only fails when trying to export, not before
    openExporter(exporter);
    assertThatThrownBy(testHarness::export).isInstanceOf(ElasticsearchExporterException.class);
  }
"
"  @Test
  public void shouldCreateIndexTemplates() {
    // given
    config.index.prefix = ""foo-bar"";
    config.index.createTemplate = true;
    config.index.deployment = true;
    config.index.process = true;
    config.index.error = true;
    config.index.incident = true;
    config.index.job = true;
    config.index.jobBatch = true;
    config.index.message = true;
    config.index.messageSubscription = true;
    config.index.variable = true;
    config.index.variableDocument = true;
    config.index.processInstance = true;
    config.index.processInstanceCreation = true;
    config.index.processMessageSubscription = true;

    // when
    createAndOpenExporter();
    testHarness.export();

    // then
    verify(esClient).putComponentTemplate(""foo-bar"", ""foo-bar"", ZEEBE_RECORD_TEMPLATE_JSON);

    verify(esClient).putIndexTemplate(ValueType.DEPLOYMENT);
    verify(esClient).putIndexTemplate(ValueType.PROCESS);
    verify(esClient).putIndexTemplate(ValueType.ERROR);
    verify(esClient).putIndexTemplate(ValueType.INCIDENT);
    verify(esClient).putIndexTemplate(ValueType.JOB);
    verify(esClient).putIndexTemplate(ValueType.JOB_BATCH);
    verify(esClient).putIndexTemplate(ValueType.MESSAGE);
    verify(esClient).putIndexTemplate(ValueType.MESSAGE_SUBSCRIPTION);
    verify(esClient).putIndexTemplate(ValueType.VARIABLE);
    verify(esClient).putIndexTemplate(ValueType.VARIABLE_DOCUMENT);
    verify(esClient).putIndexTemplate(ValueType.PROCESS_INSTANCE);
    verify(esClient).putIndexTemplate(ValueType.PROCESS_INSTANCE_CREATION);
    verify(esClient).putIndexTemplate(ValueType.PROCESS_MESSAGE_SUBSCRIPTION);
  }
"
"  @Test
  public void shouldExportEnabledValueTypes() {
    // given
    config.index.event = true;
    config.index.deployment = true;
    config.index.process = true;
    config.index.error = true;
    config.index.incident = true;
    config.index.job = true;
    config.index.jobBatch = true;
    config.index.message = true;
    config.index.messageSubscription = true;
    config.index.variable = true;
    config.index.variableDocument = true;
    config.index.processInstance = true;
    config.index.processInstanceCreation = true;
    config.index.processMessageSubscription = true;

    createAndOpenExporter();

    final ValueType[] valueTypes =
        new ValueType[] {
          ValueType.DEPLOYMENT,
          ValueType.PROCESS,
          ValueType.ERROR,
          ValueType.INCIDENT,
          ValueType.JOB,
          ValueType.JOB_BATCH,
          ValueType.MESSAGE,
          ValueType.MESSAGE_SUBSCRIPTION,
          ValueType.VARIABLE,
          ValueType.VARIABLE_DOCUMENT,
          ValueType.PROCESS_INSTANCE,
          ValueType.PROCESS_INSTANCE_CREATION,
          ValueType.PROCESS_MESSAGE_SUBSCRIPTION
        };

    // when - then
    final Context.RecordFilter filter = testHarness.getContext().getFilter();

    assertThat(Arrays.stream(valueTypes).map(filter::acceptValue)).containsOnly(true);
  }
"
"  @Test
  public void shouldNotExportDisabledValueTypes() {
    // given
    config.index.event = true;
    config.index.deployment = false;
    config.index.error = false;
    config.index.incident = false;
    config.index.job = false;
    config.index.jobBatch = false;
    config.index.message = false;
    config.index.messageSubscription = false;
    config.index.variable = false;
    config.index.variableDocument = false;
    config.index.processInstance = false;
    config.index.processInstanceCreation = false;
    config.index.processMessageSubscription = false;

    createAndOpenExporter();

    final ValueType[] valueTypes =
        new ValueType[] {
          ValueType.DEPLOYMENT,
          ValueType.ERROR,
          ValueType.INCIDENT,
          ValueType.JOB,
          ValueType.JOB_BATCH,
          ValueType.MESSAGE,
          ValueType.MESSAGE_SUBSCRIPTION,
          ValueType.VARIABLE,
          ValueType.VARIABLE_DOCUMENT,
          ValueType.PROCESS_INSTANCE,
          ValueType.PROCESS_INSTANCE_CREATION,
          ValueType.PROCESS_MESSAGE_SUBSCRIPTION
        };

    // when - then
    final Context.RecordFilter filter = testHarness.getContext().getFilter();

    assertThat(Arrays.stream(valueTypes).map(filter::acceptValue)).containsOnly(false);
  }
"
"  @Test
  public void shouldExportEnabledRecordTypes() {
    // given
    config.index.command = true;
    config.index.event = true;
    config.index.rejection = true;
    config.index.deployment = true;

    createAndOpenExporter();

    final RecordType[] recordTypes =
        new RecordType[] {RecordType.COMMAND, RecordType.EVENT, RecordType.COMMAND_REJECTION};

    // when - then
    final Context.RecordFilter filter = testHarness.getContext().getFilter();

    assertThat(Arrays.stream(recordTypes).map(filter::acceptType)).containsOnly(true);
  }
"
"  @Test
  public void shouldNotExportDisabledRecordTypes() {
    // given
    config.index.command = false;
    config.index.event = false;
    config.index.rejection = false;
    config.index.deployment = true;

    createAndOpenExporter();

    final RecordType[] recordTypes =
        new RecordType[] {RecordType.COMMAND, RecordType.EVENT, RecordType.COMMAND_REJECTION};

    // when - then
    final Context.RecordFilter filter = testHarness.getContext().getFilter();

    assertThat(Arrays.stream(recordTypes).map(filter::acceptType)).containsOnly(false);
  }
"
"  @Test
  public void shouldUpdateLastPositionOnFlush() {
    // given
    when(esClient.shouldFlush()).thenReturn(true);

    // when
    createAndOpenExporter();
    final Record record =
        testHarness.export(
            r ->
                r.getMetadata()
                    .setValueType(ValueType.PROCESS_INSTANCE)
                    .setRecordType(RecordType.EVENT));

    // then
    assertThat(testHarness.getController().getPosition()).isEqualTo(record.getPosition());
  }
"
"  @Test
  public void shouldFlushOnClose() {
    // given
    createAndOpenExporter();

    // when
    testHarness.close();

    // then
    verify(esClient).flush();
  }
"
"  @Test
  public void shouldFlushAfterDelay() {
    // given
    config.index.event = true;
    config.index.processInstance = true;
    config.bulk.delay = 10;

    // scenario: bulk size is not reached still we want to flush
    config.bulk.size = Integer.MAX_VALUE;
    when(esClient.shouldFlush()).thenReturn(false);
    createAndOpenExporter();

    // when
    testHarness.export(
        r ->
            r.getMetadata()
                .setValueType(ValueType.PROCESS_INSTANCE)
                .setRecordType(RecordType.EVENT));

    // then
    assertThat(testHarness.getController().getScheduledTasks()).hasSize(1);
    assertThat(testHarness.getController().getScheduledTasks().get(0).getDelay())
        .isEqualTo(Duration.ofSeconds(config.bulk.delay));

    // and
    testHarness.getController().runScheduledTasks(Duration.ofSeconds(config.bulk.delay));
    verify(esClient).flush();
  }
"
"  @Test
  public void shouldUpdatePositionAfterDelay() {
    // given
    config.index.event = true;
    createAndOpenExporter();

    // when
    final List<Record> exported =
        testHarness.stream(
                r ->
                    r.getMetadata()
                        .setValueType(ValueType.PROCESS_INSTANCE)
                        .setRecordType(RecordType.EVENT))
            .export(4);
    testHarness.getController().runScheduledTasks(Duration.ofSeconds(config.bulk.delay));

    // then record was indexed and the exporter record position was updated
    verify(esClient, times(4)).index(any());
    assertThat(testHarness.getController().getPosition()).isEqualTo(exported.get(3).getPosition());
  }
"
"  @Test
  public void shouldNotHandleFlushException() {
    // given
    when(esClient.shouldFlush()).thenReturn(true);
    doThrow(new ElasticsearchExporterException(""expected"")).when(esClient).flush();

    createAndOpenExporter();

    // when
    assertThatThrownBy(() -> testHarness.export())
        .isInstanceOf(ElasticsearchExporterException.class)
        .withFailMessage(""expected"");

    // then
    verify(esClient, times(1)).flush();
  }
"
"  @Test
  public void shouldFailOnWrongPrefix() {
    // given
    config.index.prefix = ""prefix_withunderscore"";

    createExporterAndTestHarness();

    // then
    assertThatThrownBy(() -> testHarness.configure(""els"", config))
        .isInstanceOf(ExporterException.class)
        .withFailMessage(
            ""Elasticsearch prefix must not contain underscore. Current value: ""
                + config.index.prefix);
  }
"
"  @Test
  public void shouldExportRecords() {
    // given
    elasticConfigurator.accept(elastic);
    elastic.start();

    // given
    configuration = getDefaultConfiguration();
    exporterConfigurator.accept(configuration);

    // when
    exporterBrokerRule.configure(""es"", ElasticsearchExporter.class, configuration);
    exporterBrokerRule.start();
    exporterBrokerRule.performSampleWorkload();

    // then

    // assert index settings for all created indices
    esClient = createElasticsearchClient(configuration);
    assertIndexSettings();

    // assert all records which where recorded during the tests where exported
    exporterBrokerRule.visitExportedRecords(
        r -> {
          if (configuration.shouldIndexRecord(r)) {
            assertRecordExported(r);
          }
        });
  }
"
"  @Test
  public void shouldThrowExceptionIfFailToFlushBulk() {
    // given
    final int bulkSize = 10;

    final Record<VariableRecordValue> recordMock = mock(Record.class);
    when(recordMock.getPartitionId()).thenReturn(1);
    when(recordMock.getValueType()).thenReturn(ValueType.PROCESS_INSTANCE);

    // bulk contains records that fail on flush
    IntStream.range(0, bulkSize)
        .forEach(
            i -> {
              when(recordMock.getKey()).thenReturn(RECORD_KEY + i);
              when(recordMock.toJson()).thenReturn(""invalid-json-"" + i);
              client.index(recordMock);
            });

    // and one valid record
    when(recordMock.getKey()).thenReturn(RECORD_KEY + bulkSize);
    when(recordMock.toJson()).thenReturn(""{}"");
    client.index(recordMock);

    // when/then
    assertThatThrownBy(client::flush)
        .isInstanceOf(ElasticsearchExporterException.class)
        .hasMessageContaining(
            ""Failed to flush 10 item(s) of bulk request [type: mapper_parsing_exception, reason: failed to parse]"");
  }
"
"  @Test
  public void shouldIgnoreRecordIfDuplicateOfLast() {
    // given
    final Record<VariableRecordValue> recordMock = mock(Record.class);
    when(recordMock.getPartitionId()).thenReturn(1);
    when(recordMock.getValueType()).thenReturn(ValueType.PROCESS_INSTANCE);
    when(recordMock.getKey()).thenReturn(RECORD_KEY + 1);
    when(recordMock.toJson()).thenReturn(""{}"");

    client.index(recordMock);
    assertThat(bulkRequest).hasSize(1);

    // when
    client.index(recordMock);

    // then
    assertThat(bulkRequest).hasSize(1);
  }
"
"  @Test
  public void shouldFlushOnMemoryLimit() {
    // given
    final var bulkMemoryLimit = 1024;
    final var recordSize = 2;

    configuration.bulk.memoryLimit = bulkMemoryLimit;
    configuration.bulk.size = Integer.MAX_VALUE;
    configuration.bulk.delay = Integer.MAX_VALUE;

    final var variableValue1 = ""x"".repeat(bulkMemoryLimit / recordSize);
    final var variableValue2 = ""y"".repeat(bulkMemoryLimit / recordSize);
    final Function<String, String> jsonRecord =
        (String value) -> String.format(""{\""value\"":\""%s\""}"", value);

    final VariableRecordValue recordValue = mock(VariableRecordValue.class);
    when(recordValue.getValue()).thenReturn(variableValue1);

    final Record<VariableRecordValue> recordMock = mock(Record.class);
    when(recordMock.getKey()).thenReturn(1L);
    when(recordMock.getPartitionId()).thenReturn(1);
    when(recordMock.getValueType()).thenReturn(ValueType.VARIABLE);
    when(recordMock.getValue()).thenReturn(recordValue);
    when(recordMock.toJson()).thenReturn(jsonRecord.apply(variableValue1));

    // when
    client.index(recordMock);

    assertThat(client.shouldFlush()).isFalse();

    when(recordMock.getKey()).thenReturn(2L);
    when(recordMock.toJson()).thenReturn(jsonRecord.apply(variableValue2));

    client.index(recordMock);

    // then
    assertThat(client.shouldFlush()).isTrue();
  }
"
"  @Test
  public void shouldGetSubscriptionHashCode() {
    assertThat(getSubscriptionHashCode(wrapString(""a""))).isEqualTo(97);
    assertThat(getSubscriptionHashCode(wrapString(""b""))).isEqualTo(98);
    assertThat(getSubscriptionHashCode(wrapString(""c""))).isEqualTo(99);
    assertThat(getSubscriptionHashCode(wrapString(""foobar""))).isEqualTo(-1268878963);
  }
"
"  @Test
  public void shouldGetZeroSubscriptionHashCodeIfEmpty() {
    assertThat(getSubscriptionHashCode(new UnsafeBuffer())).isEqualTo(0);
  }
"
"  @Test
  public void shouldGetPartitionIdForCorrelationKey() {
    assertThat(getSubscriptionPartitionId(wrapString(""a""), 10)).isEqualTo(7 + START_PARTITION_ID);
    assertThat(getSubscriptionPartitionId(wrapString(""b""), 3)).isEqualTo(2 + START_PARTITION_ID);
    assertThat(getSubscriptionPartitionId(wrapString(""c""), 11)).isEqualTo(0 + START_PARTITION_ID);
    assertThat(getSubscriptionPartitionId(wrapString(""foobar""), 100))
        .isEqualTo(63 + START_PARTITION_ID);
  }
"
"  @Test
  public void shouldConvertJsonSerializableToJson() {
    // given

    // when
    final String json = actualRecordSupplier.get().toJson();

    // then
    JsonUtil.assertEquality(json, expectedJson);
  }
"
"  @Test
  public void shouldEncodeDecodeBrokerInfo() {
    // given
    final int nodeId = 123;
    final int partitionsCount = 345;
    final int clusterSize = 567;
    final int replicationFactor = 789;
    final Map<DirectBuffer, DirectBuffer> addresses = new HashMap<>();
    addresses.put(wrapString(""foo""), wrapString(""192.159.12.1:23""));
    addresses.put(wrapString(""bar""), wrapString(""zeebe-0.cluster.loc:12312""));
    final Map<Integer, PartitionRole> partitionRoles = new HashMap<>();
    partitionRoles.put(1, PartitionRole.FOLLOWER);
    partitionRoles.put(2, PartitionRole.LEADER);
    partitionRoles.put(231, PartitionRole.FOLLOWER);
    final Map<Integer, PartitionHealthStatus> partitionHealthStatuses = new HashMap<>();
    partitionHealthStatuses.put(1, PartitionHealthStatus.HEALTHY);
    partitionHealthStatuses.put(2, PartitionHealthStatus.UNHEALTHY);
    partitionHealthStatuses.put(123, PartitionHealthStatus.HEALTHY);

    final BrokerInfo brokerInfo =
        new BrokerInfo()
            .setNodeId(nodeId)
            .setPartitionsCount(partitionsCount)
            .setClusterSize(clusterSize)
            .setReplicationFactor(replicationFactor);

    addresses.forEach(brokerInfo::addAddress);
    partitionRoles.forEach(brokerInfo::addPartitionRole);
    partitionHealthStatuses.forEach(brokerInfo::addPartitionHealth);

    // when
    encodeDecode(brokerInfo);

    // then
    assertThat(brokerInfo.getNodeId()).isEqualTo(nodeId);
    assertThat(brokerInfo.getPartitionsCount()).isEqualTo(partitionsCount);
    assertThat(brokerInfo.getClusterSize()).isEqualTo(clusterSize);
    assertThat(brokerInfo.getReplicationFactor()).isEqualTo(replicationFactor);
    assertThat(brokerInfo.getAddresses()).containsAllEntriesOf(addresses);
    assertThat(brokerInfo.getPartitionRoles()).containsAllEntriesOf(partitionRoles);
    assertThat(brokerInfo.getPartitionHealthStatuses())
        .containsAllEntriesOf(partitionHealthStatuses);
  }
"
"  @Test
  public void shouldEncodeDecodeBrokerInfoWithEmptyMaps() {
    // given
    final int nodeId = 123;
    final int partitionsCount = 345;
    final int clusterSize = 567;
    final int replicationFactor = 789;

    final BrokerInfo brokerInfo =
        new BrokerInfo()
            .setNodeId(nodeId)
            .setPartitionsCount(partitionsCount)
            .setClusterSize(clusterSize)
            .setReplicationFactor(replicationFactor);

    // when
    encodeDecode(brokerInfo);

    // then
    assertThat(brokerInfo.getNodeId()).isEqualTo(nodeId);
    assertThat(brokerInfo.getPartitionsCount()).isEqualTo(partitionsCount);
    assertThat(brokerInfo.getClusterSize()).isEqualTo(clusterSize);
    assertThat(brokerInfo.getReplicationFactor()).isEqualTo(replicationFactor);
    assertThat(brokerInfo.getAddresses()).isEmpty();
    assertThat(brokerInfo.getPartitionRoles()).isEmpty();
    assertThat(brokerInfo.getPartitionHealthStatuses()).isEmpty();
  }
"
"  @Test
  public void shouldEncodeDecodeNullValues() {
    // given
    final BrokerInfo brokerInfo = new BrokerInfo();

    // when
    encodeDecode(brokerInfo);

    // then
    assertThat(brokerInfo.getNodeId()).isEqualTo(BrokerInfoEncoder.nodeIdNullValue());
    assertThat(brokerInfo.getPartitionsCount())
        .isEqualTo(BrokerInfoEncoder.partitionsCountNullValue());
    assertThat(brokerInfo.getClusterSize()).isEqualTo(BrokerInfoEncoder.clusterSizeNullValue());
    assertThat(brokerInfo.getReplicationFactor())
        .isEqualTo(BrokerInfoEncoder.replicationFactorNullValue());
    assertThat(brokerInfo.getAddresses()).isEmpty();
    assertThat(brokerInfo.getPartitionRoles()).isEmpty();
    assertThat(brokerInfo.getPartitionHealthStatuses()).isEmpty();
  }
"
"  @Test
  public void shouldSerializePOJO() {
    // given
    final POJOArray pojo = new POJOArray();
    final ValueArray<MinimalPOJO> iterator1 = pojo.simpleArray();
    iterator1.add().setLongProp(123L);
    iterator1.add().setLongProp(456L);
    iterator1.add().setLongProp(789L);

    final int writeLength = pojo.getLength();

    // when
    final UnsafeBuffer resultBuffer = new UnsafeBuffer(new byte[writeLength]);
    pojo.write(resultBuffer, 0);

    // then
    final Map<String, Object> msgPackMap =
        MsgPackUtil.asMap(resultBuffer, 0, resultBuffer.capacity());
    assertThat(msgPackMap)
        .containsOnly(entry(""simpleArray"", ""[{longProp=123}, {longProp=456}, {longProp=789}]""));
  }
"
"  @Test
  public void shouldSerializePOJOWithEmptyArray() {
    // given
    final POJOArray pojo = new POJOArray();

    final int writeLength = pojo.getLength();

    // when
    final UnsafeBuffer resultBuffer = new UnsafeBuffer(new byte[writeLength]);
    pojo.write(resultBuffer, 0);

    // then
    final Map<String, Object> msgPackMap =
        MsgPackUtil.asMap(resultBuffer, 0, resultBuffer.capacity());
    assertThat(msgPackMap).containsOnly(entry(""simpleArray"", ""[]""));
  }
"
"  @Test
  public void shouldSerializePOJOAfterReset() {
    // given
    final POJOArray pojo = new POJOArray();
    pojo.simpleArray().add().setLongProp(124);
    pojo.reset();

    final int writeLength = pojo.getLength();

    // when
    final UnsafeBuffer resultBuffer = new UnsafeBuffer(new byte[writeLength]);
    pojo.write(resultBuffer, 0);

    // then
    final Map<String, Object> msgPackMap =
        MsgPackUtil.asMap(resultBuffer, 0, resultBuffer.capacity());
    assertThat(msgPackMap).containsOnly(entry(""simpleArray"", ""[]""));
  }
"
"  @Test
  public void shouldSerializePOJOWithDefaultValues() {
    // given
    final POJOArray pojo = new POJOArray();
    final ValueArray<MinimalPOJO> iterator1 = pojo.simpleArray();
    iterator1.add().setLongProp(123L);

    final int writeLength = pojo.getLength();

    // when
    final UnsafeBuffer resultBuffer = new UnsafeBuffer(new byte[writeLength]);
    pojo.write(resultBuffer, 0);

    // then
    final Map<String, Object> msgPackMap =
        MsgPackUtil.asMap(resultBuffer, 0, resultBuffer.capacity());
    assertThat(msgPackMap).containsOnly(entry(""simpleArray"", ""[{longProp=123}]""));
  }
"
"  @Test
  public void shouldSerializeAfterPartiallyReadEntries() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    pojo.wrap(buffer);
    final Iterator<MinimalPOJO> iterator = pojo.simpleArray().iterator();
    iterator.next();
    iterator.next();
    iterator.next();

    final int writeLength = pojo.getLength();

    // when
    final UnsafeBuffer pojoBuffer = new UnsafeBuffer(new byte[writeLength]);
    pojo.write(pojoBuffer, 0);

    // then
    final Map<String, Object> msgPackMap = MsgPackUtil.asMap(pojoBuffer, 0, pojoBuffer.capacity());
    assertThat(msgPackMap)
        .containsOnly(
            entry(
                ""simpleArray"",
                ""[{longProp=123}, {longProp=456}, {longProp=789}, {longProp=555}, {longProp=777}]""));
  }
"
"  @Test
  public void shouldNotSerializeRemovedEntry() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    pojo.wrap(buffer);
    final Iterator<MinimalPOJO> iterator = pojo.simpleArray().iterator();
    iterator.next();
    iterator.next();
    iterator.next();

    // when
    iterator.remove();

    // then
    final int writeLength = pojo.getLength();
    final UnsafeBuffer pojoBuffer = new UnsafeBuffer(new byte[writeLength]);
    pojo.write(pojoBuffer, 0);

    final Map<String, Object> msgPackMap = MsgPackUtil.asMap(pojoBuffer, 0, pojoBuffer.capacity());
    assertThat(msgPackMap)
        .containsOnly(
            entry(
                ""simpleArray"", ""[{longProp=123}, {longProp=456}, {longProp=555}, {longProp=777}]""));
  }
"
"  @Test
  public void shouldSerializeAppendedEntry() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    pojo.wrap(buffer);
    final Iterator<MinimalPOJO> iterator = pojo.simpleArray().iterator();
    iterator.next();
    iterator.next();
    iterator.next();
    iterator.next();
    iterator.next();

    // when
    pojo.simpleArray().add().setLongProp(999L);

    // then
    final int writeLength = pojo.getLength();
    final UnsafeBuffer pojoBuffer = new UnsafeBuffer(new byte[writeLength]);
    pojo.write(pojoBuffer, 0);

    final Map<String, Object> msgPackMap = MsgPackUtil.asMap(pojoBuffer, 0, pojoBuffer.capacity());
    assertThat(msgPackMap)
        .containsOnly(
            entry(
                ""simpleArray"",
                ""[{longProp=123}, {longProp=456}, {longProp=789}, {longProp=555}, {longProp=777}, {longProp=999}]""));
  }
"
"  @Test
  public void shouldSerializeInbetweenAddedEntry() {
    // given
    final POJOArray pojo = new POJOArray();
    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    pojo.wrap(buffer);
    final Iterator<MinimalPOJO> iterator = pojo.simpleArray().iterator();
    iterator.next();
    iterator.next();
    iterator.next();

    // when
    pojo.simpleArrayProp.add().setLongProp(999L);

    // then
    final int writeLength = pojo.getLength();
    final UnsafeBuffer pojoBuffer = new UnsafeBuffer(new byte[writeLength]);
    pojo.write(pojoBuffer, 0);

    final Map<String, Object> msgPackMap = MsgPackUtil.asMap(pojoBuffer, 0, pojoBuffer.capacity());
    assertThat(msgPackMap)
        .containsOnly(
            entry(
                ""simpleArray"",
                ""[{longProp=123}, {longProp=456}, {longProp=789}, {longProp=999}, {longProp=555}, {longProp=777}]""));
  }
"
"  @Test
  public void shouldDeserializePOJO() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(3);
              encodeSimpleArrayProp(w);

              w.writeString(wrapString(""emptyDefaultArray""));
              w.writeArrayHeader(1);

              w.writeMapHeader(1);
              w.writeString(wrapString(""longProp""));
              w.writeInteger(753L);

              w.writeString(wrapString(""notEmptyDefaultArray""));
              w.writeArrayHeader(0);
            });

    // when
    pojo.wrap(buffer);

    // then
    final Iterator<MinimalPOJO> iterator1 = pojo.simpleArray().iterator();
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(123L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(456L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(789L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(555L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(777L);
    assertThat(iterator1.hasNext()).isFalse();
  }
"
"  @Test
  public void shouldDeserializePOJOWithDefaultValues() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    // when
    pojo.wrap(buffer);

    // then
    final Iterator<MinimalPOJO> iterator1 = pojo.simpleArray().iterator();
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(123L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(456L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(789L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(555L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(777L);
    assertThat(iterator1.hasNext()).isFalse();
  }
"
"  @Test
  public void shouldFailOnInitialRemove() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    pojo.wrap(buffer);
    final Iterator<MinimalPOJO> iterator = pojo.simpleArray().iterator();

    // then
    exception.expect(IllegalStateException.class);

    // when
    iterator.remove();
  }
"
"  @Test
  public void shouldFailOnRemovingEntryTwice() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    pojo.wrap(buffer);
    final Iterator<MinimalPOJO> iterator = pojo.simpleArray().iterator();
    iterator.next();
    iterator.remove();

    // then
    exception.expect(IllegalStateException.class);

    // when
    iterator.remove();
  }
"
"  @Test
  public void shouldFailOnRemovingWhenEntryHasBeenAddedBefore() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    pojo.wrap(buffer);
    final Iterator<MinimalPOJO> iterator = pojo.simpleArray().iterator();
    iterator.next();
    pojo.simpleArray().add().setLongProp(999L);

    // then
    exception.expect(IllegalStateException.class);

    // when
    iterator.remove();
  }
"
"  @Test
  public void shouldAddFirstEntryToSimpleArrayProp() {
    // given
    final POJOArray pojo = new POJOArray();
    final ValueArray<MinimalPOJO> iterator = pojo.simpleArray();

    // when
    iterator.add().setLongProp(741L);

    // then
    final int length = pojo.getLength();
    final UnsafeBuffer resultBuffer = new UnsafeBuffer(new byte[length]);
    pojo.write(resultBuffer, 0);

    final Map<String, Object> msgPackMap =
        MsgPackUtil.asMap(resultBuffer, 0, resultBuffer.capacity());
    assertThat(msgPackMap).containsOnly(entry(""simpleArray"", ""[{longProp=741}]""));
  }
"
"  @Test
  public void shouldIterateOverModifiedArray() {
    // given
    final POJOArray pojo = new POJOArray();
    final ValueArray<MinimalPOJO> array = pojo.simpleArray();

    // when
    array.add().setLongProp(123L);

    // then
    final Iterator<MinimalPOJO> iterator = array.iterator();
    assertThat(iterator.hasNext()).isTrue();
    assertThat(iterator.next().getLongProp()).isEqualTo(123L);
    assertThat(iterator.hasNext()).isFalse();
  }
"
"  @Test
  public void shouldDeserializePOJOWithUndeclaredProperties() {
    // given
    final MinimalPOJO pojo = new MinimalPOJO();

    // when
    pojo.wrap(MSG_PACK);

    // then
    assertThat(pojo.getLongProp()).isEqualTo(123L);
  }
"
"  @Test
  public void shouldIncludeUndeclaredPropertiesInLengthEstimation() {
    // given
    final MinimalPOJO pojo = new MinimalPOJO();
    pojo.wrap(MSG_PACK);

    // when
    final long writeLength = pojo.getLength();

    // then
    assertThat(writeLength).isEqualTo(MSG_PACK.capacity());
  }
"
"  @Test
  public void shouldSerializeUndeclaredProperties() {
    // given
    final MinimalPOJO pojo = new MinimalPOJO();
    pojo.wrap(MSG_PACK);

    final MutableDirectBuffer writeBuffer = new UnsafeBuffer(new byte[pojo.getLength()]);

    // when
    pojo.write(writeBuffer, 0);

    // then
    final Map<String, Object> serialized = asMap(writeBuffer, 0, writeBuffer.capacity());

    assertThat(serialized).hasSize(2);
    assertThat(serialized).contains(entry(""longProp"", 123L), entry(""undeclaredProp"", 456L));
  }
"
"  @Test
  public void shouldDropUndeclaredPropertiesOnReset() {
    // given
    final MinimalPOJO pojo = new MinimalPOJO();
    pojo.wrap(MSG_PACK);

    final MutableDirectBuffer writeBuffer = new UnsafeBuffer(new byte[pojo.getLength()]);

    // when
    pojo.reset();

    // then
    pojo.wrap(
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              w.writeString(wrapString(""longProp""));
              w.writeInteger(123L);
            }));
    pojo.write(writeBuffer, 0);

    final Map<String, Object> serialized = asMap(writeBuffer, 0, writeBuffer.capacity());
    assertThat(serialized).containsExactly(entry(""longProp"", 123L));
  }
"
"  @Test
  public void shouldFailReadingInvalidUndeclaredProperty() {
    // given
    final MinimalPOJO pojo = new MinimalPOJO();

    final MutableDirectBuffer msgPack =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(2);
              w.writeString(wrapString(""longProp""));
              w.writeInteger(123L);
              w.writeInteger(789L);
              w.writeInteger(123L);
            });

    // then
    exception.expect(RuntimeException.class);
    exception.expectMessage(""Could not deserialize object"");

    // when
    pojo.wrap(msgPack);
  }
"
"    @Test
    public void shouldResetObjectBeforeReadingValue() {
      // given
      final var property = new StringProperty(""property"", ""default"");
      final var unpackedObject = new UnpackedObject();

      unpackedObject.declareProperty(property);

      final var buffer = new UnsafeBuffer(ByteBuffer.allocate(100));

      unpackedObject.write(buffer, 0);

      final var spyUnpackedObject = spy(unpackedObject);

      // when
      spyUnpackedObject.wrap(buffer);

      // then
      final var orderOfInvocations = Mockito.inOrder(spyUnpackedObject);
      orderOfInvocations.verify(spyUnpackedObject).reset();
      orderOfInvocations.verify(spyUnpackedObject).read(Mockito.any());
    }
"
"    @Test
    public void newPropertiesShouldHaveDefaultValueAfterReadingOldSerialization() {
      // given

      // set the new property to a value that is different from the default value
      addedProperty.setValue(true);

      // when
      newSchemaObject.wrap(bufferSerializedWithOldSchema);

      // then
      assertThat(addedProperty.getValue())
          .describedAs(""value of added property after reading"")
          .isFalse();
    }
"
"    @Test
    public void shouldNotAccumulateSizeWithUndeclaredProperties() {

      // given
      newSchemaObject.wrap(bufferSerializedWithOldSchema);
      final int length = newSchemaObject.getLength();

      final var buffer = new UnsafeBuffer(ByteBuffer.allocate(100));
      newSchemaObject.write(buffer, 0);

      // when
      newSchemaObject.wrap(buffer);

      // then
      assertThat(newSchemaObject.getLength()).isEqualTo(length);
    }
"
"  @Test
  public void shouldReturnDefaultValueForMissingProperty() {
    // given
    final MutableDirectBuffer msgPackBuffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              w.writeString(wrapString(""noDefaultValueProp""));
              w.writeInteger(123123L);
            });

    final long defaultValue = -1L;
    final DefaultValuesPOJO pojo = new DefaultValuesPOJO(defaultValue);

    // when
    pojo.wrap(msgPackBuffer);

    // then
    assertThat(pojo.getNoDefaultValueProperty()).isEqualTo(123123L);
    assertThat(pojo.getDefaultValueProperty()).isEqualTo(defaultValue);
  }
"
"  @Test
  public void shouldNotReturnDefaultValueForExistingProperty() {
    // given
    final MutableDirectBuffer msgPackBuffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(2);
              w.writeString(wrapString(""noDefaultValueProp""));
              w.writeInteger(123123L);
              w.writeString(wrapString(""defaultValueProp""));
              w.writeInteger(987L);
            });

    final long defaultValue = -1L;
    final DefaultValuesPOJO pojo = new DefaultValuesPOJO(defaultValue);

    // when
    pojo.wrap(msgPackBuffer);

    // then
    assertThat(pojo.getNoDefaultValueProperty()).isEqualTo(123123L);
    assertThat(pojo.getDefaultValueProperty()).isEqualTo(987L);
  }
"
"  @Test
  public void shouldReturnDefaultValueAfterReset() {
    // given
    final MutableDirectBuffer msgPackBuffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(2);
              w.writeString(wrapString(""noDefaultValueProp""));
              w.writeInteger(123123L);
              w.writeString(wrapString(""defaultValueProp""));
              w.writeInteger(987L);
            });

    final long defaultValue = -1L;
    final DefaultValuesPOJO pojo = new DefaultValuesPOJO(defaultValue);
    pojo.wrap(msgPackBuffer);

    // when
    pojo.reset();

    // then
    assertThat(pojo.getDefaultValueProperty()).isEqualTo(defaultValue);
  }
"
"  @Test
  public void shouldWriteDefaultValue() {
    // given
    final long defaultValue = -1L;
    final DefaultValuesPOJO pojo = new DefaultValuesPOJO(defaultValue);
    pojo.setNoDefaultValueProperty(123123L);

    final UnsafeBuffer buf = new UnsafeBuffer(new byte[pojo.getLength()]);

    // when
    pojo.write(buf, 0);

    // then
    final MsgPackReader reader = new MsgPackReader();
    reader.wrap(buf, 0, buf.capacity());
    final Map<String, Object> msgPackMap = MsgPackUtil.asMap(buf, 0, buf.capacity());

    assertThat(msgPackMap).hasSize(2);
    assertThat(msgPackMap)
        .contains(entry(""noDefaultValueProp"", 123123L), entry(""defaultValueProp"", defaultValue));
  }
"
"  @Test
  public void shouldSupportDefaultValuesForAllPropertyTypes() {
    // given
    final MutableDirectBuffer msgPackBuffer = encodeMsgPack((w) -> w.writeMapHeader(0));

    final MutableDirectBuffer packedMsgPackBuffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              w.writeInteger(123L);
              w.writeInteger(456L);
            });

    final AllTypesDefaultValuesPOJO pojo =
        new AllTypesDefaultValuesPOJO(
            POJOEnum.FOO,
            654L,
            123,
            ""defaultString"",
            packedMsgPackBuffer,
            wrapString(""defaultBinary""),
            new POJONested());

    // when
    pojo.wrap(msgPackBuffer);

    // then
    assertThat(pojo.getEnum()).isEqualTo(POJOEnum.FOO);
    assertThat(pojo.getLong()).isEqualTo(654L);
    assertThat(pojo.getInt()).isEqualTo(123);
    assertThatBuffer(pojo.getString()).hasBytes(wrapString(""defaultString""));
    assertThatBuffer(pojo.getPacked()).hasBytes(packedMsgPackBuffer);
    assertThatBuffer(pojo.getBinary()).hasBytes(wrapString(""defaultBinary""));
    assertThat(pojo.getNestedObject().getLong()).isEqualTo(-1L);
  }
"
"  @Test
  public void shouldSerializePOJO() {
    // given
    final POJO pojo = new POJO();
    pojo.setEnum(POJOEnum.BAR);
    pojo.setLong(456456L);
    pojo.setInt(123);
    pojo.setString(BUF1);
    pojo.setBinary(BUF2);
    pojo.setPacked(MSGPACK_BUF1);

    pojo.nestedObject().setLong(24L);

    final int writeLength = pojo.getLength();

    // when
    final UnsafeBuffer resultBuffer = new UnsafeBuffer(new byte[writeLength]);
    pojo.write(resultBuffer, 0);

    // then
    final Map<String, Object> msgPackMap =
        MsgPackUtil.asMap(resultBuffer, 0, resultBuffer.capacity());
    assertThat(msgPackMap).hasSize(7);
    assertThat(msgPackMap)
        .contains(
            entry(""enumProp"", POJOEnum.BAR.toString()),
            entry(""longProp"", 456456L),
            entry(""intProp"", 123L),
            entry(""stringProp"", ""foo""),
            entry(""binaryProp"", BUF2.byteArray()));

    final Map<String, Object> packedProp = (Map<String, Object>) msgPackMap.get(""packedProp"");
    assertThat(packedProp).containsExactly(entry(""foo"", 123123L));

    final Map<String, Object> objectProp = (Map<String, Object>) msgPackMap.get(""objectProp"");
    assertThat(objectProp).containsExactly(entry(""foo"", 24L));
  }
"
"  @Test
  public void shouldDeserializePOJO() {
    // given
    final POJO pojo = new POJO();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(7);

              w.writeString(wrapString(""enumProp""));
              w.writeString(wrapString(POJOEnum.BAR.toString()));

              w.writeString(wrapString(""binaryProp""));
              w.writeBinary(BUF1);

              w.writeString(wrapString(""stringProp""));
              w.writeString(BUF2);

              w.writeString(wrapString(""packedProp""));
              w.writeRaw(MSGPACK_BUF1);

              w.writeString(wrapString(""longProp""));
              w.writeInteger(88888L);

              w.writeString(wrapString(""intProp""));
              w.writeInteger(123L);

              w.writeString(wrapString(""objectProp""));
              w.writeRaw(MSGPACK_BUF1);
            });

    // when
    pojo.wrap(buffer);

    // then
    assertThat(pojo.getEnum()).isEqualByComparingTo(POJOEnum.BAR);
    assertThat(pojo.getLong()).isEqualTo(88888L);
    assertThat(pojo.getInt()).isEqualTo(123);
    assertThatBuffer(pojo.getPacked()).hasBytes(MSGPACK_BUF1);
    assertThatBuffer(pojo.getBinary()).hasBytes(BUF1);
    assertThatBuffer(pojo.getString()).hasBytes(BUF2);
    assertThat(pojo.nestedObject().getLong()).isEqualTo(123123L);
  }
"
"  @Test
  public void shouldNotDeserializePOJOWithWrongValueType() {
    // given
    final POJO pojo = new POJO();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);

              w.writeString(wrapString(""stringProp""));
              w.writeFloat(123123.123123d);
            });

    // then
    exception.expect(RuntimeException.class);
    exception.expectMessage(
        ""Could not deserialize object [POJO]. Deserialization stuck at offset 13"");

    // when
    pojo.wrap(buffer);
  }
"
"  @Test
  public void shouldNotDeserializePOJOWithWrongKeyType() {
    // given
    final POJO pojo = new POJO();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);

              w.writeInteger(123123L);
              w.writeFloat(123123.123123d);
            });

    // then
    exception.expect(RuntimeException.class);
    exception.expectMessage(
        ""Could not deserialize object [POJO]. Deserialization stuck at offset 2"");

    // when
    pojo.wrap(buffer);
  }
"
"  @Test
  public void shouldNotDeserializePOJOFromNonMap() {
    // given
    final POJO pojo = new POJO();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeString(wrapString(""stringProp""));
              w.writeFloat(123123.123123d);
            });

    // then
    exception.expect(RuntimeException.class);
    exception.expectMessage(
        ""Could not deserialize object [POJO]. Deserialization stuck at offset 1"");

    // when
    pojo.wrap(buffer);
  }
"
"  @Test
  public void shouldFailDeserializationWithMissingRequiredValues() {
    // given
    final POJO pojo = new POJO();

    final DirectBuffer buf1 = encodeMsgPack((w) -> w.writeMapHeader(0));

    // when
    final Throwable error = catchThrowable(() -> pojo.wrap(buf1));

    // then
    assertThat(error)
        .isInstanceOf(RuntimeException.class)
        .hasMessageContaining(""Could not deserialize object"")
        .hasCause(new RuntimeException(""Property 'enumProp' has no valid value""));
  }
"
"  @Test
  public void shouldFailDeserializationWithOversizedIntegerValue() {
    // given
    final POJO pojo = new POJO();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);

              w.writeString(wrapString(""intProp""));
              w.writeInteger(Integer.MAX_VALUE + 1L);
            });

    // then
    exception.expect(RuntimeException.class);
    exception.expectMessage(""Could not deserialize object"");

    // when
    pojo.wrap(buffer);
  }
"
"  @Test
  public void shouldFailDeserializationWithUndersizedIntegerValue() {
    // given
    final POJO pojo = new POJO();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(6);

              w.writeString(wrapString(""enumProp""));
              w.writeString(wrapString(POJOEnum.BAR.toString()));

              w.writeString(wrapString(""binaryProp""));
              w.writeBinary(BUF1);

              w.writeString(wrapString(""stringProp""));
              w.writeString(BUF2);

              w.writeString(wrapString(""packedProp""));
              w.writeRaw(MSGPACK_BUF1);

              w.writeString(wrapString(""longProp""));
              w.writeInteger(88888L);

              w.writeString(wrapString(""intProp""));
              w.writeInteger(Integer.MIN_VALUE - 1L);
            });

    // then
    exception.expect(RuntimeException.class);
    exception.expectMessage(""Could not deserialize object"");

    // when
    pojo.wrap(buffer);
  }
"
"  @Test
  public void shouldFailSerializationWithMissingRequiredValues() {
    // given
    final POJO pojo = new POJO();

    final UnsafeBuffer buf = new UnsafeBuffer(new byte[1024]);

    // then
    exception.expect(MsgpackPropertyException.class);
    exception.expectMessage(
        ""Property 'enumProp' is invalid: Expected a value or default value to be set before writing, but has nothing"");

    // when
    pojo.write(buf, 0);
  }
"
"  @Test
  public void shouldFailLengthEstimationWithMissingRequiredValues() {
    // given
    final POJO pojo = new POJO();

    // then
    exception.expect(MsgpackPropertyException.class);
    exception.expectMessage(
        ""Property 'enumProp' is invalid: Expected a value or default value to be specified, but has nothing"");

    // when
    pojo.getLength();
  }
"
"  @Test
  public void shouldDeserializeWithReusedPOJO() {
    // given
    final POJO pojo = new POJO();

    final DirectBuffer buf1 =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(7);

              w.writeString(wrapString(""enumProp""));
              w.writeString(wrapString(POJOEnum.BAR.toString()));

              w.writeString(wrapString(""binaryProp""));
              w.writeBinary(BUF1);

              w.writeString(wrapString(""stringProp""));
              w.writeString(BUF2);

              w.writeString(wrapString(""packedProp""));
              w.writeRaw(MSGPACK_BUF1);

              w.writeString(wrapString(""longProp""));
              w.writeInteger(88888L);

              w.writeString(wrapString(""intProp""));
              w.writeInteger(123);

              w.writeString(wrapString(""objectProp""));
              w.writeRaw(MSGPACK_BUF1);
            });
    pojo.wrap(buf1);

    final DirectBuffer buf2 =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(7);

              w.writeString(wrapString(""enumProp""));
              w.writeString(wrapString(POJOEnum.FOO.toString()));

              w.writeString(wrapString(""binaryProp""));
              w.writeBinary(BUF2);

              w.writeString(wrapString(""stringProp""));
              w.writeString(BUF1);

              w.writeString(wrapString(""packedProp""));
              w.writeRaw(MSGPACK_BUF2);

              w.writeString(wrapString(""longProp""));
              w.writeInteger(7777L);

              w.writeString(wrapString(""intProp""));
              w.writeInteger(456);

              w.writeString(wrapString(""objectProp""));
              w.writeRaw(MSGPACK_BUF3);
            });

    // when
    pojo.reset();
    pojo.wrap(buf2);

    // then
    assertThat(pojo.getEnum()).isEqualByComparingTo(POJOEnum.FOO);
    assertThat(pojo.getLong()).isEqualTo(7777L);
    assertThat(pojo.getInt()).isEqualTo(456);
    assertThatBuffer(pojo.getPacked()).hasBytes(MSGPACK_BUF2);
    assertThatBuffer(pojo.getBinary()).hasBytes(BUF2);
    assertThatBuffer(pojo.getString()).hasBytes(BUF1);
    assertThat(pojo.nestedObject().getLong()).isEqualTo(24L);
  }
"
"  @Test
  public void shouldAppendValues() {
    // when
    addIntValues(array, 1, 2, 3);

    // then
    encodeAndDecode(array);
    assertIntValues(array, 1, 2, 3);
  }
"
"  @Test
  public void shouldAddValueAtBeginning() {
    // given
    addIntValues(array, 1, 2, 3);

    // when
    // reset iterator to append at beginning
    array.iterator();
    addIntValues(array, 4, 5, 6);

    // then
    encodeAndDecode(array);
    assertIntValues(array, 4, 5, 6, 1, 2, 3);
  }
"
"  @Test
  public void shouldAddValueInBetween() {
    // given
    addIntValues(array, 1, 2, 3);

    // when
    final Iterator<IntegerValue> iterator = array.iterator();
    iterator.next();
    addIntValues(array, 4, 5, 6);

    // then
    encodeAndDecode(array);
    assertIntValues(array, 1, 4, 5, 6, 2, 3);
  }
"
"  @Test
  public void shouldAddValuesAtEndAfterRead() {
    // given
    addIntValues(array, 1, 2, 3);

    // when
    final Iterator<IntegerValue> iterator = array.iterator();
    iterator.next();
    iterator.next();
    iterator.next();
    addIntValues(array, 4, 5, 6);

    // then
    encodeAndDecode(array);
    assertIntValues(array, 1, 2, 3, 4, 5, 6);
  }
"
"  @Test
  public void shouldUpdateValues() {
    // given
    addIntValues(array, 1, 2, 3);

    // when
    final Iterator<IntegerValue> iterator = array.iterator();
    iterator.next().setValue(4);
    iterator.next().setValue(5);
    iterator.next().setValue(6);

    // then
    encodeAndDecode(array);
    assertIntValues(array, 4, 5, 6);
  }
"
"  @Test
  public void shouldSerializeValuesAfterPartialRead() {
    // given
    addIntValues(array, 1, 2, 3);

    // when
    final Iterator<IntegerValue> iterator = array.iterator();
    iterator.next();
    iterator.next();

    // then
    encodeAndDecode(array);
    assertIntValues(array, 1, 2, 3);
  }
"
"  @Test
  public void shouldRemoveValueAtBeginning() {
    // given
    addIntValues(array, 1, 2, 3);

    // when
    final Iterator<IntegerValue> iterator = array.iterator();
    iterator.next();
    iterator.remove();

    // then
    encodeAndDecode(array);
    assertIntValues(array, 2, 3);
  }
"
"  @Test
  public void shouldRemoveValueInBetween() {
    // given
    addIntValues(array, 1, 2, 3);

    // when
    final Iterator<IntegerValue> iterator = array.iterator();
    iterator.next();
    iterator.next();
    iterator.remove();

    // then
    encodeAndDecode(array);
    assertIntValues(array, 1, 3);
  }
"
"  @Test
  public void shouldRemoveValueAtEnd() {
    // given
    addIntValues(array, 1, 2, 3);

    // when
    final Iterator<IntegerValue> iterator = array.iterator();
    iterator.next();
    iterator.next();
    iterator.next();
    iterator.remove();

    // then
    encodeAndDecode(array);
    assertIntValues(array, 1, 2);
  }
"
"  @Test
  public void shouldRemoveAllValues() {
    // given
    addIntValues(array, 1, 2, 3);

    // when
    final Iterator<IntegerValue> iterator = array.iterator();
    iterator.next();
    iterator.remove();
    iterator.next();
    iterator.remove();
    iterator.next();
    iterator.remove();

    // then
    encodeAndDecode(array);
    assertIntValues(array);
  }
"
"  @Test
  public void shouldNotInvalidElementOnRemove() {
    // given
    addIntValues(array, 1, 2, 3);

    // when
    final Iterator<IntegerValue> iterator = array.iterator();
    final IntegerValue element = iterator.next();
    iterator.remove();

    // then
    assertThat(element.getValue()).isEqualTo(1);
    encodeAndDecode(array);
    assertIntValues(array, 2, 3);
  }
"
"  @Test
  public void shouldUpdateWithSmallerValue() {
    // given
    final ArrayValue<StringValue> array = new ArrayValue<>(new StringValue());
    addStringValues(array, ""foo"", ""bar"", ""baz"");

    // when
    final Iterator<StringValue> iterator = array.iterator();
    StringValue element = iterator.next();
    element.wrap(BufferUtil.wrapString(""a""));
    element = iterator.next();
    element.wrap(BufferUtil.wrapString(""b""));
    element = iterator.next();
    element.wrap(BufferUtil.wrapString(""c""));

    // then
    encodeAndDecode(array);
    assertStringValues(array, ""a"", ""b"", ""c"");
  }
"
"  @Test
  public void shouldUpdateWithBiggerValue() {
    // given
    final ArrayValue<StringValue> array = new ArrayValue<>(new StringValue());
    addStringValues(array, ""foo"", ""bar"", ""baz"");

    // when
    final Iterator<StringValue> iterator = array.iterator();
    StringValue element = iterator.next();
    element.wrap(BufferUtil.wrapString(""hello""));
    element = iterator.next();
    element.wrap(BufferUtil.wrapString(""world""));
    element = iterator.next();
    element.wrap(BufferUtil.wrapString(""friend""));

    // then
    encodeAndDecode(array);
    assertStringValues(array, ""hello"", ""world"", ""friend"");
  }
"
"  @Test
  public void shouldIncreaseInternalBufferWhenAddingToEnd() {
    // given
    final int valueCount = 10_000;

    final Integer[] values =
        IntStream.iterate(0, (i) -> ++i)
            .limit(valueCount)
            .boxed()
            .collect(Collectors.toList())
            .toArray(new Integer[valueCount]);

    // when
    addIntValues(array, values);

    // then
    encodeAndDecode(array);
    assertIntValues(array, values);
  }
"
"  @Test
  public void shouldIncreaseInternalBufferWhenAddingToBeginning() {
    // given
    final int valueCount = 10_000;
    final List<Integer> generatedList =
        IntStream.iterate(0, (i) -> ++i).limit(valueCount).boxed().collect(Collectors.toList());
    final List<Integer> reverseList = new ArrayList<>(generatedList);
    Collections.reverse(generatedList);

    final Integer[] values = generatedList.toArray(new Integer[valueCount]);

    // when
    for (final Integer value : values) {
      // reset cursor to first position
      array.iterator();
      array.add().setValue(value);
    }

    // then
    encodeAndDecode(array);

    final Integer[] resultValues = reverseList.toArray(new Integer[valueCount]);
    assertIntValues(array, resultValues);
  }
"
"	@Test
	public void testIssue151() {
		JSONDoc jsonDoc = jsondocScanner.getJSONDoc("""", """", Lists.newArrayList(""org.jsondoc.core.issues.issue151""), true, MethodDisplay.URI);
		Assert.assertEquals(2, jsonDoc.getObjects().keySet().size());
		Assert.assertEquals(1, jsonDoc.getObjects().get(""bargroup"").size());
		Assert.assertEquals(1, jsonDoc.getObjects().get(""foogroup"").size());
	}
"
"	@Test
	public void testApiErrorsDoc() throws Exception {

		final ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>>newHashSet(Test3Controller.class),
				MethodDisplay.URI).iterator().next();

		final Set<ApiMethodDoc> methods = apiDoc.getMethods();
		final ApiMethodDoc apiMethodDoc = methods.iterator().next();
		final List<ApiErrorDoc> apiErrors = apiMethodDoc.getApierrors();

		Assert.assertEquals(1, methods.size());
		Assert.assertEquals(3, apiErrors.size());
		Assert.assertEquals(""1000"", apiErrors.get(0).getCode());
		Assert.assertEquals(""method-level annotation should be applied"",
				""A test error #1"", apiErrors.get(0).getDescription());
		Assert.assertEquals(""2000"", apiErrors.get(1).getCode());
		Assert.assertEquals(""400"", apiErrors.get(2).getCode());

	}
"
"	@Test
	public void testApiDoc() {
		Set<Class<?>> classes = new HashSet<Class<?>>();
		classes.add(TestController.class);
		ApiDoc apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""test-controller"", apiDoc.getName());
		Assert.assertEquals(""a-test-controller"", apiDoc.getDescription());
		Assert.assertEquals(""1.0"", apiDoc.getSupportedversions().getSince());
		Assert.assertEquals(""2.12"", apiDoc.getSupportedversions().getUntil());
		Assert.assertEquals(ApiAuthType.NONE.name(), apiDoc.getAuth().getType());
		Assert.assertEquals(DefaultJSONDocScanner.ANONYMOUS, apiDoc.getAuth().getRoles().get(0));

		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			
			if (apiMethodDoc.getPath().contains(""/name"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""string"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""string"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				Assert.assertEquals(""200 - OK"", apiMethodDoc.getResponsestatuscode());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""name"")) {
						Assert.assertEquals(""string"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}

			if (apiMethodDoc.getPath().contains(""/age"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""204"", apiMethodDoc.getResponsestatuscode());
				Assert.assertEquals(""integer"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""integer"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""age"")) {
						Assert.assertEquals(""integer"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}

			if (apiMethodDoc.getPath().contains(""/avg"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""long"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""long"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""avg"")) {
						Assert.assertEquals(""long"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}

			if (apiMethodDoc.getPath().contains(""/map"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""map[string, integer]"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""map[string, integer]"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""map"")) {
						Assert.assertEquals(""map[string, integer]"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}

			if (apiMethodDoc.getPath().contains(""/parametrizedList"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""list of string"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""list of string"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""parametrizedList"")) {
						Assert.assertEquals(""list of string"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
				
			}

			if (apiMethodDoc.getPath().contains(""/wildcardParametrizedList"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""list of wildcard"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""list of wildcard"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""wildcardParametrizedList"")) {
						Assert.assertEquals(""list of wildcard"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}

			if (apiMethodDoc.getPath().contains(""/LongArray"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""array of long"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""array of long"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""LongArray"")) {
						Assert.assertEquals(""array of long"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}

			if (apiMethodDoc.getPath().contains(""/longArray"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""array of long"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""array of long"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""longArray"")) {
						Assert.assertEquals(""array of long"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}
			
			if (apiMethodDoc.getPath().contains(""/version"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""1.0"", apiMethodDoc.getSupportedversions().getSince());
				Assert.assertEquals(""2.12"", apiMethodDoc.getSupportedversions().getUntil());
			}
			
			if (apiMethodDoc.getPath().contains(""/child"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""child"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
			}
			
			if (apiMethodDoc.getPath().contains(""/pizza"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""customPizzaObject"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
			}
			
			if (apiMethodDoc.getPath().contains(""/multiple-request-methods"")) {
				Assert.assertEquals(2, apiMethodDoc.getVerb().size());
				Iterator<ApiVerb> iterator = apiMethodDoc.getVerb().iterator();
				Assert.assertEquals(ApiVerb.GET, iterator.next());
				Assert.assertEquals(ApiVerb.POST, iterator.next());
			}
			
		}

		classes.clear();
		classes.add(TestControllerWithBasicAuth.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""test-controller-with-basic-auth"", apiDoc.getName());
		Assert.assertEquals(ApiAuthType.BASIC_AUTH.name(), apiDoc.getAuth().getType());
		Assert.assertEquals(""ROLE_USER"", apiDoc.getAuth().getRoles().get(0));
		Assert.assertEquals(""ROLE_ADMIN"", apiDoc.getAuth().getRoles().get(1));
		Assert.assertTrue(apiDoc.getAuth().getTestusers().size() > 0);
		
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/basicAuth"")) {
				Assert.assertEquals(ApiAuthType.BASIC_AUTH.name(), apiMethodDoc.getAuth().getType());
				Assert.assertEquals(""ROLE_USER"", apiMethodDoc.getAuth().getRoles().get(0));
				Assert.assertTrue(apiMethodDoc.getAuth().getTestusers().size() > 0);
			}
			
			if (apiMethodDoc.getPath().contains(""/noAuth"")) {
				Assert.assertEquals(ApiAuthType.NONE.name(), apiMethodDoc.getAuth().getType());
				Assert.assertEquals(DefaultJSONDocScanner.ANONYMOUS, apiMethodDoc.getAuth().getRoles().get(0));
			}
			
			if (apiMethodDoc.getPath().contains(""/undefinedAuthWithAuthOnClass"")) {
				Assert.assertEquals(ApiAuthType.BASIC_AUTH.name(), apiMethodDoc.getAuth().getType());
				Assert.assertEquals(""ROLE_USER"", apiMethodDoc.getAuth().getRoles().get(0));
				Assert.assertEquals(""ROLE_ADMIN"", apiMethodDoc.getAuth().getRoles().get(1));
			}
			
		}
		
		classes.clear();
		classes.add(TestControllerWithNoAuthAnnotation.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""test-controller-with-no-auth-annotation"", apiDoc.getName());
		Assert.assertNull(apiDoc.getAuth());
		
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/basicAuth"")) {
				Assert.assertEquals(ApiAuthType.BASIC_AUTH.name(), apiMethodDoc.getAuth().getType());
				Assert.assertEquals(""ROLE_USER"", apiMethodDoc.getAuth().getRoles().get(0));
				Assert.assertTrue(apiMethodDoc.getAuth().getTestusers().size() > 0);
			}
			
			if (apiMethodDoc.getPath().contains(""/noAuth"")) {
				Assert.assertEquals(ApiAuthType.NONE.name(), apiMethodDoc.getAuth().getType());
				Assert.assertEquals(DefaultJSONDocScanner.ANONYMOUS, apiMethodDoc.getAuth().getRoles().get(0));
			}
			
			if (apiMethodDoc.getPath().contains(""/undefinedAuthWithoutAuthOnClass"")) {
				Assert.assertNull(apiMethodDoc.getAuth());
			}
			
		}
		
		classes.clear();
		classes.add(TestOldStyleServlets.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""test-old-style-servlets"", apiDoc.getName());
		
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/oldStyle"")) {
				Assert.assertEquals(1, apiMethodDoc.getPathparameters().size());
			}
			
			if (apiMethodDoc.getPath().contains(""/oldStyleWithList"")) {
				Assert.assertEquals(1, apiMethodDoc.getPathparameters().size());
			}
			
			if (apiMethodDoc.getPath().contains(""/oldStyleWithMap"")) {
				Assert.assertEquals(1, apiMethodDoc.getPathparameters().size());
			}
			
			if (apiMethodDoc.getPath().contains(""/oldStyleMixed"")) {
				Assert.assertEquals(3, apiMethodDoc.getPathparameters().size());
				Assert.assertEquals(1, apiMethodDoc.getQueryparameters().size());
				Assert.assertEquals(""qTest"", apiMethodDoc.getQueryparameters().iterator().next().getDefaultvalue());
			}
			
			if (apiMethodDoc.getPath().contains(""/oldStyleResponseObject"")) {
				Assert.assertEquals(""list"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
			}
			
			if (apiMethodDoc.getPath().contains(""/oldStyleBodyObject"")) {
				Assert.assertEquals(""list"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
			}
		}
		
		classes.clear();
		classes.add(TestErrorsAndWarningsAndHints.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""test-errors-warnings-hints"", apiDoc.getName());
		ApiMethodDoc apiMethodDoc = apiDoc.getMethods().iterator().next();
		Assert.assertEquals(1, apiMethodDoc.getJsondocerrors().size());
		Assert.assertEquals(1, apiMethodDoc.getJsondocwarnings().size());
		Assert.assertEquals(2, apiMethodDoc.getJsondochints().size());
		
		classes.clear();
		classes.add(TestErrorsAndWarningsAndHintsMethodSummary.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.SUMMARY).iterator().next();
		apiMethodDoc = apiDoc.getMethods().iterator().next();
		Assert.assertEquals(1, apiMethodDoc.getJsondocerrors().size());
		Assert.assertEquals(1, apiMethodDoc.getJsondocwarnings().size());
		Assert.assertEquals(3, apiMethodDoc.getJsondochints().size());
		
		classes.clear();
		classes.add(InterfaceController.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""interface-controller"", apiDoc.getName());
		apiMethodDoc = apiDoc.getMethods().iterator().next();
		Assert.assertNotNull(apiMethodDoc);
		Assert.assertEquals(""/interface"", apiMethodDoc.getPath().iterator().next());
		
		classes.clear();
		classes.add(TestDeclaredMethods.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""test-declared-methods"", apiDoc.getName());
		Assert.assertEquals(2, apiDoc.getMethods().size());
		
		
		classes.clear();
		classes.add(TestMultipleParamsWithSameMethod.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(3, apiDoc.getMethods().size());
		
	}
"
"	@Test
	public void testNotEqual() {
		first = new ApiMethodDoc();
		first.setPath(Sets.newHashSet(""/first""));
		first.setVerb(Sets.newHashSet(ApiVerb.GET));
		second = new ApiMethodDoc();
		second.setPath(Sets.newHashSet(""/second""));
		second.setVerb(Sets.newHashSet(ApiVerb.GET));
		Assert.assertNotEquals(0, first.compareTo(second));
	}
"
"	@Test
	public void testEqual() {
		first = new ApiMethodDoc();
		first.setPath(Sets.newHashSet(""/test""));
		first.setVerb(Sets.newHashSet(ApiVerb.GET));
		second = new ApiMethodDoc();
		second.setPath(Sets.newHashSet(""/test""));
		second.setVerb(Sets.newHashSet(ApiVerb.GET));
		Assert.assertEquals(0, first.compareTo(second));
	}
"
"	@Test
	public void testNotEqualMultipleVerbs() {
		first = new ApiMethodDoc();
		first.setPath(Sets.newHashSet(""/first""));
		first.setVerb(Sets.newHashSet(ApiVerb.GET, ApiVerb.POST));
		second = new ApiMethodDoc();
		second.setPath(Sets.newHashSet(""/second""));
		second.setVerb(Sets.newHashSet(ApiVerb.GET, ApiVerb.POST));
		Assert.assertNotEquals(0, first.compareTo(second));
		
		second.setPath(Sets.newHashSet(""/first""));
		second.setVerb(Sets.newHashSet(ApiVerb.PUT, ApiVerb.POST));
		Assert.assertNotEquals(0, first.compareTo(second));
	}
"
"	@Test
	public void testEqualMultipleVerbs() {
		first = new ApiMethodDoc();
		first.setPath(Sets.newHashSet(""/test""));
		first.setVerb(Sets.newHashSet(ApiVerb.GET, ApiVerb.POST));
		second = new ApiMethodDoc();
		second.setPath(Sets.newHashSet(""/test""));
		second.setVerb(Sets.newHashSet(ApiVerb.GET, ApiVerb.POST));
		Assert.assertEquals(0, first.compareTo(second));
		
		second.setVerb(Sets.newHashSet(ApiVerb.POST, ApiVerb.GET));
		Assert.assertEquals(0, first.compareTo(second));
	}
"
"	@Test
	public void testUndefinedVisibilityAndStageDoc() {
		Set<Class<?>> classes = new HashSet<Class<?>>();
		classes.add(UndefinedVisibilityAndStage.class);
		ApiObjectDoc apiObjectDoc = jsondocScanner.getApiObjectDocs(classes).iterator().next();
		Assert.assertEquals(""undefinedvisibilityandstage"", apiObjectDoc.getName());
		Assert.assertEquals(ApiVisibility.UNDEFINED, apiObjectDoc.getVisibility());
		Assert.assertEquals(ApiStage.UNDEFINED, apiObjectDoc.getStage());
	}
"
"	@Test
	public void testTemplateApiObjectDoc() {
		Set<Class<?>> classes = new HashSet<Class<?>>();
		classes.add(TemplateApiObject.class);
		ApiObjectDoc apiObjectDoc = jsondocScanner.getApiObjectDocs(classes).iterator().next();
		Assert.assertEquals(""templateapiobject"", apiObjectDoc.getName());
		Iterator<ApiObjectFieldDoc> iterator = apiObjectDoc.getFields().iterator();
		Assert.assertEquals(""id"", iterator.next().getName());
		Assert.assertEquals(""name"", iterator.next().getName());
	}
"
"	@Test
	public void testNoNameApiObjectDoc() {
		Set<Class<?>> classes = new HashSet<Class<?>>();
		classes.add(NoNameApiObject.class);
		ApiObjectDoc apiObjectDoc = jsondocScanner.getApiObjectDocs(classes).iterator().next();
		Assert.assertEquals(""nonameapiobject"", apiObjectDoc.getName());
		Assert.assertEquals(""id"", apiObjectDoc.getFields().iterator().next().getName());
		Assert.assertEquals(1, apiObjectDoc.getJsondochints().size());
	}
"
"	@Test
	public void testEnumObjectDoc() {
		Set<Class<?>> classes = new HashSet<Class<?>>();
		classes.add(TestEnum.class);
		ApiObjectDoc childDoc = jsondocScanner.getApiObjectDocs(classes).iterator().next(); 
		Assert.assertEquals(""test-enum"", childDoc.getName());
		Assert.assertEquals(0, childDoc.getFields().size());
		Assert.assertEquals(TestEnum.TESTENUM1.name(), childDoc.getAllowedvalues()[0]);
		Assert.assertEquals(TestEnum.TESTENUM2.name(), childDoc.getAllowedvalues()[1]);
		Assert.assertEquals(TestEnum.TESTENUM3.name(), childDoc.getAllowedvalues()[2]);
	}
"
"	@Test
	public void testApiObjectDoc() {
		Set<Class<?>> classes = new HashSet<Class<?>>();
		classes.add(TestObject.class);
		ApiObjectDoc childDoc = jsondocScanner.getApiObjectDocs(classes).iterator().next(); 
		Assert.assertEquals(""test-object"", childDoc.getName());
		Assert.assertEquals(14, childDoc.getFields().size());
		Assert.assertEquals(""1.0"", childDoc.getSupportedversions().getSince());
		Assert.assertEquals(""2.12"", childDoc.getSupportedversions().getUntil());
		Assert.assertEquals(ApiVisibility.PUBLIC, childDoc.getVisibility());
		Assert.assertEquals(ApiStage.PRE_ALPHA, childDoc.getStage());
		
		for (ApiObjectFieldDoc fieldDoc : childDoc.getFields()) {
			if(fieldDoc.getName().equals(""wildcardParametrized"")) {
				Assert.assertEquals(""list"", fieldDoc.getJsondocType().getType().get(0));
			}
			
			if(fieldDoc.getName().equals(""unparametrizedList"")) {
				Assert.assertEquals(""list"", fieldDoc.getJsondocType().getType().get(0));
			}
			
			if(fieldDoc.getName().equals(""parametrizedList"")) {
				Assert.assertEquals(""list of string"", fieldDoc.getJsondocType().getOneLineText());
			}
			
			if(fieldDoc.getName().equals(""name"")) {
				Assert.assertEquals(""string"", fieldDoc.getJsondocType().getType().get(0));
				Assert.assertEquals(""name"", fieldDoc.getName());
				Assert.assertEquals(""true"", fieldDoc.getRequired());
			}
			
			if(fieldDoc.getName().equals(""age"")) {
				Assert.assertEquals(""integer"", fieldDoc.getJsondocType().getType().get(0));
				Assert.assertEquals(""age"", fieldDoc.getName());
				Assert.assertEquals(""false"", fieldDoc.getRequired());
			}
			
			if(fieldDoc.getName().equals(""avg"")) {
				Assert.assertEquals(""long"", fieldDoc.getJsondocType().getType().get(0));
				Assert.assertEquals(""avg"", fieldDoc.getName());
				Assert.assertEquals(""false"", fieldDoc.getRequired());
			}
			
			if(fieldDoc.getName().equals(""map"")) {
				Assert.assertEquals(""map"", fieldDoc.getJsondocType().getType().get(0));
				Assert.assertEquals(""string"", fieldDoc.getJsondocType().getMapKey().getType().get(0));
				Assert.assertEquals(""integer"", fieldDoc.getJsondocType().getMapValue().getType().get(0));
			}
			
			if(fieldDoc.getName().equals(""LongArray"")) {
				Assert.assertEquals(""array of long"", fieldDoc.getJsondocType().getOneLineText());
				Assert.assertEquals(""LongArray"", fieldDoc.getName());
				Assert.assertEquals(""false"", fieldDoc.getRequired());
			}

			if(fieldDoc.getName().equals(""longArray"")) {
				Assert.assertEquals(""array of long"", fieldDoc.getJsondocType().getOneLineText());
				Assert.assertEquals(""longArray"", fieldDoc.getName());
				Assert.assertEquals(""false"", fieldDoc.getRequired());
			}
			
			if(fieldDoc.getName().equals(""fooBar"")) {
				Assert.assertEquals(""string"", fieldDoc.getJsondocType().getOneLineText());
				Assert.assertEquals(""foo_bar"", fieldDoc.getName());
				Assert.assertEquals(""false"", fieldDoc.getRequired());
			}
			
			if(fieldDoc.getName().equals(""version"")) {
				Assert.assertEquals(""string"", fieldDoc.getJsondocType().getOneLineText());
				Assert.assertEquals(""1.0"", fieldDoc.getSupportedversions().getSince());
				Assert.assertEquals(""2.12"", fieldDoc.getSupportedversions().getUntil());
			}
			
			if(fieldDoc.getName().equals(""test-enum"")) {
				Assert.assertEquals(""test-enum"", fieldDoc.getName());
				Assert.assertEquals(TestEnum.TESTENUM1.name(), fieldDoc.getAllowedvalues()[0]);
				Assert.assertEquals(TestEnum.TESTENUM2.name(), fieldDoc.getAllowedvalues()[1]);
				Assert.assertEquals(TestEnum.TESTENUM3.name(), fieldDoc.getAllowedvalues()[2]);
			}
			
			if(fieldDoc.getName().equals(""test-enum-with-allowed-values"")) {
				Assert.assertEquals(""A"", fieldDoc.getAllowedvalues()[0]);
				Assert.assertEquals(""B"", fieldDoc.getAllowedvalues()[1]);
				Assert.assertEquals(""C"", fieldDoc.getAllowedvalues()[2]);
			}

			if(fieldDoc.getName().equals(""orderedProperty"")) {
				Assert.assertEquals(""orderedProperty"", fieldDoc.getName());
				Assert.assertEquals(1, fieldDoc.getOrder().intValue());
			} else {
				Assert.assertEquals(Integer.MAX_VALUE, fieldDoc.getOrder().intValue());
			}

		}
	}
"
"	@Test
	public void testApiHeadersOnClass() {
		final ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>>newHashSet(ApiHeadersController.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""ApiHeadersController"", apiDoc.getName());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if(apiMethodDoc.getPath().contains(""/api-headers-controller-method-one"")) {
				Assert.assertEquals(2, apiMethodDoc.getHeaders().size());
			}
			if(apiMethodDoc.getPath().contains(""/api-headers-controller-method-two"")) {
				Assert.assertEquals(3, apiMethodDoc.getHeaders().size());
			}
		}
	}
"
"	@Test
	public void testApiDoc() {
		Set<Class<?>> classes = new HashSet<Class<?>>();
		classes.add(TestFlow.class);
		
		List<ApiMethodDoc> apiMethodDocs = new ArrayList<ApiMethodDoc>();
		ApiMethodDoc apiMethodDoc = new ApiMethodDoc();
		apiMethodDoc.setId(""F1"");
		apiMethodDocs.add(apiMethodDoc);
		
		Set<ApiFlowDoc> apiFlowDocs = jsondocScanner.getApiFlowDocs(classes, apiMethodDocs);
		for (ApiFlowDoc apiFlowDoc : apiFlowDocs) {
			if(apiFlowDoc.getName().equals(""flow"")) {
				Assert.assertEquals(""A test flow"", apiFlowDoc.getDescription());
				Assert.assertEquals(3, apiFlowDoc.getSteps().size());
				Assert.assertEquals(""F1"", apiFlowDoc.getSteps().get(0).getApimethodid());
				Assert.assertEquals(""F2"", apiFlowDoc.getSteps().get(1).getApimethodid());
				Assert.assertEquals(""Flows A"", apiFlowDoc.getGroup());
				Assert.assertNotNull(apiFlowDoc.getSteps().get(0).getApimethoddoc());
				Assert.assertEquals(""F1"", apiFlowDoc.getSteps().get(0).getApimethoddoc().getId());
			}
			
			if(apiFlowDoc.getName().equals(""flow2"")) {
				Assert.assertEquals(""A test flow 2"", apiFlowDoc.getDescription());
				Assert.assertEquals(3, apiFlowDoc.getSteps().size());
				Assert.assertEquals(""F4"", apiFlowDoc.getSteps().get(0).getApimethodid());
				Assert.assertEquals(""F5"", apiFlowDoc.getSteps().get(1).getApimethodid());
				Assert.assertEquals(""Flows B"", apiFlowDoc.getGroup());
			}
		}
	}
"
"	@Test
	public void testApiObjectDocWithHibernateValidator() {
		Set<ApiObjectDoc> apiObjectDocs = jsondocScanner.getApiObjectDocs(Sets.<Class<?>>newHashSet(HibernateValidatorPojo.class));
		Iterator<ApiObjectDoc> iterator = apiObjectDocs.iterator();
		ApiObjectDoc next = iterator.next();
		Set<ApiObjectFieldDoc> fields = next.getFields();
		for (ApiObjectFieldDoc apiObjectFieldDoc : fields) {
			if(apiObjectFieldDoc.getName().equals(""id"")) {
				Iterator<String> formats = apiObjectFieldDoc.getFormat().iterator();
				Assert.assertEquals(""a not empty id"", formats.next());
				Assert.assertEquals(""length must be between 2 and 2147483647"", formats.next());
				Assert.assertEquals(""must be less than or equal to 9"", formats.next());
			}
		}
	}
"
"	@Test
	public void testApiGlobalDoc() {
		ApiGlobalDoc apiGlobalDoc = jsondocScanner.getApiGlobalDoc(Sets.<Class<?>>newHashSet(Global.class), Sets.<Class<?>>newHashSet(), Sets.<Class<?>>newHashSet());
		Assert.assertNotNull(apiGlobalDoc);
		Assert.assertEquals(1, apiGlobalDoc.getSections().size());
		ApiGlobalSectionDoc sectionDoc = apiGlobalDoc.getSections().iterator().next();
		Assert.assertEquals(""title"", sectionDoc.getTitle());
		Assert.assertEquals(3, sectionDoc.getParagraphs().size());
		
		apiGlobalDoc = jsondocScanner.getApiGlobalDoc(Sets.<Class<?>>newHashSet(), Sets.<Class<?>>newHashSet(Changelog.class), Sets.<Class<?>>newHashSet());
		Assert.assertNotNull(apiGlobalDoc);
		Assert.assertEquals(1, apiGlobalDoc.getChangelogset().getChangelogs().size());

		apiGlobalDoc = jsondocScanner.getApiGlobalDoc(Sets.<Class<?>>newHashSet(MultipleGlobalSections.class), Sets.<Class<?>>newHashSet(), Sets.<Class<?>>newHashSet());
		Assert.assertNotNull(apiGlobalDoc);
		Assert.assertEquals(3, apiGlobalDoc.getSections().size());
		
		ApiGlobalSectionDoc[] apiGlobalSectionDocs = apiGlobalDoc.getSections().toArray(new ApiGlobalSectionDoc[apiGlobalDoc.getSections().size()]);
		Assert.assertEquals(""section1"", apiGlobalSectionDocs[0].getTitle());
		Assert.assertEquals(""abc"", apiGlobalSectionDocs[1].getTitle());
		Assert.assertEquals(""198xyz"", apiGlobalSectionDocs[2].getTitle());
		
		apiGlobalDoc = jsondocScanner.getApiGlobalDoc(Sets.<Class<?>>newHashSet(), Sets.<Class<?>>newHashSet(), Sets.<Class<?>>newHashSet(Migration.class));
		Assert.assertNotNull(apiGlobalDoc);
		Assert.assertEquals(1, apiGlobalDoc.getMigrationset().getMigrations().size());
		
		apiGlobalDoc = jsondocScanner.getApiGlobalDoc(Sets.<Class<?>>newHashSet(AllTogether.class), Sets.<Class<?>>newHashSet(AllTogether.class), Sets.<Class<?>>newHashSet(AllTogether.class));
		Assert.assertNotNull(apiGlobalDoc);
		Assert.assertEquals(1, apiGlobalDoc.getSections().size());
		Assert.assertEquals(1, apiGlobalDoc.getMigrationset().getMigrations().size());
		Assert.assertEquals(1, apiGlobalDoc.getChangelogset().getChangelogs().size());
	}
"
"	@Test
	public void testApiVisibility() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(Controller.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(ApiVisibility.PUBLIC, apiDoc.getVisibility());
		Assert.assertEquals(ApiStage.BETA, apiDoc.getStage());
		
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if(apiMethodDoc.getPath().contains(""/inherit"")) {
				Assert.assertEquals(ApiVisibility.PUBLIC, apiMethodDoc.getVisibility());
				Assert.assertEquals(ApiStage.BETA, apiMethodDoc.getStage());
			}
			if(apiMethodDoc.getPath().contains(""/override"")) {
				Assert.assertEquals(ApiVisibility.PRIVATE, apiMethodDoc.getVisibility());
				Assert.assertEquals(ApiStage.GA, apiMethodDoc.getStage());
			}
		}
		
		apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(Controller2.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(ApiVisibility.UNDEFINED, apiDoc.getVisibility());
		Assert.assertEquals(ApiStage.UNDEFINED, apiDoc.getStage());
		
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if(apiMethodDoc.getPath().contains(""/only-method"")) {
				Assert.assertEquals(ApiVisibility.PRIVATE, apiMethodDoc.getVisibility());
				Assert.assertEquals(ApiStage.DEPRECATED, apiMethodDoc.getStage());
			}
		}
		
	}
"
"	@Test
	public void testPathWithMethodDisplayURI() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(Controller.class), MethodDisplay.URI).iterator().next();

		boolean allRight = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
			@Override
			public boolean apply(ApiMethodDoc input) {
				return 
						input.getPath().contains(""/path1"") && 
						input.getPath().contains(""/path2"") && 
						input.getDisplayedMethodString().contains(""/path1"") &&
						input.getDisplayedMethodString().contains(""/path2"");
			}
"
"	@Test
	public void testPathWithMethodDisplayMethod() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(Controller.class), MethodDisplay.METHOD).iterator().next();
		
		boolean allRight = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
			@Override
			public boolean apply(ApiMethodDoc input) {
				return 
						input.getPath().contains(""/path1"") && 
						input.getPath().contains(""/path2"") && 
						input.getDisplayedMethodString().contains(""path"") &&
						!input.getDisplayedMethodString().contains(""/path1"");
			}
"
"	@Test
	public void testReflex() throws NoSuchMethodException, SecurityException, ClassNotFoundException, JsonGenerationException, JsonMappingException, IOException {
		mapper.setSerializationInclusion(Include.NON_NULL);
		JSONDocType jsonDocType = new JSONDocType();
		
		Method method = JSONDocTypeBuilderTest.class.getMethod(""getString"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""string"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getInteger"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""integer"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getInt"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""int"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getLong"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""long"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getlong"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""long"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getListString"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""list of string"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getListSetString"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""list of set of string"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getStringArray"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""array of string"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getIntegerArray"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""array of integer"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getListOfStringArray"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""array of list of string"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getSetOfStringArray"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""array of set of string"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getList"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""list"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getListOfWildcard"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""list of wildcard"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getListOfWildcardArray"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""array of list of wildcard"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getListArray"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""array of list"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getSetArray"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""array of set"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getMap"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""map"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getHashMap"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""hashmap"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getMapStringInteger"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""map[string, integer]"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getMapListOfStringInteger"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""map[list of string, integer]"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getMapStringSetOfInteger"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""map[string, set of integer]"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getMapListOfStringSetOfInteger"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""map[list of string, set of integer]"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getMapListOfSetOfStringSetOfInteger"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""map[list of set of string, set of integer]"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getMapWildcardInteger"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""map[wildcard, integer]"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getMapWildcardWildcard"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""map[wildcard, wildcard]"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getMapListOfWildcardWildcard"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""map[list of wildcard, wildcard]"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getMapMapInteger"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""map[map, integer]"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getMapMapStringLongInteger"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""map[map[string, long], integer]"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getResponseEntityString"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""responseentity of string"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");

		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getResponseEntityListOfString"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""responseentity of list of string"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getParentPojoList"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""list of my_parent"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");
		
		jsonDocType = new JSONDocType();
		method = JSONDocTypeBuilderTest.class.getMethod(""getSpecializedWGenericsPojo"");
		JSONDocTypeBuilder.build(jsonDocType, method.getReturnType(), method.getGenericReturnType());
		System.out.println(mapper.writeValueAsString(jsonDocType));
		System.out.println(jsonDocType.getOneLineText());
		Assert.assertEquals(""fooPojo of T"", jsonDocType.getOneLineText());
		System.out.println(""---------------------------"");		
	}
"
"	@Test
	public void testTemplate() throws IOException, IllegalArgumentException, IllegalAccessException, InstantiationException {
		ObjectMapper mapper = new ObjectMapper();
		Set<Class<?>> classes = Sets.<Class<?>>newHashSet(MyEnum.class);
		
		Map<String, Object> template = JSONDocTemplateBuilder.build(MyEnum.class, classes);
		System.out.println(mapper.writeValueAsString(template));
	}
"
"	@Test
	public void thatTemplateIsMappedToStringCorrectly() throws Exception {
		final ObjectMapper mapper = new ObjectMapper();
		Set<Class<?>> classes = Sets.<Class<?>>newHashSet(Unordered.class, Ordered.class);

		Map<String, Object> unorderedTemplate = JSONDocTemplateBuilder.build(Unordered.class, classes);
		Assert.assertEquals(""{\""aField\"":\""\"",\""xField\"":\""\""}"", mapper.writeValueAsString(unorderedTemplate));

		Map<String, Object> orderedTemplate = JSONDocTemplateBuilder.build(Ordered.class, classes);
		Assert.assertEquals(""{\""xField\"":\""\"",\""aField\"":\""\"",\""bField\"":\""\""}"", mapper.writeValueAsString(orderedTemplate));
	}
"
"    @Test
    public void getJSONDoc() throws IOException {
    	JSONDocScanner jsondocScanner = new DefaultJSONDocScanner();
        JSONDoc jsondoc = jsondocScanner.getJSONDoc(version, basePath, Lists.newArrayList(""org.jsondoc.core.util""), true, MethodDisplay.URI);
        assertEquals(1, jsondoc.getApis().size());

        int countApis = 0;
        for (String string : jsondoc.getApis().keySet()) {
            countApis += jsondoc.getApis().get(string).size();
        }
        assertEquals(4, countApis);

        assertEquals(3, jsondoc.getObjects().size());
        
        int countFlows = 0;
        for (String string : jsondoc.getFlows().keySet()) {
        	countFlows += jsondoc.getFlows().get(string).size();
        }
        assertEquals(2, countFlows);

        int countObjects = 0;
        for (String string : jsondoc.getObjects().keySet()) {
            countObjects += jsondoc.getObjects().get(string).size();
        }
        assertEquals(10, countObjects);

        Set<ApiVerb> apiVerbs = getAllTestedApiVerbs(jsondoc);
        assertEquals(ApiVerb.values().length, apiVerbs.size());

        log.debug(objectMapper.writeValueAsString(jsondoc));
    }
"
"	@Test
	public void testTemplate() throws JsonGenerationException, JsonMappingException, IOException, IllegalArgumentException, IllegalAccessException, InstantiationException {
		Set<Class<?>> classes = Sets.<Class<?>>newHashSet(StackOverflowTemplateSelf.class, StackOverflowTemplateObjectOne.class, StackOverflowTemplateObjectTwo.class);
		
		StackOverflowTemplateSelf objectSelf = new StackOverflowTemplateSelf();
		Map<String, Object> template = JSONDocTemplateBuilder.build(objectSelf.getClass(), classes);
		System.out.println(mapper.writeValueAsString(template));
		
		StackOverflowTemplateObjectOne objectOne = new StackOverflowTemplateObjectOne();
		template = JSONDocTemplateBuilder.build(objectOne.getClass(), classes);
		System.out.println(mapper.writeValueAsString(template));
		
		StackOverflowTemplateObjectTwo objectTwo = new StackOverflowTemplateObjectTwo();
		template = JSONDocTemplateBuilder.build(objectTwo.getClass(), classes);
		System.out.println(mapper.writeValueAsString(template));
	}
"
"	@Test
	public void typeOneTwo() throws JsonGenerationException, JsonMappingException, IOException {
		Set<Class<?>> classes = Sets.<Class<?>>newHashSet(NotAnnotatedStackOverflowObjectOne.class, NotAnnotatedStackOverflowObjectTwo.class);
		
		NotAnnotatedStackOverflowObjectOne typeOne = new NotAnnotatedStackOverflowObjectOne();
		Map<String, Object> template = JSONDocTemplateBuilder.build(typeOne.getClass(), classes);
		System.out.println(mapper.writeValueAsString(template));
	}
"
"	@Test
	public void testTemplate() throws IOException, IllegalArgumentException, IllegalAccessException, InstantiationException {
		ObjectMapper mapper = new ObjectMapper();
		Set<Class<?>> classes = Sets.<Class<?>>newHashSet(TemplateObject.class);
		
		Map<String, Object> template = JSONDocTemplateBuilder.build(TemplateObject.class, classes);

		Assert.assertEquals(0, template.get(""my_id""));
		Assert.assertEquals(0, template.get(""idint""));
		Assert.assertEquals(0, template.get(""idlong""));
		Assert.assertEquals("""", template.get(""name""));
		Assert.assertEquals("""", template.get(""gender""));
		Assert.assertEquals(true, template.get(""bool""));
		Assert.assertEquals(new ArrayList(), template.get(""intarrarr""));
		Assert.assertEquals(new JSONDocTemplate(), template.get(""sub_obj""));
		Assert.assertEquals(new ArrayList(), template.get(""untypedlist""));
		Assert.assertEquals(new ArrayList(), template.get(""subsubobjarr""));
		Assert.assertEquals(new ArrayList(), template.get(""stringlist""));
		Assert.assertEquals(new ArrayList(), template.get(""stringarrarr""));
		Assert.assertEquals(new ArrayList(), template.get(""integerarr""));
		Assert.assertEquals(new ArrayList(), template.get(""stringarr""));
		Assert.assertEquals(new ArrayList(), template.get(""intarr""));
		Assert.assertEquals(new ArrayList(), template.get(""subobjlist""));
		Assert.assertEquals(new ArrayList(), template.get(""wildcardlist""));
		Assert.assertEquals(new ArrayList(), template.get(""longlist""));
		Assert.assertEquals("""", template.get(""namechar""));
		Assert.assertEquals(new HashMap(), template.get(""map""));
		Assert.assertEquals(new HashMap(), template.get(""mapstringinteger""));
		Assert.assertEquals(new HashMap(), template.get(""mapsubobjinteger""));
		Assert.assertEquals(new HashMap(), template.get(""mapintegersubobj""));
		Assert.assertEquals(new HashMap(), template.get(""mapintegerlistsubsubobj""));
		
		System.out.println(mapper.writeValueAsString(template));
	}
"
"	@Test
	public void testTemplateWithConstant() throws Exception {
        final ObjectMapper mapper = new ObjectMapper();
        final Set<Class<?>> classes = Sets.<Class<?>>newHashSet(ClassWithConstant.class);

        final Map<String, Object> template = JSONDocTemplateBuilder.build(ClassWithConstant.class, classes);
        Assert.assertEquals("""", template.get(""identifier""));
        Assert.assertEquals(null, template.get(THIS_IS_A_CONSTANT));

        final String serializedTemplate =
            ""{"" +
                ""\""identifier\"":\""\"""" +
            ""}"";

        assertThat(mapper.writeValueAsString(template), is(serializedTemplate));
	}
"
"	@Test
	public void testTemplate() throws IOException, IllegalArgumentException, IllegalAccessException, InstantiationException {
		ObjectMapper mapper = new ObjectMapper();
		Set<Class<?>> classes = Sets.<Class<?>>newHashSet(NoAnnotationPojo.class);
		
		Map<String, Object> template = JSONDocTemplateBuilder.build(NoAnnotationPojo.class, classes);
		System.out.println(mapper.writeValueAsString(template));
	}
"
"	@Test
	public void testInvisible() {
		JSONDoc jsonDoc = jsondocScanner.getJSONDoc(""version"", ""basePath"", Lists.newArrayList(""org.jsondoc.springmvc.issues.invisible""), true, MethodDisplay.URI);
		Assert.assertEquals(1, jsonDoc.getObjects().keySet().size());
		for (String string : jsonDoc.getObjects().keySet()) {
			Assert.assertEquals(2, jsonDoc.getObjects().get(string).size());
		}
		for (ApiDoc apiDoc : jsonDoc.getApis().get("""")) {
			for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
				Assert.assertEquals(""Resource Interface"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
			}
		}
		
	}
"
"	@Test
	public void testIssue151() {
		JSONDoc jsonDoc = jsondocScanner.getJSONDoc(""version"", ""basePath"", Lists.newArrayList(""org.jsondoc.springmvc.issues.issue151""), true, MethodDisplay.URI);
		Assert.assertEquals(2, jsonDoc.getObjects().keySet().size());
		Assert.assertEquals(1, jsonDoc.getObjects().get(""bargroup"").size());
		Assert.assertEquals(1, jsonDoc.getObjects().get(""foogroup"").size());
	}
"
"	@Test
	public void testApiVerb() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController"", apiDoc.getName());
		Assert.assertEquals(2, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/status-one"")) {
				Assert.assertEquals(""201 - Created"", apiMethodDoc.getResponsestatuscode());
			}
			if (apiMethodDoc.getPath().contains(""/status-two"")) {
				Assert.assertEquals(""200 - OK"", apiMethodDoc.getResponsestatuscode());
			}
		}
	}
"
"	@Test
	public void testMergeApiDoc() {
		Set<Class<?>> controllers = new LinkedHashSet<Class<?>>();
		controllers.add(SpringController.class);
		Set<ApiDoc> apiDocs = jsondocScanner.getApiDocs(controllers, MethodDisplay.URI);

		ApiDoc apiDoc = apiDocs.iterator().next();
		Assert.assertEquals(""SpringController"", apiDoc.getDescription());
		Assert.assertEquals(""SpringController"", apiDoc.getName());
		Assert.assertNotNull(apiDoc.getGroup());

		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			Assert.assertEquals(MethodDisplay.URI, apiMethodDoc.getDisplayMethodAs());
			Assert.assertNull(apiMethodDoc.getAuth());
			Assert.assertNull(apiMethodDoc.getSupportedversions());
			Assert.assertTrue(apiMethodDoc.getApierrors().isEmpty());
			Assert.assertNull(apiMethodDoc.getId());
			Assert.assertEquals("""", apiMethodDoc.getSummary());
			Assert.assertEquals("""", apiMethodDoc.getDescription());
			
			if (apiMethodDoc.getPath().contains(""/api/string/{name}"")) {
				Assert.assertEquals(2, apiMethodDoc.getHeaders().size());
				Set<ApiHeaderDoc> headers = apiMethodDoc.getHeaders();
				Iterator<ApiHeaderDoc> headersIterator = headers.iterator();
				ApiHeaderDoc headerTest = headersIterator.next();
				Assert.assertEquals(""header"", headerTest.getName());
				Assert.assertEquals(""test"", headerTest.getAllowedvalues()[0]);
				ApiHeaderDoc headerTwo = headersIterator.next();
				Assert.assertEquals(""header-two"", headerTwo.getName());
				Assert.assertEquals(""header-test"", headerTwo.getAllowedvalues()[0]);

				Assert.assertEquals(""string"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				Assert.assertEquals(""string"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""POST"", apiMethodDoc.getVerb().iterator().next().name());
				Assert.assertEquals(""application/json"", apiMethodDoc.getProduces().iterator().next());
				Assert.assertEquals(""application/json"", apiMethodDoc.getConsumes().iterator().next());
				Assert.assertEquals(""201 - Created"", apiMethodDoc.getResponsestatuscode());

				Set<ApiParamDoc> queryparameters = apiMethodDoc.getQueryparameters();
				Assert.assertEquals(4, queryparameters.size());
				Iterator<ApiParamDoc> qpIterator = queryparameters.iterator();
				ApiParamDoc apiParamDoc = qpIterator.next();
				Assert.assertEquals(""delete"", apiParamDoc.getName());
				Assert.assertEquals(""true"", apiParamDoc.getRequired());
				Assert.assertEquals(null, apiParamDoc.getDefaultvalue());
				Assert.assertEquals(0, apiParamDoc.getAllowedvalues().length);
				apiParamDoc = qpIterator.next();
				Assert.assertEquals(""id"", apiParamDoc.getName());
				Assert.assertEquals(""true"", apiParamDoc.getRequired());
				Assert.assertTrue(apiParamDoc.getDefaultvalue().isEmpty());
				apiParamDoc = qpIterator.next();
				Assert.assertEquals("""", apiParamDoc.getName());
				Assert.assertEquals(""true"", apiParamDoc.getRequired());
				Assert.assertEquals("""", apiParamDoc.getDefaultvalue());

				apiParamDoc = qpIterator.next();
				Assert.assertEquals(""user"", apiParamDoc.getName());
				Assert.assertEquals(""false"", apiParamDoc.getRequired());
				Assert.assertEquals(""admin"", apiParamDoc.getDefaultvalue());

				Set<ApiParamDoc> pathparameters = apiMethodDoc.getPathparameters();
				Iterator<ApiParamDoc> ppIterator = pathparameters.iterator();
				apiParamDoc = ppIterator.next();
				apiParamDoc = apiMethodDoc.getPathparameters().iterator().next();
				Assert.assertEquals(""test"", apiParamDoc.getName());
			}
		}

	}
"
"	@Test
	public void getJSONDoc() throws IOException {
		JSONDocScanner jsondocScanner = new Spring3JSONDocScanner();
		JSONDoc jsondoc = jsondocScanner.getJSONDoc(version, basePath, Lists.newArrayList(""org.jsondoc.springmvc.issues.issue174""), true, MethodDisplay.URI);

		Map<String, Set<ApiObjectDoc>> objects = jsondoc.getObjects();
		for (Set<ApiObjectDoc> values : objects.values()) {
			for (ApiObjectDoc apiObjectDoc : values) {
				System.out.println(apiObjectDoc.getName());
			}
		}
	}
"
"	@Test
	public void testApiVerb() {
		ApiObjectDoc buildObject = SpringObjectBuilder.buildObject(MyObject.class);
		Assert.assertEquals(""MyObject"", buildObject.getName());
		Assert.assertEquals(3, buildObject.getFields().size());
	}
"
"	@Test
	public void testPath() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController"", apiDoc.getName());

		boolean slashPath = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
			@Override
			public boolean apply(ApiMethodDoc input) {
				return input.getPath().contains(""/path"");
			}
"
"	@Test
	public void testPath2() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController2.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController2"", apiDoc.getName());

		boolean none = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
			
			@Override
			public boolean apply(ApiMethodDoc input) {
				System.out.println(input.getPath());
				return input.getPath().contains(""/"");
			}
"
"	@Test
	public void testPath3() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController3.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController3"", apiDoc.getName());

		boolean allRight = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
			@Override
			public boolean apply(ApiMethodDoc input) {
				boolean allRight =
								input.getPath().contains(""/path1/path3"") && 
								input.getPath().contains(""/path1/path4"") && 
								input.getPath().contains(""/path2/path3"") && 
								input.getPath().contains(""/path2/path4"");     
				return allRight;
			}
"
"	@Test
	public void testPath4() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController4.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController4"", apiDoc.getName());

		boolean allRight = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
			@Override
			public boolean apply(ApiMethodDoc input) {
				boolean allRight =
								input.getPath().contains(""/path""); 
				return allRight;
			}
"
"	@Test
	public void testPath5() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController5.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController5"", apiDoc.getName());
		
		boolean allRight = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
			@Override
			public boolean apply(ApiMethodDoc input) {
				boolean allRight = input.getPath().contains(""/path"") && input.getPath().contains(""/path2"");
				return allRight;
			}
"
"	@Test
	public void testPath6() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController6.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController6"", apiDoc.getName());

		boolean allRight = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
			@Override
			public boolean apply(ApiMethodDoc input) {
				return input.getPath().contains(""/api/widget/frame"");
			}
"
"	@Test
	public void testPathWithMethodDisplayMethod() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController5.class), MethodDisplay.METHOD).iterator().next();
		boolean allRight = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
			@Override
			public boolean apply(ApiMethodDoc input) {
				boolean allRight = input.getPath().contains(""/path"") && input.getPath().contains(""/path2"") && input.getDisplayedMethodString().contains(""none"");
				return allRight;
			}
"
"    @Test
    public void testApiVerb() {
	ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController.class), MethodDisplay.URI).iterator().next();
	Assert.assertEquals(""SpringController"", apiDoc.getName());
	Assert.assertEquals(3, apiDoc.getMethods().size());
	for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
	    if (apiMethodDoc.getPath().contains(""/consumes-one"")) {
		Assert.assertEquals(1, apiMethodDoc.getConsumes().size());
		Assert.assertEquals(MediaType.APPLICATION_JSON_VALUE, apiMethodDoc.getConsumes().iterator().next());
	    }
	    if (apiMethodDoc.getPath().contains(""/consumes-two"")) {
		Assert.assertEquals(2, apiMethodDoc.getConsumes().size());
		Iterator<String> iterator = apiMethodDoc.getConsumes().iterator();
		Assert.assertEquals(MediaType.APPLICATION_JSON_VALUE, iterator.next());
		Assert.assertEquals(MediaType.APPLICATION_XML_VALUE, iterator.next());
	    }
	    if (apiMethodDoc.getPath().contains(""/consumes-three"")) {
		Assert.assertEquals(1, apiMethodDoc.getConsumes().size());
		String consumes = apiMethodDoc.getConsumes().iterator().next();
		Assert.assertEquals(MediaType.APPLICATION_JSON_VALUE, consumes);
	    }
	}

	apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController2.class), MethodDisplay.URI).iterator().next();
	Assert.assertEquals(""SpringController2"", apiDoc.getName());
	Assert.assertEquals(3, apiDoc.getMethods().size());
	for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
	    if (apiMethodDoc.getPath().contains(""/consumes-one"")) {
		Assert.assertEquals(1, apiMethodDoc.getConsumes().size());
		Assert.assertEquals(MediaType.APPLICATION_JSON_VALUE, apiMethodDoc.getConsumes().iterator().next());
	    }
	    if (apiMethodDoc.getPath().contains(""/consumes-two"")) {
		Assert.assertEquals(2, apiMethodDoc.getConsumes().size());
		Iterator<String> iterator = apiMethodDoc.getConsumes().iterator();
		Assert.assertEquals(MediaType.APPLICATION_JSON_VALUE, iterator.next());
		Assert.assertEquals(MediaType.APPLICATION_XML_VALUE, iterator.next());
	    }
	    if (apiMethodDoc.getPath().contains(""/consumes-three"")) {
		Assert.assertEquals(1, apiMethodDoc.getConsumes().size());
		Assert.assertEquals(MediaType.APPLICATION_XML_VALUE, apiMethodDoc.getConsumes().iterator().next());
	    }
	}
    }
"
"	@Test
	public void testQueryParam() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController"", apiDoc.getName());
		Assert.assertEquals(3, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/param-one"")) {
				Assert.assertEquals(1, apiMethodDoc.getQueryparameters().size());
			}
			if (apiMethodDoc.getPath().contains(""/param-two"")) {
				Assert.assertEquals(2, apiMethodDoc.getQueryparameters().size());
			}
			if (apiMethodDoc.getPath().contains(""/param-three"")) {
				Assert.assertEquals(2, apiMethodDoc.getQueryparameters().size());
				Iterator<ApiParamDoc> iterator = apiMethodDoc.getQueryparameters().iterator();
				ApiParamDoc param = iterator.next();
				Assert.assertEquals(""param"", param.getName());
				Assert.assertEquals(""value"", param.getAllowedvalues()[0]);
				ApiParamDoc param2 = iterator.next();
				Assert.assertEquals(""param2"", param2.getName());
				Assert.assertEquals(""value2"", param2.getAllowedvalues()[0]);
			}
		}
		
		apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController2.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController2"", apiDoc.getName());
		Assert.assertEquals(2, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/param-one"")) {
				Assert.assertEquals(2, apiMethodDoc.getQueryparameters().size());
			}
			if (apiMethodDoc.getPath().contains(""/param-two"")) {
				Assert.assertEquals(3, apiMethodDoc.getQueryparameters().size());
			}
		}
		
		apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController3.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController3"", apiDoc.getName());
		Assert.assertEquals(4, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/param-one"")) {
				Assert.assertEquals(2, apiMethodDoc.getQueryparameters().size());
				Iterator<ApiParamDoc> iterator = apiMethodDoc.getQueryparameters().iterator();
				ApiParamDoc param = iterator.next();
				ApiParamDoc queryParam = iterator.next();
				Assert.assertEquals(""name"", queryParam.getName());
				Assert.assertEquals(""true"", queryParam.getRequired());
				Assert.assertEquals(""string"", queryParam.getJsondocType().getOneLineText());
				Assert.assertEquals("""", queryParam.getDefaultvalue());
			}
			if (apiMethodDoc.getPath().contains(""/param-two"")) {
				Assert.assertEquals(2, apiMethodDoc.getQueryparameters().size());
				Iterator<ApiParamDoc> iterator = apiMethodDoc.getQueryparameters().iterator();
				ApiParamDoc param = iterator.next();
				ApiParamDoc queryParam = iterator.next();
				Assert.assertEquals(""name"", queryParam.getName());
				Assert.assertEquals(""false"", queryParam.getRequired());
				Assert.assertEquals(""string"", queryParam.getJsondocType().getOneLineText());
				Assert.assertEquals(""test"", queryParam.getDefaultvalue());
			}
			if (apiMethodDoc.getPath().contains(""/param-three"")) {
				Assert.assertEquals(2, apiMethodDoc.getQueryparameters().size());
				Iterator<ApiParamDoc> iterator = apiMethodDoc.getQueryparameters().iterator();
				ApiParamDoc param = iterator.next();
				ApiParamDoc queryParam = iterator.next();
				Assert.assertEquals("""", queryParam.getName());
				Assert.assertEquals(""true"", queryParam.getRequired());
				Assert.assertEquals(""string"", queryParam.getJsondocType().getOneLineText());
				Assert.assertEquals("""", queryParam.getDefaultvalue());
			}
			if (apiMethodDoc.getPath().contains(""/param-four"")) {
				Assert.assertEquals(2, apiMethodDoc.getQueryparameters().size());
				Iterator<ApiParamDoc> iterator = apiMethodDoc.getQueryparameters().iterator();
				ApiParamDoc param = iterator.next();
				ApiParamDoc queryParam = iterator.next();
				Assert.assertEquals(""value"", queryParam.getName());
				Assert.assertEquals(""false"", queryParam.getRequired());
				Assert.assertEquals(""string"", queryParam.getJsondocType().getOneLineText());
				Assert.assertEquals("""", queryParam.getDefaultvalue());
			}
		}
		
		apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController4.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController4"", apiDoc.getName());
		Assert.assertEquals(2, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/"")) {
				Assert.assertEquals(1, apiMethodDoc.getQueryparameters().size());
				ApiParamDoc param = apiMethodDoc.getQueryparameters().iterator().next();
				Assert.assertEquals(""name"", param.getName());
			}
			if (apiMethodDoc.getPath().contains(""/two"")) {
				Assert.assertEquals(2, apiMethodDoc.getQueryparameters().size());
			}
		}
		
		apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController5.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController5"", apiDoc.getName());
		Assert.assertEquals(1, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/"")) {
				Assert.assertEquals(1, apiMethodDoc.getQueryparameters().size());
				ApiParamDoc param = apiMethodDoc.getQueryparameters().iterator().next();
				Assert.assertEquals(""modelAttributePojo"", param.getName());
				Assert.assertEquals(""modelattributepojo"", param.getJsondocType().getOneLineText());
			}
		}
		
	}
"
"    @Test
    public void testGetMapping() {
        ApiDoc
            apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(RequestMappingController.class), MethodDisplay.URI).iterator().next();
        Assert.assertEquals(""RequestMappingController"", apiDoc.getName());

        boolean getMethodPresent = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
            @Override
            public boolean apply(ApiMethodDoc input) {
                return input.getMethod().equals(""get"");
            }
"
"	@Test
	public void testApiHeadersOnClass() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringApiHeadersController.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringApiHeadersController"", apiDoc.getName());
		Assert.assertEquals(3, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/spring-api-headers-controller-method-one"")) {
				Assert.assertEquals(2, apiMethodDoc.getHeaders().size());
			}
			if (apiMethodDoc.getPath().contains(""/spring-api-headers-controller-method-two"")) {
				Assert.assertEquals(3, apiMethodDoc.getHeaders().size());
			}
			if (apiMethodDoc.getPath().contains(""/spring-api-headers-controller-method-three"")) {
				Assert.assertEquals(4, apiMethodDoc.getHeaders().size());
				Iterator<ApiHeaderDoc> headers = apiMethodDoc.getHeaders().iterator();
				ApiHeaderDoc h1 = headers.next();
				ApiHeaderDoc h2 = headers.next();
				ApiHeaderDoc h4 = headers.next();
				Assert.assertEquals(""h4"", h4.getName());
				ApiHeaderDoc h5 = headers.next();
				Assert.assertEquals(""h5"", h5.getName());
			}
		}
	}
"
"	@Test
	public void testPathVariable() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController"", apiDoc.getName());
		Assert.assertEquals(2, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/param-one/{id}/{string}"")) {
				Assert.assertEquals(2, apiMethodDoc.getPathparameters().size());
				Iterator<ApiParamDoc> iterator = apiMethodDoc.getPathparameters().iterator();
				ApiParamDoc id = iterator.next();
				Assert.assertEquals("""", id.getName());
				Assert.assertEquals(""long"", id.getJsondocType().getOneLineText());
				ApiParamDoc name = iterator.next();
				Assert.assertEquals(""name"", name.getName());
				Assert.assertEquals(""string"", name.getJsondocType().getOneLineText());
			}
			
			if (apiMethodDoc.getPath().contains(""/param-one/{id}/{string}/{test}"")) {
				Assert.assertEquals(3, apiMethodDoc.getPathparameters().size());
				Iterator<ApiParamDoc> iterator = apiMethodDoc.getPathparameters().iterator();
				ApiParamDoc id = iterator.next();
				Assert.assertEquals(""id"", id.getName());
				Assert.assertEquals(""long"", id.getJsondocType().getOneLineText());
				ApiParamDoc name = iterator.next();
				Assert.assertEquals(""name"", name.getName());
				Assert.assertEquals(""string"", name.getJsondocType().getOneLineText());
				ApiParamDoc test = iterator.next();
				Assert.assertEquals("""", test.getName());
				Assert.assertEquals(""long"", test.getJsondocType().getOneLineText());
			}
		}
		
	}
"
"	@Test
	public void testPathVariableWithJSONDoc() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController2.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController2"", apiDoc.getName());
		Assert.assertEquals(1, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/param-one/{id}/{string}"")) {
				Assert.assertEquals(2, apiMethodDoc.getPathparameters().size());
				Iterator<ApiParamDoc> iterator = apiMethodDoc.getPathparameters().iterator();
				ApiParamDoc id = iterator.next();
				Assert.assertEquals("""", id.getName());
				Assert.assertEquals(""long"", id.getJsondocType().getOneLineText());
				Assert.assertEquals(""description for id"", id.getDescription());
				ApiParamDoc name = iterator.next();
				Assert.assertEquals(""name"", name.getName());
				Assert.assertEquals(""string"", name.getJsondocType().getOneLineText());
			}
		}
		
	}
"
"	@Test
	public void testBodyOne() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController"", apiDoc.getName());
		Assert.assertEquals(2, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/body-one"")) {
				Assert.assertNotNull(apiMethodDoc.getBodyobject());
				Assert.assertEquals(""string"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
			}
			if (apiMethodDoc.getPath().contains(""/body-two"")) {
				Assert.assertNotNull(apiMethodDoc.getBodyobject());
				Assert.assertEquals(""body"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
			}
		}
	}
"
"	@Test
	public void testApiVerb() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController"", apiDoc.getName());
		Assert.assertEquals(3, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/response-one"")) {
				Assert.assertEquals(""string"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
			}
			if (apiMethodDoc.getPath().contains(""/response-two"")) {
				Assert.assertEquals(""string"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
			}
			if (apiMethodDoc.getPath().contains(""/response-three"")) {
				Assert.assertEquals(""map[string, integer]"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
			}
		}
	}
"
"	@Test
	public void testApiVerb() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringApiVerbController.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringApiVerbController"", apiDoc.getName());
		Assert.assertEquals(2, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/api-verb/spring-api-verb-controller-method-one"")) {
				Assert.assertEquals(1, apiMethodDoc.getVerb().size());
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
			}
			if (apiMethodDoc.getPath().contains(""/api-verb/spring-api-verb-controller-method-two"")) {
				Assert.assertEquals(2, apiMethodDoc.getVerb().size());
			}
		}
		
		apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringApiVerbController2.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringApiVerbController2"", apiDoc.getName());
		Assert.assertEquals(1, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/api-verb-2/spring-api-verb-controller-method-one"")) {
				Assert.assertEquals(2, apiMethodDoc.getVerb().size());
			}
		}
		
	}
"
"	@Test
	public void testApiVerb() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController"", apiDoc.getName());
		Assert.assertEquals(3, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/produces-one"")) {
				Assert.assertEquals(1, apiMethodDoc.getProduces().size());
				Assert.assertEquals(MediaType.APPLICATION_JSON_VALUE, apiMethodDoc.getProduces().iterator().next());
			}
			if (apiMethodDoc.getPath().contains(""/produces-two"")) {
				Assert.assertEquals(2, apiMethodDoc.getProduces().size());
				Iterator<String> iterator = apiMethodDoc.getProduces().iterator();
				Assert.assertEquals(MediaType.APPLICATION_JSON_VALUE, iterator.next());
				Assert.assertEquals(MediaType.APPLICATION_XML_VALUE, iterator.next());
			}
			if (apiMethodDoc.getPath().contains(""/produces-three"")) {
				Assert.assertEquals(1, apiMethodDoc.getProduces().size());
				String produces = apiMethodDoc.getProduces().iterator().next();
				Assert.assertEquals(""application/json"", produces);
			}
		}
		
		apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController2.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController2"", apiDoc.getName());
		Assert.assertEquals(3, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/produces-one"")) {
				Assert.assertEquals(1, apiMethodDoc.getProduces().size());
				Assert.assertEquals(MediaType.APPLICATION_JSON_VALUE, apiMethodDoc.getProduces().iterator().next());
			}
			if (apiMethodDoc.getPath().contains(""/produces-two"")) {
				Assert.assertEquals(2, apiMethodDoc.getProduces().size());
				Iterator<String> iterator = apiMethodDoc.getProduces().iterator();
				Assert.assertEquals(MediaType.APPLICATION_JSON_VALUE, iterator.next());
				Assert.assertEquals(MediaType.APPLICATION_XML_VALUE, iterator.next());
			}
			if (apiMethodDoc.getPath().contains(""/produces-three"")) {
				Assert.assertEquals(1, apiMethodDoc.getProduces().size());
				Assert.assertEquals(MediaType.APPLICATION_XML_VALUE, apiMethodDoc.getProduces().iterator().next());
			}
		}
	}
"
"	@Test
	public void testMergeApiDoc() {
		Set<Class<?>> controllers = new LinkedHashSet<Class<?>>();
		controllers.add(SpringController.class);
		Set<ApiDoc> apiDocs = jsondocScanner.getApiDocs(controllers, MethodDisplay.URI);
		
		ApiDoc apiDoc = apiDocs.iterator().next();
		Assert.assertEquals(""A spring controller"", apiDoc.getDescription());
		Assert.assertEquals(""Spring controller"", apiDoc.getName());
		
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if(apiMethodDoc.getPath().contains(""/api/string/{name}"")) {
				Assert.assertNotNull(apiMethodDoc.getAuth());
				Assert.assertNotNull(apiMethodDoc.getSupportedversions());
				Assert.assertFalse(apiMethodDoc.getApierrors().isEmpty());
				
				Assert.assertEquals(""string"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				Assert.assertEquals(""string"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""/api/string/{name}"", apiMethodDoc.getPath().iterator().next());
				Assert.assertEquals(""POST"", apiMethodDoc.getVerb().iterator().next().name());
				Assert.assertEquals(""application/json"", apiMethodDoc.getProduces().iterator().next());
				Assert.assertEquals(""application/json"", apiMethodDoc.getConsumes().iterator().next());
				Assert.assertEquals(""201 - Created"", apiMethodDoc.getResponsestatuscode());
				
				Set<ApiHeaderDoc> headers = apiMethodDoc.getHeaders();
				ApiHeaderDoc header = headers.iterator().next();
				Assert.assertEquals(""header"", header.getName());
				Assert.assertEquals(""test"", header.getAllowedvalues()[0]);
				
				Set<ApiParamDoc> queryparameters = apiMethodDoc.getQueryparameters();
				Assert.assertEquals(3, queryparameters.size());
				Iterator<ApiParamDoc> qpIterator = queryparameters.iterator();
				ApiParamDoc apiParamDoc = qpIterator.next();
				Assert.assertEquals(""delete"", apiParamDoc.getName());
				Assert.assertEquals(""true"", apiParamDoc.getRequired());
				Assert.assertEquals(null, apiParamDoc.getDefaultvalue());
				Assert.assertEquals(0, apiParamDoc.getAllowedvalues().length);
				apiParamDoc = qpIterator.next();
				Assert.assertEquals(""id"", apiParamDoc.getName());
				Assert.assertEquals(""true"", apiParamDoc.getRequired());
				Assert.assertTrue(apiParamDoc.getDefaultvalue().isEmpty());
				apiParamDoc = qpIterator.next();
				Assert.assertEquals(""myquery"", apiParamDoc.getName());
				Assert.assertEquals(""true"", apiParamDoc.getRequired());
				Assert.assertEquals("""", apiParamDoc.getDefaultvalue());
				
				Set<ApiParamDoc> pathparameters = apiMethodDoc.getPathparameters();
				Iterator<ApiParamDoc> ppIterator = pathparameters.iterator();
				apiParamDoc = ppIterator.next();
				apiParamDoc = apiMethodDoc.getPathparameters().iterator().next();
				Assert.assertEquals(""test"", apiParamDoc.getName());
			}
		}
		
	}
"
"    @Test
    public void getJSONDoc() throws IOException {
        JSONDocScanner jsondocScanner = new Spring3JSONDocScanner();
        JSONDoc jsondoc = jsondocScanner.getJSONDoc(version, basePath, Lists.newArrayList(""org.jsondoc.springmvc.controller""), true, MethodDisplay.URI);

        Map<String, Set<ApiObjectDoc>> objects = jsondoc.getObjects();
        for (Set<ApiObjectDoc> values : objects.values()) {
            for (ApiObjectDoc apiObjectDoc : values) {
                System.out.println(apiObjectDoc.getName());
            }
        }

    }
"
"    @Test
    public void findsNestedObject() throws Exception {
        JSONDocScanner jsondocScanner = new Spring3JSONDocScanner();
        JSONDoc jsondoc = jsondocScanner.getJSONDoc(version, basePath, Lists.newArrayList(""org.jsondoc.springmvc.controller""), true, MethodDisplay.URI);

        Map<String, Set<ApiObjectDoc>> objects = jsondoc.getObjects();
        for (Set<ApiObjectDoc> values : objects.values()) {
            assertContainsDoc(values, ""NestedObject1"");
        }
    }
"
"    @Test
    public void findsDeeplyNestedObjects() throws Exception {
        JSONDocScanner jsondocScanner = new Spring3JSONDocScanner();
        JSONDoc jsondoc = jsondocScanner.getJSONDoc(version, basePath, Lists.newArrayList(""org.jsondoc.springmvc.controller""), true, MethodDisplay.URI);

        Map<String, Set<ApiObjectDoc>> objects = jsondoc.getObjects();
        for (Set<ApiObjectDoc> values : objects.values()) {
            assertContainsDoc(values, ""NestedObject2"");
            assertContainsDoc(values, ""NestedObject3"");
        }
    }
"
"  @Test
  public void testGetReconDbDir() throws Exception {

    String filePath = folder.getRoot().getAbsolutePath();
    OzoneConfiguration configuration = new OzoneConfiguration();
    configuration.set(""TEST_DB_DIR"", filePath);

    File file = new ReconUtils().getReconDbDir(configuration,
        ""TEST_DB_DIR"");
    Assert.assertEquals(filePath, file.getAbsolutePath());
  }
"
"  @Test
  public void testCreateTarFile() throws Exception {

    File tempSnapshotDir = null;
    FileInputStream fis = null;
    FileOutputStream fos = null;
    File tarFile = null;

    try {
      String testDirName = System.getProperty(""java.io.tmpdir"");
      if (!testDirName.endsWith(""/"")) {
        testDirName += ""/"";
      }
      testDirName += ""TestCreateTarFile_Dir"" + System.currentTimeMillis();
      tempSnapshotDir = new File(testDirName);
      tempSnapshotDir.mkdirs();

      File file = new File(testDirName + ""/temp1.txt"");
      OutputStreamWriter writer = new OutputStreamWriter(
          new FileOutputStream(file), UTF_8);
      writer.write(""Test data 1"");
      writer.close();

      file = new File(testDirName + ""/temp2.txt"");
      writer = new OutputStreamWriter(
          new FileOutputStream(file), UTF_8);
      writer.write(""Test data 2"");
      writer.close();

      tarFile = createTarFile(Paths.get(testDirName));
      Assert.assertNotNull(tarFile);

    } finally {
      org.apache.hadoop.io.IOUtils.closeStream(fis);
      org.apache.hadoop.io.IOUtils.closeStream(fos);
      FileUtils.deleteDirectory(tempSnapshotDir);
      FileUtils.deleteQuietly(tarFile);
    }
  }
"
"  @Test
  public void testUntarCheckpointFile() throws Exception {

    File newDir = folder.newFolder();

    File file1 = Paths.get(newDir.getAbsolutePath(), ""file1"")
        .toFile();
    String str = ""File1 Contents"";
    BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(
        new FileOutputStream(file1.getAbsoluteFile()), UTF_8));
    writer.write(str);
    writer.close();

    File file2 = Paths.get(newDir.getAbsolutePath(), ""file2"")
        .toFile();
    str = ""File2 Contents"";
    writer = new BufferedWriter(new OutputStreamWriter(
        new FileOutputStream(file2.getAbsoluteFile()), UTF_8));
    writer.write(str);
    writer.close();

    //Create test tar file.
    File tarFile = createTarFile(newDir.toPath());
    File outputDir = folder.newFolder();
    new ReconUtils().untarCheckpointFile(tarFile, outputDir.toPath());

    assertTrue(outputDir.isDirectory());
    assertTrue(outputDir.listFiles().length == 2);
  }
"
"  @Test
  public void testMakeHttpCall() throws Exception {
    String url = ""http://localhost:9874/dbCheckpoint"";
    File file1 = Paths.get(folder.getRoot().getPath(), ""file1"")
        .toFile();
    BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(
        new FileOutputStream(file1.getAbsoluteFile()), UTF_8));
    writer.write(""File 1 Contents"");
    writer.close();
    InputStream fileInputStream = new FileInputStream(file1);

    String contents;
    URLConnectionFactory connectionFactoryMock =
        mock(URLConnectionFactory.class);
    HttpURLConnection urlConnectionMock = mock(HttpURLConnection.class);
    when(urlConnectionMock.getInputStream()).thenReturn(fileInputStream);
    when(connectionFactoryMock.openConnection(any(URL.class), anyBoolean()))
        .thenReturn(urlConnectionMock);
    try (InputStream inputStream = new ReconUtils()
        .makeHttpCall(connectionFactoryMock, url, false).getInputStream()) {
      contents = IOUtils.toString(inputStream, Charset.defaultCharset());
    }

    assertEquals(""File 1 Contents"", contents);
  }
"
"  @Test
  public void testGetLastKnownDB() throws IOException {
    File newDir = folder.newFolder();

    File file1 = Paths.get(newDir.getAbsolutePath(), ""valid_1"")
        .toFile();
    String str = ""File1 Contents"";
    BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(
        new FileOutputStream(file1.getAbsoluteFile()), UTF_8));
    writer.write(str);
    writer.close();

    File file2 = Paths.get(newDir.getAbsolutePath(), ""valid_2"")
        .toFile();
    str = ""File2 Contents"";
    writer = new BufferedWriter(new OutputStreamWriter(
        new FileOutputStream(file2.getAbsoluteFile()), UTF_8));
    writer.write(str);
    writer.close();


    File file3 = Paths.get(newDir.getAbsolutePath(), ""invalid_3"")
        .toFile();
    str = ""File3 Contents"";
    writer = new BufferedWriter(new OutputStreamWriter(
        new FileOutputStream(file3.getAbsoluteFile()), UTF_8));
    writer.write(str);
    writer.close();

    ReconUtils reconUtils = new ReconUtils();
    File latestValidFile = reconUtils.getLastKnownDB(newDir, ""valid"");
    assertTrue(latestValidFile.getName().equals(""valid_2""));
  }
"
"  @Test
  public void testStart() throws Exception {

    OMMetadataManager omMetadataManager = getOMMetadataManager();

    //Take checkpoint of the above OM DB.
    DBCheckpoint checkpoint = omMetadataManager.getStore()
        .getCheckpoint(true);
    File snapshotFile = new File(
        checkpoint.getCheckpointLocation().getParent() + ""/"" +
            ""om.snapshot.db_"" + System.currentTimeMillis());
    checkpoint.getCheckpointLocation().toFile().renameTo(snapshotFile);

    //Create new Recon OM Metadata manager instance.
    File reconOmDbDir = temporaryFolder.newFolder();
    OzoneConfiguration configuration = new OzoneConfiguration();
    configuration.set(OZONE_RECON_OM_SNAPSHOT_DB_DIR, reconOmDbDir
        .getAbsolutePath());
    FileUtils.copyDirectory(snapshotFile.getParentFile(), reconOmDbDir);

    ReconOMMetadataManager reconOMMetadataManager =
        new ReconOmMetadataManagerImpl(configuration, new ReconUtils());
    reconOMMetadataManager.start(configuration);

    Assert.assertNotNull(reconOMMetadataManager.getBucketTable());
    Assert.assertNotNull(reconOMMetadataManager.getVolumeTable()
        .get(""/sampleVol""));
    Assert.assertNotNull(reconOMMetadataManager.getBucketTable()
        .get(""/sampleVol/bucketOne""));
    Assert.assertNotNull(reconOMMetadataManager.getKeyTable(getBucketLayout())
        .get(""/sampleVol/bucketOne/key_one""));
    Assert.assertNotNull(reconOMMetadataManager.getKeyTable(getBucketLayout())
        .get(""/sampleVol/bucketOne/key_two""));
  }
"
"  @Test
  public void testUpdateOmDB() throws Exception {

    OMMetadataManager omMetadataManager = getOMMetadataManager();
    //Make sure OM Metadata reflects the keys that were inserted.
    Assert.assertNotNull(omMetadataManager.getKeyTable(getBucketLayout())
        .get(""/sampleVol/bucketOne/key_one""));
    Assert.assertNotNull(omMetadataManager.getKeyTable(getBucketLayout())
        .get(""/sampleVol/bucketOne/key_two""));

    //Take checkpoint of OM DB.
    DBCheckpoint checkpoint = omMetadataManager.getStore()
        .getCheckpoint(true);
    Assert.assertNotNull(checkpoint.getCheckpointLocation());

    //Create new Recon OM Metadata manager instance.
    File reconOmDbDir = temporaryFolder.newFolder();
    OzoneConfiguration configuration = new OzoneConfiguration();
    configuration.set(OZONE_RECON_OM_SNAPSHOT_DB_DIR, reconOmDbDir
        .getAbsolutePath());
    ReconOMMetadataManager reconOMMetadataManager =
        new ReconOmMetadataManagerImpl(configuration, new ReconUtils());
    reconOMMetadataManager.start(configuration);

    //Before accepting a snapshot, the metadata should have null tables.
    Assert.assertNull(reconOMMetadataManager.getBucketTable());

    //Update Recon OM DB with the OM DB checkpoint location.
    reconOMMetadataManager.updateOmDB(
        checkpoint.getCheckpointLocation().toFile());

    //Now, the tables should have been initialized.
    Assert.assertNotNull(reconOMMetadataManager.getBucketTable());

    // Check volume and bucket entries.
    Assert.assertNotNull(reconOMMetadataManager.getVolumeTable()
        .get(""/sampleVol""));
    Assert.assertNotNull(reconOMMetadataManager.getBucketTable()
        .get(""/sampleVol/bucketOne""));

    //Verify Keys inserted in OM DB are available in Recon OM DB.
    Assert.assertNotNull(reconOMMetadataManager.getKeyTable(getBucketLayout())
        .get(""/sampleVol/bucketOne/key_one""));
    Assert.assertNotNull(reconOMMetadataManager.getKeyTable(getBucketLayout())
        .get(""/sampleVol/bucketOne/key_two""));

  }
"
"  @Test
  public void testReprocessOMDB() throws Exception{

    Map<ContainerKeyPrefix, Integer> keyPrefixesForContainer =
        reconContainerMetadataManager.getKeyPrefixesForContainer(1);
    assertTrue(keyPrefixesForContainer.isEmpty());

    keyPrefixesForContainer = reconContainerMetadataManager
        .getKeyPrefixesForContainer(2);
    assertTrue(keyPrefixesForContainer.isEmpty());

    Pipeline pipeline = getRandomPipeline();

    List<OmKeyLocationInfo> omKeyLocationInfoList = new ArrayList<>();
    BlockID blockID1 = new BlockID(1, 1);
    OmKeyLocationInfo omKeyLocationInfo1 = getOmKeyLocationInfo(blockID1,
        pipeline);

    BlockID blockID2 = new BlockID(2, 1);
    OmKeyLocationInfo omKeyLocationInfo2
        = getOmKeyLocationInfo(blockID2, pipeline);

    omKeyLocationInfoList.add(omKeyLocationInfo1);
    omKeyLocationInfoList.add(omKeyLocationInfo2);

    OmKeyLocationInfoGroup omKeyLocationInfoGroup = new
        OmKeyLocationInfoGroup(0, omKeyLocationInfoList);

    writeDataToOm(reconOMMetadataManager,
        ""key_one"",
        ""bucketOne"",
        ""sampleVol"",
        Collections.singletonList(omKeyLocationInfoGroup));

    ContainerKeyMapperTask containerKeyMapperTask =
        new ContainerKeyMapperTask(reconContainerMetadataManager);
    containerKeyMapperTask.reprocess(reconOMMetadataManager);

    keyPrefixesForContainer =
        reconContainerMetadataManager.getKeyPrefixesForContainer(1);
    assertEquals(1, keyPrefixesForContainer.size());
    String omKey = omMetadataManager.getOzoneKey(""sampleVol"",
        ""bucketOne"", ""key_one"");
    ContainerKeyPrefix containerKeyPrefix = new ContainerKeyPrefix(1,
        omKey, 0);
    assertEquals(1,
        keyPrefixesForContainer.get(containerKeyPrefix).intValue());

    keyPrefixesForContainer =
        reconContainerMetadataManager.getKeyPrefixesForContainer(2);
    assertEquals(1, keyPrefixesForContainer.size());
    containerKeyPrefix = new ContainerKeyPrefix(2, omKey,
        0);
    assertEquals(1,
        keyPrefixesForContainer.get(containerKeyPrefix).intValue());

    // Test if container key counts are updated
    assertEquals(1, reconContainerMetadataManager.getKeyCountForContainer(1L));
    assertEquals(1, reconContainerMetadataManager.getKeyCountForContainer(2L));
    assertEquals(0, reconContainerMetadataManager.getKeyCountForContainer(3L));

    // Test if container count is updated
    assertEquals(2, reconContainerMetadataManager.getCountForContainers());
  }
"
"  @Test
  public void testProcessOMEvents() throws IOException {
    Map<ContainerKeyPrefix, Integer> keyPrefixesForContainer =
        reconContainerMetadataManager.getKeyPrefixesForContainer(1);
    assertTrue(keyPrefixesForContainer.isEmpty());

    keyPrefixesForContainer = reconContainerMetadataManager
        .getKeyPrefixesForContainer(2);
    assertTrue(keyPrefixesForContainer.isEmpty());

    Pipeline pipeline = getRandomPipeline();

    List<OmKeyLocationInfo> omKeyLocationInfoList = new ArrayList<>();
    BlockID blockID1 = new BlockID(1, 1);
    OmKeyLocationInfo omKeyLocationInfo1 = getOmKeyLocationInfo(blockID1,
        pipeline);

    BlockID blockID2 = new BlockID(2, 1);
    OmKeyLocationInfo omKeyLocationInfo2
        = getOmKeyLocationInfo(blockID2, pipeline);

    omKeyLocationInfoList.add(omKeyLocationInfo1);
    omKeyLocationInfoList.add(omKeyLocationInfo2);

    OmKeyLocationInfoGroup omKeyLocationInfoGroup = new
        OmKeyLocationInfoGroup(0, omKeyLocationInfoList);

    String bucket = ""bucketOne"";
    String volume = ""sampleVol"";
    String key = ""key_one"";
    String omKey = omMetadataManager.getOzoneKey(volume, bucket, key);
    OmKeyInfo omKeyInfo = buildOmKeyInfo(volume, bucket, key,
        omKeyLocationInfoGroup);

    OMDBUpdateEvent keyEvent1 = new OMDBUpdateEvent.
        OMUpdateEventBuilder<String, OmKeyInfo>()
        .setKey(omKey)
        .setValue(omKeyInfo)
        .setTable(omMetadataManager.getKeyTable(getBucketLayout()).getName())
        .setAction(OMDBUpdateEvent.OMDBUpdateAction.PUT)
        .build();

    BlockID blockID3 = new BlockID(1, 2);
    OmKeyLocationInfo omKeyLocationInfo3 =
        getOmKeyLocationInfo(blockID3, pipeline);

    BlockID blockID4 = new BlockID(3, 1);
    OmKeyLocationInfo omKeyLocationInfo4
        = getOmKeyLocationInfo(blockID4, pipeline);

    omKeyLocationInfoList = new ArrayList<>();
    omKeyLocationInfoList.add(omKeyLocationInfo3);
    omKeyLocationInfoList.add(omKeyLocationInfo4);
    omKeyLocationInfoGroup = new OmKeyLocationInfoGroup(0,
        omKeyLocationInfoList);

    String key2 = ""key_two"";
    writeDataToOm(reconOMMetadataManager, key2, bucket, volume, Collections
        .singletonList(omKeyLocationInfoGroup));

    omKey = omMetadataManager.getOzoneKey(volume, bucket, key2);
    OMDBUpdateEvent keyEvent2 = new OMDBUpdateEvent.
        OMUpdateEventBuilder<String, OmKeyInfo>()
        .setKey(omKey)
        .setAction(OMDBUpdateEvent.OMDBUpdateAction.DELETE)
        .setTable(omMetadataManager.getKeyTable(getBucketLayout()).getName())
        .build();

    OMUpdateEventBatch omUpdateEventBatch = new OMUpdateEventBatch(new
        ArrayList<OMDBUpdateEvent>() {{
          add(keyEvent1);
          add(keyEvent2);
        }});

    ContainerKeyMapperTask containerKeyMapperTask =
        new ContainerKeyMapperTask(reconContainerMetadataManager);
    containerKeyMapperTask.reprocess(reconOMMetadataManager);

    keyPrefixesForContainer = reconContainerMetadataManager
        .getKeyPrefixesForContainer(1);
    assertEquals(1, keyPrefixesForContainer.size());

    keyPrefixesForContainer = reconContainerMetadataManager
        .getKeyPrefixesForContainer(2);
    assertTrue(keyPrefixesForContainer.isEmpty());

    keyPrefixesForContainer = reconContainerMetadataManager
        .getKeyPrefixesForContainer(3);
    assertEquals(1, keyPrefixesForContainer.size());

    assertEquals(1, reconContainerMetadataManager.getKeyCountForContainer(1L));
    assertEquals(0, reconContainerMetadataManager.getKeyCountForContainer(2L));
    assertEquals(1, reconContainerMetadataManager.getKeyCountForContainer(3L));

    // Process PUT & DELETE event.
    containerKeyMapperTask.process(omUpdateEventBatch);

    keyPrefixesForContainer = reconContainerMetadataManager
        .getKeyPrefixesForContainer(1);
    assertEquals(1, keyPrefixesForContainer.size());

    keyPrefixesForContainer = reconContainerMetadataManager
        .getKeyPrefixesForContainer(2);
    assertEquals(1, keyPrefixesForContainer.size());

    keyPrefixesForContainer = reconContainerMetadataManager
        .getKeyPrefixesForContainer(3);
    assertTrue(keyPrefixesForContainer.isEmpty());

    assertEquals(1, reconContainerMetadataManager.getKeyCountForContainer(1L));
    assertEquals(1, reconContainerMetadataManager.getKeyCountForContainer(2L));
    assertEquals(0, reconContainerMetadataManager.getKeyCountForContainer(3L));

    // Test if container count is updated
    assertEquals(3, reconContainerMetadataManager.getCountForContainers());
  }
"
"  @Test
  public void testReprocess() throws Exception {
    NSSummary nonExistentSummary =
            reconNamespaceSummaryManager.getNSSummary(BUCKET_ONE_OBJECT_ID);
    Assert.assertNull(nonExistentSummary);

    populateOMDB();

    // write a NSSummary prior to reprocess and verify it got cleaned up after.
    NSSummary staleNSSummary = new NSSummary();
    reconNamespaceSummaryManager.storeNSSummary(-1L, staleNSSummary);
    NSSummaryTask nsSummaryTask = new NSSummaryTask(
            reconNamespaceSummaryManager);
    nsSummaryTask.reprocess(reconOMMetadataManager);

    Assert.assertNull(reconNamespaceSummaryManager.getNSSummary(-1L));
    NSSummary nsSummaryForBucket1 =
            reconNamespaceSummaryManager.getNSSummary(BUCKET_ONE_OBJECT_ID);
    NSSummary nsSummaryForBucket2 =
            reconNamespaceSummaryManager.getNSSummary(BUCKET_TWO_OBJECT_ID);
    Assert.assertNotNull(nsSummaryForBucket1);
    Assert.assertNotNull(nsSummaryForBucket2);

    Assert.assertEquals(1, nsSummaryForBucket1.getNumOfFiles());
    Assert.assertEquals(2, nsSummaryForBucket2.getNumOfFiles());

    Assert.assertEquals(KEY_ONE_SIZE, nsSummaryForBucket1.getSizeOfFiles());
    Assert.assertEquals(KEY_TWO_OLD_SIZE + KEY_FOUR_SIZE,
            nsSummaryForBucket2.getSizeOfFiles());

    int[] fileDistBucket1 = nsSummaryForBucket1.getFileSizeBucket();
    int[] fileDistBucket2 = nsSummaryForBucket2.getFileSizeBucket();
    Assert.assertEquals(ReconConstants.NUM_OF_BINS, fileDistBucket1.length);
    Assert.assertEquals(ReconConstants.NUM_OF_BINS, fileDistBucket2.length);

    Assert.assertEquals(1, fileDistBucket1[0]);
    for (int i = 1; i < ReconConstants.NUM_OF_BINS; ++i) {
      Assert.assertEquals(0, fileDistBucket1[i]);
    }
    Assert.assertEquals(1, fileDistBucket2[1]);
    Assert.assertEquals(1, fileDistBucket2[2]);
    for (int i = 0; i < ReconConstants.NUM_OF_BINS; ++i) {
      if (i == 1 || i == 2) {
        continue;
      }
      Assert.assertEquals(0, fileDistBucket2[i]);
    }

    // Bucket one has one dir, bucket two has none.
    Set<Long> childDirBucketOne = nsSummaryForBucket1.getChildDir();
    Set<Long> childDirBucketTwo = nsSummaryForBucket2.getChildDir();
    Assert.assertEquals(1, childDirBucketOne.size());
    bucketOneAns.clear();
    bucketOneAns.add(DIR_ONE_OBJECT_ID);
    Assert.assertEquals(bucketOneAns, childDirBucketOne);
    Assert.assertEquals(0, childDirBucketTwo.size());

    // Dir 1 has two dir: dir2 and dir3.
    NSSummary nsSummaryInDir1 = reconNamespaceSummaryManager
            .getNSSummary(DIR_ONE_OBJECT_ID);
    Assert.assertNotNull(nsSummaryInDir1);
    Set<Long> childDirForDirOne = nsSummaryInDir1.getChildDir();
    Assert.assertEquals(2, childDirForDirOne.size());
    dirOneAns.clear();
    dirOneAns.add(DIR_TWO_OBJECT_ID);
    dirOneAns.add(DIR_THREE_OBJECT_ID);
    Assert.assertEquals(dirOneAns, childDirForDirOne);

    NSSummary nsSummaryInDir2 = reconNamespaceSummaryManager
            .getNSSummary(DIR_TWO_OBJECT_ID);
    Assert.assertEquals(1, nsSummaryInDir2.getNumOfFiles());
    Assert.assertEquals(KEY_THREE_SIZE, nsSummaryInDir2.getSizeOfFiles());

    int[] fileDistForDir2 = nsSummaryInDir2.getFileSizeBucket();
    Assert.assertEquals(ReconConstants.NUM_OF_BINS, fileDistForDir2.length);
    Assert.assertEquals(1, fileDistForDir2[fileDistForDir2.length - 1]);
    for (int i = 0; i < ReconConstants.NUM_OF_BINS - 1; ++i) {
      Assert.assertEquals(0, fileDistForDir2[i]);
    }
    Assert.assertEquals(0, nsSummaryInDir2.getChildDir().size());

    // bucket should have empty dirName
    Assert.assertEquals(0, nsSummaryForBucket1.getDirName().length());
    Assert.assertEquals(0, nsSummaryForBucket2.getDirName().length());
    // check dirName is correctly written
    Assert.assertEquals(DIR_ONE, nsSummaryInDir1.getDirName());
    Assert.assertEquals(DIR_TWO, nsSummaryInDir2.getDirName());
  }
"
"  @Test
  public void testProcess() throws Exception {
    NSSummary nonExistentSummary =
            reconNamespaceSummaryManager.getNSSummary(BUCKET_ONE_OBJECT_ID);
    Assert.assertNull(nonExistentSummary);

    populateOMDB();

    // Events for keyTable change:
    // put file5 under bucket 2
    String omPutKey = BUCKET_TWO_OBJECT_ID + OM_KEY_PREFIX + FILE_FIVE;
    OmKeyInfo omPutKeyInfo = buildOmKeyInfo(VOL, BUCKET_TWO, KEY_FIVE,
            FILE_FIVE, KEY_FIVE_OBJECT_ID, BUCKET_TWO_OBJECT_ID, KEY_FIVE_SIZE);
    OMDBUpdateEvent keyEvent1 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmKeyInfo>()
            .setKey(omPutKey)
            .setValue(omPutKeyInfo)
            .setTable(omMetadataManager.getKeyTable(getBucketLayout())
            .getName())
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.PUT)
            .build();

    // delete file 1 under bucket 1
    String omDeleteKey = BUCKET_ONE_OBJECT_ID + OM_KEY_PREFIX + FILE_ONE;
    OmKeyInfo omDeleteInfo = buildOmKeyInfo(VOL, BUCKET_ONE, KEY_ONE, FILE_ONE,
            KEY_ONE_OBJECT_ID, BUCKET_ONE_OBJECT_ID);
    OMDBUpdateEvent keyEvent2 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmKeyInfo>()
            .setKey(omDeleteKey)
            .setValue(omDeleteInfo)
            .setTable(omMetadataManager.getKeyTable(getBucketLayout())
            .getName())
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.DELETE)
            .build();

    // update file 2's size under bucket 2
    String omUpdateKey = BUCKET_TWO_OBJECT_ID + OM_KEY_PREFIX + FILE_TWO;
    OmKeyInfo omOldInfo = buildOmKeyInfo(VOL, BUCKET_TWO, KEY_TWO, FILE_TWO,
            KEY_TWO_OBJECT_ID, BUCKET_TWO_OBJECT_ID, KEY_TWO_OLD_SIZE);
    OmKeyInfo omUpdateInfo = buildOmKeyInfo(VOL, BUCKET_TWO, KEY_TWO, FILE_TWO,
            KEY_TWO_OBJECT_ID, BUCKET_TWO_OBJECT_ID, KEY_TWO_UPDATE_SIZE);
    OMDBUpdateEvent keyEvent3 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmKeyInfo>()
            .setKey(omUpdateKey)
            .setValue(omUpdateInfo)
            .setOldValue(omOldInfo)
            .setTable(omMetadataManager.getKeyTable(getBucketLayout())
            .getName())
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.UPDATE)
            .build();

    // Events for DirectoryTable change:
    // add dir 4 under bucket 1
    String omDirPutKey1 = BUCKET_ONE_OBJECT_ID + OM_KEY_PREFIX + DIR_FOUR;
    OmDirectoryInfo omDirPutValue1 = buildOmDirInfo(DIR_FOUR,
            DIR_FOUR_OBJECT_ID, BUCKET_ONE_OBJECT_ID);
    OMDBUpdateEvent keyEvent4 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmDirectoryInfo>()
            .setKey(omDirPutKey1)
            .setValue(omDirPutValue1)
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.PUT)
            .setTable(omMetadataManager.getDirectoryTable().getName())
            .build();

    // add dir 5 under bucket 2
    String omDirPutKey2 = BUCKET_TWO_OBJECT_ID + OM_KEY_PREFIX + DIR_FIVE;
    OmDirectoryInfo omDirPutValue2 = buildOmDirInfo(DIR_FIVE,
            DIR_FIVE_OBJECT_ID, BUCKET_TWO_OBJECT_ID);
    OMDBUpdateEvent keyEvent5 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmDirectoryInfo>()
            .setKey(omDirPutKey2)
            .setValue(omDirPutValue2)
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.PUT)
            .setTable(omMetadataManager.getDirectoryTable().getName())
            .build();

    // delete dir 3 under dir 1
    String omDirDeleteKey = DIR_ONE_OBJECT_ID + OM_KEY_PREFIX + DIR_THREE;
    OmDirectoryInfo omDirDeleteValue = buildOmDirInfo(DIR_FIVE,
            DIR_THREE_OBJECT_ID, DIR_ONE_OBJECT_ID);
    OMDBUpdateEvent keyEvent6 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmDirectoryInfo>()
            .setKey(omDirDeleteKey)
            .setValue(omDirDeleteValue)
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.DELETE)
            .setTable(omMetadataManager.getDirectoryTable().getName())
            .build();

    // rename dir1
    String omDirUpdateKey = BUCKET_ONE_OBJECT_ID + OM_KEY_PREFIX + DIR_ONE;
    OmDirectoryInfo omDirOldValue = buildOmDirInfo(DIR_ONE,
            DIR_ONE_OBJECT_ID, BUCKET_ONE_OBJECT_ID);
    OmDirectoryInfo omDirUpdateValue = buildOmDirInfo(DIR_ONE_RENAME,
            DIR_ONE_OBJECT_ID, BUCKET_ONE_OBJECT_ID);
    OMDBUpdateEvent keyEvent7 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmDirectoryInfo>()
            .setKey(omDirUpdateKey)
            .setValue(omDirUpdateValue)
            .setOldValue(omDirOldValue)
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.UPDATE)
            .setTable(omMetadataManager.getDirectoryTable().getName())
            .build();

    OMUpdateEventBatch omUpdateEventBatch = new OMUpdateEventBatch(
            new ArrayList<OMDBUpdateEvent>() {{
              add(keyEvent1);
              add(keyEvent2);
              add(keyEvent3);
              add(keyEvent4);
              add(keyEvent5);
              add(keyEvent6);
              add(keyEvent7);
          }});

    NSSummaryTask nsSummaryTask = new NSSummaryTask(
            reconNamespaceSummaryManager);
    nsSummaryTask.reprocess(reconOMMetadataManager);
    nsSummaryTask.process(omUpdateEventBatch);

    // file 5 is added under bucket 2, so bucket 2 has 3 keys now
    // file 1 is gone, so bucket 1 is empty now
    // file 2 is updated with new datasize,
    // so file size dist for bucket 2 should be updated
    NSSummary nsSummaryForBucket1 =
            reconNamespaceSummaryManager.getNSSummary(BUCKET_ONE_OBJECT_ID);
    Assert.assertNotNull(nsSummaryForBucket1);
    Assert.assertEquals(0, nsSummaryForBucket1.getNumOfFiles());

    Set<Long> childDirBucket1 = nsSummaryForBucket1.getChildDir();
    // after put dir4, bucket1 now has two child dirs: dir1 and dir4
    Assert.assertEquals(2, childDirBucket1.size());
    bucketOneAns.clear();
    bucketOneAns.add(DIR_ONE_OBJECT_ID);
    bucketOneAns.add(DIR_FOUR_OBJECT_ID);
    Assert.assertEquals(bucketOneAns, childDirBucket1);

    NSSummary nsSummaryForBucket2 =
            reconNamespaceSummaryManager.getNSSummary(BUCKET_TWO_OBJECT_ID);
    Assert.assertNotNull(nsSummaryForBucket2);
    Assert.assertEquals(3, nsSummaryForBucket2.getNumOfFiles());
    // key 4 + key 5 + updated key 2
    Assert.assertEquals(KEY_FOUR_SIZE + KEY_FIVE_SIZE + KEY_TWO_UPDATE_SIZE,
            nsSummaryForBucket2.getSizeOfFiles());

    int[] fileSizeDist = nsSummaryForBucket2.getFileSizeBucket();
    Assert.assertEquals(ReconConstants.NUM_OF_BINS, fileSizeDist.length);
    // 1023L and 100L
    Assert.assertEquals(2, fileSizeDist[0]);
    // 2050L
    Assert.assertEquals(1, fileSizeDist[2]);
    for (int i = 0; i < ReconConstants.NUM_OF_BINS; ++i) {
      if (i == 0 || i == 2) {
        continue;
      }
      Assert.assertEquals(0, fileSizeDist[i]);
    }

    // after put dir5, bucket 2 now has one dir
    Set<Long> childDirBucket2 = nsSummaryForBucket2.getChildDir();
    Assert.assertEquals(1, childDirBucket2.size());
    bucketTwoAns.add(DIR_FIVE_OBJECT_ID);
    Assert.assertEquals(bucketTwoAns, childDirBucket2);

    // after delete dir 3, dir 1 now has only one dir: dir2
    NSSummary nsSummaryForDir1 = reconNamespaceSummaryManager
            .getNSSummary(DIR_ONE_OBJECT_ID);
    Assert.assertNotNull(nsSummaryForDir1);
    Set<Long> childDirForDir1 = nsSummaryForDir1.getChildDir();
    Assert.assertEquals(1, childDirForDir1.size());
    dirOneAns.clear();
    dirOneAns.add(DIR_TWO_OBJECT_ID);
    Assert.assertEquals(dirOneAns, childDirForDir1);

    // after renaming dir1, check its new name
    Assert.assertEquals(DIR_ONE_RENAME, nsSummaryForDir1.getDirName());
  }
"
"  @Test
  public void testReprocess() throws IOException {
    OmKeyInfo omKeyInfo1 = mock(OmKeyInfo.class);
    given(omKeyInfo1.getKeyName()).willReturn(""key1"");
    given(omKeyInfo1.getVolumeName()).willReturn(""vol1"");
    given(omKeyInfo1.getBucketName()).willReturn(""bucket1"");
    given(omKeyInfo1.getDataSize()).willReturn(1000L);

    OmKeyInfo omKeyInfo2 = mock(OmKeyInfo.class);
    given(omKeyInfo2.getKeyName()).willReturn(""key2"");
    given(omKeyInfo2.getVolumeName()).willReturn(""vol1"");
    given(omKeyInfo2.getBucketName()).willReturn(""bucket1"");
    given(omKeyInfo2.getDataSize()).willReturn(100000L);

    OmKeyInfo omKeyInfo3 = mock(OmKeyInfo.class);
    given(omKeyInfo3.getKeyName()).willReturn(""key3"");
    given(omKeyInfo3.getVolumeName()).willReturn(""vol1"");
    given(omKeyInfo3.getBucketName()).willReturn(""bucket1"");
    given(omKeyInfo3.getDataSize()).willReturn(1125899906842624L * 4); // 4PB

    OMMetadataManager omMetadataManager = mock(OmMetadataManagerImpl.class);
    TypedTable<String, OmKeyInfo> keyTable = mock(TypedTable.class);

    TypedTable.TypedTableIterator mockKeyIter = mock(TypedTable
        .TypedTableIterator.class);
    TypedTable.TypedKeyValue mockKeyValue = mock(
        TypedTable.TypedKeyValue.class);

    when(keyTable.iterator()).thenReturn(mockKeyIter);
    when(omMetadataManager.getKeyTable(getBucketLayout())).thenReturn(keyTable);
    when(mockKeyIter.hasNext())
        .thenReturn(true)
        .thenReturn(true)
        .thenReturn(true)
        .thenReturn(false);
    when(mockKeyIter.next()).thenReturn(mockKeyValue);
    when(mockKeyValue.getValue())
        .thenReturn(omKeyInfo1)
        .thenReturn(omKeyInfo2)
        .thenReturn(omKeyInfo3);

    // Reprocess could be called from table having existing entries. Adding
    // an entry to simulate that.
    fileCountBySizeDao.insert(
        new FileCountBySize(""vol1"", ""bucket1"", 1024L, 10L));

    Pair<String, Boolean> result =
        fileSizeCountTask.reprocess(omMetadataManager);
    assertTrue(result.getRight());

    assertEquals(3, fileCountBySizeDao.count());
    Record3<String, String, Long> recordToFind = dslContext
        .newRecord(FILE_COUNT_BY_SIZE.VOLUME,
        FILE_COUNT_BY_SIZE.BUCKET,
        FILE_COUNT_BY_SIZE.FILE_SIZE)
        .value1(""vol1"")
        .value2(""bucket1"")
        .value3(1024L);
    assertEquals(1L,
        fileCountBySizeDao.findById(recordToFind).getCount().longValue());
    // file size upper bound for 100000L is 131072L (next highest power of 2)
    recordToFind.value3(131072L);
    assertEquals(1L,
        fileCountBySizeDao.findById(recordToFind).getCount().longValue());
    // file size upper bound for 4PB is Long.MAX_VALUE
    recordToFind.value3(Long.MAX_VALUE);
    assertEquals(1L,
        fileCountBySizeDao.findById(recordToFind).getCount().longValue());
  }
"
"  @Test
  public void testProcess() {
    // Write 2 keys.
    OmKeyInfo toBeDeletedKey = mock(OmKeyInfo.class);
    given(toBeDeletedKey.getVolumeName()).willReturn(""vol1"");
    given(toBeDeletedKey.getBucketName()).willReturn(""bucket1"");
    given(toBeDeletedKey.getKeyName()).willReturn(""deletedKey"");
    given(toBeDeletedKey.getDataSize()).willReturn(2000L); // Bin 1
    OMDBUpdateEvent event = new OMUpdateEventBuilder()
        .setAction(PUT)
        .setKey(""deletedKey"")
        .setValue(toBeDeletedKey)
        .setTable(OmMetadataManagerImpl.KEY_TABLE)
        .build();

    OmKeyInfo toBeUpdatedKey = mock(OmKeyInfo.class);
    given(toBeUpdatedKey.getVolumeName()).willReturn(""vol1"");
    given(toBeUpdatedKey.getBucketName()).willReturn(""bucket1"");
    given(toBeUpdatedKey.getKeyName()).willReturn(""updatedKey"");
    given(toBeUpdatedKey.getDataSize()).willReturn(10000L); // Bin 4
    OMDBUpdateEvent event2 = new OMUpdateEventBuilder()
        .setAction(PUT)
        .setKey(""updatedKey"")
        .setValue(toBeUpdatedKey)
        .setTable(OmMetadataManagerImpl.KEY_TABLE)
        .build();

    OMUpdateEventBatch omUpdateEventBatch =
        new OMUpdateEventBatch(Arrays.asList(event, event2));
    fileSizeCountTask.process(omUpdateEventBatch);

    // Verify 2 keys are in correct bins.
    assertEquals(2, fileCountBySizeDao.count());
    Record3<String, String, Long> recordToFind = dslContext
        .newRecord(FILE_COUNT_BY_SIZE.VOLUME,
            FILE_COUNT_BY_SIZE.BUCKET,
            FILE_COUNT_BY_SIZE.FILE_SIZE)
        .value1(""vol1"")
        .value2(""bucket1"")
        .value3(2048L);
    assertEquals(1L,
        fileCountBySizeDao.findById(recordToFind).getCount().longValue());
    // file size upper bound for 10000L is 16384L (next highest power of 2)
    recordToFind.value3(16384L);
    assertEquals(1L,
        fileCountBySizeDao.findById(recordToFind).getCount().longValue());

    // Add new key.
    OmKeyInfo newKey = mock(OmKeyInfo.class);
    given(newKey.getVolumeName()).willReturn(""vol1"");
    given(newKey.getBucketName()).willReturn(""bucket1"");
    given(newKey.getKeyName()).willReturn(""newKey"");
    given(newKey.getDataSize()).willReturn(1000L); // Bin 0
    OMDBUpdateEvent putEvent = new OMUpdateEventBuilder()
        .setAction(PUT)
        .setKey(""newKey"")
        .setValue(newKey)
        .setTable(OmMetadataManagerImpl.KEY_TABLE)
        .build();

    // Update existing key.
    OmKeyInfo updatedKey = mock(OmKeyInfo.class);
    given(updatedKey.getVolumeName()).willReturn(""vol1"");
    given(updatedKey.getBucketName()).willReturn(""bucket1"");
    given(updatedKey.getKeyName()).willReturn(""updatedKey"");
    given(updatedKey.getDataSize()).willReturn(50000L); // Bin 6
    OMDBUpdateEvent updateEvent = new OMUpdateEventBuilder()
        .setAction(UPDATE)
        .setKey(""updatedKey"")
        .setValue(updatedKey)
        .setOldValue(toBeUpdatedKey)
        .setTable(OmMetadataManagerImpl.KEY_TABLE)
        .build();

    // Delete another existing key.
    OMDBUpdateEvent deleteEvent = new OMUpdateEventBuilder()
        .setAction(DELETE)
        .setKey(""deletedKey"")
        .setValue(toBeDeletedKey)
        .setTable(OmMetadataManagerImpl.KEY_TABLE)
        .build();

    omUpdateEventBatch = new OMUpdateEventBatch(
        Arrays.asList(updateEvent, putEvent, deleteEvent));
    fileSizeCountTask.process(omUpdateEventBatch);

    assertEquals(4, fileCountBySizeDao.count());
    recordToFind.value3(1024L);
    assertEquals(1, fileCountBySizeDao.findById(recordToFind)
        .getCount().longValue());
    recordToFind.value3(2048L);
    assertEquals(0, fileCountBySizeDao.findById(recordToFind)
        .getCount().longValue());
    recordToFind.value3(16384L);
    assertEquals(0, fileCountBySizeDao.findById(recordToFind)
        .getCount().longValue());
    recordToFind.value3(65536L);
    assertEquals(1, fileCountBySizeDao.findById(recordToFind)
        .getCount().longValue());
  }
"
"  @Test
  public void testReprocessAtScale() throws IOException {
    // generate mocks for 2 volumes, 500 buckets each volume
    // and 42 keys in each bucket.
    List<OmKeyInfo> omKeyInfoList = new ArrayList<>();
    List<Boolean> hasNextAnswer = new ArrayList<>();
    for (int volIndex = 1; volIndex <= 2; volIndex++) {
      for (int bktIndex = 1; bktIndex <= 500; bktIndex++) {
        for (int keyIndex = 1; keyIndex <= 42; keyIndex++) {
          OmKeyInfo omKeyInfo = mock(OmKeyInfo.class);
          given(omKeyInfo.getKeyName()).willReturn(""key"" + keyIndex);
          given(omKeyInfo.getVolumeName()).willReturn(""vol"" + volIndex);
          given(omKeyInfo.getBucketName()).willReturn(""bucket"" + bktIndex);
          // Place keys in each bin
          long fileSize = (long)Math.pow(2, keyIndex + 9) - 1L;
          given(omKeyInfo.getDataSize()).willReturn(fileSize);
          omKeyInfoList.add(omKeyInfo);
          hasNextAnswer.add(true);
        }
      }
    }
    hasNextAnswer.add(false);

    OMMetadataManager omMetadataManager = mock(OmMetadataManagerImpl.class);
    TypedTable<String, OmKeyInfo> keyTable = mock(TypedTable.class);

    TypedTable.TypedTableIterator mockKeyIter = mock(TypedTable
        .TypedTableIterator.class);
    TypedTable.TypedKeyValue mockKeyValue = mock(
        TypedTable.TypedKeyValue.class);

    when(keyTable.iterator()).thenReturn(mockKeyIter);
    when(omMetadataManager.getKeyTable(getBucketLayout())).thenReturn(keyTable);
    when(mockKeyIter.hasNext())
        .thenAnswer(AdditionalAnswers.returnsElementsOf(hasNextAnswer));
    when(mockKeyIter.next()).thenReturn(mockKeyValue);
    when(mockKeyValue.getValue())
        .thenAnswer(AdditionalAnswers.returnsElementsOf(omKeyInfoList));

    Pair<String, Boolean> result =
        fileSizeCountTask.reprocess(omMetadataManager);
    assertTrue(result.getRight());

    // 2 volumes * 500 buckets * 42 bins = 42000 rows
    assertEquals(42000, fileCountBySizeDao.count());
    Record3<String, String, Long> recordToFind = dslContext
        .newRecord(FILE_COUNT_BY_SIZE.VOLUME,
            FILE_COUNT_BY_SIZE.BUCKET,
            FILE_COUNT_BY_SIZE.FILE_SIZE)
        .value1(""vol1"")
        .value2(""bucket1"")
        .value3(1024L);
    assertEquals(1L,
        fileCountBySizeDao.findById(recordToFind).getCount().longValue());
    // file size upper bound for 100000L is 131072L (next highest power of 2)
    recordToFind.value1(""vol1"");
    recordToFind.value3(131072L);
    assertEquals(1L,
        fileCountBySizeDao.findById(recordToFind).getCount().longValue());
    recordToFind.value2(""bucket500"");
    recordToFind.value3(Long.MAX_VALUE);
    assertEquals(1L,
        fileCountBySizeDao.findById(recordToFind).getCount().longValue());
  }
"
"  @Test
  public void testProcessAtScale() {
    // Write 10000 keys.
    List<OMDBUpdateEvent> omDbEventList = new ArrayList<>();
    List<OmKeyInfo> omKeyInfoList = new ArrayList<>();
    for (int volIndex = 1; volIndex <= 10; volIndex++) {
      for (int bktIndex = 1; bktIndex <= 100; bktIndex++) {
        for (int keyIndex = 1; keyIndex <= 10; keyIndex++) {
          OmKeyInfo omKeyInfo = mock(OmKeyInfo.class);
          given(omKeyInfo.getKeyName()).willReturn(""key"" + keyIndex);
          given(omKeyInfo.getVolumeName()).willReturn(""vol"" + volIndex);
          given(omKeyInfo.getBucketName()).willReturn(""bucket"" + bktIndex);
          // Place keys in each bin
          long fileSize = (long)Math.pow(2, keyIndex + 9) - 1L;
          given(omKeyInfo.getDataSize()).willReturn(fileSize);
          omKeyInfoList.add(omKeyInfo);
          omDbEventList.add(new OMUpdateEventBuilder()
              .setAction(PUT)
              .setKey(""key"" + keyIndex)
              .setValue(omKeyInfo)
              .setTable(OmMetadataManagerImpl.KEY_TABLE)
              .build());
        }
      }
    }

    OMUpdateEventBatch omUpdateEventBatch =
        new OMUpdateEventBatch(omDbEventList);
    fileSizeCountTask.process(omUpdateEventBatch);

    // Verify 2 keys are in correct bins.
    assertEquals(10000, fileCountBySizeDao.count());
    Record3<String, String, Long> recordToFind = dslContext
        .newRecord(FILE_COUNT_BY_SIZE.VOLUME,
            FILE_COUNT_BY_SIZE.BUCKET,
            FILE_COUNT_BY_SIZE.FILE_SIZE)
        .value1(""vol1"")
        .value2(""bucket1"")
        .value3(2048L);
    assertEquals(1L,
        fileCountBySizeDao.findById(recordToFind).getCount().longValue());
    recordToFind.value1(""vol10"");
    recordToFind.value2(""bucket100"");
    // file size upper bound for 10000L is 16384L (next highest power of 2)
    recordToFind.value3(16384L);
    assertEquals(1L,
        fileCountBySizeDao.findById(recordToFind).getCount().longValue());

    // Process 500 deletes and 500 updates
    omDbEventList = new ArrayList<>();
    for (int volIndex = 1; volIndex <= 1; volIndex++) {
      for (int bktIndex = 1; bktIndex <= 100; bktIndex++) {
        for (int keyIndex = 1; keyIndex <= 10; keyIndex++) {
          OmKeyInfo omKeyInfo = mock(OmKeyInfo.class);
          given(omKeyInfo.getKeyName()).willReturn(""key"" + keyIndex);
          given(omKeyInfo.getVolumeName()).willReturn(""vol"" + volIndex);
          given(omKeyInfo.getBucketName()).willReturn(""bucket"" + bktIndex);
          if (keyIndex <= 5) {
            long fileSize = (long)Math.pow(2, keyIndex + 9) - 1L;
            given(omKeyInfo.getDataSize()).willReturn(fileSize);
            omDbEventList.add(new OMUpdateEventBuilder()
                .setAction(DELETE)
                .setKey(""key"" + keyIndex)
                .setValue(omKeyInfo)
                .setTable(OmMetadataManagerImpl.KEY_TABLE)
                .build());
          } else {
            // update all the files with keyIndex > 5 to filesize 1023L
            // so that they get into first bin
            given(omKeyInfo.getDataSize()).willReturn(1023L);
            omDbEventList.add(new OMUpdateEventBuilder()
                .setAction(UPDATE)
                .setKey(""key"" + keyIndex)
                .setValue(omKeyInfo)
                .setTable(OmMetadataManagerImpl.KEY_TABLE)
                .setOldValue(
                    omKeyInfoList.get((volIndex * bktIndex) + keyIndex))
                .build());
          }
        }
      }
    }

    omUpdateEventBatch = new OMUpdateEventBatch(omDbEventList);
    fileSizeCountTask.process(omUpdateEventBatch);

    assertEquals(10000, fileCountBySizeDao.count());
    recordToFind = dslContext
        .newRecord(FILE_COUNT_BY_SIZE.VOLUME,
            FILE_COUNT_BY_SIZE.BUCKET,
            FILE_COUNT_BY_SIZE.FILE_SIZE)
        .value1(""vol1"")
        .value2(""bucket1"")
        .value3(1024L);
    // The update events on keys 6-10 should now put them under first bin 1024L
    assertEquals(5, fileCountBySizeDao.findById(recordToFind)
        .getCount().longValue());
    recordToFind.value2(""bucket100"");
    assertEquals(5, fileCountBySizeDao.findById(recordToFind)
        .getCount().longValue());
    recordToFind.value3(2048L);
    assertEquals(0, fileCountBySizeDao.findById(recordToFind)
        .getCount().longValue());
    // Volumes 2 - 10 should not be affected by this process
    recordToFind.value1(""vol2"");
    assertEquals(1, fileCountBySizeDao.findById(recordToFind)
        .getCount().longValue());
  }
"
"  @Test
  public void testRegisterTask() {
    String taskName = ""Dummy_"" + System.currentTimeMillis();
    DummyReconDBTask dummyReconDBTask =
        new DummyReconDBTask(taskName, DummyReconDBTask.TaskType.ALWAYS_PASS);
    reconTaskController.registerTask(dummyReconDBTask);
    assertTrue(reconTaskController.getRegisteredTasks().size() == 1);
    assertTrue(reconTaskController.getRegisteredTasks()
        .get(dummyReconDBTask.getTaskName()) == dummyReconDBTask);
  }
"
"  @Test
  public void testConsumeOMEvents() throws Exception {
    ReconOmTask reconOmTaskMock = getMockTask(""MockTask"");
    when(reconOmTaskMock.process(any(OMUpdateEventBatch.class)))
        .thenReturn(new ImmutablePair<>(""MockTask"", true));
    reconTaskController.registerTask(reconOmTaskMock);
    OMUpdateEventBatch omUpdateEventBatchMock = mock(OMUpdateEventBatch.class);
    when(omUpdateEventBatchMock.getLastSequenceNumber()).thenReturn(100L);
    when(omUpdateEventBatchMock.isEmpty()).thenReturn(false);

    long startTime = System.currentTimeMillis();
    reconTaskController.consumeOMEvents(
        omUpdateEventBatchMock,
        mock(OMMetadataManager.class));

    verify(reconOmTaskMock, times(1))
        .process(any());
    long endTime = System.currentTimeMillis();

    reconTaskStatusDao = getDao(ReconTaskStatusDao.class);
    ReconTaskStatus reconTaskStatus = reconTaskStatusDao.findById(""MockTask"");
    long taskTimeStamp = reconTaskStatus.getLastUpdatedTimestamp();
    long seqNumber = reconTaskStatus.getLastUpdatedSeqNumber();

    Assert.assertTrue(startTime <= taskTimeStamp
        && taskTimeStamp <= endTime);
    Assert.assertEquals(seqNumber,
        omUpdateEventBatchMock.getLastSequenceNumber());
  }
"
"  @Test
  public void testFailedTaskRetryLogic() throws Exception {
    String taskName = ""Dummy_"" + System.currentTimeMillis();

    DummyReconDBTask dummyReconDBTask =
        new DummyReconDBTask(taskName, DummyReconDBTask.TaskType.FAIL_ONCE);
    reconTaskController.registerTask(dummyReconDBTask);

    long currentTime = System.currentTimeMillis();
    OMUpdateEventBatch omUpdateEventBatchMock = mock(OMUpdateEventBatch.class);
    when(omUpdateEventBatchMock.isEmpty()).thenReturn(false);
    when(omUpdateEventBatchMock.getLastSequenceNumber()).thenReturn(100L);

    reconTaskController.consumeOMEvents(omUpdateEventBatchMock,
        mock(OMMetadataManager.class));
    assertFalse(reconTaskController.getRegisteredTasks().isEmpty());
    assertEquals(dummyReconDBTask, reconTaskController.getRegisteredTasks()
        .get(dummyReconDBTask.getTaskName()));

    reconTaskStatusDao = getDao(ReconTaskStatusDao.class);
    ReconTaskStatus dbRecord = reconTaskStatusDao.findById(taskName);

    Assert.assertEquals(taskName, dbRecord.getTaskName());
    Assert.assertTrue(
        dbRecord.getLastUpdatedTimestamp() > currentTime);

    Assert.assertEquals(Long.valueOf(100L), dbRecord.getLastUpdatedSeqNumber());
  }
"
"  @Test
  public void testBadBehavedTaskIsIgnored() throws Exception {
    String taskName = ""Dummy_"" + System.currentTimeMillis();
    DummyReconDBTask dummyReconDBTask =
        new DummyReconDBTask(taskName, DummyReconDBTask.TaskType.ALWAYS_FAIL);
    reconTaskController.registerTask(dummyReconDBTask);

    OMUpdateEventBatch omUpdateEventBatchMock = mock(OMUpdateEventBatch.class);
    when(omUpdateEventBatchMock.isEmpty()).thenReturn(false);
    when(omUpdateEventBatchMock.getLastSequenceNumber()).thenReturn(100L);

    OMMetadataManager omMetadataManagerMock = mock(OMMetadataManager.class);
    for (int i = 0; i < 2; i++) {
      reconTaskController.consumeOMEvents(omUpdateEventBatchMock,
          omMetadataManagerMock);

      assertFalse(reconTaskController.getRegisteredTasks().isEmpty());
      assertEquals(dummyReconDBTask, reconTaskController.getRegisteredTasks()
          .get(dummyReconDBTask.getTaskName()));
    }

    //Should be ignored now.
    reconTaskController.consumeOMEvents(omUpdateEventBatchMock,
        omMetadataManagerMock);
    assertTrue(reconTaskController.getRegisteredTasks().isEmpty());

    reconTaskStatusDao = getDao(ReconTaskStatusDao.class);
    ReconTaskStatus dbRecord = reconTaskStatusDao.findById(taskName);

    Assert.assertEquals(taskName, dbRecord.getTaskName());
    Assert.assertEquals(Long.valueOf(0L), dbRecord.getLastUpdatedTimestamp());
    Assert.assertEquals(Long.valueOf(0L), dbRecord.getLastUpdatedSeqNumber());
  }
"
"  @Test
  public void testReInitializeTasks() throws Exception {

    ReconOMMetadataManager omMetadataManagerMock = mock(
        ReconOMMetadataManager.class);
    ReconOmTask reconOmTaskMock =
        getMockTask(""MockTask2"");
    when(reconOmTaskMock.reprocess(omMetadataManagerMock))
        .thenReturn(new ImmutablePair<>(""MockTask2"", true));
    when(omMetadataManagerMock.getLastSequenceNumberFromDB()
    ).thenReturn(100L);

    long startTime = System.currentTimeMillis();
    reconTaskController.registerTask(reconOmTaskMock);
    reconTaskController.reInitializeTasks(omMetadataManagerMock);
    long endTime = System.currentTimeMillis();

    verify(reconOmTaskMock, times(1))
        .reprocess(omMetadataManagerMock);

    verify(omMetadataManagerMock, times(1)
    ).getLastSequenceNumberFromDB();

    ReconTaskStatus reconTaskStatus = reconTaskStatusDao.findById(""MockTask2"");
    long taskTimeStamp = reconTaskStatus.getLastUpdatedTimestamp();
    long seqNumber = reconTaskStatus.getLastUpdatedSeqNumber();

    Assert.assertTrue(startTime <= taskTimeStamp
        && taskTimeStamp <= endTime);
    Assert.assertEquals(seqNumber,
        omMetadataManagerMock.getLastSequenceNumberFromDB());
  }
"
"  @Test
  public void testPut() throws Exception {
    OzoneConfiguration configuration = createNewTestPath();
    OmMetadataManagerImpl metaMgr = new OmMetadataManagerImpl(configuration);

    // Create 1 volume, 2 keys and write to source OM DB.
    String volumeKey = metaMgr.getVolumeKey(""sampleVol"");
    OmVolumeArgs args =
        OmVolumeArgs.newBuilder()
            .setVolume(""sampleVol"")
            .setAdminName(""bilbo"")
            .setOwnerName(""bilbo"")
            .build();
    metaMgr.getVolumeTable().put(volumeKey, args);

    OmKeyInfo firstKey = getOmKeyInfo(""sampleVol"", ""bucketOne"", ""key_one"");
    metaMgr.getKeyTable(getBucketLayout())
        .put(""/sampleVol/bucketOne/key_one"", firstKey);

    OmKeyInfo secondKey = getOmKeyInfo(""sampleVol"", ""bucketOne"", ""key_two"");
    metaMgr.getKeyTable(getBucketLayout())
        .put(""/sampleVol/bucketOne/key_two"", secondKey);

    // Write the secondKey to the target OM DB.
    OzoneConfiguration conf2 = createNewTestPath();
    OmMetadataManagerImpl reconOmmetaMgr = new OmMetadataManagerImpl(conf2);
    reconOmmetaMgr.getKeyTable(getBucketLayout())
        .put(""/sampleVol/bucketOne/key_two"", secondKey);

    RDBStore rdbStore = (RDBStore) metaMgr.getStore();
    RocksDB rocksDB = rdbStore.getDb();
    // Get all updates from source DB. (3 PUTs)
    TransactionLogIterator transactionLogIterator =
        rocksDB.getUpdatesSince(0);
    List<byte[]> writeBatches = new ArrayList<>();

    while(transactionLogIterator.isValid()) {
      TransactionLogIterator.BatchResult result =
          transactionLogIterator.getBatch();
      result.writeBatch().markWalTerminationPoint();
      WriteBatch writeBatch = result.writeBatch();
      writeBatches.add(writeBatch.data());
      transactionLogIterator.next();
    }

    // OMDBUpdatesHandler has access to target DB. Hence it has only the
    // ""secondKey"".
    OMDBUpdatesHandler omdbUpdatesHandler =
        new OMDBUpdatesHandler(reconOmmetaMgr);
    for (byte[] data : writeBatches) {
      WriteBatch writeBatch = new WriteBatch(data);
      // Capture the 3 PUT events from source DB.
      writeBatch.iterate(omdbUpdatesHandler);
    }

    List<OMDBUpdateEvent> events = omdbUpdatesHandler.getEvents();
    assertEquals(3, events.size());

    OMDBUpdateEvent volEvent = events.get(0);
    assertEquals(PUT, volEvent.getAction());
    assertEquals(volumeKey, volEvent.getKey());
    assertEquals(args.getVolume(), ((OmVolumeArgs)volEvent.getValue())
        .getVolume());

    OMDBUpdateEvent keyEvent = events.get(1);
    assertEquals(PUT, keyEvent.getAction());
    assertEquals(""/sampleVol/bucketOne/key_one"", keyEvent.getKey());
    assertNull(keyEvent.getOldValue());

    OMDBUpdateEvent updateEvent = events.get(2);
    assertEquals(UPDATE, updateEvent.getAction());
    assertEquals(""/sampleVol/bucketOne/key_two"", updateEvent.getKey());
    assertNotNull(updateEvent.getOldValue());
    assertEquals(secondKey.getKeyName(),
        ((OmKeyInfo)updateEvent.getOldValue()).getKeyName());
  }
"
"  @Test
  public void testDelete() throws Exception {

    OzoneConfiguration configuration = createNewTestPath();
    OmMetadataManagerImpl metaMgr = new OmMetadataManagerImpl(configuration);

    OzoneConfiguration conf2 = createNewTestPath();
    OmMetadataManagerImpl metaMgrCopy = new OmMetadataManagerImpl(conf2);

    // Write 1 volume, 1 key into source and target OM DBs.
    String volumeKey = metaMgr.getVolumeKey(""sampleVol"");
    String nonExistVolumeKey = metaMgr.getVolumeKey(""nonExistingVolume"");
    OmVolumeArgs args =
        OmVolumeArgs.newBuilder()
            .setVolume(""sampleVol"")
            .setAdminName(""bilbo"")
            .setOwnerName(""bilbo"")
            .build();
    metaMgr.getVolumeTable().put(volumeKey, args);
    metaMgrCopy.getVolumeTable().put(volumeKey, args);

    OmKeyInfo omKeyInfo = getOmKeyInfo(""sampleVol"", ""bucketOne"", ""key_one"");
    metaMgr.getKeyTable(getBucketLayout())
        .put(""/sampleVol/bucketOne/key_one"", omKeyInfo);
    metaMgrCopy.getKeyTable(getBucketLayout())
        .put(""/sampleVol/bucketOne/key_one"", omKeyInfo);

    // Delete the volume and key from target DB.
    metaMgr.getKeyTable(getBucketLayout())
        .delete(""/sampleVol/bucketOne/key_one"");
    metaMgr.getVolumeTable().delete(volumeKey);
    // Delete a non-existing volume and key
    metaMgr.getKeyTable(getBucketLayout())
        .delete(""/sampleVol/bucketOne/key_two"");
    metaMgr.getVolumeTable().delete(metaMgr.getVolumeKey(""nonExistingVolume""));

    RDBStore rdbStore = (RDBStore) metaMgr.getStore();
    RocksDB rocksDB = rdbStore.getDb();
    TransactionLogIterator transactionLogIterator =
        rocksDB.getUpdatesSince(3);
    List<byte[]> writeBatches = new ArrayList<>();

    while(transactionLogIterator.isValid()) {
      TransactionLogIterator.BatchResult result =
          transactionLogIterator.getBatch();
      result.writeBatch().markWalTerminationPoint();
      WriteBatch writeBatch = result.writeBatch();
      writeBatches.add(writeBatch.data());
      transactionLogIterator.next();
    }

    // OMDBUpdatesHandler has access to target DB. So it has the volume and
    // key.
    OMDBUpdatesHandler omdbUpdatesHandler =
        new OMDBUpdatesHandler(metaMgrCopy);
    for (byte[] data : writeBatches) {
      WriteBatch writeBatch = new WriteBatch(data);
      writeBatch.iterate(omdbUpdatesHandler);
    }

    List<OMDBUpdateEvent> events = omdbUpdatesHandler.getEvents();
    assertEquals(4, events.size());

    OMDBUpdateEvent keyEvent = events.get(0);
    assertEquals(OMDBUpdateEvent.OMDBUpdateAction.DELETE, keyEvent.getAction());
    assertEquals(""/sampleVol/bucketOne/key_one"", keyEvent.getKey());
    assertEquals(omKeyInfo, keyEvent.getValue());

    OMDBUpdateEvent volEvent = events.get(1);
    assertEquals(OMDBUpdateEvent.OMDBUpdateAction.DELETE, volEvent.getAction());
    assertEquals(volumeKey, volEvent.getKey());
    assertNotNull(volEvent.getValue());
    OmVolumeArgs volumeInfo = (OmVolumeArgs) volEvent.getValue();
    assertEquals(""sampleVol"", volumeInfo.getVolume());

    // Assert the values of non existent keys are set to null.
    OMDBUpdateEvent nonExistKey = events.get(2);
    assertEquals(OMDBUpdateEvent.OMDBUpdateAction.DELETE,
        nonExistKey.getAction());
    assertEquals(""/sampleVol/bucketOne/key_two"", nonExistKey.getKey());
    assertNull(nonExistKey.getValue());

    OMDBUpdateEvent nonExistVolume = events.get(3);
    assertEquals(OMDBUpdateEvent.OMDBUpdateAction.DELETE,
        nonExistVolume.getAction());
    assertEquals(nonExistVolumeKey, nonExistVolume.getKey());
    assertNull(nonExistVolume.getValue());
  }
"
"  @Test
  public void testGetKeyType() throws IOException {
    OzoneConfiguration configuration = createNewTestPath();
    OmMetadataManagerImpl metaMgr = new OmMetadataManagerImpl(configuration);

    assertEquals(String.class, omdbDefinition.getKeyType(
        metaMgr.getKeyTable(getBucketLayout()).getName()).get());
    assertEquals(OzoneTokenIdentifier.class, omdbDefinition.getKeyType(
        metaMgr.getDelegationTokenTable().getName()).get());
  }
"
"  @Test
  public void testGetValueType() throws IOException {
    OzoneConfiguration configuration = createNewTestPath();
    OmMetadataManagerImpl metaMgr = new OmMetadataManagerImpl(configuration);

    assertEquals(OmKeyInfo.class, omdbDefinition.getValueType(
        metaMgr.getKeyTable(getBucketLayout()).getName()).get());
    assertEquals(OmVolumeArgs.class, omdbDefinition.getValueType(
        metaMgr.getVolumeTable().getName()).get());
    assertEquals(OmBucketInfo.class, omdbDefinition.getValueType(
        metaMgr.getBucketTable().getName()).get());
  }
"
"  @Test
  public void testReprocess() {
    OMMetadataManager omMetadataManager = mock(OmMetadataManagerImpl.class);
    // Mock 5 rows in each table and test the count
    for (String tableName: tableCountTask.getTaskTables()) {
      TypedTable<String, Object> table = mock(TypedTable.class);
      TypedTable.TypedTableIterator mockIter = mock(TypedTable
          .TypedTableIterator.class);
      when(table.iterator()).thenReturn(mockIter);
      when(omMetadataManager.getTable(tableName)).thenReturn(table);
      when(mockIter.hasNext())
          .thenReturn(true)
          .thenReturn(true)
          .thenReturn(true)
          .thenReturn(true)
          .thenReturn(true)
          .thenReturn(false);
    }

    Pair<String, Boolean> result = tableCountTask.reprocess(omMetadataManager);
    assertTrue(result.getRight());

    assertEquals(5L, getCountForTable(KEY_TABLE));
    assertEquals(5L, getCountForTable(VOLUME_TABLE));
    assertEquals(5L, getCountForTable(BUCKET_TABLE));
    assertEquals(5L, getCountForTable(OPEN_KEY_TABLE));
    assertEquals(5L, getCountForTable(DELETED_TABLE));
  }
"
"  @Test
  public void testProcess() {
    ArrayList<OMDBUpdateEvent> events = new ArrayList<>();
    // Create 5 put, 1 delete and 1 update event for each table
    for (String tableName: tableCountTask.getTaskTables()) {
      for (int i=0; i<5; i++) {
        events.add(getOMUpdateEvent(""item"" + i, null, tableName, PUT));
      }
      // for delete event, if value is set to null, the counter will not be
      // decremented. This is because the value will be null if item does not
      // exist in the database and there is no need to delete.
      events.add(getOMUpdateEvent(""item0"", mock(OmKeyInfo.class), tableName,
          DELETE));
      events.add(getOMUpdateEvent(""item1"", null, tableName, UPDATE));
    }
    OMUpdateEventBatch omUpdateEventBatch = new OMUpdateEventBatch(events);
    tableCountTask.process(omUpdateEventBatch);

    // Verify 4 items in each table. (5 puts - 1 delete + 0 update)
    assertEquals(4L, getCountForTable(KEY_TABLE));
    assertEquals(4L, getCountForTable(VOLUME_TABLE));
    assertEquals(4L, getCountForTable(BUCKET_TABLE));
    assertEquals(4L, getCountForTable(OPEN_KEY_TABLE));
    assertEquals(4L, getCountForTable(DELETED_TABLE));

    // add a new key and simulate delete on non-existing item (value: null)
    ArrayList<OMDBUpdateEvent> newEvents = new ArrayList<>();
    for (String tableName: tableCountTask.getTaskTables()) {
      newEvents.add(getOMUpdateEvent(""item5"", null, tableName, PUT));
      // This delete event should be a noop since value is null
      newEvents.add(getOMUpdateEvent(""item0"", null, tableName, DELETE));
    }

    omUpdateEventBatch = new OMUpdateEventBatch(newEvents);
    tableCountTask.process(omUpdateEventBatch);

    // Verify 5 items in each table. (1 new put + 0 delete)
    assertEquals(5L, getCountForTable(KEY_TABLE));
    assertEquals(5L, getCountForTable(VOLUME_TABLE));
    assertEquals(5L, getCountForTable(BUCKET_TABLE));
    assertEquals(5L, getCountForTable(OPEN_KEY_TABLE));
    assertEquals(5L, getCountForTable(DELETED_TABLE));
  }
"
"  @Test
  public void testReconSchemaCreated() throws Exception {
    Connection connection = getConnection();
    // Verify table definition
    DatabaseMetaData metaData = connection.getMetaData();
    ResultSet resultSet = metaData.getColumns(null, null,
        CLUSTER_GROWTH_DAILY_TABLE_NAME, null);

    List<Pair<String, Integer>> expectedPairs = new ArrayList<>();

    expectedPairs.add(new ImmutablePair<>(""timestamp"", Types.TIMESTAMP));
    expectedPairs.add(new ImmutablePair<>(""datanode_id"", Types.INTEGER));
    expectedPairs.add(new ImmutablePair<>(""datanode_host"", Types.VARCHAR));
    expectedPairs.add(new ImmutablePair<>(""rack_id"", Types.VARCHAR));
    expectedPairs.add(new ImmutablePair<>(""available_size"", Types.BIGINT));
    expectedPairs.add(new ImmutablePair<>(""used_size"", Types.BIGINT));
    expectedPairs.add(new ImmutablePair<>(""container_count"", Types.INTEGER));
    expectedPairs.add(new ImmutablePair<>(""block_count"", Types.INTEGER));

    List<Pair<String, Integer>> actualPairs = new ArrayList<>();

    while (resultSet.next()) {
      actualPairs.add(new ImmutablePair<>(resultSet.getString(""COLUMN_NAME""),
          resultSet.getInt(""DATA_TYPE"")));
    }

    Assert.assertEquals(8, actualPairs.size());
    Assert.assertEquals(expectedPairs, actualPairs);

    ResultSet resultSetFileCount = metaData.getColumns(null, null,
        FILE_COUNT_BY_SIZE_TABLE_NAME, null);

    List<Pair<String, Integer>> expectedPairsFileCount = new ArrayList<>();
    expectedPairsFileCount.add(
        new ImmutablePair<>(""volume"", Types.VARCHAR));
    expectedPairsFileCount.add(
        new ImmutablePair<>(""bucket"", Types.VARCHAR));
    expectedPairsFileCount.add(
        new ImmutablePair<>(""file_size"", Types.BIGINT));
    expectedPairsFileCount.add(
        new ImmutablePair<>(""count"", Types.BIGINT));

    List<Pair<String, Integer>> actualPairsFileCount = new ArrayList<>();
    while(resultSetFileCount.next()) {
      actualPairsFileCount.add(new ImmutablePair<>(resultSetFileCount.getString(
          ""COLUMN_NAME""), resultSetFileCount.getInt(
              ""DATA_TYPE"")));
    }
    assertEquals(""Unexpected number of columns"",
        4, actualPairsFileCount.size());
    assertEquals(""Columns Do not Match "",
        expectedPairsFileCount, actualPairsFileCount);
  }
"
"  @Test
  public void testClusterGrowthDailyCRUDOperations() throws Exception {
    // Verify table exists
    Connection connection = getConnection();

    DatabaseMetaData metaData = connection.getMetaData();
    ResultSet resultSet = metaData.getTables(null, null,
        CLUSTER_GROWTH_DAILY_TABLE_NAME, null);

    while (resultSet.next()) {
      Assert.assertEquals(CLUSTER_GROWTH_DAILY_TABLE_NAME,
          resultSet.getString(""TABLE_NAME""));
    }

    ClusterGrowthDailyDao dao = getDao(ClusterGrowthDailyDao.class);
    long now = System.currentTimeMillis();
    ClusterGrowthDaily newRecord = new ClusterGrowthDaily();
    newRecord.setTimestamp(new Timestamp(now));
    newRecord.setDatanodeId(10);
    newRecord.setDatanodeHost(""host1"");
    newRecord.setRackId(""rack1"");
    newRecord.setAvailableSize(1024L);
    newRecord.setUsedSize(512L);
    newRecord.setContainerCount(10);
    newRecord.setBlockCount(25);

    // Create
    dao.insert(newRecord);

    // Read
    ClusterGrowthDaily dbRecord =
        dao.findById(getDslContext().newRecord(CLUSTER_GROWTH_DAILY.TIMESTAMP,
            CLUSTER_GROWTH_DAILY.DATANODE_ID)
            .value1(new Timestamp(now)).value2(10));

    Assert.assertEquals(""host1"", dbRecord.getDatanodeHost());
    Assert.assertEquals(""rack1"", dbRecord.getRackId());
    Assert.assertEquals(Long.valueOf(1024), dbRecord.getAvailableSize());
    Assert.assertEquals(Long.valueOf(512), dbRecord.getUsedSize());
    Assert.assertEquals(Integer.valueOf(10), dbRecord.getContainerCount());
    Assert.assertEquals(Integer.valueOf(25), dbRecord.getBlockCount());

    // Update
    dbRecord.setUsedSize(700L);
    dbRecord.setBlockCount(30);
    dao.update(dbRecord);

    // Read updated
    dbRecord =
        dao.findById(getDslContext().newRecord(CLUSTER_GROWTH_DAILY.TIMESTAMP,
            CLUSTER_GROWTH_DAILY.DATANODE_ID)
            .value1(new Timestamp(now)).value2(10));

    Assert.assertEquals(Long.valueOf(700), dbRecord.getUsedSize());
    Assert.assertEquals(Integer.valueOf(30), dbRecord.getBlockCount());

    // Delete
    dao.deleteById(getDslContext().newRecord(CLUSTER_GROWTH_DAILY.TIMESTAMP,
        CLUSTER_GROWTH_DAILY.DATANODE_ID)
        .value1(new Timestamp(now)).value2(10));

    // Verify
    dbRecord =
        dao.findById(getDslContext().newRecord(CLUSTER_GROWTH_DAILY.TIMESTAMP,
            CLUSTER_GROWTH_DAILY.DATANODE_ID)
            .value1(new Timestamp(now)).value2(10));

    Assert.assertNull(dbRecord);
  }
"
"  @Test
  public void testFileCountBySizeCRUDOperations() throws SQLException {
    Connection connection = getConnection();

    DatabaseMetaData metaData = connection.getMetaData();
    ResultSet resultSet = metaData.getTables(null, null,
        FILE_COUNT_BY_SIZE_TABLE_NAME, null);

    while (resultSet.next()) {
      Assert.assertEquals(FILE_COUNT_BY_SIZE_TABLE_NAME,
          resultSet.getString(""TABLE_NAME""));
    }

    FileCountBySizeDao fileCountBySizeDao = getDao(FileCountBySizeDao.class);
    UtilizationSchemaDefinition utilizationSchemaDefinition =
        getSchemaDefinition(UtilizationSchemaDefinition.class);

    FileCountBySize newRecord = new FileCountBySize();
    newRecord.setVolume(""vol1"");
    newRecord.setBucket(""bucket1"");
    newRecord.setFileSize(1024L);
    newRecord.setCount(1L);

    fileCountBySizeDao.insert(newRecord);

    Record3<String, String, Long> recordToFind = utilizationSchemaDefinition
        .getDSLContext().newRecord(FILE_COUNT_BY_SIZE.VOLUME,
            FILE_COUNT_BY_SIZE.BUCKET,
            FILE_COUNT_BY_SIZE.FILE_SIZE)
        .value1(""vol1"")
        .value2(""bucket1"")
        .value3(1024L);
    FileCountBySize dbRecord = fileCountBySizeDao.findById(recordToFind);
    assertEquals(Long.valueOf(1), dbRecord.getCount());

    dbRecord.setCount(2L);
    fileCountBySizeDao.update(dbRecord);

    dbRecord = fileCountBySizeDao.findById(recordToFind);
    assertEquals(Long.valueOf(2), dbRecord.getCount());

    Table<FileCountBySizeRecord> fileCountBySizeRecordTable =
        fileCountBySizeDao.getTable();
    List<UniqueKey<FileCountBySizeRecord>> tableKeys =
        fileCountBySizeRecordTable.getKeys();
    for (UniqueKey key : tableKeys) {
      String name = key.getName();
    }
  }
"
"  @Test
  public void testSchemaCreated() throws Exception {

    Connection connection = getConnection();
    // Verify table definition
    DatabaseMetaData metaData = connection.getMetaData();
    ResultSet resultSet = metaData.getColumns(null, null,
        RECON_TASK_STATUS_TABLE_NAME, null);

    List<Pair<String, Integer>> expectedPairs = new ArrayList<>();

    expectedPairs.add(new ImmutablePair<>(""task_name"", Types.VARCHAR));
    expectedPairs.add(new ImmutablePair<>(""last_updated_timestamp"",
        Types.BIGINT));
    expectedPairs.add(new ImmutablePair<>(""last_updated_seq_number"",
        Types.BIGINT));

    List<Pair<String, Integer>> actualPairs = new ArrayList<>();

    while (resultSet.next()) {
      actualPairs.add(new ImmutablePair<>(
          resultSet.getString(""COLUMN_NAME""),
          resultSet.getInt(""DATA_TYPE"")));
    }

    Assert.assertEquals(3, actualPairs.size());
    Assert.assertEquals(expectedPairs, actualPairs);
  }
"
"  @Test
  public void testReconTaskStatusCRUDOperations() throws Exception {
    // Verify table exists
    Connection connection = getConnection();
    DatabaseMetaData metaData = connection.getMetaData();
    ResultSet resultSet = metaData.getTables(null, null,
        RECON_TASK_STATUS_TABLE_NAME, null);

    while (resultSet.next()) {
      Assert.assertEquals(RECON_TASK_STATUS_TABLE_NAME,
          resultSet.getString(""TABLE_NAME""));
    }

    ReconTaskStatusDao dao = getDao(ReconTaskStatusDao.class);
    long now = System.currentTimeMillis();
    ReconTaskStatus newRecord = new ReconTaskStatus();
    newRecord.setTaskName(""HelloWorldTask"");
    newRecord.setLastUpdatedTimestamp(now);
    newRecord.setLastUpdatedSeqNumber(100L);

    // Create
    dao.insert(newRecord);

    ReconTaskStatus newRecord2 = new ReconTaskStatus();
    newRecord2.setTaskName(""GoodbyeWorldTask"");
    newRecord2.setLastUpdatedTimestamp(now);
    newRecord2.setLastUpdatedSeqNumber(200L);
    // Create
    dao.insert(newRecord2);

    // Read
    ReconTaskStatus dbRecord = dao.findById(""HelloWorldTask"");

    Assert.assertEquals(""HelloWorldTask"", dbRecord.getTaskName());
    Assert.assertEquals(Long.valueOf(now), dbRecord.getLastUpdatedTimestamp());
    Assert.assertEquals(Long.valueOf(100), dbRecord.getLastUpdatedSeqNumber());

    // Update
    dbRecord.setLastUpdatedSeqNumber(150L);
    dao.update(dbRecord);

    // Read updated
    dbRecord = dao.findById(""HelloWorldTask"");
    Assert.assertEquals(Long.valueOf(150), dbRecord.getLastUpdatedSeqNumber());

    // Delete
    dao.deleteById(""GoodbyeWorldTask"");

    // Verify
    dbRecord = dao.findById(""GoodbyeWorldTask"");

    Assert.assertNull(dbRecord);
  }
"
"  @Test
  public void testSchemaSetup() throws SQLException {
    assertNotNull(getInjector());
    assertNotNull(getConfiguration());
    assertNotNull(getDslContext());
    assertNotNull(getConnection());
    RECON_DAO_LIST.forEach(dao -> {
      assertNotNull(getDao(dao));
    });
    ReconTaskStatusDao dao = getDao(ReconTaskStatusDao.class);
    dao.insert(new ReconTaskStatus(""TestTask"", 1L, 2L));
    assertEquals(1, dao.findAll().size());

    int numRows = getDslContext().delete(RECON_TASK_STATUS).execute();
    assertEquals(1, numRows);
    assertEquals(0, dao.findAll().size());
  }
"
"  @Test
  public void testSchemaSetup() throws SQLException {
    assertNotNull(getInjector());
    assertNotNull(getConfiguration());
    assertNotNull(getDslContext());
    assertNotNull(getConnection());
    RECON_DAO_LIST.forEach(dao -> {
      assertNotNull(getDao(dao));
    });
    ReconTaskStatusDao dao = getDao(ReconTaskStatusDao.class);
    dao.insert(new ReconTaskStatus(""TestTask"", 1L, 2L));
    assertEquals(1, dao.findAll().size());
  }
"
"  @Test
  public void testIfStatsSchemaCreated() throws Exception {
    Connection connection = getConnection();
    // Verify table definition
    DatabaseMetaData metaData = connection.getMetaData();
    ResultSet resultSet = metaData.getColumns(null, null,
        GLOBAL_STATS_TABLE_NAME, null);

    List<Pair<String, Integer>> expectedPairs = new ArrayList<>();

    expectedPairs.add(new ImmutablePair<>(""key"", Types.VARCHAR));
    expectedPairs.add(new ImmutablePair<>(""value"", Types.BIGINT));
    expectedPairs.add(new ImmutablePair<>(""last_updated_timestamp"",
        Types.TIMESTAMP));

    List<Pair<String, Integer>> actualPairs = new ArrayList<>();

    while (resultSet.next()) {
      actualPairs.add(new ImmutablePair<>(resultSet.getString(""COLUMN_NAME""),
          resultSet.getInt(""DATA_TYPE"")));
    }

    Assert.assertEquals(3, actualPairs.size());
    Assert.assertEquals(expectedPairs, actualPairs);
  }
"
"  @Test
  public void testGlobalStatsCRUDOperations() throws Exception {
    Connection connection = getConnection();

    DatabaseMetaData metaData = connection.getMetaData();
    ResultSet resultSet = metaData.getTables(null, null,
        GLOBAL_STATS_TABLE_NAME, null);

    while (resultSet.next()) {
      Assert.assertEquals(GLOBAL_STATS_TABLE_NAME,
          resultSet.getString(""TABLE_NAME""));
    }

    GlobalStatsDao dao = getDao(GlobalStatsDao.class);

    long now = System.currentTimeMillis();
    GlobalStats newRecord = new GlobalStats();
    newRecord.setLastUpdatedTimestamp(new Timestamp(now));
    newRecord.setKey(""key1"");
    newRecord.setValue(500L);

    // Create
    dao.insert(newRecord);
    GlobalStats newRecord2 = new GlobalStats();
    newRecord2.setLastUpdatedTimestamp(new Timestamp(now + 1000L));
    newRecord2.setKey(""key2"");
    newRecord2.setValue(10L);
    dao.insert(newRecord2);

    // Read
    GlobalStats dbRecord = dao.findById(""key1"");

    Assert.assertEquals(""key1"", dbRecord.getKey());
    Assert.assertEquals(Long.valueOf(500), dbRecord.getValue());
    Assert.assertEquals(new Timestamp(now), dbRecord.getLastUpdatedTimestamp());

    dbRecord = dao.findById(""key2"");
    Assert.assertEquals(""key2"", dbRecord.getKey());
    Assert.assertEquals(Long.valueOf(10), dbRecord.getValue());
    Assert.assertEquals(new Timestamp(now + 1000L),
        dbRecord.getLastUpdatedTimestamp());

    // Update
    dbRecord.setValue(100L);
    dbRecord.setLastUpdatedTimestamp(new Timestamp(now + 2000L));
    dao.update(dbRecord);

    // Read updated
    dbRecord = dao.findById(""key2"");

    Assert.assertEquals(new Timestamp(now + 2000L),
        dbRecord.getLastUpdatedTimestamp());
    Assert.assertEquals(Long.valueOf(100L), dbRecord.getValue());

    // Delete
    dao.deleteById(""key1"");

    // Verify
    dbRecord = dao.findById(""key1"");

    Assert.assertNull(dbRecord);
  }
"
"  @Test
  public void testMissingRecordRetained() {
    Set<ContainerReplica> replicas = new HashSet<>();
    ContainerHealthStatus status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    // Missing record should be retained
    assertTrue(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, missingRecord()));
    // Under / Over / Mis replicated should not be retained as if a container is
    // missing then it is not in any other category.
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, underReplicatedRecord()));
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, overReplicatedRecord()));
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, misReplicatedRecord()));

    replicas = generateReplicas(container, CLOSED, CLOSED, CLOSED);
    status = new ContainerHealthStatus(container, replicas, placementPolicy);
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, missingRecord()));
  }
"
"  @Test
  public void testUnderReplicatedRecordRetainedAndUpdated() {
    // under replicated container
    Set<ContainerReplica> replicas =
        generateReplicas(container, CLOSED, CLOSED);
    ContainerHealthStatus status =
        new ContainerHealthStatus(container, replicas, placementPolicy);

    UnhealthyContainersRecord rec = underReplicatedRecord();
    assertTrue(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, rec));
    // The record actual count should be updated from 1 -> 2
    assertEquals(2, rec.getActualReplicaCount().intValue());
    assertEquals(1, rec.getReplicaDelta().intValue());

    // Missing / Over / Mis replicated should not be retained
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, missingRecord()));
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, overReplicatedRecord()));
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, misReplicatedRecord()));

    // Container is now replicated OK - should be removed.
    replicas = generateReplicas(container, CLOSED, CLOSED, CLOSED);
    status = new ContainerHealthStatus(container, replicas, placementPolicy);
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, rec));
  }
"
"  @Test
  public void testOverReplicatedRecordRetainedAndUpdated() {
    // under replicated container
    Set<ContainerReplica> replicas =
        generateReplicas(container, CLOSED, CLOSED, CLOSED, CLOSED);
    ContainerHealthStatus status =
        new ContainerHealthStatus(container, replicas, placementPolicy);

    UnhealthyContainersRecord rec = overReplicatedRecord();
    assertTrue(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, rec));
    // The record actual count should be updated from 5 -> 4
    assertEquals(4, rec.getActualReplicaCount().intValue());
    assertEquals(-1, rec.getReplicaDelta().intValue());

    // Missing / Over / Mis replicated should not be retained
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, missingRecord()));
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, underReplicatedRecord()));
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, misReplicatedRecord()));

    // Container is now replicated OK - should be removed.
    replicas = generateReplicas(container, CLOSED, CLOSED, CLOSED);
    status = new ContainerHealthStatus(container, replicas, placementPolicy);
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, rec));
  }
"
"  @Test
  public void testMisReplicatedRecordRetainedAndUpdated() {
    // under replicated container
    Set<ContainerReplica> replicas =
        generateReplicas(container, CLOSED, CLOSED, CLOSED);
    when(placementPolicy.validateContainerPlacement(
        Mockito.anyList(), Mockito.anyInt()))
        .thenReturn(new ContainerPlacementStatusDefault(2, 3, 5));
    ContainerHealthStatus status =
        new ContainerHealthStatus(container, replicas, placementPolicy);

    UnhealthyContainersRecord rec = misReplicatedRecord();
    assertTrue(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, rec));
    // The record actual count should be updated from 1 -> 2
    assertEquals(2, rec.getActualReplicaCount().intValue());
    assertEquals(1, rec.getReplicaDelta().intValue());
    assertNotNull(rec.getReason());

    // Missing / Over / Mis replicated should not be retained
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, missingRecord()));
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, underReplicatedRecord()));
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, overReplicatedRecord()));

    // Container is now placed OK - should be removed.
    when(placementPolicy.validateContainerPlacement(
        Mockito.anyList(), Mockito.anyInt()))
        .thenReturn(new ContainerPlacementStatusDefault(3, 3, 5));
    status = new ContainerHealthStatus(container, replicas, placementPolicy);
    assertFalse(ContainerHealthTask.ContainerHealthRecords
        .retainOrUpdateRecord(status, rec));
  }
"
"  @Test
  public void testCorrectRecordsGenerated() {
    Set<ContainerReplica> replicas =
        generateReplicas(container, CLOSED, CLOSED, CLOSED);

    // HEALTHY container - no records generated.
    ContainerHealthStatus status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    List<UnhealthyContainers> records =
        ContainerHealthTask.ContainerHealthRecords
            .generateUnhealthyRecords(status, (long)1234567);
    assertEquals(0, records.size());

    // Over-replicated - expect 1 over replicated record
    replicas =
        generateReplicas(container, CLOSED, CLOSED, CLOSED, CLOSED, CLOSED);
    status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    records = ContainerHealthTask.ContainerHealthRecords
        .generateUnhealthyRecords(status, (long)1234567);
    assertEquals(1, records.size());
    UnhealthyContainers rec = records.get(0);
    assertEquals(UnHealthyContainerStates.OVER_REPLICATED.toString(),
        rec.getContainerState());
    assertEquals(3, rec.getExpectedReplicaCount().intValue());
    assertEquals(5, rec.getActualReplicaCount().intValue());
    assertEquals(-2, rec.getReplicaDelta().intValue());

    // Under and Mis Replicated - expect 2 records - mis and under replicated
    replicas =
        generateReplicas(container, CLOSED, CLOSED);
    when(placementPolicy.validateContainerPlacement(
        Mockito.anyList(), Mockito.anyInt()))
        .thenReturn(new ContainerPlacementStatusDefault(1, 2, 5));
    status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    records = ContainerHealthTask.ContainerHealthRecords
        .generateUnhealthyRecords(status, (long)1234567);
    assertEquals(2, records.size());

    rec = findRecordForState(records, UnHealthyContainerStates.MIS_REPLICATED);
    assertEquals(UnHealthyContainerStates.MIS_REPLICATED.toString(),
        rec.getContainerState());
    assertEquals(2, rec.getExpectedReplicaCount().intValue());
    assertEquals(1, rec.getActualReplicaCount().intValue());
    assertEquals(1, rec.getReplicaDelta().intValue());
    assertNotNull(rec.getReason());

    rec = findRecordForState(records,
        UnHealthyContainerStates.UNDER_REPLICATED);
    assertEquals(UnHealthyContainerStates.UNDER_REPLICATED.toString(),
        rec.getContainerState());
    assertEquals(3, rec.getExpectedReplicaCount().intValue());
    assertEquals(2, rec.getActualReplicaCount().intValue());
    assertEquals(1, rec.getReplicaDelta().intValue());

    // Missing Record - expect just a single missing record even though
    // it is mis-replicated too
    replicas.clear();
    when(placementPolicy.validateContainerPlacement(
        Mockito.anyList(), Mockito.anyInt()))
        .thenReturn(new ContainerPlacementStatusDefault(1, 2, 5));
    status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    records = ContainerHealthTask.ContainerHealthRecords
        .generateUnhealthyRecords(status, (long)1234567);
    assertEquals(1, records.size());
    rec = records.get(0);
    assertEquals(UnHealthyContainerStates.MISSING.toString(),
        rec.getContainerState());
    assertEquals(3, rec.getExpectedReplicaCount().intValue());
    assertEquals(0, rec.getActualReplicaCount().intValue());
    assertEquals(3, rec.getReplicaDelta().intValue());
  }
"
"  @Test
  public void testRecordNotGeneratedIfAlreadyExists() {
    Set<String> existingRec = new HashSet<>();
    for (UnHealthyContainerStates s : UnHealthyContainerStates.values()) {
      existingRec.add(s.toString());
    }

    // Over-replicated
    Set<ContainerReplica> replicas = generateReplicas(
        container, CLOSED, CLOSED, CLOSED, CLOSED, CLOSED);
    ContainerHealthStatus status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    List<UnhealthyContainers> records =
        ContainerHealthTask.ContainerHealthRecords
            .generateUnhealthyRecords(status, existingRec, (long)1234567);
    assertEquals(0, records.size());

    // Missing
    replicas.clear();
    status = new ContainerHealthStatus(container, replicas, placementPolicy);
    records = ContainerHealthTask.ContainerHealthRecords
        .generateUnhealthyRecords(status, existingRec, (long)1234567);
    assertEquals(0, records.size());

    // Under and Mis-Replicated
    replicas = generateReplicas(container, CLOSED, CLOSED);
    when(placementPolicy.validateContainerPlacement(
        Mockito.anyList(), Mockito.anyInt()))
        .thenReturn(new ContainerPlacementStatusDefault(1, 2, 5));
    status = new ContainerHealthStatus(container, replicas, placementPolicy);
    records = ContainerHealthTask.ContainerHealthRecords
        .generateUnhealthyRecords(status, existingRec, (long)1234567);
    assertEquals(0, records.size());
  }
"
"  @Test
  public void testHealthyContainer() {
    Set<ContainerReplica> replicas = generateReplicas(container,
        ContainerReplicaProto.State.CLOSED,
        ContainerReplicaProto.State.CLOSED,
        ContainerReplicaProto.State.CLOSED);
    ContainerHealthStatus status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    assertTrue(status.isHealthy());
    assertFalse(status.isOverReplicated());
    assertFalse(status.isUnderReplicated());
    assertEquals(0, status.replicaDelta());
    assertFalse(status.isMissing());
    assertEquals(false, status.isMisReplicated());
    assertEquals(0, status.misReplicatedDelta());

    assertEquals(container, status.getContainer());
    assertEquals((long)123456, status.getContainerID());
    assertEquals(3, status.getReplicationFactor());
    assertEquals(3, status.getReplicaCount());
  }
"
"  @Test
  public void testHealthyContainerWithExtraUnhealthyReplica() {
    Set<ContainerReplica> replicas = generateReplicas(container,
        ContainerReplicaProto.State.CLOSED,
        ContainerReplicaProto.State.CLOSED,
        ContainerReplicaProto.State.CLOSED,
        ContainerReplicaProto.State.UNHEALTHY);
    ContainerHealthStatus status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    assertTrue(status.isHealthy());
    assertFalse(status.isOverReplicated());
    assertFalse(status.isUnderReplicated());
    assertEquals(0, status.replicaDelta());
    assertFalse(status.isMissing());
    assertEquals(false, status.isMisReplicated());
    assertEquals(0, status.misReplicatedDelta());
  }
"
"  @Test
  public void testMissingContainer() {
    Set<ContainerReplica> replicas = new HashSet<>();
    ContainerHealthStatus status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    assertFalse(status.isHealthy());
    assertFalse(status.isOverReplicated());
    assertFalse(status.isUnderReplicated());
    assertEquals(3, status.replicaDelta());
    assertTrue(status.isMissing());
    assertEquals(false, status.isMisReplicated());
    assertEquals(0, status.misReplicatedDelta());
  }
"
"  @Test
  public void testUnderReplicatedContainer() {
    Set<ContainerReplica> replicas = generateReplicas(container,
        ContainerReplicaProto.State.CLOSED);
    ContainerHealthStatus status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    assertFalse(status.isHealthy());
    assertFalse(status.isMissing());
    assertFalse(status.isOverReplicated());
    assertTrue(status.isUnderReplicated());
    assertEquals(2, status.replicaDelta());
    assertEquals(false, status.isMisReplicated());
    assertEquals(0, status.misReplicatedDelta());
  }
"
"  @Test
  public void testOverReplicatedContainer() {
    Set<ContainerReplica> replicas = generateReplicas(container,
        ContainerReplicaProto.State.CLOSED,
        ContainerReplicaProto.State.CLOSED,
        ContainerReplicaProto.State.CLOSED,
        ContainerReplicaProto.State.CLOSED);
    ContainerHealthStatus status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    assertFalse(status.isHealthy());
    assertFalse(status.isMissing());
    assertFalse(status.isUnderReplicated());
    assertTrue(status.isOverReplicated());
    assertEquals(-1, status.replicaDelta());
    assertEquals(false, status.isMisReplicated());
    assertEquals(0, status.misReplicatedDelta());
  }
"
"  @Test
  public void testMisReplicated() {
    Set<ContainerReplica> replicas = generateReplicas(container,
        ContainerReplicaProto.State.CLOSED,
        ContainerReplicaProto.State.CLOSED,
        ContainerReplicaProto.State.CLOSED);
    when(placementPolicy.validateContainerPlacement(
        Mockito.anyList(), Mockito.anyInt()))
        .thenReturn(new ContainerPlacementStatusDefault(1, 2, 5));
    ContainerHealthStatus status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    assertFalse(status.isHealthy());
    assertFalse(status.isMissing());
    assertFalse(status.isUnderReplicated());
    assertFalse(status.isOverReplicated());
    assertEquals(0, status.replicaDelta());
    assertTrue(status.isMisReplicated());
    assertEquals(1, status.misReplicatedDelta());
  }
"
"  @Test
  public void testRun() throws Exception {
    UnhealthyContainersDao unHealthyContainersTableHandle =
        getDao(UnhealthyContainersDao.class);

    ContainerHealthSchemaManager containerHealthSchemaManager =
        new ContainerHealthSchemaManager(
            getSchemaDefinition(ContainerSchemaDefinition.class),
            unHealthyContainersTableHandle);
    ReconStorageContainerManagerFacade scmMock =
        mock(ReconStorageContainerManagerFacade.class);
    MockPlacementPolicy placementMock = new MockPlacementPolicy();
    ContainerManager containerManagerMock = mock(ContainerManager.class);
    StorageContainerServiceProvider scmClientMock =
        mock(StorageContainerServiceProvider.class);
    ContainerReplica unhealthyReplicaMock = mock(ContainerReplica.class);
    when(unhealthyReplicaMock.getState()).thenReturn(State.UNHEALTHY);
    ContainerReplica healthyReplicaMock = mock(ContainerReplica.class);
    when(healthyReplicaMock.getState()).thenReturn(State.CLOSED);

    // Create 6 containers. The first 5 will have various unhealthy states
    // defined below. The container with ID=6 will be healthy.
    List<ContainerInfo> mockContainers = getMockContainers(6);
    when(scmMock.getScmServiceProvider()).thenReturn(scmClientMock);
    when(scmMock.getContainerManager()).thenReturn(containerManagerMock);
    when(containerManagerMock.getContainers()).thenReturn(mockContainers);
    for (ContainerInfo c : mockContainers) {
      when(containerManagerMock.getContainer(c.containerID())).thenReturn(c);
      when(scmClientMock.getContainerWithPipeline(c.getContainerID()))
          .thenReturn(new ContainerWithPipeline(c, null));
    }
    // Under replicated
    when(containerManagerMock.getContainerReplicas(ContainerID.valueOf(1L)))
        .thenReturn(getMockReplicas(1L, State.CLOSED, State.UNHEALTHY));

    // return all UNHEALTHY replicas for container ID 2 -> UNDER_REPLICATED
    when(containerManagerMock.getContainerReplicas(ContainerID.valueOf(2L)))
        .thenReturn(getMockReplicas(2L, State.UNHEALTHY));

    // return 0 replicas for container ID 3 -> Missing
    when(containerManagerMock.getContainerReplicas(ContainerID.valueOf(3L)))
        .thenReturn(Collections.emptySet());

    // Return 5 Healthy -> Over replicated
    when(containerManagerMock.getContainerReplicas(ContainerID.valueOf(4L)))
        .thenReturn(getMockReplicas(4L, State.CLOSED, State.CLOSED,
        State.CLOSED, State.CLOSED, State.CLOSED));

    // Mis-replicated
    Set<ContainerReplica> misReplicas = getMockReplicas(5L,
        State.CLOSED, State.CLOSED, State.CLOSED);
    placementMock.setMisRepWhenDnPresent(
        misReplicas.iterator().next().getDatanodeDetails().getUuid());
    when(containerManagerMock.getContainerReplicas(ContainerID.valueOf(5L)))
        .thenReturn(misReplicas);

    // Return 3 Healthy -> Healthy container
    when(containerManagerMock.getContainerReplicas(ContainerID.valueOf(6L)))
        .thenReturn(getMockReplicas(6L,
            State.CLOSED, State.CLOSED, State.CLOSED));

    List<UnhealthyContainers> all = unHealthyContainersTableHandle.findAll();
    Assert.assertTrue(all.isEmpty());

    long currentTime = System.currentTimeMillis();
    ReconTaskStatusDao reconTaskStatusDao = getDao(ReconTaskStatusDao.class);
    ReconTaskConfig reconTaskConfig = new ReconTaskConfig();
    reconTaskConfig.setMissingContainerTaskInterval(Duration.ofSeconds(2));
    ContainerHealthTask containerHealthTask =
        new ContainerHealthTask(scmMock.getContainerManager(),
            scmMock.getScmServiceProvider(),
            reconTaskStatusDao, containerHealthSchemaManager,
            placementMock, reconTaskConfig);
    containerHealthTask.start();
    LambdaTestUtils.await(6000, 1000, () ->
        (unHealthyContainersTableHandle.count() == 5));
    UnhealthyContainers rec =
        unHealthyContainersTableHandle.fetchByContainerId(1L).get(0);
    assertEquals(""UNDER_REPLICATED"", rec.getContainerState());
    assertEquals(2, rec.getReplicaDelta().intValue());

    rec = unHealthyContainersTableHandle.fetchByContainerId(2L).get(0);
    assertEquals(""UNDER_REPLICATED"", rec.getContainerState());
    assertEquals(3, rec.getReplicaDelta().intValue());

    List<UnhealthyContainers> unhealthyContainers =
        containerHealthSchemaManager.getUnhealthyContainers(
            ALL_REPLICAS_UNHEALTHY, 0, Integer.MAX_VALUE);
    assertEquals(1, unhealthyContainers.size());
    assertEquals(2L,
        unhealthyContainers.get(0).getContainerId().longValue());
    assertEquals(0,
        unhealthyContainers.get(0).getActualReplicaCount().intValue());

    rec = unHealthyContainersTableHandle.fetchByContainerId(3L).get(0);
    assertEquals(""MISSING"", rec.getContainerState());
    assertEquals(3, rec.getReplicaDelta().intValue());

    rec = unHealthyContainersTableHandle.fetchByContainerId(4L).get(0);
    assertEquals(""OVER_REPLICATED"", rec.getContainerState());
    assertEquals(-2, rec.getReplicaDelta().intValue());

    rec = unHealthyContainersTableHandle.fetchByContainerId(5L).get(0);
    assertEquals(""MIS_REPLICATED"", rec.getContainerState());
    assertEquals(1, rec.getReplicaDelta().intValue());
    assertEquals(2, rec.getExpectedReplicaCount().intValue());
    assertEquals(1, rec.getActualReplicaCount().intValue());
    assertNotNull(rec.getReason());

    ReconTaskStatus taskStatus =
        reconTaskStatusDao.findById(containerHealthTask.getTaskName());
    Assert.assertTrue(taskStatus.getLastUpdatedTimestamp() >
        currentTime);

    // Now run the job again, to check that relevant records are updated or
    // removed as appropriate. Need to adjust the return value for all the mocks
    // Under replicated -> Delta goes from 2 to 1
    when(containerManagerMock.getContainerReplicas(ContainerID.valueOf(1L)))
        .thenReturn(getMockReplicas(1L, State.CLOSED, State.CLOSED));

    // ID 2 was missing - make it healthy now
    when(containerManagerMock.getContainerReplicas(ContainerID.valueOf(2L)))
        .thenReturn(getMockReplicas(2L,
            State.CLOSED, State.CLOSED, State.CLOSED));

    // return 0 replicas for container ID 3 -> Still Missing
    when(containerManagerMock.getContainerReplicas(ContainerID.valueOf(3L)))
        .thenReturn(Collections.emptySet());

    // Return 4 Healthy -> Delta changes from -2 to -1
    when(containerManagerMock.getContainerReplicas(ContainerID.valueOf(4L)))
        .thenReturn(getMockReplicas(4L, State.CLOSED, State.CLOSED,
            State.CLOSED, State.CLOSED));

    // Was mis-replicated - make it healthy now
    placementMock.setMisRepWhenDnPresent(null);

    LambdaTestUtils.await(6000, 1000, () ->
        (unHealthyContainersTableHandle.count() == 3));
    rec = unHealthyContainersTableHandle.fetchByContainerId(1L).get(0);
    assertEquals(""UNDER_REPLICATED"", rec.getContainerState());
    assertEquals(1, rec.getReplicaDelta().intValue());

    // This container is now healthy, it should not be in the table any more
    assertEquals(0,
        unHealthyContainersTableHandle.fetchByContainerId(2L).size());

    rec = unHealthyContainersTableHandle.fetchByContainerId(3L).get(0);

    assertEquals(""MISSING"", rec.getContainerState());
    assertEquals(3, rec.getReplicaDelta().intValue());

    rec = unHealthyContainersTableHandle.fetchByContainerId(4L).get(0);
    assertEquals(""OVER_REPLICATED"", rec.getContainerState());
    assertEquals(-1, rec.getReplicaDelta().intValue());

    // This container is now healthy, it should not be in the table any more
    assertEquals(0,
        unHealthyContainersTableHandle.fetchByContainerId(5L).size());
  }
"
"  @Test
  public void testDeletedContainer() throws Exception {
    UnhealthyContainersDao unHealthyContainersTableHandle =
        getDao(UnhealthyContainersDao.class);

    ContainerHealthSchemaManager containerHealthSchemaManager =
        new ContainerHealthSchemaManager(
            getSchemaDefinition(ContainerSchemaDefinition.class),
            unHealthyContainersTableHandle);
    ReconStorageContainerManagerFacade scmMock =
        mock(ReconStorageContainerManagerFacade.class);
    MockPlacementPolicy placementMock = new MockPlacementPolicy();
    ContainerManager containerManagerMock = mock(ContainerManager.class);
    StorageContainerServiceProvider scmClientMock =
        mock(StorageContainerServiceProvider.class);

    // Create 2 containers. The first is OPEN will no replicas, the second is
    // CLOSED with no replicas.
    List<ContainerInfo> mockContainers = getMockContainers(2);
    when(scmMock.getScmServiceProvider()).thenReturn(scmClientMock);
    when(scmMock.getContainerManager()).thenReturn(containerManagerMock);
    when(containerManagerMock.getContainers()).thenReturn(mockContainers);
    for (ContainerInfo c : mockContainers) {
      when(containerManagerMock.getContainer(c.containerID())).thenReturn(c);
      when(scmClientMock.getContainerWithPipeline(c.getContainerID()))
          .thenReturn(new ContainerWithPipeline(c, null));
    }
    // Container State OPEN with no replicas
    when(containerManagerMock.getContainer(ContainerID.valueOf(1L)).getState())
        .thenReturn(HddsProtos.LifeCycleState.OPEN);
    when(containerManagerMock.getContainerReplicas(ContainerID.valueOf(1L)))
        .thenReturn(Collections.emptySet());
    when(scmClientMock.getContainerWithPipeline(1))
        .thenReturn(new ContainerWithPipeline(mockContainers.get(0), null));

    // Container State CLOSED with no replicas
    when(containerManagerMock.getContainer(ContainerID.valueOf(2L)).getState())
        .thenReturn(HddsProtos.LifeCycleState.CLOSED);
    when(containerManagerMock.getContainerReplicas(ContainerID.valueOf(2L)))
        .thenReturn(Collections.emptySet());
    ContainerInfo mockDeletedContainer = getMockDeletedContainer(2);
    when(scmClientMock.getContainerWithPipeline(2))
        .thenReturn(new ContainerWithPipeline(mockDeletedContainer, null));

    List<UnhealthyContainers> all = unHealthyContainersTableHandle.findAll();
    Assert.assertTrue(all.isEmpty());

    long currentTime = System.currentTimeMillis();
    ReconTaskStatusDao reconTaskStatusDao = getDao(ReconTaskStatusDao.class);
    ReconTaskConfig reconTaskConfig = new ReconTaskConfig();
    reconTaskConfig.setMissingContainerTaskInterval(Duration.ofSeconds(2));
    ContainerHealthTask containerHealthTask =
        new ContainerHealthTask(scmMock.getContainerManager(),
            scmMock.getScmServiceProvider(),
            reconTaskStatusDao, containerHealthSchemaManager,
            placementMock, reconTaskConfig);
    containerHealthTask.start();
    LambdaTestUtils.await(6000, 1000, () ->
        (unHealthyContainersTableHandle.count() == 1));
    UnhealthyContainers rec =
        unHealthyContainersTableHandle.fetchByContainerId(1L).get(0);
    assertEquals(""MISSING"", rec.getContainerState());
    assertEquals(3, rec.getReplicaDelta().intValue());

    ReconTaskStatus taskStatus =
        reconTaskStatusDao.findById(containerHealthTask.getTaskName());
    Assert.assertTrue(taskStatus.getLastUpdatedTimestamp() >
        currentTime);
  }
"
"  @Test
  public void testProcessPipelineReport() throws IOException {

    // Check with pipeline which does not exist in Recon.
    Pipeline pipeline = getRandomPipeline();
    PipelineID pipelineID = pipeline.getId();
    HddsProtos.PipelineID pipelineIDProto =  pipelineID.getProtobuf();

    ReconPipelineManager reconPipelineManagerMock = mock(
        ReconPipelineManager.class);
    when(reconPipelineManagerMock.getPipeline(pipelineID)).thenReturn(pipeline);

    StorageContainerServiceProvider scmServiceProviderMock = mock(
        StorageContainerServiceProvider.class);
    when(scmServiceProviderMock.getPipeline(pipelineIDProto))
        .thenReturn(pipeline);

    OzoneConfiguration configuration = new OzoneConfiguration();

    ReconPipelineReportHandler handler =
        new ReconPipelineReportHandler(new ReconSafeModeManager(),
            reconPipelineManagerMock, SCMContext.emptyContext(),
            configuration, scmServiceProviderMock);

    EventPublisher eventPublisherMock = mock(EventPublisher.class);
    PipelineReport report = mock(PipelineReport.class);
    when(report.getPipelineID()).thenReturn(pipelineIDProto);

    handler.processPipelineReport(report, pipeline.getNodes().get(0),
        eventPublisherMock);

    // Verify that the new pipeline was added to pipeline manager.
    verify(reconPipelineManagerMock, times(1))
        .addPipeline(pipeline);
    verify(reconPipelineManagerMock, times(1))
        .getPipeline(pipelineID);

    // Check with pipeline which already exists in Recon.
    pipeline = getRandomPipeline();
    pipelineID = pipeline.getId();
    pipelineIDProto =  pipelineID.getProtobuf();

    when(reconPipelineManagerMock.containsPipeline(pipelineID))
        .thenReturn(true);
    when(reconPipelineManagerMock.getPipeline(pipelineID))
        .thenReturn(pipeline);
    when(report.getPipelineID()).thenReturn(pipelineIDProto);

    handler.processPipelineReport(report, pipeline.getNodes().get(0),
        eventPublisherMock);

    // Verify that the pipeline was not added to pipeline manager.
    verify(reconPipelineManagerMock, times(0))
        .addPipeline(pipeline);
    verify(reconPipelineManagerMock, times(1))
        .getPipeline(pipelineID);
  }
"
"  @Test
  public void testProcessICR() throws IOException, NodeNotFoundException {

    ContainerID containerID = ContainerID.valueOf(100L);
    DatanodeDetails datanodeDetails = randomDatanodeDetails();
    IncrementalContainerReportFromDatanode reportMock =
        mock(IncrementalContainerReportFromDatanode.class);
    when(reportMock.getDatanodeDetails()).thenReturn(datanodeDetails);
    IncrementalContainerReportProto containerReport =
        getIncrementalContainerReportProto(containerID,
            State.OPEN,
            datanodeDetails.getUuidString());
    when(reportMock.getReport()).thenReturn(containerReport);

    final String path =
        GenericTestUtils.getTempPath(UUID.randomUUID().toString());
    Path scmPath = Paths.get(path, ""scm-meta"");
    final OzoneConfiguration conf = new OzoneConfiguration();
    conf.set(HddsConfigKeys.OZONE_METADATA_DIRS, scmPath.toString());
    NetworkTopology clusterMap = new NetworkTopologyImpl(conf);
    EventQueue eventQueue = new EventQueue();
    SCMStorageConfig storageConfig = new SCMStorageConfig(conf);
    this.versionManager =
        Mockito.mock(HDDSLayoutVersionManager.class);
    Mockito.when(versionManager.getMetadataLayoutVersion())
        .thenReturn(maxLayoutVersion());
    Mockito.when(versionManager.getSoftwareLayoutVersion())
        .thenReturn(maxLayoutVersion());

    NodeManager nodeManager = new SCMNodeManager(conf, storageConfig,
        eventQueue, clusterMap, SCMContext.emptyContext(), versionManager);

    nodeManager.register(datanodeDetails, null, null);

    ReconContainerManager containerManager = getContainerManager();
    ReconIncrementalContainerReportHandler reconIcr =
        new ReconIncrementalContainerReportHandler(nodeManager,
            containerManager, SCMContext.emptyContext());
    EventPublisher eventPublisherMock = mock(EventPublisher.class);

    reconIcr.onMessage(reportMock, eventPublisherMock);
    nodeManager.addContainer(datanodeDetails, containerID);
    assertTrue(containerManager.containerExist(containerID));
    assertEquals(1, containerManager.getContainerReplicas(containerID).size());
    assertEquals(OPEN, containerManager.getContainer(containerID).getState());
  }
"
"  @Test
  public void testProcessICRStateMismatch() throws IOException {

    // Recon container state is ""OPEN"".
    // Replica state could be any Non OPEN state.
    long containerId = 11;
    for (State state : Arrays.asList(State.CLOSING, State.QUASI_CLOSED,
        State.CLOSED)) {
      ContainerWithPipeline containerWithPipeline = getTestContainer(
          containerId++, OPEN);
      ContainerID containerID =
          containerWithPipeline.getContainerInfo().containerID();

      ReconContainerManager containerManager = getContainerManager();
      containerManager.addNewContainer(containerWithPipeline);

      DatanodeDetails datanodeDetails =
          containerWithPipeline.getPipeline().getFirstNode();
      NodeManager nodeManagerMock = mock(NodeManager.class);
      when(nodeManagerMock.getNodeByUuid(any())).thenReturn(datanodeDetails);
      IncrementalContainerReportFromDatanode reportMock =
          mock(IncrementalContainerReportFromDatanode.class);
      when(reportMock.getDatanodeDetails())
          .thenReturn(containerWithPipeline.getPipeline().getFirstNode());

      IncrementalContainerReportProto containerReport =
          getIncrementalContainerReportProto(containerID, state,
              datanodeDetails.getUuidString());
      when(reportMock.getReport()).thenReturn(containerReport);
      ReconIncrementalContainerReportHandler reconIcr =
          new ReconIncrementalContainerReportHandler(nodeManagerMock,
              containerManager, SCMContext.emptyContext());

      reconIcr.onMessage(reportMock, mock(EventPublisher.class));
      assertTrue(containerManager.containerExist(containerID));
      assertEquals(1,
          containerManager.getContainerReplicas(containerID).size());
      LifeCycleState expectedState = getContainerStateFromReplicaState(state);
      LifeCycleState actualState =
          containerManager.getContainer(containerID).getState();
      assertEquals(String.format(""Expecting %s in "" +
              ""container state for replica state %s"", expectedState,
          state), expectedState, actualState);
    }
  }
"
"  @Test
  public void testReconNodeDB() throws IOException, NodeNotFoundException {
    ReconStorageConfig scmStorageConfig = new ReconStorageConfig(conf);
    EventQueue eventQueue = new EventQueue();
    NetworkTopology clusterMap = new NetworkTopologyImpl(conf);
    Table<UUID, DatanodeDetails> nodeTable =
        ReconSCMDBDefinition.NODES.getTable(store);
    ReconNodeManager reconNodeManager = new ReconNodeManager(conf,
        scmStorageConfig, eventQueue, clusterMap, nodeTable, versionManager);
    ReconNewNodeHandler reconNewNodeHandler =
        new ReconNewNodeHandler(reconNodeManager);
    assertTrue(reconNodeManager.getAllNodes().isEmpty());

    DatanodeDetails datanodeDetails = randomDatanodeDetails();
    String uuidString = datanodeDetails.getUuidString();

    // Register a random datanode.
    reconNodeManager.register(datanodeDetails, null, null);
    reconNewNodeHandler.onMessage(reconNodeManager.getNodeByUuid(uuidString),
        null);

    assertEquals(1, reconNodeManager.getAllNodes().size());
    assertNotNull(reconNodeManager.getNodeByUuid(uuidString));

    // If any commands are added to the eventQueue without using the onMessage
    // interface, then they should be filtered out and not returned to the DN
    // when it heartbeats.
    // This command should never be returned by Recon
    reconNodeManager.addDatanodeCommand(datanodeDetails.getUuid(),
        new SetNodeOperationalStateCommand(1234,
        DECOMMISSIONING, 0));

    // This one should be returned
    reconNodeManager.addDatanodeCommand(datanodeDetails.getUuid(),
        new ReregisterCommand());

    // OperationalState sanity check
    final DatanodeDetails dnDetails =
        reconNodeManager.getNodeByUuid(datanodeDetails.getUuidString());
    assertEquals(HddsProtos.NodeOperationalState.IN_SERVICE,
        dnDetails.getPersistedOpState());
    assertEquals(dnDetails.getPersistedOpState(),
        reconNodeManager.getNodeStatus(dnDetails)
            .getOperationalState());
    assertEquals(dnDetails.getPersistedOpStateExpiryEpochSec(),
        reconNodeManager.getNodeStatus(dnDetails)
            .getOpStateExpiryEpochSeconds());

    // Upon processing the heartbeat, the illegal command should be filtered out
    List<SCMCommand> returnedCmds =
        reconNodeManager.processHeartbeat(datanodeDetails,
            defaultLayoutVersionProto());
    assertEquals(1, returnedCmds.size());
    assertEquals(SCMCommandProto.Type.reregisterCommand,
        returnedCmds.get(0).getType());

    // Now feed a DECOMMISSIONED heartbeat of the same DN
    datanodeDetails.setPersistedOpState(
        HddsProtos.NodeOperationalState.DECOMMISSIONED);
    datanodeDetails.setPersistedOpStateExpiryEpochSec(12345L);
    reconNodeManager.processHeartbeat(datanodeDetails,
        defaultLayoutVersionProto());
    // Check both persistedOpState and NodeStatus#operationalState
    assertEquals(HddsProtos.NodeOperationalState.DECOMMISSIONED,
        dnDetails.getPersistedOpState());
    assertEquals(dnDetails.getPersistedOpState(),
        reconNodeManager.getNodeStatus(dnDetails)
            .getOperationalState());
    assertEquals(12345L, dnDetails.getPersistedOpStateExpiryEpochSec());
    assertEquals(dnDetails.getPersistedOpStateExpiryEpochSec(),
        reconNodeManager.getNodeStatus(dnDetails)
            .getOpStateExpiryEpochSeconds());

    // Close the DB, and recreate the instance of Recon Node Manager.
    eventQueue.close();
    reconNodeManager.close();
    reconNodeManager = new ReconNodeManager(conf, scmStorageConfig, eventQueue,
        clusterMap, nodeTable, versionManager);

    // Verify that the node information was persisted and loaded back.
    assertEquals(1, reconNodeManager.getAllNodes().size());
    assertNotNull(
        reconNodeManager.getNodeByUuid(datanodeDetails.getUuidString()));
  }
"
"  @Test
  public void testUpdateNodeOperationalStateFromScm() throws Exception {
    ReconStorageConfig scmStorageConfig = new ReconStorageConfig(conf);
    EventQueue eventQueue = new EventQueue();
    NetworkTopology clusterMap = new NetworkTopologyImpl(conf);
    Table<UUID, DatanodeDetails> nodeTable =
        ReconSCMDBDefinition.NODES.getTable(store);
    ReconNodeManager reconNodeManager = new ReconNodeManager(conf,
        scmStorageConfig, eventQueue, clusterMap, nodeTable, versionManager);


    DatanodeDetails datanodeDetails = randomDatanodeDetails();
    HddsProtos.Node node = mock(HddsProtos.Node.class);

    LambdaTestUtils.intercept(NodeNotFoundException.class, () -> {
      reconNodeManager.updateNodeOperationalStateFromScm(node, datanodeDetails);
    });

    reconNodeManager.register(datanodeDetails, null, null);
    assertEquals(IN_SERVICE, reconNodeManager
        .getNodeByUuid(datanodeDetails.getUuidString()).getPersistedOpState());

    when(node.getNodeOperationalStates(eq(0)))
        .thenReturn(DECOMMISSIONING);
    reconNodeManager.updateNodeOperationalStateFromScm(node, datanodeDetails);
    assertEquals(DECOMMISSIONING, reconNodeManager
        .getNodeByUuid(datanodeDetails.getUuidString()).getPersistedOpState());
    List<DatanodeDetails> nodes =
        reconNodeManager.getNodes(DECOMMISSIONING, null);
    assertEquals(1, nodes.size());
    assertEquals(datanodeDetails.getUuid(), nodes.get(0).getUuid());
  }
"
"  @Test
  public void testDatanodeUpdate() throws IOException {
    ReconStorageConfig scmStorageConfig = new ReconStorageConfig(conf);
    EventQueue eventQueue = new EventQueue();
    NetworkTopology clusterMap = new NetworkTopologyImpl(conf);
    Table<UUID, DatanodeDetails> nodeTable =
        ReconSCMDBDefinition.NODES.getTable(store);
    ReconNodeManager reconNodeManager = new ReconNodeManager(conf,
        scmStorageConfig, eventQueue, clusterMap, nodeTable, versionManager);
    ReconNewNodeHandler reconNewNodeHandler =
        new ReconNewNodeHandler(reconNodeManager);
    assertTrue(reconNodeManager.getAllNodes().isEmpty());

    DatanodeDetails datanodeDetails = randomDatanodeDetails();
    datanodeDetails.setHostName(""hostname1"");
    String uuidString = datanodeDetails.getUuidString();

    // Register ""hostname1"" datanode.
    reconNodeManager.register(datanodeDetails, null, null);
    reconNewNodeHandler.onMessage(reconNodeManager.getNodeByUuid(uuidString),
        null);

    assertEquals(1, reconNodeManager.getAllNodes().size());
    assertNotNull(reconNodeManager.getNodeByUuid(uuidString));
    assertEquals(""hostname1"",
        reconNodeManager.getNodeByUuid(uuidString).getHostName());

    datanodeDetails.setHostName(""hostname2"");
    // Upon processing the heartbeat, the illegal command should be filtered out
    List<SCMCommand> returnedCmds =
        reconNodeManager.processHeartbeat(datanodeDetails,
            defaultLayoutVersionProto());
    assertEquals(1, returnedCmds.size());
    assertEquals(SCMCommandProto.Type.reregisterCommand,
        returnedCmds.get(0).getType());

  }
"
"  @Test
  public void testAddNewOpenContainer() throws IOException {
    ContainerWithPipeline containerWithPipeline =
        getTestContainer(LifeCycleState.OPEN);
    ContainerID containerID =
        containerWithPipeline.getContainerInfo().containerID();
    ContainerInfo containerInfo = containerWithPipeline.getContainerInfo();

    ReconContainerManager containerManager = getContainerManager();
    assertFalse(containerManager.containerExist(containerID));
    assertFalse(getContainerTable().isExist(containerID));

    containerManager.addNewContainer(containerWithPipeline);

    assertTrue(containerManager.containerExist(containerID));

    List<ContainerInfo> containers =
        containerManager.getContainers(LifeCycleState.OPEN);
    assertEquals(1, containers.size());
    assertEquals(containerInfo, containers.get(0));
    NavigableSet<ContainerID> containersInPipeline =
        getPipelineManager().getContainersInPipeline(
            containerWithPipeline.getPipeline().getId());
    assertEquals(1, containersInPipeline.size());
    assertEquals(containerID, containersInPipeline.first());

    // Verify container DB.
    SCMHAManager scmhaManager = containerManager.getSCMHAManager();
    scmhaManager.getDBTransactionBuffer().close();
    assertTrue(getContainerTable().isExist(containerID));
  }
"
"  @Test
  public void testAddNewClosedContainer() throws IOException {
    ContainerWithPipeline containerWithPipeline = getTestContainer(CLOSED);
    ContainerID containerID =
        containerWithPipeline.getContainerInfo().containerID();
    ContainerInfo containerInfo = containerWithPipeline.getContainerInfo();

    ReconContainerManager containerManager = getContainerManager();
    assertFalse(containerManager.containerExist(containerID));
    assertFalse(getContainerTable().isExist(containerID));

    containerManager.addNewContainer(containerWithPipeline);

    assertTrue(containerManager.containerExist(containerID));

    List<ContainerInfo> containers = containerManager.getContainers(CLOSED);
    assertEquals(1, containers.size());
    assertEquals(containerInfo, containers.get(0));
    // Verify container DB.
    SCMHAManager scmhaManager = containerManager.getSCMHAManager();
    scmhaManager.getDBTransactionBuffer().close();
    assertTrue(getContainerTable().isExist(containerID));
  }
"
"  @Test
  public void testCheckAndAddNewContainer() throws Exception {
    ContainerID containerID = ContainerID.valueOf(100L);
    ReconContainerManager containerManager = getContainerManager();
    assertFalse(containerManager.containerExist(containerID));
    DatanodeDetails datanodeDetails = randomDatanodeDetails();
    containerManager.checkAndAddNewContainer(containerID,
        OPEN, datanodeDetails);
    assertTrue(containerManager.containerExist(containerID));

    // Doing it one more time should not change any state.
    containerManager.checkAndAddNewContainer(containerID, OPEN,
        datanodeDetails);
    assertTrue(containerManager.containerExist(containerID));
    assertEquals(LifeCycleState.OPEN,
        getContainerManager().getContainer(containerID).getState());
  }
"
"  @Test
  public void testCheckAndAddNewContainerBatch() throws IOException {
    List<ContainerReplicaProto> containerReplicaProtoList = new LinkedList<>();
    ReconContainerManager containerManager = getContainerManager();
    State[] stateTypes = State.values();
    LifeCycleState[] lifeCycleStateTypes = LifeCycleState.values();
    int lifeCycleStateCount = lifeCycleStateTypes.length;
    for (int i = 200; i < 300; i++) {
      assertFalse(containerManager.containerExist(ContainerID.valueOf(i)));
      ContainerReplicaProto.Builder ciBuilder =
          ContainerReplicaProto.newBuilder();
      ContainerReplicaProto crp = ciBuilder.
          setContainerID(i).
          setState(stateTypes[i % lifeCycleStateCount]).build();
      containerReplicaProtoList.add(crp);
    }

    containerManager.checkAndAddNewContainerBatch(containerReplicaProtoList);
    for (long i = 200L; i < 300L; i++) {
      assertTrue(containerManager.containerExist(ContainerID.valueOf(i)));
    }

    // Doing it one more time should not change any state.
    containerManager.checkAndAddNewContainerBatch(containerReplicaProtoList);
    for (int i = 200; i < 300; i++) {
      assertTrue(containerManager.containerExist(ContainerID.valueOf(i)));
      assertEquals(lifeCycleStateTypes[i % lifeCycleStateCount],
          getContainerManager().
            getContainer(ContainerID.valueOf(i)).getState());
    }
  }
"
"  @Test
  public void testUpdateContainerStateFromOpen() throws Exception {
    ContainerWithPipeline containerWithPipeline =
        getTestContainer(LifeCycleState.OPEN);
    ContainerID containerID =
        containerWithPipeline.getContainerInfo().containerID();

    // Adding container #100.
    getContainerManager().addNewContainer(containerWithPipeline);
    assertEquals(LifeCycleState.OPEN,
        getContainerManager().getContainer(containerID).getState());

    DatanodeDetails datanodeDetails = randomDatanodeDetails();

    // First report with ""CLOSED"" replica state moves container state to
    // ""CLOSING"".
    getContainerManager().checkAndAddNewContainer(containerID, State.CLOSED,
        datanodeDetails);
    assertEquals(CLOSING,
        getContainerManager().getContainer(containerID).getState());
  }
"
"  @Test
  public void testUpdateAndRemoveContainerReplica() throws IOException {
    // Sanity checking updateContainerReplica and ContainerReplicaHistory

    // Init Container 1
    final long cIDlong1 = 1L;
    final ContainerID containerID1 = ContainerID.valueOf(cIDlong1);

    // Init DN01
    final UUID uuid1 = UUID.randomUUID();
    final DatanodeDetails datanodeDetails1 = DatanodeDetails.newBuilder()
        .setUuid(uuid1).setHostName(""host1"").setIpAddress(""127.0.0.1"").build();
    ContainerReplica containerReplica1 = ContainerReplica.newBuilder()
        .setContainerID(containerID1).setContainerState(State.OPEN)
        .setDatanodeDetails(datanodeDetails1).setSequenceId(1001L).build();

    final ReconContainerManager containerManager = getContainerManager();
    final Map<Long, Map<UUID, ContainerReplicaHistory>> repHistMap =
        containerManager.getReplicaHistoryMap();
    // Should be empty at the beginning
    Assert.assertEquals(0, repHistMap.size());

    // Put a replica info and call updateContainerReplica
    Pipeline pipeline = getRandomPipeline();
    getPipelineManager().addPipeline(pipeline);
    for (int i = 1; i <= 10; i++) {
      final ContainerInfo info = newContainerInfo(i, pipeline);
      containerManager.addNewContainer(
          new ContainerWithPipeline(info, pipeline));
    }

    containerManager.updateContainerReplica(containerID1, containerReplica1);
    // Should have 1 container entry in the replica history map
    Assert.assertEquals(1, repHistMap.size());
    // Should only have 1 entry for this replica (on DN01)
    Assert.assertEquals(1, repHistMap.get(cIDlong1).size());
    ContainerReplicaHistory repHist1 = repHistMap.get(cIDlong1).get(uuid1);
    Assert.assertEquals(uuid1, repHist1.getUuid());
    // Because this is a new entry, first seen time equals last seen time
    assertEquals(repHist1.getLastSeenTime(), repHist1.getFirstSeenTime());
    assertEquals(containerReplica1.getSequenceId().longValue(),
        repHist1.getBcsId());

    // Let's update the entry again
    containerReplica1 = ContainerReplica.newBuilder()
        .setContainerID(containerID1).setContainerState(State.OPEN)
        .setDatanodeDetails(datanodeDetails1).setSequenceId(1051L).build();
    containerManager.updateContainerReplica(containerID1, containerReplica1);
    // Should still have 1 entry in the replica history map
    Assert.assertEquals(1, repHistMap.size());
    // Now last seen time should be larger than first seen time
    Assert.assertTrue(repHist1.getLastSeenTime() > repHist1.getFirstSeenTime());
    assertEquals(1051L, repHist1.getBcsId());

    // Init DN02
    final UUID uuid2 = UUID.randomUUID();
    final DatanodeDetails datanodeDetails2 = DatanodeDetails.newBuilder()
        .setUuid(uuid2).setHostName(""host2"").setIpAddress(""127.0.0.2"").build();
    final ContainerReplica containerReplica2 = ContainerReplica.newBuilder()
        .setContainerID(containerID1).setContainerState(State.OPEN)
        .setDatanodeDetails(datanodeDetails2).setSequenceId(1051L).build();

    // Add replica to DN02
    containerManager.updateContainerReplica(containerID1, containerReplica2);

    // Should still have 1 container entry in the replica history map
    Assert.assertEquals(1, repHistMap.size());
    // Should have 2 entries for this replica (on DN01 and DN02)
    Assert.assertEquals(2, repHistMap.get(cIDlong1).size());
    ContainerReplicaHistory repHist2 = repHistMap.get(cIDlong1).get(uuid2);
    Assert.assertEquals(uuid2, repHist2.getUuid());
    // Because this is a new entry, first seen time equals last seen time
    assertEquals(repHist2.getLastSeenTime(), repHist2.getFirstSeenTime());
    assertEquals(1051L, repHist2.getBcsId());

    // Remove replica from DN01
    containerManager.removeContainerReplica(containerID1, containerReplica1);
    // Should still have 1 container entry in the replica history map
    Assert.assertEquals(1, repHistMap.size());
    // Should have 1 entry for this replica
    Assert.assertEquals(1, repHistMap.get(cIDlong1).size());
    // And the only entry should match DN02
    Assert.assertEquals(uuid2,
        repHistMap.get(cIDlong1).keySet().iterator().next());
  }
"
"  @Test
  public void testInitialize() throws IOException {

    // Get 3 OPEN pipelines from SCM.
    List<Pipeline> pipelinesFromScm = getPipelines(3);

    // Recon has 2 pipelines in ALLOCATED state. (1 is valid and 1 is obsolete)

    // Valid pipeline in Allocated state.
    Pipeline validPipeline = Pipeline.newBuilder()
        .setReplicationConfig(
            new StandaloneReplicationConfig(ReplicationFactor.ONE))
        .setId(pipelinesFromScm.get(0).getId())
        .setNodes(pipelinesFromScm.get(0).getNodes())
        .setState(Pipeline.PipelineState.ALLOCATED)

        .build();

    // Invalid pipeline.
    Pipeline invalidPipeline = Pipeline.newBuilder()
        .setReplicationConfig(
            new StandaloneReplicationConfig(ReplicationFactor.ONE))
        .setId(PipelineID.randomId())
        .setNodes(Collections.singletonList(randomDatanodeDetails()))
        .setState(Pipeline.PipelineState.CLOSED)
        .build();

    NetworkTopology clusterMap = new NetworkTopologyImpl(conf);
    EventQueue eventQueue = new EventQueue();
    this.versionManager =
        Mockito.mock(HDDSLayoutVersionManager.class);
    Mockito.when(versionManager.getMetadataLayoutVersion())
        .thenReturn(maxLayoutVersion());
    Mockito.when(versionManager.getSoftwareLayoutVersion())
        .thenReturn(maxLayoutVersion());
    NodeManager nodeManager = new SCMNodeManager(conf, scmStorageConfig,
        eventQueue, clusterMap, SCMContext.emptyContext(), versionManager);

    try (ReconPipelineManager reconPipelineManager =
             ReconPipelineManager.newReconPipelineManager(
                 conf,
                 nodeManager,
                 ReconSCMDBDefinition.PIPELINES.getTable(store),
                 eventQueue,
                 scmhaManager,
                 scmContext)) {
      scmContext = new SCMContext.Builder().setIsInSafeMode(true)
              .setLeader(true).setIsPreCheckComplete(true)
              .setSCM(mock(StorageContainerManager.class)).build();
      reconPipelineManager.setScmContext(scmContext);
      reconPipelineManager.addPipeline(validPipeline);
      reconPipelineManager.addPipeline(invalidPipeline);

      reconPipelineManager.initializePipelines(pipelinesFromScm);
      List<Pipeline> newReconPipelines = reconPipelineManager.getPipelines();

      // Test if the number of pipelines in SCM is as expected.
      assertEquals(3, newReconPipelines.size());

      // Test if new pipelines from SCM are picked up.
      for (Pipeline pipeline : pipelinesFromScm) {
        assertTrue(reconPipelineManager.containsPipeline(pipeline.getId()));
      }

      // Test if existing pipeline state is updated.
      assertEquals(Pipeline.PipelineState.OPEN, reconPipelineManager
          .getPipeline(validPipeline.getId()).getPipelineState());

      // Test if obsolete pipelines in Recon are removed.
      assertFalse(reconPipelineManager.containsPipeline(
          invalidPipeline.getId()));
    }
  }
"
"  @Test
  public void testAddPipeline() throws IOException {

    Pipeline pipeline = getRandomPipeline();
    NetworkTopology clusterMap = new NetworkTopologyImpl(conf);
    EventQueue eventQueue = new EventQueue();
    this.versionManager =
        Mockito.mock(HDDSLayoutVersionManager.class);
    Mockito.when(versionManager.getMetadataLayoutVersion())
        .thenReturn(maxLayoutVersion());
    Mockito.when(versionManager.getSoftwareLayoutVersion())
        .thenReturn(maxLayoutVersion());
    NodeManager nodeManager = new SCMNodeManager(conf, scmStorageConfig,
        eventQueue, clusterMap, SCMContext.emptyContext(), versionManager);

    ReconPipelineManager reconPipelineManager =
        ReconPipelineManager.newReconPipelineManager(
            conf,
            nodeManager,
            ReconSCMDBDefinition.PIPELINES.getTable(store),
            eventQueue,
            scmhaManager,
            scmContext);

    assertFalse(reconPipelineManager.containsPipeline(pipeline.getId()));
    reconPipelineManager.addPipeline(pipeline);
    assertTrue(reconPipelineManager.containsPipeline(pipeline.getId()));
  }
"
"  @Test
  public void testStubbedReconPipelineFactory() throws IOException {

    NodeManager nodeManagerMock = mock(NodeManager.class);

    ReconPipelineManager reconPipelineManager =
        ReconPipelineManager.newReconPipelineManager(
            conf,
            nodeManagerMock,
            ReconSCMDBDefinition.PIPELINES.getTable(store),
            new EventQueue(),
            scmhaManager,
            scmContext);

    PipelineFactory pipelineFactory = reconPipelineManager.getPipelineFactory();
    assertTrue(pipelineFactory instanceof ReconPipelineFactory);
    ReconPipelineFactory reconPipelineFactory =
        (ReconPipelineFactory) pipelineFactory;
    assertTrue(reconPipelineFactory.getProviders().isEmpty());
    for (ReplicationType type  : reconPipelineFactory.getProviders().keySet()) {
      PipelineProvider pipelineProvider =
          reconPipelineFactory.getProviders().get(type);
      assertTrue(pipelineProvider instanceof ReconPipelineProvider);
    }
  }
"
"  @Test
  public void testAdminOnlyEndpoints() {
    // Get all classes with @Path annotation anywhere in recon.
    Reflections reflections = new Reflections(
        ""org.apache.hadoop.ozone.recon"",
        new TypeAnnotationsScanner(),
        new SubTypesScanner());
    Set<Class<?>> allEndpoints =
        reflections.getTypesAnnotatedWith(Path.class);

    Assert.assertFalse(allEndpoints.isEmpty());

    // If an endpoint is added, it must be explicitly added to this set or be
    // marked with @AdminOnly for this test to pass.
    Set<Class<?>> nonAdminEndpoints = new HashSet<>();
    nonAdminEndpoints.add(UtilizationEndpoint.class);
    nonAdminEndpoints.add(ClusterStateEndpoint.class);
    nonAdminEndpoints.add(MetricsProxyEndpoint.class);
    nonAdminEndpoints.add(NodeEndpoint.class);
    nonAdminEndpoints.add(PipelineEndpoint.class);
    nonAdminEndpoints.add(TaskStatusService.class);

    Assert.assertTrue(allEndpoints.containsAll(nonAdminEndpoints));

    Set<Class<?>> adminEndpoints = Sets.difference(allEndpoints,
        nonAdminEndpoints);

    for (Class<?> endpoint: nonAdminEndpoints) {
      Assert.assertFalse(String.format(""Endpoint class %s has been "" +
              ""declared as non admin in this test, but is marked as "" +
              ""@AdminOnly."", endpoint),
          endpoint.isAnnotationPresent(AdminOnly.class));
    }

    for (Class<?> endpoint: adminEndpoints) {
      Assert.assertTrue(String.format(""Endpoint class %s must be marked as "" +
              ""@AdminOnly or explicitly declared as non admin in this test."",
          endpoint),
          endpoint.isAnnotationPresent(AdminOnly.class));
    }
  }
"
"  @Test
  public void testAdminFilterOzoneAdminsOnly() throws Exception {
    OzoneConfiguration conf = new OzoneConfiguration();
    conf.setStrings(OzoneConfigKeys.OZONE_ADMINISTRATORS, ""ozone"");
    testAdminFilterWithPrincipal(conf, ""ozone"", true);
    testAdminFilterWithPrincipal(conf, ""reject"", false);

    conf.setStrings(OzoneConfigKeys.OZONE_ADMINISTRATORS,
        OzoneConfigKeys.OZONE_ADMINISTRATORS_WILDCARD);
    testAdminFilterWithPrincipal(conf, ""other"", true);
  }
"
"  @Test
  public void testAdminFilterReconAdminsOnly() throws Exception {
    OzoneConfiguration conf = new OzoneConfiguration();
    conf.setStrings(ReconConfigKeys.OZONE_RECON_ADMINISTRATORS, ""recon"");
    testAdminFilterWithPrincipal(conf, ""recon"", true);
    testAdminFilterWithPrincipal(conf, ""reject"", false);

    conf.setStrings(ReconConfigKeys.OZONE_RECON_ADMINISTRATORS,
        OzoneConfigKeys.OZONE_ADMINISTRATORS_WILDCARD);
    testAdminFilterWithPrincipal(conf, ""other"", true);
  }
"
"  @Test
  public void testAdminFilterOzoneAndReconAdmins() throws Exception {
    OzoneConfiguration conf = new OzoneConfiguration();
    conf.setStrings(OzoneConfigKeys.OZONE_ADMINISTRATORS, ""ozone"");
    conf.setStrings(ReconConfigKeys.OZONE_RECON_ADMINISTRATORS, ""recon"");
    testAdminFilterWithPrincipal(conf, ""ozone"", true);
    testAdminFilterWithPrincipal(conf, ""recon"", true);
    testAdminFilterWithPrincipal(conf, ""reject"", false);

    conf.setStrings(OzoneConfigKeys.OZONE_ADMINISTRATORS,
        OzoneConfigKeys.OZONE_ADMINISTRATORS_WILDCARD);
    conf.setStrings(ReconConfigKeys.OZONE_RECON_ADMINISTRATORS,
        OzoneConfigKeys.OZONE_ADMINISTRATORS_WILDCARD);
    testAdminFilterWithPrincipal(conf, ""other"", true);
  }
"
"  @Test
  public void testAdminFilterNoAdmins() throws Exception {
    testAdminFilterWithPrincipal(new OzoneConfiguration(), ""reject"", false);
  }
"
"  @Test
  public void testUtility() {
    String[] names = NSSummaryEndpoint.parseRequestPath(TEST_PATH_UTILITY);
    Assert.assertArrayEquals(TEST_NAMES, names);
    String keyName = NSSummaryEndpoint.getKeyName(names);
    Assert.assertEquals(TEST_KEY_NAMES, keyName);
    String subpath = NSSummaryEndpoint.buildSubpath(PARENT_DIR, ""file1.txt"");
    Assert.assertEquals(TEST_PATH_UTILITY, subpath);
  }
"
"  @Test
  public void testBasic() throws Exception {
    // Test volume basics
    Response volResponse = nsSummaryEndpoint.getBasicInfo(VOL_PATH);
    NamespaceSummaryResponse volResponseObj =
            (NamespaceSummaryResponse) volResponse.getEntity();
    Assert.assertEquals(EntityType.VOLUME, volResponseObj.getEntityType());
    Assert.assertEquals(2, volResponseObj.getNumBucket());
    Assert.assertEquals(4, volResponseObj.getNumTotalDir());
    Assert.assertEquals(6, volResponseObj.getNumTotalKey());

    // Test bucket 1's basics
    Response bucketOneResponse =
            nsSummaryEndpoint.getBasicInfo(BUCKET_ONE_PATH);
    NamespaceSummaryResponse bucketOneObj =
            (NamespaceSummaryResponse) bucketOneResponse.getEntity();
    Assert.assertEquals(EntityType.BUCKET, bucketOneObj.getEntityType());
    Assert.assertEquals(4, bucketOneObj.getNumTotalDir());
    Assert.assertEquals(4, bucketOneObj.getNumTotalKey());

    // Test bucket 2's basics
    Response bucketTwoResponse =
            nsSummaryEndpoint.getBasicInfo(BUCKET_TWO_PATH);
    NamespaceSummaryResponse bucketTwoObj =
            (NamespaceSummaryResponse) bucketTwoResponse.getEntity();
    Assert.assertEquals(EntityType.BUCKET, bucketTwoObj.getEntityType());
    Assert.assertEquals(0, bucketTwoObj.getNumTotalDir());
    Assert.assertEquals(2, bucketTwoObj.getNumTotalKey());

    // Test intermediate directory basics
    Response dirOneResponse = nsSummaryEndpoint.getBasicInfo(DIR_ONE_PATH);
    NamespaceSummaryResponse dirOneObj =
            (NamespaceSummaryResponse) dirOneResponse.getEntity();
    Assert.assertEquals(EntityType.DIRECTORY, dirOneObj.getEntityType());
    Assert.assertEquals(3, dirOneObj.getNumTotalDir());
    Assert.assertEquals(3, dirOneObj.getNumTotalKey());

    // Test invalid path
    Response invalidResponse = nsSummaryEndpoint.getBasicInfo(INVALID_PATH);
    NamespaceSummaryResponse invalidObj =
            (NamespaceSummaryResponse) invalidResponse.getEntity();
    Assert.assertEquals(ResponseStatus.PATH_NOT_FOUND,
            invalidObj.getStatus());

    // Test key
    Response keyResponse = nsSummaryEndpoint.getBasicInfo(KEY_PATH);
    NamespaceSummaryResponse keyResObj =
            (NamespaceSummaryResponse) keyResponse.getEntity();
    Assert.assertEquals(EntityType.KEY, keyResObj.getEntityType());
  }
"
"  @Test
  public void testDiskUsage() throws Exception {
    // volume level DU
    Response volResponse = nsSummaryEndpoint.getDiskUsage(VOL_PATH,
            false, false);
    DUResponse duVolRes = (DUResponse) volResponse.getEntity();
    Assert.assertEquals(2, duVolRes.getCount());
    List<DUResponse.DiskUsage> duData = duVolRes.getDuData();
    // sort based on subpath
    Collections.sort(duData,
            Comparator.comparing(DUResponse.DiskUsage::getSubpath));
    DUResponse.DiskUsage duBucket1 = duData.get(0);
    DUResponse.DiskUsage duBucket2 = duData.get(1);
    Assert.assertEquals(BUCKET_ONE_PATH, duBucket1.getSubpath());
    Assert.assertEquals(BUCKET_TWO_PATH, duBucket2.getSubpath());
    Assert.assertEquals(BUCKET_ONE_DATA_SIZE, duBucket1.getSize());
    Assert.assertEquals(BUCKET_TWO_DATA_SIZE, duBucket2.getSize());

    // bucket level DU
    Response bucketResponse = nsSummaryEndpoint.getDiskUsage(BUCKET_ONE_PATH,
            false, false);
    DUResponse duBucketResponse = (DUResponse) bucketResponse.getEntity();
    Assert.assertEquals(1, duBucketResponse.getCount());
    DUResponse.DiskUsage duDir1 = duBucketResponse.getDuData().get(0);
    Assert.assertEquals(DIR_ONE_PATH, duDir1.getSubpath());
    Assert.assertEquals(DIR_ONE_DATA_SIZE, duDir1.getSize());

    // dir level DU
    Response dirResponse = nsSummaryEndpoint.getDiskUsage(DIR_ONE_PATH,
            false, false);
    DUResponse duDirReponse = (DUResponse) dirResponse.getEntity();
    Assert.assertEquals(3, duDirReponse.getCount());
    List<DUResponse.DiskUsage> duSubDir = duDirReponse.getDuData();
    Collections.sort(duSubDir,
            Comparator.comparing(DUResponse.DiskUsage::getSubpath));
    DUResponse.DiskUsage duDir2 = duSubDir.get(0);
    DUResponse.DiskUsage duDir3 = duSubDir.get(1);
    DUResponse.DiskUsage duDir4 = duSubDir.get(2);
    Assert.assertEquals(DIR_TWO_PATH, duDir2.getSubpath());
    Assert.assertEquals(KEY_TWO_SIZE, duDir2.getSize());

    Assert.assertEquals(DIR_THREE_PATH, duDir3.getSubpath());
    Assert.assertEquals(KEY_THREE_SIZE, duDir3.getSize());

    Assert.assertEquals(DIR_FOUR_PATH, duDir4.getSubpath());
    Assert.assertEquals(KEY_SIX_SIZE, duDir4.getSize());

    // key level DU
    Response keyResponse = nsSummaryEndpoint.getDiskUsage(KEY_PATH,
            false, false);
    DUResponse keyObj = (DUResponse) keyResponse.getEntity();
    Assert.assertEquals(0, keyObj.getCount());
    Assert.assertEquals(KEY_FOUR_SIZE, keyObj.getSize());

    // invalid path check
    Response invalidResponse = nsSummaryEndpoint.getDiskUsage(INVALID_PATH,
            false, false);
    DUResponse invalidObj = (DUResponse) invalidResponse.getEntity();
    Assert.assertEquals(ResponseStatus.PATH_NOT_FOUND,
            invalidObj.getStatus());
  }
"
"  @Test
  public void testDiskUsageWithReplication() throws Exception {
    setUpMultiBlockKey();
    Response keyResponse = nsSummaryEndpoint.getDiskUsage(MULTI_BLOCK_KEY_PATH,
            false, true);
    DUResponse replicaDUResponse = (DUResponse) keyResponse.getEntity();
    Assert.assertEquals(ResponseStatus.OK, replicaDUResponse.getStatus());
    Assert.assertEquals(MULTI_BLOCK_KEY_SIZE_WITH_REPLICA,
            replicaDUResponse.getSizeWithReplica());
  }
"
"  @Test
  public void testQuotaUsage() throws Exception {
    // volume level quota usage
    Response volResponse = nsSummaryEndpoint.getQuotaUsage(VOL_PATH);
    QuotaUsageResponse quVolRes = (QuotaUsageResponse) volResponse.getEntity();
    Assert.assertEquals(VOL_QUOTA, quVolRes.getQuota());
    Assert.assertEquals(TOTAL_DATA_SIZE, quVolRes.getQuotaUsed());

    // bucket level quota usage
    Response bucketRes = nsSummaryEndpoint.getQuotaUsage(BUCKET_ONE_PATH);
    QuotaUsageResponse quBucketRes = (QuotaUsageResponse) bucketRes.getEntity();
    Assert.assertEquals(BUCKET_ONE_QUOTA, quBucketRes.getQuota());
    Assert.assertEquals(BUCKET_ONE_DATA_SIZE, quBucketRes.getQuotaUsed());

    Response bucketRes2 = nsSummaryEndpoint.getQuotaUsage(BUCKET_TWO_PATH);
    QuotaUsageResponse quBucketRes2 =
            (QuotaUsageResponse) bucketRes2.getEntity();
    Assert.assertEquals(BUCKET_TWO_QUOTA, quBucketRes2.getQuota());
    Assert.assertEquals(BUCKET_TWO_DATA_SIZE, quBucketRes2.getQuotaUsed());

    // other level not applicable
    Response naResponse1 = nsSummaryEndpoint.getQuotaUsage(DIR_ONE_PATH);
    QuotaUsageResponse quotaUsageResponse1 =
            (QuotaUsageResponse) naResponse1.getEntity();
    Assert.assertEquals(ResponseStatus.TYPE_NOT_APPLICABLE,
            quotaUsageResponse1.getResponseCode());

    Response naResponse2 = nsSummaryEndpoint.getQuotaUsage(KEY_PATH);
    QuotaUsageResponse quotaUsageResponse2 =
            (QuotaUsageResponse) naResponse2.getEntity();
    Assert.assertEquals(ResponseStatus.TYPE_NOT_APPLICABLE,
            quotaUsageResponse2.getResponseCode());

    // invalid path request
    Response invalidRes = nsSummaryEndpoint.getQuotaUsage(INVALID_PATH);
    QuotaUsageResponse invalidResObj =
            (QuotaUsageResponse) invalidRes.getEntity();
    Assert.assertEquals(ResponseStatus.PATH_NOT_FOUND,
            invalidResObj.getResponseCode());
  }
"
"  @Test
  public void testFileSizeDist() throws Exception {
    Response volRes = nsSummaryEndpoint.getFileSizeDistribution(VOL_PATH);
    FileSizeDistributionResponse volFileSizeDistResObj =
            (FileSizeDistributionResponse) volRes.getEntity();
    // If the volume has the correct file size distribution,
    // other lower level should be correct as well, given all
    // other previous tests have passed.
    int[] volFileSizeDist = volFileSizeDistResObj.getFileSizeDist();
    for (int i = 0; i < ReconConstants.NUM_OF_BINS; ++i) {
      if (i == 0 || i == 2) {
        Assert.assertEquals(2, volFileSizeDist[i]);
      } else if (i == 1 || i == 3) {
        Assert.assertEquals(1, volFileSizeDist[i]);
      } else {
        Assert.assertEquals(0, volFileSizeDist[i]);
      }
    }
  }
"
"  @Test
  public void testGetDatanodes() throws Exception {
    Response response = nodeEndpoint.getDatanodes();
    DatanodesResponse datanodesResponse =
        (DatanodesResponse) response.getEntity();
    Assert.assertEquals(2, datanodesResponse.getTotalCount());
    Assert.assertEquals(2, datanodesResponse.getDatanodes().size());

    datanodesResponse.getDatanodes().forEach(datanodeMetadata -> {
      try {
        testDatanodeResponse(datanodeMetadata);
      } catch (IOException e) {
        Assert.fail(e.getMessage());
      }
    });

    waitAndCheckConditionAfterHeartbeat(() -> {
      Response response1 = nodeEndpoint.getDatanodes();
      DatanodesResponse datanodesResponse1 =
          (DatanodesResponse) response1.getEntity();
      DatanodeMetadata datanodeMetadata1 =
          datanodesResponse1.getDatanodes().stream().filter(datanodeMetadata ->
              datanodeMetadata.getHostname().equals(""host1.datanode""))
              .findFirst().orElse(null);
      return (datanodeMetadata1 != null &&
          datanodeMetadata1.getContainers() == 1 &&
          datanodeMetadata1.getOpenContainers() == 1 &&
          reconScm.getPipelineManager()
              .getContainersInPipeline(pipeline.getId()).size() == 1);
    });

    // Change Node OperationalState with NodeManager
    final NodeManager nodeManager = reconScm.getScmNodeManager();
    final DatanodeDetails dnDetailsInternal =
        nodeManager.getNodeByUuid(datanodeDetails.getUuidString());
    // Backup existing state and sanity check
    final NodeStatus nStatus = nodeManager.getNodeStatus(dnDetailsInternal);
    final NodeOperationalState backupOpState =
        dnDetailsInternal.getPersistedOpState();
    final long backupOpStateExpiry =
        dnDetailsInternal.getPersistedOpStateExpiryEpochSec();
    assertEquals(backupOpState, nStatus.getOperationalState());
    assertEquals(backupOpStateExpiry, nStatus.getOpStateExpiryEpochSeconds());

    dnDetailsInternal.setPersistedOpState(NodeOperationalState.DECOMMISSIONING);
    dnDetailsInternal.setPersistedOpStateExpiryEpochSec(666L);
    nodeManager.setNodeOperationalState(dnDetailsInternal,
        NodeOperationalState.DECOMMISSIONING, 666L);
    // Check if the endpoint response reflects the change
    response = nodeEndpoint.getDatanodes();
    datanodesResponse = (DatanodesResponse) response.getEntity();
    // Order of datanodes in the response is random
    AtomicInteger count = new AtomicInteger();
    datanodesResponse.getDatanodes().forEach(metadata -> {
      if (metadata.getUuid().equals(dnDetailsInternal.getUuidString())) {
        count.incrementAndGet();
        assertEquals(NodeOperationalState.DECOMMISSIONING,
            metadata.getOperationalState());
      }
    });
    assertEquals(1, count.get());

    // Restore state
    dnDetailsInternal.setPersistedOpState(backupOpState);
    dnDetailsInternal.setPersistedOpStateExpiryEpochSec(backupOpStateExpiry);
    nodeManager.setNodeOperationalState(dnDetailsInternal,
        backupOpState, backupOpStateExpiry);
  }
"
"  @Test
  public void testGetPipelines() throws Exception {
    Response response = pipelineEndpoint.getPipelines();
    PipelinesResponse pipelinesResponse =
        (PipelinesResponse) response.getEntity();
    Assert.assertEquals(1, pipelinesResponse.getTotalCount());
    Assert.assertEquals(1, pipelinesResponse.getPipelines().size());
    PipelineMetadata pipelineMetadata =
        pipelinesResponse.getPipelines().iterator().next();
    Assert.assertEquals(1, pipelineMetadata.getDatanodes().size());
    Assert.assertEquals(pipeline.getType().toString(),
        pipelineMetadata.getReplicationType());
    Assert.assertEquals(pipeline.getReplicationConfig().getRequiredNodes(),
        pipelineMetadata.getReplicationFactor());
    Assert.assertEquals(datanodeDetails.getHostName(),
        pipelineMetadata.getLeaderNode());
    Assert.assertEquals(pipeline.getId().getId(),
        pipelineMetadata.getPipelineId());
    Assert.assertEquals(5, pipelineMetadata.getLeaderElections());

    waitAndCheckConditionAfterHeartbeat(() -> {
      Response response1 = pipelineEndpoint.getPipelines();
      PipelinesResponse pipelinesResponse1 =
          (PipelinesResponse) response1.getEntity();
      PipelineMetadata pipelineMetadata1 =
          pipelinesResponse1.getPipelines().iterator().next();
      return (pipelineMetadata1.getContainers() == 1);
    });
  }
"
"  @Test
  public void testGetMetricsResponse() throws Exception {
    HttpServletResponse responseMock = mock(HttpServletResponse.class);
    ServletOutputStream outputStreamMock = mock(ServletOutputStream.class);
    when(responseMock.getOutputStream()).thenReturn(outputStreamMock);
    UriInfo uriInfoMock = mock(UriInfo.class);
    URI uriMock = mock(URI.class);
    when(uriMock.getQuery()).thenReturn("""");
    when(uriInfoMock.getRequestUri()).thenReturn(uriMock);

    // Mock makeHttpCall to send a json response
    // when the prometheus endpoint is queried.
    ClassLoader classLoader = Thread.currentThread().getContextClassLoader();
    InputStream inputStream = classLoader
        .getResourceAsStream(PROMETHEUS_TEST_RESPONSE_FILE);
    HttpURLConnection urlConnectionMock = mock(HttpURLConnection.class);
    when(urlConnectionMock.getResponseCode())
        .thenReturn(HttpServletResponse.SC_OK);
    when(urlConnectionMock.getInputStream()).thenReturn(inputStream);
    when(reconUtilsMock.makeHttpCall(any(URLConnectionFactory.class),
        anyString(), anyBoolean())).thenReturn(urlConnectionMock);

    metricsProxyEndpoint.getMetricsResponse(PROMETHEUS_INSTANT_QUERY_API,
        uriInfoMock, responseMock);

    byte[] fileBytes = FileUtils.readFileToByteArray(
        new File(classLoader.getResource(PROMETHEUS_TEST_RESPONSE_FILE)
            .getFile())
        );
    verify(outputStreamMock).write(fileBytes, 0, fileBytes.length);
  }
"
"  @Test
  public void testGetClusterState() throws Exception {
    Response response = clusterStateEndpoint.getClusterState();
    ClusterStateResponse clusterStateResponse =
        (ClusterStateResponse) response.getEntity();

    Assert.assertEquals(1, clusterStateResponse.getPipelines());
    Assert.assertEquals(0, clusterStateResponse.getVolumes());
    Assert.assertEquals(0, clusterStateResponse.getBuckets());
    Assert.assertEquals(0, clusterStateResponse.getKeys());
    Assert.assertEquals(2, clusterStateResponse.getTotalDatanodes());
    Assert.assertEquals(2, clusterStateResponse.getHealthyDatanodes());

    waitAndCheckConditionAfterHeartbeat(() -> {
      Response response1 = clusterStateEndpoint.getClusterState();
      ClusterStateResponse clusterStateResponse1 =
          (ClusterStateResponse) response1.getEntity();
      return (clusterStateResponse1.getContainers() == 1);
    });

    // check volume, bucket and key count after running table count task
    Pair<String, Boolean> result =
        tableCountTask.reprocess(reconOMMetadataManager);
    assertTrue(result.getRight());
    response = clusterStateEndpoint.getClusterState();
    clusterStateResponse = (ClusterStateResponse) response.getEntity();
    Assert.assertEquals(2, clusterStateResponse.getVolumes());
    Assert.assertEquals(2, clusterStateResponse.getBuckets());
    Assert.assertEquals(3, clusterStateResponse.getKeys());
  }
"
"  @Test
  public void testGetFileCounts() throws Exception {
    OmKeyInfo omKeyInfo1 = mock(OmKeyInfo.class);
    given(omKeyInfo1.getKeyName()).willReturn(""key1"");
    given(omKeyInfo1.getVolumeName()).willReturn(""vol1"");
    given(omKeyInfo1.getBucketName()).willReturn(""bucket1"");
    given(omKeyInfo1.getDataSize()).willReturn(1000L);

    OmKeyInfo omKeyInfo2 = mock(OmKeyInfo.class);
    given(omKeyInfo2.getKeyName()).willReturn(""key2"");
    given(omKeyInfo2.getVolumeName()).willReturn(""vol1"");
    given(omKeyInfo2.getBucketName()).willReturn(""bucket1"");
    given(omKeyInfo2.getDataSize()).willReturn(100000L);

    OmKeyInfo omKeyInfo3 = mock(OmKeyInfo.class);
    given(omKeyInfo3.getKeyName()).willReturn(""key1"");
    given(omKeyInfo3.getVolumeName()).willReturn(""vol2"");
    given(omKeyInfo3.getBucketName()).willReturn(""bucket1"");
    given(omKeyInfo3.getDataSize()).willReturn(1000L);

    OMMetadataManager omMetadataManager = mock(OmMetadataManagerImpl.class);
    TypedTable<String, OmKeyInfo> keyTable = mock(TypedTable.class);

    TypedTable.TypedTableIterator mockKeyIter = mock(TypedTable
        .TypedTableIterator.class);
    TypedTable.TypedKeyValue mockKeyValue = mock(
        TypedTable.TypedKeyValue.class);

    when(keyTable.iterator()).thenReturn(mockKeyIter);
    when(omMetadataManager.getKeyTable(getBucketLayout())).thenReturn(keyTable);
    when(mockKeyIter.hasNext())
        .thenReturn(true)
        .thenReturn(true)
        .thenReturn(true)
        .thenReturn(false);
    when(mockKeyIter.next()).thenReturn(mockKeyValue);
    when(mockKeyValue.getValue())
        .thenReturn(omKeyInfo1)
        .thenReturn(omKeyInfo2)
        .thenReturn(omKeyInfo3);

    Pair<String, Boolean> result =
        fileSizeCountTask.reprocess(omMetadataManager);
    assertTrue(result.getRight());

    assertEquals(3, fileCountBySizeDao.count());
    Response response = utilizationEndpoint.getFileCounts(null, null, 0);
    List<FileCountBySize> resultSet =
        (List<FileCountBySize>) response.getEntity();
    assertEquals(3, resultSet.size());
    assertTrue(resultSet.stream().anyMatch(o -> o.getVolume().equals(""vol1"") &&
        o.getBucket().equals(""bucket1"") && o.getFileSize() == 1024L &&
        o.getCount() == 1L));
    assertTrue(resultSet.stream().anyMatch(o -> o.getVolume().equals(""vol1"") &&
        o.getBucket().equals(""bucket1"") && o.getFileSize() == 131072 &&
        o.getCount() == 1L));
    assertTrue(resultSet.stream().anyMatch(o -> o.getVolume().equals(""vol2"") &&
        o.getBucket().equals(""bucket1"") && o.getFileSize() == 1024L &&
        o.getCount() == 1L));

    // Test for ""volume"" query param
    response = utilizationEndpoint.getFileCounts(""vol1"", null, 0);
    resultSet = (List<FileCountBySize>) response.getEntity();
    assertEquals(2, resultSet.size());
    assertTrue(resultSet.stream().allMatch(o -> o.getVolume().equals(""vol1"")));

    // Test for non-existent volume
    response = utilizationEndpoint.getFileCounts(""vol"", null, 0);
    resultSet = (List<FileCountBySize>) response.getEntity();
    assertEquals(0, resultSet.size());

    // Test for ""volume"" + ""bucket"" query param
    response = utilizationEndpoint.getFileCounts(""vol1"", ""bucket1"", 0);
    resultSet = (List<FileCountBySize>) response.getEntity();
    assertEquals(2, resultSet.size());
    assertTrue(resultSet.stream().allMatch(o -> o.getVolume().equals(""vol1"") &&
        o.getBucket().equals(""bucket1"")));

    // Test for non-existent bucket
    response = utilizationEndpoint.getFileCounts(""vol1"", ""bucket"", 0);
    resultSet = (List<FileCountBySize>) response.getEntity();
    assertEquals(0, resultSet.size());

    // Test for ""volume"" + ""bucket"" + ""fileSize"" query params
    response = utilizationEndpoint.getFileCounts(""vol1"", ""bucket1"", 131072);
    resultSet = (List<FileCountBySize>) response.getEntity();
    assertEquals(1, resultSet.size());
    FileCountBySize o = resultSet.get(0);
    assertTrue(o.getVolume().equals(""vol1"") && o.getBucket().equals(
        ""bucket1"") && o.getFileSize() == 131072);

    // Test for non-existent fileSize
    response = utilizationEndpoint.getFileCounts(""vol1"", ""bucket1"", 1310725);
    resultSet = (List<FileCountBySize>) response.getEntity();
    assertEquals(0, resultSet.size());
  }
"
"  @Test
  public void testOpenContainerCount() throws Exception {
    // In case of pipeline doesn't exist
    waitAndCheckConditionAfterHeartbeat(() -> {

      DatanodeMetadata datanodeMetadata1 = getDatanodeMetadata();
      return datanodeMetadata1.getContainers() == 10
              && datanodeMetadata1.getPipelines().size() == 2;
    });

    DatanodeMetadata datanodeMetadata = getDatanodeMetadata();

    int expectedCnt = datanodeMetadata.getOpenContainers();

    // check if open container's count decrement according
    for (long id = 1L; id <= 10L; ++id) {
      --expectedCnt;
      closeContainer(id);
      DatanodeMetadata metadata = getDatanodeMetadata();
      Assert.assertEquals(expectedCnt, metadata.getOpenContainers());
    }
  }
"
"  @Test
  public void testGetTaskTimes() {
    ReconTaskStatusDao reconTaskStatusDao = getDao(ReconTaskStatusDao.class);

    ReconTaskStatus reconTaskStatusRecord = new ReconTaskStatus(
        ""Dummy_Task"", System.currentTimeMillis(), 0L);
    reconTaskStatusDao.insert(reconTaskStatusRecord);

    List<ReconTaskStatus> resultList = new ArrayList<>();
    resultList.add(reconTaskStatusRecord);

    Response response = taskStatusService.getTaskTimes();

    List<ReconTaskStatus> responseList = (List<ReconTaskStatus>)
        response.getEntity();

    Assert.assertEquals(resultList.size(), responseList.size());
    for(ReconTaskStatus r : responseList) {
      Assert.assertEquals(reconTaskStatusRecord.getTaskName(), r.getTaskName());
      Assert.assertEquals(reconTaskStatusRecord.getLastUpdatedTimestamp(),
          r.getLastUpdatedTimestamp());
    }
  }
"
"  @Test
  public void testGetKeysForContainer() {
    Response response = containerEndpoint.getKeysForContainer(1L, -1, """");

    KeysResponse data = (KeysResponse) response.getEntity();
    Collection<KeyMetadata> keyMetadataList = data.getKeys();

    assertEquals(3, data.getTotalCount());
    assertEquals(2, keyMetadataList.size());

    Iterator<KeyMetadata> iterator = keyMetadataList.iterator();

    KeyMetadata keyMetadata = iterator.next();
    assertEquals(""key_one"", keyMetadata.getKey());
    assertEquals(1, keyMetadata.getVersions().size());
    assertEquals(1, keyMetadata.getBlockIds().size());
    Map<Long, List<KeyMetadata.ContainerBlockMetadata>> blockIds =
        keyMetadata.getBlockIds();
    assertEquals(101, blockIds.get(0L).iterator().next().getLocalID());

    keyMetadata = iterator.next();
    assertEquals(""key_two"", keyMetadata.getKey());
    assertEquals(2, keyMetadata.getVersions().size());
    assertTrue(keyMetadata.getVersions().contains(0L) && keyMetadata
        .getVersions().contains(1L));
    assertEquals(2, keyMetadata.getBlockIds().size());
    blockIds = keyMetadata.getBlockIds();
    assertEquals(103, blockIds.get(0L).iterator().next().getLocalID());
    assertEquals(104, blockIds.get(1L).iterator().next().getLocalID());

    response = containerEndpoint.getKeysForContainer(3L, -1, """");
    data = (KeysResponse) response.getEntity();
    keyMetadataList = data.getKeys();
    assertTrue(keyMetadataList.isEmpty());
    assertEquals(0, data.getTotalCount());

    // test if limit works as expected
    response = containerEndpoint.getKeysForContainer(1L, 1, """");
    data = (KeysResponse) response.getEntity();
    keyMetadataList = data.getKeys();
    assertEquals(1, keyMetadataList.size());
    assertEquals(3, data.getTotalCount());
  }
"
"  @Test
  public void testGetKeysForContainerWithPrevKey() {
    // test if prev-key param works as expected
    Response response = containerEndpoint.getKeysForContainer(
        1L, -1, ""/sampleVol/bucketOne/key_one"");

    KeysResponse data =
        (KeysResponse) response.getEntity();

    assertEquals(3, data.getTotalCount());

    Collection<KeyMetadata> keyMetadataList = data.getKeys();
    assertEquals(1, keyMetadataList.size());

    Iterator<KeyMetadata> iterator = keyMetadataList.iterator();
    KeyMetadata keyMetadata = iterator.next();

    assertEquals(""key_two"", keyMetadata.getKey());
    assertEquals(2, keyMetadata.getVersions().size());
    assertEquals(2, keyMetadata.getBlockIds().size());

    response = containerEndpoint.getKeysForContainer(
        1L, -1, StringUtils.EMPTY);
    data = (KeysResponse) response.getEntity();
    keyMetadataList = data.getKeys();

    assertEquals(3, data.getTotalCount());
    assertEquals(2, keyMetadataList.size());
    iterator = keyMetadataList.iterator();
    keyMetadata = iterator.next();
    assertEquals(""key_one"", keyMetadata.getKey());

    // test for negative cases
    response = containerEndpoint.getKeysForContainer(
        1L, -1, ""/sampleVol/bucketOne/invalid_key"");
    data = (KeysResponse) response.getEntity();
    keyMetadataList = data.getKeys();
    assertEquals(3, data.getTotalCount());
    assertEquals(0, keyMetadataList.size());

    response = containerEndpoint.getKeysForContainer(
        5L, -1, """");
    data = (KeysResponse) response.getEntity();
    keyMetadataList = data.getKeys();
    assertEquals(0, keyMetadataList.size());
    assertEquals(0, data.getTotalCount());
  }
"
"  @Test
  public void testGetContainers() {
    Response response = containerEndpoint.getContainers(-1, 0L);

    ContainersResponse responseObject =
        (ContainersResponse) response.getEntity();

    ContainersResponse.ContainersResponseData data =
        responseObject.getContainersResponseData();
    assertEquals(2, data.getTotalCount());

    List<ContainerMetadata> containers = new ArrayList<>(data.getContainers());

    Iterator<ContainerMetadata> iterator = containers.iterator();

    ContainerMetadata containerMetadata = iterator.next();
    assertEquals(1L, containerMetadata.getContainerID());
    // Number of keys for CID:1 should be 3 because of two different versions
    // of key_two stored in CID:1
    assertEquals(3L, containerMetadata.getNumberOfKeys());

    containerMetadata = iterator.next();
    assertEquals(2L, containerMetadata.getContainerID());
    assertEquals(2L, containerMetadata.getNumberOfKeys());

    // test if limit works as expected
    response = containerEndpoint.getContainers(1, 0L);
    responseObject = (ContainersResponse) response.getEntity();
    data = responseObject.getContainersResponseData();
    containers = new ArrayList<>(data.getContainers());
    assertEquals(1, containers.size());
    assertEquals(2, data.getTotalCount());
  }
"
"  @Test
  public void testGetContainersWithPrevKey() {

    Response response = containerEndpoint.getContainers(1, 1L);

    ContainersResponse responseObject =
        (ContainersResponse) response.getEntity();

    ContainersResponse.ContainersResponseData data =
        responseObject.getContainersResponseData();
    assertEquals(2, data.getTotalCount());

    List<ContainerMetadata> containers = new ArrayList<>(data.getContainers());

    Iterator<ContainerMetadata> iterator = containers.iterator();

    ContainerMetadata containerMetadata = iterator.next();

    assertEquals(1, containers.size());
    assertEquals(2L, containerMetadata.getContainerID());

    response = containerEndpoint.getContainers(-1, 0L);
    responseObject = (ContainersResponse) response.getEntity();
    data = responseObject.getContainersResponseData();
    containers = new ArrayList<>(data.getContainers());
    assertEquals(2, containers.size());
    assertEquals(2, data.getTotalCount());
    iterator = containers.iterator();
    containerMetadata = iterator.next();
    assertEquals(1L, containerMetadata.getContainerID());

    // test for negative cases
    response = containerEndpoint.getContainers(-1, 5L);
    responseObject = (ContainersResponse) response.getEntity();
    data = responseObject.getContainersResponseData();
    containers = new ArrayList<>(data.getContainers());
    assertEquals(0, containers.size());
    assertEquals(2, data.getTotalCount());

    response = containerEndpoint.getContainers(-1, -1L);
    responseObject = (ContainersResponse) response.getEntity();
    data = responseObject.getContainersResponseData();
    containers = new ArrayList<>(data.getContainers());
    assertEquals(2, containers.size());
    assertEquals(2, data.getTotalCount());
  }
"
"  @Test
  public void testGetMissingContainers() throws IOException {
    Response response = containerEndpoint.getMissingContainers();

    MissingContainersResponse responseObject =
        (MissingContainersResponse) response.getEntity();

    assertEquals(0, responseObject.getTotalCount());
    assertEquals(Collections.EMPTY_LIST, responseObject.getContainers());

    // Add missing containers to the database
    long missingSince = System.currentTimeMillis();
    UnhealthyContainers missing = new UnhealthyContainers();
    missing.setContainerId(1L);
    missing.setInStateSince(missingSince);
    missing.setActualReplicaCount(0);
    missing.setExpectedReplicaCount(3);
    missing.setReplicaDelta(3);
    missing.setContainerState(
        ContainerSchemaDefinition.UnHealthyContainerStates.MISSING.toString());
    ArrayList<UnhealthyContainers> missingList =
        new ArrayList<UnhealthyContainers>();
    missingList.add(missing);
    containerHealthSchemaManager.insertUnhealthyContainerRecords(missingList);

    putContainerInfos(1);
    // Add container history for id 1
    final UUID u1 = newDatanode(""host1"", ""127.0.0.1"");
    final UUID u2 = newDatanode(""host2"", ""127.0.0.2"");
    final UUID u3 = newDatanode(""host3"", ""127.0.0.3"");
    final UUID u4 = newDatanode(""host4"", ""127.0.0.4"");
    reconContainerManager.upsertContainerHistory(1L, u1, 1L, 1L);
    reconContainerManager.upsertContainerHistory(1L, u2, 2L, 1L);
    reconContainerManager.upsertContainerHistory(1L, u3, 3L, 1L);
    reconContainerManager.upsertContainerHistory(1L, u4, 4L, 1L);

    response = containerEndpoint.getMissingContainers();
    responseObject = (MissingContainersResponse) response.getEntity();
    assertEquals(1, responseObject.getTotalCount());
    MissingContainerMetadata container =
        responseObject.getContainers().stream().findFirst().orElse(null);
    Assert.assertNotNull(container);

    assertEquals(containerID.getId(), container.getContainerID());
    assertEquals(keyCount, container.getKeys());
    assertEquals(pipelineID.getId(), container.getPipelineID());
    assertEquals(3, container.getReplicas().size());
    assertEquals(missingSince, container.getMissingSince());

    Set<String> datanodes = Collections.unmodifiableSet(
        new HashSet<>(Arrays.asList(""host2"", ""host3"", ""host4"")));
    List<ContainerHistory> containerReplicas = container.getReplicas();
    containerReplicas.forEach(history -> {
      Assert.assertTrue(datanodes.contains(history.getDatanodeHost()));
    });
  }
"
"  @Test
  public void testUnhealthyContainers() throws IOException {
    Response response = containerEndpoint.getUnhealthyContainers(1000, 1);

    UnhealthyContainersResponse responseObject =
        (UnhealthyContainersResponse) response.getEntity();

    assertEquals(0, responseObject.getMissingCount());
    assertEquals(0, responseObject.getOverReplicatedCount());
    assertEquals(0, responseObject.getUnderReplicatedCount());
    assertEquals(0, responseObject.getMisReplicatedCount());

    assertEquals(Collections.EMPTY_LIST, responseObject.getContainers());

    putContainerInfos(14);
    uuid1 = newDatanode(""host1"", ""127.0.0.1"");
    uuid2 = newDatanode(""host2"", ""127.0.0.2"");
    uuid3 = newDatanode(""host3"", ""127.0.0.3"");
    uuid4 = newDatanode(""host4"", ""127.0.0.4"");
    createUnhealthyRecords(5, 4, 3, 2);

    response = containerEndpoint.getUnhealthyContainers(1000, 1);

    responseObject = (UnhealthyContainersResponse) response.getEntity();
    assertEquals(5, responseObject.getMissingCount());
    assertEquals(4, responseObject.getOverReplicatedCount());
    assertEquals(3, responseObject.getUnderReplicatedCount());
    assertEquals(2, responseObject.getMisReplicatedCount());

    Collection<UnhealthyContainerMetadata> records
        = responseObject.getContainers();
    List<UnhealthyContainerMetadata> missing = records
        .stream()
        .filter(r -> r.getContainerState()
            .equals(UnHealthyContainerStates.MISSING.toString()))
        .collect(Collectors.toList());
    assertEquals(5, missing.size());
    assertEquals(3, missing.get(0).getExpectedReplicaCount());
    assertEquals(0, missing.get(0).getActualReplicaCount());
    assertEquals(3, missing.get(0).getReplicaDeltaCount());
    assertEquals(12345L, missing.get(0).getUnhealthySince());
    assertEquals(1L, missing.get(0).getContainerID());
    assertEquals(keyCount, missing.get(0).getKeys());
    assertEquals(pipelineID.getId(), missing.get(0).getPipelineID());
    assertEquals(3, missing.get(0).getReplicas().size());
    assertNull(missing.get(0).getReason());

    Set<String> datanodes = Collections.unmodifiableSet(
        new HashSet<>(Arrays.asList(""host2"", ""host3"", ""host4"")));
    List<ContainerHistory> containerReplicas = missing.get(0).getReplicas();
    containerReplicas.forEach(history -> {
      Assert.assertTrue(datanodes.contains(history.getDatanodeHost()));
    });

    List<UnhealthyContainerMetadata> overRep = records
        .stream()
        .filter(r -> r.getContainerState()
            .equals(UnHealthyContainerStates.OVER_REPLICATED.toString()))
        .collect(Collectors.toList());
    assertEquals(4, overRep.size());
    assertEquals(3, overRep.get(0).getExpectedReplicaCount());
    assertEquals(5, overRep.get(0).getActualReplicaCount());
    assertEquals(-2, overRep.get(0).getReplicaDeltaCount());
    assertEquals(12345L, overRep.get(0).getUnhealthySince());
    assertEquals(6L, overRep.get(0).getContainerID());
    assertNull(overRep.get(0).getReason());

    List<UnhealthyContainerMetadata> underRep = records
        .stream()
        .filter(r -> r.getContainerState()
            .equals(UnHealthyContainerStates.UNDER_REPLICATED.toString()))
        .collect(Collectors.toList());
    assertEquals(3, underRep.size());
    assertEquals(3, underRep.get(0).getExpectedReplicaCount());
    assertEquals(1, underRep.get(0).getActualReplicaCount());
    assertEquals(2, underRep.get(0).getReplicaDeltaCount());
    assertEquals(12345L, underRep.get(0).getUnhealthySince());
    assertEquals(10L, underRep.get(0).getContainerID());
    assertNull(underRep.get(0).getReason());

    List<UnhealthyContainerMetadata> misRep = records
        .stream()
        .filter(r -> r.getContainerState()
            .equals(UnHealthyContainerStates.MIS_REPLICATED.toString()))
        .collect(Collectors.toList());
    assertEquals(2, misRep.size());
    assertEquals(2, misRep.get(0).getExpectedReplicaCount());
    assertEquals(1, misRep.get(0).getActualReplicaCount());
    assertEquals(1, misRep.get(0).getReplicaDeltaCount());
    assertEquals(12345L, misRep.get(0).getUnhealthySince());
    assertEquals(13L, misRep.get(0).getContainerID());
    assertEquals(""some reason"", misRep.get(0).getReason());
  }
"
"  @Test
  public void testUnhealthyContainersFilteredResponse() throws IOException {
    String missing =  UnHealthyContainerStates.MISSING.toString();

    Response response = containerEndpoint
        .getUnhealthyContainers(missing, 1000, 1);

    UnhealthyContainersResponse responseObject =
        (UnhealthyContainersResponse) response.getEntity();

    assertEquals(0, responseObject.getMissingCount());
    assertEquals(0, responseObject.getOverReplicatedCount());
    assertEquals(0, responseObject.getUnderReplicatedCount());
    assertEquals(0, responseObject.getMisReplicatedCount());
    assertEquals(Collections.EMPTY_LIST, responseObject.getContainers());

    putContainerInfos(5);
    uuid1 = newDatanode(""host1"", ""127.0.0.1"");
    uuid2 = newDatanode(""host2"", ""127.0.0.2"");
    uuid3 = newDatanode(""host3"", ""127.0.0.3"");
    uuid4 = newDatanode(""host4"", ""127.0.0.4"");
    createUnhealthyRecords(5, 4, 3, 2);

    response = containerEndpoint.getUnhealthyContainers(missing, 1000, 1);

    responseObject = (UnhealthyContainersResponse) response.getEntity();
    // Summary should have the count for all unhealthy:
    assertEquals(5, responseObject.getMissingCount());
    assertEquals(4, responseObject.getOverReplicatedCount());
    assertEquals(3, responseObject.getUnderReplicatedCount());
    assertEquals(2, responseObject.getMisReplicatedCount());

    Collection<UnhealthyContainerMetadata> records
        = responseObject.getContainers();

    // There should only be 5 missing containers and no others as we asked for
    // only missing.
    assertEquals(5, records.size());
    for (UnhealthyContainerMetadata r : records) {
      assertEquals(missing, r.getContainerState());
    }
  }
"
"  @Test
  public void testUnhealthyContainersInvalidState() {
    try {
      containerEndpoint.getUnhealthyContainers(""invalid"", 1000, 1);
      fail(""Expected exception to be raised"");
    } catch (WebApplicationException e) {
      assertEquals(""HTTP 400 Bad Request"", e.getMessage());
    }
  }
"
"  @Test
  public void testUnhealthyContainersPaging() throws IOException {
    putContainerInfos(6);
    uuid1 = newDatanode(""host1"", ""127.0.0.1"");
    uuid2 = newDatanode(""host2"", ""127.0.0.2"");
    uuid3 = newDatanode(""host3"", ""127.0.0.3"");
    uuid4 = newDatanode(""host4"", ""127.0.0.4"");
    createUnhealthyRecords(5, 4, 3, 2);
    UnhealthyContainersResponse firstBatch =
        (UnhealthyContainersResponse) containerEndpoint.getUnhealthyContainers(
            3, 1).getEntity();

    UnhealthyContainersResponse secondBatch =
        (UnhealthyContainersResponse) containerEndpoint.getUnhealthyContainers(
            3, 2).getEntity();

    ArrayList<UnhealthyContainerMetadata> records
        = new ArrayList<>(firstBatch.getContainers());
    assertEquals(3, records.size());
    assertEquals(1L, records.get(0).getContainerID());
    assertEquals(2L, records.get(1).getContainerID());
    assertEquals(3L, records.get(2).getContainerID());

    records
        = new ArrayList<>(secondBatch.getContainers());
    assertEquals(3, records.size());
    assertEquals(4L, records.get(0).getContainerID());
    assertEquals(5L, records.get(1).getContainerID());
    assertEquals(6L, records.get(2).getContainerID());
  }
"
"  @Test
  public void testGetReplicaHistoryForContainer() throws IOException {
    // Add container history for container id 1
    final UUID u1 = newDatanode(""host1"", ""127.0.0.1"");
    final UUID u2 = newDatanode(""host2"", ""127.0.0.2"");
    final UUID u3 = newDatanode(""host3"", ""127.0.0.3"");
    final UUID u4 = newDatanode(""host4"", ""127.0.0.4"");
    reconContainerManager.upsertContainerHistory(1L, u1, 1L, 1L);
    reconContainerManager.upsertContainerHistory(1L, u2, 2L, 1L);
    reconContainerManager.upsertContainerHistory(1L, u3, 3L, 1L);
    reconContainerManager.upsertContainerHistory(1L, u4, 4L, 1L);

    reconContainerManager.upsertContainerHistory(1L, u1, 5L, 1L);

    Response response = containerEndpoint.getReplicaHistoryForContainer(1L);
    List<ContainerHistory> histories =
        (List<ContainerHistory>) response.getEntity();
    Set<String> datanodes = Collections.unmodifiableSet(
        new HashSet<>(Arrays.asList(
            u1.toString(), u2.toString(), u3.toString(), u4.toString())));
    Assert.assertEquals(4, histories.size());
    histories.forEach(history -> {
      Assert.assertTrue(datanodes.contains(history.getDatanodeUuid()));
      if (history.getDatanodeUuid().equals(u1.toString())) {
        Assert.assertEquals(""host1"", history.getDatanodeHost());
        Assert.assertEquals(1L, history.getFirstSeenTime());
        Assert.assertEquals(5L, history.getLastSeenTime());
      }
    });

    // Check getLatestContainerHistory
    List<ContainerHistory> hist1 = reconContainerManager
        .getLatestContainerHistory(1L, 10);
    Assert.assertTrue(hist1.size() <= 10);
    // Descending order by last report timestamp
    for (int i = 0; i < hist1.size() - 1; i++) {
      Assert.assertTrue(hist1.get(i).getLastSeenTime()
          >= hist1.get(i + 1).getLastSeenTime());
    }
  }
"
"  @Test
  public void testContainerKeyPrefixCodec() throws IOException {
    ContainerKeyPrefix containerKeyPrefix = new ContainerKeyPrefix(
        System.currentTimeMillis(), ""TestKeyPrefix"", 0);

    Codec<ContainerKeyPrefix> codec = new ContainerKeyPrefixCodec();
    byte[] persistedFormat = codec.toPersistedFormat(containerKeyPrefix);
    Assert.assertTrue(persistedFormat != null);
    ContainerKeyPrefix fromPersistedFormat =
        codec.fromPersistedFormat(persistedFormat);
    Assert.assertEquals(containerKeyPrefix, fromPersistedFormat);
  }
"
"  @Test
  public void testIntegerCodec() throws IOException {
    Integer i = 1000;
    Codec<Integer> codec = new IntegerCodec();
    byte[] persistedFormat = codec.toPersistedFormat(i);
    Assert.assertTrue(persistedFormat != null);
    Integer fromPersistedFormat =
        codec.fromPersistedFormat(persistedFormat);
    Assert.assertEquals(i, fromPersistedFormat);
  }
"
"  @Test
  public void testGet() throws Exception {
    ReconDBProvider reconDBProvider = injector.getInstance(
        ReconDBProvider.class);
    assertNotNull(reconDBProvider.getDbStore());
  }
"
"  @Test
  public void testGetPipelines() throws IOException {
    StorageContainerServiceProvider scmProvider =
        injector.getInstance(StorageContainerServiceProvider.class);
    StorageContainerLocationProtocol scmClient =
        injector.getInstance(StorageContainerLocationProtocol.class);
    scmProvider.getPipelines();
    verify(scmClient, times(1)).listPipelines();
  }
"
"  @Test
  public void testGetPipeline() throws IOException {
    StorageContainerServiceProvider scmProvider =
        injector.getInstance(StorageContainerServiceProvider.class);
    StorageContainerLocationProtocol scmClient =
        injector.getInstance(StorageContainerLocationProtocol.class);
    Pipeline pipeline = scmProvider.getPipeline(pipelineID);
    assertNotNull(pipeline);
    verify(scmClient, times(1))
        .getPipeline(pipelineID);
  }
"
"  @Test
  public void testInitNewContainerDB() throws Exception {
    long containerId = System.currentTimeMillis();
    Map<ContainerKeyPrefix, Integer> prefixCounts = new HashMap<>();

    ContainerKeyPrefix ckp1 = new ContainerKeyPrefix(containerId,
        ""V1/B1/K1"", 0);
    prefixCounts.put(ckp1, 1);

    ContainerKeyPrefix ckp2 = new ContainerKeyPrefix(containerId,
        ""V1/B1/K2"", 0);
    prefixCounts.put(ckp2, 2);

    ContainerKeyPrefix ckp3 = new ContainerKeyPrefix(containerId,
        ""V1/B2/K3"", 0);
    prefixCounts.put(ckp3, 3);

    for (Map.Entry<ContainerKeyPrefix, Integer> entry :
        prefixCounts.entrySet()) {
      reconContainerMetadataManager.storeContainerKeyMapping(
          entry.getKey(), prefixCounts.get(entry.getKey()));
    }

    assertEquals(1, reconContainerMetadataManager
        .getCountForContainerKeyPrefix(ckp1).intValue());

    prefixCounts.clear();
    prefixCounts.put(ckp2, 12);
    prefixCounts.put(ckp3, 13);
    ContainerKeyPrefix ckp4 = new ContainerKeyPrefix(containerId,
        ""V1/B3/K1"", 0);
    prefixCounts.put(ckp4, 14);
    ContainerKeyPrefix ckp5 = new ContainerKeyPrefix(containerId,
        ""V1/B3/K2"", 0);
    prefixCounts.put(ckp5, 15);

    reconContainerMetadataManager
            .reinitWithNewContainerDataFromOm(prefixCounts);
    Map<ContainerKeyPrefix, Integer> keyPrefixesForContainer =
        reconContainerMetadataManager.getKeyPrefixesForContainer(containerId);

    assertEquals(4, keyPrefixesForContainer.size());
    assertEquals(12, keyPrefixesForContainer.get(ckp2).intValue());
    assertEquals(13, keyPrefixesForContainer.get(ckp3).intValue());
    assertEquals(14, keyPrefixesForContainer.get(ckp4).intValue());
    assertEquals(15, keyPrefixesForContainer.get(ckp5).intValue());

    assertEquals(0, reconContainerMetadataManager
        .getCountForContainerKeyPrefix(ckp1).intValue());
  }
"
"  @Test
  public void testStoreContainerKeyMapping() throws Exception {

    long containerId = System.currentTimeMillis();
    Map<String, Integer> prefixCounts = new HashMap<>();
    prefixCounts.put(keyPrefix1, 1);
    prefixCounts.put(keyPrefix2, 2);
    prefixCounts.put(keyPrefix3, 3);

    for (Map.Entry<String, Integer> entry : prefixCounts.entrySet()) {
      ContainerKeyPrefix containerKeyPrefix = new ContainerKeyPrefix(
          containerId, entry.getKey(), 0);
      reconContainerMetadataManager.storeContainerKeyMapping(
          containerKeyPrefix, prefixCounts.get(entry.getKey()));
    }

    Assert.assertEquals(1,
        reconContainerMetadataManager.getCountForContainerKeyPrefix(
            new ContainerKeyPrefix(containerId, keyPrefix1,
                0)).longValue());
    Assert.assertEquals(2,
        reconContainerMetadataManager.getCountForContainerKeyPrefix(
            new ContainerKeyPrefix(containerId, keyPrefix2,
                0)).longValue());
    Assert.assertEquals(3,
        reconContainerMetadataManager.getCountForContainerKeyPrefix(
            new ContainerKeyPrefix(containerId, keyPrefix3,
                0)).longValue());
  }
"
"  @Test
  public void testStoreContainerKeyCount() throws Exception {
    long containerId = 1L;
    long nextContainerId = 2L;
    reconContainerMetadataManager.storeContainerKeyCount(containerId, 2L);
    reconContainerMetadataManager.storeContainerKeyCount(nextContainerId, 3L);

    assertEquals(2,
        reconContainerMetadataManager.getKeyCountForContainer(containerId));
    assertEquals(3,
        reconContainerMetadataManager.getKeyCountForContainer(nextContainerId));

    reconContainerMetadataManager.storeContainerKeyCount(containerId, 20L);
    assertEquals(20,
        reconContainerMetadataManager.getKeyCountForContainer(containerId));
  }
"
"	@Test
	public void matchAllTest() {
		CronPattern pattern;
		// ä»»ä½æ¶é´å¹é
		pattern = new CronPattern(""* * * * * *"");
		Assert.assertTrue(pattern.match(DateUtil.current(), true));
		Assert.assertTrue(pattern.match(DateUtil.current(), false));
	}
"
"	@Test
	public void matchAllTest2() {
		// å¨5ä½è¡¨è¾¾å¼ä¸­ï¼ç§é¨åå¹¶ä¸æ¯ä»»æå¹éï¼èæ¯ä¸ä¸ªåºå®å¼
		// å æ­¤æ­¤å¤å¹éå°±ä¸è½å¹éç§
		CronPattern pattern;
		// ä»»ä½æ¶é´å¹é
		pattern = new CronPattern(""* * * * *"");
		for(int i = 0; i < 1; i++) {
			Assert.assertTrue(pattern.match(DateUtil.current(), false));
		}
	}
"
"	@Test
	public void cronPatternTest() {
		CronPattern pattern;

		// 12:11å¹é
		pattern = new CronPattern(""39 11 12 * * *"");
		assertMatch(pattern, ""12:11:39"");

		// æ¯5åéå¹éï¼å¹éåéä¸ºï¼[0,5,10,15,20,25,30,35,40,45,50,55]
		pattern = new CronPattern(""39 */5 * * * *"");
		assertMatch(pattern, ""12:00:39"");
		assertMatch(pattern, ""12:05:39"");
		assertMatch(pattern, ""12:10:39"");
		assertMatch(pattern, ""12:15:39"");
		assertMatch(pattern, ""12:20:39"");
		assertMatch(pattern, ""12:25:39"");
		assertMatch(pattern, ""12:30:39"");
		assertMatch(pattern, ""12:35:39"");
		assertMatch(pattern, ""12:40:39"");
		assertMatch(pattern, ""12:45:39"");
		assertMatch(pattern, ""12:50:39"");
		assertMatch(pattern, ""12:55:39"");

		// 2:01,3:01,4:01
		pattern = new CronPattern(""39 1 2-4 * * *"");
		assertMatch(pattern, ""02:01:39"");
		assertMatch(pattern, ""03:01:39"");
		assertMatch(pattern, ""04:01:39"");

		// 2:01,3:01,4:01
		pattern = new CronPattern(""39 1 2,3,4 * * *"");
		assertMatch(pattern, ""02:01:39"");
		assertMatch(pattern, ""03:01:39"");
		assertMatch(pattern, ""04:01:39"");

		// 08-07, 08-06
		pattern = new CronPattern(""39 0 0 6,7 8 *"");
		assertMatch(pattern, ""2016-08-07 00:00:39"");
		assertMatch(pattern, ""2016-08-06 00:00:39"");

		// å«åå¿½ç¥å¤§å°å
		pattern = new CronPattern(""39 0 0 6,7 Aug *"");
		assertMatch(pattern, ""2016-08-06 00:00:39"");
		assertMatch(pattern, ""2016-08-07 00:00:39"");

		pattern = new CronPattern(""39 0 0 7 aug *"");
		assertMatch(pattern, ""2016-08-07 00:00:39"");

		// ææå
		pattern = new CronPattern(""39 0 0 * * Thu"");
		assertMatch(pattern, ""2017-02-09 00:00:39"");
		assertMatch(pattern, ""2017-02-09 00:00:39"");

	}
"
"	@Test
	public void CronPatternTest2() {
		CronPattern pattern = new CronPattern(""0/30 * * * *"");
		Assert.assertTrue(pattern.match(DateUtil.parse(""2018-10-09 12:00:00"").getTime(), false));
		Assert.assertTrue(pattern.match(DateUtil.parse(""2018-10-09 12:30:00"").getTime(), false));
		
		pattern = new CronPattern(""32 * * * *"");
		Assert.assertTrue(pattern.match(DateUtil.parse(""2018-10-09 12:32:00"").getTime(), false));
	}
"
"	@Test
	public void patternTest() {
		CronPattern pattern = new CronPattern(""* 0 4 * * ?"");
		assertMatch(pattern, ""2017-02-09 04:00:00"");
		assertMatch(pattern, ""2017-02-19 04:00:33"");

		// 6ä½Quartzé£æ ¼è¡¨è¾¾å¼
		pattern = new CronPattern(""* 0 4 * * ?"");
		assertMatch(pattern, ""2017-02-09 04:00:00"");
		assertMatch(pattern, ""2017-02-19 04:00:33"");
	}
"
"	@Test
	public void rangePatternTest() {
		CronPattern pattern = new CronPattern(""* 20/2 * * * ?"");
		assertMatch(pattern, ""2017-02-09 04:20:00"");
		assertMatch(pattern, ""2017-02-09 05:20:00"");
		assertMatch(pattern, ""2017-02-19 04:22:33"");

		pattern = new CronPattern(""* 2-20/2 * * * ?"");
		assertMatch(pattern, ""2017-02-09 04:02:00"");
		assertMatch(pattern, ""2017-02-09 05:04:00"");
		assertMatch(pattern, ""2017-02-19 04:20:33"");
	}
"
"	@Test
	public void lastTest() {
		// æ¯ææåä¸å¤©çä»»ææ¶é´
		CronPattern pattern = new CronPattern(""* * * L * ?"");
		assertMatch(pattern, ""2017-07-31 04:20:00"");
		assertMatch(pattern, ""2017-02-28 04:20:00"");

		// æåä¸ä¸ªæçä»»ææ¶é´
		pattern = new CronPattern(""* * * * L ?"");
		assertMatch(pattern, ""2017-12-02 04:20:00"");

		// ä»»æå¤©çæåæ¶é´
		pattern = new CronPattern(""L L L * * ?"");
		assertMatch(pattern, ""2017-12-02 23:59:59"");
	}
"
"	@Test(expected = CronException.class)
	public void rangeYearTest() {
		// yearçèå´æ¯1970~2099å¹´ï¼è¶åºæ¥é
		CronPattern pattern = new CronPattern(""0/1 * * * 1/1 ? 2020-2120"");
	}
"
"	@Test
	public void matchedDatesTest() {
		//æµè¯æ¯30ç§æ§è¡
		List<Date> matchedDates = CronPatternUtil.matchedDates(""0/30 * 8-18 * * ?"", DateUtil.parse(""2018-10-15 14:33:22""), 5, true);
		Assert.assertEquals(5, matchedDates.size());
		Assert.assertEquals(""2018-10-15 14:33:30"", matchedDates.get(0).toString());
		Assert.assertEquals(""2018-10-15 14:34:00"", matchedDates.get(1).toString());
		Assert.assertEquals(""2018-10-15 14:34:30"", matchedDates.get(2).toString());
		Assert.assertEquals(""2018-10-15 14:35:00"", matchedDates.get(3).toString());
		Assert.assertEquals(""2018-10-15 14:35:30"", matchedDates.get(4).toString());
	}
"
"	@Test
	public void matchedDatesTest2() {
		//æµè¯æ¯å°æ¶æ§è¡
		List<Date> matchedDates = CronPatternUtil.matchedDates(""0 0 */1 * * *"", DateUtil.parse(""2018-10-15 14:33:22""), 5, true);
		Assert.assertEquals(5, matchedDates.size());
		Assert.assertEquals(""2018-10-15 15:00:00"", matchedDates.get(0).toString());
		Assert.assertEquals(""2018-10-15 16:00:00"", matchedDates.get(1).toString());
		Assert.assertEquals(""2018-10-15 17:00:00"", matchedDates.get(2).toString());
		Assert.assertEquals(""2018-10-15 18:00:00"", matchedDates.get(3).toString());
		Assert.assertEquals(""2018-10-15 19:00:00"", matchedDates.get(4).toString());
	}
"
"	@Test
	public void matchedDatesTest3() {
		//æµè¯æåä¸å¤©
		List<Date> matchedDates = CronPatternUtil.matchedDates(""0 0 */1 L * *"", DateUtil.parse(""2018-10-30 23:33:22""), 5, true);
		Assert.assertEquals(5, matchedDates.size());
		Assert.assertEquals(""2018-10-31 00:00:00"", matchedDates.get(0).toString());
		Assert.assertEquals(""2018-10-31 01:00:00"", matchedDates.get(1).toString());
		Assert.assertEquals(""2018-10-31 02:00:00"", matchedDates.get(2).toString());
		Assert.assertEquals(""2018-10-31 03:00:00"", matchedDates.get(3).toString());
		Assert.assertEquals(""2018-10-31 04:00:00"", matchedDates.get(4).toString());
	}
"
"	@Test
	public void customCronTest() {
		CronUtil.schedule(""*/2 * * * * *"", (Task) () -> Console.log(""Task excuted.""));

		// æ¯æç§çº§å«å®æ¶ä»»å¡
		CronUtil.setMatchSecond(true);
		CronUtil.start();

		ThreadUtil.waitForDie();
		Console.log(""Exit."");
	}
"
"	@Test
	public void cronTest() {
		// æ¯æç§çº§å«å®æ¶ä»»å¡
		CronUtil.setMatchSecond(true);
		CronUtil.getScheduler().setDaemon(false);
		CronUtil.start();

		ThreadUtil.waitForDie();
		CronUtil.stop();
	}
"
"	@Test
	public void cronWithListenerTest() {
		CronUtil.getScheduler().addListener(new TaskListener() {
			@Override
			public void onStart(TaskExecutor executor) {
				Console.log(""Found task:[{}] start!"", executor.getCronTask().getId());
			}
"
"	@Test
	public void addAndRemoveTest() {
		String id = CronUtil.schedule(""*/2 * * * * *"", (Runnable) () -> Console.log(""task running : 2s""));

		Console.log(id);
		CronUtil.remove(id);

		// æ¯æç§çº§å«å®æ¶ä»»å¡
		CronUtil.setMatchSecond(true);
		CronUtil.start();
	}
"
"	@Test
	public void sendWithFileTest() {
		MailUtil.send(""hutool@foxmail.com"", ""æµè¯"", ""<h1>é®ä»¶æ¥èªHutoolæµè¯</h1>"", true, FileUtil.file(""d:/æµè¯éä»¶ææ¬.txt""));
	}
"
"	@Test
	public void sendWithLongNameFileTest() {
		//éä»¶åé¿åº¦å¤§äº60æ¶çæµè¯
		MailUtil.send(""hutool@foxmail.com"", ""æµè¯"", ""<h1>é®ä»¶æ¥èªHutoolæµè¯</h1>"", true, FileUtil.file(""d:/6-LongLongä¸é¶æ®µå¹³å°å»ºè®¾å¨æ¥2018.3.12-3.16.xlsx""));
	}
"
"	@Test
	public void sendWithImageTest() {
		Map<String, InputStream> map = new HashMap<>();
		map.put(""testImage"", FileUtil.getInputStream(""f:/test/me.png""));
		MailUtil.sendHtml(""hutool@foxmail.com"", ""æµè¯"", ""<h1>é®ä»¶æ¥èªHutoolæµè¯</h1><img src=\""cid:testImage\"" />"", map);
	}
"
"	@Test
	public void sendHtmlTest() {
		MailUtil.send(""hutool@foxmail.com"", ""æµè¯"", ""<h1>é®ä»¶æ¥èªHutoolæµè¯</h1>"", true);
	}
"
"	@Test
	public void sendByAccountTest() {
		MailAccount account = new MailAccount();
		account.setHost(""smtp.yeah.net"");
		account.setPort(465);
		account.setSslEnable(true);
		account.setFrom(""hutool@yeah.net"");
		account.setUser(""hutool"");
		account.setPass(""q1w2e3"");
		MailUtil.send(account, ""914104645@qq.com"", ""æµè¯"", ""<h1>é®ä»¶æ¥èªHutoolæµè¯</h1>"", true);
	}
"
"	@Test
	public void mailAccountTest() {
		MailAccount account = new MailAccount();
		account.setFrom(""hutool@yeah.net"");
		account.setDebug(true);
		account.defaultIfEmpty();
		Properties props = account.getSmtpProps();
		Assert.assertEquals(""true"", props.getProperty(""mail.debug""));
	}
"
"	@Test
	public void parseSettingTest() {
		MailAccount account = GlobalMailAccount.INSTANCE.getAccount();
		account.getSmtpProps();
		
		Assert.assertNotNull(account.getCharset());
		Assert.assertTrue(account.isSslEnable());
	}
"
"	@Test
	public void generateTest() {
		final BufferedImage image = QrCodeUtil.generate(""https://hutool.cn/"", 300, 300);
		Assert.assertNotNull(image);
	}
"
"	@Test
	public void generateCustomTest() {
		QrConfig config = new QrConfig();
		config.setMargin(0);
		config.setForeColor(Color.CYAN);
		// èæ¯è²éæ
		config.setBackColor(null);
		config.setErrorCorrection(ErrorCorrectionLevel.H);
		QrCodeUtil.generate(""https://hutool.cn/"", config, FileUtil.file(""d:/qrcodeCustom.png""));
	}
"
"	@Test
	public void generateWithLogoTest() {
		QrCodeUtil.generate(//
				""http://hutool.cn/"", //
				QrConfig.create().setImg(""e:/pic/face.jpg""), //
				FileUtil.file(""e:/qrcodeWithLogo.jpg""));
	}
"
"	@Test
	public void decodeTest() {
		String decode = QrCodeUtil.decode(FileUtil.file(""e:/pic/qr.png""));
		Console.log(decode);
	}
"
"	@Test
	public void generateAsBase64Test(){
		String base64 = QrCodeUtil.generateAsBase64(""http://hutool.cn/"", new QrConfig(400, 400), ""png"");
		System.out.println(base64);

		byte[] bytes = FileUtil.readBytes(
			new File(""d:/test/qr.png""));
		String encode = Base64.encode(bytes);
		String base641 = QrCodeUtil.generateAsBase64(""http://hutool.cn/"", new QrConfig(400, 400), ""png"", encode);
		System.out.println(base641);

	}
"
"	@Test
	public void getPinyinTest(){
		final String pinyin = PinyinUtil.getPinyin(""ä½ å¥½"", "" "");
		Assert.assertEquals(""ni hao"", pinyin);
	}
"
"	@Test
	public void getPinyinByPinyin4jTest() {
		final Pinyin4jEngine engine = new Pinyin4jEngine();
		final String pinyin = engine.getPinyin(""ä½ å¥½h"", "" "");
		Assert.assertEquals(""ni hao h"", pinyin);
	}
"
"	@Test
	public void getPinyinByBopomofo4jTest() {
		final Bopomofo4jEngine engine = new Bopomofo4jEngine();
		final String pinyin = engine.getPinyin(""ä½ å¥½h"", "" "");
		Assert.assertEquals(""ni haoh"", pinyin);
	}
"
"	@Test
	public void getPinyinUpperCaseTest(){
		final String pinyin = PinyinUtil.getPinyin(""ä½ å¥½æ¡"", "" "");
		Assert.assertEquals(""ni hao yi"", pinyin);
	}
"
"	@Test
	public void getFirstLetterTest(){
		final String result = PinyinUtil.getFirstLetter(""Hæ¯ç¬¬ä¸ä¸ª"", "", "");
		Assert.assertEquals(""h, s, d, y, g"", result);
	}
"
"	@Test
	public void getFirstLetterByPinyin4jTest(){
		final Pinyin4jEngine engine = new Pinyin4jEngine();
		final String result = engine.getFirstLetter(""ææµ·"", """");
		Assert.assertEquals(""lh"", result);
	}
"
"	@Test
	public void getFirstLetterByBopomofo4jTest(){
		final Bopomofo4jEngine engine = new Bopomofo4jEngine();
		final String result = engine.getFirstLetter(""ææµ·"", """");
		Assert.assertEquals(""lh"", result);
	}
"
"	@Test
	public void zipTest(){
		final File file = FileUtil.file(""d:/test/compress/test.zip"");
		StreamArchiver.create(CharsetUtil.CHARSET_UTF_8, ArchiveStreamFactory.ZIP, file)
				.add(FileUtil.file(""d:/Java""), (f)->{
					Console.log(""Add: {}"", f.getPath());
					return true;
				})
				.finish().close();
	}
"
"	@Test
	public void tarTest(){
		final File file = FileUtil.file(""d:/test/compress/test.tar"");
		StreamArchiver.create(CharsetUtil.CHARSET_UTF_8, ArchiveStreamFactory.TAR, file)
				.add(FileUtil.file(""d:/Java""), (f)->{
					Console.log(""Add: {}"", f.getPath());
					return true;
				})
				.finish().close();
	}
"
"	@Test
	public void cpioTest(){
		final File file = FileUtil.file(""d:/test/compress/test.cpio"");
		StreamArchiver.create(CharsetUtil.CHARSET_UTF_8, ArchiveStreamFactory.CPIO, file)
				.add(FileUtil.file(""d:/Java""), (f)->{
					Console.log(""Add: {}"", f.getPath());
					return true;
				})
				.finish().close();
	}
"
"	@Test
	public void senvenZTest(){
		final File file = FileUtil.file(""d:/test/compress/test.7z"");
		CompressUtil.createArchiver(CharsetUtil.CHARSET_UTF_8, ArchiveStreamFactory.SEVEN_Z, file)
				.add(FileUtil.file(""d:/Java/apache-maven-3.6.3""), (f)->{
					Console.log(""Add: {}"", f.getPath());
					return true;
				})
				.finish().close();
	}
"
"	@Test
	public void zipTest(){
		Extractor extractor = CompressUtil.createExtractor(
				CharsetUtil.defaultCharset(),
				FileUtil.file(""d:/test/compress/test.zip""));

		extractor.extract(FileUtil.file(""d:/test/compress/test2/""));
	}
"
"	@Test
	public void sevenZTest(){
		Extractor extractor = CompressUtil.createExtractor(
				CharsetUtil.defaultCharset(),
				FileUtil.file(""d:/test/compress/test.7z""));

		extractor.extract(FileUtil.file(""d:/test/compress/test2/""));
	}
"
"	@Test
	public void evalTest(){
		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = ExpressionUtil.eval(""a-(b-c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
"
"	@Test
	public void jexlTest(){
		ExpressionEngine engine = new JexlEngine();

		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = engine.eval(""a-(b-c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
"
"	@Test
	public void mvelTest(){
		ExpressionEngine engine = new MvelEngine();

		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = engine.eval(""a-(b-c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
"
"	@Test
	public void jfireELTest(){
		ExpressionEngine engine = new JfireELEngine();

		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = engine.eval(""a-(b-c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
"
"	@Test
	public void spELTest(){
		ExpressionEngine engine = new SpELEngine();

		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = engine.eval(""#a-(#b-#c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
"
"	@Test
	public void rhinoTest(){
		ExpressionEngine engine = new RhinoEngine();

		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = engine.eval(""a-(b-c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
"
"	@Test
	public void simpleTest(){
		Foo foo = new Foo(100, 3.14f, new Date());
		ExpressionEngine engine = new AviatorEngine();
		String exp =
				""\""[foo i=\""+ foo.i + \"", f=\"" + foo.f + \"", date.year=\"" + (foo.date.year+1900) + \"", date.month=\"" + foo.date.month + \"", bars[0].name=\"" + #foo.bars[0].name + \""]\"""";
		String result = (String) engine.eval(exp, Dict.create().set(""foo"", foo));
		Assert.assertEquals(""[foo i=100, f=3.14, date.year=2020, date.month=10, bars[0].name=bar]"", result);

		// Assignment.
		exp = ""#foo.bars[0].name='hello aviator' ; #foo.bars[0].name"";
		result = (String) engine.eval(exp, Dict.create().set(""foo"", foo));
		Assert.assertEquals(""hello aviator"", result);
		Assert.assertEquals(""hello aviator"", foo.bars[0].getName());

		exp = ""foo.bars[0] = nil ; foo.bars[0]"";
		result = (String) engine.eval(exp, Dict.create().set(""foo"", foo));
		Console.log(""Execute expression: "" + exp);
		Assert.assertNull(result);
		Assert.assertNull(foo.bars[0]);
	}
"
"	@Test
	public void registerBeanTest() {
		Demo2 registerBean = new Demo2();
		registerBean.setId(123);
		registerBean.setName(""222"");
		SpringUtil.registerBean(""registerBean"", registerBean);

		Demo2 registerBean2 = SpringUtil.getBean(""registerBean"");
		Assert.assertEquals(123, registerBean2.getId());
		Assert.assertEquals(""222"", registerBean2.getName());
	}
"
"	@Test
	public void getBeanTest(){
		final Demo2 testDemo = SpringUtil.getBean(""testDemo"");
		Assert.assertEquals(12345, testDemo.getId());
		Assert.assertEquals(""test"", testDemo.getName());
	}
"
"	@Test
	public void getBeanWithTypeReferenceTest() {
		Map<String, Object> mapBean = SpringUtil.getBean(new TypeReference<Map<String, Object>>() {});
		Assert.assertNotNull(mapBean);
		Assert.assertEquals(""value1"", mapBean.get(""key1""));
		Assert.assertEquals(""value2"", mapBean.get(""key2""));
	}
"
"    @Test
    public void test() {
        // ä½¿ç¨@EnableSpringUtilæ³¨è§£å, è½è·åä¸ä¸æ
        Assert.assertNotNull(SpringUtil.getApplicationContext());
        // ä¸ä½¿ç¨æ¶, ä¸ºnull
//        Assert.assertNull(SpringUtil.getApplicationContext());
    }
"
"	@Test
	public void beanValidatorTest() {
		BeanValidationResult result = ValidationUtil.warpValidate(new TestClass());
		Assert.assertFalse(result.isSuccess());
		Assert.assertEquals(2, result.getErrorMessages().size());
	}
"
"	@Test
	public void propertyValidatorTest() {
		BeanValidationResult result = ValidationUtil.warpValidateProperty(new TestClass(), ""name"");
		Assert.assertFalse(result.isSuccess());
		Assert.assertEquals(1, result.getErrorMessages().size());
	}
"
"	@Test
	public void toUnicodeTest() {
		String emoji = EmojiUtil.toUnicode("":smile:"");
		Assert.assertEquals(""ð"", emoji);
	}
"
"	@Test
	public void toAliasTest() {
		String alias = EmojiUtil.toAlias(""ð"");
		Assert.assertEquals("":smile:"", alias);
	}
"
"	@Test
	public void containsEmojiTest() {
		boolean containsEmoji = EmojiUtil.containsEmoji(""æµè¯ä¸ä¸æ¯å¦åå«EMOJ:ð"");
		Assert.assertEquals(containsEmoji, true);
		boolean notContainsEmoji = EmojiUtil.containsEmoji(""ä¸åå«EMOJ:^_^"");
		Assert.assertEquals(notContainsEmoji, false);

	}
"
"	@Test
	public void bindPortTest() {
		//æ°å»ºä¼è¯ï¼æ­¤ä¼è¯ç¨äºsshè¿æ¥å°è·³æ¿æºï¼å ¡åæºï¼ï¼æ­¤å¤ä¸º10.1.1.1:22
		Session session = JschUtil.getSession(""looly.centos"", 22, ""test"", ""123456"");
		// å°å ¡åæºä¿æ¤çåç½8080ç«¯å£æ å°å°localhostï¼æä»¬å°±å¯ä»¥éè¿è®¿é®http://localhost:8080/è®¿é®åç½æå¡äº
		JschUtil.bindPort(session, ""172.20.12.123"", 8080, 8080);
	}
"
"	@Test
	public void bindRemotePort() throws InterruptedException {
		// å»ºç«ä¼è¯
		Session session = JschUtil.getSession(""looly.centos"", 22, ""test"", ""123456"");
		// ç»å®sshæå¡ç«¯8089ç«¯å£å°æ¬æºç8000ç«¯å£ä¸
		boolean b = JschUtil.bindRemotePort(session, 8089, ""localhost"", 8000);
		Assert.assertTrue(b);
		// ä¿è¯ä¸ç´è¿è¡
//		while (true){
//			Thread.sleep(3000);
//		}
	}
"
"	@Test
	public void sftpTest() {
		Session session = JschUtil.getSession(""looly.centos"", 22, ""root"", ""123456"");
		Sftp sftp = JschUtil.createSftp(session);
		sftp.mkDirs(""/opt/test/aaa/bbb"");
		Console.log(""OK"");
	}
"
"	@Test
	public void reconnectIfTimeoutTest() throws InterruptedException {
		Session session = JschUtil.getSession(""sunnyserver"", 22,""mysftp"",""liuyang1234"");
		Sftp sftp = JschUtil.createSftp(session);

		Console.log(""æå°pwd: "" + sftp.pwd());
		Console.log(""cd / : "" + sftp.cd(""/""));
		Console.log(""ä¼ç ä¸æ®µæ¶é´ï¼æ¥çæ¯å¦è¶æ¶"");
		Thread.sleep(30 * 1000);

		try{
			// å½è¿æ¥è¶æ¶æ¶ï¼isConnected()ä»ç¶è¿åtrueï¼pwdå½ä»¤ä¹è½æ­£å¸¸è¿åï¼å æ­¤ï¼å©ç¨åécdå½ä»¤çè¿åç»æï¼æ¥å¤æ­æ¯å¦è¿æ¥è¶æ¶
			Console.log(""isConnected "" + sftp.getClient().isConnected());
			Console.log(""æå°pwd: "" + sftp.pwd());
			Console.log(""cd / : "" + sftp.cd(""/""));
		}catch (JschRuntimeException e) {
			e.printStackTrace();
		}

		Console.log(""è°ç¨reconnectIfTimeoutæ¹æ³ï¼å¤æ­æ¯å¦è¶æ¶å¹¶éè¿"");
		sftp.reconnectIfTimeout();

		Console.log(""æå°pwd: "" + sftp.pwd());

		IoUtil.close(sftp);
	}
"
"	@Test
	public void getSessionTest(){
		JschUtil.getSession(""192.168.1.134"", 22, ""root"", ""aaa"", null);
	}
"
"	@Test
	public void cdTest() {
		Ftp ftp = new Ftp(""looly.centos"");
		
		ftp.cd(""/file/aaa"");
		Console.log(ftp.pwd());
		
		IoUtil.close(ftp);
	}
"
"	@Test
	public void uploadTest() {
		Ftp ftp = new Ftp(""looly.centos"");
		
		List<String> ls = ftp.ls(""/file"");
		Console.log(ls);
		
		boolean upload = ftp.upload(""/file/aaa"", FileUtil.file(""E:/qrcodeWithLogo.jpg""));
		Console.log(upload);
		
		IoUtil.close(ftp);
	}
"
"	@Test
	public void reconnectIfTimeoutTest() throws InterruptedException {
		Ftp ftp = new Ftp(""looly.centos"");

		Console.log(""æå°pwd: "" + ftp.pwd());

		Console.log(""ä¼ç ä¸æ®µæ¶é´ï¼ç¶ååæ¬¡åépwdå½ä»¤ï¼æåºå¼å¸¸è¡¨æè¿æ¥è¶æ¶"");
		Thread.sleep(35 * 1000);

		try{
			Console.log(""æå°pwd: "" + ftp.pwd());
		}catch (FtpException e) {
			e.printStackTrace();
		}

		Console.log(""å¤æ­æ¯å¦è¶æ¶å¹¶éè¿..."");
		ftp.reconnectIfTimeout();

		Console.log(""æå°pwd: "" + ftp.pwd());

		IoUtil.close(ftp);
	}
"
"	@Test
	public void recursiveDownloadFolder() {
		Ftp ftp = new Ftp(""looly.centos"");
		ftp.recursiveDownloadFolder(""/"",FileUtil.file(""d:/test/download""));

		IoUtil.close(ftp);
	}
"
"	@Test
	public void recursiveDownloadFolderSftp() {
		Sftp ftp = new Sftp(""127.0.0.1"", 22, ""test"", ""test"");

		ftp.cd(""/file/aaa"");
		Console.log(ftp.pwd());
		ftp.recursiveDownloadFolder(""/"",FileUtil.file(""d:/test/download""));

		IoUtil.close(ftp);
	}
"
"	@Test
	public void copyTest() {
		SampleBean bean = new SampleBean();
		bean.setValue(""Hello world"");

		OtherSampleBean otherBean = new OtherSampleBean();
		CglibUtil.copy(bean, otherBean);
		Assert.assertEquals(""Hello world"", otherBean.getValue());

		OtherSampleBean otherBean2 = CglibUtil.copy(bean, OtherSampleBean.class);
		Assert.assertEquals(""Hello world"", otherBean2.getValue());
	}
"
"	@Test
	public void createEngineTest() {
		// é»è®¤åè¯å¼æï¼æ­¤å¤ä¸ºAnsj
		TokenizerEngine engine = TokenizerUtil.createEngine();
		Result result = engine.parse(text);
		checkResult(result);
	}
"
"	@Test
	public void hanlpTest() {
		TokenizerEngine engine = new HanLPEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""è¿ ä¸¤ ä¸ª æ¹æ³ ç åºå« å¨äº è¿å å¼"", resultStr);
	}
"
"	@Test
	public void ikAnalyzerTest() {
		TokenizerEngine engine = new IKAnalyzerEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""è¿ä¸¤ä¸ª æ¹æ³ ç åºå« å¨äº è¿åå¼"", resultStr);
	}
"
"	@Test
	public void jcsegTest() {
		TokenizerEngine engine = new JcsegEngine();
		Result result = engine.parse(text);
		checkResult(result);
	}
"
"	@Test
	public void jiebaTest() {
		TokenizerEngine engine = new JiebaEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""è¿ ä¸¤ä¸ª æ¹æ³ ç åºå« å¨äº è¿åå¼"", resultStr);
	}
"
"	@Test
	public void mmsegTest() {
		TokenizerEngine engine = new MmsegEngine();
		Result result = engine.parse(text);
		checkResult(result);
	}
"
"	@Test
	public void smartcnTest() {
		TokenizerEngine engine = new SmartcnEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""è¿ ä¸¤ ä¸ª æ¹æ³ ç åºå« å¨äº è¿å å¼"", resultStr);
	}
"
"	@Test
	public void wordTest() {
		TokenizerEngine engine = new WordEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""è¿ä¸¤ä¸ª æ¹æ³ ç åºå« å¨äº è¿åå¼"", resultStr);
	}
"
"	@Test
	public void mynlpTest() {
		// æ­¤ååæµè¯éè¦JDK8ï¼é»è®¤å¿½ç¥
		TokenizerEngine engine = new MynlpEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""è¿ ä¸¤ä¸ª æ¹æ³ ç åºå« å¨äº è¿å å¼"", resultStr);
	}
"
"	@Test
	public void charsetTest(){
		final TemplateConfig config = new TemplateConfig(""templates"", TemplateConfig.ResourceMode.CLASSPATH);
		config.setCustomEngine(VelocityEngine.class);
		config.setCharset(CharsetUtil.CHARSET_GBK);
		final TemplateEngine engine = TemplateUtil.createEngine(config);
		Template template = engine.getTemplate(""velocity_test_gbk.vtl"");
		String result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""ä½ å¥½,hutool"", result);
	}
"
"	@Test
	public void thymeleafEngineTest() {
		Map<String, Object> map1 = new HashMap<>();
		map1.put(""name"", ""a"");

		Map<String, Object> map2 = new HashMap<>();
		map2.put(""name"", ""b"");

		// æ¥ææµè¯
		Map<String, Object> map3 = new HashMap<>();
		map3.put(""name"", DateUtil.parse(""2019-01-01""));

		List<Map<String, Object>> list = new ArrayList<>();
		list.add(map1);
		list.add(map2);
		list.add(map3);

		// å­ç¬¦ä¸²æ¨¡æ¿
		TemplateEngine engine = new ThymeleafEngine(new TemplateConfig());
		Template template = engine.getTemplate(""<h3 th:each=\""item : ${list}\"" th:text=\""${item.name}\""></h3>"");
		String render = template.render(Dict.create().set(""list"", list));
		Assert.assertEquals(""<h3>a</h3><h3>b</h3><h3>2019-01-01 00:00:00</h3>"", render);
	}
"
"	@Test
	public void thymeleafEngineTest2() {
		Map<String, Object> map1 = new HashMap<>();
		map1.put(""name"", ""a"");

		Map<String, Object> map2 = new HashMap<>();
		map2.put(""name"", ""b"");

		// æ¥ææµè¯
		Map<String, Object> map3 = new HashMap<>();
		map3.put(""name"", DateUtil.parse(""2019-01-01""));

		List<Map<String, Object>> list = new ArrayList<>();
		list.add(map1);
		list.add(map2);
		list.add(map3);

		LinkedHashMap<String, Object> map = new LinkedHashMap<>();
		map.put(""list"", list);

		 hutoolApi(map);
		thymeleaf(map);
	}
"
"	@Test
	public void createEngineTest() {
		// å­ç¬¦ä¸²æ¨¡æ¿, é»è®¤æ¨¡æ¿å¼æï¼æ­¤å¤ä¸ºBeetl
		TemplateEngine engine = TemplateUtil.createEngine(new TemplateConfig());
		Template template = engine.getTemplate(""hello,${name}"");
		String result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result);

		// classpathä¸­è·åæ¨¡æ¿
		engine = TemplateUtil.createEngine(new TemplateConfig(""templates"", ResourceMode.CLASSPATH));
		Template template2 = engine.getTemplate(""beetl_test.btl"");
		String result2 = template2.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result2);
	}
"
"	@Test
	public void beetlEngineTest() {
		// å­ç¬¦ä¸²æ¨¡æ¿
		TemplateEngine engine = new BeetlEngine(new TemplateConfig(""templates""));
		Template template = engine.getTemplate(""hello,${name}"");
		String result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result);

		// classpathä¸­è·åæ¨¡æ¿
		engine = new BeetlEngine(new TemplateConfig(""templates"", ResourceMode.CLASSPATH));
		Template template2 = engine.getTemplate(""beetl_test.btl"");
		String result2 = template2.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result2);
	}
"
"	@Test
	public void rythmEngineTest() {
		// å­ç¬¦ä¸²æ¨¡æ¿
		TemplateEngine engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"").setCustomEngine(RythmEngine.class));
		Template template = engine.getTemplate(""hello,@name"");
		String result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result);

		// classpathä¸­è·åæ¨¡æ¿
		Template template2 = engine.getTemplate(""rythm_test.tmpl"");
		String result2 = template2.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result2);
	}
"
"	@Test
	public void freemarkerEngineTest() {
		// å­ç¬¦ä¸²æ¨¡æ¿
		TemplateEngine engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"", ResourceMode.STRING).setCustomEngine(FreemarkerEngine.class));
		Template template = engine.getTemplate(""hello,${name}"");
		String result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result);
		
		//ClassPathæ¨¡æ¿
		engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"", ResourceMode.CLASSPATH).setCustomEngine(FreemarkerEngine.class));
		template = engine.getTemplate(""freemarker_test.ftl"");
		result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result);
	}
"
"	@Test
	public void velocityEngineTest() {
		// å­ç¬¦ä¸²æ¨¡æ¿
		TemplateEngine engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"", ResourceMode.STRING).setCustomEngine(VelocityEngine.class));
		Template template = engine.getTemplate(""ä½ å¥½,$name"");
		String result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""ä½ å¥½,hutool"", result);
		
		//ClassPathæ¨¡æ¿
		engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"", ResourceMode.CLASSPATH).setCustomEngine(VelocityEngine.class));
		template = engine.getTemplate(""velocity_test.vtl"");
		result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""ä½ å¥½,hutool"", result);

		template = engine.getTemplate(""templates/velocity_test.vtl"");
		result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""ä½ å¥½,hutool"", result);
	}
"
"	@Test
	public void enjoyEngineTest() {
		// å­ç¬¦ä¸²æ¨¡æ¿
		TemplateEngine engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"").setCustomEngine(EnjoyEngine.class));
		Template template = engine.getTemplate(""#(x + 123)"");
		String result = template.render(Dict.create().set(""x"", 1));
		Assert.assertEquals(""124"", result);

		//ClassPathæ¨¡æ¿
		engine = new EnjoyEngine(
				new TemplateConfig(""templates"", ResourceMode.CLASSPATH).setCustomEngine(EnjoyEngine.class));
		template = engine.getTemplate(""enjoy_test.etl"");
		result = template.render(Dict.create().set(""x"", 1));
		Assert.assertEquals(""124"", result);
	}
"
"	@Test
	public void thymeleafEngineTest() {
		// å­ç¬¦ä¸²æ¨¡æ¿
		TemplateEngine engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"").setCustomEngine(ThymeleafEngine.class));
		Template template = engine.getTemplate(""<h3 th:text=\""${message}\""></h3>"");
		String result = template.render(Dict.create().set(""message"", ""Hutool""));
		Assert.assertEquals(""<h3>Hutool</h3>"", result);
		
		//ClassPathæ¨¡æ¿
		engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"", ResourceMode.CLASSPATH).setCustomEngine(ThymeleafEngine.class));
		template = engine.getTemplate(""thymeleaf_test.ttl"");
		result = template.render(Dict.create().set(""message"", ""Hutool""));
		Assert.assertEquals(""<h3>Hutool</h3>"", result);
	}
"
"	@Test
	public void renderToFileTest() {
		TemplateEngine engine = new BeetlEngine(new TemplateConfig(""templates"", ResourceMode.CLASSPATH));
		Template template = engine.getTemplate(""freemarker_test.ftl"");

		final Map<String, Object> bindingMap = new HashMap<>();
		bindingMap.put(""name"", ""aa"");
		File outputFile = new File(""e:/test.txt"");
		template.render(bindingMap, outputFile);
	}
"
"	@Test
	public void renderStrTest() throws IOException {
		GroupTemplate groupTemplate = BeetlUtil.createGroupTemplate(new StringTemplateResourceLoader(), Configuration.defaultConfiguration());
		Template template = BeetlUtil.getTemplate(groupTemplate, ""hello,${name}"");
		String result = BeetlUtil.render(template, Dict.create().set(""name"", ""hutool""));

		Assert.assertEquals(""hello,hutool"", result);

		String renderFromStr = BeetlUtil.renderFromStr(""hello,${name}"", Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", renderFromStr);

	}
"
"	@Test
	public void aopTest() {
		Animal cat = ProxyUtil.proxy(new Cat(), TimeIntervalAspect.class);
		String result = cat.eat();
		Assert.assertEquals(""ç«åé±¼"", result);
		cat.seize();
	}
"
"	@Test
	public void aopByAutoCglibTest() {
		Dog dog = ProxyUtil.proxy(new Dog(), TimeIntervalAspect.class);
		String result = dog.eat();
		Assert.assertEquals(""çåè"", result);

		dog.seize();
	}
"
"	@Test
	public void testCGLIBProxy() {
		TagObj target = new TagObj();
		//ç®æ ç±»è®¾ç½®æ è®°
		target.setTag(""tag"");

		TagObj proxy = ProxyUtil.proxy(target, TimeIntervalAspect.class);
		//ä»£çç±»è·åæ è®°tag (æ­è¨éè¯¯)
		Assert.assertEquals(""tag"", proxy.getTag());
	}
"
"	@Test
	public void compileTest() {
		CompiledScript script = ScriptUtil.compile(""print('Script test!');"");
		try {
			script.eval();
		} catch (ScriptException e) {
			throw new ScriptRuntimeException(e);
		}
	}
"
"	@Test
	public void evalTest() {
		ScriptUtil.eval(""print('Script test!');"");
	}
"
"	@Test
	public void invokeTest() {
		final Object result = ScriptUtil.invoke(ResourceUtil.readUtf8Str(""filter1.js""), ""filter1"", 2, 1);
		Assert.assertTrue((Boolean) result);
	}
"
"	@Test
	public void pythonTest() throws ScriptException {
		final ScriptEngine pythonEngine = ScriptUtil.getPythonEngine();
		pythonEngine.eval(""print('Hello Python')"");
	}
"
"	@Test
	public void luaTest() throws ScriptException {
		final ScriptEngine engine = ScriptUtil.getLuaEngine();
		engine.eval(""print('Hello Lua')"");
	}
"
"	@Test
	public void groovyTest() throws ScriptException {
		final ScriptEngine engine = ScriptUtil.getGroovyEngine();
		engine.eval(""println 'Hello Groovy'"");
	}
"
"	@Test
	public void dumpTest() {
		SystemUtil.dumpSystemInfo();
	}
"
"	@Test
	public void getCurrentPidTest() {
		long pid = SystemUtil.getCurrentPID();
		Assert.assertTrue(pid > 0);
	}
"
"	@Test
	public void getJavaInfoTest() {
		JavaInfo javaInfo = SystemUtil.getJavaInfo();
		Assert.assertNotNull(javaInfo);
	}
"
"  @Test
  public void testStartShouldStartTheMetricsReportersAndServer() throws Exception {
    NetworkConnector connector = Mockito.mock(NetworkConnector.class);
    int testServerPort = 100;
    Mockito.doReturn(testServerPort).when(connector).getPort();
    Mockito.when(server.getConnectors()).thenReturn(new NetworkConnector[]{connector});
    Mockito.doNothing().when(server).start();
    samzaRestService.start();
    Mockito.verify(metricsReporter).start();
    Mockito.verify(metricsReporter).register(""SamzaRest"", metricsRegistry);
    Mockito.verify(server).start();
  }
"
"  @Test
  public void testStopShouldStopTheMetricsReportersAndStopTheServer() throws Exception {
    samzaRestService.stop();
    Mockito.verify(metricsReporter).stop();
    Mockito.verify(server).stop();
  }
"
"  @Test
  public void testGetJobStatuses() throws IOException, InterruptedException {
    doReturn(APPS_RESPONSE.getBytes()).when(provider).httpGet(anyString());

    List<Job> jobs = Lists.newArrayList(
        new Job(""job1"", ""1""),  // Job with multiple applications, 1 RUNNING
        new Job(""job2"", ""1""),  // Job with 1 KILLED application
        new Job(""job3"", ""1""),  // Job with 1 RUNNING application
        new Job(""job4"", ""1"")); // Job not found in YARN
    provider.getJobStatuses(jobs);

    Collections.sort(jobs, (o1, o2) -> o1.getJobName().compareTo(o2.getJobName()));

    assertEquals(4, jobs.size());
    verifyJobStatus(jobs.get(0), ""job1"", JobStatus.STARTED, ""RUNNING"");
    verifyJobStatus(jobs.get(1), ""job2"", JobStatus.STOPPED, ""KILLED"");
    verifyJobStatus(jobs.get(2), ""job3"", JobStatus.STARTED, ""RUNNING"");
    verifyJobStatus(jobs.get(3), ""job4"", JobStatus.UNKNOWN, null);
  }
"
"  @Test
   public void testGetJobs()
      throws IOException {

    Response resp = target(""v1/jobs"").request().get();
    assertEquals(200, resp.getStatus());
    final Job[] jobs = objectMapper.readValue(resp.readEntity(String.class), Job[].class);
    assertEquals(4, jobs.length);

    assertEquals(MockJobProxy.JOB_INSTANCE_1_NAME, jobs[0].getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_1_ID, jobs[0].getJobId());
    assertStatusNotDefault(jobs[0]);
    assertEquals(MockJobProxy.JOB_INSTANCE_2_NAME, jobs[1].getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_2_ID, jobs[1].getJobId());
    assertStatusNotDefault(jobs[1]);
    assertEquals(MockJobProxy.JOB_INSTANCE_3_NAME, jobs[2].getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_3_ID, jobs[2].getJobId());
    assertStatusNotDefault(jobs[2]);
    assertEquals(MockJobProxy.JOB_INSTANCE_4_NAME, jobs[3].getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_4_ID, jobs[3].getJobId());
    assertStatusNotDefault(jobs[3]);
    resp.close();
  }
"
"  @Test
   public void testPostJobs()
      throws IOException {
    Response resp = target(""v1/jobs"").request().post(Entity.text(""""));
    assertEquals(405, resp.getStatus());
    resp.close();
  }
"
"  @Test
  public void testPutJobs()
      throws IOException {
    Response resp = target(""v1/jobs"").request().put(Entity.text(""""));
    assertEquals(405, resp.getStatus());
    resp.close();
  }
"
"  @Test
  public void testGetJob()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID)).request().get();
    assertEquals(200, resp.getStatus());
    final Job job2 = objectMapper.readValue(resp.readEntity(String.class), Job.class);

    assertEquals(MockJobProxy.JOB_INSTANCE_2_NAME, job2.getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_2_ID, job2.getJobId());
    assertStatusNotDefault(job2);
    resp.close();
  }
"
"  @Test
  public void testPostJob()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID)).request().post(
        Entity.text(""""));
    assertEquals(405, resp.getStatus());
    resp.close();
  }
"
"  @Test
  public void testGetJobNameNotFound()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", ""BadJobName"", MockJobProxy.JOB_INSTANCE_2_ID)).request().get();
    assertEquals(404, resp.getStatus());

    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message""), errorMessage.get(""message"").contains(""does not exist""));
    resp.close();
  }
"
"  @Test
  public void testGetJobIdNotFound()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, ""BadJobId"")).request().get();
    assertEquals(404, resp.getStatus());

    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message""), errorMessage.get(""message"").contains(""does not exist""));
    resp.close();
  }
"
"  @Test
  public void testGetJobNameWithoutId()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s"", MockJobProxy.JOB_INSTANCE_2_NAME)).request().get();
    assertEquals(404, resp.getStatus());
    resp.close();
  }
"
"  @Test
  public void testStartJob()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID))
        .queryParam(""status"", ""started"").request().put(Entity.form(new Form()));
    assertEquals(202, resp.getStatus());

    final Job job2 = objectMapper.readValue(resp.readEntity(String.class), Job.class);
    assertEquals(MockJobProxy.JOB_INSTANCE_2_NAME, job2.getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_2_ID, job2.getJobId());
    assertStatusNotDefault(job2);
    resp.close();
  }
"
"  @Test
  public void testStopJob()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID))
        .queryParam(""status"", ""stopped"").request().put(Entity.form(new Form()));
    assertEquals(202, resp.getStatus());

    final Job job2 = objectMapper.readValue(resp.readEntity(String.class), Job.class);
    assertEquals(MockJobProxy.JOB_INSTANCE_2_NAME, job2.getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_2_ID, job2.getJobId());
    assertStatusNotDefault(job2);
    resp.close();
  }
"
"  @Test
  public void testPutBadJobStatus()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID))
        .queryParam(""status"", ""BADSTATUS"").request().put(Entity.form(new Form()));
    assertEquals(400, resp.getStatus());

    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message"").contains(""BADSTATUS""));
    resp.close();
  }
"
"  @Test
  public void testPutMissingStatus()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID)).request()
        .put(Entity.form(new Form()));
    assertEquals(400, resp.getStatus());

    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message"").contains(""status""));
    resp.close();
  }
"
"  @Test
  public void testGetTasks() throws IOException {
    String requestUrl = String.format(""v1/jobs/%s/%s/tasks"", ""testJobName"", ""testJobId"");
    Response response = target(requestUrl).request().get();
    assertEquals(200, response.getStatus());
    Task[] tasks = objectMapper.readValue(response.readEntity(String.class), Task[].class);
    assertEquals(2, tasks.length);

    assertEquals(MockTaskProxy.TASK_1_PREFERRED_HOST, tasks[0].getPreferredHost());
    assertEquals(MockTaskProxy.TASK_1_CONTAINER_ID, tasks[0].getContainerId());
    assertEquals(MockTaskProxy.TASK_1_NAME, tasks[0].getTaskName());
    assertEquals(MockTaskProxy.PARTITIONS, tasks[0].getPartitions());

    assertEquals(MockTaskProxy.TASK_2_PREFERRED_HOST, tasks[1].getPreferredHost());
    assertEquals(MockTaskProxy.TASK_2_CONTAINER_ID, tasks[1].getContainerId());
    assertEquals(MockTaskProxy.TASK_2_NAME, tasks[1].getTaskName());
    assertEquals(MockTaskProxy.PARTITIONS, tasks[1].getPartitions());
  }
"
"  @Test
  public void testGetTasksWithInvalidJobName() throws IOException {
    String requestUrl = String.format(""v1/jobs/%s/%s/tasks"", ""BadJobName"", MockJobProxy.JOB_INSTANCE_4_ID);
    Response resp = target(requestUrl).request().get();
    assertEquals(400, resp.getStatus());
    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message""), errorMessage.get(""message"").contains(""Invalid arguments for getTasks. ""));
    resp.close();
  }
"
"  @Test
  public void testGetTasksWithInvalidJobId() throws IOException {
    String requestUrl = String.format(""v1/jobs/%s/%s/tasks"", MockJobProxy.JOB_INSTANCE_1_NAME, ""BadJobId"");
    Response resp = target(requestUrl).request().get();
    assertEquals(400, resp.getStatus());
    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message""), errorMessage.get(""message"").contains(""Invalid arguments for getTasks. ""));
    resp.close();
  }
"
"  @Test
  public void shouldDeleteLocalTaskStoreWhenItHasNoOffsetFile() throws Exception {
    localStoreMonitor.monitor();
    assertTrue(""Task store directory should not exist."", !taskStoreDir.exists());
    assertEquals(taskStoreSize, localStoreMonitorMetrics.diskSpaceFreedInBytes.getCount());
    assertEquals(1, localStoreMonitorMetrics.noOfDeletedTaskPartitionStores.getCount());
  }
"
"  @Test
  public void shouldDeleteLocalStoreWhenLastModifiedTimeOfOffsetFileIsGreaterThanOffsetTTL() throws Exception {
    File offsetFile = createOffsetFile(taskStoreDir);
    offsetFile.setLastModified(0);
    localStoreMonitor.monitor();
    assertTrue(""Offset file should not exist."", !offsetFile.exists());
    assertEquals(0, localStoreMonitorMetrics.diskSpaceFreedInBytes.getCount());
  }
"
"  @Test
  public void shouldDeleteInActiveLocalStoresOfTheJob() throws Exception {
    File inActiveStoreDir = new File(jobDir, ""inActiveStore"");
    FileUtils.forceMkdir(inActiveStoreDir);
    File inActiveTaskDir = new File(inActiveStoreDir, ""test-task"");
    FileUtils.forceMkdir(inActiveTaskDir);
    long inActiveTaskDirSize = inActiveTaskDir.getTotalSpace();
    localStoreMonitor.monitor();
    assertTrue(""Inactive task store directory should not exist."", !inActiveTaskDir.exists());
    assertEquals(taskStoreSize + inActiveTaskDirSize, localStoreMonitorMetrics.diskSpaceFreedInBytes.getCount());
    assertEquals(2, localStoreMonitorMetrics.noOfDeletedTaskPartitionStores.getCount());
    FileUtils.deleteDirectory(inActiveStoreDir);
  }
"
"  @Test
  public void shouldDoNothingWhenLastModifiedTimeOfOffsetFileIsLessThanOffsetTTL() throws Exception {
    File offsetFile = createOffsetFile(taskStoreDir);
    localStoreMonitor.monitor();
    assertTrue(""Offset file should exist."", offsetFile.exists());
    assertEquals(0, localStoreMonitorMetrics.diskSpaceFreedInBytes.getCount());
  }
"
"  @Test
  public void shouldDoNothingWhenTheJobIsRunning() throws Exception {
    Mockito.when(jobsClientMock.getJobStatus(Mockito.any())).thenReturn(JobStatus.STARTED);
    File offsetFile = createOffsetFile(taskStoreDir);
    localStoreMonitor.monitor();
    assertTrue(""Offset file should exist."", offsetFile.exists());
    assertEquals(0, localStoreMonitorMetrics.diskSpaceFreedInBytes.getCount());
  }
"
"  @Test
  public void shouldDeleteTaskStoreWhenTaskPreferredStoreIsNotLocalHost() throws Exception {
    Task task = new Task(""notLocalHost"", ""test-task"", ""0"", new ArrayList<>(), ImmutableList.of(""test-store""));
    Mockito.when(jobsClientMock.getTasks(Mockito.any())).thenReturn(ImmutableList.of(task));
    localStoreMonitor.monitor();
    assertTrue(""Task store directory should not exist."", !taskStoreDir.exists());
    assertEquals(taskStoreSize, localStoreMonitorMetrics.diskSpaceFreedInBytes.getCount());
    assertEquals(1, localStoreMonitorMetrics.noOfDeletedTaskPartitionStores.getCount());
  }
"
"  @Test
  public void shouldContinueLocalStoreCleanUpAfterFailureToCleanUpStoreOfAJob() throws Exception {
    File testFailingJobDir = new File(localStoreDir, ""test-jobName-jobId-1"");

    File testFailingTaskStoreDir = new File(new File(testFailingJobDir, ""test-store""), ""test-task"");

    FileUtils.forceMkdir(testFailingTaskStoreDir);

    // For job: test-jobName-jobId-1, throw up in getTasks call and
    // expect the cleanup to succeed for other job: test-jobName-jobId.
    Mockito.doThrow(new RuntimeException(""Dummy exception message.""))
        .when(jobsClientMock)
        .getTasks(new JobInstance(""test-jobName"", ""jobId-1""));

    Task task = new Task(""notLocalHost"", ""test-task"", ""0"", new ArrayList<>(), ImmutableList.of(""test-store""));

    Mockito.when(jobsClientMock.getTasks(new JobInstance(""test-jobName"", ""jobId""))).thenReturn(ImmutableList.of(task));

    Map<String, String> configMap = new HashMap<>(config);
    configMap.put(LocalStoreMonitorConfig.CONFIG_IGNORE_FAILURES, ""true"");

    LocalStoreMonitor localStoreMonitor =
        new LocalStoreMonitor(new LocalStoreMonitorConfig(new MapConfig(configMap)), localStoreMonitorMetrics,
            jobsClientMock);

    localStoreMonitor.monitor();

    // Non failing job directory should be cleaned up.
    assertTrue(""Task store directory should not exist."", !taskStoreDir.exists());
    FileUtils.deleteDirectory(testFailingJobDir);
  }
"
"  @Test
  public void testMonitorsShouldBeInstantiatedProperly() {
    // Test that a monitor should be instantiated properly by invoking
    // the appropriate factory method.
    Map<String, String> configMap = ImmutableMap.of(CONFIG_MONITOR_FACTORY_CLASS,
                                                    DummyMonitorFactory.class.getCanonicalName());
    Monitor monitor = null;
    try {
      monitor = MonitorLoader.instantiateMonitor(""testMonitor"", new MonitorConfig(new MapConfig(configMap)),
          METRICS_REGISTRY);
    } catch (InstantiationException e) {
      fail();
    }
    assertNotNull(monitor);
    // Object should implement the monitor().
    try {
      monitor.monitor();
    } catch (Exception e) {
      fail();
    }
  }
"
"  @Test
  public void testShouldGroupRelevantMonitorConfigTogether() {
    // Test that Monitor Loader groups relevant config together.
    Map<String, String> firstMonitorConfig = ImmutableMap.of(""monitor.monitor1.factory.class"",
                                                             ""org.apache.samza.monitor.DummyMonitor"",
                                                             ""monitor.monitor1.scheduling.interval.ms"",
                                                             ""100"");
    Map<String, String> secondMonitorConfig = ImmutableMap.of(""monitor.monitor2.factory.class"",
                                                              ""org.apache.samza.monitor.DummyMonitor"",
                                                              ""monitor.monitor2.scheduling.interval.ms"",
                                                              ""200"");
    MapConfig mapConfig = new MapConfig(ImmutableList.of(firstMonitorConfig, secondMonitorConfig));
    MonitorConfig expectedFirstConfig = new MonitorConfig(new MapConfig(firstMonitorConfig).subset(""monitor.monitor1.""));
    MonitorConfig expectedSecondConfig = new MonitorConfig(new MapConfig(secondMonitorConfig).subset(""monitor.monitor2.""));
    Map<String, MonitorConfig> expected = ImmutableMap.of(""monitor1"", expectedFirstConfig, ""monitor2"", expectedSecondConfig);
    assertEquals(expected, MonitorConfig.getMonitorConfigs(mapConfig));
  }
"
"  @Test
  public void testMonitorExceptionIsolation() {
    // Test that an exception from a monitor doesn't bubble up out of the scheduler.
    Map<String, String> configMap =
        ImmutableMap.of(String.format(""monitor.name.%s"", CONFIG_MONITOR_FACTORY_CLASS),
                        ExceptionThrowingMonitorFactory.class.getCanonicalName());
    SamzaRestConfig config = new SamzaRestConfig(new MapConfig(configMap));
    SamzaMonitorService monitorService = new SamzaMonitorService(config,
                                                                 METRICS_REGISTRY);

    // This will throw if the exception isn't caught within the provider.
    monitorService.start();
    monitorService.stop();
  }
"
"  @Test
  public void testShouldNotFailWhenTheMonitorFactoryClassIsNotDefined()
      throws Exception {
    // Test that when MonitorFactoryClass is not defined in the config, monitor service
    // should not fail.
    Map<String, String> configMap = ImmutableMap.of(""monitor.monitor1.config.key1"", ""configValue1"",
                                                    ""monitor.monitor1.config.key2"", ""configValue2"",
                                                    String.format(""monitor.MOCK_MONITOR.%s"", CONFIG_MONITOR_FACTORY_CLASS),
                                                    MockMonitorFactory.class.getCanonicalName());

    SamzaRestConfig config = new SamzaRestConfig(new MapConfig(configMap));

    class SamzaMonitorServiceTest extends SamzaMonitorService {
      MetricsRegistry metricsRegistry;
      public SamzaMonitorServiceTest(SamzaRestConfig config, MetricsRegistry metricsRegistry) {
        super(config, metricsRegistry);
        this.metricsRegistry = metricsRegistry;
      }

      @Override
      public void createSchedulerAndScheduleMonitor(String monitorName, MonitorConfig monitorConfig, long schedulingIntervalInMs) {
        try {
          // immediately run monitor, without scheduling
          instantiateMonitor(monitorName, monitorConfig, metricsRegistry).monitor();
        } catch (Exception e) {
          fail();
        }
      }
"
"  @Test(expected = SamzaException.class)
  public void testShouldFailWhenTheMonitorFactoryClassIsInvalid() {
    // Test that when MonitorFactoryClass is defined in the config and is invalid,
    // monitor service should fail. Should throw back SamzaException.
    Map<String, String> configMap = ImmutableMap.of(String.format(""monitor.name.%s"", CONFIG_MONITOR_FACTORY_CLASS),
                                                    ""RandomClassName"");
    SamzaRestConfig config = new SamzaRestConfig(new MapConfig(configMap));
    SamzaMonitorService monitorService = new SamzaMonitorService(config,
                                                                 METRICS_REGISTRY);
    monitorService.start();
  }
"
"  @Test
  public void testScheduledExecutorSchedulingProvider() {
    // Test that the monitor is scheduled by the ScheduledExecutorSchedulingProvider
    ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1);

    // notifyingMonitor.monitor() should be called repeatedly.
    final CountDownLatch wasCalledLatch = new CountDownLatch(3);

    final Monitor notifyingMonitor = new Monitor() {
      @Override
      public void monitor() {
        wasCalledLatch.countDown();
      }
"
"  @Test
  public void testKafkaSystemConsumerMetrics() {
    String systemName = ""system"";
    TopicPartition tp1 = new TopicPartition(""topic1"", 1);
    TopicPartition tp2 = new TopicPartition(""topic2"", 2);
    String clientName = ""clientName"";

    // record expected values for further comparison
    Map<String, String> expectedValues = new HashMap<>();

    ReadableMetricsRegistry registry = new MetricsRegistryMap();
    KafkaSystemConsumerMetrics metrics = new KafkaSystemConsumerMetrics(systemName, registry);

    // initialize the metrics for the partitions
    metrics.registerTopicPartition(tp1);
    metrics.registerTopicPartition(tp2);

    // initialize the metrics for the host:port
    metrics.registerClientProxy(clientName);

    metrics.setOffsets(tp1, 1001);
    metrics.setOffsets(tp2, 1002);
    expectedValues.put(metrics.offsets().get(tp1).getName(), ""1001"");
    expectedValues.put(metrics.offsets().get(tp2).getName(), ""1002"");

    metrics.incBytesReads(tp1, 10);
    metrics.incBytesReads(tp1, 5); // total 15
    expectedValues.put(metrics.bytesRead().get(tp1).getName(), ""15"");

    metrics.incReads(tp1);
    metrics.incReads(tp1); // total 2
    expectedValues.put(metrics.reads().get(tp1).getName(), ""2"");

    metrics.setHighWatermarkValue(tp2, 1000);
    metrics.setHighWatermarkValue(tp2, 1001); // final value 1001
    expectedValues.put(metrics.highWatermark().get(tp2).getName(), ""1001"");

    metrics.setLagValue(tp1, 200);
    metrics.setLagValue(tp1, 201); // final value 201
    expectedValues.put(metrics.lag().get(tp1).getName(), ""201"");

    metrics.incClientBytesReads(clientName, 100); // broker-bytes-read
    metrics.incClientBytesReads(clientName, 110); // total 210
    expectedValues.put(metrics.clientBytesRead().get(clientName).getName(), ""210"");

    metrics.incClientReads(clientName); // messages-read
    metrics.incClientReads(clientName); // total 2
    expectedValues.put(metrics.clientReads().get(clientName).getName(), ""2"");

    metrics.setNumTopicPartitions(clientName, 2); // ""topic-partitions""
    metrics.setNumTopicPartitions(clientName, 3); // final value 3
    expectedValues.put(metrics.topicPartitions().get(clientName).getName(), ""3"");


    String groupName = metrics.group();
    Assert.assertEquals(groupName, KafkaSystemConsumerMetrics.class.getName());
    Assert.assertEquals(metrics.systemName(), systemName);

    Map<String, Metric> metricMap = registry.getGroup(groupName);
    validate(metricMap, expectedValues);
  }
"
"  @Test
  public void testGetSystemStreamMetaDataWithValidTopic() {
    System.out.println(""STARTING"");
    Map<String, SystemStreamMetadata> metadataMap =
        kafkaSystemAdmin.getSystemStreamMetadata(ImmutableSet.of(VALID_TOPIC));

    // verify metadata size
    assertEquals(""metadata should return for 1 topic"", metadataMap.size(), 1);
    System.out.println(""STARTING1"");
    // verify the metadata streamName
    assertEquals(""the stream name should be "" + VALID_TOPIC, metadataMap.get(VALID_TOPIC).getStreamName(), VALID_TOPIC);
    System.out.println(""STARTING2"");
    // verify the offset for each partition
    Map<Partition, SystemStreamMetadata.SystemStreamPartitionMetadata> systemStreamPartitionMetadata =
        metadataMap.get(VALID_TOPIC).getSystemStreamPartitionMetadata();
    assertEquals(""there are 2 partitions"", systemStreamPartitionMetadata.size(), 2);
    System.out.println(""STARTING3"");
    SystemStreamMetadata.SystemStreamPartitionMetadata partition0Metadata =
        systemStreamPartitionMetadata.get(new Partition(0));
    assertEquals(""oldest offset for partition 0"", partition0Metadata.getOldestOffset(),
        KAFKA_BEGINNING_OFFSET_FOR_PARTITION0.toString());
    assertEquals(""upcoming offset for partition 0"", partition0Metadata.getUpcomingOffset(),
        KAFKA_END_OFFSET_FOR_PARTITION0.toString());
    assertEquals(""newest offset for partition 0"", partition0Metadata.getNewestOffset(),
        Long.toString(KAFKA_END_OFFSET_FOR_PARTITION0 - 1));
    System.out.println(""STARTING4"");
    SystemStreamMetadata.SystemStreamPartitionMetadata partition1Metadata =
        systemStreamPartitionMetadata.get(new Partition(1));
    assertEquals(""oldest offset for partition 1"", partition1Metadata.getOldestOffset(),
        KAFKA_BEGINNING_OFFSET_FOR_PARTITION1.toString());
    assertEquals(""upcoming offset for partition 1"", partition1Metadata.getUpcomingOffset(),
        KAFKA_END_OFFSET_FOR_PARTITION1.toString());
    assertEquals(""newest offset for partition 1"", partition1Metadata.getNewestOffset(),
        Long.toString(KAFKA_END_OFFSET_FOR_PARTITION1 - 1));
  }
"
"  @Test
  public void testGetSystemStreamMetaDataWithInvalidTopic() {
    Map<String, SystemStreamMetadata> metadataMap =
        kafkaSystemAdmin.getSystemStreamMetadata(ImmutableSet.of(INVALID_TOPIC));
    assertEquals(""empty metadata for invalid topic"", metadataMap.size(), 0);
  }
"
"  @Test
  public void testGetSystemStreamMetaDataWithNoTopic() {
    Map<String, SystemStreamMetadata> metadataMap = kafkaSystemAdmin.getSystemStreamMetadata(Collections.emptySet());
    assertEquals(""empty metadata for no topic"", metadataMap.size(), 0);
  }
"
"  @Test
  public void testGetSystemStreamMetaDataForTopicWithNoMessage() {
    // The topic with no messages will have beginningOffset = 0 and endOffset = 0
    when(mockKafkaConsumer.beginningOffsets(ImmutableList.of(testTopicPartition0, testTopicPartition1))).thenReturn(
        ImmutableMap.of(testTopicPartition0, 0L, testTopicPartition1, 0L));
    when(mockKafkaConsumer.endOffsets(ImmutableList.of(testTopicPartition0, testTopicPartition1))).thenReturn(
        ImmutableMap.of(testTopicPartition0, 0L, testTopicPartition1, 0L));

    Map<String, SystemStreamMetadata> metadataMap =
        kafkaSystemAdmin.getSystemStreamMetadata(ImmutableSet.of(VALID_TOPIC));
    assertEquals(""metadata should return for 1 topic"", metadataMap.size(), 1);

    // verify the metadata streamName
    assertEquals(""the stream name should be "" + VALID_TOPIC, metadataMap.get(VALID_TOPIC).getStreamName(), VALID_TOPIC);

    // verify the offset for each partition
    Map<Partition, SystemStreamMetadata.SystemStreamPartitionMetadata> systemStreamPartitionMetadata =
        metadataMap.get(VALID_TOPIC).getSystemStreamPartitionMetadata();
    assertEquals(""there are 2 partitions"", systemStreamPartitionMetadata.size(), 2);

    SystemStreamMetadata.SystemStreamPartitionMetadata partition0Metadata =
        systemStreamPartitionMetadata.get(new Partition(0));
    assertEquals(""oldest offset for partition 0"", partition0Metadata.getOldestOffset(), ""0"");
    assertEquals(""upcoming offset for partition 0"", partition0Metadata.getUpcomingOffset(), ""0"");
    assertEquals(""newest offset is not set due to abnormal upcoming offset"", partition0Metadata.getNewestOffset(),
        null);

    SystemStreamMetadata.SystemStreamPartitionMetadata partition1Metadata =
        systemStreamPartitionMetadata.get(new Partition(1));
    assertEquals(""oldest offset for partition 1"", partition1Metadata.getOldestOffset(), ""0"");
    assertEquals(""upcoming offset for partition 1"", partition1Metadata.getUpcomingOffset(), ""0"");
    assertEquals(""newest offset is not set due to abnormal upcoming offset"", partition1Metadata.getNewestOffset(),
        null);
  }
"
"  @Test
  public void testGetSSPMetadata() {
    SystemStreamPartition ssp = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    SystemStreamPartition otherSSP = new SystemStreamPartition(TEST_SYSTEM, ""otherTopic"", new Partition(1));
    TopicPartition topicPartition = new TopicPartition(VALID_TOPIC, 0);
    TopicPartition otherTopicPartition = new TopicPartition(""otherTopic"", 1);
    when(mockKafkaConsumer.beginningOffsets(ImmutableList.of(topicPartition, otherTopicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 1L, otherTopicPartition, 2L));
    when(mockKafkaConsumer.endOffsets(ImmutableList.of(topicPartition, otherTopicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 11L, otherTopicPartition, 12L));
    Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> expected =
        ImmutableMap.of(ssp, new SystemStreamMetadata.SystemStreamPartitionMetadata(""1"", ""10"", ""11""), otherSSP,
            new SystemStreamMetadata.SystemStreamPartitionMetadata(""2"", ""11"", ""12""));
    assertEquals(kafkaSystemAdmin.getSSPMetadata(ImmutableSet.of(ssp, otherSSP)), expected);
  }
"
"  @Test
  public void testGetSSPMetadataEmptyPartition() {
    SystemStreamPartition ssp = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    SystemStreamPartition otherSSP = new SystemStreamPartition(TEST_SYSTEM, ""otherTopic"", new Partition(1));
    TopicPartition topicPartition = new TopicPartition(VALID_TOPIC, 0);
    TopicPartition otherTopicPartition = new TopicPartition(""otherTopic"", 1);
    when(mockKafkaConsumer.beginningOffsets(ImmutableList.of(topicPartition, otherTopicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 1L));
    when(mockKafkaConsumer.endOffsets(ImmutableList.of(topicPartition, otherTopicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 11L));

    Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> expected =
        ImmutableMap.of(ssp, new SystemStreamMetadata.SystemStreamPartitionMetadata(""1"", ""10"", ""11""), otherSSP,
            new SystemStreamMetadata.SystemStreamPartitionMetadata(null, null, null));
    assertEquals(expected, kafkaSystemAdmin.getSSPMetadata(ImmutableSet.of(ssp, otherSSP)));
  }
"
"  @Test
  public void testGetSSPMetadataEmptyUpcomingOffset() {
    SystemStreamPartition ssp = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    TopicPartition topicPartition = new TopicPartition(VALID_TOPIC, 0);
    when(mockKafkaConsumer.beginningOffsets(ImmutableList.of(topicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 0L));
    when(mockKafkaConsumer.endOffsets(ImmutableList.of(topicPartition))).thenReturn(ImmutableMap.of());
    Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> expected =
        ImmutableMap.of(ssp, new SystemStreamMetadata.SystemStreamPartitionMetadata(""0"", null, null));
    assertEquals(kafkaSystemAdmin.getSSPMetadata(ImmutableSet.of(ssp)), expected);
  }
"
"  @Test
  public void testGetSSPMetadataZeroUpcomingOffset() {
    SystemStreamPartition ssp = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    TopicPartition topicPartition = new TopicPartition(VALID_TOPIC, 0);
    when(mockKafkaConsumer.beginningOffsets(ImmutableList.of(topicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, -1L));
    when(mockKafkaConsumer.endOffsets(ImmutableList.of(topicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 0L));
    Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> expected =
        ImmutableMap.of(ssp, new SystemStreamMetadata.SystemStreamPartitionMetadata(""0"", null, ""0""));
    assertEquals(kafkaSystemAdmin.getSSPMetadata(ImmutableSet.of(ssp)), expected);
  }
"
"  @Test
  public void testGetSystemStreamMetaDataWithRetry() {
    final List<PartitionInfo> partitionInfosForTopic = ImmutableList.of(mockPartitionInfo0, mockPartitionInfo1);
    when(mockKafkaConsumer.partitionsFor(VALID_TOPIC)).thenThrow(new RuntimeException())
        .thenReturn(partitionInfosForTopic);

    Map<String, SystemStreamMetadata> metadataMap =
        kafkaSystemAdmin.getSystemStreamMetadata(ImmutableSet.of(VALID_TOPIC));
    assertEquals(""metadata should return for 1 topic"", metadataMap.size(), 1);

    // retried twice because the first fails and the second succeeds
    Mockito.verify(mockKafkaConsumer, Mockito.times(2)).partitionsFor(VALID_TOPIC);

    final List<TopicPartition> topicPartitions =
        Arrays.asList(new TopicPartition(mockPartitionInfo0.topic(), mockPartitionInfo0.partition()),
            new TopicPartition(mockPartitionInfo1.topic(), mockPartitionInfo1.partition()));
    // the following methods thereafter are only called once
    Mockito.verify(mockKafkaConsumer, Mockito.times(1)).beginningOffsets(topicPartitions);
    Mockito.verify(mockKafkaConsumer, Mockito.times(1)).endOffsets(topicPartitions);
  }
"
"  @Test(expected = SamzaException.class)
  public void testGetSystemStreamMetadataShouldTerminateAfterFiniteRetriesOnException() {
    when(mockKafkaConsumer.partitionsFor(VALID_TOPIC)).thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException());

    kafkaSystemAdmin.getSystemStreamMetadata(ImmutableSet.of(VALID_TOPIC));
  }
"
"  @Test(expected = SamzaException.class)
  public void testGetSystemStreamPartitionCountsShouldTerminateAfterFiniteRetriesOnException() throws Exception {
    final Set<String> streamNames = ImmutableSet.of(VALID_TOPIC);
    final long cacheTTL = 100L;

    when(mockKafkaConsumer.partitionsFor(VALID_TOPIC)).thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException());

    kafkaSystemAdmin.getSystemStreamPartitionCounts(streamNames, cacheTTL);
  }
"
"  @Test
  public void testGetSSPMetadataWithRetry() {
    SystemStreamPartition oneSSP = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    SystemStreamPartition otherSSP = new SystemStreamPartition(TEST_SYSTEM, ""otherTopic"", new Partition(1));
    ImmutableSet<SystemStreamPartition> ssps = ImmutableSet.of(oneSSP, otherSSP);
    List<TopicPartition> topicPartitions = ssps.stream()
        .map(ssp -> new TopicPartition(ssp.getStream(), ssp.getPartition().getPartitionId()))
        .collect(Collectors.toList());
    Map<TopicPartition, Long> testBeginningOffsets =
        ImmutableMap.of(testTopicPartition0, KAFKA_BEGINNING_OFFSET_FOR_PARTITION0, testTopicPartition1,
            KAFKA_BEGINNING_OFFSET_FOR_PARTITION1);

    when(mockKafkaConsumer.beginningOffsets(topicPartitions)).thenThrow(new RuntimeException())
        .thenReturn(testBeginningOffsets);
    Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> sspMetadata =
        kafkaSystemAdmin.getSSPMetadata(ssps, new ExponentialSleepStrategy(2,
            1, 1));

    assertEquals(""metadata should return for 2 topics"", sspMetadata.size(), 2);

    // retried twice because the first fails and the second succeeds
    Mockito.verify(mockKafkaConsumer, Mockito.times(2)).beginningOffsets(topicPartitions);
  }
"
"  @Test(expected = SamzaException.class)
  public void testGetSSPMetadataShouldTerminateAfterFiniteRetriesOnException() throws Exception {
    SystemStreamPartition oneSSP = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    SystemStreamPartition otherSSP = new SystemStreamPartition(TEST_SYSTEM, ""otherTopic"", new Partition(1));

    ImmutableSet<SystemStreamPartition> ssps = ImmutableSet.of(oneSSP, otherSSP);
    List<TopicPartition> topicPartitions = ssps.stream()
        .map(ssp -> new TopicPartition(ssp.getStream(), ssp.getPartition().getPartitionId()))
        .collect(Collectors.toList());

    when(mockKafkaConsumer.beginningOffsets(topicPartitions)).thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException());

    kafkaSystemAdmin.getSSPMetadata(ssps, new ExponentialSleepStrategy(2,
        1, 1));
  }
"
"  @Test
  public void testConfigValidations() {

    final KafkaSystemConsumer consumer = createConsumer(FETCH_THRESHOLD_MSGS, FETCH_THRESHOLD_BYTES);

    consumer.start();
    // should be no failures
  }
"
"  @Test
  public void testFetchThresholdShouldDivideEvenlyAmongPartitions() {
    final KafkaSystemConsumer consumer = createConsumer(FETCH_THRESHOLD_MSGS, FETCH_THRESHOLD_BYTES);
    final int partitionsNum = 50;
    for (int i = 0; i < partitionsNum; i++) {
      consumer.register(new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(i)), ""0"");
    }

    consumer.start();

    Assert.assertEquals(Long.valueOf(FETCH_THRESHOLD_MSGS) / partitionsNum, consumer.perPartitionFetchThreshold);
    Assert.assertEquals(Long.valueOf(FETCH_THRESHOLD_BYTES) / 2 / partitionsNum,
        consumer.perPartitionFetchThresholdBytes);

    consumer.stop();
  }
"
"  @Test
  public void testConsumerRegisterOlderOffsetOfTheSamzaSSP() {

    KafkaSystemConsumer consumer = createConsumer(FETCH_THRESHOLD_MSGS, FETCH_THRESHOLD_BYTES);

    SystemStreamPartition ssp0 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(0));
    SystemStreamPartition ssp1 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(1));
    SystemStreamPartition ssp2 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(2));

    consumer.register(ssp0, ""0"");
    consumer.register(ssp0, ""5"");
    consumer.register(ssp1, ""2"");
    consumer.register(ssp1, ""3"");
    consumer.register(ssp2, ""0"");

    assertEquals(""0"", consumer.topicPartitionsToOffset.get(KafkaSystemConsumer.toTopicPartition(ssp0)));
    assertEquals(""2"", consumer.topicPartitionsToOffset.get(KafkaSystemConsumer.toTopicPartition(ssp1)));
    assertEquals(""0"", consumer.topicPartitionsToOffset.get(KafkaSystemConsumer.toTopicPartition(ssp2)));
  }
"
"  @Test
  public void testFetchThresholdBytes() {

    SystemStreamPartition ssp0 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(0));
    SystemStreamPartition ssp1 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(1));
    int partitionsNum = 2;
    int ime0Size = Integer.valueOf(FETCH_THRESHOLD_MSGS) / partitionsNum; // fake size
    int ime1Size = Integer.valueOf(FETCH_THRESHOLD_MSGS) / partitionsNum - 1; // fake size
    int ime11Size = 20;
    ByteArraySerializer bytesSerde = new ByteArraySerializer();
    IncomingMessageEnvelope ime0 = new IncomingMessageEnvelope(ssp0, ""0"", bytesSerde.serialize("""", ""key0"".getBytes()),
        bytesSerde.serialize("""", ""value0"".getBytes()), ime0Size);
    IncomingMessageEnvelope ime1 = new IncomingMessageEnvelope(ssp1, ""0"", bytesSerde.serialize("""", ""key1"".getBytes()),
        bytesSerde.serialize("""", ""value1"".getBytes()), ime1Size);
    IncomingMessageEnvelope ime11 = new IncomingMessageEnvelope(ssp1, ""0"", bytesSerde.serialize("""", ""key11"".getBytes()),
        bytesSerde.serialize("""", ""value11"".getBytes()), ime11Size);
    KafkaSystemConsumer consumer = createConsumer(FETCH_THRESHOLD_MSGS, FETCH_THRESHOLD_BYTES);

    consumer.register(ssp0, ""0"");
    consumer.register(ssp1, ""0"");
    consumer.start();
    consumer.messageSink.addMessage(ssp0, ime0);
    // queue for ssp0 should be full now, because we added message of size FETCH_THRESHOLD_MSGS/partitionsNum
    Assert.assertFalse(consumer.messageSink.needsMoreMessages(ssp0));
    consumer.messageSink.addMessage(ssp1, ime1);
    // queue for ssp1 should be less then full now, because we added message of size (FETCH_THRESHOLD_MSGS/partitionsNum - 1)
    Assert.assertTrue(consumer.messageSink.needsMoreMessages(ssp1));
    consumer.messageSink.addMessage(ssp1, ime11);
    // queue for ssp1 should full now, because we added message of size 20 on top
    Assert.assertFalse(consumer.messageSink.needsMoreMessages(ssp1));

    Assert.assertEquals(1, consumer.getNumMessagesInQueue(ssp0));
    Assert.assertEquals(2, consumer.getNumMessagesInQueue(ssp1));
    Assert.assertEquals(ime0Size, consumer.getMessagesSizeInQueue(ssp0));
    Assert.assertEquals(ime1Size + ime11Size, consumer.getMessagesSizeInQueue(ssp1));

    consumer.stop();
  }
"
"  @Test
  public void testFetchThresholdBytesDiabled() {
    // Pass 0 as fetchThresholdByBytes, which disables checking for limit by size

    SystemStreamPartition ssp0 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(0));
    SystemStreamPartition ssp1 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(1));
    int partitionsNum = 2;
    int ime0Size = Integer.valueOf(FETCH_THRESHOLD_MSGS) / partitionsNum; // fake size, upto the limit
    int ime1Size = Integer.valueOf(FETCH_THRESHOLD_MSGS) / partitionsNum - 100; // fake size, below the limit
    int ime11Size = 20; // event with the second message still below the size limit
    ByteArraySerializer bytesSerde = new ByteArraySerializer();
    IncomingMessageEnvelope ime0 = new IncomingMessageEnvelope(ssp0, ""0"", bytesSerde.serialize("""", ""key0"".getBytes()),
        bytesSerde.serialize("""", ""value0"".getBytes()), ime0Size);
    IncomingMessageEnvelope ime1 = new IncomingMessageEnvelope(ssp1, ""0"", bytesSerde.serialize("""", ""key1"".getBytes()),
        bytesSerde.serialize("""", ""value1"".getBytes()), ime1Size);
    IncomingMessageEnvelope ime11 = new IncomingMessageEnvelope(ssp1, ""0"", bytesSerde.serialize("""", ""key11"".getBytes()),
        bytesSerde.serialize("""", ""value11"".getBytes()), ime11Size);

    // limit by number of messages 4/2 = 2 per partition
    // limit by number of bytes - disabled
    KafkaSystemConsumer consumer = createConsumer(""4"", ""0""); // should disable

    consumer.register(ssp0, ""0"");
    consumer.register(ssp1, ""0"");
    consumer.start();
    consumer.messageSink.addMessage(ssp0, ime0);
    // should be full by size, but not full by number of messages (1 of 2)
    Assert.assertTrue(consumer.messageSink.needsMoreMessages(ssp0));
    consumer.messageSink.addMessage(ssp1, ime1);
    // not full neither by size nor by messages
    Assert.assertTrue(consumer.messageSink.needsMoreMessages(ssp1));
    consumer.messageSink.addMessage(ssp1, ime11);
    // not full by size, but should be full by messages
    Assert.assertFalse(consumer.messageSink.needsMoreMessages(ssp1));

    Assert.assertEquals(1, consumer.getNumMessagesInQueue(ssp0));
    Assert.assertEquals(2, consumer.getNumMessagesInQueue(ssp1));
    Assert.assertEquals(ime0Size, consumer.getMessagesSizeInQueue(ssp0));
    Assert.assertEquals(ime1Size + ime11Size, consumer.getMessagesSizeInQueue(ssp1));

    consumer.stop();
  }
"
"  @Test
  public void testStartConsumer() {
    final Consumer consumer = Mockito.mock(Consumer.class);
    final KafkaConsumerProxyFactory kafkaConsumerProxyFactory = Mockito.mock(KafkaConsumerProxyFactory.class);

    final KafkaSystemConsumerMetrics kafkaSystemConsumerMetrics = new KafkaSystemConsumerMetrics(TEST_SYSTEM, new NoOpMetricsRegistry());
    final SystemStreamPartition testSystemStreamPartition1 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(0));
    final SystemStreamPartition testSystemStreamPartition2 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(1));
    final String testOffset = ""1"";
    final KafkaConsumerProxy kafkaConsumerProxy = Mockito.mock(KafkaConsumerProxy.class);

    Mockito.when(kafkaConsumerProxyFactory.create(Mockito.anyObject())).thenReturn(kafkaConsumerProxy);
    Mockito.doNothing().when(consumer).seek(new TopicPartition(TEST_STREAM, 0), 1);
    Mockito.doNothing().when(consumer).seek(new TopicPartition(TEST_STREAM, 1), 1);

    KafkaSystemConsumer kafkaSystemConsumer = new KafkaSystemConsumer(consumer, TEST_SYSTEM, new MapConfig(), TEST_CLIENT_ID, kafkaConsumerProxyFactory,
                                                                      kafkaSystemConsumerMetrics, new SystemClock());
    kafkaSystemConsumer.register(testSystemStreamPartition1, testOffset);
    kafkaSystemConsumer.register(testSystemStreamPartition2, testOffset);

    kafkaSystemConsumer.startConsumer();

    Mockito.verify(consumer).seek(new TopicPartition(TEST_STREAM, 0), 1);
    Mockito.verify(consumer).seek(new TopicPartition(TEST_STREAM, 1), 1);
    Mockito.verify(kafkaConsumerProxy).start();
    Mockito.verify(kafkaConsumerProxy).addTopicPartition(testSystemStreamPartition1, Long.valueOf(testOffset));
    Mockito.verify(kafkaConsumerProxy).addTopicPartition(testSystemStreamPartition2, Long.valueOf(testOffset));
  }
"
"  @Test
  public void testCreateStreamShouldCoordinatorStreamWithCorrectTopicProperties() throws Exception {
    String coordinatorTopicName = String.format(""topic-name-%s"", RandomStringUtils.randomAlphabetic(5));
    StreamSpec coordinatorStreamSpec = KafkaStreamSpec.createCoordinatorStreamSpec(coordinatorTopicName, SYSTEM());

    boolean hasCreatedStream = systemAdmin().createStream(coordinatorStreamSpec);

    assertTrue(hasCreatedStream);

    Map<String, String> coordinatorTopicProperties = getTopicConfigFromKafkaBroker(coordinatorTopicName);

    assertEquals(""compact"", coordinatorTopicProperties.get(TopicConfig.CLEANUP_POLICY_CONFIG));
    assertEquals(""26214400"", coordinatorTopicProperties.get(TopicConfig.SEGMENT_BYTES_CONFIG));
    assertEquals(""86400000"", coordinatorTopicProperties.get(TopicConfig.DELETE_RETENTION_MS_CONFIG));
  }
"
"  @Test
  public void testGetOffsetsAfter() {
    SystemStreamPartition ssp1 = new SystemStreamPartition(SYSTEM, TOPIC, new Partition(0));
    SystemStreamPartition ssp2 = new SystemStreamPartition(SYSTEM, TOPIC, new Partition(1));
    Map<SystemStreamPartition, String> offsets = new HashMap<>();
    offsets.put(ssp1, ""1"");
    offsets.put(ssp2, ""2"");

    offsets = systemAdmin().getOffsetsAfter(offsets);

    Assert.assertEquals(""2"", offsets.get(ssp1));
    Assert.assertEquals(""3"", offsets.get(ssp2));
  }
"
"  @Test
  public void testToKafkaSpecForCheckpointStreamShouldReturnTheCorrectStreamSpecByPreservingTheConfig() {
    String topicName = ""testStream"";
    String streamId = ""samza-internal-checkpoint-stream-id"";
    int partitionCount = 1;
    Map<String, String> map = new HashMap<>();
    map.put(""cleanup.policy"", ""compact"");
    map.put(""replication.factor"", ""3"");
    map.put(""segment.bytes"", ""536870912"");
    map.put(""delete.retention.ms"", ""86400000"");

    Config config = new MapConfig(map);

    StreamSpec spec = new StreamSpec(streamId, topicName, SYSTEM, partitionCount, config);
    KafkaSystemAdmin kafkaSystemAdmin = systemAdmin();
    KafkaStreamSpec kafkaStreamSpec = kafkaSystemAdmin.toKafkaSpec(spec);
    System.out.println(kafkaStreamSpec);
    assertEquals(streamId, kafkaStreamSpec.getId());
    assertEquals(topicName, kafkaStreamSpec.getPhysicalName());
    assertEquals(partitionCount, kafkaStreamSpec.getPartitionCount());
    assertEquals(3, kafkaStreamSpec.getReplicationFactor());
    assertEquals(""compact"", kafkaStreamSpec.getConfig().get(""cleanup.policy""));
    assertEquals(""536870912"", kafkaStreamSpec.getConfig().get(""segment.bytes""));
    assertEquals(""86400000"", kafkaStreamSpec.getConfig().get(""delete.retention.ms""));
  }
"
"  @Test
  public void testToKafkaSpec() {
    String topicName = ""testStream"";

    int defaultPartitionCount = 2;
    int changeLogPartitionFactor = 5;
    Map<String, String> map = new HashMap<>();
    Config config = new MapConfig(map);
    StreamSpec spec = new StreamSpec(""id"", topicName, SYSTEM, defaultPartitionCount, config);

    KafkaSystemAdmin kafkaAdmin = systemAdmin();
    KafkaStreamSpec kafkaSpec = kafkaAdmin.toKafkaSpec(spec);

    Assert.assertEquals(""id"", kafkaSpec.getId());
    Assert.assertEquals(topicName, kafkaSpec.getPhysicalName());
    Assert.assertEquals(SYSTEM, kafkaSpec.getSystemName());
    Assert.assertEquals(defaultPartitionCount, kafkaSpec.getPartitionCount());

    // validate that conversion is using coordination metadata
    map.put(""job.coordinator.segment.bytes"", ""123"");
    map.put(""job.coordinator.cleanup.policy"", ""superCompact"");
    int coordReplicatonFactor = 4;
    map.put(org.apache.samza.config.KafkaConfig.JOB_COORDINATOR_REPLICATION_FACTOR(),
        String.valueOf(coordReplicatonFactor));

    KafkaSystemAdmin admin = Mockito.spy(createSystemAdmin(SYSTEM, map));
    spec = StreamSpec.createCoordinatorStreamSpec(topicName, SYSTEM);
    kafkaSpec = admin.toKafkaSpec(spec);
    Assert.assertEquals(coordReplicatonFactor, kafkaSpec.getReplicationFactor());
    Assert.assertEquals(""123"", kafkaSpec.getProperties().getProperty(""segment.bytes""));
    // cleanup policy is overridden in the KafkaAdmin
    Assert.assertEquals(""compact"", kafkaSpec.getProperties().getProperty(""cleanup.policy""));

    // validate that conversion is using changeLog metadata
    map = new HashMap<>();
    map.put(JobConfig.JOB_DEFAULT_SYSTEM, SYSTEM);

    map.put(String.format(""stores.%s.changelog"", ""fakeStore""), topicName);
    int changeLogReplicationFactor = 3;
    map.put(String.format(""stores.%s.changelog.replication.factor"", ""fakeStore""),
        String.valueOf(changeLogReplicationFactor));
    admin = Mockito.spy(createSystemAdmin(SYSTEM, map));
    spec = StreamSpec.createChangeLogStreamSpec(topicName, SYSTEM, changeLogPartitionFactor);
    kafkaSpec = admin.toKafkaSpec(spec);
    Assert.assertEquals(changeLogReplicationFactor, kafkaSpec.getReplicationFactor());

    // same, but with missing topic info
    try {
      admin = Mockito.spy(createSystemAdmin(SYSTEM, map));
      spec = StreamSpec.createChangeLogStreamSpec(""anotherTopic"", SYSTEM, changeLogPartitionFactor);
      kafkaSpec = admin.toKafkaSpec(spec);
      Assert.fail(""toKafkaSpec should've failed for missing topic"");
    } catch (StreamValidationException e) {
      // expected
    }

    // validate that conversion is using intermediate streams properties
    String interStreamId = ""isId"";

    Map<String, String> interStreamMap = new HashMap<>();
    interStreamMap.put(""app.mode"", ApplicationConfig.ApplicationMode.BATCH.toString());
    interStreamMap.put(String.format(""streams.%s.samza.intermediate"", interStreamId), ""true"");
    interStreamMap.put(String.format(""streams.%s.samza.system"", interStreamId), ""testSystem"");
    interStreamMap.put(String.format(""streams.%s.p1"", interStreamId), ""v1"");
    interStreamMap.put(String.format(""streams.%s.retention.ms"", interStreamId), ""123"");
    // legacy format
    interStreamMap.put(String.format(""systems.%s.streams.%s.p2"", ""testSystem"", interStreamId), ""v2"");

    admin = Mockito.spy(createSystemAdmin(SYSTEM, interStreamMap));
    spec = new StreamSpec(interStreamId, topicName, SYSTEM, defaultPartitionCount, config);
    kafkaSpec = admin.toKafkaSpec(spec);
    Assert.assertEquals(""v1"", kafkaSpec.getProperties().getProperty(""p1""));
    Assert.assertEquals(""v2"", kafkaSpec.getProperties().getProperty(""p2""));
    Assert.assertEquals(""123"", kafkaSpec.getProperties().getProperty(""retention.ms""));
    Assert.assertEquals(defaultPartitionCount, kafkaSpec.getPartitionCount());
  }
"
"  @Test
  public void testCreateCoordinatorStream() {
    SystemAdmin admin = Mockito.spy(systemAdmin());
    StreamSpec spec = StreamSpec.createCoordinatorStreamSpec(""testCoordinatorStream"", ""testSystem"");

    admin.createStream(spec);
    admin.validateStream(spec);
    Mockito.verify(admin).createStream(Mockito.any());
  }
"
"  @Test
  public void testCreateCoordinatorStreamWithSpecialCharsInTopicName() {
    final String stream = ""test.coordinator_test.Stream"";

    Map<String, String> map = new HashMap<>();
    map.put(""job.coordinator.segment.bytes"", ""123"");
    map.put(""job.coordinator.cleanup.policy"", ""compact"");
    int coordReplicatonFactor = 2;
    map.put(org.apache.samza.config.KafkaConfig.JOB_COORDINATOR_REPLICATION_FACTOR(),
        String.valueOf(coordReplicatonFactor));

    KafkaSystemAdmin admin = Mockito.spy(createSystemAdmin(SYSTEM, map));
    StreamSpec spec = StreamSpec.createCoordinatorStreamSpec(stream, SYSTEM);

    Mockito.doAnswer(invocationOnMock -> {
      StreamSpec internalSpec = (StreamSpec) invocationOnMock.callRealMethod();
      assertTrue(internalSpec instanceof KafkaStreamSpec);  // KafkaStreamSpec is used to carry replication factor
      assertTrue(internalSpec.isCoordinatorStream());
      assertEquals(SYSTEM, internalSpec.getSystemName());
      assertEquals(stream, internalSpec.getPhysicalName());
      assertEquals(1, internalSpec.getPartitionCount());
      Assert.assertEquals(coordReplicatonFactor, ((KafkaStreamSpec) internalSpec).getReplicationFactor());
      Assert.assertEquals(""123"", ((KafkaStreamSpec) internalSpec).getProperties().getProperty(""segment.bytes""));
      // cleanup policy is overridden in the KafkaAdmin
      Assert.assertEquals(""compact"", ((KafkaStreamSpec) internalSpec).getProperties().getProperty(""cleanup.policy""));

      return internalSpec;
    }).when(admin).toKafkaSpec(Mockito.any());

    admin.createStream(spec);
    admin.validateStream(spec);
  }
"
"  @Test
  public void testCreateChangelogStreamHelp() {
    testCreateChangelogStreamHelp(""testChangeLogStream"");
  }
"
"  @Test
  public void testCreateChangelogStreamWithSpecialCharsInTopicName() {
    // cannot contain period
    testCreateChangelogStreamHelp(""test-Change_Log-Stream"");
  }
"
"  @Test
  public void testCreateStream() {
    StreamSpec spec = new StreamSpec(""testId"", ""testStream"", ""testSystem"", 8);
    KafkaSystemAdmin admin = systemAdmin();
    assertTrue(""createStream should return true if the stream does not exist and then is created."",
        admin.createStream(spec));
    admin.validateStream(spec);

    assertFalse(""createStream should return false if the stream already exists."", systemAdmin().createStream(spec));
  }
"
"  @Test(expected = StreamValidationException.class)
  public void testValidateStreamDoesNotExist() {

    StreamSpec spec = new StreamSpec(""testId"", ""testStreamNameExist"", ""testSystem"", 8);

    systemAdmin().validateStream(spec);
  }
"
"  @Test(expected = StreamValidationException.class)
  public void testValidateStreamWrongPartitionCount() {
    StreamSpec spec1 = new StreamSpec(""testId"", ""testStreamPartition"", ""testSystem"", 8);
    StreamSpec spec2 = new StreamSpec(""testId"", ""testStreamPartition"", ""testSystem"", 4);

    assertTrue(""createStream should return true if the stream does not exist and then is created."",
        systemAdmin().createStream(spec1));

    systemAdmin().validateStream(spec2);
  }
"
"  @Test(expected = StreamValidationException.class)
  public void testValidateStreamWrongName() {
    StreamSpec spec1 = new StreamSpec(""testId"", ""testStreamName1"", ""testSystem"", 8);
    StreamSpec spec2 = new StreamSpec(""testId"", ""testStreamName2"", ""testSystem"", 8);

    assertTrue(""createStream should return true if the stream does not exist and then is created."",
        systemAdmin().createStream(spec1));

    systemAdmin().validateStream(spec2);
  }
"
"  @Test
  public void testClearStream() {
    StreamSpec spec = new StreamSpec(""testId"", ""testStreamClear"", ""testSystem"", 8);

    KafkaSystemAdmin admin = systemAdmin();
    String topicName = spec.getPhysicalName();

    assertTrue(""createStream should return true if the stream does not exist and then is created."", admin.createStream(spec));
    // validate topic exists
    assertTrue(admin.clearStream(spec));

    // validate that topic was removed
    DescribeTopicsResult dtr = admin.adminClient.describeTopics(ImmutableSet.of(topicName));
    try {
      TopicDescription td = dtr.all().get().get(topicName);
      Assert.fail(""topic "" + topicName + "" should've been removed. td="" + td);
    } catch (Exception e) {
      if (!(e.getCause() instanceof org.apache.kafka.common.errors.UnknownTopicOrPartitionException)) {
        Assert.fail(""topic "" + topicName + "" should've been removed. Expected UnknownTopicOrPartitionException."");
      }
    }
  }
"
"  @Test
  public void testShouldAssembleMetadata() {
    Map<SystemStreamPartition, String> oldestOffsets = new ImmutableMap.Builder<SystemStreamPartition, String>()
        .put(new SystemStreamPartition(SYSTEM, ""stream1"", new Partition(0)), ""o1"")
        .put(new SystemStreamPartition(SYSTEM, ""stream2"", new Partition(0)), ""o2"")
        .put(new SystemStreamPartition(SYSTEM, ""stream1"", new Partition(1)), ""o3"")
        .put(new SystemStreamPartition(SYSTEM, ""stream2"", new Partition(1)), ""o4"")
        .build();

    Map<SystemStreamPartition, String> newestOffsets = new ImmutableMap.Builder<SystemStreamPartition, String>()
        .put(new SystemStreamPartition(SYSTEM, ""stream1"", new Partition(0)), ""n1"")
        .put(new SystemStreamPartition(SYSTEM, ""stream2"", new Partition(0)), ""n2"")
        .put(new SystemStreamPartition(SYSTEM, ""stream1"", new Partition(1)), ""n3"")
        .put(new SystemStreamPartition(SYSTEM, ""stream2"", new Partition(1)), ""n4"")
        .build();

    Map<SystemStreamPartition, String> upcomingOffsets = new ImmutableMap.Builder<SystemStreamPartition, String>()
        .put(new SystemStreamPartition(SYSTEM, ""stream1"", new Partition(0)), ""u1"")
        .put(new SystemStreamPartition(SYSTEM, ""stream2"", new Partition(0)), ""u2"")
        .put(new SystemStreamPartition(SYSTEM, ""stream1"", new Partition(1)), ""u3"")
        .put(new SystemStreamPartition(SYSTEM, ""stream2"", new Partition(1)), ""u4"")
        .build();

    Map<String, SystemStreamMetadata> metadata = assembleMetadata(oldestOffsets, newestOffsets, upcomingOffsets);
    assertNotNull(metadata);
    assertEquals(2, metadata.size());
    assertTrue(metadata.containsKey(""stream1""));
    assertTrue(metadata.containsKey(""stream2""));
    SystemStreamMetadata stream1Metadata = metadata.get(""stream1"");
    SystemStreamMetadata stream2Metadata = metadata.get(""stream2"");
    assertNotNull(stream1Metadata);
    assertNotNull(stream2Metadata);
    assertEquals(""stream1"", stream1Metadata.getStreamName());
    assertEquals(""stream2"", stream2Metadata.getStreamName());
    SystemStreamMetadata.SystemStreamPartitionMetadata expectedSystemStream1Partition0Metadata =
        new SystemStreamMetadata.SystemStreamPartitionMetadata(""o1"", ""n1"", ""u1"");
    SystemStreamMetadata.SystemStreamPartitionMetadata expectedSystemStream1Partition1Metadata =
        new SystemStreamMetadata.SystemStreamPartitionMetadata(""o3"", ""n3"", ""u3"");
    SystemStreamMetadata.SystemStreamPartitionMetadata expectedSystemStream2Partition0Metadata =
        new SystemStreamMetadata.SystemStreamPartitionMetadata(""o2"", ""n2"", ""u2"");
    SystemStreamMetadata.SystemStreamPartitionMetadata expectedSystemStream2Partition1Metadata =
        new SystemStreamMetadata.SystemStreamPartitionMetadata(""o4"", ""n4"", ""u4"");
    Map<Partition, SystemStreamMetadata.SystemStreamPartitionMetadata> stream1PartitionMetadata =
        stream1Metadata.getSystemStreamPartitionMetadata();
    Map<Partition, SystemStreamMetadata.SystemStreamPartitionMetadata> stream2PartitionMetadata =
        stream2Metadata.getSystemStreamPartitionMetadata();
    assertEquals(expectedSystemStream1Partition0Metadata, stream1PartitionMetadata.get(new Partition(0)));
    assertEquals(expectedSystemStream1Partition1Metadata, stream1PartitionMetadata.get(new Partition(1)));
    assertEquals(expectedSystemStream2Partition0Metadata, stream2PartitionMetadata.get(new Partition(0)));
    assertEquals(expectedSystemStream2Partition1Metadata, stream2PartitionMetadata.get(new Partition(1)));
  }
"
"  @Test
  public void testStartpointSpecificOffsetVisitorShouldResolveToCorrectOffset() {
    final KafkaConsumer consumer = Mockito.mock(KafkaConsumer.class);
    final KafkaStartpointToOffsetResolver kafkaStartpointToOffsetResolver = new KafkaStartpointToOffsetResolver(consumer);

    final StartpointSpecific testStartpointSpecific = new StartpointSpecific(TEST_OFFSET);

    // Invoke the consumer with startpoint.
    String resolvedOffset = kafkaStartpointToOffsetResolver.visit(TEST_SYSTEM_STREAM_PARTITION, testStartpointSpecific);
    Assert.assertEquals(TEST_OFFSET, resolvedOffset);
  }
"
"  @Test
  public void testStartpointTimestampVisitorShouldResolveToCorrectOffset() {
    // Define dummy variables for testing.
    final Long testTimeStamp = 10L;

    final KafkaConsumer consumer = Mockito.mock(KafkaConsumer.class);

    final KafkaStartpointToOffsetResolver kafkaStartpointToOffsetResolver = new KafkaStartpointToOffsetResolver(consumer);

    final StartpointTimestamp startpointTimestamp = new StartpointTimestamp(testTimeStamp);
    final Map<TopicPartition, OffsetAndTimestamp> offsetForTimesResult = ImmutableMap.of(
        TEST_TOPIC_PARTITION, new OffsetAndTimestamp(Long.valueOf(TEST_OFFSET), testTimeStamp));

    // Mock the consumer interactions.
    Mockito.when(consumer.offsetsForTimes(ImmutableMap.of(TEST_TOPIC_PARTITION, testTimeStamp))).thenReturn(offsetForTimesResult);
    Mockito.when(consumer.position(TEST_TOPIC_PARTITION)).thenReturn(Long.valueOf(TEST_OFFSET));

    String resolvedOffset = kafkaStartpointToOffsetResolver.visit(TEST_SYSTEM_STREAM_PARTITION, startpointTimestamp);
    Assert.assertEquals(TEST_OFFSET, resolvedOffset);
  }
"
"  @Test
  public void testStartpointTimestampVisitorShouldResolveToCorrectOffsetWhenTimestampDoesNotExist() {
    final KafkaConsumer consumer = Mockito.mock(KafkaConsumer.class);
    final KafkaStartpointToOffsetResolver kafkaStartpointToOffsetResolver = new KafkaStartpointToOffsetResolver(consumer);

    final StartpointTimestamp startpointTimestamp = new StartpointTimestamp(0L);
    final Map<TopicPartition, OffsetAndTimestamp> offsetForTimesResult = new HashMap<>();
    offsetForTimesResult.put(TEST_TOPIC_PARTITION, null);

    // Mock the consumer interactions.
    Mockito.when(consumer.offsetsForTimes(ImmutableMap.of(TEST_TOPIC_PARTITION, 0L))).thenReturn(offsetForTimesResult);
    Mockito.when(consumer.endOffsets(ImmutableSet.of(TEST_TOPIC_PARTITION))).thenReturn(ImmutableMap.of(TEST_TOPIC_PARTITION, 10L));

    String resolvedOffset = kafkaStartpointToOffsetResolver.visit(TEST_SYSTEM_STREAM_PARTITION, startpointTimestamp);
    Assert.assertEquals(TEST_OFFSET, resolvedOffset);

    // Mock verifications.
    Mockito.verify(consumer).offsetsForTimes(ImmutableMap.of(TEST_TOPIC_PARTITION, 0L));
  }
"
"  @Test
  public void testStartpointOldestVisitorShouldResolveToCorrectOffset() {
    // Define dummy variables for testing.
    final KafkaConsumer consumer = Mockito.mock(KafkaConsumer.class);
    final KafkaStartpointToOffsetResolver kafkaStartpointToOffsetResolver = new KafkaStartpointToOffsetResolver(consumer);

    final StartpointOldest testStartpointSpecific = new StartpointOldest();

    // Mock the consumer interactions.
    Mockito.when(consumer.beginningOffsets(ImmutableSet.of(TEST_TOPIC_PARTITION))).thenReturn(ImmutableMap.of(TEST_TOPIC_PARTITION, 10L));

    // Invoke the consumer with startpoint.
    String resolvedOffset = kafkaStartpointToOffsetResolver.visit(TEST_SYSTEM_STREAM_PARTITION, testStartpointSpecific);
    Assert.assertEquals(TEST_OFFSET, resolvedOffset);
  }
"
"  @Test
  public void testStartpointUpcomingVisitorShouldResolveToCorrectOffset() {
    // Define dummy variables for testing.
    final KafkaConsumer consumer = Mockito.mock(KafkaConsumer.class);

    final KafkaStartpointToOffsetResolver kafkaStartpointToOffsetResolver = new KafkaStartpointToOffsetResolver(consumer);

    final StartpointUpcoming testStartpointSpecific = new StartpointUpcoming();

    // Mock the consumer interactions.
    Mockito.when(consumer.endOffsets(ImmutableSet.of(TEST_TOPIC_PARTITION))).thenReturn(ImmutableMap.of(TEST_TOPIC_PARTITION, 10L));

    // Invoke the consumer with startpoint.
    String resolvedOffset = kafkaStartpointToOffsetResolver.visit(TEST_SYSTEM_STREAM_PARTITION, testStartpointSpecific);
    Assert.assertEquals(TEST_OFFSET, resolvedOffset);
  }
"
"  @Test
  public void testUnsupportedConfigStrippedFromProperties() {
    StreamSpec original = new StreamSpec(""dummyId"", ""dummyPhysicalName"", ""dummySystemName"",
        ImmutableMap.of(""segment.bytes"", ""4"", ""replication.factor"", ""7""));

    // First verify the original
    assertEquals(""7"", original.get(""replication.factor""));
    assertEquals(""4"", original.get(""segment.bytes""));

    Map<String, String> config = original.getConfig();
    assertEquals(""7"", config.get(""replication.factor""));
    assertEquals(""4"", config.get(""segment.bytes""));


    // Now verify the Kafka spec
    KafkaStreamSpec spec = KafkaStreamSpec.fromSpec(original);
    assertNull(spec.get(""replication.factor""));
    assertEquals(""4"", spec.get(""segment.bytes""));

    Properties kafkaProperties = spec.getProperties();
    Map<String, String> kafkaConfig = spec.getConfig();
    assertNull(kafkaProperties.get(""replication.factor""));
    assertEquals(""4"", kafkaProperties.get(""segment.bytes""));

    assertNull(kafkaConfig.get(""replication.factor""));
    assertEquals(""4"", kafkaConfig.get(""segment.bytes""));
  }
"
"  @Test(expected = IllegalArgumentException.class)
  public void testInvalidPartitionCount() {
    new KafkaStreamSpec(""dummyId"", ""dummyPhysicalName"", ""dummySystemName"", 0);
  }
"
"  @Test
  public void testInstantiateProducer() {
    KafkaSystemProducer ksp = new KafkaSystemProducer(""SysName"", new ExponentialSleepStrategy(2.0, 200, 10000),
      new AbstractFunction0<Producer<byte[], byte[]>>() {
        @Override
        public Producer<byte[], byte[]> apply() {
          return new KafkaProducer<>(new HashMap<String, Object>());
        }
      }, new KafkaSystemProducerMetrics(""SysName"", new MetricsRegistryMap()), new AbstractFunction0<Object>() {
        @Override
        public Object apply() {
          return System.currentTimeMillis();
        }
"
"  @Test
  public void testISDConfigsWithOverrides() {
    KafkaSystemDescriptor sd = new KafkaSystemDescriptor(""kafka"");

    KafkaInputDescriptor<KV<String, Integer>> isd =
        sd.getInputDescriptor(""input-stream"", KVSerde.of(new StringSerde(), new IntegerSerde()))
            .withConsumerAutoOffsetReset(""largest"")
            .withConsumerFetchMessageMaxBytes(1024 * 1024);

    Map<String, String> generatedConfigs = isd.toConfig();
    assertEquals(""kafka"", generatedConfigs.get(""streams.input-stream.samza.system""));
    assertEquals(""largest"", generatedConfigs.get(""systems.kafka.streams.input-stream.consumer.auto.offset.reset""));
    assertEquals(""1048576"", generatedConfigs.get(""systems.kafka.streams.input-stream.consumer.fetch.message.max.bytes""));
  }
"
"  @Test
  public void testISDConfigsWithDefaults() {
    KafkaSystemDescriptor sd = new KafkaSystemDescriptor(""kafka"")
        .withConsumerZkConnect(ImmutableList.of(""localhost:123""))
        .withProducerBootstrapServers(ImmutableList.of(""localhost:567"", ""localhost:890""));

    KafkaInputDescriptor<KV<String, Integer>> isd =
        sd.getInputDescriptor(""input-stream"", KVSerde.of(new StringSerde(), new IntegerSerde()));

    Map<String, String> generatedConfigs = isd.toConfig();
    assertEquals(""kafka"", generatedConfigs.get(""streams.input-stream.samza.system""));
    assertEquals(1, generatedConfigs.size()); // verify that there are no other configs
  }
"
"  @Test
  public void testSDConfigsWithOverrides() {
    KafkaSystemDescriptor sd =
        new KafkaSystemDescriptor(""kafka"")
            .withConsumerZkConnect(ImmutableList.of(""localhost:1234""))
            .withProducerBootstrapServers(ImmutableList.of(""localhost:567"", ""localhost:890""))
            .withDefaultStreamOffsetDefault(SystemStreamMetadata.OffsetType.OLDEST)
            .withConsumerAutoOffsetReset(""smallest"")
            .withConsumerFetchMessageMaxBytes(1024 * 1024)
            .withSamzaFetchThreshold(10000)
            .withSamzaFetchThresholdBytes(1024 * 1024)
            .withConsumerConfigs(ImmutableMap.of(""custom-consumer-config-key"", ""custom-consumer-config-value""))
            .withProducerConfigs(ImmutableMap.of(""custom-producer-config-key"", ""custom-producer-config-value""))
            .withDefaultStreamConfigs(ImmutableMap.of(""custom-stream-config-key"", ""custom-stream-config-value""));

    Map<String, String> generatedConfigs = sd.toConfig();
    assertEquals(""org.apache.samza.system.kafka.KafkaSystemFactory"", generatedConfigs.get(""systems.kafka.samza.factory""));
    assertEquals(""localhost:1234"", generatedConfigs.get(""systems.kafka.consumer.zookeeper.connect""));
    assertEquals(""localhost:567,localhost:890"", generatedConfigs.get(""systems.kafka.producer.bootstrap.servers""));
    assertEquals(""smallest"", generatedConfigs.get(""systems.kafka.consumer.auto.offset.reset""));
    assertEquals(""1048576"", generatedConfigs.get(""systems.kafka.consumer.fetch.message.max.bytes""));
    assertEquals(""10000"", generatedConfigs.get(""systems.kafka.samza.fetch.threshold""));
    assertEquals(""1048576"", generatedConfigs.get(""systems.kafka.samza.fetch.threshold.bytes""));
    assertEquals(""custom-consumer-config-value"", generatedConfigs.get(""systems.kafka.consumer.custom-consumer-config-key""));
    assertEquals(""custom-producer-config-value"", generatedConfigs.get(""systems.kafka.producer.custom-producer-config-key""));
    assertEquals(""custom-stream-config-value"", generatedConfigs.get(""systems.kafka.default.stream.custom-stream-config-key""));
    assertEquals(""oldest"", generatedConfigs.get(""systems.kafka.default.stream.samza.offset.default""));
    assertEquals(11, generatedConfigs.size());
  }
"
"  @Test
  public void testSDConfigsWithoutOverrides() {
    KafkaSystemDescriptor sd = new KafkaSystemDescriptor(""kafka"");

    Map<String, String> generatedConfigs = sd.toConfig();
    assertEquals(""org.apache.samza.system.kafka.KafkaSystemFactory"", generatedConfigs.get(""systems.kafka.samza.factory""));
    assertEquals(1, generatedConfigs.size()); // verify that there are no other configs
  }
"
"  @Test
  public void testGetIntermediateStreamProperties() {
    Map<String, String> config = new HashMap<>();
    KafkaSystemFactory factory = new KafkaSystemFactory();
    Map<String, Properties> properties = JavaConversions.mapAsJavaMap(
        factory.getIntermediateStreamProperties(new MapConfig(config)));
    assertTrue(properties.isEmpty());

    // no properties for stream
    config.put(""streams.test.samza.intermediate"", ""true"");
    config.put(""streams.test.compression.type"", ""lz4""); //some random config
    properties = JavaConversions.mapAsJavaMap(
        factory.getIntermediateStreamProperties(new MapConfig(config)));
    assertTrue(properties.isEmpty());

    config.put(ApplicationConfig.APP_MODE, ApplicationConfig.ApplicationMode.BATCH.name());

    KafkaSystemAdmin admin = createSystemAdmin(SYSTEM(), config);
    StreamSpec spec = new StreamSpec(""test"", ""test"", SYSTEM(),
        Collections.singletonMap(""replication.factor"", ""1""));
    KafkaStreamSpec kspec = admin.toKafkaSpec(spec);

    Properties prop = kspec.getProperties();
    assertEquals(prop.getProperty(""retention.ms""), String.valueOf(KafkaConfig.DEFAULT_RETENTION_MS_FOR_BATCH()));
    assertEquals(prop.getProperty(""compression.type""), ""lz4"");

    // replication.factor should be removed from the properties and set on the spec directly
    assertEquals(kspec.getReplicationFactor(), 1);
    assertNull(prop.getProperty(""replication.factor""));
  }
"
"  @Test
  public void testGetCheckpointTopicProperties() {
    Map<String, String> config = new HashMap<>();
    Properties properties = new KafkaConfig(new MapConfig(config)).getCheckpointTopicProperties();

    assertEquals(properties.getProperty(""cleanup.policy""), ""compact"");
    assertEquals(properties.getProperty(""segment.bytes""), String.valueOf(KafkaConfig.DEFAULT_CHECKPOINT_SEGMENT_BYTES()));

    config.put(ApplicationConfig.APP_MODE, ApplicationConfig.ApplicationMode.BATCH.name());
    properties = new KafkaConfig(new MapConfig(config)).getCheckpointTopicProperties();

    assertEquals(properties.getProperty(""cleanup.policy""), ""compact,delete"");
    assertEquals(properties.getProperty(""segment.bytes""), String.valueOf(KafkaConfig.DEFAULT_CHECKPOINT_SEGMENT_BYTES()));
    assertEquals(properties.getProperty(""retention.ms""), String.valueOf(KafkaConfig.DEFAULT_RETENTION_MS_FOR_BATCH()));
  }
"
"  @Test
  public void testBinaryCompatibility() {
    KafkaCheckpointLogKey logKey1 = new KafkaCheckpointLogKey(KafkaCheckpointLogKey.CHECKPOINT_V1_KEY_TYPE,
        new TaskName(""Partition 0""), GroupByPartitionFactory.class.getCanonicalName());
    KafkaCheckpointLogKeySerde checkpointSerde = new KafkaCheckpointLogKeySerde();

    byte[] bytes = (""{\""systemstreampartition-grouper-factory\"""" +
        "":\""org.apache.samza.container.grouper.stream.GroupByPartitionFactory\"",\""taskName\"":\""Partition 0\"","" +
        ""\""type\"":\""checkpoint\""}"").getBytes();

    // test that the checkpoints returned by the Serde are byte-wise identical to an actual checkpoint in Kafka
    Assert.assertEquals(true, Arrays.equals(bytes, checkpointSerde.toBytes(logKey1)));
  }
"
"  @Test
  public void testSerde() {
    KafkaCheckpointLogKey key = new KafkaCheckpointLogKey(KafkaCheckpointLogKey.CHECKPOINT_V1_KEY_TYPE,
        new TaskName(""Partition 0""), GroupByPartitionFactory.class.getCanonicalName());
    KafkaCheckpointLogKeySerde checkpointSerde = new KafkaCheckpointLogKeySerde();

    // test that deserialize(serialize(k)) == k
    Assert.assertEquals(key, checkpointSerde.fromBytes(checkpointSerde.toBytes(key)));
  }
"
"  @Test
  public void testCheckpointTypeV2() {
    KafkaCheckpointLogKey keyV2 = new KafkaCheckpointLogKey(KafkaCheckpointLogKey.CHECKPOINT_V2_KEY_TYPE, new TaskName(""Partition 0""),
        GroupByPartitionFactory.class.getCanonicalName());
    KafkaCheckpointLogKeySerde checkpointKeySerde = new KafkaCheckpointLogKeySerde();

    // test that deserialize(serialize(k)) == k
    Assert.assertEquals(keyV2, checkpointKeySerde.fromBytes(checkpointKeySerde.toBytes(keyV2)));
  }
"
"  @Test
  public void testForwardsCompatibility() {
    // Set the key to another value, this is for the future if we want to support multiple checkpoint keys
    // we do not want to throw in the Serdes layer, but must be validated in the CheckpointManager
    KafkaCheckpointLogKey key = new KafkaCheckpointLogKey(""checkpoint-v2"",
        new TaskName(""Partition 0""), GroupByPartitionFactory.class.getCanonicalName());
    KafkaCheckpointLogKeySerde checkpointSerde = new KafkaCheckpointLogKeySerde();

    // test that deserialize(serialize(k)) == k
    Assert.assertEquals(key, checkpointSerde.fromBytes(checkpointSerde.toBytes(key)));
  }
"
"  @Test(expected = TopicAlreadyMarkedForDeletionException.class)
  public void testCreateResourcesTopicCreationError() {
    setupSystemFactory(config());
    // throw an exception during createStream
    doThrow(new TopicAlreadyMarkedForDeletionException(""invalid stream"")).when(this.createResourcesSystemAdmin)
        .createStream(CHECKPOINT_SPEC);
    KafkaCheckpointManager checkpointManager = buildKafkaCheckpointManager(true, config());
    // expect an exception during startup
    checkpointManager.createResources();
  }
"
"  @Test(expected = StreamValidationException.class)
  public void testCreateResourcesTopicValidationError() {
    setupSystemFactory(config());
    // throw an exception during validateStream
    doThrow(new StreamValidationException(""invalid stream"")).when(this.createResourcesSystemAdmin)
        .validateStream(CHECKPOINT_SPEC);
    KafkaCheckpointManager checkpointManager = buildKafkaCheckpointManager(true, config());
    // expect an exception during startup
    checkpointManager.createResources();
  }
"
"  @Test(expected = SamzaException.class)
  public void testReadFailsOnSerdeExceptions() throws InterruptedException {
    setupSystemFactory(config());
    List<IncomingMessageEnvelope> checkpointEnvelopes =
        ImmutableList.of(newCheckpointV1Envelope(TASK0, buildCheckpointV1(INPUT_SSP0, ""0""), ""0""));
    setupConsumer(checkpointEnvelopes);
    // wire up an exception throwing serde with the checkpointManager
    CheckpointV1Serde checkpointV1Serde = mock(CheckpointV1Serde.class);
    doThrow(new RuntimeException(""serde failed"")).when(checkpointV1Serde).fromBytes(any());
    KafkaCheckpointManager checkpointManager =
        new KafkaCheckpointManager(CHECKPOINT_SPEC, this.systemFactory, true, config(), this.metricsRegistry,
            checkpointV1Serde, CHECKPOINT_V2_SERDE, KAFKA_CHECKPOINT_LOG_KEY_SERDE);
    checkpointManager.register(TASK0);

    // expect an exception
    checkpointManager.readLastCheckpoint(TASK0);
  }
"
"  @Test
  public void testReadSucceedsOnKeySerdeExceptionsWhenValidationIsDisabled() throws InterruptedException {
    setupSystemFactory(config());
    List<IncomingMessageEnvelope> checkpointEnvelopes =
        ImmutableList.of(newCheckpointV1Envelope(TASK0, buildCheckpointV1(INPUT_SSP0, ""0""), ""0""));
    setupConsumer(checkpointEnvelopes);
    // wire up an exception throwing serde with the checkpointManager
    CheckpointV1Serde checkpointV1Serde = mock(CheckpointV1Serde.class);
    doThrow(new RuntimeException(""serde failed"")).when(checkpointV1Serde).fromBytes(any());
    KafkaCheckpointManager checkpointManager =
        new KafkaCheckpointManager(CHECKPOINT_SPEC, this.systemFactory, false, config(), this.metricsRegistry,
            checkpointV1Serde, CHECKPOINT_V2_SERDE, KAFKA_CHECKPOINT_LOG_KEY_SERDE);
    checkpointManager.register(TASK0);

    // expect the read to succeed in spite of the exception from ExceptionThrowingSerde
    assertNull(checkpointManager.readLastCheckpoint(TASK0));
  }
"
"  @Test
  public void testStart() {
    setupSystemFactory(config());
    String oldestOffset = ""1"";
    String newestOffset = ""2"";
    SystemStreamMetadata checkpointTopicMetadata = new SystemStreamMetadata(CHECKPOINT_TOPIC,
        ImmutableMap.of(new Partition(0), new SystemStreamPartitionMetadata(oldestOffset, newestOffset,
            Integer.toString(Integer.parseInt(newestOffset) + 1))));
    when(this.systemAdmin.getSystemStreamMetadata(Collections.singleton(CHECKPOINT_TOPIC))).thenReturn(
        ImmutableMap.of(CHECKPOINT_TOPIC, checkpointTopicMetadata));

    KafkaCheckpointManager checkpointManager = buildKafkaCheckpointManager(true, config());

    checkpointManager.start();

    verify(this.systemProducer).start();
    verify(this.systemAdmin).start();
    verify(this.systemConsumer).register(CHECKPOINT_SSP, oldestOffset);
    verify(this.systemConsumer).start();
  }
"
"  @Test
  public void testRegister() {
    setupSystemFactory(config());
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config());
    kafkaCheckpointManager.register(TASK0);
    verify(this.systemProducer).register(TASK0.getTaskName());
  }
"
"  @Test
  public void testStop() {
    setupSystemFactory(config());
    KafkaCheckpointManager checkpointManager = buildKafkaCheckpointManager(true, config());
    checkpointManager.stop();
    verify(this.systemProducer).stop();
    // default configuration for stopConsumerAfterFirstRead means that consumer is not stopped here
    verify(this.systemConsumer, never()).stop();
    verify(this.systemAdmin).stop();
  }
"
"  @Test
  public void testWriteCheckpointShouldRecreateSystemProducerOnFailure() {
    setupSystemFactory(config());
    SystemProducer secondKafkaProducer = mock(SystemProducer.class);
    // override default mock behavior to return a second producer on the second call to create a producer
    when(this.systemFactory.getProducer(CHECKPOINT_SYSTEM, config(), this.metricsRegistry,
        KafkaCheckpointManager.class.getSimpleName())).thenReturn(this.systemProducer, secondKafkaProducer);
    // first producer throws an exception on flush
    doThrow(new RuntimeException(""flush failed"")).when(this.systemProducer).flush(TASK0.getTaskName());
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config());
    kafkaCheckpointManager.register(TASK0);

    CheckpointV1 checkpointV1 = buildCheckpointV1(INPUT_SSP0, ""0"");
    kafkaCheckpointManager.writeCheckpoint(TASK0, checkpointV1);

    // first producer should be stopped
    verify(this.systemProducer).stop();
    // register and start the second producer
    verify(secondKafkaProducer).register(TASK0.getTaskName());
    verify(secondKafkaProducer).start();
    // check that the second producer was given the message to send out
    ArgumentCaptor<OutgoingMessageEnvelope> outgoingMessageEnvelopeArgumentCaptor =
        ArgumentCaptor.forClass(OutgoingMessageEnvelope.class);
    verify(secondKafkaProducer).send(eq(TASK0.getTaskName()), outgoingMessageEnvelopeArgumentCaptor.capture());
    assertEquals(CHECKPOINT_SSP, outgoingMessageEnvelopeArgumentCaptor.getValue().getSystemStream());
    assertEquals(new KafkaCheckpointLogKey(KafkaCheckpointLogKey.CHECKPOINT_V1_KEY_TYPE, TASK0, GROUPER_FACTORY_CLASS),
        KAFKA_CHECKPOINT_LOG_KEY_SERDE.fromBytes((byte[]) outgoingMessageEnvelopeArgumentCaptor.getValue().getKey()));
    assertEquals(checkpointV1,
        CHECKPOINT_V1_SERDE.fromBytes((byte[]) outgoingMessageEnvelopeArgumentCaptor.getValue().getMessage()));
    verify(secondKafkaProducer).flush(TASK0.getTaskName());
  }
"
"  @Test
  public void testCreateResources() {
    setupSystemFactory(config());
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config());
    kafkaCheckpointManager.createResources();

    verify(this.createResourcesSystemAdmin).start();
    verify(this.createResourcesSystemAdmin).createStream(CHECKPOINT_SPEC);
    verify(this.createResourcesSystemAdmin).validateStream(CHECKPOINT_SPEC);
    verify(this.createResourcesSystemAdmin).stop();
  }
"
"  @Test
  public void testCreateResourcesSkipValidation() {
    setupSystemFactory(config());
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(false, config());
    kafkaCheckpointManager.createResources();

    verify(this.createResourcesSystemAdmin).start();
    verify(this.createResourcesSystemAdmin).createStream(CHECKPOINT_SPEC);
    verify(this.createResourcesSystemAdmin, never()).validateStream(CHECKPOINT_SPEC);
    verify(this.createResourcesSystemAdmin).stop();
  }
"
"  @Test
  public void testReadEmpty() throws InterruptedException {
    setupSystemFactory(config());
    setupConsumer(ImmutableList.of());
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config());
    kafkaCheckpointManager.register(TASK0);
    assertNull(kafkaCheckpointManager.readLastCheckpoint(TASK0));
  }
"
"  @Test
  public void testReadCheckpointV1() throws InterruptedException {
    setupSystemFactory(config());
    CheckpointV1 checkpointV1 = buildCheckpointV1(INPUT_SSP0, ""0"");
    List<IncomingMessageEnvelope> checkpointEnvelopes =
        ImmutableList.of(newCheckpointV1Envelope(TASK0, checkpointV1, ""0""));
    setupConsumer(checkpointEnvelopes);
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config());
    kafkaCheckpointManager.register(TASK0);
    Checkpoint actualCheckpoint = kafkaCheckpointManager.readLastCheckpoint(TASK0);
    assertEquals(checkpointV1, actualCheckpoint);
  }
"
"  @Test
  public void testReadIgnoreCheckpointV2WhenV1Enabled() throws InterruptedException {
    setupSystemFactory(config());
    CheckpointV1 checkpointV1 = buildCheckpointV1(INPUT_SSP0, ""0"");
    List<IncomingMessageEnvelope> checkpointEnvelopes =
        ImmutableList.of(newCheckpointV1Envelope(TASK0, checkpointV1, ""0""),
            newCheckpointV2Envelope(TASK0, buildCheckpointV2(INPUT_SSP0, ""1""), ""1""));
    setupConsumer(checkpointEnvelopes);
    // default is to only read CheckpointV1
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config());
    kafkaCheckpointManager.register(TASK0);
    Checkpoint actualCheckpoint = kafkaCheckpointManager.readLastCheckpoint(TASK0);
    assertEquals(checkpointV1, actualCheckpoint);
  }
"
"  @Test
  public void testReadCheckpointV2() throws InterruptedException {
    Config config = config(ImmutableMap.of(TaskConfig.CHECKPOINT_READ_VERSIONS, ""1,2""));
    setupSystemFactory(config);
    CheckpointV2 checkpointV2 = buildCheckpointV2(INPUT_SSP0, ""0"");
    List<IncomingMessageEnvelope> checkpointEnvelopes =
        ImmutableList.of(newCheckpointV2Envelope(TASK0, checkpointV2, ""0""));
    setupConsumer(checkpointEnvelopes);
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config);
    kafkaCheckpointManager.register(TASK0);
    Checkpoint actualCheckpoint = kafkaCheckpointManager.readLastCheckpoint(TASK0);
    assertEquals(checkpointV2, actualCheckpoint);
  }
"
"  @Test
  public void testReadCheckpointPriority() throws InterruptedException {
    Config config = config(ImmutableMap.of(TaskConfig.CHECKPOINT_READ_VERSIONS, ""2,1""));
    setupSystemFactory(config);
    CheckpointV2 checkpointV2 = buildCheckpointV2(INPUT_SSP0, ""1"");
    List<IncomingMessageEnvelope> checkpointEnvelopes =
        ImmutableList.of(newCheckpointV1Envelope(TASK0, buildCheckpointV1(INPUT_SSP0, ""0""), ""0""),
            newCheckpointV2Envelope(TASK0, checkpointV2, ""1""));
    setupConsumer(checkpointEnvelopes);
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config);
    kafkaCheckpointManager.register(TASK0);
    Checkpoint actualCheckpoint = kafkaCheckpointManager.readLastCheckpoint(TASK0);
    assertEquals(checkpointV2, actualCheckpoint);
  }
"
"  @Test
  public void testReadMultipleCheckpointsMultipleSSP() throws InterruptedException {
    setupSystemFactory(config());
    KafkaCheckpointManager checkpointManager = buildKafkaCheckpointManager(true, config());
    checkpointManager.register(TASK0);
    checkpointManager.register(TASK1);

    // mock out a consumer that returns 5 checkpoint IMEs for each SSP
    int newestOffset = 5;
    int checkpointOffsetCounter = 0;
    List<List<IncomingMessageEnvelope>> pollOutputs = new ArrayList<>();
    for (int offset = 1; offset <= newestOffset; offset++) {
      pollOutputs.add(ImmutableList.of(
          // use regular offset value for INPUT_SSP0
          newCheckpointV1Envelope(TASK0, buildCheckpointV1(INPUT_SSP0, Integer.toString(offset)),
              Integer.toString(checkpointOffsetCounter++)),
          // use (offset * 2) value for INPUT_SSP1 so offsets are different from INPUT_SSP0
          newCheckpointV1Envelope(TASK1, buildCheckpointV1(INPUT_SSP1, Integer.toString(offset * 2)),
              Integer.toString(checkpointOffsetCounter++))));
    }
    setupConsumerMultiplePoll(pollOutputs);

    assertEquals(buildCheckpointV1(INPUT_SSP0, Integer.toString(newestOffset)),
        checkpointManager.readLastCheckpoint(TASK0));
    assertEquals(buildCheckpointV1(INPUT_SSP1, Integer.toString(newestOffset * 2)),
        checkpointManager.readLastCheckpoint(TASK1));
    // check expected number of polls (+1 is for the final empty poll), and the checkpoint is the newest message
    verify(this.systemConsumer, times(newestOffset + 1)).poll(ImmutableSet.of(CHECKPOINT_SSP),
        SystemConsumer.BLOCK_ON_OUTSTANDING_MESSAGES);
  }
"
"  @Test
  public void testReadMultipleCheckpointsUpgradeCheckpointVersion() throws InterruptedException {
    Config config = config(ImmutableMap.of(TaskConfig.CHECKPOINT_READ_VERSIONS, ""2,1""));
    setupSystemFactory(config);
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config);
    kafkaCheckpointManager.register(TASK0);
    kafkaCheckpointManager.register(TASK1);

    List<IncomingMessageEnvelope> checkpointEnvelopesV1 =
        ImmutableList.of(newCheckpointV1Envelope(TASK0, buildCheckpointV1(INPUT_SSP0, ""0""), ""0""),
            newCheckpointV1Envelope(TASK1, buildCheckpointV1(INPUT_SSP1, ""0""), ""1""));
    CheckpointV2 ssp0CheckpointV2 = buildCheckpointV2(INPUT_SSP0, ""10"");
    CheckpointV2 ssp1CheckpointV2 = buildCheckpointV2(INPUT_SSP1, ""11"");
    List<IncomingMessageEnvelope> checkpointEnvelopesV2 =
        ImmutableList.of(newCheckpointV2Envelope(TASK0, ssp0CheckpointV2, ""2""),
            newCheckpointV2Envelope(TASK1, ssp1CheckpointV2, ""3""));
    setupConsumerMultiplePoll(ImmutableList.of(checkpointEnvelopesV1, checkpointEnvelopesV2));
    assertEquals(ssp0CheckpointV2, kafkaCheckpointManager.readLastCheckpoint(TASK0));
    assertEquals(ssp1CheckpointV2, kafkaCheckpointManager.readLastCheckpoint(TASK1));
    // 2 polls for actual checkpoints, 1 final empty poll
    verify(this.systemConsumer, times(3)).poll(ImmutableSet.of(CHECKPOINT_SSP),
        SystemConsumer.BLOCK_ON_OUTSTANDING_MESSAGES);
  }
"
"  @Test
  public void testValidMpsEventCreation() throws CTPException {
    List<Event> events = getExistingEvents();
    Instant timestamp = Instant.now().plus(2, ChronoUnit.DAYS);
    Event newMpsEvent = new Event();
    newMpsEvent.setTag((EventService.Tag.mps.toString()));
    newMpsEvent.setTimestamp(Timestamp.from(timestamp));
    validator.validate(events, newMpsEvent, CollectionExerciseDTO.CollectionExerciseState.CREATED);
  }
"
"  @Test
  public void testValidGoLiveEventCreation() throws CTPException {
    List<Event> events = getExistingEvents();
    Instant timestamp = Instant.now().plus(4, ChronoUnit.DAYS);
    Event newGoLiveEvent = new Event();
    newGoLiveEvent.setTag((EventService.Tag.go_live.toString()));
    newGoLiveEvent.setTimestamp(Timestamp.from(timestamp));
    validator.validate(
        events, newGoLiveEvent, CollectionExerciseDTO.CollectionExerciseState.CREATED);
  }
"
"  @Test
  public void testValidReturnByEventCreation() throws CTPException {
    List<Event> events = getExistingEvents();
    Instant timestamp = Instant.now().plus(6, ChronoUnit.DAYS);
    Event newReturnByEvent = new Event();
    newReturnByEvent.setTag((EventService.Tag.return_by.toString()));
    newReturnByEvent.setTimestamp(Timestamp.from(timestamp));
    validator.validate(
        events, newReturnByEvent, CollectionExerciseDTO.CollectionExerciseState.CREATED);
  }
"
"  @Test
  public void testValidExerciseEndEventCreation() throws CTPException {
    List<Event> events = getExistingEvents();
    Instant timestamp = Instant.now().plus(8, ChronoUnit.DAYS);
    Event newExerciseEndEvent = new Event();
    newExerciseEndEvent.setTag((EventService.Tag.exercise_end.toString()));
    newExerciseEndEvent.setTimestamp(Timestamp.from(timestamp));
    validator.validate(
        events, newExerciseEndEvent, CollectionExerciseDTO.CollectionExerciseState.CREATED);
  }
"
"  @Test
  public void isEventValidator() {
    assertThat(reminderValidator, instanceOf(EventValidator.class));
  }
"
"  @Test
  public void returnTrueAndDoNothingIfNotReminder() throws CTPException {
    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now()));
    final List<Event> events = new ArrayList<>();
    reminderValidator.validate(events, mpsEvent, CollectionExerciseState.CREATED);

    verify(eventDateOrderChecker, never()).isEventDatesInOrder(anyList());
  }
"
"  @Test
  public void testCanUpdateReminderWhenReadyForLive() throws CTPException {
    final Event reminderEvent = new Event();
    reminderEvent.setTag(Tag.reminder.toString());
    reminderEvent.setTimestamp(Timestamp.from(Instant.now()));

    final List<Event> events = new ArrayList<>();
    reminderValidator.validate(events, reminderEvent, CollectionExerciseState.READY_FOR_LIVE);
  }
"
"  @Test
  public void testCanUpdateReminderWhenLive() throws CTPException {
    final Event reminderEvent = new Event();
    reminderEvent.setTag(Tag.reminder.toString());
    reminderEvent.setTimestamp(Timestamp.from(Instant.now()));

    final List<Event> events = new ArrayList<>();

    reminderValidator.validate(events, reminderEvent, CollectionExerciseState.LIVE);
  }
"
"  @Test
  public void testCantUpdateReminderThatHasPastAndCollectionExerciseInLockedState() {
    final Event reminder = new Event();
    reminder.setTag((Tag.reminder.toString()));
    reminder.setTimestamp(Timestamp.from(Instant.now().minus(2, ChronoUnit.DAYS)));

    final Event newReminder = new Event();
    newReminder.setTag((Tag.reminder.toString()));
    newReminder.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));

    final List<Event> events = Collections.singletonList(reminder);
    CTPException actualException = null;
    try {
      reminderValidator.validate(events, newReminder, CollectionExerciseState.LIVE);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(""Reminder cannot be set in the past"", actualException.getMessage());
  }
"
"  @Test
  public void testCanUpdateReminderThatHasPastAndCollectionExerciseNotInLockedState()
      throws CTPException {
    final Event reminder = new Event();
    reminder.setTag((Tag.reminder.toString()));
    reminder.setTimestamp(Timestamp.from(Instant.now().minus(2, ChronoUnit.DAYS)));

    final Event newReminder = new Event();
    newReminder.setTag((Tag.reminder.toString()));
    newReminder.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));

    final List<Event> events = Collections.singletonList(reminder);

    reminderValidator.validate(events, newReminder, CollectionExerciseState.SCHEDULED);
  }
"
"  @Test
  public void testValidReminderEventCreation() throws CTPException {
    final Event goLive = new Event();
    goLive.setTag((Tag.go_live.toString()));
    goLive.setTimestamp(Timestamp.from(Instant.now()));

    final Event reminder = new Event();
    reminder.setTag((Tag.reminder.toString()));
    reminder.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));

    final Event exerciseEnd = new Event();
    exerciseEnd.setTag((Tag.exercise_end.toString()));
    exerciseEnd.setTimestamp(Timestamp.from(Instant.now().plus(4, ChronoUnit.DAYS)));

    final List<Event> events = Arrays.asList(goLive, exerciseEnd);

    reminderValidator.validate(events, reminder, CollectionExerciseState.CREATED);
  }
"
"  @Test
  public void testReminderAfterExerciseEndInvalid() {
    final Event reminderEvent = new Event();
    reminderEvent.setTag(Tag.reminder3.toString());
    reminderEvent.setTimestamp(Timestamp.from(Instant.now().plus(4, ChronoUnit.DAYS)));

    final Event exerciseEnd = new Event();
    exerciseEnd.setTag((Tag.exercise_end.toString()));
    exerciseEnd.setTimestamp(Timestamp.from(Instant.now().plus(3, ChronoUnit.DAYS)));

    final List<Event> events = Collections.singletonList(exerciseEnd);
    CTPException actualException = null;
    try {
      reminderValidator.validate(events, reminderEvent, CollectionExerciseState.SCHEDULED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Reminder must take place during collection exercise period"", actualException.getMessage());
  }
"
"  @Test
  public void testReminderBeforeGoliveInvalid() {
    final Event goLive = new Event();
    goLive.setTag((Tag.go_live.toString()));
    goLive.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));
    final List<Event> events = Collections.singletonList(goLive);

    final Event reminderEvent = new Event();
    reminderEvent.setTag(Tag.reminder.toString());
    reminderEvent.setTimestamp(Timestamp.from(Instant.now().plus(1, ChronoUnit.DAYS)));

    CTPException actualException = null;
    try {
      reminderValidator.validate(events, reminderEvent, CollectionExerciseState.SCHEDULED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Reminder must take place during collection exercise period"", actualException.getMessage());
  }
"
"  @Test
  public void testReminder2WrongOrderEventCreation() {
    final Event reminder = new Event();
    reminder.setTag((Tag.reminder.toString()));
    reminder.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));
    final Event reminder2 = new Event();
    reminder2.setTag((Tag.reminder2.toString()));
    reminder2.setTimestamp(Timestamp.from(Instant.now().plus(1, ChronoUnit.DAYS)));
    final List<Event> events = new ArrayList<>();
    events.add(reminder);
    CTPException actualException = null;
    try {
      reminderValidator.validate(events, reminder2, CollectionExerciseState.CREATED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Collection exercise events must be set sequentially"", actualException.getMessage());
  }
"
"  @Test
  public void testReminder3WrongOrderEventCreation() {
    final Event reminder2 = new Event();
    reminder2.setTag((Tag.reminder2.toString()));
    reminder2.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));
    final Event reminder3 = new Event();
    reminder3.setTag((Tag.reminder3.toString()));
    reminder3.setTimestamp(Timestamp.from(Instant.now().plus(1, ChronoUnit.DAYS)));
    final List<Event> events = new ArrayList<>();
    events.add(reminder2);
    CTPException actualException = null;
    try {
      reminderValidator.validate(events, reminder3, CollectionExerciseState.CREATED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Collection exercise events must be set sequentially"", actualException.getMessage());
  }
"
"  @Test
  public void isEventValidator() {
    assertThat(mandatoryValidator, instanceOf(EventValidator.class));
  }
"
"  @Test
  public void returnTrueAndDoNothingIfNotReminder() throws CTPException {
    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.reminder.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now()));
    final List<Event> events = new ArrayList<>();
    mandatoryValidator.validate(events, mpsEvent, CollectionExerciseState.CREATED);

    verify(eventDateOrderChecker, never()).isEventDatesInOrder(anyList());
  }
"
"  @Test
  public void testValidMpsEventCreation() throws CTPException {
    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));
    final List<Event> events = new ArrayList<>();
    mandatoryValidator.validate(events, mpsEvent, CollectionExerciseState.CREATED);
  }
"
"  @Test
  public void testValidGoLiveEventCreation() throws CTPException {
    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));

    final Event goLiveEvent = new Event();
    goLiveEvent.setTag((Tag.go_live.toString()));
    goLiveEvent.setTimestamp(Timestamp.from(Instant.now().plus(4, ChronoUnit.DAYS)));

    final List<Event> events = Arrays.asList(mpsEvent);

    mandatoryValidator.validate(events, goLiveEvent, CollectionExerciseState.CREATED);
  }
"
"  @Test
  public void testValidReturnByEventCreation() throws CTPException {
    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));

    final Event goLiveEvent = new Event();
    goLiveEvent.setTag((Tag.go_live.toString()));
    goLiveEvent.setTimestamp(Timestamp.from(Instant.now().plus(4, ChronoUnit.DAYS)));

    final List<Event> events = Arrays.asList(mpsEvent, goLiveEvent);

    final Event returnByEvent = new Event();
    returnByEvent.setTag((Tag.return_by.toString()));
    returnByEvent.setTimestamp(Timestamp.from(Instant.now().plus(6, ChronoUnit.DAYS)));

    mandatoryValidator.validate(events, returnByEvent, CollectionExerciseState.CREATED);
  }
"
"  @Test
  public void testInvalidGoLiveEventCreation() {
    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now().plus(10, ChronoUnit.DAYS)));

    final Event goLive = new Event();
    goLive.setTag((Tag.go_live.toString()));
    goLive.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));

    final List<Event> events = Arrays.asList(mpsEvent);

    CTPException actualException = null;
    try {
      mandatoryValidator.validate(events, goLive, CollectionExerciseState.CREATED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Collection exercise events must be set sequentially"", actualException.getMessage());
  }
"
"  @Test
  public void testInvalidReturnByEventCreation() {
    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));

    final Event goLiveEvent = new Event();
    goLiveEvent.setTag((Tag.go_live.toString()));
    goLiveEvent.setTimestamp(Timestamp.from(Instant.now().plus(4, ChronoUnit.DAYS)));

    final List<Event> events = Arrays.asList(mpsEvent, goLiveEvent);

    final Event returnByEvent = new Event();
    returnByEvent.setTag((Tag.return_by.toString()));
    returnByEvent.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));

    CTPException actualException = null;
    try {
      mandatoryValidator.validate(events, returnByEvent, CollectionExerciseState.CREATED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Collection exercise events must be set sequentially"", actualException.getMessage());
  }
"
"  @Test
  public void testMandatoryEventsCannotBeChangedIfCollectionExerciseIsLive() {
    final List<Event> events = new ArrayList<>();

    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now().plus(1, ChronoUnit.MINUTES)));

    CTPException actualException = null;
    try {
      mandatoryValidator.validate(events, mpsEvent, CollectionExerciseState.LIVE);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Mandatory events cannot be changed if collection exercise is set to live, executed, validated or locked"",
        actualException.getMessage());
  }
"
"  @Test
  public void testMandatoryEventsCannotBeChangedIfCollectionExerciseIsValidated() {
    final List<Event> events = new ArrayList<>();

    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now().plus(1, ChronoUnit.MINUTES)));

    CTPException actualException = null;
    try {
      mandatoryValidator.validate(events, mpsEvent, CollectionExerciseState.VALIDATED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Mandatory events cannot be changed if collection exercise is set to live, executed, validated or locked"",
        actualException.getMessage());
  }
"
"  @Test
  public void testMandatoryEventsCannotBeChangedIfCollectionExerciseIsExecutionStarted() {
    final List<Event> events = new ArrayList<>();

    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now().plus(1, ChronoUnit.MINUTES)));

    CTPException actualException = null;
    try {
      mandatoryValidator.validate(events, mpsEvent, CollectionExerciseState.EXECUTION_STARTED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Mandatory events cannot be changed if collection exercise is set to live, executed, validated or locked"",
        actualException.getMessage());
  }
"
"  @Test
  public void testMandatoryEventsCannotBeChangedIfCollectionExerciseIsReadyForLive() {
    final List<Event> events = new ArrayList<>();

    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now().plus(1, ChronoUnit.MINUTES)));

    CTPException actualException = null;
    try {
      mandatoryValidator.validate(events, mpsEvent, CollectionExerciseState.READY_FOR_LIVE);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Mandatory events cannot be changed if collection exercise is set to live, executed, validated or locked"",
        actualException.getMessage());
  }
"
"  @Test
  public void testMandatoryEventsCannotBeChangedIfCollectionExerciseIsExecuted() {
    final List<Event> events = new ArrayList<>();

    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now().plus(1, ChronoUnit.MINUTES)));

    CTPException actualException = null;
    try {
      mandatoryValidator.validate(events, mpsEvent, CollectionExerciseState.EXECUTED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Mandatory events cannot be changed if collection exercise is set to live, executed, validated or locked"",
        actualException.getMessage());
  }
"
"  @Test
  public void testValidReturnByEventUpdate() throws CTPException {
    final List<Event> events = createMandatoryEvents();

    final Event returnByEvent = new Event();
    returnByEvent.setTag(Tag.return_by.toString());
    returnByEvent.setTimestamp(Timestamp.from(Instant.now().plus(5, ChronoUnit.DAYS)));

    mandatoryValidator.validate(events, returnByEvent, CollectionExerciseState.SCHEDULED);
  }
"
"  @Test
  public void testValidExerciseEndEventUpdate() throws CTPException {
    final List<Event> events = createMandatoryEvents();

    final Event exerciseEndEvent = new Event();
    exerciseEndEvent.setTag(Tag.exercise_end.toString());
    exerciseEndEvent.setTimestamp(Timestamp.from(Instant.now().plus(10, ChronoUnit.DAYS)));

    mandatoryValidator.validate(events, exerciseEndEvent, CollectionExerciseState.SCHEDULED);
  }
"
"  @Test
  public void testInvalidMpsEventUpdate() {
    final List<Event> events = createMandatoryEvents();

    final Event mpsEvent = new Event();
    mpsEvent.setTag(Tag.mps.toString());
    mpsEvent.setTimestamp(Timestamp.from(Instant.now().plus(6, ChronoUnit.DAYS)));

    CTPException actualException = null;
    try {
      mandatoryValidator.validate(events, mpsEvent, CollectionExerciseState.SCHEDULED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Collection exercise events must be set sequentially"", actualException.getMessage());
  }
"
"  @Test
  public void testInvalidGoLiveEventUpdate() {
    final List<Event> events = createMandatoryEvents();

    final Event goLiveEvent = new Event();
    goLiveEvent.setTag(Tag.go_live.toString());
    goLiveEvent.setTimestamp(Timestamp.from(Instant.now().plus(8, ChronoUnit.DAYS)));

    CTPException actualException = null;
    try {
      mandatoryValidator.validate(events, goLiveEvent, CollectionExerciseState.SCHEDULED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Collection exercise events must be set sequentially"", actualException.getMessage());
  }
"
"  @Test
  public void testInvalidReturnByEventUpdate() {
    final List<Event> events = createMandatoryEvents();

    final Event returnByEvent = new Event();
    returnByEvent.setTag(Tag.return_by.toString());
    returnByEvent.setTimestamp(Timestamp.from(Instant.now().plus(1, ChronoUnit.DAYS)));

    CTPException actualException = null;
    try {
      mandatoryValidator.validate(events, returnByEvent, CollectionExerciseState.SCHEDULED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Collection exercise events must be set sequentially"", actualException.getMessage());
  }
"
"  @Test
  public void testInvalidExerciseEndEventUpdate() {
    final List<Event> events = createMandatoryEvents();

    final Event exerciseEndEvent = new Event();
    exerciseEndEvent.setTag(Tag.exercise_end.toString());
    exerciseEndEvent.setTimestamp(Timestamp.from(Instant.now().plus(1, ChronoUnit.DAYS)));

    CTPException actualException = null;
    try {
      mandatoryValidator.validate(events, exerciseEndEvent, CollectionExerciseState.SCHEDULED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Collection exercise events must be set sequentially"", actualException.getMessage());
  }
"
"  @Test
  public void isEventValidator() {
    assertThat(referencePeriodValidator, instanceOf(EventValidator.class));
  }
"
"  @Test
  public void returnTrueAndDoNothingIfNotReferencePeriodEvent() throws CTPException {
    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now()));
    final List<Event> events = new ArrayList<>();
    referencePeriodValidator.validate(events, mpsEvent, CollectionExerciseState.CREATED);
  }
"
"  @Test
  public void canUpdateReferencePeriodWhenCollectionExerciseReadyForLive() throws CTPException {
    final Event referencePeriodStart = new Event();
    referencePeriodStart.setTag(Tag.ref_period_end.toString());
    referencePeriodStart.setTimestamp(Timestamp.from(Instant.now()));

    final List<Event> events = new ArrayList<>();

    referencePeriodValidator.validate(
        events, referencePeriodStart, CollectionExerciseState.READY_FOR_LIVE);
  }
"
"  @Test
  public void canUpdateReferencePeriodWhenCollectionExerciseLive() throws CTPException {
    final Event referencePeriodStart = new Event();
    referencePeriodStart.setTag(Tag.ref_period_start.toString());
    referencePeriodStart.setTimestamp(Timestamp.from(Instant.now()));

    final List<Event> events = new ArrayList<>();

    referencePeriodValidator.validate(events, referencePeriodStart, CollectionExerciseState.LIVE);
  }
"
"  @Test
  public void testReferenceStartCanBeSetInThePast() throws CTPException {
    final Event refStart = new Event();
    refStart.setTag((Tag.ref_period_start.toString()));
    refStart.setTimestamp(Timestamp.from(Instant.now().minus(1, ChronoUnit.DAYS)));

    final List<Event> events = new ArrayList<>();
    referencePeriodValidator.validate(events, refStart, CollectionExerciseState.CREATED);
  }
"
"  @Test
  public void testReferenceEndCanBeSetInThePast() throws CTPException {
    final Event refEnd = new Event();
    refEnd.setTag((Tag.ref_period_end.toString()));
    refEnd.setTimestamp(Timestamp.from(Instant.now().minus(1, ChronoUnit.DAYS)));

    final List<Event> events = new ArrayList<>();
    referencePeriodValidator.validate(events, refEnd, CollectionExerciseState.CREATED);
  }
"
"  @Test
  public void testReferenceEndBeforeReferenceStartIsInvalid() {
    final Event refEnd = new Event();
    refEnd.setTag((Tag.ref_period_end.toString()));
    refEnd.setTimestamp(Timestamp.from(Instant.now().plus(1, ChronoUnit.DAYS)));
    final Event refStart = new Event();
    refStart.setTag((Tag.ref_period_start.toString()));
    refStart.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));
    final List<Event> events = new ArrayList<>();
    events.add(refEnd);
    CTPException actualException = null;
    try {
      referencePeriodValidator.validate(events, refStart, CollectionExerciseState.CREATED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Reference period end date must be after start date"", actualException.getMessage());
  }
"
"  @Test
  public void isEventValidator() {
    assertThat(nudgeEmailValidator, instanceOf(EventValidator.class));
  }
"
"  @Test
  public void returnTrueAndDoNothingIfNotNudge() throws CTPException {
    final Event mpsEvent = new Event();
    mpsEvent.setTag((EventService.Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now()));
    final List<Event> events = new ArrayList<>();
    nudgeEmailValidator.validate(
        events, mpsEvent, CollectionExerciseDTO.CollectionExerciseState.CREATED);

    verify(eventDateOrderChecker, never()).isEventDatesInOrder(anyList());
  }
"
"  @Test
  public void testCanUpdateNudgeWhenReadyForLive() throws CTPException {
    final Event nudgeEvent = new Event();
    nudgeEvent.setTag(EventService.Tag.nudge_email_0.toString());
    nudgeEvent.setTimestamp(Timestamp.from(Instant.now()));

    final List<Event> events = new ArrayList<>();
    nudgeEmailValidator.validate(
        events, nudgeEvent, CollectionExerciseDTO.CollectionExerciseState.READY_FOR_LIVE);
  }
"
"  @Test
  public void testCanUpdateNudgeWhenLive() throws CTPException {
    final Event nudgeEvent = new Event();
    nudgeEvent.setTag(EventService.Tag.nudge_email_0.toString());
    nudgeEvent.setTimestamp(Timestamp.from(Instant.now()));

    final List<Event> events = new ArrayList<>();

    nudgeEmailValidator.validate(
        events, nudgeEvent, CollectionExerciseDTO.CollectionExerciseState.LIVE);
  }
"
"  @Test
  public void testCantUpdateNudgeThatHasPastAndCollectionExerciseInLockedState() {
    final Event nudge = new Event();
    nudge.setTag((EventService.Tag.nudge_email_0.toString()));
    nudge.setTimestamp(Timestamp.from(Instant.now().minus(2, ChronoUnit.DAYS)));

    final Event newNudge = new Event();
    newNudge.setTag((EventService.Tag.nudge_email_0.toString()));
    newNudge.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));

    final List<Event> events = Collections.singletonList(nudge);
    CTPException actualException = null;
    try {
      nudgeEmailValidator.validate(
          events, newNudge, CollectionExerciseDTO.CollectionExerciseState.LIVE);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(""Nudge email cannot be set in the past"", actualException.getMessage());
  }
"
"  @Test
  public void testCanUpdateNudgeThatHasPastAndCollectionExerciseNotInLockedState()
      throws CTPException {
    final Event nudge = new Event();
    nudge.setTag((EventService.Tag.nudge_email_0.toString()));
    nudge.setTimestamp(Timestamp.from(Instant.now().minus(2, ChronoUnit.DAYS)));

    final Event newNudge = new Event();
    newNudge.setTag((EventService.Tag.nudge_email_0.toString()));
    newNudge.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));

    final List<Event> events = Collections.singletonList(nudge);

    nudgeEmailValidator.validate(
        events, newNudge, CollectionExerciseDTO.CollectionExerciseState.SCHEDULED);
  }
"
"  @Test
  public void testValidNudgeEventCreation() throws CTPException {
    final Event goLive = new Event();
    goLive.setTag((EventService.Tag.go_live.toString()));
    goLive.setTimestamp(Timestamp.from(Instant.now()));

    final Event nudge = new Event();
    nudge.setTag((EventService.Tag.nudge_email_0.toString()));
    nudge.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));

    final Event returnBy = new Event();
    returnBy.setTag((EventService.Tag.return_by.toString()));
    returnBy.setTimestamp(Timestamp.from(Instant.now().plus(4, ChronoUnit.DAYS)));

    final List<Event> events = Arrays.asList(goLive, returnBy);

    nudgeEmailValidator.validate(
        events, nudge, CollectionExerciseDTO.CollectionExerciseState.CREATED);
  }
"
"  @Test
  public void testNudgeAfterReturnByEndInvalid() {
    final Event goLive = new Event();
    goLive.setTag((EventService.Tag.go_live.toString()));
    goLive.setTimestamp(Timestamp.from(Instant.now()));

    final Event nudgeEvent = new Event();
    nudgeEvent.setTag(EventService.Tag.nudge_email_0.toString());
    nudgeEvent.setTimestamp(Timestamp.from(Instant.now().plus(4, ChronoUnit.DAYS)));

    final Event returnBy = new Event();
    returnBy.setTag((EventService.Tag.return_by.toString()));
    returnBy.setTimestamp(Timestamp.from(Instant.now().plus(3, ChronoUnit.DAYS)));

    final List<Event> events = Arrays.asList(goLive, returnBy);
    CTPException actualException = null;

    SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss.SSS"");
    sdf.setTimeZone(TimeZone.getTimeZone(""Europe/London""));
    Date goLiveDate = new Date(goLive.getTimestamp().getTime());
    Date returnByDate = new Date(returnBy.getTimestamp().getTime());

    try {
      nudgeEmailValidator.validate(
          events, nudgeEvent, CollectionExerciseDTO.CollectionExerciseState.SCHEDULED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    String expectedMessage =
        ""Nudge email must be set after the Go Live date (""
            + sdf.format(goLiveDate)
            + "") ""
            + ""and before Return by date (""
            + sdf.format(returnByDate)
            + "")"";
    assertEquals(expectedMessage, actualException.getMessage());
  }
"
"  @Test
  public void testNudgeBeforeGoliveInvalid() {
    final Event goLive = new Event();
    goLive.setTag((EventService.Tag.go_live.toString()));
    goLive.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));
    final Event returnBy = new Event();
    returnBy.setTag((EventService.Tag.return_by.toString()));
    returnBy.setTimestamp(Timestamp.from(Instant.now().plus(3, ChronoUnit.DAYS)));
    final List<Event> events = Arrays.asList(goLive, returnBy);

    final Event nudgeEvent = new Event();
    nudgeEvent.setTag(EventService.Tag.nudge_email_0.toString());
    nudgeEvent.setTimestamp(Timestamp.from(Instant.now().plus(1, ChronoUnit.DAYS)));

    SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss.SSS"");
    sdf.setTimeZone(TimeZone.getTimeZone(""Europe/London""));
    Date goLiveDate = new Date(goLive.getTimestamp().getTime());
    Date returnByDate = new Date(returnBy.getTimestamp().getTime());

    CTPException actualException = null;
    try {
      nudgeEmailValidator.validate(
          events, nudgeEvent, CollectionExerciseDTO.CollectionExerciseState.SCHEDULED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    String expectedMessage =
        ""Nudge email must be set after the Go Live date (""
            + sdf.format(goLiveDate)
            + "") ""
            + ""and before Return by date (""
            + sdf.format(returnByDate)
            + "")"";
    assertEquals(expectedMessage, actualException.getMessage());
  }
"
"  @Test
  public void testNudgeWithSameDateAndTimeEventCreation() {
    final Instant now = Instant.now();
    final Long nudgeTime = now.plus(2, ChronoUnit.DAYS).toEpochMilli();
    final Event goLive = new Event();
    goLive.setTag((EventService.Tag.go_live.toString()));
    goLive.setTimestamp(Timestamp.from(now));

    final Event nudge = new Event();
    nudge.setTag((EventService.Tag.nudge_email_0.toString()));
    nudge.setTimestamp(new Timestamp(nudgeTime));

    final Event returnBy = new Event();
    returnBy.setTag((EventService.Tag.return_by.toString()));
    returnBy.setTimestamp(Timestamp.from(now.plus(4, ChronoUnit.DAYS)));

    final List<Event> events = Arrays.asList(goLive, returnBy, nudge);

    final Event submittedEvent = new Event();
    submittedEvent.setTag((EventService.Tag.nudge_email_1.toString()));
    submittedEvent.setTimestamp(new Timestamp(nudgeTime));

    CTPException actualException = null;
    try {
      nudgeEmailValidator.validate(
          events, submittedEvent, CollectionExerciseDTO.CollectionExerciseState.CREATED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""A nudge email has already been scheduled for this date and time. Choose a different date or time."",
        actualException.getMessage());
  }
"
"  @Test
  public void testNudgeWithSameDateAndTimeEventCreationNotValidForTheSameEvent() {
    final Instant now = Instant.now();
    final Long nudgeTime = now.plus(2, ChronoUnit.DAYS).toEpochMilli();
    final Event goLive = new Event();
    goLive.setTag((EventService.Tag.go_live.toString()));
    goLive.setTimestamp(Timestamp.from(now));

    final Event nudge = new Event();
    nudge.setTag((EventService.Tag.nudge_email_0.toString()));
    nudge.setTimestamp(new Timestamp(nudgeTime));

    final Event returnBy = new Event();
    returnBy.setTag((EventService.Tag.return_by.toString()));
    returnBy.setTimestamp(Timestamp.from(now.plus(4, ChronoUnit.DAYS)));

    final List<Event> events = Arrays.asList(goLive, returnBy, nudge);

    final Event submittedEvent = new Event();
    submittedEvent.setTag((EventService.Tag.nudge_email_0.toString()));
    submittedEvent.setTimestamp(new Timestamp(nudgeTime));

    CTPException actualException = null;
    try {
      nudgeEmailValidator.validate(
          events, submittedEvent, CollectionExerciseDTO.CollectionExerciseState.CREATED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNull(actualException);
  }
"
"  @Test
  public void testCreateCollectionExercise() throws Exception {
    // Given
    CollectionExercise collectionExercise =
        FixtureHelper.loadClassFixtures(CollectionExercise[].class).get(0);
    when(collexRepo.saveAndFlush(any())).thenReturn(collectionExercise);

    SurveyDTO survey = FixtureHelper.loadClassFixtures(SurveyDTO[].class).get(0);
    CollectionExerciseDTO toCreate =
        FixtureHelper.loadClassFixtures(CollectionExerciseDTO[].class).get(0);

    // When
    this.collectionExerciseService.createCollectionExercise(toCreate, survey);

    // Then
    ArgumentCaptor<CollectionExercise> captor = ArgumentCaptor.forClass(CollectionExercise.class);
    verify(this.collexRepo).saveAndFlush(captor.capture());
    CollectionExercise collex = captor.getValue();
    assertEquals(toCreate.getUserDescription(), collex.getUserDescription());
    assertEquals(toCreate.getExerciseRef(), collex.getExerciseRef());
    assertEquals(toCreate.getSurveyId(), collex.getSurveyId().toString());
    assertNotNull(collex.getCreated());
  }
"
"  @Test
  public void testUpdateCollectionExercise() throws Exception {
    CollectionExerciseDTO toUpdate =
        FixtureHelper.loadClassFixtures(CollectionExerciseDTO[].class).get(0);
    CollectionExercise existing =
        FixtureHelper.loadClassFixtures(CollectionExercise[].class).get(0);
    SurveyDTO survey = FixtureHelper.loadClassFixtures(SurveyDTO[].class).get(0);
    UUID surveyId = UUID.fromString(survey.getId());
    existing.setSurveyId(surveyId);
    when(collexRepo.findOneById(existing.getId())).thenReturn(existing);
    when(surveyService.findSurvey(surveyId)).thenReturn(survey);

    this.collectionExerciseService.updateCollectionExercise(existing.getId(), toUpdate);

    ArgumentCaptor<CollectionExercise> captor = ArgumentCaptor.forClass(CollectionExercise.class);

    verify(collexRepo).saveAndFlush(captor.capture());
    CollectionExercise collex = captor.getValue();
    assertEquals(UUID.fromString(toUpdate.getSurveyId()), collex.getSurveyId());
    assertEquals(toUpdate.getExerciseRef(), collex.getExerciseRef());
    assertEquals(toUpdate.getUserDescription(), collex.getUserDescription());
    assertNotNull(collex.getUpdated());
  }
"
"  @Test
  public void testUpdateCollectionExerciseInvalidSurvey() throws Exception {
    CollectionExerciseDTO toUpdate =
        FixtureHelper.loadClassFixtures(CollectionExerciseDTO[].class).get(0);
    CollectionExercise existing =
        FixtureHelper.loadClassFixtures(CollectionExercise[].class).get(0);
    existing.setSurveyId(UUID.randomUUID());
    when(collexRepo.findOneById(existing.getId())).thenReturn(existing);

    try {
      this.collectionExerciseService.updateCollectionExercise(existing.getId(), toUpdate);
      fail(""Update collection exercise with null survey succeeded"");
    } catch (CTPException e) {
      assertEquals(CTPException.Fault.BAD_REQUEST, e.getFault());
    }
  }
"
"  @Test
  public void testUpdateCollectionExerciseNonUnique() throws Exception {
    CollectionExerciseDTO toUpdate =
        FixtureHelper.loadClassFixtures(CollectionExerciseDTO[].class).get(0);
    CollectionExercise existing =
        FixtureHelper.loadClassFixtures(CollectionExercise[].class).get(0);
    existing.setSurveyId(UUID.randomUUID());
    // Set up the mock to return the one we are attempting to update
    when(collexRepo.findOneById(existing.getId())).thenReturn(existing);

    UUID uuid = UUID.fromString(""0f66744b-bfdb-458a-b495-1eb605462003"");
    CollectionExercise otherExisting = new CollectionExercise();
    otherExisting.setId(uuid);
    // Set up the mock to return a different one with the same exercise ref and survey id
    when(collexRepo.findByExerciseRefAndSurveyId(
            toUpdate.getExerciseRef(), UUID.fromString(toUpdate.getSurveyId())))
        .thenReturn(Collections.singletonList(otherExisting));

    try {
      this.collectionExerciseService.updateCollectionExercise(existing.getId(), toUpdate);

      fail(""Update to collection exercise breaking uniqueness constraint succeeded"");
    } catch (CTPException e) {
      assertEquals(CTPException.Fault.RESOURCE_VERSION_CONFLICT, e.getFault());
    }
  }
"
"  @Test
  public void testUpdateCollectionExerciseDoesNotExist() throws Exception {
    CollectionExerciseDTO toUpdate =
        FixtureHelper.loadClassFixtures(CollectionExerciseDTO[].class).get(0);
    UUID updateUuid = UUID.randomUUID();

    try {
      this.collectionExerciseService.updateCollectionExercise(updateUuid, toUpdate);
      fail(""Update of non-existent collection exercise succeeded"");
    } catch (CTPException e) {
      assertEquals(CTPException.Fault.RESOURCE_NOT_FOUND, e.getFault());
    }
  }
"
"  @Test
  public void testDeleteCollectionExercise() throws Exception {
    CollectionExercise existing =
        FixtureHelper.loadClassFixtures(CollectionExercise[].class).get(0);
    when(collexRepo.findOneById(existing.getId())).thenReturn(existing);

    this.collectionExerciseService.deleteCollectionExercise(existing.getId());

    ArgumentCaptor<CollectionExercise> captor = ArgumentCaptor.forClass(CollectionExercise.class);
    verify(this.collexRepo).saveAndFlush(captor.capture());

    assertEquals(true, captor.getValue().getDeleted());
  }
"
"  @Test
  public void testUndeleteCollectionExercise() throws Exception {
    CollectionExercise existing =
        FixtureHelper.loadClassFixtures(CollectionExercise[].class).get(0);
    when(collexRepo.findOneById(existing.getId())).thenReturn(existing);

    this.collectionExerciseService.undeleteCollectionExercise(existing.getId());

    ArgumentCaptor<CollectionExercise> captor = ArgumentCaptor.forClass(CollectionExercise.class);
    verify(this.collexRepo).saveAndFlush(captor.capture());

    assertEquals(false, captor.getValue().getDeleted());
  }
"
"  @Test
  public void testPatchCollectionExerciseNotExists() throws Exception {
    CollectionExerciseDTO toUpdate =
        FixtureHelper.loadClassFixtures(CollectionExerciseDTO[].class).get(0);
    UUID updateUuid = UUID.randomUUID();

    try {
      this.collectionExerciseService.patchCollectionExercise(updateUuid, toUpdate);

      fail(""Attempt to patch non-existent collection exercise succeeded"");
    } catch (CTPException e) {
      assertEquals(CTPException.Fault.RESOURCE_NOT_FOUND, e.getFault());
    }
  }
"
"  @Test
  public void testPatchCollectionExerciseExerciseRef() throws Exception {
    CollectionExercise existing = setupCollectionExercise();
    CollectionExerciseDTO collex = new CollectionExerciseDTO();
    SurveyDTO survey = FixtureHelper.loadClassFixtures(SurveyDTO[].class).get(0);
    UUID surveyId = UUID.fromString(survey.getId());
    String exerciseRef = ""209966"";
    collex.setExerciseRef(exerciseRef);
    collex.setSurveyId(surveyId.toString());
    when(surveyService.findSurvey(surveyId)).thenReturn(survey);
    this.collectionExerciseService.patchCollectionExercise(existing.getId(), collex);

    ArgumentCaptor<CollectionExercise> captor = ArgumentCaptor.forClass(CollectionExercise.class);
    verify(this.collexRepo).saveAndFlush(captor.capture());

    CollectionExercise ce = captor.getValue();
    assertEquals(exerciseRef, ce.getExerciseRef());
    assertNotNull(ce.getUpdated());
  }
"
"  @Test
  public void testPatchCollectionExerciseName() throws Exception {
    CollectionExercise existing = setupCollectionExercise();
    CollectionExerciseDTO collex = new CollectionExerciseDTO();
    String name = ""Not BRES"";
    SurveyDTO survey = FixtureHelper.loadClassFixtures(SurveyDTO[].class).get(0);
    when(surveyService.findSurvey(any())).thenReturn(survey);
    this.collectionExerciseService.patchCollectionExercise(existing.getId(), collex);

    ArgumentCaptor<CollectionExercise> captor = ArgumentCaptor.forClass(CollectionExercise.class);
    verify(this.collexRepo).saveAndFlush(captor.capture());

    CollectionExercise ce = captor.getValue();
    assertNotNull(ce.getUpdated());
  }
"
"  @Test
  public void testPatchCollectionExerciseUserDescription() throws Exception {
    CollectionExercise existing = setupCollectionExercise();
    CollectionExerciseDTO collex = new CollectionExerciseDTO();
    String userDescription = ""Really odd description"";
    collex.setUserDescription(userDescription);
    SurveyDTO survey = FixtureHelper.loadClassFixtures(SurveyDTO[].class).get(0);
    when(surveyService.findSurvey(any())).thenReturn(survey);
    this.collectionExerciseService.patchCollectionExercise(existing.getId(), collex);

    ArgumentCaptor<CollectionExercise> captor = ArgumentCaptor.forClass(CollectionExercise.class);
    verify(this.collexRepo).saveAndFlush(captor.capture());

    CollectionExercise ce = captor.getValue();
    assertEquals(userDescription, ce.getUserDescription());
    assertNotNull(ce.getUpdated());
  }
"
"  @Test
  public void testPatchCollectionExerciseNonUnique() throws Exception {
    CollectionExerciseDTO toUpdate =
        FixtureHelper.loadClassFixtures(CollectionExerciseDTO[].class).get(0);
    CollectionExercise existing =
        FixtureHelper.loadClassFixtures(CollectionExercise[].class).get(0);
    existing.setSurveyId(UUID.randomUUID());
    // Set up the mock to return the one we are attempting to update
    when(collexRepo.findOneById(existing.getId())).thenReturn(existing);

    UUID uuid = UUID.fromString(""0f66744b-bfdb-458a-b495-1eb605462003"");
    CollectionExercise otherExisting = new CollectionExercise();
    otherExisting.setId(uuid);
    // Set up the mock to return a different one with the same exercise ref and survey id
    when(collexRepo.findByExerciseRefAndSurveyId(
            toUpdate.getExerciseRef(), UUID.fromString(toUpdate.getSurveyId())))
        .thenReturn(Collections.singletonList(otherExisting));

    try {
      this.collectionExerciseService.patchCollectionExercise(existing.getId(), toUpdate);

      fail(""Update to collection exercise breaking uniqueness constraint succeeded"");
    } catch (CTPException e) {
      assertEquals(CTPException.Fault.RESOURCE_VERSION_CONFLICT, e.getFault());
    }
  }
"
"  @Test
  public void testTransitionToReadyToReviewWhenScheduledWithCIsAndSample() throws Exception {
    // Given
    CollectionExercise exercise =
        FixtureHelper.loadClassFixtures(CollectionExercise[].class).get(0);
    exercise.setState(CollectionExerciseDTO.CollectionExerciseState.SCHEDULED);
    SampleLink testSampleLink = new SampleLink();
    testSampleLink.setSampleSummaryId(UUID.randomUUID());
    given(sampleLinkRepository.findByCollectionExerciseId(exercise.getId()))
        .willReturn(Collections.singletonList(testSampleLink));

    SampleSummaryDTO sampleSummary = new SampleSummaryDTO();
    sampleSummary.setState(SampleSummaryDTO.SampleState.ACTIVE);
    given(sampleSvcClient.getSampleSummary(testSampleLink.getSampleSummaryId()))
        .willReturn(sampleSummary);

    String searchStringJson =
        new JSONObject(Collections.singletonMap(""COLLECTION_EXERCISE"", exercise.getId().toString()))
            .toString();
    given(collectionInstrument.countCollectionInstruments(searchStringJson)).willReturn(1);

    // When
    collectionExerciseService.transitionScheduleCollectionExerciseToReadyToReview(exercise);

    // Then
    exercise.setState(CollectionExerciseDTO.CollectionExerciseState.READY_FOR_REVIEW);
    verify(collexRepo).saveAndFlush(exercise);
  }
"
"  @Test
  public void testDoNotTransitionToReadyToReviewWhenScheduledWithCIsAndNoSample() throws Exception {
    // Given
    CollectionExercise exercise =
        FixtureHelper.loadClassFixtures(CollectionExercise[].class).get(0);
    exercise.setState(CollectionExerciseDTO.CollectionExerciseState.SCHEDULED);
    given(sampleLinkRepository.findByCollectionExerciseId(exercise.getId()))
        .willReturn(Collections.emptyList());
    String searchStringJson =
        new JSONObject(Collections.singletonMap(""COLLECTION_EXERCISE"", exercise.getId().toString()))
            .toString();
    given(collectionInstrument.countCollectionInstruments(searchStringJson)).willReturn(1);

    // When
    collectionExerciseService.transitionScheduleCollectionExerciseToReadyToReview(exercise);

    // Then
    exercise.setState(CollectionExerciseDTO.CollectionExerciseState.READY_FOR_REVIEW);
    verify(collexRepo, times(0)).saveAndFlush(exercise);
  }
"
"  @Test
  public void testDoNotTransitionToReadyToReviewWhenScheduledWithNoCIsAndSample() throws Exception {
    // Given
    CollectionExercise exercise =
        FixtureHelper.loadClassFixtures(CollectionExercise[].class).get(0);
    exercise.setState(CollectionExerciseDTO.CollectionExerciseState.SCHEDULED);
    given(sampleLinkRepository.findByCollectionExerciseId(exercise.getId()))
        .willReturn(Collections.emptyList());
    String searchStringJson =
        new JSONObject(Collections.singletonMap(""COLLECTION_EXERCISE"", exercise.getId().toString()))
            .toString();
    given(collectionInstrument.countCollectionInstruments(searchStringJson)).willReturn(0);

    // When
    collectionExerciseService.transitionScheduleCollectionExerciseToReadyToReview(exercise);

    // Then
    exercise.setState(CollectionExerciseDTO.CollectionExerciseState.READY_FOR_REVIEW);
    verify(collexRepo, times(0)).saveAndFlush(exercise);
  }
"
"  @Test
  public void testDoNotTransitionToReadyToReviewWhenCIsCountFailsAndReturnsNull() throws Exception {
    // Given
    CollectionExercise exercise =
        FixtureHelper.loadClassFixtures(CollectionExercise[].class).get(0);
    exercise.setState(CollectionExerciseDTO.CollectionExerciseState.SCHEDULED);
    given(sampleLinkRepository.findByCollectionExerciseId(exercise.getId()))
        .willReturn(Collections.emptyList());
    String searchStringJson =
        new JSONObject(Collections.singletonMap(""COLLECTION_EXERCISE"", exercise.getId().toString()))
            .toString();
    given(collectionInstrument.countCollectionInstruments(searchStringJson)).willReturn(null);

    // When
    collectionExerciseService.transitionScheduleCollectionExerciseToReadyToReview(exercise);

    // Then
    exercise.setState(CollectionExerciseDTO.CollectionExerciseState.READY_FOR_REVIEW);
    verify(collexRepo, times(0)).saveAndFlush(exercise);
  }
"
"  @Test
  public void testCreateLink() {
    UUID sampleSummaryUuid = UUID.randomUUID(), collexUuid = UUID.randomUUID();

    when(this.sampleLinkRepository.saveAndFlush(any(SampleLink.class))).then(returnsFirstArg());

    SampleLink sampleLink =
        this.collectionExerciseService.createLink(sampleSummaryUuid, collexUuid);

    assertEquals(sampleSummaryUuid, sampleLink.getSampleSummaryId());
    assertEquals(collexUuid, sampleLink.getCollectionExerciseId());

    verify(sampleLinkRepository, times(1)).saveAndFlush(any());
  }
"
"  @Test
  public void testCreateLinkShouldAttemptToTransitionToReadyToReview() throws CTPException {
    // Given
    UUID sampleSummaryUuid = UUID.randomUUID();
    UUID collexUuid = UUID.randomUUID();
    CollectionExercise collectionExercise = new CollectionExercise();
    collectionExercise.setId(collexUuid);
    collectionExercise.setState(CollectionExerciseDTO.CollectionExerciseState.CREATED);
    given(collexRepo.findOneById(collexUuid)).willReturn(collectionExercise);
    given(collectionInstrument.countCollectionInstruments(any())).willReturn(1);
    SampleSummaryDTO sampleSummary = new SampleSummaryDTO();
    SampleLink sampleLink = new SampleLink();
    sampleLink.setSampleSummaryId(sampleSummaryUuid);
    given(sampleLinkRepository.findByCollectionExerciseId(collexUuid))
        .willReturn(Collections.singletonList(sampleLink));
    sampleSummary.setState(SampleSummaryDTO.SampleState.ACTIVE);
    given(sampleSvcClient.getSampleSummary(sampleSummaryUuid)).willReturn(sampleSummary);

    // When
    this.collectionExerciseService.linkSampleSummaryToCollectionExercise(
        collexUuid, Collections.singletonList(sampleSummaryUuid));

    // Then
    verify(stateManager)
        .transition(
            CollectionExerciseDTO.CollectionExerciseState.CREATED,
            CollectionExerciseDTO.CollectionExerciseEvent.CI_SAMPLE_ADDED);
  }
"
"  @Test
  public void testFindCollectionExercisesForSurveys() throws Exception {
    final UUID SURVEY_ID_1 = UUID.fromString(""31ec898e-f370-429a-bca4-eab1045aff4e"");

    List<UUID> surveys = Arrays.asList(SURVEY_ID_1);

    List<CollectionExercise> existing = FixtureHelper.loadClassFixtures(CollectionExercise[].class);

    given(collexRepo.findBySurveyIdInOrderBySurveyId(surveys)).willReturn(existing);

    HashMap<UUID, List<CollectionExercise>> result =
        this.collectionExerciseService.findCollectionExercisesForSurveys(surveys);

    assertEquals(result.get(SURVEY_ID_1).size(), 2);
  }
"
"  @Test
  public void testFindCollectionExercisesForSurveysByState() throws Exception {
    final UUID SURVEY_ID_1 = UUID.fromString(""31ec898e-f370-429a-bca4-eab1045aff4e"");

    List<UUID> surveys = Arrays.asList(SURVEY_ID_1);

    List<CollectionExercise> existing = FixtureHelper.loadClassFixtures(CollectionExercise[].class);

    given(
            collexRepo.findBySurveyIdInAndStateOrderBySurveyId(
                surveys, CollectionExerciseDTO.CollectionExerciseState.LIVE))
        .willReturn(existing);

    HashMap<UUID, List<CollectionExercise>> result =
        this.collectionExerciseService.findCollectionExercisesForSurveysByState(
            surveys, CollectionExerciseDTO.CollectionExerciseState.LIVE);

    assertEquals(result.get(SURVEY_ID_1).size(), 2);
  }
"
"  @Test
  public void testAcceptSampleUnitAlreadyExists() throws CTPException {
    CollectionExercise collex = new CollectionExercise();
    collex.setId(COLLEX_ID);
    collex.setSampleSize(99);
    collex.setState(CollectionExerciseState.EXECUTION_STARTED);

    SampleUnit sampleUnit = new SampleUnit();
    sampleUnit.setCollectionExerciseId(COLLEX_ID.toString());
    sampleUnit.setFormType(""X"");
    sampleUnit.setId(SAMPLE_ID.toString());
    sampleUnit.setSampleUnitType(""B"");
    sampleUnit.setSampleUnitRef(""REF123"");
    when(collectRepo.findOneById(any())).thenReturn(collex);
    when(sampleUnitRepo.existsBySampleUnitRefAndSampleUnitTypeAndSampleUnitGroupCollectionExercise(
            any(), any(), any()))
        .thenReturn(true);

    underTest.acceptSampleUnit(sampleUnit);

    verify(collectionExerciseTransitionState, never()).transition(any(), any());
    verify(sampleUnitGroupRepo, never()).saveAndFlush(any());
    verify(sampleUnitRepo, never()).saveAndFlush(any());
    verify(collectRepo, never()).saveAndFlush(any());
  }
"
"  @Test
  public void requestSampleUnitsHappyPath() throws CTPException {
    UUID collexId = UUID.randomUUID();
    UUID sampleSummaryId = UUID.randomUUID();
    CollectionExercise collectionExercise = new CollectionExercise();
    collectionExercise.setId(collexId);
    SampleLink sampleLink = new SampleLink();
    sampleLink.setSampleSummaryId(sampleSummaryId);
    List<SampleLink> sampleLinks = Collections.singletonList(sampleLink);
    SampleUnitsRequestDTO sampleUnitsRequestDTO = new SampleUnitsRequestDTO();
    sampleUnitsRequestDTO.setSampleUnitsTotal(666);

    // Given
    when(collectRepo.findOneById(eq(collexId))).thenReturn(collectionExercise);
    when(sampleLinkRepo.findByCollectionExerciseId(any())).thenReturn(sampleLinks);
    when(sampleSvcClient.getSampleUnitCount(any())).thenReturn(sampleUnitsRequestDTO);
    when(sampleSvcClient.requestSampleUnits(any())).thenReturn(sampleUnitsRequestDTO);

    // When
    underTest.requestSampleUnits(collexId);

    // Then
    verify(collexSampleUnitReceiptPreparer).prepareCollexToAcceptSampleUnits(eq(collexId), eq(666));
    verify(partySvcClient).linkSampleSummaryId(any(), any());
  }
"
"  @Test
  public void givenCollectionExcerciseDoesNotExistWhenEventIsCreatedThenExceptionIsThrown() {
    EventDTO eventDto = new EventDTO();
    UUID collexUuid = UUID.randomUUID();
    eventDto.setCollectionExerciseId(collexUuid);

    try {
      eventService.createEvent(eventDto);

      fail(""Created event with non-existent collection exercise"");
    } catch (CTPException e) {
      // Expected 404
      assertThat(e.getFault(), is(Fault.RESOURCE_NOT_FOUND));
    }
  }
"
"  @Test
  public void givenEventAlreadyExistsWhenEventIsCreatedThenExceptionIsThrown() throws CTPException {
    String tag = Tag.mps.name();
    EventDTO eventDto = new EventDTO();
    CollectionExercise collex = new CollectionExercise();
    UUID collexUuid = UUID.randomUUID();
    eventDto.setCollectionExerciseId(collexUuid);
    eventDto.setTag(tag);
    collex.setId(collexUuid);

    when(collectionExerciseService.findCollectionExercise(collexUuid)).thenReturn(collex);
    when(eventRepository.findOneByCollectionExerciseAndTag(collex, tag)).thenReturn(new Event());

    try {
      eventService.createEvent(eventDto);

      fail(""Created event with non-existent collection exercise"");
    } catch (CTPException e) {
      // Expected 409
      assertThat(e.getFault(), is(Fault.RESOURCE_VERSION_CONFLICT));
    }
  }
"
"  @Test
  public void givenNoEventsWhenScheduledIsCheckedThenFalse() throws CTPException {
    UUID collexUuid = UUID.randomUUID();
    when(eventRepository.findByCollectionExerciseId(collexUuid)).thenReturn(new ArrayList<>());

    boolean scheduled = this.eventService.isScheduled(collexUuid);

    assertFalse(scheduled);
  }
"
"  @Test
  public void givenCollectionExcerciseDoesNotExistWhenEventIsUpdatedThenExceptionIsThrown() {
    final UUID collexUuid = UUID.randomUUID();

    when(collectionExerciseService.findCollectionExercise(collexUuid)).thenReturn(null);

    try {
      eventService.updateEvent(collexUuid, Tag.mps.name(), new Date());

      Assert.fail(""Updated event with non-existent collection exercise"");
    } catch (final CTPException e) {
      assertThat(e.getFault(), is(Fault.BAD_REQUEST));
    }
  }
"
"  @Test
  public void givenCollectionExcerciseDoesNotExistWhenEventIsDeletedThenExceptionIsThrown() {
    final UUID collexUuid = UUID.randomUUID();

    when(collectionExerciseService.findCollectionExercise(collexUuid)).thenReturn(null);

    try {
      eventService.deleteEvent(collexUuid, Tag.mps.name());

      Assert.fail(""Deleted event with non-existent collection exercise"");
    } catch (final CTPException e) {
      assertThat(e.getFault(), is(Fault.BAD_REQUEST));
    }
  }
"
"  @Test
  public void givenEventDoesNotExistWhenEventIsUpdatedThenExceptionIsThrown() {
    final UUID collexUuid = UUID.randomUUID();

    final CollectionExercise collex = new CollectionExercise();
    collex.setId(collexUuid);

    when(collectionExerciseService.findCollectionExercise(collexUuid)).thenReturn(collex);
    when(eventRepository.findOneByCollectionExerciseAndTag(collex, Tag.mps.name()))
        .thenReturn(null);

    try {
      eventService.updateEvent(collexUuid, Tag.mps.name(), new Date());

      Assert.fail(""Updated non-existent event"");
    } catch (final CTPException e) {
      assertThat(e.getFault(), is(Fault.RESOURCE_NOT_FOUND));
    }
  }
"
"  @Test
  public void givenEventDoesNotExistWhenEventIsDeletedThenExceptionIsThrown() {
    final UUID collexUuid = UUID.randomUUID();

    final CollectionExercise collex = new CollectionExercise();
    collex.setId(collexUuid);

    when(collectionExerciseService.findCollectionExercise(collexUuid)).thenReturn(collex);
    when(eventRepository.findOneByCollectionExerciseAndTag(collex, Tag.mps.name()))
        .thenReturn(null);

    try {
      eventService.deleteEvent(collexUuid, Tag.mps.name());

      Assert.fail(""Deleted non-existent event"");
    } catch (final CTPException e) {
      assertThat(e.getFault(), is(Fault.RESOURCE_NOT_FOUND));
    }
  }
"
"  @Test
  public void givenEventsForCollectionExerciseValidateWhenEventIsUpdatedItIsSaved()
      throws CTPException {

    final CollectionExercise collex = new CollectionExercise();
    collex.setId(COLLEX_UUID);
    collex.setExercisePK(EXERCISE_PK);
    final CollectionExerciseState collectionExerciseState = CollectionExerciseState.SCHEDULED;
    collex.setState(collectionExerciseState);

    when(collectionExerciseService.findCollectionExercise(COLLEX_UUID)).thenReturn(collex);
    final Event existingEvent = new Event();
    when(eventRepository.findOneByCollectionExerciseAndTag(collex, Tag.mps.name()))
        .thenReturn(existingEvent);

    final List<Event> existingEvents = new ArrayList<>();

    when(eventRepository.findByCollectionExercise(collex)).thenReturn(existingEvents);
    eventValidators.add(eventValidator);

    eventService.updateEvent(COLLEX_UUID, Tag.mps.name(), new Date());

    verify(eventRepository, atLeastOnce()).save(eq(existingEvent));
  }
"
"  @Test
  public void givenEventsForCollectionExerciseValidateWhenEventIsDeletedItIsSaved()
      throws CTPException {

    final CollectionExercise collex = new CollectionExercise();
    collex.setId(COLLEX_UUID);
    collex.setExercisePK(EXERCISE_PK);
    final CollectionExerciseState collectionExerciseState = CollectionExerciseState.SCHEDULED;
    collex.setState(collectionExerciseState);

    when(collectionExerciseService.findCollectionExercise(COLLEX_UUID)).thenReturn(collex);
    final Event existingEvent = new Event();
    existingEvent.setTag(Tag.nudge_email_4.toString());
    existingEvent.setId(UUID.randomUUID());
    when(eventRepository.findOneByCollectionExerciseAndTag(collex, Tag.nudge_email_4.name()))
        .thenReturn(existingEvent);

    final List<Event> existingEvents = new ArrayList<>();

    eventValidators.add(eventValidator);

    eventService.deleteEvent(COLLEX_UUID, Tag.nudge_email_4.name());

    verify(eventRepository, atLeastOnce()).delete(eq(existingEvent));
  }
"
"  @Test
  public void givenReminderEmailIsDeletedItGetsPropagatedToActionSVC() throws CTPException {

    final CollectionExercise collex = new CollectionExercise();
    collex.setId(COLLEX_UUID);
    collex.setExercisePK(EXERCISE_PK);
    final CollectionExerciseState collectionExerciseState = CollectionExerciseState.SCHEDULED;
    collex.setState(collectionExerciseState);

    when(collectionExerciseService.findCollectionExercise(COLLEX_UUID)).thenReturn(collex);
    final Event existingEvent = new Event();
    existingEvent.setTag(Tag.reminder.toString());
    existingEvent.setId(UUID.randomUUID());
    when(eventRepository.findOneByCollectionExerciseAndTag(collex, Tag.reminder.name()))
        .thenReturn(existingEvent);

    final List<Event> existingEvents = new ArrayList<>();

    eventValidators.add(eventValidator);

    eventService.deleteEvent(COLLEX_UUID, Tag.reminder.name());

    verify(eventRepository, atLeastOnce()).delete(eq(existingEvent));
  }
"
"  @Test
  public void givenSomeEventsWhenScheduledIsCheckedThenFalse() throws CTPException {
    UUID collexUuid = UUID.randomUUID();
    List<Event> events = createEventList(Tag.mps, Tag.exercise_end);
    when(eventRepository.findByCollectionExerciseId(collexUuid)).thenReturn(events);

    boolean scheduled = this.eventService.isScheduled(collexUuid);

    assertFalse(scheduled);
  }
"
"  @Test
  public void givenAllEventsWhenScheduledIsCheckedThenTrue() throws CTPException {
    UUID collexUuid = UUID.randomUUID();
    List<Event> events = createEventList(Tag.values());
    when(eventRepository.findByCollectionExerciseId(collexUuid)).thenReturn(events);

    boolean scheduled = this.eventService.isScheduled(collexUuid);

    assertTrue(scheduled);
  }
"
"  @Test
  public void givenCollectionExerciseDoesNotExistWhenCreatingAnExceptionThrowError() {
    final String tag = Tag.mps.name();
    final EventDTO eventDto = new EventDTO();
    final UUID collexUuid = UUID.randomUUID();
    eventDto.setCollectionExerciseId(collexUuid);
    eventDto.setTag(tag);
    when(collectionExerciseService.findCollectionExercise(collexUuid)).thenReturn(null);
    try {
      eventService.createEvent(eventDto);
      fail(""Created event with non-existent collection exercise"");
    } catch (final CTPException e) {
      assertThat(e.getFault(), is(Fault.RESOURCE_NOT_FOUND));
    }
  }
"
"  @Test
  public void givenCollectionExerciseEventsAreInInvalidStateThrowException() {
    final String tag = Tag.mps.name();
    final EventDTO eventDto = new EventDTO();
    final CollectionExercise collex = new CollectionExercise();
    final UUID collexUuid = UUID.randomUUID();
    eventDto.setCollectionExerciseId(collexUuid);
    eventDto.setTag(tag);
    eventDto.setTimestamp(new Timestamp(Instant.now().toEpochMilli()));
    collex.setId(collexUuid);
    when(collectionExerciseService.findCollectionExercise(collexUuid)).thenReturn(collex);
    when(eventRepository.findOneByCollectionExerciseAndTag(collex, Tag.mps.name()))
        .thenReturn(null);
    final List<Event> existingEvents = new ArrayList<>();
    final Event event = new Event();
    existingEvents.add(event);
    when(eventRepository.findByCollectionExercise(collex)).thenReturn(existingEvents);
    eventValidators.add(eventValidator);
    try {
      eventService.createEvent(eventDto);
    } catch (final CTPException e) {
      assertThat(e.getFault(), is(Fault.BAD_REQUEST));
    }
  }
"
"  @Test
  public void testStatusIsSetToScheduledNewEventCreated() {
    final CollectionExercise collex = new CollectionExercise();
    String tag = Tag.mps.name();

    when(collectionExerciseService.findCollectionExercise(COLLEX_UUID)).thenReturn(collex);
    when(eventRepository.save(any(Event.class))).then(returnsFirstArg());

    EventDTO eventDto = new EventDTO();
    eventDto.setCollectionExerciseId(COLLEX_UUID);
    eventDto.setTag(tag);
    eventDto.setTimestamp(new Timestamp(new Date().getTime()));

    try {
      Event event = eventService.createEvent(eventDto);
      assertThat(event.getStatus(), is(EventDTO.Status.SCHEDULED));
    } catch (CTPException e) {
      fail();
    }
  }
"
"  @Test
  public void testProcessEventsNoScheduledEvents() {
    // Given
    List<Event> emptyList = Collections.emptyList();
    when(eventRepository.findByStatus(EventDTO.Status.SCHEDULED)).thenReturn(emptyList);

    // When
    eventService.processEvents();

    // Then
    verify(eventRepository, atMost(1)).findByStatus(EventDTO.Status.SCHEDULED);
    verify(actionSvcClient, never()).processEvent(any(), any());
  }
"
"  @Test
  public void testProcessEventsOnlyEventInFuture() {
    // Given
    List<Event> list = new ArrayList<>();
    Event event = createEvent(Tag.mps, ""31/12/2999"");
    CollectionExercise collectionExercise = new CollectionExercise();
    collectionExercise.setState(CollectionExerciseState.LIVE);
    event.setCollectionExercise(collectionExercise);
    list.add(event);

    when(eventRepository.findByStatus(EventDTO.Status.SCHEDULED)).thenReturn(list);

    // When
    eventService.processEvents();

    // Then
    verify(eventRepository, atMost(1)).findByStatus(EventDTO.Status.SCHEDULED);
    verify(actionSvcClient, never()).processEvent(any(), any());
  }
"
"  @Test
  public void testProcessEventsTransitionGoLive() {
    // Given
    List<Event> list = new ArrayList<>();
    Event event = createEvent(Tag.go_live);
    CollectionExercise collectionExercise = new CollectionExercise();
    collectionExercise.setState(CollectionExerciseState.LIVE);
    event.setCollectionExercise(collectionExercise);
    list.add(event);

    when(eventRepository.findByStatus(EventDTO.Status.SCHEDULED)).thenReturn(list);

    // When
    eventService.processEvents();

    // Then
    verify(eventRepository, atMost(1)).findByStatus(EventDTO.Status.SCHEDULED);
    verify(actionSvcClient, atMost(1)).processEvent(any(), any());
    try {
      verify(collectionExerciseService, atMost(1))
          .transitionCollectionExercise(
              any(CollectionExercise.class),
              any(CollectionExerciseDTO.CollectionExerciseEvent.class));
    } catch (CTPException e) {
      fail();
    }
  }
"
"  @Test
  public void testTagShouldHaveMpsAsIsActionable() {
    assertThat(Tag.mps.isActionable(), Matchers.is(true));
  }
"
"  @Test
  public void testTagShouldHaveGoLiveAsIsAnActionableTag() {
    assertThat(Tag.go_live.isActionable(), Matchers.is(true));
  }
"
"  @Test
  public void testTagShouldHaveExerciseEndAsNotIsAnActionableTag() {
    assertThat(Tag.exercise_end.isActionable(), Matchers.is(false));
  }
"
"  @Test
  public void testTagShouldHaveReminderAsAnActionableTag() {
    assertThat(Tag.reminder.isActionable(), Matchers.is(true));
  }
"
"  @Test
  public void testTagShouldHaveReminder2AsAnActionableTag() {
    assertThat(Tag.reminder2.isActionable(), Matchers.is(true));
  }
"
"  @Test
  public void testTagShouldHaveReminder3AsAnActionableTag() {
    assertThat(Tag.reminder3.isActionable(), Matchers.is(true));
  }
"
"  @Test
  public void testTagShouldHaveNudge0AsAnActionableTag() {
    assertThat(Tag.nudge_email_0.isActionable(), Matchers.is(true));
  }
"
"  @Test
  public void testTagShouldHaveNudge1AsAnActionableTag() {
    assertThat(Tag.nudge_email_1.isActionable(), Matchers.is(true));
  }
"
"  @Test
  public void testTagShouldHaveNudge2AsAnActionableTag() {
    assertThat(Tag.nudge_email_2.isActionable(), Matchers.is(true));
  }
"
"  @Test
  public void testQueries()
      throws Exception {
    String sql = ""SELECT SUM(AirTime), SUM(ArrDelay) FROM mytable"";
    testSqlQuery(sql, Collections.singletonList(sql));
    sql = ""SELECT SUM(AirTime), DaysSinceEpoch FROM mytable GROUP BY DaysSinceEpoch ORDER BY SUM(AirTime) DESC"";
    testSqlQuery(sql, Collections.singletonList(sql));
    sql = ""SELECT Origin, SUM(ArrDelay) FROM mytable WHERE Carrier = 'AA' GROUP BY Origin ORDER BY Origin"";
    testSqlQuery(sql, Collections.singletonList(sql));
  }
"
"  @Test
  public void testPartitionMetadata() {
    int[] numSegmentsForPartition = new int[2];
    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(getTableName());
    List<SegmentZKMetadata> segmentsZKMetadata = _helixResourceManager.getSegmentsZKMetadata(realtimeTableName);
    for (SegmentZKMetadata segmentZKMetadata : segmentsZKMetadata) {
      SegmentPartitionMetadata segmentPartitionMetadata = segmentZKMetadata.getPartitionMetadata();
      assertNotNull(segmentPartitionMetadata);
      Map<String, ColumnPartitionMetadata> columnPartitionMetadataMap =
          segmentPartitionMetadata.getColumnPartitionMap();
      assertEquals(columnPartitionMetadataMap.size(), 1);
      ColumnPartitionMetadata columnPartitionMetadata = columnPartitionMetadataMap.get(PARTITION_COLUMN);
      assertNotNull(columnPartitionMetadata);
      assertTrue(columnPartitionMetadata.getFunctionName().equalsIgnoreCase(""murmur""));
      assertEquals(columnPartitionMetadata.getNumPartitions(), 2);
      int partitionGroupId = new LLCSegmentName(segmentZKMetadata.getSegmentName()).getPartitionGroupId();
      assertEquals(columnPartitionMetadata.getPartitions(), Collections.singleton(partitionGroupId));
      numSegmentsForPartition[partitionGroupId]++;
    }

    // There should be 2 segments for partition 0, 2 segments for partition 1
    assertEquals(numSegmentsForPartition[0], 2);
    assertEquals(numSegmentsForPartition[1], 2);
  }
"
"  @Test(dependsOnMethods = ""testPartitionMetadata"")
  public void testPartitionRouting()
      throws Exception {
    // Query partition 0
    {
      String query = ""SELECT COUNT(*) FROM mytable WHERE DestState = 'CA'"";
      JsonNode response = postQuery(query);

      String queryToCompare = ""SELECT COUNT(*) FROM mytable WHERE DestState BETWEEN 'CA' AND 'CA'"";
      JsonNode responseToCompare = postQuery(queryToCompare);

      // Should only query the segments for partition 0
      assertEquals(response.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), 2);
      assertEquals(responseToCompare.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), 4);

      assertEquals(response.get(""aggregationResults"").get(0).get(""value"").asInt(),
          responseToCompare.get(""aggregationResults"").get(0).get(""value"").asInt());
    }

    // Query partition 1
    {
      String query = ""SELECT COUNT(*) FROM mytable WHERE DestState = 'FL'"";
      JsonNode response = postQuery(query);

      String queryToCompare = ""SELECT COUNT(*) FROM mytable WHERE DestState BETWEEN 'FL' AND 'FL'"";
      JsonNode responseToCompare = postQuery(queryToCompare);

      // Should only query the segments for partition 1
      assertEquals(response.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), 2);
      assertEquals(responseToCompare.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), 4);

      assertEquals(response.get(""aggregationResults"").get(0).get(""value"").asInt(),
          responseToCompare.get(""aggregationResults"").get(0).get(""value"").asInt());
    }
  }
"
"  @Test(dependsOnMethods = ""testPartitionRouting"")
  public void testNonPartitionedStream()
      throws Exception {
    // Push the second Avro file into Kafka without partitioning
    _partitionColumn = null;
    pushAvroIntoKafka(Collections.singletonList(_avroFiles.get(1)));

    // Wait for all documents loaded
    _countStarResult += NUM_DOCS_IN_SECOND_AVRO_FILE;
    waitForAllDocsLoaded(600_000L);

    // Check partition metadata
    int[] numSegmentsForPartition = new int[2];
    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(getTableName());
    List<SegmentZKMetadata> segmentsZKMetadata = _helixResourceManager.getSegmentsZKMetadata(realtimeTableName);
    for (SegmentZKMetadata segmentZKMetadata : segmentsZKMetadata) {
      SegmentPartitionMetadata segmentPartitionMetadata = segmentZKMetadata.getPartitionMetadata();
      assertNotNull(segmentPartitionMetadata);
      Map<String, ColumnPartitionMetadata> columnPartitionMetadataMap =
          segmentPartitionMetadata.getColumnPartitionMap();
      assertEquals(columnPartitionMetadataMap.size(), 1);
      ColumnPartitionMetadata columnPartitionMetadata = columnPartitionMetadataMap.get(PARTITION_COLUMN);
      assertNotNull(columnPartitionMetadata);
      assertTrue(columnPartitionMetadata.getFunctionName().equalsIgnoreCase(""murmur""));
      assertEquals(columnPartitionMetadata.getNumPartitions(), 2);
      int partitionGroupId = new LLCSegmentName(segmentZKMetadata.getSegmentName()).getPartitionGroupId();
      numSegmentsForPartition[partitionGroupId]++;

      if (segmentZKMetadata.getStatus() == Status.IN_PROGRESS) {
        // For consuming segment, the partition metadata should only contain the stream partition
        assertEquals(columnPartitionMetadata.getPartitions(), Collections.singleton(partitionGroupId));
      } else {
        LLCSegmentName llcSegmentName = new LLCSegmentName(segmentZKMetadata.getSegmentName());
        int sequenceNumber = llcSegmentName.getSequenceNumber();
        if (sequenceNumber == 0) {
          // The partition metadata for the first completed segment should only contain the stream partition
          assertEquals(columnPartitionMetadata.getPartitions(), Collections.singleton(partitionGroupId));
        } else {
          // The partition metadata for the new completed segments should contain both partitions
          assertEquals(columnPartitionMetadata.getPartitions(), new HashSet<>(Arrays.asList(0, 1)));
        }
      }
    }

    // There should be 4 segments for partition 0, 4 segments for partition 1
    assertEquals(numSegmentsForPartition[0], 4);
    assertEquals(numSegmentsForPartition[1], 4);

    // Check partition routing
    int numSegments = segmentsZKMetadata.size();

    // Query partition 0
    {
      String query = ""SELECT COUNT(*) FROM mytable WHERE DestState = 'CA'"";
      JsonNode response = postQuery(query);

      String queryToCompare = ""SELECT COUNT(*) FROM mytable WHERE DestState BETWEEN 'CA' AND 'CA'"";
      JsonNode responseToCompare = postQuery(queryToCompare);

      // Should skip the first completed segments and the consuming segment for partition 1
      assertEquals(response.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments - 2);
      assertEquals(responseToCompare.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments);

      // The result won't match because the consuming segment for partition 1 is pruned out
    }

    // Query partition 1
    {
      String query = ""SELECT COUNT(*) FROM mytable WHERE DestState = 'FL'"";
      JsonNode response = postQuery(query);

      String queryToCompare = ""SELECT COUNT(*) FROM mytable WHERE DestState BETWEEN 'FL' AND 'FL'"";
      JsonNode responseToCompare = postQuery(queryToCompare);

      // Should skip the first completed segments and the consuming segment for partition 0
      assertEquals(response.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments - 2);
      assertEquals(responseToCompare.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments);

      // The result won't match because the consuming segment for partition 0 is pruned out
    }

    // Push the third Avro file into Kafka with partitioning
    _partitionColumn = PARTITION_COLUMN;
    pushAvroIntoKafka(Collections.singletonList(_avroFiles.get(2)));

    // Wait for all documents loaded
    _countStarResult += NUM_DOCS_IN_THIRD_AVRO_FILE;
    waitForAllDocsLoaded(600_000L);

    // Check partition metadata
    numSegmentsForPartition = new int[2];
    segmentsZKMetadata = _helixResourceManager.getSegmentsZKMetadata(realtimeTableName);
    for (SegmentZKMetadata segmentZKMetadata : segmentsZKMetadata) {
      SegmentPartitionMetadata segmentPartitionMetadata = segmentZKMetadata.getPartitionMetadata();
      assertNotNull(segmentPartitionMetadata);
      Map<String, ColumnPartitionMetadata> columnPartitionMetadataMap =
          segmentPartitionMetadata.getColumnPartitionMap();
      assertEquals(columnPartitionMetadataMap.size(), 1);
      ColumnPartitionMetadata columnPartitionMetadata = columnPartitionMetadataMap.get(PARTITION_COLUMN);
      assertNotNull(columnPartitionMetadata);
      assertTrue(columnPartitionMetadata.getFunctionName().equalsIgnoreCase(""murmur""));
      assertEquals(columnPartitionMetadata.getNumPartitions(), 2);
      int partitionGroupId = new LLCSegmentName(segmentZKMetadata.getSegmentName()).getPartitionGroupId();
      numSegmentsForPartition[partitionGroupId]++;

      if (segmentZKMetadata.getStatus() == Status.IN_PROGRESS) {
        // For consuming segment, the partition metadata should only contain the stream partition
        assertEquals(columnPartitionMetadata.getPartitions(), Collections.singleton(partitionGroupId));
      } else {
        // The partition metadata for the new completed segments should only contain the stream partition
        LLCSegmentName llcSegmentName = new LLCSegmentName(segmentZKMetadata.getSegmentName());
        int sequenceNumber = llcSegmentName.getSequenceNumber();
        if (sequenceNumber == 0 || sequenceNumber >= 4) {
          // The partition metadata for the first and new completed segments should only contain the stream partition
          assertEquals(columnPartitionMetadata.getPartitions(), Collections.singleton(partitionGroupId));
        } else {
          // The partition metadata for the completed segments containing records from the second Avro file should
          // contain both partitions
          assertEquals(columnPartitionMetadata.getPartitions(), new HashSet<>(Arrays.asList(0, 1)));
        }
      }
    }

    // There should be 6 segments for partition 0, 6 segments for partition 1
    assertEquals(numSegmentsForPartition[0], 6);
    assertEquals(numSegmentsForPartition[1], 6);

    // Check partition routing
    numSegments = segmentsZKMetadata.size();

    // Query partition 0
    {
      String query = ""SELECT COUNT(*) FROM mytable WHERE DestState = 'CA'"";
      JsonNode response = postQuery(query);

      String queryToCompare = ""SELECT COUNT(*) FROM mytable WHERE DestState BETWEEN 'CA' AND 'CA'"";
      JsonNode responseToCompare = postQuery(queryToCompare);

      // Should skip 2 completed segments and the consuming segment for partition 1
      assertEquals(response.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments - 3);
      assertEquals(responseToCompare.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments);

      // The result should match again after all the segments with the non-partitioning records are committed
      assertEquals(response.get(""aggregationResults"").get(0).get(""value"").asInt(),
          responseToCompare.get(""aggregationResults"").get(0).get(""value"").asInt());
    }

    // Query partition 1
    {
      String query = ""SELECT COUNT(*) FROM mytable WHERE DestState = 'FL'"";
      JsonNode response = postQuery(query);

      String queryToCompare = ""SELECT COUNT(*) FROM mytable WHERE DestState BETWEEN 'FL' AND 'FL'"";
      JsonNode responseToCompare = postQuery(queryToCompare);

      // Should skip 2 completed segments and the consuming segment for partition 0
      assertEquals(response.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments - 3);
      assertEquals(responseToCompare.get(MetadataKey.NUM_SEGMENTS_QUERIED.getName()).asInt(), numSegments);

      // The result should match again after all the segments with the non-partitioning records are committed
      assertEquals(response.get(""aggregationResults"").get(0).get(""value"").asInt(),
          responseToCompare.get(""aggregationResults"").get(0).get(""value"").asInt());
    }
  }
"
"  @Test
  public void testTotalCount()
      throws Exception {
    String query = ""SELECT count(*) FROM "" + getTableName();
    testQuery(query, Collections.singletonList(query));
  }
"
"  @Test
  public void testCountWithNullDescription()
      throws Exception {
    String query = ""SELECT count(*) FROM "" + getTableName() + "" where description IS NOT NULL"";
    testQuery(query, Collections.singletonList(query));
  }
"
"  @Test
  public void testCountWithNullDescriptionAndSalary()
      throws Exception {
    String query = ""SELECT count(*) FROM "" + getTableName() + "" where description IS NOT NULL AND salary IS NOT NULL"";
    testQuery(query, Collections.singletonList(query));
  }
"
"  @Test(enabled = false)
  public void testShortZookeeperFreeze()
      throws Exception {
    testFreezeZookeeper(10000L);
  }
"
"  @Test(enabled = false)
  public void testLongZookeeperFreeze()
      throws Exception {
    testFreezeZookeeper(60000L);
  }
"
"  @Test
  public void testQueriesFromQueryFile()
      throws Exception {
    super.testQueriesFromQueryFile();
  }
"
"  @Test
  public void testGeneratedQueriesWithMultiValues()
      throws Exception {
    super.testGeneratedQueriesWithMultiValues();
  }
"
"  @Test
  public void testDictionaryBasedQueries()
      throws Exception {

    // Dictionary columns
    // int
    testDictionaryBasedFunctions(""NASDelay"");

    // long
    testDictionaryBasedFunctions(""AirlineID"");

    // double
    testDictionaryBasedFunctions(""ArrDelayMinutes"");

    // float
    testDictionaryBasedFunctions(""DepDelayMinutes"");

    // Non Dictionary columns
    // int
    testDictionaryBasedFunctions(""ActualElapsedTime"");

    // double
    testDictionaryBasedFunctions(""DepDelay"");

    // float
    testDictionaryBasedFunctions(""ArrDelay"");
  }
"
"  @Test
  public void testQueryExceptions()
      throws Exception {
    super.testQueryExceptions();
  }
"
"  @Test
  public void testInstanceShutdown()
      throws Exception {
    super.testInstanceShutdown();
  }
"
"  @Test
  public void testHardcodedSqlQueries()
      throws Exception {
    super.testHardcodedSqlQueries();
  }
"
"  @Test
  public void testSqlQueriesFromQueryFile()
      throws Exception {
    super.testSqlQueriesFromQueryFile();
  }
"
"  @Test
  public void testSingleLevelConcat()
      throws Exception {
    // The original segments are time partitioned by month:
    // segmentName (totalDocs)
    // myTable1_16071_16101_3 (9746)
    // myTable1_16102_16129_4 (8690)
    // myTable1_16130_16159_5 (9621)
    // myTable1_16160_16189_6 (9454)
    // myTable1_16190_16220_7 (10329)
    // myTable1_16221_16250_8 (10468)
    // myTable1_16251_16281_9 (10499)
    // myTable1_16282_16312_10 (10196)
    // myTable1_16313_16342_11 (9136)
    // myTable1_16343_16373_0 (9292)
    // myTable1_16374_16404_1 (8736)
    // myTable1_16405_16435_2 (9378)

    // Expected merge tasks and result segments:
    // 1.
    //    {myTable1_16071_16101_3}
    //      -> {merged_100days_T1_0_myTable1_16071_16099_0, merged_100days_T1_0_myTable1_16100_16101_1}
    // 2.
    //    {merged_100days_T1_0_myTable1_16100_16101_1, myTable1_16102_16129_4, myTable1_16130_16159_5}
    //      -> {merged_100days_T2_0_myTable1_16100_???_0(15000), merged_100days_T2_0_myTable1_???_16159_1}
    //    {myTable1_16160_16189_6, myTable1_16190_16220_7}
    //      -> {merged_100days_T2_1_myTable1_16160_16199_0, merged_100days_T2_1_myTable1_16200_16220_1}
    // 3.
    //    {merged_100days_T2_1_myTable1_16200_16220_1, myTable1_16221_16250_8}
    //      -> {merged_100days_T3_0_myTable1_16200_???_0(15000), merged_100days_T3_0_myTable1_???_16250_1}
    //    {myTable1_16251_16281_9, myTable1_16282_16312_10}
    //      -> {merged_100days_T3_1_myTable1_16251_???_0(15000), merged_100days_T3_1_myTable1_???_16299_1,
    //      merged_100days_T3_1_myTable1_16300_16312_2}
    // 4.
    //    {merged_100days_T3_1_myTable1_16300_16312_2, myTable1_16313_16342_11, myTable1_16343_16373_0}
    //      -> {merged_100days_T4_0_myTable1_16300_???_0(15000), merged_100days_T4_0_myTable1_???_16373_1}
    //    {myTable1_16374_16404_1}
    //      -> {merged_100days_T4_1_16374_16399_0, merged_100days_T4_1_16400_16404_1}
    // 5.
    //    {merged_100days_T4_1_16400_16404_1, myTable1_16405_16435_2}
    //      -> {merged_100days_T5_0_myTable1_16400_16435_0}

    String sqlQuery = ""SELECT count(*) FROM myTable1""; // 115545 rows for the test table
    JsonNode expectedJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    int[] expectedNumSubTasks = {1, 2, 2, 2, 1};
    int[] expectedNumSegmentsQueried = {13, 12, 13, 13, 12};
    long expectedWatermark = 16000 * 86_400_000L;
    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(SINGLE_LEVEL_CONCAT_TEST_TABLE);
    int numTasks = 0;
    for (String tasks = _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE);
        tasks != null; tasks =
        _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE), numTasks++) {
      assertEquals(_helixTaskResourceManager.getTaskConfigs(tasks).size(), expectedNumSubTasks[numTasks]);
      assertTrue(_helixTaskResourceManager.getTaskQueues()
          .contains(PinotHelixTaskResourceManager.getHelixJobQueueName(MinionConstants.MergeRollupTask.TASK_TYPE)));
      // Will not schedule task if there's incomplete task
      assertNull(
          _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.RealtimeToOfflineSegmentsTask.TASK_TYPE));
      waitForTaskToComplete();

      // Check watermark
      MergeRollupTaskMetadata minionTaskMetadata = MergeRollupTaskMetadata
          .fromZNRecord(_taskManager.getClusterInfoAccessor().getMinionMergeRollupTaskZNRecord(offlineTableName));
      assertNotNull(minionTaskMetadata);
      assertEquals((long) minionTaskMetadata.getWatermarkMap().get(""100days""), expectedWatermark);
      expectedWatermark += 100 * 86_400_000L;

      // Check metadata of merged segments
      for (SegmentZKMetadata metadata : _pinotHelixResourceManager.getSegmentsZKMetadata(offlineTableName)) {
        if (metadata.getSegmentName().startsWith(""merged"")) {
          // Check merged segment zk metadata
          assertNotNull(metadata.getCustomMap());
          assertEquals(""100days"",
              metadata.getCustomMap().get(MinionConstants.MergeRollupTask.SEGMENT_ZK_METADATA_MERGE_LEVEL_KEY));
          // Check merged segments are time partitioned
          assertEquals(metadata.getEndTimeMs() / (86_400_000L * 100), metadata.getStartTimeMs() / (86_400_000L * 100));
        }
      }

      // Check num total doc of merged segments are the same as the original segments
      JsonNode actualJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
      SqlResultComparator.areEqual(actualJson, expectedJson, sqlQuery);
      // Check query routing
      int numSegmentsQueried = actualJson.get(""numSegmentsQueried"").asInt();
      assertEquals(numSegmentsQueried, expectedNumSegmentsQueried[numTasks]);
    }
    // Check total tasks
    assertEquals(numTasks, 5);

    assertTrue(_controllerStarter.getControllerMetrics()
        .containsGauge(""mergeRollupTaskDelayInNumBuckets.myTable1_OFFLINE.100days""));

    // Drop the table
    dropOfflineTable(SINGLE_LEVEL_CONCAT_TEST_TABLE);

    // Check if the task metadata is cleaned up on table deletion
    verifyTableDelete(offlineTableName);
  }
"
"  @Test
  public void testSingleLevelRollup()
      throws Exception {
    // The original segments are time partitioned by month:
    // segmentName (totalDocs)
    // myTable2_16071_16101_3_1, myTable2_16071_16101_3_2 (9746)
    // myTable2_16102_16129_4_1, myTable2_16102_16129_4_2 (8690)
    // myTable2_16130_16159_5_1, myTable2_16130_16159_5_2 (9621)
    // myTable2_16160_16189_6_1, myTable2_16160_16189_6_2 (9454)
    // myTable2_16190_16220_7_1, myTable2_16190_16220_7_2 (10329)
    // myTable2_16221_16250_8_1, myTable2_16221_16250_8_2 (10468)
    // myTable2_16251_16281_9_1, myTable2_16251_16281_9_2 (10499)
    // myTable2_16282_16312_10_1, myTable2_16282_16312_10_2 (10196)
    // myTable2_16313_16342_11_1, myTable2_16313_16342_11_2 (9136)
    // myTable2_16343_16373_0_1, myTable2_16343_16373_0_2 (9292)
    // myTable2_16374_16404_1_1, myTable2_16374_16404_1_2 (8736)
    // myTable2_16405_16435_2_1, myTable2_16405_16435_2_2 (9378)

    // Expected merge tasks and result segments:
    // 1.
    //    {myTable2_16071_16101_3_1, myTable2_16071_16101_3_2, myTable2_16102_16129_4_1, myTable2_16102_16129_4_2,
    //     myTable2_16130_16159_5_1, myTable2_16130_16159_5_2, myTable2_16160_16189_6_1, myTable2_16160_16189_6_2
    //     myTable2_16190_16220_7}
    //      -> {merged_150days_T1_0_myTable2_16065_16198_0, merged_150days_T1_0_myTable2_16205_16219_1}
    // 2.
    //    {merged_150days_T1_0_myTable2_16205_16219_1, myTable2_16221_16250_8_1, myTable2_16221_16250_8_2,
    //     myTable2_16251_16281_9_1, myTable2_16251_16281_9_2, myTable2_16282_16312_10_1
    //     myTable2_16282_16312_10_2, myTable2_16313_16342_11_1, myTable2_16313_16342_11_2,
    //     myTable2_16343_16373_0_1, myTable2_16343_16373_0_2}
    //      -> {merged_150days_1628644088146_0_myTable2_16205_16345_0,
    //          merged_150days_1628644088146_0_myTable2_16352_16373_1}
    // 3.
    //    {merged_150days_1628644088146_0_myTable2_16352_16373_1, myTable2_16374_16404_1_1, myTable2_16374_16404_1_2
    //     myTable2_16405_16435_2_1, myTable2_16405_16435_2_2}
    //      -> {merged_150days_1628644105127_0_myTable2_16352_16429_0}

    String sqlQuery = ""SELECT count(*) FROM myTable2""; // 115545 rows for the test table
    JsonNode expectedJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    int[] expectedNumSegmentsQueried = {16, 7, 3};
    long expectedWatermark = 16050 * 86_400_000L;
    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(SINGLE_LEVEL_ROLLUP_TEST_TABLE);
    int numTasks = 0;
    for (String tasks = _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE);
        tasks != null; tasks =
        _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE), numTasks++) {
      assertEquals(_helixTaskResourceManager.getTaskConfigs(tasks).size(), 1);
      assertTrue(_helixTaskResourceManager.getTaskQueues()
          .contains(PinotHelixTaskResourceManager.getHelixJobQueueName(MinionConstants.MergeRollupTask.TASK_TYPE)));
      // Will not schedule task if there's incomplete task
      assertNull(
          _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.RealtimeToOfflineSegmentsTask.TASK_TYPE));
      waitForTaskToComplete();

      // Check watermark
      MergeRollupTaskMetadata minionTaskMetadata = MergeRollupTaskMetadata
          .fromZNRecord(_taskManager.getClusterInfoAccessor().getMinionMergeRollupTaskZNRecord(offlineTableName));
      assertNotNull(minionTaskMetadata);
      assertEquals((long) minionTaskMetadata.getWatermarkMap().get(""150days""), expectedWatermark);
      expectedWatermark += 150 * 86_400_000L;

      // Check metadata of merged segments
      for (SegmentZKMetadata metadata : _pinotHelixResourceManager.getSegmentsZKMetadata(offlineTableName)) {
        if (metadata.getSegmentName().startsWith(""merged"")) {
          // Check merged segment zk metadata
          assertNotNull(metadata.getCustomMap());
          assertEquals(""150days"",
              metadata.getCustomMap().get(MinionConstants.MergeRollupTask.SEGMENT_ZK_METADATA_MERGE_LEVEL_KEY));
          // Check merged segments are time partitioned
          assertEquals(metadata.getEndTimeMs() / (86_400_000L * 150), metadata.getStartTimeMs() / (86_400_000L * 150));
        }
      }

      // Check total doc of merged segments are less than the original segments
      JsonNode actualJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
      assertTrue(
          actualJson.get(""resultTable"").get(""rows"").get(0).get(0).asInt() < expectedJson.get(""resultTable"").get(""rows"")
              .get(0).get(0).asInt());
      // Check query routing
      int numSegmentsQueried = actualJson.get(""numSegmentsQueried"").asInt();
      assertEquals(numSegmentsQueried, expectedNumSegmentsQueried[numTasks]);
    }

    // Check total doc is half of the original after all merge tasks are finished
    JsonNode actualJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    assertEquals(actualJson.get(""resultTable"").get(""rows"").get(0).get(0).asInt(),
        expectedJson.get(""resultTable"").get(""rows"").get(0).get(0).asInt() / 2);
    // Check time column is rounded
    JsonNode responseJson =
        postSqlQuery(""SELECT count(*), DaysSinceEpoch FROM myTable2 GROUP BY DaysSinceEpoch ORDER BY DaysSinceEpoch"");
    for (int i = 0; i < responseJson.get(""resultTable"").get(""rows"").size(); i++) {
      int daysSinceEpoch = responseJson.get(""resultTable"").get(""rows"").get(i).get(1).asInt();
      assertTrue(daysSinceEpoch % 7 == 0);
    }
    // Check total tasks
    assertEquals(numTasks, 3);

    assertTrue(_controllerStarter.getControllerMetrics()
        .containsGauge(""mergeRollupTaskDelayInNumBuckets.myTable2_OFFLINE.150days""));
  }
"
"  @Test
  public void testMultiLevelConcat()
      throws Exception {
    // The original segments are time partitioned by month:
    // segmentName (totalDocs)
    // myTable3_16071_16101_3 (9746)
    // myTable3_16102_16129_4 (8690)
    // myTable3_16130_16159_5 (9621)
    // myTable3_16160_16189_6 (9454)
    // myTable3_16190_16220_7 (10329)
    // myTable3_16221_16250_8 (10468)
    // myTable3_16251_16281_9 (10499)
    // myTable3_16282_16312_10 (10196)
    // myTable3_16313_16342_11 (9136)
    // myTable3_16343_16373_0 (9292)
    // myTable3_16374_16404_1 (8736)
    // myTable3_16405_16435_2 (9378)

    // Expected merge tasks and results:
    // 1.
    //    45days: {myTable3_16071_16101_3, myTable3_16102_16129_4}
    //      -> {merged_45days_T1_0_myTable3_16071_16109_0, merged_45days_T1_0_myTable3_16110_16129_1}
    //    watermark: {45days: 16065, 90days: null}
    // 2.
    //    45days: {merged_45days_T1_0_myTable3_16110_16129_1, myTable3_16130_16159_5}
    //      -> {merged_45days_T2_0_myTable3_16110_16154_0, merged_45days_T2_0_myTable3_16155_16159_1}
    //    90days: {merged_45days_T1_0_myTable3_16071_16109_0}
    //      -> {merged_90days_T2_0_myTable3_16071_16109_0}
    //    watermark: {45days: 16110, 90days: 16020}
    // 3.
    //    45days: {merged_45days_T2_0_myTable3_16155_16159_1, myTable3_16160_16189_6, myTable3_16190_16220_7}
    //      -> {merged_45days_T3_0_myTable3_16155_16199_0, merged_45days_T3_0_myTable3_16200_16220_1}
    //    watermark: {45days: 16155, 90days: 16020}
    // 4.
    //    45days: {merged_45days_T3_-_myTable3_16200_16220_1, myTable3_16221_16250_8}
    //      -> {merged_45days_T4_0_myTable3_16200_16244_0, merged_45days_T4_0_myTable3_16245_16250_1}
    //    90days: {merged_45days_T2_0_myTable3_16110_16154_0, merged_45days_T3_0_myTable3_16155_16199_0}
    //      -> {merged_90days_T4_0_myTable3_16110_16199_0}
    //    watermark: {45days: 16200, 90days: 16110}
    // 5.
    //    45days: {merged_45days_T4_0_myTable3_16245_16250_1, myTable3_16251_16281_9, myTable3_16282_16312_10}
    //      -> {merged_45days_T5_0_myTable3_16245_16289_0, merged_45days_T5_0_myTable3_16290_16312_1}
    //    watermark: {45days: 16245, 90days: 16110}
    // 6.
    //    45days: {merged_45days_T5_0_myTable3_16290_16312_1, myTable3_16313_16342_11}
    //      -> {merged_45days_T6_0_myTable3_16290_16334_0, merged_45days_T6_0_myTable3_16335_16342_1}
    //    90days: {merged_45days_T4_0_myTable3_16200_16244_0, merged_45days_T5_0_myTable3_16245_16289_0}
    //      -> {merged_90days_T6_0_myTable3_16200_16289_0}
    //    watermark: {45days: 16290, 90days: 16200}
    // 7.
    //    45days: {merged_45days_T6_0_myTable3_16335_16342_1, myTable_16343_16373_0, myTable_16374_16404_1}
    //      -> {merged_45days_T7_0_myTable3_16335_16379_0, merged_45days_T7_0_myTable3_16380_16404_1}
    //    watermark: {45days: 16335, 90days: 16200}
    // 8.
    //    45days: {merged_45days_T7_0_myTable3_16380_16404_1, myTable3_16405_16435_2}
    //      -> {merged_45days_T8_0_myTable3_16380_16424_0, merged_45days_T8_1_myTable3_16425_16435_1}
    //    90days: {merged_45days_T6_0_myTable3_16290_16334_0, merged_45days_T7_0_myTable3_16335_16379_0}
    //      -> {merged_90days_T8_0_myTable3_16290_16379_0}
    //    watermark: {45days:16380, 90days: 16290}
    // 9.
    //    45days: no segment left, not scheduling
    //    90days: [16380, 16470) is not a valid merge window because windowEndTime > 45days watermark, not scheduling

    String sqlQuery = ""SELECT count(*) FROM myTable3""; // 115545 rows for the test table
    JsonNode expectedJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    int[] expectedNumSubTasks = {1, 2, 1, 2, 1, 2, 1, 2, 1};
    int[] expectedNumSegmentsQueried = {12, 12, 11, 10, 9, 8, 7, 6, 5};
    Long[] expectedWatermarks45Days = {16065L, 16110L, 16155L, 16200L, 16245L, 16290L, 16335L, 16380L};
    Long[] expectedWatermarks90Days = {null, 16020L, 16020L, 16110L, 16110L, 16200L, 16200L, 16290L};
    for (int i = 0; i < expectedWatermarks45Days.length; i++) {
      expectedWatermarks45Days[i] *= 86_400_000L;
    }
    for (int i = 1; i < expectedWatermarks90Days.length; i++) {
      expectedWatermarks90Days[i] *= 86_400_000L;
    }

    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(MULTI_LEVEL_CONCAT_TEST_TABLE);
    int numTasks = 0;
    for (String tasks = _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE);
        tasks != null; tasks =
        _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE), numTasks++) {
      assertEquals(_helixTaskResourceManager.getTaskConfigs(tasks).size(), expectedNumSubTasks[numTasks]);
      assertTrue(_helixTaskResourceManager.getTaskQueues()
          .contains(PinotHelixTaskResourceManager.getHelixJobQueueName(MinionConstants.MergeRollupTask.TASK_TYPE)));
      // Will not schedule task if there's incomplete task
      assertNull(
          _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.RealtimeToOfflineSegmentsTask.TASK_TYPE));
      waitForTaskToComplete();

      // Check watermark
      MergeRollupTaskMetadata minionTaskMetadata = MergeRollupTaskMetadata
          .fromZNRecord(_taskManager.getClusterInfoAccessor().getMinionMergeRollupTaskZNRecord(offlineTableName));
      assertNotNull(minionTaskMetadata);
      assertEquals(minionTaskMetadata.getWatermarkMap().get(""45days""), expectedWatermarks45Days[numTasks]);
      assertEquals(minionTaskMetadata.getWatermarkMap().get(""90days""), expectedWatermarks90Days[numTasks]);

      // Check metadata of merged segments
      for (SegmentZKMetadata metadata : _pinotHelixResourceManager.getSegmentsZKMetadata(offlineTableName)) {
        if (metadata.getSegmentName().startsWith(""merged"")) {
          // Check merged segment zk metadata
          assertNotNull(metadata.getCustomMap());
          if (metadata.getSegmentName().startsWith(""merged_45days"")) {
            assertEquals(""45days"",
                metadata.getCustomMap().get(MinionConstants.MergeRollupTask.SEGMENT_ZK_METADATA_MERGE_LEVEL_KEY));
            assertEquals(metadata.getEndTimeMs() / (86_400_000L * 45), metadata.getStartTimeMs() / (86_400_000L * 45));
          }
          if (metadata.getSegmentName().startsWith(""merged_90days"")) {
            assertEquals(""90days"",
                metadata.getCustomMap().get(MinionConstants.MergeRollupTask.SEGMENT_ZK_METADATA_MERGE_LEVEL_KEY));
            assertEquals(metadata.getEndTimeMs() / (86_400_000L * 90), metadata.getStartTimeMs() / (86_400_000L * 90));
          }
        }
      }

      // Check total doc of merged segments are the same as the original segments
      JsonNode actualJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
      SqlResultComparator.areEqual(actualJson, expectedJson, sqlQuery);
      // Check query routing
      int numSegmentsQueried = actualJson.get(""numSegmentsQueried"").asInt();
      assertEquals(numSegmentsQueried, expectedNumSegmentsQueried[numTasks]);
    }
    // Check total tasks
    assertEquals(numTasks, 8);

    assertTrue(_controllerStarter.getControllerMetrics()
        .containsGauge(""mergeRollupTaskDelayInNumBuckets.myTable3_OFFLINE.45days""));
    assertTrue(_controllerStarter.getControllerMetrics()
        .containsGauge(""mergeRollupTaskDelayInNumBuckets.myTable3_OFFLINE.90days""));
  }
"
"  @Test
  public void testInstancesStarted() {
    assertEquals(_serviceStatusCallbacks.size(), getNumBrokers() + getNumServers());
    for (ServiceStatus.ServiceStatusCallback serviceStatusCallback : _serviceStatusCallbacks) {
      assertEquals(serviceStatusCallback.getServiceStatus(), ServiceStatus.Status.GOOD);
    }
  }
"
"  @Test
  public void testInvalidTableConfig() {
    TableConfig tableConfig = new TableConfigBuilder(TableType.OFFLINE).setTableName(""badTable"").build();
    ObjectNode tableConfigJson = (ObjectNode) tableConfig.toJsonNode();
    // Remove a mandatory field
    tableConfigJson.remove(TableConfig.VALIDATION_CONFIG_KEY);
    try {
      sendPostRequest(_controllerRequestURLBuilder.forTableCreate(), tableConfigJson.toString());
      fail();
    } catch (IOException e) {
      // Should get response code 400 (BAD_REQUEST)
      assertTrue(e.getMessage().startsWith(""Server returned HTTP response code: 400""));
    }
  }
"
"  @Test
  public void testRefreshTableConfigAndQueryTimeout()
      throws Exception {
    // Set timeout as 5ms so that query will timeout
    TableConfig tableConfig = getOfflineTableConfig();
    tableConfig.setQueryConfig(new QueryConfig(5L));
    updateTableConfig(tableConfig);

    // Wait for at most 1 minute for broker to receive and process the table config refresh message
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_TIMEOUT_QUERY);
        JsonNode exceptions = queryResponse.get(""exceptions"");
        if (exceptions.isEmpty()) {
          return false;
        }
        int errorCode = exceptions.get(0).get(""errorCode"").asInt();
        if (errorCode == QueryException.BROKER_TIMEOUT_ERROR_CODE) {
          // Timed out on broker side
          return true;
        }
        if (errorCode == QueryException.SERVER_NOT_RESPONDING_ERROR_CODE) {
          // Timed out on server side
          int numServersQueried = queryResponse.get(""numServersQueried"").asInt();
          int numServersResponded = queryResponse.get(""numServersResponded"").asInt();
          int numDocsScanned = queryResponse.get(""numDocsScanned"").asInt();
          return numServersQueried == getNumServers() && numServersResponded == 0 && numDocsScanned == 0;
        }
        return false;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 60_000L, ""Failed to refresh table config"");

    // Remove timeout so that query will finish
    tableConfig.setQueryConfig(null);
    updateTableConfig(tableConfig);

    // Wait for at most 1 minute for broker to receive and process the table config refresh message
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_TIMEOUT_QUERY);
        JsonNode exceptions = queryResponse.get(""exceptions"");
        if (!exceptions.isEmpty()) {
          return false;
        }
        int numServersQueried = queryResponse.get(""numServersQueried"").asInt();
        int numServersResponded = queryResponse.get(""numServersResponded"").asInt();
        int numDocsScanned = queryResponse.get(""numDocsScanned"").asInt();
        return numServersQueried == getNumServers() && numServersResponded == getNumServers()
            && numDocsScanned == getCountStarResult();
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 60_000L, ""Failed to refresh table config"");
  }
"
"  @Test
  public void testUploadSameSegments()
      throws Exception {
    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(getTableName());
    SegmentZKMetadata segmentZKMetadata = _helixResourceManager.getSegmentsZKMetadata(offlineTableName).get(0);
    String segmentName = segmentZKMetadata.getSegmentName();
    long crc = segmentZKMetadata.getCrc();
    // Creation time is when the segment gets created
    long creationTime = segmentZKMetadata.getCreationTime();
    // Push time is when the segment gets first pushed (new segment)
    long pushTime = segmentZKMetadata.getPushTime();
    // Refresh time is when the segment gets refreshed (existing segment)
    long refreshTime = segmentZKMetadata.getRefreshTime();

    uploadSegments(offlineTableName, _tarDir);
    for (SegmentZKMetadata segmentZKMetadataAfterUpload : _helixResourceManager
        .getSegmentsZKMetadata(offlineTableName)) {
      // Only check one segment
      if (segmentZKMetadataAfterUpload.getSegmentName().equals(segmentName)) {
        assertEquals(segmentZKMetadataAfterUpload.getCrc(), crc);
        assertEquals(segmentZKMetadataAfterUpload.getCreationTime(), creationTime);
        assertEquals(segmentZKMetadataAfterUpload.getPushTime(), pushTime);
        // Refresh time should change
        assertTrue(segmentZKMetadataAfterUpload.getRefreshTime() > refreshTime);
        return;
      }
    }
  }
"
"  @Test
  public void testUploadSegmentRefreshOnly()
      throws Exception {
    TableConfig segmentUploadTestTableConfig =
        new TableConfigBuilder(TableType.OFFLINE).setTableName(SEGMENT_UPLOAD_TEST_TABLE).setSchemaName(getSchemaName())
            .setTimeColumnName(getTimeColumnName()).setSortedColumn(getSortedColumn())
            .setInvertedIndexColumns(getInvertedIndexColumns()).setNoDictionaryColumns(getNoDictionaryColumns())
            .setRangeIndexColumns(getRangeIndexColumns()).setBloomFilterColumns(getBloomFilterColumns())
            .setFieldConfigList(getFieldConfigs()).setNumReplicas(getNumReplicas())
            .setSegmentVersion(getSegmentVersion())
            .setLoadMode(getLoadMode()).setTaskConfig(getTaskConfig()).setBrokerTenant(getBrokerTenant())
            .setServerTenant(getServerTenant()).setIngestionConfig(getIngestionConfig())
            .setNullHandlingEnabled(getNullHandlingEnabled()).build();
    addTableConfig(segmentUploadTestTableConfig);
    String offlineTableName = segmentUploadTestTableConfig.getTableName();
    File[] segmentTarFiles = _tarDir.listFiles();
    assertNotNull(segmentTarFiles);
    int numSegments = segmentTarFiles.length;
    assertTrue(numSegments > 0);
    List<Header> headers = new ArrayList<>();
    headers.add(new BasicHeader(FileUploadDownloadClient.CustomHeaders.REFRESH_ONLY, ""true""));
    List<NameValuePair> parameters = new ArrayList<>();
    NameValuePair tableNameParameter = new BasicNameValuePair(FileUploadDownloadClient.QueryParameters.TABLE_NAME,
        TableNameBuilder.extractRawTableName(offlineTableName));
    parameters.add(tableNameParameter);

    URI uploadSegmentHttpURI = FileUploadDownloadClient.getUploadSegmentHttpURI(LOCAL_HOST, _controllerPort);
    try (FileUploadDownloadClient fileUploadDownloadClient = new FileUploadDownloadClient()) {
      // Refresh non-existing segment
      File segmentTarFile = segmentTarFiles[0];
      try {
        fileUploadDownloadClient
            .uploadSegment(uploadSegmentHttpURI, segmentTarFile.getName(), segmentTarFile, headers, parameters,
                FileUploadDownloadClient.DEFAULT_SOCKET_TIMEOUT_MS);
        fail();
      } catch (HttpErrorStatusException e) {
        assertEquals(e.getStatusCode(), HttpStatus.SC_GONE);
        assertTrue(_helixResourceManager.getSegmentsZKMetadata(SEGMENT_UPLOAD_TEST_TABLE).isEmpty());
      }

      // Upload segment
      SimpleHttpResponse response = fileUploadDownloadClient
          .uploadSegment(uploadSegmentHttpURI, segmentTarFile.getName(), segmentTarFile, null, parameters,
              FileUploadDownloadClient.DEFAULT_SOCKET_TIMEOUT_MS);
      assertEquals(response.getStatusCode(), HttpStatus.SC_OK);
      System.out.println(response.getResponse());
      List<SegmentZKMetadata> segmentsZKMetadata = _helixResourceManager.getSegmentsZKMetadata(offlineTableName);
      assertEquals(segmentsZKMetadata.size(), 1);

      // Refresh existing segment
      response = fileUploadDownloadClient
          .uploadSegment(uploadSegmentHttpURI, segmentTarFile.getName(), segmentTarFile, headers, parameters,
              FileUploadDownloadClient.DEFAULT_SOCKET_TIMEOUT_MS);
      assertEquals(response.getStatusCode(), HttpStatus.SC_OK);
      segmentsZKMetadata = _helixResourceManager.getSegmentsZKMetadata(offlineTableName);
      assertEquals(segmentsZKMetadata.size(), 1);
      assertNotEquals(segmentsZKMetadata.get(0).getRefreshTime(), Long.MIN_VALUE);
    }
    dropOfflineTable(SEGMENT_UPLOAD_TEST_TABLE);
  }
"
"  @Test(dependsOnMethods = ""testRangeIndexTriggering"")
  public void testInvertedIndexTriggering()
      throws Exception {
    long numTotalDocs = getCountStarResult();

    // Without index on DivActualElapsedTime, all docs are scanned at filtering stage.
    assertEquals(postQuery(TEST_UPDATED_INVERTED_INDEX_QUERY).get(""numEntriesScannedInFilter"").asLong(), numTotalDocs);

    addInvertedIndex();
    long tableSizeWithNewIndex = getTableSize(getTableName());

    // Update table config to remove the new inverted index, and
    // reload table to clean the new inverted indices physically.
    TableConfig tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setInvertedIndexColumns(getInvertedIndexColumns());
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_INVERTED_INDEX_QUERY);
        // Total docs should not change during reload, but num entries scanned
        // gets back to total number of documents as the index is removed.
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numEntriesScannedInFilter"").asLong() == numTotalDocs;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to cleanup obsolete index"");
    assertEquals(getTableSize(getTableName()), _tableSizeAfterRemovingIndex);

    // Add the inverted index back to test index removal via force download.
    addInvertedIndex();
    long tableSizeAfterAddingIndexAgain = getTableSize(getTableName());
    assertEquals(tableSizeAfterAddingIndexAgain, tableSizeWithNewIndex);

    // Update table config to remove the new inverted index.
    tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setInvertedIndexColumns(getInvertedIndexColumns());
    updateTableConfig(tableConfig);

    // Force to download a single segment, and disk usage should drop a bit.
    SegmentZKMetadata segmentZKMetadata =
        _helixResourceManager.getSegmentsZKMetadata(TableNameBuilder.OFFLINE.tableNameWithType(getTableName())).get(0);
    String segmentName = segmentZKMetadata.getSegmentName();
    reloadOfflineSegment(getTableName(), segmentName, true);
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_INVERTED_INDEX_QUERY);
        // Total docs should not change during reload
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return getTableSize(getTableName()) < tableSizeAfterAddingIndexAgain;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to clean up obsolete index in segment"");

    // Force to download the whole table and expect disk usage drops further.
    reloadOfflineTable(getTableName(), true);
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_INVERTED_INDEX_QUERY);
        // Total docs should not change during reload, but num entries scanned
        // gets back to total number of documents as the index is removed.
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numEntriesScannedInFilter"").asLong() == numTotalDocs;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to cleanup obsolete index in table"");
    // With force download, the table size gets back to the initial value.
    assertEquals(getTableSize(getTableName()), DISK_SIZE_IN_BYTES);
  }
"
"  @Test
  public void testTimeFunc()
      throws Exception {
    String sqlQuery = ""SELECT toDateTime(now(), 'yyyy-MM-dd z'), toDateTime(ago('PT1H'), 'yyyy-MM-dd z') FROM mytable"";
    JsonNode response = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    String todayStr = response.get(""resultTable"").get(""rows"").get(0).get(0).asText();
    String expectedTodayStr =
        Instant.now().atZone(ZoneId.of(""UTC"")).format(DateTimeFormatter.ofPattern(""yyyy-MM-dd z""));
    assertEquals(todayStr, expectedTodayStr);

    String oneHourAgoTodayStr = response.get(""resultTable"").get(""rows"").get(0).get(1).asText();
    String expectedOneHourAgoTodayStr = Instant.now().minus(Duration.parse(""PT1H"")).atZone(ZoneId.of(""UTC""))
        .format(DateTimeFormatter.ofPattern(""yyyy-MM-dd z""));
    assertEquals(oneHourAgoTodayStr, expectedOneHourAgoTodayStr);
  }
"
"  @Test
  public void testLiteralOnlyFunc()
      throws Exception {
    long currentTsMin = System.currentTimeMillis();
    long oneHourAgoTsMin = currentTsMin - ONE_HOUR_IN_MS;
    String sqlQuery =
        ""SELECT 1, now() as currentTs, ago('PT1H') as oneHourAgoTs, 'abc', toDateTime(now(), 'yyyy-MM-dd z') as ""
            + ""today, now(), ago('PT1H')"";
    JsonNode response = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    long currentTsMax = System.currentTimeMillis();
    long oneHourAgoTsMax = currentTsMax - ONE_HOUR_IN_MS;

    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(0).asText(), ""1"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(1).asText(), ""currentTs"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(2).asText(), ""oneHourAgoTs"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(3).asText(), ""abc"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(4).asText(), ""today"");
    String nowColumnName = response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(5).asText();
    String oneHourAgoColumnName = response.get(""resultTable"").get(""dataSchema"").get(""columnNames"").get(6).asText();
    assertTrue(Long.parseLong(nowColumnName) > currentTsMin);
    assertTrue(Long.parseLong(nowColumnName) < currentTsMax);
    assertTrue(Long.parseLong(oneHourAgoColumnName) > oneHourAgoTsMin);
    assertTrue(Long.parseLong(oneHourAgoColumnName) < oneHourAgoTsMax);

    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(0).asText(), ""LONG"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(1).asText(), ""LONG"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(2).asText(), ""LONG"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(3).asText(), ""STRING"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(4).asText(), ""STRING"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(5).asText(), ""LONG"");
    assertEquals(response.get(""resultTable"").get(""dataSchema"").get(""columnDataTypes"").get(6).asText(), ""LONG"");

    int first = response.get(""resultTable"").get(""rows"").get(0).get(0).asInt();
    long second = response.get(""resultTable"").get(""rows"").get(0).get(1).asLong();
    long third = response.get(""resultTable"").get(""rows"").get(0).get(2).asLong();
    String fourth = response.get(""resultTable"").get(""rows"").get(0).get(3).asText();
    assertEquals(first, 1);
    assertTrue(second > currentTsMin);
    assertTrue(second < currentTsMax);
    assertTrue(third > oneHourAgoTsMin);
    assertTrue(third < oneHourAgoTsMax);
    assertEquals(fourth, ""abc"");
    String todayStr = response.get(""resultTable"").get(""rows"").get(0).get(4).asText();
    String expectedTodayStr =
        Instant.now().atZone(ZoneId.of(""UTC"")).format(DateTimeFormatter.ofPattern(""yyyy-MM-dd z""));
    assertEquals(todayStr, expectedTodayStr);
    long nowValue = response.get(""resultTable"").get(""rows"").get(0).get(5).asLong();
    assertEquals(nowValue, Long.parseLong(nowColumnName));
    long oneHourAgoValue = response.get(""resultTable"").get(""rows"").get(0).get(6).asLong();
    assertEquals(oneHourAgoValue, Long.parseLong(oneHourAgoColumnName));
  }
"
"  @Test(dependsOnMethods = ""testBloomFilterTriggering"")
  public void testRangeIndexTriggering()
      throws Exception {
    long numTotalDocs = getCountStarResult();
    assertEquals(postQuery(TEST_UPDATED_RANGE_INDEX_QUERY).get(""numEntriesScannedInFilter"").asLong(), numTotalDocs);

    // Update table config and trigger reload
    TableConfig tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setRangeIndexColumns(UPDATED_RANGE_INDEX_COLUMNS);
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_RANGE_INDEX_QUERY);
        // Total docs should not change during reload
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numEntriesScannedInFilter"").asLong() < numTotalDocs;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to generate range index"");

    // Update table config to remove the new range index, and
    // reload table to clean the new range index physically.
    tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setRangeIndexColumns(getRangeIndexColumns());
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_RANGE_INDEX_QUERY);
        // Total docs should not change during reload, but num entries scanned
        // gets back to total number of documents as the index is removed.
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numEntriesScannedInFilter"").asLong() == numTotalDocs;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to cleanup obsolete index"");

    assertEquals(getTableSize(getTableName()), _tableSizeAfterRemovingIndex);
  }
"
"  @Test(dependsOnMethods = ""testDefaultColumns"")
  public void testBloomFilterTriggering()
      throws Exception {
    long numTotalDocs = getCountStarResult();
    assertEquals(postQuery(TEST_UPDATED_BLOOM_FILTER_QUERY).get(""numSegmentsProcessed"").asLong(), NUM_SEGMENTS);

    // Update table config and trigger reload
    TableConfig tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setBloomFilterColumns(UPDATED_BLOOM_FILTER_COLUMNS);
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_BLOOM_FILTER_QUERY);
        // Total docs should not change during reload
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numSegmentsProcessed"").asLong() == 0L;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to generate bloom filter"");

    // Update table config to remove the new bloom filter, and
    // reload table to clean the new bloom filter physically.
    tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setBloomFilterColumns(getBloomFilterColumns());
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_BLOOM_FILTER_QUERY);
        // Total docs should not change during reload, but num entries scanned
        // gets back to total number of documents as bloom filter is removed.
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numSegmentsProcessed"").asLong() == NUM_SEGMENTS;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to cleanup obsolete index"");
    assertEquals(getTableSize(getTableName()), _tableSizeAfterRemovingIndex);
  }
"
"  @Test
  public void testServerErrorWithBrokerTimeout()
      throws Exception {
    // Set query timeout
    long queryTimeout = 5000;
    TableConfig tableConfig = getOfflineTableConfig();
    tableConfig.setQueryConfig(new QueryConfig(queryTimeout));
    updateTableConfig(tableConfig);

    long startTime = System.currentTimeMillis();
    // The query below will fail execution due to JSON_MATCH on column without json index
    JsonNode queryResponse = postSqlQuery(""SELECT count(*) FROM mytable WHERE JSON_MATCH(Dest, '$=123')"");

    assertTrue(System.currentTimeMillis() - startTime < queryTimeout);
    assertTrue(queryResponse.get(""exceptions"").get(0).get(""message"").toString().startsWith(""\""QueryExecutionError""));

    // Remove timeout
    tableConfig.setQueryConfig(null);
    updateTableConfig(tableConfig);
  }
"
"  @Test
  public void testStarTreeTriggering()
      throws Exception {
    long numTotalDocs = getCountStarResult();
    long tableSizeWithDefaultIndex = getTableSize(getTableName());

    // Test the first query
    JsonNode firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
    int firstQueryResult = firstQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt();
    assertEquals(firstQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    // Initially 'numDocsScanned' should be the same as 'COUNT(*)' result
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), firstQueryResult);

    // Update table config and trigger reload
    TableConfig tableConfig = getOfflineTableConfig();
    IndexingConfig indexingConfig = tableConfig.getIndexingConfig();
    indexingConfig.setStarTreeIndexConfigs(Collections.singletonList(STAR_TREE_INDEX_CONFIG_1));
    indexingConfig.setEnableDynamicStarTreeCreation(true);
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());

    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
        // Result should not change during reload
        assertEquals(queryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), firstQueryResult);
        // Total docs should not change during reload
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        // With star-tree, 'numDocsScanned' should be the same as number of segments (1 per segment)
        return queryResponse.get(""numDocsScanned"").asInt() == NUM_SEGMENTS;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to add first star-tree index"");

    // Reload again should have no effect
    reloadOfflineTable(getTableName());
    firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
    assertEquals(firstQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), firstQueryResult);
    assertEquals(firstQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), NUM_SEGMENTS);

    // Should be able to use the star-tree with an additional match-all predicate on another dimension
    firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1 + "" AND DaysSinceEpoch > 16070"");
    assertEquals(firstQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), firstQueryResult);
    assertEquals(firstQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), NUM_SEGMENTS);

    // Test the second query
    JsonNode secondQueryResponse = postQuery(TEST_STAR_TREE_QUERY_2);
    int secondQueryResult = secondQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt();
    assertEquals(secondQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    // Initially 'numDocsScanned' should be the same as 'COUNT(*)' result
    assertEquals(secondQueryResponse.get(""numDocsScanned"").asInt(), secondQueryResult);

    // Update table config with a different star-tree index config and trigger reload
    indexingConfig.setStarTreeIndexConfigs(Collections.singletonList(STAR_TREE_INDEX_CONFIG_2));
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());

    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_STAR_TREE_QUERY_2);
        // Result should not change during reload
        assertEquals(queryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), secondQueryResult);
        // Total docs should not change during reload
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        // With star-tree, 'numDocsScanned' should be the same as number of segments (1 per segment)
        return queryResponse.get(""numDocsScanned"").asInt() == NUM_SEGMENTS;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to change to second star-tree index"");

    // First query should not be able to use the star-tree
    firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), firstQueryResult);

    // Reload again should have no effect
    reloadOfflineTable(getTableName());
    firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
    assertEquals(firstQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), firstQueryResult);
    assertEquals(firstQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), firstQueryResult);
    secondQueryResponse = postQuery(TEST_STAR_TREE_QUERY_2);
    assertEquals(secondQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), secondQueryResult);
    assertEquals(secondQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(secondQueryResponse.get(""numDocsScanned"").asInt(), NUM_SEGMENTS);

    // Should be able to use the star-tree with an additional match-all predicate on another dimension
    secondQueryResponse = postQuery(TEST_STAR_TREE_QUERY_2 + "" AND DaysSinceEpoch > 16070"");
    assertEquals(secondQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), secondQueryResult);
    assertEquals(secondQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(secondQueryResponse.get(""numDocsScanned"").asInt(), NUM_SEGMENTS);

    // Remove the star-tree index config and trigger reload
    indexingConfig.setStarTreeIndexConfigs(null);
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());

    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_STAR_TREE_QUERY_2);
        // Result should not change during reload
        assertEquals(queryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), secondQueryResult);
        // Total docs should not change during reload
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        // Without star-tree, 'numDocsScanned' should be the same as the 'COUNT(*)' result
        return queryResponse.get(""numDocsScanned"").asInt() == secondQueryResult;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to remove star-tree index"");
    assertEquals(getTableSize(getTableName()), tableSizeWithDefaultIndex);

    // First query should not be able to use the star-tree
    firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), firstQueryResult);

    // Reload again should have no effect
    reloadOfflineTable(getTableName());
    firstQueryResponse = postQuery(TEST_STAR_TREE_QUERY_1);
    assertEquals(firstQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), firstQueryResult);
    assertEquals(firstQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(firstQueryResponse.get(""numDocsScanned"").asInt(), firstQueryResult);
    secondQueryResponse = postQuery(TEST_STAR_TREE_QUERY_2);
    assertEquals(secondQueryResponse.get(""aggregationResults"").get(0).get(""value"").asInt(), secondQueryResult);
    assertEquals(secondQueryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(secondQueryResponse.get(""numDocsScanned"").asInt(), secondQueryResult);
  }
"
"  @Test(dependsOnMethods = ""testAggregateMetadataAPI"")
  public void testDefaultColumns()
      throws Exception {
    long numTotalDocs = getCountStarResult();

    reloadWithExtraColumns();
    JsonNode queryResponse = postQuery(SELECT_STAR_QUERY);
    assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(queryResponse.get(""selectionResults"").get(""columns"").size(), 91);

    testNewAddedColumns();

    reloadWithMissingColumns();
    queryResponse = postQuery(SELECT_STAR_QUERY);
    assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(queryResponse.get(""selectionResults"").get(""columns"").size(), 75);

    reloadWithRegularColumns();
    queryResponse = postQuery(SELECT_STAR_QUERY);
    assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(queryResponse.get(""selectionResults"").get(""columns"").size(), 79);

    _tableSizeAfterRemovingIndex = getTableSize(getTableName());
  }
"
"  @Test
  public void testBrokerResponseMetadata()
      throws Exception {
    super.testBrokerResponseMetadata();
  }
"
"  @Test
  public void testGroupByUDF()
      throws Exception {
    String pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY timeConvert(DaysSinceEpoch,'DAYS','SECONDS')"";
    JsonNode response = postQuery(pqlQuery);
    JsonNode groupByResult = response.get(""aggregationResults"").get(0);
    JsonNode groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 605.0);
    assertEquals(groupByEntry.get(""group"").get(0).asInt(), 16138 * 24 * 3600);
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""timeconvert(DaysSinceEpoch,'DAYS','SECONDS')"");

    pqlQuery =
        ""SELECT COUNT(*) FROM mytable GROUP BY dateTimeConvert(DaysSinceEpoch,'1:DAYS:EPOCH','1:HOURS:EPOCH',""
            + ""'1:HOURS')"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 605.0);
    assertEquals(groupByEntry.get(""group"").get(0).asInt(), 16138 * 24);
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(),
        ""datetimeconvert(DaysSinceEpoch,'1:DAYS:EPOCH','1:HOURS:EPOCH','1:HOURS')"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY add(DaysSinceEpoch,DaysSinceEpoch,15)"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 605.0);
    assertEquals(groupByEntry.get(""group"").get(0).asDouble(), 16138.0 + 16138 + 15);
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""add(DaysSinceEpoch,DaysSinceEpoch,'15')"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY sub(DaysSinceEpoch,25)"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 605.0);
    assertEquals(groupByEntry.get(""group"").get(0).asDouble(), 16138.0 - 25);
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""sub(DaysSinceEpoch,'25')"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY mult(DaysSinceEpoch,24,3600)"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 605.0);
    assertEquals(groupByEntry.get(""group"").get(0).asDouble(), 16138.0 * 24 * 3600);
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""mult(DaysSinceEpoch,'24','3600')"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY div(DaysSinceEpoch,2)"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 605.0);
    assertEquals(groupByEntry.get(""group"").get(0).asDouble(), 16138.0 / 2);
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""div(DaysSinceEpoch,'2')"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY arrayLength(DivAirports)"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 115545.0);
    assertEquals(groupByEntry.get(""group"").get(0).asText(), ""5"");
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""arraylength(DivAirports)"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY arrayLength(valueIn(DivAirports,'DFW','ORD'))"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 114895.0);
    assertEquals(groupByEntry.get(""group"").get(0).asText(), ""0"");
    groupByEntry = groupByResult.get(""groupByResult"").get(1);
    assertEquals(groupByEntry.get(""value"").asDouble(), 648.0);
    assertEquals(groupByEntry.get(""group"").get(0).asText(), ""1"");
    groupByEntry = groupByResult.get(""groupByResult"").get(2);
    assertEquals(groupByEntry.get(""value"").asDouble(), 2.0);
    assertEquals(groupByEntry.get(""group"").get(0).asText(), ""2"");
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""arraylength(valuein(DivAirports,'DFW','ORD'))"");

    pqlQuery = ""SELECT COUNT(*) FROM mytable GROUP BY valueIn(DivAirports,'DFW','ORD')"";
    response = postQuery(pqlQuery);
    groupByResult = response.get(""aggregationResults"").get(0);
    groupByEntry = groupByResult.get(""groupByResult"").get(0);
    assertEquals(groupByEntry.get(""value"").asDouble(), 336.0);
    assertEquals(groupByEntry.get(""group"").get(0).asText(), ""ORD"");
    assertEquals(groupByResult.get(""groupByColumns"").get(0).asText(), ""valuein(DivAirports,'DFW','ORD')"");

    pqlQuery = ""SELECT MAX(timeConvert(DaysSinceEpoch,'DAYS','SECONDS')) FROM mytable"";
    response = postQuery(pqlQuery);
    JsonNode aggregationResult = response.get(""aggregationResults"").get(0);
    assertEquals(aggregationResult.get(""function"").asText(), ""max_timeconvert(DaysSinceEpoch,'DAYS','SECONDS')"");
    assertEquals(aggregationResult.get(""value"").asDouble(), 16435.0 * 24 * 3600);

    pqlQuery = ""SELECT MIN(div(DaysSinceEpoch,2)) FROM mytable"";
    response = postQuery(pqlQuery);
    aggregationResult = response.get(""aggregationResults"").get(0);
    assertEquals(aggregationResult.get(""function"").asText(), ""min_div(DaysSinceEpoch,'2')"");
    assertEquals(aggregationResult.get(""value"").asDouble(), 16071.0 / 2);
  }
"
"  @Test
  public void testAggregationUDF()
      throws Exception {

    String pqlQuery = ""SELECT MAX(timeConvert(DaysSinceEpoch,'DAYS','SECONDS')) FROM mytable"";
    JsonNode response = postQuery(pqlQuery);
    JsonNode aggregationResult = response.get(""aggregationResults"").get(0);
    assertEquals(aggregationResult.get(""function"").asText(), ""max_timeconvert(DaysSinceEpoch,'DAYS','SECONDS')"");
    assertEquals(aggregationResult.get(""value"").asDouble(), 16435.0 * 24 * 3600);

    pqlQuery = ""SELECT MIN(div(DaysSinceEpoch,2)) FROM mytable"";
    response = postQuery(pqlQuery);
    aggregationResult = response.get(""aggregationResults"").get(0);
    assertEquals(aggregationResult.get(""function"").asText(), ""min_div(DaysSinceEpoch,'2')"");
    assertEquals(aggregationResult.get(""value"").asDouble(), 16071.0 / 2);
  }
"
"  @Test
  public void testSelectionUDF()
      throws Exception {
    String pqlQuery = ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable"";
    JsonNode response = postQuery(pqlQuery);
    ArrayNode selectionResults = (ArrayNode) response.get(""selectionResults"").get(""results"");
    assertNotNull(selectionResults);
    assertFalse(selectionResults.isEmpty());
    for (int i = 0; i < selectionResults.size(); i++) {
      long daysSinceEpoch = selectionResults.get(i).get(0).asLong();
      long secondsSinceEpoch = selectionResults.get(i).get(1).asLong();
      assertEquals(daysSinceEpoch * 24 * 60 * 60, secondsSinceEpoch);
    }

    pqlQuery =
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by DaysSinceEpoch ""
            + ""limit 10000"";
    response = postQuery(pqlQuery);
    selectionResults = (ArrayNode) response.get(""selectionResults"").get(""results"");
    assertNotNull(selectionResults);
    assertFalse(selectionResults.isEmpty());
    long prevValue = -1;
    for (int i = 0; i < selectionResults.size(); i++) {
      long daysSinceEpoch = selectionResults.get(i).get(0).asLong();
      long secondsSinceEpoch = selectionResults.get(i).get(1).asLong();
      assertEquals(daysSinceEpoch * 24 * 60 * 60, secondsSinceEpoch);
      assertTrue(daysSinceEpoch >= prevValue);
      prevValue = daysSinceEpoch;
    }

    pqlQuery =
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by timeConvert""
            + ""(DaysSinceEpoch,'DAYS','SECONDS') DESC limit 10000"";
    response = postQuery(pqlQuery);
    selectionResults = (ArrayNode) response.get(""selectionResults"").get(""results"");
    assertNotNull(selectionResults);
    assertFalse(selectionResults.isEmpty());
    prevValue = Long.MAX_VALUE;
    for (int i = 0; i < selectionResults.size(); i++) {
      long daysSinceEpoch = selectionResults.get(i).get(0).asLong();
      long secondsSinceEpoch = selectionResults.get(i).get(1).asLong();
      assertEquals(daysSinceEpoch * 24 * 60 * 60, secondsSinceEpoch);
      assertTrue(secondsSinceEpoch <= prevValue);
      prevValue = secondsSinceEpoch;
    }
  }
"
"  @Test
  public void testFilterUDF()
      throws Exception {
    int daysSinceEpoch = 16138;
    long secondsSinceEpoch = 16138 * 24 * 60 * 60;

    String pqlQuery;
    pqlQuery = ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch = "" + daysSinceEpoch;
    long expectedResult = postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong();

    pqlQuery = ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch;
    assertEquals(postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResult);

    pqlQuery = ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch = "" + daysSinceEpoch
        + "" OR timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch;
    assertEquals(postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResult);

    pqlQuery = ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch = "" + daysSinceEpoch
        + "" AND timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch;
    assertEquals(postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResult);

    pqlQuery =
        ""SELECT count(*) FROM mytable WHERE DIV(timeConvert(DaysSinceEpoch,'DAYS','SECONDS'),1) = "" + secondsSinceEpoch;
    assertEquals(postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResult);

    pqlQuery = String
        .format(""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','SECONDS') IN (%d, %d)"",
            secondsSinceEpoch - 100, secondsSinceEpoch);
    assertEquals(postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResult);

    pqlQuery = String
        .format(""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','SECONDS') BETWEEN %d AND %d"",
            secondsSinceEpoch - 100, secondsSinceEpoch);
    assertEquals(postQuery(pqlQuery).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResult);
  }
"
"  @Test
  public void testCaseStatementInSelection()
      throws Exception {
    List<String> origins = Arrays
        .asList(""ATL"", ""ORD"", ""DFW"", ""DEN"", ""LAX"", ""IAH"", ""SFO"", ""PHX"", ""LAS"", ""EWR"", ""MCO"", ""BOS"", ""SLC"", ""SEA"", ""MSP"",
            ""CLT"", ""LGA"", ""DTW"", ""JFK"", ""BWI"");
    StringBuilder caseStatementBuilder = new StringBuilder(""CASE "");
    for (int i = 0; i < origins.size(); i++) {
      // WHEN origin = 'ATL' THEN 1
      // WHEN origin = 'ORD' THEN 2
      // WHEN origin = 'DFW' THEN 3
      // ....
      caseStatementBuilder.append(String.format(""WHEN origin = '%s' THEN %d "", origins.get(i), i + 1));
    }
    caseStatementBuilder.append(""ELSE 0 END"");
    String sqlQuery = ""SELECT origin, "" + caseStatementBuilder + "" AS origin_code FROM mytable LIMIT 1000"";
    JsonNode response = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    JsonNode rows = response.get(""resultTable"").get(""rows"");
    assertEquals(response.get(""exceptions"").size(), 0);
    for (int i = 0; i < rows.size(); i++) {
      String origin = rows.get(i).get(0).asText();
      int originCode = rows.get(i).get(1).asInt();
      if (originCode > 0) {
        assertEquals(origin, origins.get(originCode - 1));
      } else {
        assertFalse(origins.contains(origin));
      }
    }
  }
"
"  @Test
  public void testCaseStatementInSelectionWithTransformFunctionInThen()
      throws Exception {
    String sqlQuery =
        ""SELECT ArrDelay, CASE WHEN ArrDelay > 0 THEN ArrDelay WHEN ArrDelay < 0 THEN ArrDelay * -1 ELSE 0 END AS ""
            + ""ArrTimeDiff FROM mytable LIMIT 1000"";
    JsonNode response = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    JsonNode rows = response.get(""resultTable"").get(""rows"");
    assertEquals(response.get(""exceptions"").size(), 0);
    for (int i = 0; i < rows.size(); i++) {
      int arrDelay = rows.get(i).get(0).asInt();
      int arrDelayDiff = rows.get(i).get(1).asInt();
      if (arrDelay > 0) {
        assertEquals(arrDelay, arrDelayDiff);
      } else {
        assertEquals(arrDelay, arrDelayDiff * -1);
      }
    }
  }
"
"  @Test
  public void testCaseStatementWithLogicalTransformFunction()
      throws Exception {
    String sqlQuery = ""SELECT ArrDelay"" + "", CASE WHEN ArrDelay > 50 OR ArrDelay < 10 THEN 10 ELSE 0 END""
        + "", CASE WHEN ArrDelay < 50 AND ArrDelay >= 10 THEN 10 ELSE 0 END"" + "" FROM mytable LIMIT 1000"";
    JsonNode response = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    JsonNode rows = response.get(""resultTable"").get(""rows"");
    assertEquals(response.get(""exceptions"").size(), 0);
    for (int i = 0; i < rows.size(); i++) {
      int row0 = rows.get(i).get(0).asInt();
      int row1 = rows.get(i).get(1).asInt();
      int row2 = rows.get(i).get(2).asInt();
      if (row0 > 50 || row0 < 10) {
        assertEquals(row1, 10);
      } else {
        assertEquals(row1, 0);
      }
      if (row0 < 50 && row0 >= 10) {
        assertEquals(row2, 10);
      } else {
        assertEquals(row2, 0);
      }
    }
  }
"
"  @Test
  public void testCaseStatementWithInAggregation()
      throws Exception {
    testCountVsCaseQuery(""origin = 'ATL'"");
    testCountVsCaseQuery(""origin <> 'ATL'"");

    testCountVsCaseQuery(""DaysSinceEpoch > 16312"");
    testCountVsCaseQuery(""DaysSinceEpoch >= 16312"");
    testCountVsCaseQuery(""DaysSinceEpoch < 16312"");
    testCountVsCaseQuery(""DaysSinceEpoch <= 16312"");
    testCountVsCaseQuery(""DaysSinceEpoch = 16312"");
    testCountVsCaseQuery(""DaysSinceEpoch <> 16312"");
  }
"
"  @Test
  public void testFilterWithInvertedIndexUDF()
      throws Exception {
    int daysSinceEpoch = 16138;
    long secondsSinceEpoch = 16138 * 24 * 60 * 60;

    String[] origins = new String[]{
        ""ATL"", ""ORD"", ""DFW"", ""DEN"", ""LAX"", ""IAH"", ""SFO"", ""PHX"", ""LAS"", ""EWR"", ""MCO"", ""BOS"", ""SLC"", ""SEA"", ""MSP"", ""CLT"",
        ""LGA"", ""DTW"", ""JFK"", ""BWI""
    };
    String pqlQuery;
    for (String origin : origins) {
      pqlQuery =
          ""SELECT count(*) FROM mytable WHERE Origin = \"""" + origin + ""\"" AND DaysSinceEpoch = "" + daysSinceEpoch;
      JsonNode response1 = postQuery(pqlQuery);
      pqlQuery = ""SELECT count(*) FROM mytable WHERE Origin = \"""" + origin
          + ""\"" AND timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch;
      JsonNode response2 = postQuery(pqlQuery);
      double val1 = response1.get(""aggregationResults"").get(0).get(""value"").asDouble();
      double val2 = response2.get(""aggregationResults"").get(0).get(""value"").asDouble();
      assertEquals(val1, val2);
    }
  }
"
"  @Test
  public void testQueryWithRepeatedColumns()
      throws Exception {
    //test repeated columns in selection query
    String query = ""SELECT ArrTime, ArrTime FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));

    //test repeated columns in selection query with order by
    query = ""SELECT ArrTime, ArrTime FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL' order by ArrTime"";
    testQuery(query, Collections.singletonList(query));

    //test repeated columns in agg query
    query = ""SELECT count(*), count(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL'"";
    testQuery(query, Arrays.asList(""SELECT count(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL'"",
        ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL'""));

    //test repeated columns in agg group by query
    query =
        ""SELECT ArrTime, ArrTime, count(*), count(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL' ""
            + ""group by ArrTime, ArrTime"";
    testQuery(query, Arrays.asList(
        ""SELECT ArrTime, ArrTime, count(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL' group by ""
            + ""ArrTime, ArrTime"",
        ""SELECT ArrTime, ArrTime, count(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL' group by ""
            + ""ArrTime, ArrTime""));
  }
"
"  @Test
  public void testQueryWithOrderby()
      throws Exception {
    //test repeated columns in selection query
    String query = ""SELECT ArrTime, Carrier, DaysSinceEpoch FROM mytable ORDER BY DaysSinceEpoch DESC"";
    testQuery(query, Collections.singletonList(query));

    //test repeated columns in selection query
    query = ""SELECT ArrTime, DaysSinceEpoch, Carrier FROM mytable ORDER BY Carrier DESC"";
    testQuery(query, Collections.singletonList(query));

    //test repeated columns in selection query
    query = ""SELECT ArrTime, DaysSinceEpoch, Carrier FROM mytable ORDER BY Carrier DESC, ArrTime DESC"";
    testQuery(query, Collections.singletonList(query));
  }
"
"  @Test
  public void testQueryWithAlias()
      throws Exception {
    {
      //test same alias name with column name
      String query =
          ""SELECT ArrTime AS ArrTime, Carrier AS Carrier, DaysSinceEpoch AS DaysSinceEpoch FROM mytable ORDER BY ""
              + ""DaysSinceEpoch DESC"";
      testSqlQuery(query, Collections.singletonList(query));

      query =
          ""SELECT ArrTime AS ArrTime, DaysSinceEpoch AS DaysSinceEpoch, Carrier AS Carrier FROM mytable ORDER BY ""
              + ""Carrier DESC"";
      testSqlQuery(query, Collections.singletonList(query));

      query =
          ""SELECT ArrTime AS ArrTime, DaysSinceEpoch AS DaysSinceEpoch, Carrier AS Carrier FROM mytable ORDER BY ""
              + ""Carrier DESC, ArrTime DESC"";
      testSqlQuery(query, Collections.singletonList(query));
    }
    {
      //test single alias
      String query = ""SELECT ArrTime, Carrier AS CarrierName, DaysSinceEpoch FROM mytable ORDER BY DaysSinceEpoch DESC"";
      testSqlQuery(query, Collections.singletonList(query));

      query = ""SELECT count(*) AS cnt, max(ArrTime) as maxArrTime FROM mytable"";
      testSqlQuery(query, Collections.singletonList(query));

      query = ""SELECT count(*) AS cnt, Carrier AS CarrierName FROM mytable GROUP BY CarrierName ORDER BY cnt"";
      testSqlQuery(query, Collections.singletonList(query));
    }
    {
      //test multiple alias
      String query =
          ""SELECT ArrTime, Carrier, Carrier AS CarrierName1, Carrier AS CarrierName2, DaysSinceEpoch FROM mytable ""
              + ""ORDER BY DaysSinceEpoch DESC"";
      testSqlQuery(query, Collections.singletonList(query));

      query = ""SELECT count(*) AS cnt, max(ArrTime) as maxArrTime1, max(ArrTime) as maxArrTime2 FROM mytable"";
      testSqlQuery(query, Collections.singletonList(query));

      query =
          ""SELECT count(*), count(*) AS cnt1, count(*) AS cnt2, Carrier AS CarrierName FROM mytable GROUP BY ""
              + ""CarrierName ORDER BY cnt2"";
      testSqlQuery(query, Collections.singletonList(query));
    }
  }
"
"  @Test
  public void testDistinctQuery()
      throws Exception {
    // by default 10 rows will be returned, so use high limit
    String pql = ""SELECT DISTINCT(Carrier) FROM mytable LIMIT 1000000"";
    String sql = ""SELECT DISTINCT Carrier FROM mytable"";
    testQuery(pql, Collections.singletonList(sql));
    pql = ""SELECT DISTINCT Carrier FROM mytable LIMIT 1000000"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT DISTINCT(Carrier, DestAirportID) FROM mytable LIMIT 1000000"";
    sql = ""SELECT DISTINCT Carrier, DestAirportID FROM mytable"";
    testQuery(pql, Collections.singletonList(sql));
    pql = ""SELECT DISTINCT Carrier, DestAirportID FROM mytable LIMIT 1000000"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT DISTINCT(Carrier, DestAirportID, DestStateName) FROM mytable LIMIT 1000000"";
    sql = ""SELECT DISTINCT Carrier, DestAirportID, DestStateName FROM mytable"";
    testQuery(pql, Collections.singletonList(sql));
    pql = ""SELECT DISTINCT Carrier, DestAirportID, DestStateName FROM mytable LIMIT 1000000"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT DISTINCT(Carrier, DestAirportID, DestCityName) FROM mytable LIMIT 1000000"";
    sql = ""SELECT DISTINCT Carrier, DestAirportID, DestCityName FROM mytable"";
    testQuery(pql, Collections.singletonList(sql));
    pql = ""SELECT DISTINCT Carrier, DestAirportID, DestCityName FROM mytable LIMIT 1000000"";
    testSqlQuery(pql, Collections.singletonList(sql));
  }
"
"  @Test
  public void testNonAggregationGroupByQuery()
      throws Exception {
    // by default 10 rows will be returned, so use high limit
    String pql = ""SELECT Carrier FROM mytable GROUP BY Carrier LIMIT 1000000"";
    String sql = ""SELECT Carrier FROM mytable GROUP BY Carrier"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT Carrier, DestAirportID FROM mytable GROUP BY Carrier, DestAirportID LIMIT 1000000"";
    sql = ""SELECT Carrier, DestAirportID FROM mytable GROUP BY Carrier, DestAirportID"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql =
        ""SELECT Carrier, DestAirportID, DestStateName FROM mytable GROUP BY Carrier, DestAirportID, DestStateName ""
            + ""LIMIT 1000000"";
    sql = ""SELECT Carrier, DestAirportID, DestStateName FROM mytable GROUP BY Carrier, DestAirportID, DestStateName"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql =
        ""SELECT Carrier, DestAirportID, DestCityName FROM mytable GROUP BY Carrier, DestAirportID, DestCityName LIMIT""
            + "" 1000000"";
    sql = ""SELECT Carrier, DestAirportID, DestCityName FROM mytable GROUP BY Carrier, DestAirportID, DestCityName"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT ArrTime-DepTime FROM mytable GROUP BY ArrTime, DepTime LIMIT 1000000"";
    sql = ""SELECT ArrTime-DepTime FROM mytable GROUP BY ArrTime, DepTime"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT ArrTime-DepTime,ArrTime/3,DepTime*2 FROM mytable GROUP BY ArrTime, DepTime LIMIT 1000000"";
    sql = ""SELECT ArrTime-DepTime,ArrTime/3,DepTime*2 FROM mytable GROUP BY ArrTime, DepTime"";
    testSqlQuery(pql, Collections.singletonList(sql));

    pql = ""SELECT ArrTime+DepTime FROM mytable GROUP BY ArrTime + DepTime LIMIT 1000000"";
    sql = ""SELECT ArrTime+DepTime FROM mytable GROUP BY ArrTime + DepTime"";
    testSqlQuery(pql, Collections.singletonList(sql));
  }
"
"  @Test
  public void testCaseInsensitivity() {
    int daysSinceEpoch = 16138;
    int hoursSinceEpoch = 16138 * 24;
    int secondsSinceEpoch = 16138 * 24 * 60 * 60;
    List<String> baseQueries = Arrays.asList(""SELECT * FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by DaysSinceEpoch ""
            + ""limit 10000"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by timeConvert""
            + ""(DaysSinceEpoch,'DAYS','SECONDS') DESC limit 10000"",
        ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch = "" + daysSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','HOURS') = "" + hoursSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch,
        ""SELECT MAX(timeConvert(DaysSinceEpoch,'DAYS','SECONDS')) FROM mytable"",
        ""SELECT COUNT(*) FROM mytable GROUP BY dateTimeConvert(DaysSinceEpoch,'1:DAYS:EPOCH','1:HOURS:EPOCH',""
            + ""'1:HOURS')"");
    List<String> queries = new ArrayList<>();
    baseQueries.forEach(q -> queries.add(q.replace(""mytable"", ""MYTABLE"").replace(""DaysSinceEpoch"", ""DAYSSinceEpOch"")));
    baseQueries
        .forEach(q -> queries.add(q.replace(""mytable"", ""MYDB.MYTABLE"").replace(""DaysSinceEpoch"", ""DAYSSinceEpOch"")));

    for (String query : queries) {
      try {
        JsonNode response = postQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""PQL: "" + query + "" failed"");

        response = postSqlQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""SQL: "" + query + "" failed"");
      } catch (Exception e) {
        // Fail the test when exception caught
        throw new RuntimeException(""Got Exceptions from query - "" + query);
      }
    }
  }
"
"  @Test
  public void testColumnNameContainsTableName() {
    int daysSinceEpoch = 16138;
    int hoursSinceEpoch = 16138 * 24;
    int secondsSinceEpoch = 16138 * 24 * 60 * 60;
    List<String> baseQueries = Arrays.asList(""SELECT * FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by DaysSinceEpoch ""
            + ""limit 10000"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by timeConvert""
            + ""(DaysSinceEpoch,'DAYS','SECONDS') DESC limit 10000"",
        ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch = "" + daysSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','HOURS') = "" + hoursSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch,
        ""SELECT MAX(timeConvert(DaysSinceEpoch,'DAYS','SECONDS')) FROM mytable"",
        ""SELECT COUNT(*) FROM mytable GROUP BY dateTimeConvert(DaysSinceEpoch,'1:DAYS:EPOCH','1:HOURS:EPOCH',""
            + ""'1:HOURS')"");
    List<String> queries = new ArrayList<>();
    baseQueries.forEach(q -> queries.add(q.replace(""DaysSinceEpoch"", ""mytable.DAYSSinceEpOch"")));
    baseQueries.forEach(q -> queries.add(q.replace(""DaysSinceEpoch"", ""mytable.DAYSSinceEpOch"")));

    for (String query : queries) {
      try {
        JsonNode response = postQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""PQL: "" + query + "" failed"");

        response = postSqlQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""SQL: "" + query + "" failed"");
      } catch (Exception e) {
        // Fail the test when exception caught
        throw new RuntimeException(""Got Exceptions from query - "" + query);
      }
    }
  }
"
"  @Test
  public void testCaseInsensitivityWithColumnNameContainsTableName() {
    int daysSinceEpoch = 16138;
    int hoursSinceEpoch = 16138 * 24;
    int secondsSinceEpoch = 16138 * 24 * 60 * 60;
    List<String> baseQueries = Arrays.asList(""SELECT * FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by DaysSinceEpoch ""
            + ""limit 10000"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by timeConvert""
            + ""(DaysSinceEpoch,'DAYS','SECONDS') DESC limit 10000"",
        ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch = "" + daysSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','HOURS') = "" + hoursSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch,
        ""SELECT MAX(timeConvert(DaysSinceEpoch,'DAYS','SECONDS')) FROM mytable"",
        ""SELECT COUNT(*) FROM mytable GROUP BY dateTimeConvert(DaysSinceEpoch,'1:DAYS:EPOCH','1:HOURS:EPOCH',""
            + ""'1:HOURS')"");
    List<String> queries = new ArrayList<>();
    baseQueries
        .forEach(q -> queries.add(q.replace(""mytable"", ""MYTABLE"").replace(""DaysSinceEpoch"", ""MYTABLE.DAYSSinceEpOch"")));
    baseQueries.forEach(
        q -> queries.add(q.replace(""mytable"", ""MYDB.MYTABLE"").replace(""DaysSinceEpoch"", ""MYTABLE.DAYSSinceEpOch"")));

    for (String query : queries) {
      try {
        JsonNode response = postQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""PQL: "" + query + "" failed"");

        response = postSqlQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""SQL: "" + query + "" failed"");
      } catch (Exception e) {
        // Fail the test when exception caught
        throw new RuntimeException(""Got Exceptions from query - "" + query);
      }
    }
  }
"
"  @Test
  public void testQuerySourceWithDatabaseName()
      throws Exception {
    // by default 10 rows will be returned, so use high limit
    String pql = ""SELECT DISTINCT(Carrier) FROM mytable LIMIT 1000000"";
    String sql = ""SELECT DISTINCT Carrier FROM mytable"";
    testQuery(pql, Collections.singletonList(sql));
    pql = ""SELECT DISTINCT Carrier FROM db.mytable LIMIT 1000000"";
    testSqlQuery(pql, Collections.singletonList(sql));
  }
"
"  @Test
  public void testDistinctCountHll()
      throws Exception {
    String query;

    // The Accurate value is 6538.
    query = ""SELECT distinctCount(FlightNum) FROM mytable "";
    assertEquals(postQuery(query).get(""aggregationResults"").get(0).get(""value"").asLong(), 6538);
    assertEquals(postSqlQuery(query, _brokerBaseApiUrl).get(""resultTable"").get(""rows"").get(0).get(0).asLong(), 6538);

    // Expected distinctCountHll with different log2m value from 2 to 19. The Accurate value is 6538.
    long[] expectedResults = new long[]{
        3504, 6347, 8877, 9729, 9046, 7672, 7538, 6993, 6649, 6651, 6553, 6525, 6459, 6523, 6532, 6544, 6538, 6539
    };

    for (int i = 2; i < 20; i++) {
      query = String.format(""SELECT distinctCountHLL(FlightNum, %d) FROM mytable "", i);
      assertEquals(postQuery(query).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResults[i - 2]);
      assertEquals(postSqlQuery(query, _brokerBaseApiUrl).get(""resultTable"").get(""rows"").get(0).get(0).asLong(),
          expectedResults[i - 2]);
    }

    // Default HLL is set as log2m=12
    query = ""SELECT distinctCountHLL(FlightNum) FROM mytable "";
    assertEquals(postQuery(query).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResults[10]);
    assertEquals(postSqlQuery(query, _brokerBaseApiUrl).get(""resultTable"").get(""rows"").get(0).get(0).asLong(),
        expectedResults[10]);
  }
"
"  @Test
  public void testAggregationFunctionsWithUnderscore()
      throws Exception {
    String query;

    // The Accurate value is 6538.
    query = ""SELECT distinct_count(FlightNum) FROM mytable "";
    assertEquals(postQuery(query).get(""aggregationResults"").get(0).get(""value"").asLong(), 6538);
    assertEquals(postSqlQuery(query, _brokerBaseApiUrl).get(""resultTable"").get(""rows"").get(0).get(0).asLong(), 6538);

    // The Accurate value is 6538.
    query = ""SELECT c_o_u_n_t(FlightNum) FROM mytable "";
    assertEquals(postQuery(query).get(""aggregationResults"").get(0).get(""value"").asLong(), 115545);
    assertEquals(postSqlQuery(query, _brokerBaseApiUrl).get(""resultTable"").get(""rows"").get(0).get(0).asLong(), 115545);
  }
"
"  @Test
  public void testGrpcQueryServer()
      throws Exception {
    GrpcQueryClient queryClient = new GrpcQueryClient(""localhost"", CommonConstants.Server.DEFAULT_GRPC_PORT);
    String sql = ""SELECT * FROM mytable_OFFLINE LIMIT 1000000"";
    BrokerRequest brokerRequest = new Pql2Compiler().compileToBrokerRequest(sql);
    List<String> segments = _helixResourceManager.getSegmentsFor(""mytable_OFFLINE"");

    GrpcRequestBuilder requestBuilder = new GrpcRequestBuilder().setSegments(segments);
    testNonStreamingRequest(queryClient.submit(requestBuilder.setSql(sql).build()));
    testNonStreamingRequest(queryClient.submit(requestBuilder.setBrokerRequest(brokerRequest).build()));

    requestBuilder.setEnableStreaming(true);
    testStreamingRequest(queryClient.submit(requestBuilder.setSql(sql).build()));
    testStreamingRequest(queryClient.submit(requestBuilder.setBrokerRequest(brokerRequest).build()));
  }
"
"  @Test
  public void testHardcodedServerPartitionedSqlQueries()
      throws Exception {
    super.testHardcodedServerPartitionedSqlQueries();
  }
"
"  @Test
  public void testAggregateMetadataAPI()
      throws IOException {
    JsonNode oneColumnResponse = JsonUtils
        .stringToJsonNode(sendGetRequest(_controllerBaseApiUrl + ""/tables/mytable/metadata?columns=DestCityMarketID""));
    assertEquals(oneColumnResponse.get(DISK_SIZE_IN_BYTES_KEY).asInt(), DISK_SIZE_IN_BYTES);
    assertEquals(oneColumnResponse.get(NUM_SEGMENTS_KEY).asInt(), NUM_SEGMENTS);
    assertEquals(oneColumnResponse.get(NUM_ROWS_KEY).asInt(), NUM_ROWS);
    assertEquals(oneColumnResponse.get(COLUMN_LENGTH_MAP_KEY).size(), 1);
    assertEquals(oneColumnResponse.get(COLUMN_CARDINALITY_MAP_KEY).size(), 1);

    JsonNode threeColumnsResponse = JsonUtils.stringToJsonNode(sendGetRequest(_controllerBaseApiUrl
        + ""/tables/mytable/metadata?columns=DivActualElapsedTime&columns=CRSElapsedTime&columns=OriginStateName""));
    assertEquals(threeColumnsResponse.get(DISK_SIZE_IN_BYTES_KEY).asInt(), DISK_SIZE_IN_BYTES);
    assertEquals(threeColumnsResponse.get(NUM_SEGMENTS_KEY).asInt(), NUM_SEGMENTS);
    assertEquals(threeColumnsResponse.get(NUM_ROWS_KEY).asInt(), NUM_ROWS);
    assertEquals(threeColumnsResponse.get(COLUMN_LENGTH_MAP_KEY).size(), 3);
    assertEquals(threeColumnsResponse.get(COLUMN_CARDINALITY_MAP_KEY).size(), 3);

    JsonNode zeroColumnResponse =
        JsonUtils.stringToJsonNode(sendGetRequest(_controllerBaseApiUrl + ""/tables/mytable/metadata""));
    assertEquals(zeroColumnResponse.get(DISK_SIZE_IN_BYTES_KEY).asInt(), DISK_SIZE_IN_BYTES);
    assertEquals(zeroColumnResponse.get(NUM_SEGMENTS_KEY).asInt(), NUM_SEGMENTS);
    assertEquals(zeroColumnResponse.get(NUM_ROWS_KEY).asInt(), NUM_ROWS);
    assertEquals(zeroColumnResponse.get(COLUMN_LENGTH_MAP_KEY).size(), 0);
    assertEquals(zeroColumnResponse.get(COLUMN_CARDINALITY_MAP_KEY).size(), 0);

    JsonNode allColumnResponse =
        JsonUtils.stringToJsonNode(sendGetRequest(_controllerBaseApiUrl + ""/tables/mytable/metadata?columns=*""));
    assertEquals(allColumnResponse.get(DISK_SIZE_IN_BYTES_KEY).asInt(), DISK_SIZE_IN_BYTES);
    assertEquals(allColumnResponse.get(NUM_SEGMENTS_KEY).asInt(), NUM_SEGMENTS);
    assertEquals(allColumnResponse.get(NUM_ROWS_KEY).asInt(), NUM_ROWS);
    assertEquals(allColumnResponse.get(COLUMN_LENGTH_MAP_KEY).size(), 82);
    assertEquals(allColumnResponse.get(COLUMN_CARDINALITY_MAP_KEY).size(), 82);

    allColumnResponse = JsonUtils.stringToJsonNode(sendGetRequest(
        _controllerBaseApiUrl + ""/tables/mytable/metadata?columns=CRSElapsedTime&columns=*&columns=OriginStateName""));
    assertEquals(allColumnResponse.get(DISK_SIZE_IN_BYTES_KEY).asInt(), DISK_SIZE_IN_BYTES);
    assertEquals(allColumnResponse.get(NUM_SEGMENTS_KEY).asInt(), NUM_SEGMENTS);
    assertEquals(allColumnResponse.get(NUM_ROWS_KEY).asInt(), NUM_ROWS);
    assertEquals(allColumnResponse.get(COLUMN_LENGTH_MAP_KEY).size(), 82);
    assertEquals(allColumnResponse.get(COLUMN_CARDINALITY_MAP_KEY).size(), 82);
  }
"
"  @Test
  public void testRecords()
      throws Exception {
    Assert.assertNotEquals(_totalRecordsPushedInStream, 0);

    ResultSet pinotResultSet = getPinotConnection()
        .execute(new Request(""sql"", ""SELECT * FROM "" + getTableName() + "" ORDER BY Origin LIMIT 10000""))
        .getResultSet(0);

    Assert.assertNotEquals(pinotResultSet.getRowCount(), 0);

    Statement h2statement =
        _h2Connection.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY, java.sql.ResultSet.CONCUR_READ_ONLY);
    h2statement.execute(""SELECT * FROM "" + getTableName() + "" ORDER BY Origin"");
    java.sql.ResultSet h2ResultSet = h2statement.getResultSet();

    Assert.assertFalse(h2ResultSet.isLast());

    h2ResultSet.beforeFirst();
    int row = 0;
    Map<String, Integer> columnToIndex = new HashMap<>();
    for (int i = 0; i < _h2FieldNameAndTypes.size(); i++) {
      columnToIndex.put(pinotResultSet.getColumnName(i), i);
    }

    while (h2ResultSet.next()) {

      for (String fieldNameAndDatatype : _h2FieldNameAndTypes) {
        String[] fieldNameAndDatatypeList = fieldNameAndDatatype.split("" "");
        String fieldName = fieldNameAndDatatypeList[0];
        String h2DataType = fieldNameAndDatatypeList[1];
        switch (h2DataType) {
          case ""int"": {
            int expectedValue = h2ResultSet.getInt(fieldName);
            int actualValue = pinotResultSet.getInt(row, columnToIndex.get(fieldName));
            Assert.assertEquals(expectedValue, actualValue);
            break;
          }
          case ""varchar(128)"": {
            String expectedValue = h2ResultSet.getString(fieldName);
            String actualValue = pinotResultSet.getString(row, columnToIndex.get(fieldName));
            Assert.assertEquals(expectedValue, actualValue);
            break;
          }
          default:
            break;
        }
      }

      row++;

      if (row >= pinotResultSet.getRowCount()) {
        int cnt = 0;
        while (h2ResultSet.next()) {
          cnt++;
        }
        Assert.assertEquals(cnt, 0);
        break;
      }
    }
  }
"
"  @Test
  public void testCountRecords() {
    long count =
        getPinotConnection().execute(new Request(""sql"", ""SELECT COUNT(*) FROM "" + getTableName())).getResultSet(0)
            .getLong(0);

    Assert.assertEquals(count, _totalRecordsPushedInStream);
  }
"
"  @Test
  public void testGeneratedQueries()
      throws Exception {
    for (int i = 0; i < NUM_QUERIES_TO_GENERATE; i += 2) {
      testStarQuery(_starTree1QueryGenerator.nextQuery());
      testStarQuery(_starTree2QueryGenerator.nextQuery());
    }
  }
"
"  @Test
  public void testPredicateOnMetrics()
      throws Exception {
    String starQuery;

    // Query containing predicate on one metric only
    starQuery = ""SELECT SUM(DepDelayMinutes) FROM myStarTable WHERE DepDelay > 0"";
    testStarQuery(starQuery);
    starQuery = ""SELECT SUM(DepDelayMinutes) FROM myStarTable WHERE DepDelay BETWEEN 0 and 10000"";
    testStarQuery(starQuery);

    // Query containing predicate on multiple metrics
    starQuery = ""SELECT SUM(DepDelayMinutes) FROM myStarTable WHERE DepDelay > 0 AND ArrDelay > 0"";
    testStarQuery(starQuery);

    // Query containing predicate on multiple metrics and dimensions
    starQuery =
        ""SELECT SUM(DepDelayMinutes) FROM myStarTable WHERE DepDelay > 0 AND ArrDelay > 0 AND OriginStateName = ""
            + ""'Massachusetts'"";
    testStarQuery(starQuery);
  }
"
"  @Test
  public void testTextSearchCountQuery()
      throws Exception {
    // Keep posting queries until all records are consumed
    long previousResult = 0;
    while (getCurrentCountStarResult() < NUM_RECORDS) {
      long result = getTextColumnQueryResult();
      assertTrue(result >= previousResult);
      previousResult = result;
      Thread.sleep(100);
    }

    //Lucene index on consuming segments to update the latest records
    TestUtils.waitForCondition(aVoid -> {
      try {
        return getTextColumnQueryResult() == NUM_MATCHING_RECORDS;
      } catch (Exception e) {
        fail(""Caught exception while getting text column query result"");
        return false;
      }
    }, 10_000L, ""Failed to reach expected number of matching records"");
  }
"
"  @Test
  public void testRealtimeToOfflineSegmentsTask()
      throws IOException {
    List<SegmentZKMetadata> segmentsZKMetadata = _pinotHelixResourceManager.getSegmentsZKMetadata(_offlineTableName);
    Assert.assertTrue(segmentsZKMetadata.isEmpty());

    long expectedWatermark = _dataSmallestTimeMs + 86400000;
    int numOfflineSegments = 0;
    for (int i = 0; i < 3; i++) {
      // Schedule task
      Assert.assertNotNull(_taskManager.scheduleTasks().get(MinionConstants.RealtimeToOfflineSegmentsTask.TASK_TYPE));
      Assert.assertTrue(_helixTaskResourceManager.getTaskQueues().contains(
          PinotHelixTaskResourceManager.getHelixJobQueueName(MinionConstants.RealtimeToOfflineSegmentsTask.TASK_TYPE)));
      // Should not generate more tasks
      Assert.assertNull(_taskManager.scheduleTasks().get(MinionConstants.RealtimeToOfflineSegmentsTask.TASK_TYPE));

      // Wait at most 600 seconds for all tasks COMPLETED
      waitForTaskToComplete(expectedWatermark);
      // check segment is in offline
      segmentsZKMetadata = _pinotHelixResourceManager.getSegmentsZKMetadata(_offlineTableName);
      numOfflineSegments++;
      Assert.assertEquals(segmentsZKMetadata.size(), numOfflineSegments);
      long expectedOfflineSegmentTimeMs = expectedWatermark - 86400000;
      Assert.assertEquals(segmentsZKMetadata.get(i).getStartTimeMs(), expectedOfflineSegmentTimeMs);
      Assert.assertEquals(segmentsZKMetadata.get(i).getEndTimeMs(), expectedOfflineSegmentTimeMs);

      expectedWatermark += 86400000;
    }
    testHardcodedSqlQueries();

    // Delete the table
    dropRealtimeTable(_realtimeTableName);

    // Check if the metadata is cleaned up on table deletion
    verifyTableDelete(_realtimeTableName);
  }
"
"  @Test(enabled = false)
  public void testSegmentListApi() {
  }
"
"  @Test(enabled = false)
  public void testBrokerDebugOutput() {
  }
"
"  @Test(enabled = false)
  public void testBrokerDebugRoutingTableSQL() {
  }
"
"  @Test(enabled = false)
  public void testBrokerResponseMetadata() {
  }
"
"  @Test(enabled = false)
  public void testDictionaryBasedQueries() {
  }
"
"  @Test(enabled = false)
  public void testGeneratedQueriesWithMultiValues() {
  }
"
"  @Test(enabled = false)
  public void testGeneratedQueriesWithoutMultiValues() {
  }
"
"  @Test(enabled = false)
  public void testHardcodedQueries() {
  }
"
"  @Test(enabled = false)
  public void testHardcodedSqlQueries() {
  }
"
"  @Test(enabled = false)
  public void testInstanceShutdown() {
  }
"
"  @Test(enabled = false)
  public void testQueriesFromQueryFile() {
  }
"
"  @Test(enabled = false)
  public void testQueryExceptions() {
  }
"
"  @Test(enabled = false)
  public void testReload(boolean includeOfflineTable) {
  }
"
"  @Test(enabled = false)
  public void testSqlQueriesFromQueryFile() {
  }
"
"  @Test(enabled = false)
  public void testVirtualColumnQueries() {
  }
"
"  @Test
  public void testJsonPathQueries()
      throws Exception {
    // Selection only
    String query = ""SELECT stringKeyMapStr FROM "" + getTableName();
    JsonNode pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(selectionResults.get(i).get(0).textValue(), String.format(""{\""k1\"":%d,\""k2\"":100%d}"", i, i));
    }
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k1', 'INT') FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), i);
    }
    query = ""SELECT jsonExtractScalar(intKeyMapStr, '$.95', 'INT') FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), i);
    }

    // Selection order-by
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k2', 'INT') FROM "" + getTableName()
        + "" ORDER BY jsonExtractScalar(stringKeyMapStr, '$.k1', 'INT')"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), NUM_DOCS + i);
    }
    query = ""SELECT jsonExtractScalar(intKeyMapStr, '$.717', 'INT') FROM "" + getTableName()
        + "" ORDER BY jsonExtractScalar(intKeyMapStr, '$.95', 'INT')"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), NUM_DOCS + i);
    }

    // Aggregation only
    query = ""SELECT MAX(jsonExtractScalar(stringKeyMapStr, '$.k1', 'INT')) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode aggregationResult = pinotResponse.get(""aggregationResults"").get(0).get(""value"");
    assertEquals((int) Double.parseDouble(aggregationResult.textValue()), NUM_DOCS - 1);
    query = ""SELECT MAX(jsonExtractScalar(intKeyMapStr, '$.95', 'INT')) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    aggregationResult = pinotResponse.get(""aggregationResults"").get(0).get(""value"");
    assertEquals((int) Double.parseDouble(aggregationResult.textValue()), NUM_DOCS - 1);

    // Aggregation group-by
    query = ""SELECT MIN(jsonExtractScalar(stringKeyMapStr, '$.k2', 'INT')) FROM "" + getTableName()
        + "" GROUP BY jsonExtractScalar(stringKeyMapStr, '$.k1', 'INT')"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode groupByResults = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    assertEquals(groupByResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      JsonNode groupByResult = groupByResults.get(i);
      assertEquals(Integer.parseInt(groupByResult.get(""group"").get(0).asText()), i);
      assertEquals((int) Double.parseDouble(groupByResult.get(""value"").asText()), NUM_DOCS + i);
    }
    query = ""SELECT MIN(jsonExtractScalar(intKeyMapStr, '$.717', 'INT')) FROM "" + getTableName()
        + "" GROUP BY jsonExtractScalar(intKeyMapStr, '$.95', 'INT')"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    groupByResults = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    assertEquals(groupByResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      JsonNode groupByResult = groupByResults.get(i);
      assertEquals(Integer.parseInt(groupByResult.get(""group"").get(0).asText()), i);
      assertEquals((int) Double.parseDouble(groupByResult.get(""value"").asText()), NUM_DOCS + i);
    }

    // Filter
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k2', 'INT') FROM "" + getTableName()
        + "" WHERE jsonExtractScalar(stringKeyMapStr, '$.k1', 'INT') = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 1);
    assertEquals(Integer.parseInt(selectionResults.get(0).get(0).textValue()), NUM_DOCS + 25);
    query = ""SELECT jsonExtractScalar(intKeyMapStr, '$.717', 'INT') FROM "" + getTableName()
        + "" WHERE jsonExtractScalar(intKeyMapStr, '$.95', 'INT') = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 1);
    assertEquals(Integer.parseInt(selectionResults.get(0).get(0).textValue()), NUM_DOCS + 25);

    // Filter on non-existing key
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k2', 'INT') FROM "" + getTableName()
        + "" WHERE jsonExtractScalar(stringKeyMapStr, '$.k3', 'INT_ARRAY') = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
    query = ""SELECT jsonExtractScalar(intKeyMapStr, '$.717', 'INT') FROM "" + getTableName()
        + "" WHERE jsonExtractScalar(intKeyMapStr, '$.123', 'INT_ARRAY') = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);

    // Select non-existing key (illegal query)
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k3', 'INT') FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertNotEquals(pinotResponse.get(""exceptions"").size(), 0);
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.123', 'INT') FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertNotEquals(pinotResponse.get(""exceptions"").size(), 0);

    // Select non-existing key with default value
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k3', 'INT', '0') FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.123', 'INT', '0') FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);

    // Select non-existing key with proper filter
    query = ""SELECT jsonExtractScalar(intKeyMapStr, '$.123', 'INT') FROM "" + getTableName()
        + "" WHERE jsonExtractKey(intKeyMapStr, '$.*') = \""$['123']\"""";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
    query = ""SELECT jsonExtractScalar(stringKeyMapStr, '$.k3', 'INT') FROM "" + getTableName()
        + "" WHERE jsonExtractKey(stringKeyMapStr, '$.*') = \""$['k3']\"""";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
  }
"
"  @Test
  public void testQueries()
      throws Exception {
    // Selection only
    String query = ""SELECT mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES) FROM "" + getTableName();
    JsonNode pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), i);
    }
    query = ""SELECT mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), i);
    }

    // Selection order-by
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k2', stringKeyMap__VALUES) FROM "" + getTableName()
        + "" ORDER BY mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES)"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), NUM_DOCS + i);
    }
    query = ""SELECT mapValue(intKeyMap__KEYS, 717, intKeyMap__VALUES) FROM "" + getTableName()
        + "" ORDER BY mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES)"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), NUM_DOCS + i);
    }

    // Aggregation only
    query = ""SELECT MAX(mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES)) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode aggregationResult = pinotResponse.get(""aggregationResults"").get(0).get(""value"");
    assertEquals((int) Double.parseDouble(aggregationResult.textValue()), NUM_DOCS - 1);
    query = ""SELECT MAX(mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES)) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    aggregationResult = pinotResponse.get(""aggregationResults"").get(0).get(""value"");
    assertEquals((int) Double.parseDouble(aggregationResult.textValue()), NUM_DOCS - 1);

    // Aggregation group-by
    query = ""SELECT MIN(mapValue(stringKeyMap__KEYS, 'k2', stringKeyMap__VALUES)) FROM "" + getTableName()
        + "" GROUP BY mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES)"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode groupByResults = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    assertEquals(groupByResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      JsonNode groupByResult = groupByResults.get(i);
      assertEquals(Integer.parseInt(groupByResult.get(""group"").get(0).asText()), i);
      assertEquals((int) Double.parseDouble(groupByResult.get(""value"").asText()), NUM_DOCS + i);
    }
    query = ""SELECT MIN(mapValue(intKeyMap__KEYS, 717, intKeyMap__VALUES)) FROM "" + getTableName()
        + "" GROUP BY mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES)"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    groupByResults = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    assertEquals(groupByResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      JsonNode groupByResult = groupByResults.get(i);
      assertEquals(Integer.parseInt(groupByResult.get(""group"").get(0).asText()), i);
      assertEquals((int) Double.parseDouble(groupByResult.get(""value"").asText()), NUM_DOCS + i);
    }

    // Filter
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k2', stringKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES) = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 1);
    assertEquals(Integer.parseInt(selectionResults.get(0).get(0).textValue()), NUM_DOCS + 25);
    query = ""SELECT mapValue(intKeyMap__KEYS, 717, intKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES) = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 1);
    assertEquals(Integer.parseInt(selectionResults.get(0).get(0).textValue()), NUM_DOCS + 25);

    // Filter on non-existing key
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k2', stringKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE mapValue(stringKeyMap__KEYS, 'k3', stringKeyMap__VALUES) = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
    query = ""SELECT mapValue(intKeyMap__KEYS, 717, intKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE mapValue(intKeyMap__KEYS, 123, intKeyMap__VALUES) = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);

    // Select non-existing key (illegal query)
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k3', stringKeyMap__VALUES) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertNotEquals(pinotResponse.get(""exceptions"").size(), 0);
    query = ""SELECT mapValue(stringKeyMap__KEYS, 123, stringKeyMap__VALUES) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertNotEquals(pinotResponse.get(""exceptions"").size(), 0);

    // Select non-existing key with proper filter
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k3', stringKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE stringKeyMap__KEYS = 'k3'"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
    query = ""SELECT mapValue(intKeyMap__KEYS, 123, intKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE stringKeyMap__KEYS = 123"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
  }
"
"  @Test
  public void testSegmentAssignment()
      throws Exception {
    IdealState idealState = HelixHelper.getTableIdealState(_helixManager, TABLE_NAME_WITH_TYPE);
    Assert.assertEquals(getCurrentCountStarResult(), getCountStarResult());
    verifyTableIdealStates(idealState);
    // Wait 3 seconds to let the realtime validation thread to run.
    Thread.sleep(3000);
    // Verify the result again.
    Assert.assertEquals(getCurrentCountStarResult(), getCountStarResult());
    verifyTableIdealStates(idealState);
  }
"
"  @Test
  public void testSegmentUploadDownload()
      throws Exception {
    final Request query = new Request(""sql"", ""SELECT count(*) FROM "" + getTableName());

    ResultSetGroup resultBeforeOffline = getPinotConnection().execute(query);
    Assert.assertTrue(resultBeforeOffline.getResultSet(0).getLong(0) > 0);

    // schedule offline segment generation
    Assert.assertNotNull(_controllerStarter.getTaskManager().scheduleTasks());

    // wait for offline segments
    JsonNode offlineSegments = TestUtils.waitForResult(() -> {
      JsonNode segmentSets = JsonUtils.stringToJsonNode(
          sendGetRequest(_controllerRequestURLBuilder.forSegmentListAPI(getTableName()), AUTH_HEADER));
      JsonNode currentOfflineSegments =
          new IntRange(0, segmentSets.size()).stream().map(segmentSets::get).filter(s -> s.has(""OFFLINE""))
              .map(s -> s.get(""OFFLINE"")).findFirst().get();
      Assert.assertFalse(currentOfflineSegments.isEmpty());
      return currentOfflineSegments;
    }, 30000);

    // Verify constant row count
    ResultSetGroup resultAfterOffline = getPinotConnection().execute(query);
    Assert.assertEquals(resultBeforeOffline.getResultSet(0).getLong(0), resultAfterOffline.getResultSet(0).getLong(0));

    // download and sanity-check size of offline segment(s)
    for (int i = 0; i < offlineSegments.size(); i++) {
      String segment = offlineSegments.get(i).asText();
      Assert.assertTrue(
          sendGetRequest(_controllerRequestURLBuilder.forSegmentDownload(getTableName(), segment), AUTH_HEADER).length()
              > 200000); // download segment
    }
  }
"
"  @Test
  public void testConvertToRawIndexTask()
      throws Exception {
    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(getTableName());

    File testDataDir = new File(CommonConstants.Server.DEFAULT_INSTANCE_DATA_DIR + ""-0"", offlineTableName);
    if (!testDataDir.isDirectory()) {
      testDataDir = new File(CommonConstants.Server.DEFAULT_INSTANCE_DATA_DIR + ""-1"", offlineTableName);
    }
    Assert.assertTrue(testDataDir.isDirectory());
    File tableDataDir = testDataDir;

    // Check that all columns have dictionary
    File[] indexDirs = tableDataDir.listFiles();
    Assert.assertNotNull(indexDirs);
    for (File indexDir : indexDirs) {
      SegmentMetadata segmentMetadata = new SegmentMetadataImpl(indexDir);
      for (String columnName : segmentMetadata.getSchema().getColumnNames()) {
        Assert.assertTrue(segmentMetadata.getColumnMetadataFor(columnName).hasDictionary());
      }
    }

    // Should create the task queues and generate a ConvertToRawIndexTask task with 5 child tasks
    Assert.assertNotNull(_taskManager.scheduleTasks().get(ConvertToRawIndexTask.TASK_TYPE));
    Assert.assertTrue(_helixTaskResourceManager.getTaskQueues()
        .contains(PinotHelixTaskResourceManager.getHelixJobQueueName(ConvertToRawIndexTask.TASK_TYPE)));

    // Should generate one more ConvertToRawIndexTask task with 3 child tasks
    Assert.assertNotNull(_taskManager.scheduleTasks().get(ConvertToRawIndexTask.TASK_TYPE));

    // Should not generate more tasks
    Assert.assertNull(_taskManager.scheduleTasks().get(ConvertToRawIndexTask.TASK_TYPE));

    // Wait at most 600 seconds for all tasks COMPLETED and new segments refreshed
    TestUtils.waitForCondition(input -> {
      // Check task state
      for (TaskState taskState : _helixTaskResourceManager.getTaskStates(ConvertToRawIndexTask.TASK_TYPE).values()) {
        if (taskState != TaskState.COMPLETED) {
          return false;
        }
      }

      // Check segment ZK metadata
      for (SegmentZKMetadata segmentZKMetadata : _helixResourceManager.getSegmentsZKMetadata(offlineTableName)) {
        Map<String, String> customMap = segmentZKMetadata.getCustomMap();
        if (customMap == null || customMap.size() != 1 || !customMap
            .containsKey(ConvertToRawIndexTask.TASK_TYPE + MinionConstants.TASK_TIME_SUFFIX)) {
          return false;
        }
      }

      // Check segment metadata
      File[] indexDirs1 = tableDataDir.listFiles();
      Assert.assertNotNull(indexDirs1);
      for (File indexDir : indexDirs1) {
        SegmentMetadata segmentMetadata;

        // Segment metadata file might not exist if the segment is refreshing
        try {
          segmentMetadata = new SegmentMetadataImpl(indexDir);
        } catch (Exception e) {
          return false;
        }

        // The columns in COLUMNS_TO_CONVERT should have raw index
        List<String> rawIndexColumns = Arrays.asList(StringUtils.split(COLUMNS_TO_CONVERT, ','));
        for (String columnName : segmentMetadata.getSchema().getColumnNames()) {
          if (rawIndexColumns.contains(columnName)) {
            if (segmentMetadata.getColumnMetadataFor(columnName).hasDictionary()) {
              return false;
            }
          } else {
            if (!segmentMetadata.getColumnMetadataFor(columnName).hasDictionary()) {
              return false;
            }
          }
        }
      }

      return true;
    }, 600_000L, ""Failed to get all tasks COMPLETED and new segments refreshed"");
  }
"
"  @Test
  public void testPinotHelixResourceManagerAPIs() {
    // Instance APIs
    Assert.assertEquals(_helixResourceManager.getAllInstances().size(), 5);
    Assert.assertEquals(_helixResourceManager.getOnlineInstanceList().size(), 5);
    Assert.assertEquals(_helixResourceManager.getOnlineUnTaggedBrokerInstanceList().size(), 0);
    Assert.assertEquals(_helixResourceManager.getOnlineUnTaggedServerInstanceList().size(), 0);

    // Table APIs
    String rawTableName = getTableName();
    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(rawTableName);
    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(rawTableName);
    List<String> tableNames = _helixResourceManager.getAllTables();
    Assert.assertEquals(tableNames.size(), 2);
    Assert.assertTrue(tableNames.contains(offlineTableName));
    Assert.assertTrue(tableNames.contains(realtimeTableName));
    Assert.assertEquals(_helixResourceManager.getAllRawTables(), Collections.singletonList(rawTableName));
    Assert.assertEquals(_helixResourceManager.getAllRealtimeTables(), Collections.singletonList(realtimeTableName));

    // Tenant APIs
    Assert.assertEquals(_helixResourceManager.getAllBrokerTenantNames(), Collections.singleton(""TestTenant""));
    Assert.assertEquals(_helixResourceManager.getAllServerTenantNames(), Collections.singleton(""TestTenant""));
  }
"
" * <p>To enable the test, override it and add @Test annotation.
  public void testHardcodedQueries()
      throws Exception {
    // Here are some sample queries.
    String query;
    query = ""SELECT COUNT(*) FROM mytable WHERE DaysSinceEpoch = 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));
    query = ""SELECT COUNT(*) FROM mytable WHERE DaysSinceEpoch <> 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));
    query = ""SELECT COUNT(*) FROM mytable WHERE DaysSinceEpoch > 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));
    query = ""SELECT COUNT(*) FROM mytable WHERE DaysSinceEpoch >= 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));
    query = ""SELECT COUNT(*) FROM mytable WHERE DaysSinceEpoch < 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));
    query = ""SELECT COUNT(*) FROM mytable WHERE DaysSinceEpoch <= 16312 AND Carrier = 'DL'"";
    testQuery(query, Collections.singletonList(query));
    query = ""SELECT MAX(ArrTime), MIN(ArrTime) FROM mytable WHERE DaysSinceEpoch >= 16312"";
    testQuery(query, Arrays.asList(""SELECT MAX(ArrTime) FROM mytable WHERE DaysSinceEpoch >= 15312"",
        ""SELECT MIN(ArrTime) FROM mytable WHERE DaysSinceEpoch >= 15312""));
    query =
        ""SELECT SUM(TotalAddGTime) FROM mytable WHERE DivArrDelay NOT IN (67, 260) AND Carrier IN ('F9', 'B6') OR ""
            + ""DepTime BETWEEN 2144 AND 1926"";
    testQuery(query, Collections.singletonList(query));
  }
"
"  @Test
  public void testConsumerDirectoryExists() {
    File consumerDirectory = new File(CONSUMER_DIRECTORY, ""mytable_REALTIME"");
    assertEquals(consumerDirectory.exists(), _isConsumerDirConfigured,
        ""The off heap consumer directory does not exist"");
  }
"
"  @Test
  public void testSegmentFlushSize() {
    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(getTableName());
    List<SegmentZKMetadata> segmentsZKMetadata =
        ZKMetadataProvider.getSegmentsZKMetadata(_propertyStore, realtimeTableName);
    for (SegmentZKMetadata segmentZKMetadata : segmentsZKMetadata) {
      assertEquals(segmentZKMetadata.getSizeThresholdToFlushSegment(),
          getRealtimeSegmentFlushSize() / getNumKafkaPartitions());
    }
  }
"
"  @Test
  public void testInvertedIndexTriggering()
      throws Exception {
    long numTotalDocs = getCountStarResult();

    JsonNode queryResponse = postQuery(TEST_UPDATED_INVERTED_INDEX_QUERY);
    assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertTrue(queryResponse.get(""numEntriesScannedInFilter"").asLong() > 0L);

    TableConfig tableConfig = getRealtimeTableConfig();
    tableConfig.getIndexingConfig().setInvertedIndexColumns(UPDATED_INVERTED_INDEX_COLUMNS);
    updateTableConfig(tableConfig);
    reloadRealtimeTable(getTableName());

    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse1 = postQuery(TEST_UPDATED_INVERTED_INDEX_QUERY);
        // Total docs should not change during reload
        assertEquals(queryResponse1.get(""totalDocs"").asLong(), numTotalDocs);
        assertEquals(queryResponse1.get(""numConsumingSegmentsQueried"").asLong(), 2);
        assertTrue(queryResponse1.get(""minConsumingFreshnessTimeMs"").asLong() > _startTime);
        assertTrue(queryResponse1.get(""minConsumingFreshnessTimeMs"").asLong() < System.currentTimeMillis());
        return queryResponse1.get(""numEntriesScannedInFilter"").asLong() == 0;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to generate inverted index"");
  }
"
"  @Test(expectedExceptions = IOException.class)
  public void testAddHLCTableShouldFail()
      throws IOException {
    TableConfig tableConfig = new TableConfigBuilder(TableType.REALTIME).setTableName(""testTable"")
        .setStreamConfigs(Collections.singletonMap(""stream.kafka.consumer.type"", ""HIGHLEVEL"")).build();
    sendPostRequest(_controllerRequestURLBuilder.forTableCreate(), tableConfig.toJsonString());
  }
"
"  @Test
  public void testReload()
      throws Exception {
    testReload(false);
  }
"
"  @Test
  public void testHardcodedServerPartitionedSqlQueries()
      throws Exception {
    super.testHardcodedServerPartitionedSqlQueries();
  }
"
"  @Test
  public void testFileBasedSegmentWriterAndDefaultUploader()
      throws Exception {

    TableConfig offlineTableConfig = createOfflineTableConfig();
    addTableConfig(offlineTableConfig);

    SegmentWriter segmentWriter = new FileBasedSegmentWriter();
    segmentWriter.init(offlineTableConfig, _schema);
    SegmentUploader segmentUploader = new SegmentUploaderDefault();
    segmentUploader.init(offlineTableConfig);

    GenericRow reuse = new GenericRow();
    long totalDocs = 0;
    for (int i = 0; i < 3; i++) {
      AvroRecordReader avroRecordReader = new AvroRecordReader();
      avroRecordReader.init(_avroFiles.get(i), null, null);

      long numDocsInSegment = 0;
      while (avroRecordReader.hasNext()) {
        avroRecordReader.next(reuse);
        segmentWriter.collect(reuse);
        numDocsInSegment++;
        totalDocs++;
      }
      // flush to segment
      URI segmentTarURI = segmentWriter.flush();
      // upload
      segmentUploader.uploadSegment(segmentTarURI, null);

      // check num segments
      Assert.assertEquals(getNumSegments(), i + 1);
      // check numDocs in latest segment
      Assert.assertEquals(getNumDocsInLatestSegment(), numDocsInSegment);
      // check totalDocs in query
      checkTotalDocsInQuery(totalDocs);
    }
    segmentWriter.close();

    dropAllSegments(_tableNameWithType, TableType.OFFLINE);
    checkNumSegments(0);

    // upload all together using dir
    segmentUploader.uploadSegmentsFromDir(_tarDir.toURI(), null);
    // check num segments
    Assert.assertEquals(getNumSegments(), 3);
    // check totalDocs in query
    checkTotalDocsInQuery(totalDocs);

    dropOfflineTable(_tableNameWithType);
  }
"
"  @Test
  public void testSegmentUploadDownload()
      throws Exception {
    final Request query = new Request(""sql"", ""SELECT count(*) FROM "" + getTableName());

    ResultSetGroup resultBeforeOffline = getPinotConnection().execute(query);
    Assert.assertTrue(resultBeforeOffline.getResultSet(0).getLong(0) > 0);

    // schedule offline segment generation
    Assert.assertNotNull(_controllerStarter.getTaskManager().scheduleTasks());

    // wait for offline segments
    JsonNode offlineSegments = TestUtils.waitForResult(() -> {
      JsonNode segmentSets = JsonUtils.stringToJsonNode(
          sendGetRequest(_controllerRequestURLBuilder.forSegmentListAPI(getTableName()), AUTH_HEADER));
      JsonNode currentOfflineSegments =
          new IntRange(0, segmentSets.size()).stream().map(segmentSets::get).filter(s -> s.has(""OFFLINE""))
              .map(s -> s.get(""OFFLINE"")).findFirst().get();
      Assert.assertFalse(currentOfflineSegments.isEmpty());
      return currentOfflineSegments;
    }, 30000);

    // Verify constant row count
    ResultSetGroup resultAfterOffline = getPinotConnection().execute(query);
    Assert.assertEquals(resultBeforeOffline.getResultSet(0).getLong(0), resultAfterOffline.getResultSet(0).getLong(0));

    // download and sanity-check size of offline segment(s)
    for (int i = 0; i < offlineSegments.size(); i++) {
      String segment = offlineSegments.get(i).asText();
      Assert.assertTrue(
          sendGetRequest(_controllerRequestURLBuilder.forSegmentDownload(getTableName(), segment), AUTH_HEADER).length()
              > 200000); // download segment
    }
  }
"
"  @Test
  public void testDefaultServerConf()
      throws Exception {
    String expectedHost = NetUtils.getHostAddress();
    String expectedInstanceId = PREFIX_OF_SERVER_INSTANCE + expectedHost + ""_"" + DEFAULT_SERVER_NETTY_PORT;

    verifyInstanceConfig(new PinotConfiguration(), expectedInstanceId, expectedHost, DEFAULT_SERVER_NETTY_PORT);
  }
"
"  @Test
  public void testSetInstanceIdToHostname()
      throws Exception {
    String expectedHost = NetUtils.getHostnameOrAddress();
    String expectedInstanceId = PREFIX_OF_SERVER_INSTANCE + expectedHost + ""_"" + DEFAULT_SERVER_NETTY_PORT;

    Map<String, Object> properties = new HashMap<>();
    properties.put(SET_INSTANCE_ID_TO_HOSTNAME_KEY, true);

    verifyInstanceConfig(new PinotConfiguration(properties), expectedInstanceId, expectedHost,
        DEFAULT_SERVER_NETTY_PORT);
  }
"
"  @Test
  public void testCustomInstanceId()
      throws Exception {
    Map<String, Object> properties = new HashMap<>();
    properties.put(CONFIG_OF_INSTANCE_ID, CUSTOM_INSTANCE_ID);

    verifyInstanceConfig(new PinotConfiguration(properties), CUSTOM_INSTANCE_ID, NetUtils.getHostAddress(),
        DEFAULT_SERVER_NETTY_PORT);
  }
"
"  @Test
  public void testCustomHost()
      throws Exception {
    String expectedInstanceId = PREFIX_OF_SERVER_INSTANCE + CUSTOM_HOST + ""_"" + DEFAULT_SERVER_NETTY_PORT;

    Map<String, Object> properties = new HashMap<>();
    properties.put(KEY_OF_SERVER_NETTY_HOST, CUSTOM_HOST);

    verifyInstanceConfig(new PinotConfiguration(properties), expectedInstanceId, CUSTOM_HOST,
        DEFAULT_SERVER_NETTY_PORT);
  }
"
"  @Test
  public void testCustomPort()
      throws Exception {
    String expectedHost = NetUtils.getHostAddress();
    String expectedInstanceId = PREFIX_OF_SERVER_INSTANCE + expectedHost + ""_"" + CUSTOM_PORT;

    Map<String, Object> properties = new HashMap<>();
    properties.put(KEY_OF_SERVER_NETTY_PORT, CUSTOM_PORT);

    verifyInstanceConfig(new PinotConfiguration(properties), expectedInstanceId, expectedHost, CUSTOM_PORT);
  }
"
"  @Test
  public void testAllCustomServerConf()
      throws Exception {
    Map<String, Object> properties = new HashMap<>();
    properties.put(CONFIG_OF_INSTANCE_ID, CUSTOM_INSTANCE_ID);
    properties.put(KEY_OF_SERVER_NETTY_HOST, CUSTOM_HOST);
    properties.put(KEY_OF_SERVER_NETTY_PORT, CUSTOM_PORT);
    verifyInstanceConfig(new PinotConfiguration(properties), CUSTOM_INSTANCE_ID, CUSTOM_HOST, CUSTOM_PORT);
  }
"
"  @Test
  public void testPqlQueries()
      throws Exception {

    //Selection Query
    String pqlQuery = ""Select "" + MY_MAP_STR_FIELD_NAME + "" from "" + DEFAULT_TABLE_NAME;
    JsonNode pinotResponse = postQuery(pqlQuery);
    ArrayNode selectionResults = (ArrayNode) pinotResponse.get(""selectionResults"").get(""results"");
    Assert.assertNotNull(selectionResults);
    Assert.assertFalse(selectionResults.isEmpty());
    for (int i = 0; i < selectionResults.size(); i++) {
      String value = selectionResults.get(i).get(0).textValue();
      Assert.assertTrue(value.indexOf(""-k1-"") > 0);
    }

    //Filter Query
    pqlQuery = ""Select jsonExtractScalar(myMapStr,'$.k1','STRING') from "" + DEFAULT_TABLE_NAME
        + ""  where jsonExtractScalar(myMapStr,'$.k1','STRING') = 'value-k1-0'"";
    pinotResponse = postQuery(pqlQuery);
    selectionResults = (ArrayNode) pinotResponse.get(""selectionResults"").get(""results"");
    Assert.assertNotNull(selectionResults);
    Assert.assertFalse(selectionResults.isEmpty());
    for (int i = 0; i < selectionResults.size(); i++) {
      String value = selectionResults.get(i).get(0).textValue();
      Assert.assertEquals(value, ""value-k1-0"");
    }
    pqlQuery =
        ""Select "" + MY_MAP_STR_K1_FIELD_NAME + "" from "" + DEFAULT_TABLE_NAME + ""  where "" + MY_MAP_STR_K1_FIELD_NAME
            + "" = 'value-k1-0'"";
    pinotResponse = postQuery(pqlQuery);
    selectionResults = (ArrayNode) pinotResponse.get(""selectionResults"").get(""results"");
    Assert.assertNotNull(selectionResults);
    Assert.assertFalse(selectionResults.isEmpty());
    for (int i = 0; i < selectionResults.size(); i++) {
      String value = selectionResults.get(i).get(0).textValue();
      Assert.assertEquals(value, ""value-k1-0"");
    }

    //selection order by
    pqlQuery = ""Select jsonExtractScalar(myMapStr,'$.k1','STRING') from "" + DEFAULT_TABLE_NAME
        + "" order by jsonExtractScalar(myMapStr,'$.k1','STRING')"";
    pinotResponse = postQuery(pqlQuery);
    selectionResults = (ArrayNode) pinotResponse.get(""selectionResults"").get(""results"");
    Assert.assertNotNull(selectionResults);
    Assert.assertFalse(selectionResults.isEmpty());
    for (int i = 0; i < selectionResults.size(); i++) {
      String value = selectionResults.get(i).get(0).textValue();
      Assert.assertTrue(value.indexOf(""-k1-"") > 0);
    }
    pqlQuery =
        ""Select "" + MY_MAP_STR_K1_FIELD_NAME + "" from "" + DEFAULT_TABLE_NAME + "" order by "" + MY_MAP_STR_K1_FIELD_NAME;
    pinotResponse = postQuery(pqlQuery);
    selectionResults = (ArrayNode) pinotResponse.get(""selectionResults"").get(""results"");
    Assert.assertNotNull(selectionResults);
    Assert.assertFalse(selectionResults.isEmpty());
    for (int i = 0; i < selectionResults.size(); i++) {
      String value = selectionResults.get(i).get(0).textValue();
      Assert.assertTrue(value.indexOf(""-k1-"") > 0);
    }

    //Group By Query
    pqlQuery = ""Select count(*) from "" + DEFAULT_TABLE_NAME + "" group by jsonExtractScalar(myMapStr,'$.k1','STRING')"";
    pinotResponse = postQuery(pqlQuery);
    Assert.assertNotNull(pinotResponse.get(""aggregationResults""));
    JsonNode groupByResult = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    Assert.assertNotNull(groupByResult);
    Assert.assertTrue(groupByResult.isArray());
    Assert.assertFalse(groupByResult.isEmpty());

    pqlQuery = ""Select count(*) from "" + DEFAULT_TABLE_NAME + "" group by "" + MY_MAP_STR_K1_FIELD_NAME;
    pinotResponse = postQuery(pqlQuery);
    Assert.assertNotNull(pinotResponse.get(""aggregationResults""));
    groupByResult = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    Assert.assertNotNull(groupByResult);
    Assert.assertTrue(groupByResult.isArray());
    Assert.assertFalse(groupByResult.isEmpty());
  }
"
"  @Test
  public void testSqlQueries()
      throws Exception {
    //Selection Query
    String sqlQuery = ""Select myMapStr from "" + DEFAULT_TABLE_NAME;
    JsonNode pinotResponse = postSqlQuery(sqlQuery);
    ArrayNode rows = (ArrayNode) pinotResponse.get(""resultTable"").get(""rows"");
    Assert.assertNotNull(rows);
    Assert.assertFalse(rows.isEmpty());
    for (int i = 0; i < rows.size(); i++) {
      String value = rows.get(i).get(0).textValue();
      Assert.assertTrue(value.indexOf(""-k1-"") > 0);
    }

    //Filter Query
    sqlQuery = ""Select jsonExtractScalar(myMapStr,'$.k1','STRING') from "" + DEFAULT_TABLE_NAME
        + ""  where jsonExtractScalar(myMapStr,'$.k1','STRING') = 'value-k1-0'"";
    pinotResponse = postSqlQuery(sqlQuery);
    rows = (ArrayNode) pinotResponse.get(""resultTable"").get(""rows"");
    Assert.assertNotNull(rows);
    Assert.assertFalse(rows.isEmpty());
    for (int i = 0; i < rows.size(); i++) {
      String value = rows.get(i).get(0).textValue();
      Assert.assertEquals(value, ""value-k1-0"");
    }

    //selection order by
    sqlQuery = ""Select jsonExtractScalar(myMapStr,'$.k1','STRING') from "" + DEFAULT_TABLE_NAME
        + "" order by jsonExtractScalar(myMapStr,'$.k1','STRING')"";
    pinotResponse = postSqlQuery(sqlQuery);
    rows = (ArrayNode) pinotResponse.get(""resultTable"").get(""rows"");
    Assert.assertNotNull(rows);
    Assert.assertFalse(rows.isEmpty());
    for (int i = 0; i < rows.size(); i++) {
      String value = rows.get(i).get(0).textValue();
      Assert.assertTrue(value.indexOf(""-k1-"") > 0);
    }

    //Group By Query
    sqlQuery = ""Select jsonExtractScalar(myMapStr,'$.k1','STRING'), count(*) from "" + DEFAULT_TABLE_NAME
        + "" group by jsonExtractScalar(myMapStr,'$.k1','STRING')"";
    pinotResponse = postSqlQuery(sqlQuery);
    Assert.assertNotNull(pinotResponse.get(""resultTable""));
    rows = (ArrayNode) pinotResponse.get(""resultTable"").get(""rows"");
    for (int i = 0; i < rows.size(); i++) {
      String value = rows.get(i).get(0).textValue();
      Assert.assertTrue(value.indexOf(""-k1-"") > 0);
    }
  }
"
"	@Test
	public void testDefaults() {
		String[] args = new String[] { ""-a"", ""json"" };
		DumpProcessingOutputAction action = getActionFromArgs(args);

		assertEquals(action.compressionType,
				DumpProcessingOutputAction.COMPRESS_NONE);
		assertFalse(action.useStdOut);
	}
"
"	@Test
	public void testCompressionOutputArgumentsShort() {
		String[] args = new String[] { ""-a"", ""json"", ""-z"", ""bz2"" };
		DumpProcessingOutputAction action = getActionFromArgs(args);

		assertEquals(action.compressionType,
				DumpProcessingOutputAction.COMPRESS_BZ2);
	}
"
"	@Test
	public void testCompressionOutputArgumentsLong() {
		String[] args = new String[] { ""-a"", ""json"", ""--compression"", ""GZ"" };
		DumpProcessingOutputAction action = getActionFromArgs(args);

		assertEquals(action.compressionType,
				DumpProcessingOutputAction.COMPRESS_GZIP);
	}
"
"	@Test
	public void testStdOutOutputArgumentsShort() {
		String[] args = new String[] { ""-a"", ""json"", ""-s"" };
		DumpProcessingOutputAction action = getActionFromArgs(args);

		assertTrue(action.useStdOut);
	}
"
"	@Test
	public void testStdOutOutputArgumentsLong() {
		String[] args = new String[] { ""-a"", ""json"", ""--stdout"" };
		DumpProcessingOutputAction action = getActionFromArgs(args);

		assertTrue(action.useStdOut);
	}
"
"	@Test
	public void testInsertDumpInformation() {
		DumpProcessingOutputAction action = new JsonSerializationAction();
		action.setDumpInformation(""wikidata"", ""20150131"");
		String result = action
				.insertDumpInformation(""{PROJECT}-{DATE}-dump.json"");
		assertEquals(result, ""wikidata-20150131-dump.json"");
	}
"
"	@Test
	public void testDefaults() {
		String[] args = new String[] { ""-a"", ""json"" };
		DumpProcessingOutputAction action = DumpProcessingOutputActionTest
				.getActionFromArgs(args);

		assertTrue(action instanceof JsonSerializationAction);
		assertFalse(action.needsSites());
		assertTrue(action.isReady());
		assertEquals(action.getActionName(), ""JsonSerializationAction"");
	}
"
"	@Test
	public void testJsonOutput() throws IOException {
		String[] args = new String[] { ""-a"", ""json"", ""-o"",
				""/path/to/output.json"" };

		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);

		ClientConfiguration config = new ClientConfiguration(args);
		JsonSerializationAction jsa = (JsonSerializationAction) config
				.getActions().get(0);

		ItemIdValue subject1 = Datamodel.makeWikidataItemIdValue(""Q42"");
		ItemIdValue subject2 = Datamodel.makeWikidataItemIdValue(""Q43"");
		MonolingualTextValue mtv1 = Datamodel.makeMonolingualTextValue(""Test1"",
				""en"");
		MonolingualTextValue mtv2 = Datamodel.makeMonolingualTextValue(""Test2"",
				""fr"");

		ItemDocument id1 = Datamodel.makeItemDocument(subject1,
				Arrays.asList(mtv1, mtv2), Arrays.asList(mtv1),
				Collections.<MonolingualTextValue> emptyList(),
				Collections.<StatementGroup> emptyList(),
				Collections.<String, SiteLink> emptyMap());

		ItemDocument id2 = Datamodel.makeItemDocument(subject2,
				Collections.<MonolingualTextValue> emptyList(),
				Arrays.asList(mtv2),
				Collections.<MonolingualTextValue> emptyList(),
				Collections.<StatementGroup> emptyList(),
				Collections.<String, SiteLink> emptyMap());

		PropertyDocument pd1 = Datamodel
				.makePropertyDocument(
						Datamodel.makeWikidataPropertyIdValue(""P31""),
						Arrays.asList(mtv1),
						Collections.<MonolingualTextValue> emptyList(),
						Arrays.asList(mtv1),
						Collections.emptyList(),
						Datamodel
								.makeDatatypeIdValue(DatatypeIdValue.DT_MONOLINGUAL_TEXT));

		jsa.open();
		jsa.processItemDocument(id1);
		jsa.processPropertyDocument(pd1);
		jsa.processItemDocument(id2);
		jsa.close();

		MockDirectoryManager mdm = new MockDirectoryManager(
				Paths.get(""/path/to/""), false);

		ObjectMapper mapper = new DatamodelMapper(Datamodel.SITE_WIKIDATA);
		ObjectReader documentReader = mapper
				.readerFor(EntityDocumentImpl.class);
		MappingIterator<EntityDocument> documentIterator = documentReader
				.readValues(mdm.getInputStreamForFile(""output.json"",
						CompressionType.NONE));

		List<EntityDocument> results = new ArrayList<>();
		while (documentIterator.hasNextValue()) {
			EntityDocument document = documentIterator.nextValue();
			results.add(document);
		}
		documentIterator.close();

		assertEquals(3, results.size());
		assertEquals(id1, results.get(0));
		assertEquals(pd1, results.get(1));
		assertEquals(id2, results.get(2));

	}
"
"	@Test
	public void testJsonGzipOutput() throws IOException {
		String[] args = new String[] { ""-a"", ""json"", ""-o"",
				""/path/to/output.json"", ""-z"", ""gz"" };

		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);

		ClientConfiguration config = new ClientConfiguration(args);
		JsonSerializationAction jsa = (JsonSerializationAction) config
				.getActions().get(0);

		ItemIdValue subject1 = Datamodel.makeWikidataItemIdValue(""Q42"");
		MonolingualTextValue mtv1 = Datamodel.makeMonolingualTextValue(""Test1"",
				""en"");
		MonolingualTextValue mtv2 = Datamodel.makeMonolingualTextValue(""Test2"",
				""fr"");

		ItemDocument id1 = Datamodel.makeItemDocument(subject1,
				Arrays.asList(mtv1, mtv2), Arrays.asList(mtv1),
				Collections.<MonolingualTextValue> emptyList(),
				Collections.<StatementGroup> emptyList(),
				Collections.<String, SiteLink> emptyMap());

		jsa.open();
		jsa.processItemDocument(id1);
		jsa.close();

		MockDirectoryManager mdm = new MockDirectoryManager(
				Paths.get(""/path/to/""), false);

		ObjectMapper mapper = new DatamodelMapper(Datamodel.SITE_WIKIDATA);
		ObjectReader documentReader = mapper.readerFor(EntityDocumentImpl.class);
		MappingIterator<EntityDocument> documentIterator = documentReader
				.readValues(mdm.getInputStreamForFile(""output.json.gz"",
						CompressionType.GZIP));

		List<EntityDocument> results = new ArrayList<>();
		while (documentIterator.hasNextValue()) {
			EntityDocument document = documentIterator.nextValue();
			results.add(document);
		}
		documentIterator.close();

		assertEquals(1, results.size());
		assertEquals(id1, results.get(0));
	}
"
"	@Test
	public void testJsonBz2Output() throws IOException {
		String[] args = new String[] { ""-a"", ""json"", ""-o"", ""output.json"", ""-z"",
				""bz2"" };

		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);

		ClientConfiguration config = new ClientConfiguration(args);
		JsonSerializationAction jsa = (JsonSerializationAction) config
				.getActions().get(0);

		ItemIdValue subject1 = Datamodel.makeWikidataItemIdValue(""Q42"");
		MonolingualTextValue mtv1 = Datamodel.makeMonolingualTextValue(""Test1"",
				""en"");
		MonolingualTextValue mtv2 = Datamodel.makeMonolingualTextValue(""Test2"",
				""fr"");

		ItemDocument id1 = Datamodel.makeItemDocument(subject1,
				Arrays.asList(mtv1, mtv2), Arrays.asList(mtv1),
				Collections.<MonolingualTextValue> emptyList(),
				Collections.<StatementGroup> emptyList(),
				Collections.<String, SiteLink> emptyMap());

		jsa.open();
		jsa.processItemDocument(id1);
		jsa.close();

		MockDirectoryManager mdm = new MockDirectoryManager(Paths.get("".""),
				false);

		ObjectMapper mapper = new DatamodelMapper(Datamodel.SITE_WIKIDATA);
		ObjectReader documentReader = mapper.readerFor(EntityDocumentImpl.class);
		MappingIterator<EntityDocument> documentIterator = documentReader
				.readValues(mdm.getInputStreamForFile(""output.json.bz2"",
						CompressionType.BZ2));

		List<EntityDocument> results = new ArrayList<>();
		while (documentIterator.hasNextValue()) {
			EntityDocument document = documentIterator.nextValue();
			results.add(document);
		}
		documentIterator.close();

		assertEquals(1, results.size());
		assertEquals(id1, results.get(0));
	}
"
"	@Test
	public void testDefaults() {
		String[] args = new String[] { ""-a"", ""rdf"", ""--rdftasks"", ""entities"" };
		DumpProcessingOutputAction action = DumpProcessingOutputActionTest
				.getActionFromArgs(args);

		assertTrue(action instanceof RdfSerializationAction);
		assertTrue(action.needsSites());
		assertTrue(action.isReady());
		assertEquals(action.getActionName(), ""RdfSerializationAction"");
	}
"
"	@Test
	public void testDefaultsNoTasks() {
		String[] args = new String[] { ""-a"", ""rdf"", ""--stdout"" };
		DumpProcessingOutputAction action = DumpProcessingOutputActionTest
				.getActionFromArgs(args);
		action.open();
		action.close();

		assertTrue(action instanceof RdfSerializationAction);
		assertFalse(action.needsSites());
		assertFalse(action.isReady());
	}
"
"	@Test
	public void testSerializerSetup() {
		String[] args = new String[] { ""-a"", ""rdf"", ""--stdout"", ""--rdftasks"",
				""properties,labels"" };
		RdfSerializationAction action = (RdfSerializationAction) DumpProcessingOutputActionTest
				.getActionFromArgs(args);
		action.open(); // creates and initializes serializer (prints to stdout)
		action.close(); // just to test that this causes no exceptions

		assertTrue(action.needsSites());
		assertEquals(action.serializer.getTasks(),
				RdfSerializer.TASK_PROPERTIES | RdfSerializer.TASK_LABELS);

	}
"
"	@Test
	public void testDefaultLoggingConfig() throws ParseException, IOException {
		String[] args = new String[] {};
		Client client = new Client(mockDpc, args);
		client.performActions(); // print help

		assertEquals(Level.INFO, Client.consoleAppender.getThreshold());
		assertEquals(Level.WARN, Client.errorAppender.getThreshold());
	}
"
"	@Test
	public void testQuietStdOutLoggingConfig() throws ParseException,
			IOException {
		String[] args = new String[] { ""-a"", ""json"", ""-s"" };
		new Client(mockDpc, args);

		assertEquals(Level.OFF, Client.consoleAppender.getThreshold());
		assertEquals(Level.WARN, Client.errorAppender.getThreshold());
	}
"
"	@Test
	public void testQuietLoggingConfig() throws ParseException, IOException {
		String[] TEST_ARGS = new String[] { ""-a"", ""json"", ""-q"" };
		new Client(mockDpc, TEST_ARGS);

		assertEquals(Level.OFF, Client.consoleAppender.getThreshold());
		assertEquals(Level.WARN, Client.errorAppender.getThreshold());
	}
"
"	@Test
	public void testJsonOutput() {
		String[] args = { ""-a"", ""json"", ""-o"", ""output/wikidata.json"" };
		ClientConfiguration configuration = new ClientConfiguration(args);
		DumpProcessingAction action = configuration.actions.get(0);
		action.open();
		action.close();
		assertTrue(action
				.getReport()
				.matches(
						""Finished serialization of \\d+ EntityDocuments in file output/wikidata.json""));
	}
"
"	@Test
	public void testRdfOutput() {
		String[] args = { ""-a"", ""rdf"", ""-o"", ""output/wikidata.rdf"" };
		ClientConfiguration configuration = new ClientConfiguration(args);
		DumpProcessingAction action = configuration.actions.get(0);
		action.open();
		action.close();
		assertTrue(action
				.getReport()
				.matches(
						""Finished serialization of \\d+ RDF triples in file output/wikidata.rdf""));
	}
"
"	@Test
	public void testSitesAction() throws ParseException, IOException {
		String[] args = new String[] { ""-a"", ""rdf"", ""--rdftasks"",
				""items,labels"" };
		Client client = new Client(mockDpc, args);
		client.performActions();

		Mockito.verify(mockDpc).processDump(Mockito.<MwDumpFile> any());
		Mockito.verify(mockDpc).getSitesInformation();
	}
"
"	@Test
	public void testSetDumpsDirectoryException() throws ParseException,
			IOException {
		Mockito.doThrow(new IOException(""Mock exception for testing.""))
				.when(mockDpc).setDownloadDirectory(Mockito.anyString());

		String[] args = new String[] { ""-a"", ""rdf"", ""--rdftasks"",
				""items,labels"", ""--dumps"", ""/tmp/"" };
		Client client = new Client(mockDpc, args);
		client.performActions(); // print help

		Mockito.verify(mockDpc, Mockito.never()).processDump(
				Mockito.<MwDumpFile> any());
		Mockito.verify(mockDpc, Mockito.never()).getSitesInformation();
	}
"
"	@Test
	public void testSitesActionException() throws ParseException, IOException {
		Mockito.doThrow(new IOException()).when(mockDpc).getSitesInformation();

		String[] args = new String[] { ""-a"", ""rdf"", ""--rdftasks"",
				""items,labels"" };
		Client client = new Client(mockDpc, args);
		client.performActions(); // print help

		Mockito.verify(mockDpc, Mockito.never()).processDump(
				Mockito.<MwDumpFile> any());
		Mockito.verify(mockDpc).getSitesInformation();
	}
"
"	@Test
	public void testNonSitesAction() throws ParseException, IOException {
		String[] args = new String[] { ""-a"", ""json"", ""-q"" };
		Client client = new Client(mockDpc, args);
		client.performActions(); // print help

		Mockito.verify(mockDpc).processDump(Mockito.<MwDumpFile> any());
		Mockito.verify(mockDpc, Mockito.never()).getSitesInformation();
	}
"
"	@Test
	public void testWriteReport() throws IOException {
		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);

		MockDirectoryManager mdm = new MockDirectoryManager(
				Paths.get(""/output/""), false);

		String[] args = {""-n"", ""-a"", ""rdf"", ""--rdftasks"", ""aliases"", ""-o"",
				""/output/wikidata.rdf"", ""-r"", ""/output/report.txt"" };

		Client client = new Client(mockDpc, args);
		DumpProcessingAction action = client.clientConfiguration.actions.get(0);
		action.open();
		action.close();
		client.writeReport();
		assertTrue(IOUtils
				.toString(
						mdm.getInputStreamForFile(""report.txt"",
								CompressionType.NONE))
				.matches(
						""RdfSerializationAction: Finished serialization of \\d+ RDF triples in file /output/wikidata.rdf""
								+ System.lineSeparator()));

	}
"
"	@Test
	public void testInsertDumpInformation() throws IOException {
		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);

		MockDirectoryManager mdm = new MockDirectoryManager(
				Paths.get(""/output/""), false);

		String[] args = { ""-n"", ""-a"", ""rdf"", ""-o"", ""/output/wikidata.rdf"",
				""--rdftasks"", ""aliases"", ""-r"", ""/output/report-{DATE}.txt"" };

		Client client = new Client(mockDpc, args);
		client.performActions();

		assertTrue(mdm.hasFile(""/output/report-""
				+ client.clientConfiguration.getDateStamp() + "".txt""));
	}
"
"	@Test
	public void testNonExistingLocalDump() {
		String[] args = { ""-f"", ""./asfjl.json"" };
		Client client = new Client(mockDpc, args);
		client.performActions();

		Mockito.verify(mockDpc, Mockito.never()).processDump(
				Mockito.<MwDumpFile> any());
	}
"
"	@Test
	public void testReadConfigFile() throws IOException {
		String configFile = ""src/test/resources/testConf.ini"";
		String[] args = new String[] { ""-c"", configFile };
		ClientConfiguration config = new ClientConfiguration(args);

		assertTrue(config.getOfflineMode());
		assertTrue(config.isQuiet());
		assertEquals(""dumps/wikidata/"", config.getDumpDirectoryLocation());
		assertEquals(Collections.<String> emptySet(),
				config.getFilterSiteKeys());
		assertEquals(Collections.singleton(Datamodel
						.makeWikidataPropertyIdValue(""P31"")),
				config.getFilterProperties());
		Set<String> langFilters = new HashSet<>();
		langFilters.add(""fr"");
		langFilters.add(""zh"");
		assertEquals(langFilters, config.getFilterLanguages());

		assertEquals(2, config.getActions().size());
		assertTrue(config.getActions().get(0) instanceof RdfSerializationAction);
		assertTrue(config.getActions().get(1) instanceof JsonSerializationAction);
		RdfSerializationAction rdfAction = (RdfSerializationAction) config
				.getActions().get(0);
		JsonSerializationAction jsonAction = (JsonSerializationAction) config
				.getActions().get(1);

		assertTrue(rdfAction.useStdOut);
		assertEquals(DumpProcessingOutputAction.COMPRESS_GZIP,
				rdfAction.compressionType);
		assertEquals(""/tmp/wikidata-items.nt"", rdfAction.outputDestination);
		assertEquals(RdfSerializer.TASK_ITEMS | RdfSerializer.TASK_STATEMENTS
				| RdfSerializer.TASK_TERMS, rdfAction.tasks);

		assertFalse(jsonAction.useStdOut);
		assertEquals(DumpProcessingOutputAction.COMPRESS_BZ2,
				jsonAction.compressionType);
		assertEquals(""/tmp/wikidata-dump.json"", jsonAction.outputDestination);
	}
"
"	@Test
	public void testReadConfigFile2() throws IOException {
		String configFile = ""src/test/resources/testConf2.ini"";
		String[] args = new String[] { ""-c"", configFile };
		ClientConfiguration config = new ClientConfiguration(args);

		assertFalse(config.getOfflineMode());
		assertFalse(config.isQuiet());
		assertEquals(""testfile.json.gz"", config.getInputDumpLocation());
		assertEquals(""report.txt"", config.getReportFileName());
		// remaining content was already tested above
	}
"
"	@Test
	public void testDefaultArguments() {
		String[] args = new String[] {};
		ClientConfiguration config = new ClientConfiguration(args);
		assertFalse(config.getOfflineMode());
		assertEquals(null, config.getDumpDirectoryLocation());
		assertEquals(null, config.getFilterLanguages());
		assertEquals(null, config.getFilterSiteKeys());
		assertEquals(null, config.getFilterProperties());
		assertEquals(null, config.getReportFileName());
		assertEquals(null, config.getInputDumpLocation());
		assertEquals(null, config.getLocalDumpFile());
		assertFalse(config.isQuiet());
	}
"
"	@Test
	public void testUnknownAction() {
		String[] args = new String[] { ""-a"", ""notImplemented"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertEquals(0, config.getActions().size());
	}
"
"	@Test
	public void testUnknownArguments() {
		String[] args = new String[] { ""--unknown"", ""-foo"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertFalse(config.getOfflineMode());
		assertEquals(null, config.getDumpDirectoryLocation());
		assertFalse(config.isQuiet());
	}
"
"	@Test
	public void testDumpLocationArgumentsShort() {
		String[] args = new String[] { ""-d"", ""dumps/wikidata/"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertEquals(""dumps/wikidata/"", config.getDumpDirectoryLocation());
	}
"
"	@Test
	public void testDumpLocationArgumentsLong() {
		String[] args = new String[] { ""--dumps"", ""dumps/wikidata/"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertEquals(""dumps/wikidata/"", config.getDumpDirectoryLocation());
	}
"
"	@Test
	public void testOfflineModeArgumentsShort() {
		String[] args = new String[] { ""-n"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertTrue(config.getOfflineMode());
	}
"
"	@Test
	public void testOfflineModeArgumentsLong() {
		String[] args = new String[] { ""--offline"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertTrue(config.getOfflineMode());
	}
"
"	@Test
	public void testStdOutOutputArgumentsShort() {
		String[] args = new String[] { ""-a"", ""json"", ""-s"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertTrue(config.isQuiet());
	}
"
"	@Test
	public void testStdOutOutputArgumentsLong() {
		String[] args = new String[] { ""--action"", ""json"", ""--stdout"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertTrue(config.isQuiet());
	}
"
"	@Test
	public void testQuietArgumentsShort() {
		String[] args = new String[] { ""-q"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertTrue(config.isQuiet());
	}
"
"	@Test
	public void testQuietArgumentsLong() {
		String[] args = new String[] { ""--quiet"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertTrue(config.isQuiet());
	}
"
"	@Test
	public void testReportArgumentsShort() {
		String[] args = new String[] { ""-r"", ""output/report.txt"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertEquals(""output/report.txt"", config.getReportFileName());
	}
"
"	@Test
	public void testReportArgumentsLong() {
		String[] args = new String[] { ""--report"", ""output/report.txt"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertEquals(""output/report.txt"", config.getReportFileName());
	}
"
"	@Test
	public void testLanguageFilterArguments() {
		String[] args = new String[] { ""--fLang"", ""en,de"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<String> langFilters = new HashSet<>();
		langFilters.add(""en"");
		langFilters.add(""de"");

		assertEquals(langFilters, config.getFilterLanguages());
	}
"
"	@Test
	public void testLanguageFilterArgumentsEmpty() {
		String[] args = new String[] { ""--fLang"", ""-"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<String> langFilters = new HashSet<>();

		assertEquals(langFilters, config.getFilterLanguages());
	}
"
"	@Test
	public void testSiteLinkFilterArguments() {
		String[] args = new String[] { ""--fSite"", ""fawiki,dewiki"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<String> siteFilters = new HashSet<>();
		siteFilters.add(""fawiki"");
		siteFilters.add(""dewiki"");

		assertEquals(siteFilters, config.getFilterSiteKeys());
	}
"
"	@Test
	public void testSiteLinkFilterArgumentsEmpty() {
		String[] args = new String[] { ""--fSite"", ""-"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<String> siteFilters = new HashSet<>();

		assertEquals(siteFilters, config.getFilterSiteKeys());
	}
"
"	@Test
	public void testPropertyFilterArguments() {
		String[] args = new String[] { ""--fProp"", ""P100,P31"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<PropertyIdValue> propFilters = new HashSet<>();
		propFilters.add(Datamodel.makeWikidataPropertyIdValue(""P31""));
		propFilters.add(Datamodel.makeWikidataPropertyIdValue(""P100""));

		assertEquals(propFilters, config.getFilterProperties());
	}
"
"	@Test
	public void testPropertyFilterArgumentsEmpty() {
		String[] args = new String[] { ""--fProp"", ""-"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<PropertyIdValue> propFilters = new HashSet<>();

		assertEquals(propFilters, config.getFilterProperties());
	}
"
"	@Test
	public void testLocalDumpFileLong() {
		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);
		String[] args = new String[] { ""--input"", ""dumptest.json"" };
		ClientConfiguration config = new ClientConfiguration(args);

		MwDumpFile df = config.getLocalDumpFile();

		assertEquals(""dumptest.json"", config.getInputDumpLocation());
		assertTrue(df instanceof MwLocalDumpFile);
		MwLocalDumpFile ldf = (MwLocalDumpFile) df;

		assertEquals(Paths.get(""dumptest.json"").toAbsolutePath(), ldf.getPath());
	}
"
"	@Test
	public void testLocalDumpFileShort() {
		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);
		String[] args = new String[] { ""-i"", ""dumptest.json"" };
		ClientConfiguration config = new ClientConfiguration(args);

		MwDumpFile df = config.getLocalDumpFile();

		assertEquals(""dumptest.json"", config.getInputDumpLocation());
		assertTrue(df instanceof MwLocalDumpFile);
		MwLocalDumpFile ldf = (MwLocalDumpFile) df;

		assertEquals(Paths.get(""dumptest.json"").toAbsolutePath(), ldf.getPath());
	}
"
"	@Test
	public void testIteration() {
		List<String> list1 = new ArrayList<String>();
		list1.add(""1"");
		list1.add(""2"");
		List<String> list2 = new ArrayList<String>();
		list2.add(""3"");
		List<String> list3 = new ArrayList<String>();
		List<String> list4 = new ArrayList<String>();
		list4.add(""4"");

		List<List<String>> listOfLists = new ArrayList<>();
		listOfLists.add(list1);
		listOfLists.add(list2);
		listOfLists.add(list3);
		listOfLists.add(list4);

		NestedIterator<String> nestedIterator = new NestedIterator<>(
				listOfLists);

		assertTrue(nestedIterator.hasNext());
		assertEquals(""1"", nestedIterator.next());
		assertTrue(nestedIterator.hasNext());
		assertEquals(""2"", nestedIterator.next());
		assertTrue(nestedIterator.hasNext());
		assertEquals(""3"", nestedIterator.next());
		assertTrue(nestedIterator.hasNext());
		assertEquals(""4"", nestedIterator.next());
		assertEquals(false, nestedIterator.hasNext());
	}
"
"	@Test(expected = UnsupportedOperationException.class)
	public void removeNotSupported() {
		NestedIterator<String> nestedIterator = new NestedIterator<>(
				Collections.singletonList(Collections.singletonList(""Test"")));
		nestedIterator.remove();
	}
"
"	@Test(expected = NoSuchElementException.class)
	public void iterateBeyondInnerList() {
		NestedIterator<String> nestedIterator = new NestedIterator<>(
				Collections.singletonList(Collections.<String> emptyList()));
		nestedIterator.next();
	}
"
"	@Test(expected = NoSuchElementException.class)
	public void iterateBeyondOuterList() {
		NestedIterator<String> nestedIterator = new NestedIterator<>(
				Collections.<List<String>> emptyList());
		nestedIterator.next();
	}
"
"	@Test
	public void createDirectoryManagerString() throws IOException {
		Path path = Paths.get(System.getProperty(""user.dir""));
		DirectoryManagerFactory
				.setDirectoryManagerClass(DirectoryManagerImpl.class);
		DirectoryManager dm = DirectoryManagerFactory.createDirectoryManager(
				System.getProperty(""user.dir""), true);
		assertTrue(dm instanceof DirectoryManagerImpl);
		DirectoryManagerImpl dmi = (DirectoryManagerImpl) dm;
		assertTrue(dmi.readOnly);
		assertEquals(path, dmi.directory);
	}
"
"	@Test
	public void createDefaultDirectoryManagerPath() throws IOException {
		Path path = Paths.get(System.getProperty(""user.dir""));
		DirectoryManager dm = DirectoryManagerFactory.createDirectoryManager(
				path, true);
		assertTrue(dm instanceof DirectoryManagerImpl);
		DirectoryManagerImpl dmi = (DirectoryManagerImpl) dm;
		assertTrue(dmi.readOnly);
		assertEquals(path, dmi.directory);
	}
"
"	@Test(expected = RuntimeException.class)
	public void createDirectoryManagerNoConstructor() throws IOException {
		DirectoryManagerFactory
				.setDirectoryManagerClass(TestDirectoryManager.class);
		DirectoryManagerFactory.createDirectoryManager(""/"", true);
	}
"
"	@Test(expected = IOException.class)
	public void createDirectoryManagerIoException() throws IOException {
		DirectoryManagerFactory.createDirectoryManager(
				""/nonexisting-directory/123456789/hopefully"", true);
	}
"
"	@Test
	public void testSetUserAgent() {
		WebResourceFetcherImpl.setUserAgent(""My user agent"");
		assertEquals(""My user agent"", WebResourceFetcherImpl.getUserAgent());
	}
"
"	@Test
	public void testSetProxy() {
		Proxy proxy = new Proxy(Proxy.Type.HTTP, new InetSocketAddress(
				""test.adress"", 8080));
		WebResourceFetcherImpl.setProxy(proxy);
		assertTrue(WebResourceFetcherImpl.hasProxy());
		assertEquals(proxy, WebResourceFetcherImpl.getProxy());
	}
"
"	@Test
	public void testToString() throws IOException {
		assertEquals(Paths.get(System.getProperty(""user.dir"")).toString(),
				dm.toString());
	}
"
"	@Test(expected = IOException.class)
	public void MissingSubdirectoryReadOnly() throws IOException {
		dm.getSubdirectoryManager(""1 2 3 not a subdirectory that exists in the test system, hopefully"");
	}
"
"	@Test(expected = IOException.class)
	public void OutputStreamReadOnly() throws IOException {
		dm.getOutputStreamForFile(""file.txt"");
	}
"
"	@Test(expected = IOException.class)
	public void NoCreateFileStringReadOnly() throws IOException {
		dm.createFile(""new-test-file.txt"", ""new contents"");
	}
"
"	@Test(expected = IOException.class)
	public void NoCreateFileInputStreamReadOnly() throws IOException {
		ByteArrayInputStream in = new ByteArrayInputStream(
				""new contents"".getBytes(StandardCharsets.UTF_8));
		dm.createFile(""new-test-file.txt"", in);
	}
"
"	@Test(expected = IOException.class)
	public void NoCreateFileAtomicInputStreamReadOnly() throws IOException {
		ByteArrayInputStream in = new ByteArrayInputStream(
				""new contents"".getBytes(StandardCharsets.UTF_8));
		dm.createFileAtomic(""new-test-file.txt"", in);
	}
"
"	@Test
	public void getCompressionInputStreamNone() throws IOException {
		ByteArrayInputStream in = new ByteArrayInputStream(
				""new contents"".getBytes(StandardCharsets.UTF_8));
		assertEquals(in, dm.getCompressorInputStream(in, CompressionType.NONE));
	}
"
"	@Test
	public void getCompressionInputStreamGzip() throws IOException {
		ByteArrayOutputStream out = new ByteArrayOutputStream();
		OutputStreamWriter ow = new OutputStreamWriter(
				new GzipCompressorOutputStream(out), StandardCharsets.UTF_8);
		ow.write(""Test data"");
		ow.close();

		ByteArrayInputStream in = new ByteArrayInputStream(out.toByteArray());
		InputStream cin = dm.getCompressorInputStream(in, CompressionType.GZIP);

		assertEquals(""Test data"",
				new BufferedReader(new InputStreamReader(cin)).readLine());
	}
"
"	@Test
	public void getCompressionInputStreamBz2() throws IOException {
		ByteArrayOutputStream out = new ByteArrayOutputStream();
		OutputStreamWriter ow = new OutputStreamWriter(
				new BZip2CompressorOutputStream(out), StandardCharsets.UTF_8);
		ow.write(""Test data"");
		ow.close();

		ByteArrayInputStream in = new ByteArrayInputStream(out.toByteArray());
		InputStream cin = dm.getCompressorInputStream(in, CompressionType.BZ2);

		assertEquals(""Test data"",
				new BufferedReader(new InputStreamReader(cin)).readLine());
	}
"
"	@Test
	public void basicTimerOperation() {
		Timer timer = new Timer(""Test timer"", Timer.RECORD_ALL);
		assertEquals(timer.getName(), ""Test timer"");
		long threadId = timer.getThreadId();

		assertEquals(timer.getAvgCpuTime(), 0);
		assertEquals(timer.getAvgWallTime(), 0);

		ThreadMXBean tmxb = ManagementFactory.getThreadMXBean();
		if (!tmxb.isThreadCpuTimeEnabled()) {
			tmxb.setThreadCpuTimeEnabled(true);
		}

		long cpuTime1 = tmxb.getThreadCpuTime(threadId);
		long wallTime1 = System.nanoTime();
		timer.start();
		doDummyComputation();
		assertTrue(""Timer should be running"", timer.isRunning());
		timer.stop();
		cpuTime1 = tmxb.getThreadCpuTime(threadId) - cpuTime1;
		wallTime1 = System.nanoTime() - wallTime1;
		assertTrue(
				""Unrealistic CPU time: "" + timer.getTotalCpuTime()
						+ "" should be closer to "" + cpuTime1,
				(cpuTime1 - TimerTest.TIME_TOLERANCE) <= timer
						.getTotalCpuTime()
						&& timer.getTotalCpuTime() <= cpuTime1);
		assertTrue(
				""Unrealistic wall time: "" + timer.getTotalWallTime()
						+ "" should be closer to "" + wallTime1,
				(wallTime1 - 2 * TimerTest.TIME_TOLERANCE) <= timer
						.getTotalWallTime()
						&& timer.getTotalWallTime() <= wallTime1);

		long cpuTime2 = tmxb.getThreadCpuTime(threadId);
		long wallTime2 = System.nanoTime();
		timer.start();
		doDummyComputation();
		timer.stop();
		cpuTime1 += tmxb.getThreadCpuTime(threadId) - cpuTime2;
		wallTime1 += System.nanoTime() - wallTime2;
		assertTrue(
				""Unrealistic total CPU time: "" + timer.getTotalCpuTime()
						+ "" should be closer to "" + cpuTime1,
				(cpuTime1 - 2 * TimerTest.TIME_TOLERANCE) <= timer
						.getTotalCpuTime()
						&& timer.getTotalCpuTime() <= cpuTime1);
		assertTrue(
				""Unrealistic total wall time: "" + timer.getTotalWallTime()
						+ "" should be closer to "" + wallTime1,
				(wallTime1 - 4 * TimerTest.TIME_TOLERANCE) <= timer
						.getTotalWallTime()
						&& timer.getTotalWallTime() <= wallTime1);

		assertEquals(timer.getTotalCpuTime() / 2, timer.getAvgCpuTime());
		assertEquals(timer.getTotalWallTime() / 2, timer.getAvgWallTime());

		timer.reset();
		assertEquals(timer.getTotalCpuTime(), 0);
		assertEquals(timer.getTotalWallTime(), 0);
		assertFalse(""Timer should not be running"", timer.isRunning());
	}
"
"	@Test
	public void namedTimers() {
		Timer timerA1 = Timer.getNamedTimer(""test timer"");
		Timer timerA2 = Timer.getNamedTimer(""test timer"");
		Timer timerA3 = Timer.getNamedTimer(""test timer"", Timer.RECORD_ALL);
		Timer timerA4 = Timer.getNamedTimer(""test timer"", Timer.RECORD_ALL,
				timerA1.getThreadId());
		Timer timerCpu = Timer
				.getNamedTimer(""test timer"", Timer.RECORD_CPUTIME);
		Timer timerWall = Timer.getNamedTimer(""test timer"",
				Timer.RECORD_WALLTIME);
		Timer timerNoThread = Timer.getNamedTimer(""test timer"",
				Timer.RECORD_ALL, 0);
		Timer timerNone = Timer.getNamedTimer(""test timer none"",
				Timer.RECORD_NONE);
		Timer timerB = Timer.getNamedTimer(""test timer 2"");

		// Testing Timer equality:
		assertEquals(timerA1, timerA2);
		assertEquals(timerA1, timerA3);
		assertEquals(timerA1, timerA4);
		assertNotEquals(timerA1, timerCpu);
		assertNotEquals(timerA1, timerWall);
		assertNotEquals(timerA1, timerNoThread);
		assertNotEquals(timerA1, timerB);
		assertNotEquals(timerA1, this);

		// Testing start/stop operation:
		Timer.startNamedTimer(""test timer"");
		Timer.startNamedTimer(""test timer"", Timer.RECORD_CPUTIME);
		Timer.startNamedTimer(""test timer"", Timer.RECORD_WALLTIME);
		Timer.startNamedTimer(""test timer"", Timer.RECORD_ALL, 0);
		doDummyComputation();
		Timer.stopNamedTimer(""test timer"");
		Timer.stopNamedTimer(""test timer"", Timer.RECORD_CPUTIME);
		Timer.stopNamedTimer(""test timer"", Timer.RECORD_WALLTIME);
		Timer.stopNamedTimer(""test timer"", Timer.RECORD_ALL, 0);

		assertTrue(""Named timer should have measured a non-zero CPU time."",
				timerA1.getTotalCpuTime() > 0);
		assertTrue(""Named timer should have measured a non-zero wall time."",
				timerA1.getTotalWallTime() > 0);
		assertTrue(
				""Timer for CPU time should have measured a non-zero CPU time."",
				timerCpu.getTotalCpuTime() > 0);
		assertTrue(""Timer for CPU time should not have measured a wall time."",
				timerCpu.getTotalWallTime() == 0);
		assertTrue(""Timer for wall time should not have measured a CPU time."",
				timerWall.getTotalCpuTime() == 0);
		assertTrue(
				""Timer for wall time should have measured a non-zero wall time."",
				timerWall.getTotalWallTime() > 0);
		assertTrue(
				""Timer without threadId should not have measured a CPU time."",
				timerNoThread.getTotalCpuTime() == 0);
		assertTrue(
				""Timer without threadId should have measured a non-zero wall time."",
				timerNoThread.getTotalWallTime() > 0);

		// Testing total timer creation:
		Timer totalTimer1 = Timer.getNamedTotalTimer(""test timer"");
		// There should be four *distinct* timers of that name
		assertEquals(totalTimer1.getTotalCpuTime(), timerA1.getTotalCpuTime()
				+ timerCpu.getTotalCpuTime() + timerWall.getTotalCpuTime()
				+ timerNoThread.getTotalCpuTime());
		assertEquals(totalTimer1.getTotalWallTime(), timerA1.getTotalWallTime()
				+ timerCpu.getTotalWallTime() + timerWall.getTotalWallTime()
				+ timerNoThread.getTotalWallTime());

		Timer totalTimer2 = Timer.getNamedTotalTimer(""test timer 2"");
		// There should be just one timer of that name
		assertEquals(totalTimer2, timerB);

		// Testing toString operation
		assertTrue(timerA1.toString().startsWith(
				""Time for test timer (thread "" + timerA1.getThreadId()
						+ "") for 1 run(s) CPU/Wall/CPU avg/Wall avg (ms):""));
		assertTrue(timerCpu.toString().startsWith(
				""Time for test timer (thread "" + timerCpu.getThreadId()
						+ "") for 1 run(s) CPU/CPU avg (ms):""));
		assertTrue(timerWall.toString().startsWith(
				""Time for test timer (thread "" + timerWall.getThreadId()
						+ "") for 1 run(s) Wall/Wall avg (ms):""));
		assertTrue(totalTimer1.toString().startsWith(
				""Time for test timer (over 4 threads)""));
		assertTrue(timerNoThread.toString().startsWith(
				""Time for test timer for 1 run(s)""));
		assertEquals(timerNone.toString(), ""Timer test timer none (thread ""
				+ timerNone.getThreadId()
				+ "") recorded 0 run(s); no times taken"");
		timerA1.start();
		assertTrue(timerA1.toString().endsWith(""[timer running!]""));

		// Testing reset operation:
		Timer.resetNamedTimer(""test timer"");
		Timer.resetNamedTimer(""test timer"", Timer.RECORD_CPUTIME);
		Timer.resetNamedTimer(""test timer"", Timer.RECORD_WALLTIME);
		Timer.resetNamedTimer(""test timer"", Timer.RECORD_ALL, 0);

		assertTrue(""Named timer should have reset CPU time."",
				timerA1.getTotalCpuTime() == 0);
		assertTrue(""Named timer should have reset wall time."",
				timerA1.getTotalWallTime() == 0);
		assertTrue(""Timer for CPU time should have reset CPU time."",
				timerCpu.getTotalCpuTime() == 0);
		assertTrue(""Timer for CPU time should have reset wall time."",
				timerCpu.getTotalWallTime() == 0);
		assertTrue(""Timer for wall time should have reset CPU time."",
				timerWall.getTotalCpuTime() == 0);
		assertTrue(""Timer for wall time should have reset wall time."",
				timerWall.getTotalWallTime() == 0);
		assertTrue(""Timer without threadId should have reset CPU time."",
				timerNoThread.getTotalCpuTime() == 0);
		assertTrue(""Timer without threadId should have reset wall time."",
				timerNoThread.getTotalWallTime() == 0);

		// Testing unregistered timer stop (does not create one):
		assertEquals(Timer.stopNamedTimer(""unknown name""), -1);
	}
"
"	@Test
	public void timerStopReturnValues() {
		Timer timer1 = new Timer(""stop test timer"", Timer.RECORD_ALL);
		Timer timer2 = new Timer(""stop test timer wall"", Timer.RECORD_WALLTIME);

		timer1.start();
		timer2.start();
		doDummyComputation();
		long cpuTime1 = timer1.stop();
		long cpuTime2 = timer2.stop();

		assertEquals(cpuTime1, timer1.getTotalCpuTime());
		assertEquals(cpuTime2, -1);

		long cpuTime3 = timer1.stop();
		assertEquals(cpuTime3, -1);
	}
"
"	@Test
	public void enableCpuTimeTaking() {
		ThreadMXBean tmxb = ManagementFactory.getThreadMXBean();
		tmxb.setThreadCpuTimeEnabled(false);

		Timer timer = new Timer(""Test timer"", Timer.RECORD_ALL);
		timer.start();
		doDummyComputation();
		timer.stop();

		assertTrue(""Timer should have measured a CPU time."",
				timer.getTotalCpuTime() > 0);
	}
"
"	@Test
	public void testWriteQuantityValue() throws RDFHandlerException,
			RDFParseException, IOException {
		QuantityValueConverter valueConverter = new QuantityValueConverter(
				this.rdfWriter, this.propertyRegister, this.rdfConversionBuffer);

		QuantityValue value = this.objectFactory.getQuantityValue(
				new BigDecimal(100), new BigDecimal(100), new BigDecimal(100));
		PropertyIdValue propertyIdValue = objectFactory.getPropertyIdValue(
				""P1081"", ""http://www.wikidata.org/entity/"");
		Value valueURI = valueConverter.getRdfValue(value, propertyIdValue,
				false);
		valueConverter.writeValue(value, (Resource) valueURI);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""QuantityValue.rdf"")));
	}
"
"	@Test
	public void testWriteUnboundedQuantityValue() throws RDFHandlerException,
			RDFParseException, IOException {
		QuantityValueConverter valueConverter = new QuantityValueConverter(
				this.rdfWriter, this.propertyRegister, this.rdfConversionBuffer);

		QuantityValue value = this.objectFactory.getQuantityValue(new BigDecimal(100));
		PropertyIdValue propertyIdValue = objectFactory.getPropertyIdValue(
				""P1081"", ""http://www.wikidata.org/entity/"");
		Value valueURI = valueConverter.getRdfValue(value, propertyIdValue,
				false);
		valueConverter.writeValue(value, (Resource) valueURI);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""UnboundedQuantityValue.rdf"")));
	}
"
"	@Test
	public void testWriteMonolingualTextValue() throws RDFHandlerException {
		MonolingualTextValueConverter valueConverter = new MonolingualTextValueConverter(
				this.rdfWriter, this.propertyRegister, this.rdfConversionBuffer);

		MonolingualTextValue value = this.objectFactory
				.getMonolingualTextValue(""ä¸­åäººæ°å±åå½"", ""zh-hans"");
		PropertyIdValue propertyIdValue = this.objectFactory
				.getPropertyIdValue(""P1448"", ""http://www.wikidata.org/entity/"");
		Value valueURI = valueConverter.getRdfValue(value, propertyIdValue,
				true);
		this.rdfWriter.finish();

		assertEquals(valueURI.toString(), ""\""ä¸­åäººæ°å±åå½\""@zh-Hans"");
	}
"
"	@Test
	public void testWriteGlobeCoordinatesValue() throws RDFHandlerException,
			RDFParseException, IOException {
		GlobeCoordinatesValueConverter valueConverter = new GlobeCoordinatesValueConverter(
				this.rdfWriter, this.propertyRegister, this.rdfConversionBuffer);

		GlobeCoordinatesValue value = this.objectFactory
				.getGlobeCoordinatesValue(51.033333333333, 13.733333333333,
						(GlobeCoordinatesValue.PREC_DECI_DEGREE),
						""http://www.wikidata.org/entity/Q2"");
		PropertyIdValue propertyIdValue = objectFactory.getPropertyIdValue(
				""P625"", ""http://www.wikidata.org/entity/"");
		Value valueURI = valueConverter.getRdfValue(value, propertyIdValue,
				false);
		valueConverter.writeValue(value, (Resource) valueURI);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""GlobeCoordinatesValue.rdf"")));
	}
"
"	@Test
	public void testWriteTimeValue() throws RDFHandlerException,
			RDFParseException, IOException {
		TimeValueConverter valueConverter = new TimeValueConverter(
				this.rdfWriter, this.propertyRegister, this.rdfConversionBuffer);

		TimeValue value = objectFactory.getTimeValue(2008, (byte) 1, (byte) 1,
				(byte) 0, (byte) 0, (byte) 0, (byte) 9, 0, 0, 0,
				""http://www.wikidata.org/entity/Q1985727"");
		PropertyIdValue propertyIdValue = objectFactory.getPropertyIdValue(
				""P569"", ""http://www.wikidata.org/entity/"");
		Value valueURI = valueConverter.getRdfValue(value, propertyIdValue,
				false);
		valueConverter.writeValue(value, (Resource) valueURI);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""TimeValue.rdf"")));
	}
"
"	@Test
	public void testSerialization() throws RDFParseException,
			RDFHandlerException, IOException {
		this.rdfSerializer.open();
		this.rdfSerializer.processItemDocument(this.objectFactory
				.createItemDocument());
		this.rdfSerializer.close();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""completeRDFDocument.rdf"")), model);
	}
"
"	@Test
	public void testGetWikidataPropertyRegister() {
		assertEquals(""P1921"", this.propertyRegister.uriPatternPropertyId);
	}
"
"	@Test
	public void testFetchPropertyUriPattern() {
		PropertyIdValue pid = this.dataObjectFactory.getPropertyIdValue(""P434"",
				this.siteIri);
		assertEquals(""http://musicbrainz.org/$1/artist"",
				this.propertyRegister.getPropertyUriPattern(pid));
		// Check twice to test that the cached retrieval works too
		assertEquals(""http://musicbrainz.org/$1/artist"",
				this.propertyRegister.getPropertyUriPattern(pid));
		assertEquals(50,
				this.propertyRegister.smallestUnfetchedPropertyIdNumber);
		assertTrue(this.propertyRegister.datatypes.keySet().contains(""P434""));
	}
"
"	@Test
	public void testGetPropertyType() {
		assertEquals(DatatypeIdValue.DT_STRING,
				this.propertyRegister.getPropertyType(dataObjectFactory
						.getPropertyIdValue(""P434"", this.siteIri)));
		// Check twice to test that the cached retrieval works too
		assertEquals(DatatypeIdValue.DT_STRING,
				this.propertyRegister.getPropertyType(dataObjectFactory
						.getPropertyIdValue(""P434"", this.siteIri)));
		assertEquals(50,
				this.propertyRegister.smallestUnfetchedPropertyIdNumber);
		assertTrue(this.propertyRegister.datatypes.keySet().contains(""P434""));
	}
"
"	@Test
	public void testGetMissingPropertyType() {
		assertNull(this.propertyRegister.getPropertyType(dataObjectFactory
				.getPropertyIdValue(""P10"", this.siteIri)));
		// Check twice to test fast failing on retry
		assertNull(this.propertyRegister.getPropertyType(dataObjectFactory
				.getPropertyIdValue(""P10"", this.siteIri)));
	}
"
"	@Test
	public void testSetPropertyTypeFromEntityIdValue() {
		assertEquals(this.propertyRegister.setPropertyTypeFromEntityIdValue(
				this.dataObjectFactory
						.getPropertyIdValue(""P1001"", this.siteIri),
				this.dataObjectFactory.getItemIdValue(""Q20"", this.siteIri)),
				DatatypeIdValue.DT_ITEM);
	}
"
"	@Test
	public void testSetPropertyTypeFromStringValue() {
		assertEquals(this.propertyRegister.setPropertyTypeFromStringValue(
				dataObjectFactory.getPropertyIdValue(""P434"", this.siteIri),
				dataObjectFactory
						.getStringValue(""http://musicbrainz.org/$1/artist"")),
				""http://wikiba.se/ontology#String"");
	}
"
"	@Test
	public void testSetMissingPropertyTypeFromStringValue() {
		assertEquals(this.propertyRegister.setPropertyTypeFromStringValue(
				dataObjectFactory.getPropertyIdValue(""P10"", this.siteIri),
				dataObjectFactory
						.getStringValue(""http://musicbrainz.org/$1/artist"")),
				""http://wikiba.se/ontology#String"");
	}
"
"	@Test
	public void testWikidataPropertyRegister() {
		PropertyRegister pr = PropertyRegister.getWikidataPropertyRegister();
		assertEquals(Datamodel.SITE_WIKIDATA, pr.getUriPrefix());
		assertEquals(""P1921"", pr.uriPatternPropertyId);
	}
"
"	@Test
	public void testWriteItemDocument() throws RDFHandlerException,
			IOException, RDFParseException {
		ItemDocument document = this.objectFactory.createItemDocument();
		this.rdfConverter.writeItemDocument(document);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""ItemDocument.rdf"")));
	}
"
"	@Test
	public void testWriteItemDocumentWithNullPropertyTypes() throws RDFHandlerException,
			IOException, RDFParseException {
		this.rdfConverter = new RdfConverter(this.rdfWriter, this.sites,
				new MockPropertyRegister.WithNullPropertyTypes());

		ItemDocument document = this.objectFactory.createItemDocument();
		this.rdfConverter.writeItemDocument(document);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""ItemDocumentUnknownPropertyTypes.rdf"")));
	}
"
"    @Test
	public void testWritePropertyDocument() throws RDFHandlerException,
			RDFParseException, IOException {
		PropertyDocument document = this.objectFactory
				.createEmptyPropertyDocument();
		this.rdfConverter.writePropertyDocument(document);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""EmptyPropertyDocument.rdf"")));
	}
"
"	@Test
	public void testWriteStatementRankTriple() throws RDFHandlerException,
			RDFParseException, IOException {
		StatementRank rank = StatementRank.DEPRECATED;
		Resource subject = this.rdfFactory
				.createIRI(""http://www.wikidata.org/Q10Snone"");
		this.rdfConverter.writeStatementRankTriple(subject, rank);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""StatementRankTriple.rdf"")), model);
	}
"
"	@Test
	public void testStatementSimpleValue() throws RDFHandlerException,
			RDFParseException, IOException {
		Statement statement = objectFactory.createStatement(""Q100"", ""P227"");
		this.rdfConverter.writeStatement(statement);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""Statement.rdf"")));
	}
"
"	@Test
	public void testStatementComplexValue() throws RDFHandlerException,
			RDFParseException, IOException {
		GlobeCoordinatesValue value = Datamodel.makeGlobeCoordinatesValue(51,
				13, GlobeCoordinatesValue.PREC_DEGREE,
				GlobeCoordinatesValue.GLOBE_EARTH);
		Statement statement = StatementBuilder
				.forSubjectAndProperty(ItemIdValue.NULL, PropertyIdValue.NULL)
				.withValue(value).build();
		this.rdfConverter.writeStatement(statement);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""StatementCplx.rdf"")));
	}
"
"	@Test
	public void testStatementNoValue() throws RDFHandlerException,
			RDFParseException, IOException {
		PropertyIdValue pid = dataObjectFactory.getPropertyIdValue(""P31"", ""http://www.wikidata.org/"");
		Statement statement = StatementBuilder
				.forSubjectAndProperty(ItemIdValue.NULL, pid)
				.withNoValue().build();
		this.rdfConverter.writeStatement(statement);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""StatementNoValue.rdf"")));
	}
"
"	@Test
	public void testWriteBasicDeclarations() throws RDFHandlerException,
			RDFParseException, IOException {
		this.rdfConverter.writeBasicDeclarations();
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""BasicDeclarations.rdf"")), model);
	}
"
"	@Test
	public void testWriteNamespaceDeclarations() throws RDFHandlerException,
			RDFParseException, IOException {
		this.rdfConverter.writeNamespaceDeclarations();
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""Namespaces.rdf"")), model);
	}
"
"	@Test
	public void testWriteSiteLinks() throws RDFHandlerException, IOException,
			RDFParseException {
		this.sites.setSiteInformation(""enwiki"", ""wikipedia"", ""en"", ""mediawiki"",
				""http://en.wikipedia.org/w/$1"",
				""http://en.wikipedia.org/wiki/$1"");
		this.sites.setSiteInformation(""dewiki"", ""wikipedia"", ""de"", ""mediawiki"",
				""http://de.wikipedia.org/w/$1"",
				""http://de.wikipedia.org/wiki/$1"");
		Map<String, SiteLink> siteLinks = objectFactory.createSiteLinks();
		this.rdfConverter.writeSiteLinks(this.resource, siteLinks);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""SiteLinks.rdf"")));

	}
"
"	@Test
	public void testWriteSimpleStatements() throws RDFHandlerException,
			RDFParseException, IOException {
		ItemDocument document = createTestItemDocument();
		this.rdfConverter.writeSimpleStatements(resource, document);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(
				RdfTestHelpers
						.parseRdf(""\n<http://test.org/> <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/Q10> ;\n""
								+ ""<http://www.wikidata.org/prop/direct/P279> <http://www.wikidata.org/Q11> .\n""),
				model);
	}
"
"	@Test
	public void testWriteInterPropertyLinks() throws RDFHandlerException,
			RDFParseException, IOException {
		PropertyDocument document = this.dataObjectFactory.getPropertyDocument(
				this.dataObjectFactory.getPropertyIdValue(""P17"",
						""http://www.wikidata.org/""), Collections
						.<MonolingualTextValue> emptyList(), Collections
						.<MonolingualTextValue> emptyList(), Collections
						.<MonolingualTextValue> emptyList(), Collections
						.<StatementGroup> emptyList(), this.dataObjectFactory
						.getDatatypeIdValue(DatatypeIdValue.DT_ITEM), 0);
		this.rdfConverter.writeInterPropertyLinks(document);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(out.toString());

		assertEquals(RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""InterPropertyLinks.rdf"")), model);
	}
"
"	@Test
	public void missingDumpFile() throws IOException {
		MwLocalDumpFile df = new MwLocalDumpFile(
				""/non-existing-dump-file.json.gz"");
		assertFalse(df.isAvailable());
	}
"
"	@Test
	public void missingDumpFileDirectory() throws IOException {
		MwLocalDumpFile df = new MwLocalDumpFile(
				""/nonexisting-directory/non-existing-file.json.gz"");
		assertFalse(df.isAvailable());
	}
"
"	@Test
	public void testExplicitGetters() throws IOException {
		this.dm.setFileContents(this.dmPath
				.resolve(""testdump-20150512.json.gz""), """");
		MwLocalDumpFile df = new MwLocalDumpFile(
				""/testdump-20150512.json.gz"",
				DumpContentType.SITES, ""20150815"",
				""wikidatawiki"");

		assertEquals(""20150815"", df.getDateStamp());
		assertEquals(""wikidatawiki"", df.getProjectName());
		assertEquals(DumpContentType.SITES, df.getDumpContentType());
		String toString = df.toString();

		assertEquals(this.dmPath.resolve(""testdump-20150512.json.gz""),
				df.getPath());

		assertTrue(toString.contains(""20150815""));
		assertTrue(toString.contains(""wikidatawiki""));
		assertTrue(toString.toLowerCase().contains(
				DumpContentType.SITES.toString().toLowerCase()));
	}
"
"  @Test
  public void testParse() {
    var param =
        ArgumentUtil.parseArgument(new FakeParameter(), new String[] {""--require"", ""require""});
    Assertions.assertEquals(""require"", param.require);
  }
"
"  @Test
  public void testRequired() {
    Assertions.assertThrows(
        ParameterException.class,
        () -> ArgumentUtil.parseArgument(new FakeParameter(), new String[] {}));
  }
"
"  @Test
  public void testLongPositive() {
    var param =
        ArgumentUtil.parseArgument(
            new FakeParameter(), new String[] {""--require"", ""require"", ""--longPositive"", ""1000""});

    Assertions.assertEquals(1000, param.longPositive);
    Assertions.assertThrows(
        ParameterException.class,
        () ->
            ArgumentUtil.parseArgument(
                new FakeParameter(), new String[] {""--require"", ""require"", ""--longPositive"", ""0""}));
  }
"
"  @Test
  public void testNotNegative() {
    FakeParameter param =
        ArgumentUtil.parseArgument(
            new FakeParameter(),
            new String[] {""--require"", ""require"", ""--longNotNegative"", ""1000""});

    Assertions.assertEquals(1000, param.longNotNegative);
    Assertions.assertThrows(
        ParameterException.class,
        () ->
            ArgumentUtil.parseArgument(
                new FakeParameter(),
                new String[] {""--require"", ""require"", ""--longNotNegative"", ""-1""}));
  }
"
"  @Test
  public void testDurationConvert() {
    FakeParameter param =
        ArgumentUtil.parseArgument(
            new FakeParameter(),
            new String[] {""--require"", ""require"", ""--durationConvert"", ""1000""});

    Assertions.assertEquals(Duration.ofSeconds(1000), param.durationConvert);
  }
"
"  @Test
  public void testSetConverter() {
    FakeParameter param =
        ArgumentUtil.parseArgument(
            new FakeParameter(),
            new String[] {""--require"", ""require"", ""--setConverter"", ""1"", ""1"", ""2""});

    Assertions.assertEquals(Set.of(""1"", ""2""), param.setConverter);
  }
"
"    @Test
    public void gradleProof() throws Exception {
        GradleProof proof = new GradleProof();
        try {
            proof.startServer();
            String result = proof.doClient(""World"");
            assertEquals(""Hello World"", result);
        } finally {
            proof.stopServer();
        }
    }
"
"    @Test
    public void useAppContext() {
        // Context of the app under test.
        Context appContext = InstrumentationRegistry.getTargetContext();

        assertEquals(""demo.client.android"", appContext.getPackageName());
    }
"
"    @Test
    public void addition_isCorrect() {
        assertEquals(4, 2 + 2);
    }
"
"    @Test
    public void clientCanCancelServerStreamExplicitly() throws InterruptedException {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        AtomicInteger lastNumberConsumed = new AtomicInteger(Integer.MAX_VALUE);
        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());
        Flux<NumberProto.Number> test = Mono.just(Empty.getDefaultInstance()).as(stub::responsePressure)
                .doOnNext(number -> {lastNumberConsumed.set(number.getNumber(0)); System.out.println(""C: "" + number.getNumber(0));})
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""));

        Disposable subscription = test.publish().connect();

        Thread.sleep(1000);
        subscription.dispose();
        Thread.sleep(1000);

        // Cancellation may or may not deliver the last generated message due to delays in the gRPC processing thread
        assertThat(Math.abs(lastNumberConsumed.get() - svc.getLastNumberProduced())).isLessThanOrEqualTo(3);
        assertThat(svc.wasCanceled()).isTrue();
    }
"
"    @Test
    public void clientCanCancelServerStreamImplicitly() throws InterruptedException {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());
        Flux<NumberProto.Number> test = Mono.just(Empty.getDefaultInstance()).as(stub::responsePressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""))
                .take(10);

        Disposable subscription = test.publish().connect();

        Thread.sleep(1000);

        assertThat(svc.wasCanceled()).isTrue();
    }
"
"    @Test
    public void serverCanCancelClientStreamImplicitly() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        svc.setExplicitCancel(false);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flux<NumberProto.Number> request = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delayElements(Duration.ofMillis(SEQUENCE_DELAY_MILLIS))
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(x -> {
                    requestDidProduce.set(true);
                    System.out.println(""Produced: "" + x.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        Mono<NumberProto.Number> observer = request.as(stub::requestPressure)
                .doOnSuccess(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()));

        StepVerifier.create(observer)
                .expectNext(protoNum(9))
                .verifyComplete();

        await().atMost(org.awaitility.Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();
    }
"
"    @Test
    public void serverCanCancelClientStreamExplicitly() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        svc.setExplicitCancel(true);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flux<NumberProto.Number> request = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delayElements(Duration.ofMillis(SEQUENCE_DELAY_MILLIS))
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(n -> {
                    requestDidProduce.set(true);
                    System.out.println(""P: "" + n.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        Mono<NumberProto.Number> observer = request.as(stub::requestPressure)
                .doOnSuccess(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()));

        StepVerifier.create(observer)
                .expectNext(protoNum(-1))
                .verifyComplete();

        await().atMost(org.awaitility.Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();
    }
"
"    @Test
    public void serverCanCancelClientStreamImplicitlyBidi() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        svc.setExplicitCancel(false);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flux<NumberProto.Number> request = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delayElements(Duration.ofMillis(SEQUENCE_DELAY_MILLIS))
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(x -> {
                    requestDidProduce.set(true);
                    System.out.println(""Produced: "" + x.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        Flux<NumberProto.Number> observer = request.compose(stub::twoWayPressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()));

        StepVerifier.create(observer)
                .expectNext(protoNum(9))
                .verifyComplete();

        await().atMost(org.awaitility.Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();
    }
"
"    @Test
    public void serverCanCancelClientStreamExplicitlyBidi() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        svc.setExplicitCancel(true);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flux<NumberProto.Number> request = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delayElements(Duration.ofMillis(SEQUENCE_DELAY_MILLIS))
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(n -> {
                    requestDidProduce.set(true);
                    System.out.println(""P: "" + n.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        Flux<NumberProto.Number> observer = request.compose(stub::twoWayPressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()));

        StepVerifier.create(observer)
                .expectNext(protoNum(-1))
                .verifyComplete();

        await().atMost(org.awaitility.Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();
    }
"
"    @Test
    public void oneToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloResponse> resp = Mono.just(HelloRequest.getDefaultInstance()).compose(stub::sayHello);

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
"
"    @Test
    public void oneToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloResponse> resp = Mono.just(HelloRequest.getDefaultInstance()).as(stub::sayHelloRespStream);
        Flux<HelloResponse> test = resp
                .doOnNext(System.out::println)
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""));

        StepVerifier.create(test)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
"
"    @Test
    public void manyToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloResponse> resp = Flux.just(HelloRequest.getDefaultInstance()).as(stub::sayHelloReqStream);
        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
"
"    @Test
    public void manyToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloResponse> resp = Flux.just(HelloRequest.getDefaultInstance()).compose(stub::sayHelloBothStream);
        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
"
"    @Test
    public void clientToServerBackpressure() {
        serverRule.getServiceRegistry().addService(new TestService());

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        Flux<NumberProto.Number> reactorRequest = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .doOnNext(i -> System.out.println(i + "" --> ""))
                .doOnNext(i -> updateNumberOfWaits(lastValueTime, numberOfWaits))
                .map(BackpressureIntegrationTest::protoNum);

        Mono<NumberProto.Number> reactorResponse = reactorRequest.as(stub::requestPressure);

        StepVerifier.create(reactorResponse)
                .expectNextMatches(v -> v.getNumber(0) == NUMBER_OF_STREAM_ELEMENTS - 1)
                .expectComplete()
                .verify(Duration.ofSeconds(5));

        assertThat(numberOfWaits.get()).isEqualTo(1);
    }
"
"    @Test
    public void serverToClientBackpressure() {
        serverRule.getServiceRegistry().addService(new TestService());

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        Mono<Empty> reactorRequest = Mono.just(Empty.getDefaultInstance());

        Flux<NumberProto.Number> reactorResponse = reactorRequest.as(stub::responsePressure)
                .doOnNext(n -> System.out.println(n.getNumber(0) + ""  <--""))
                .doOnNext(n -> waitIfValuesAreEqual(n.getNumber(0), 3));

        StepVerifier.create(reactorResponse)
                .expectNextCount(NUMBER_OF_STREAM_ELEMENTS)
                .expectComplete()
                .verify(Duration.ofSeconds(5));

        assertThat(numberOfWaits.get()).isEqualTo(1);
    }
"
"    @Test
    public void bidiResponseBackpressure() {
        serverRule.getServiceRegistry().addService(new TestService());

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        Flux<NumberProto.Number> reactorRequest = Flux.empty();

        Flux<NumberProto.Number> reactorResponse = reactorRequest.compose(stub::twoWayResponsePressure)
                .doOnNext(n -> System.out.println(n.getNumber(0) + ""  <--""))
                .doOnNext(n -> waitIfValuesAreEqual(n.getNumber(0), 3));

        StepVerifier.create(reactorResponse)
                .expectNextCount(NUMBER_OF_STREAM_ELEMENTS)
                .expectComplete()
                .verify(Duration.ofSeconds(5));

        assertThat(numberOfWaits.get()).isEqualTo(1);
    }
"
"    @Test
    public void bidiRequestBackpressure() {
        serverRule.getServiceRegistry().addService(new TestService());

        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        Flux<NumberProto.Number> reactorRequest = Flux
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .doOnNext(i -> System.out.println(i + "" --> ""))
                .doOnNext(i -> updateNumberOfWaits(lastValueTime, numberOfWaits))
                .map(BackpressureIntegrationTest::protoNum);

        Flux<NumberProto.Number> reactorResponse = reactorRequest.compose(stub::twoWayRequestPressure);

        StepVerifier.create(reactorResponse)
                .expectNextMatches(v -> v.getNumber(0) == NUMBER_OF_STREAM_ELEMENTS - 1)
                .expectComplete()
                .verify(Duration.ofSeconds(5));

        assertThat(numberOfWaits.get()).isEqualTo(1);
    }
"
"    @Test
    public void serverErrorSignalsUpstreamCancellationManyToOne() {
        serverRule.getServiceRegistry().addService(new ExplodeAfterFiveService());
        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        AtomicBoolean upstreamCancel = new AtomicBoolean(false);

        Mono<NumberProto.Number> observer = Flux.range(0, Integer.MAX_VALUE)
                .map(this::protoNum)
                .doOnCancel(() -> upstreamCancel.set(true))
                .as(stub::requestPressure)
                .doOnError(System.out::println)
                .doOnSuccess(i -> System.out.println(i.getNumber(0)));

        StepVerifier.create(observer)
                .verifyError(StatusRuntimeException.class);

        assertThat(upstreamCancel.get()).isTrue();
    }
"
"    @Test
    public void serverErrorSignalsUpstreamCancellationBidi() {
        serverRule.getServiceRegistry().addService(new ExplodeAfterFiveService());
        ReactorNumbersGrpc.ReactorNumbersStub stub = ReactorNumbersGrpc.newReactorStub(serverRule.getChannel());

        AtomicBoolean upstreamCancel = new AtomicBoolean(false);

        Flux<NumberProto.Number> subscriber = Flux.range(0, Integer.MAX_VALUE)
                .map(this::protoNum)
                .doOnCancel(() -> upstreamCancel.set(true))
                .compose(stub::twoWayPressure)
                .doOnNext(i -> System.out.println(i.getNumber(0)));

        StepVerifier.create(subscriber)
                .verifyError(StatusRuntimeException.class);
        assertThat(upstreamCancel.get()).isTrue();
    }
"
"    @Test
    public void oneToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloResponse> resp = Mono.just(HelloRequest.getDefaultInstance()).compose(stub::sayHello);

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus().getCode() == Status.Code.INTERNAL);
    }
"
"    @Test
    public void oneToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloResponse> resp = Mono.just(HelloRequest.getDefaultInstance()).as(stub::sayHelloRespStream);
        Flux<HelloResponse> test = resp
                .doOnNext(System.out::println)
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""));

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus().getCode() == Status.Code.INTERNAL);
    }
"
"    @Test
    public void manyToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(HelloRequest.getDefaultInstance());
        Mono<HelloResponse> resp = req.as(stub::sayHelloReqStream);

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus().getCode() == Status.Code.INTERNAL);
    }
"
"    @Test
    public void manyToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(HelloRequest.getDefaultInstance());
        Flux<HelloResponse> resp = req.compose(stub::sayHelloBothStream);

        StepVerifier.create(resp)
                .verifyErrorMatches(t -> t instanceof StatusRuntimeException && ((StatusRuntimeException)t).getStatus().getCode() == Status.Code.INTERNAL);
    }
"
"    @Test
    public void oneToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloRequest> req = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Mono<HelloResponse> resp = req.compose(stub::sayHello);

        AtomicReference<String> clientThreadName = new AtomicReference<>();

        StepVerifier
                .create(resp
                        .map(HelloResponse::getMessage)
                        .doOnSuccess(x -> clientThreadName.set(Thread.currentThread().getName())))
                .expectNext(""Hello reactorjava"")
                .verifyComplete();

        assertThat(clientThreadName.get()).isEqualTo(""TheGrpcClient"");
        assertThat(serverThreadName.get()).isEqualTo(""TheGrpcServer"");
    }
"
"    @Test
    public void manyToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build(),
                HelloRequest.newBuilder().setName(""d"").build(),
                HelloRequest.newBuilder().setName(""e"").build());

        Flux<HelloResponse> resp = req.compose(stub::sayHelloBothStream);

        AtomicReference<String> clientThreadName = new AtomicReference<>();

        StepVerifier
                .create(resp
                        .map(HelloResponse::getMessage)
                        .doOnNext(x -> clientThreadName.set(Thread.currentThread().getName())))
                .expectNext(""Hello a and b"", ""Hello c and d"", ""Hello e"")
                .verifyComplete();

        assertThat(clientThreadName.get()).isEqualTo(""TheGrpcClient"");
        assertThat(serverThreadName.get()).isEqualTo(""TheGrpcServer"");
    }
"
"    @Test
    public void unimplementedMethodShouldFail() {
        GreeterGrpc.GreeterBlockingStub stub = GreeterGrpc.newBlockingStub(channel);

        assertThatThrownBy(() -> stub.sayHello(HelloRequest.newBuilder().setName(""World"").build()))
                .isInstanceOf(StatusRuntimeException.class)
                .hasMessageContaining(""UNIMPLEMENTED"");
    }
"
"    @Test
    public void getChannelWorks() {
        ManagedChannel channel = serverRule.getChannel();
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);

        assertThat(stub.getChannel()).isEqualTo(channel);
    }
"
"    @Test
    public void settingCallOptionsWorks() {
        ManagedChannel channel = serverRule.getChannel();
        Deadline deadline = Deadline.after(42, TimeUnit.SECONDS);

        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel).withDeadline(deadline);

        assertThat(stub.getCallOptions().getDeadline()).isEqualTo(deadline);
    }
"
"    @Test
    public void oneToOne() {
        AtomicBoolean called = new AtomicBoolean(false);
        GreeterGrpc.GreeterStub stub = GreeterGrpc.newStub(channel);

        HelloRequest request = HelloRequest.newBuilder().setName(""World"").build();
        stub.sayHello(request, new LambdaStreamObserver<>(
                response -> {
                    assertThat(response.getMessage()).isEqualTo(""Hello World"");
                    called.set(true);
                }
        ));

        await().atMost(1, TimeUnit.SECONDS).untilTrue(called);
    }
"
"    @Test
    public void oneToMany() {
        AtomicInteger called = new AtomicInteger(0);
        GreeterGrpc.GreeterStub stub = GreeterGrpc.newStub(channel);

        HelloRequest request = HelloRequest.newBuilder().setName(""World"").build();
        stub.sayHelloRespStream(request, new LambdaStreamObserver<>(
                response -> {
                    assertThat(response.getMessage()).isIn(""Hello World"", ""Hi World"", ""Greetings World"");
                    called.incrementAndGet();
                }
        ));

        await().atMost(1, TimeUnit.SECONDS).untilAtomic(called, equalTo(3));
    }
"
"    @Test
    public void manyToOne() {
        AtomicBoolean called = new AtomicBoolean(false);
        GreeterGrpc.GreeterStub stub = GreeterGrpc.newStub(channel);

        StreamObserver<HelloRequest> requestStream = stub.sayHelloReqStream(new LambdaStreamObserver<>(
                response -> {
                    assertThat(response.getMessage()).isEqualTo(""Hello A and B and C"");
                    called.set(true);
                }
        ));

        requestStream.onNext(HelloRequest.newBuilder().setName(""A"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""B"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""C"").build());
        requestStream.onCompleted();

        await().atMost(1, TimeUnit.SECONDS).untilTrue(called);
    }
"
"    @Test
    public void manyToMany() {
        AtomicInteger called = new AtomicInteger(0);
        GreeterGrpc.GreeterStub stub = GreeterGrpc.newStub(channel);

        StreamObserver<HelloRequest> requestStream = stub.sayHelloBothStream(new LambdaStreamObserver<>(
                response -> {
                    assertThat(response.getMessage()).isIn(""Hello A and B"", ""Hello C and D"");
                    called.incrementAndGet();
                }
        ));

        requestStream.onNext(HelloRequest.newBuilder().setName(""A"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""B"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""C"").build());
        requestStream.onNext(HelloRequest.newBuilder().setName(""D"").build());
        requestStream.onCompleted();

        await().atMost(1, TimeUnit.SECONDS).untilAtomic(called, equalTo(2));
    }
"
"    @Test
    public void oneToOne() throws IOException {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloRequest> req = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Mono<HelloResponse> resp = req.compose(stub::sayHello);

        StepVerifier.create(resp.map(HelloResponse::getMessage))
                .expectNext(""Hello reactorjava"")
                .verifyComplete();
    }
"
"    @Test
    public void oneToMany() throws IOException {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<HelloRequest> req = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Flux<HelloResponse> resp = req.as(stub::sayHelloRespStream);

        StepVerifier.create(resp.map(HelloResponse::getMessage))
                .expectNext(""Hello reactorjava"", ""Hi reactorjava"", ""Greetings reactorjava"")
                .verifyComplete();
    }
"
"    @Test
    public void manyToOne() throws Exception {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build());

        Mono<HelloResponse> resp = req.as(stub::sayHelloReqStream);

        StepVerifier.create(resp.map(HelloResponse::getMessage))
                .expectNext(""Hello a and b and c"")
                .verifyComplete();
    }
"
"    @Test
    public void manyToMany() throws Exception {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<HelloRequest> req = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build(),
                HelloRequest.newBuilder().setName(""d"").build(),
                HelloRequest.newBuilder().setName(""e"").build());

        Flux<HelloResponse> resp = req.compose(stub::sayHelloBothStream);

        StepVerifier.create(resp.map(HelloResponse::getMessage))
                .expectNext(""Hello a and b"", ""Hello c and d"", ""Hello e"")
                .verifyComplete();
    }
"
"    @Test
    public void fourKindsOfRequestAtOnce() throws Exception {
        StepVerifier.setDefaultTimeout(Duration.ofSeconds(3));

        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);

        // == MAKE REQUESTS ==
        // One to One
        Mono<HelloRequest> req1 = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Mono<HelloResponse> resp1 = req1.compose(stub::sayHello);

        // One to Many
        Mono<HelloRequest> req2 = Mono.just(HelloRequest.newBuilder().setName(""reactorjava"").build());
        Flux<HelloResponse> resp2 = req2.as(stub::sayHelloRespStream);

        // Many to One
        Flux<HelloRequest> req3 = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build());

        Mono<HelloResponse> resp3 = req3.as(stub::sayHelloReqStream);

        // Many to Many
        Flux<HelloRequest> req4 = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build(),
                HelloRequest.newBuilder().setName(""d"").build(),
                HelloRequest.newBuilder().setName(""e"").build());

        Flux<HelloResponse> resp4 = req4.compose(stub::sayHelloBothStream);

        // == VERIFY RESPONSES ==
        ListeningExecutorService executorService = MoreExecutors.listeningDecorator(Executors.newCachedThreadPool());

        // Run all four verifications in parallel
        try {
            // One to One
            ListenableFuture<Boolean> oneToOne = executorService.submit(() -> {
                StepVerifier.create(resp1.map(HelloResponse::getMessage))
                        .expectNext(""Hello reactorjava"")
                        .verifyComplete();
                return true;
            });

            // One to Many
            ListenableFuture<Boolean> oneToMany = executorService.submit(() -> {
                StepVerifier.create(resp2.map(HelloResponse::getMessage))
                        .expectNext(""Hello reactorjava"", ""Hi reactorjava"", ""Greetings reactorjava"")
                        .verifyComplete();
                return true;
            });

            // Many to One
            ListenableFuture<Boolean> manyToOne = executorService.submit(() -> {
                StepVerifier.create(resp3.map(HelloResponse::getMessage))
                        .expectNext(""Hello a and b and c"")
                        .verifyComplete();
                return true;
            });

            // Many to Many
            ListenableFuture<Boolean> manyToMany = executorService.submit(() -> {
                StepVerifier.create(resp4.map(HelloResponse::getMessage))
                        .expectNext(""Hello a and b"", ""Hello c and d"", ""Hello e"")
                        .verifyComplete();
                return true;
            });

            ListenableFuture<List<Boolean>> allFutures = Futures.allAsList(Lists.newArrayList(oneToOne, oneToMany, manyToOne, manyToMany));
            // Block for response
            List<Boolean> results = allFutures.get(3, TimeUnit.SECONDS);
            assertThat(results).containsExactly(true, true, true, true);

        } finally {
            executorService.shutdown();
        }
    }
"
"    @Test
    public void oneToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<String> reactorRequest = Mono.just(""World"");
        Mono<String> reactorResponse = reactorRequest.map(this::toRequest).compose(stub::sayHello).map(this::fromResponse);

        StepVerifier.create(reactorResponse)
                .expectNext(""Hello World"")
                .verifyComplete();
    }
"
"    @Test
    public void oneToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Mono<String> reactorRequest = Mono.just(""World"");
        Flux<String> reactorResponse = reactorRequest.map(this::toRequest).as(stub::sayHelloRespStream).map(this::fromResponse);

        StepVerifier.create(reactorResponse)
                .expectNext(""Hello World"", ""Hi World"", ""Greetings World"")
                .verifyComplete();
    }
"
"    @Test
    public void manyToOne() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<String> reactorRequest = Flux.just(""A"", ""B"", ""C"");
        Mono<String> reactorResponse = reactorRequest.map(this::toRequest).as(stub::sayHelloReqStream).map(this::fromResponse);

        StepVerifier.create(reactorResponse)
                .expectNext(""Hello A and B and C"")
                .verifyComplete();
    }
"
"    @Test
    public void manyToMany() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Flux<String> reactorRequest = Flux.just(""A"", ""B"", ""C"", ""D"");
        Flux<String> reactorResponse = reactorRequest.map(this::toRequest).compose(stub::sayHelloBothStream).map(this::fromResponse);

        StepVerifier.create(reactorResponse)
                .expectNext(""Hello A and B"", ""Hello C and D"")
                .verifyComplete();
    }
"
"    @Test
    public void ClientSendsContext() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);
        Context.current()
                .withValue(ctxKey, ""ClientSendsContext"")
                .run(() -> StepVerifier.create(worldReq.compose(stub::sayHello).map(HelloResponse::getMessage))
                        .expectNext(""Hello World"")
                        .verifyComplete());

        assertThat(clientInterceptor.getSendMessageCtxValue()).isEqualTo(""ClientSendsContext"");
    }
"
"    @Test
    public void ClientGetsContext() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);

        Mono<HelloResponse> test = worldReq.compose(stub::sayHello)
                .doOnSuccess(resp -> {
                    Context ctx = Context.current();
                    assertThat(ctxKey.get(ctx)).isEqualTo(""ClientGetsContext"");
                });

        StepVerifier.create(test.map(HelloResponse::getMessage))
                .expectNext(""Hello World"")
                .verifyComplete();
    }
"
"    @Test
    public void ServerAcceptsContext() {
        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel);

        StepVerifier.create(worldReq.compose(stub::sayHello).map(HelloResponse::getMessage))
                .expectNext(""Hello World"")
                .verifyComplete();
        assertThat(svc.getReceivedCtxValue()).isEqualTo(""ServerAcceptsContext"");
    }
"
"    @Test
    public void zeroMessageResponseOneToOne() {
        serverRule.getServiceRegistry().addService(new MissingUnaryResponseService());

        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(serverRule.getChannel());
        Mono<HelloRequest> req = Mono.just(HelloRequest.newBuilder().setName(""reactor"").build());
        Mono<HelloResponse> resp = req.compose(stub::sayHello);

        StepVerifier.create(resp).verifyErrorMatches(t ->
                t instanceof StatusRuntimeException &&
                ((StatusRuntimeException) t).getStatus().getCode() == Status.Code.CANCELLED);
    }
"
"    @Test
    public void zeroMessageResponseManyToOne() {
        serverRule.getServiceRegistry().addService(new MissingUnaryResponseService());

        ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(serverRule.getChannel());
        Flux<HelloRequest> req = Flux.just(
                HelloRequest.newBuilder().setName(""a"").build(),
                HelloRequest.newBuilder().setName(""b"").build(),
                HelloRequest.newBuilder().setName(""c"").build());

        Mono<HelloResponse> resp = req.as(stub::sayHelloReqStream);

        StepVerifier.create(resp).verifyErrorMatches(t ->
                t instanceof StatusRuntimeException &&
                ((StatusRuntimeException) t).getStatus().getCode() == Status.Code.CANCELLED);
    }
"
"@Test(timeOut = 3000)
    public Publisher<Message> createPublisher(long elements) {
        ReactorTckGrpc.ReactorTckStub stub = ReactorTckGrpc.newReactorStub(channel);
        Flux<Message> request = Flux.range(0, (int)elements).map(this::toMessage);
        Publisher<Message> publisher = stub.manyToMany(request).publishOn(Schedulers.immediate());

        return publisher;
    }
"
"@Test(timeOut = 3000)
    public long maxElementsFromPublisher() {
        return 1;
    }
"
"@Test(timeOut = 3000)
    public long maxElementsFromPublisher() {
        return 1;
    }
"
"@Test(timeOut = 3000)
    public Publisher<Message> createPublisher(long elements) {
        ReactorTckGrpc.ReactorTckStub stub = ReactorTckGrpc.newReactorStub(channel);
        Mono<Message> request = Mono.just(toMessage((int) elements));
        Publisher<Message> publisher = stub.oneToMany(request).publishOn(Schedulers.immediate());

        return publisher;
    }
"
"@Test(timeOut = 3000)
    public Subscriber<Message> createSubscriber(WhiteboxSubscriberProbe<Message> probe) {
        return new ReactivePublisherBackpressureOnReadyHandlerClient<Message>(new StubServerCallStreamObserver()) {
            @Override
            public void onSubscribe(final Subscription s) {
                super.onSubscribe(s);

                // register a successful Subscription, and create a Puppet,
                // for the WhiteboxVerification to be able to drive its tests:
                probe.registerOnSubscribe(new SubscriberPuppet() {

                    @Override
                    public void triggerRequest(long elements) {
                        s.request(elements);
                    }
"
"    @Test
    public void subscribeOnlyOnceLifterErrorsWhenMultipleSubscribe() throws Exception {
        SubscribeOnlyOnceLifter<Object> op = new SubscribeOnlyOnceLifter<>();
        CoreSubscriber<Object> innerSub = mock(CoreSubscriber.class);
        Subscription subscription = mock(Subscription.class);

        CoreSubscriber<Object> outerSub = op.apply(null, innerSub);

        outerSub.onSubscribe(subscription);
        assertThatThrownBy(() -> outerSub.onSubscribe(subscription))
                .isInstanceOf(NullPointerException.class)
                .hasMessageContaining(""cannot directly subscribe to a gRPC service multiple times"");

        verify(innerSub, times(1)).onSubscribe(subscription);
    }
"
"    @Test
    public void chunkOperatorCorrectlyChunks() {
        final List<Long> requests = new ArrayList<>();
        int chunkSize = ReactiveBackpressureChunker.DEFAULT_CHUNK_SIZE;

        Flux<Integer> chunked = Flux.range(0, chunkSize + 4)
                .doOnRequest(requests::add)
                .transform(Operators.lift(new BackpressureChunkingLifter<Integer>()));

        StepVerifier.create(chunked)
                .expectNext(0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19)
                .verifyComplete();

        assertThat(requests).containsExactly((long) chunkSize, (long) chunkSize);
    }
"
"    @Test
    public void rxConsumerIsSet() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        ReactorConsumerStreamObserver rxObs = new ReactorConsumerStreamObserver();

        rxObs.beforeStart(obs);

        assertThat(rxObs.getRxConsumer()).isNotNull();
    }
"
"    @Test
    public void onNextDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        ReactorConsumerStreamObserver rxObs = new ReactorConsumerStreamObserver();
        Subscriber<Object> sub = mock(Subscriber.class);

        rxObs.beforeStart(obs);
        rxObs.getRxConsumer().subscribe(sub);

        Object obj = new Object();
        StepVerifier.create(rxObs.getRxConsumer())
                .then(() -> rxObs.onNext(obj))
                .expectNext(obj)
                .then(rxObs::onCompleted)
                .expectComplete()
                .verify(Duration.ofSeconds(3));
    }
"
"    @Test
    public void onErrorDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        ReactorConsumerStreamObserver rxObs = new ReactorConsumerStreamObserver();
        Subscriber<Object> sub = mock(Subscriber.class);

        rxObs.beforeStart(obs);
        rxObs.getRxConsumer().subscribe(sub);

        Throwable obj = new Exception(""test error"");
        StepVerifier.create(rxObs.getRxConsumer())
                .then(() -> rxObs.onError(obj))
                .expectErrorMessage(""test error"")
                .verify(Duration.ofSeconds(3));
    }
"
"    @Test
    public void noRetryMakesErrorFlowabable() {
        Flux<Integer> test = newThreeErrorFlux()
                .as(flux -> flux);

        StepVerifier.create(test)
                .expectErrorMessage(""Not yet!"")
                .verify(Duration.ofSeconds(1));
    }
"
"    @Test
    public void noRetryMakesErrorSingle() {
        Mono<Integer> test = newThreeErrorMono()
                .as(mono -> mono);

        StepVerifier.create(test)
                .expectErrorMessage(""Not yet!"")
                .verify(Duration.ofSeconds(1));
    }
"
"    @Test
    public void oneToManyRetryWhen() {
        Flux<Integer> test = newThreeErrorMono()
                .<Flux<Integer>>as(GrpcRetry.OneToMany.retryWhen(Mono::flux, Retry.any().retryMax(4)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
"
"    @Test
    public void oneToManyRetryImmediately() {
        Flux<Integer> test = newThreeErrorMono()
                .<Flux<Integer>>as(GrpcRetry.OneToMany.retryImmediately(Mono::flux));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
"
"    @Test
    public void oneToManyRetryAfter() {
        Flux<Integer> test = newThreeErrorMono()
                .<Flux<Integer>>as(GrpcRetry.OneToMany.retryAfter(Mono::flux, Duration.ofMillis(10)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
"
"    @Test
    public void manyToManyRetryWhen() {
        Flux<Integer> test = newThreeErrorFlux()
                .<Integer>compose(GrpcRetry.ManyToMany.retryWhen(Function.identity(), Retry.any().retryMax(4)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
"
"    @Test
    public void manyToManyRetryImmediately() {
        Flux<Integer> test = newThreeErrorFlux()
                .<Integer>compose(GrpcRetry.ManyToMany.retryImmediately(Function.identity()));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
"
"    @Test
    public void manyToManyRetryAfter() {
        Flux<Integer> test = newThreeErrorFlux()
                .<Integer>compose(GrpcRetry.ManyToMany.retryAfter(Function.identity(), Duration.ofMillis(10)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
"
"    @Test
    public void manyToOneRetryWhen() {
        Mono<Integer> test = newThreeErrorFlux()
                .<Mono<Integer>>as(GrpcRetry.ManyToOne.retryWhen(Flux::single, Retry.any().retryMax(4)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
"
"    @Test
    public void manyToOneRetryImmediately() {
        Mono<Integer> test = newThreeErrorFlux()
                .<Mono<Integer>>as(GrpcRetry.ManyToOne.retryImmediately(Flux::single));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
"
"    @Test
    public void manyToOneRetryAfter() {
        Mono<Integer> test = newThreeErrorFlux()
                .<Mono<Integer>>as(GrpcRetry.ManyToOne.retryAfter(Flux::single, Duration.ofMillis(10)));

        StepVerifier.create(test)
                .expectNext(0)
                .expectComplete()
                .verify(Duration.ofSeconds(1));
    }
"
"    @Test
    public void onNextDelegates() {
        ServerCallStreamObserver<Object> obs = mock(ServerCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherServer<Object> pub = new ReactiveStreamObserverPublisherServer<Object>(obs);
        pub.subscribe(sub);

        Object obj = new Object();

        pub.onNext(obj);
        verify(sub).onNext(obj);
    }
"
"    @Test
    public void onErrorDelegates() {
        ServerCallStreamObserver<Object> obs = mock(ServerCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherServer<Object> pub = new ReactiveStreamObserverPublisherServer<Object>(obs);
        pub.subscribe(sub);

        Throwable obj = new Exception();

        pub.onError(obj);
        verify(sub).onError(obj);
    }
"
"    @Test
    public void onCompletedDelegates() {
        ServerCallStreamObserver<Object> obs = mock(ServerCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherServer<Object> pub = new ReactiveStreamObserverPublisherServer<Object>(obs);
        pub.subscribe(sub);

        pub.onCompleted();
        verify(sub).onComplete();
    }
"
"    @Test
    public void requestDelegates() {
        ServerCallStreamObserver<Object> obs = mock(ServerCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        final AtomicReference<Subscription> subscription = new AtomicReference<Subscription>();
        doAnswer(new Answer() {
            @Override
            public Object answer(InvocationOnMock invocationOnMock) {
                subscription.set((Subscription) invocationOnMock.getArguments()[0]);
                return null;
            }
"
"    @Test
    public void onNextDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherClient<Object> pub = new ReactiveStreamObserverPublisherClient<Object>(obs);
        pub.subscribe(sub);

        Object obj = new Object();

        pub.onNext(obj);
        verify(sub).onNext(obj);
    }
"
"    @Test
    public void onErrorDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherClient<Object> pub = new ReactiveStreamObserverPublisherClient<Object>(obs);
        pub.subscribe(sub);

        Throwable obj = new Exception();

        pub.onError(obj);
        verify(sub).onError(obj);
    }
"
"    @Test
    public void onCompletedDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        ReactiveStreamObserverPublisherClient<Object> pub = new ReactiveStreamObserverPublisherClient<Object>(obs);
        pub.subscribe(sub);

        pub.onCompleted();
        verify(sub).onComplete();
    }
"
"    @Test
    public void requestDelegates() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        Subscriber<Object> sub = mock(Subscriber.class);

        final AtomicReference<Subscription> subscription = new AtomicReference<Subscription>();
        doAnswer(new Answer() {
            @Override
            public Object answer(InvocationOnMock invocationOnMock) {
                subscription.set((Subscription) invocationOnMock.getArguments()[0]);
                return null;
            }
"
"    @Test
    public void statusExceptionTriggersHandler() {
        ClientResponseObserver<Object, Object> delegate = mock(ClientResponseObserver.class);
        final AtomicBoolean called = new AtomicBoolean(false);

        CancellableStreamObserver<Object, Object> observer = new CancellableStreamObserver<Object, Object>(delegate, new Runnable() {
            @Override
            public void run() {
                called.set(true);
            }
"
"    @Test
    public void statusRuntimeExceptionTriggersHandler() {
        ClientResponseObserver<Object, Object> delegate = mock(ClientResponseObserver.class);
        final AtomicBoolean called = new AtomicBoolean(false);

        CancellableStreamObserver<Object, Object> observer = new CancellableStreamObserver<Object, Object>(delegate, new Runnable() {
            @Override
            public void run() {
                called.set(true);
            }
"
"    @Test
    public void applySubscribes() {
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(16);

        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        assertThat(chunkSubscriber).isNotNull();

        chunkSubscriber.onSubscribe(upstreamSubscription);
        assertThat(downstreamSubscriber.upstreamSubscription).isNotNull();
    }
"
"    @Test
    public void requestOneGetsAChunk() {
        int chunkSize = 16;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.request(1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
    }
"
"    @Test
    public void requestOneSupplyOneDoesntRequestAnother() {
        int chunkSize = 16;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.request(1);
        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(chunkSize);
    }
"
"    @Test
    public void requestManyGetsAChunkFirst() {
        int chunkSize = 16;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.request(256);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
    }
"
"    @Test
    public void requestManyChunksRequestsAsSatisfiedAndStopsWhenComplete() {
        int chunkSize = 3;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.request(9);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(chunkSize);

        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(3);
        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(3);
        send(chunkSubscriber, 1);
        // Chunk satisfied, request next chunk
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(6);

        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(6);
        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(6);
        send(chunkSubscriber, 1);
        // Chunk satisfied, request next chunk
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(9);

        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(9);
        send(chunkSubscriber, 1);
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(9);
        send(chunkSubscriber, 1);
        // Requested satisfied, do not request any more
        assertThat(upstreamSubscription.lastRequested).isEqualTo(chunkSize);
        assertThat(upstreamSubscription.totalRequested).isEqualTo(9);
    }
"
"    @Test
    public void completePropagatesDown() {
        int chunkSize = 3;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        chunkSubscriber.onComplete();
        assertThat(downstreamSubscriber.isComplete).isTrue();
    }
"
"    @Test
    public void errorPropagatesDown() {
        int chunkSize = 3;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        Throwable t = new Throwable();
        chunkSubscriber.onError(t);
        assertThat(downstreamSubscriber.lastThrowable).isEqualTo(t);
    }
"
"    @Test
    public void cancelPropagatesUp() {
        int chunkSize = 3;
        ReactiveBackpressureChunker<Object> chunker = new ReactiveBackpressureChunker<Object>(chunkSize);
        UpstreamSubscription upstreamSubscription = new UpstreamSubscription();
        DownstreamSubscriber downstreamSubscriber = new DownstreamSubscriber();

        Subscriber<Object> chunkSubscriber = chunker.apply(downstreamSubscriber);
        chunkSubscriber.onSubscribe(upstreamSubscription);

        downstreamSubscriber.upstreamSubscription.cancel();
        assertThat(upstreamSubscription.isCancelled).isTrue();
    }
"
"    @Test
    public void runPrimesThePump() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        when(obs.isReady()).thenReturn(true);
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);

        handler.onSubscribe(sub);

        handler.run();
        verify(sub).request(1);
    }
"
"    @Test
    public void onNextKeepsPumpRunning() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        when(obs.isReady()).thenReturn(true);

        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);

        handler.onSubscribe(sub);

        Object obj = new Object();
        handler.onNext(obj);

        verify(obs).onNext(obj);
        verify(sub).request(1);
    }
"
"    @Test
    public void onNextStopsPump() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        when(obs.isReady()).thenReturn(false);

        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);

        handler.onSubscribe(sub);

        Object obj = new Object();
        handler.onNext(obj);

        verify(obs).onNext(obj);
        verify(sub, never()).request(1);
    }
"
"    @Test
    public void exceptionInOnNextCancelsUpstreamSubscription() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        doThrow(new IllegalStateException(""won't be propagated to handler caller"")).when(obs).onNext(any());
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);
        handler.onSubscribe(sub);
        
        handler.onNext(new Object());
        verify(obs).cancel(anyString(), any(Throwable.class));
        verify(obs).onError(any(Throwable.class));
    }
"
"    @Test
    public void exceptionInOnOnErrorCancelsUpstreamSubscription() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        doThrow(new IllegalStateException(""won't be propagated to handler caller"")).when(obs).onError(any(Throwable.class));
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);
        handler.onSubscribe(sub);
        
        handler.onError(new RuntimeException());
        verify(obs).cancel(anyString(), any(Throwable.class));
    }
"
"    @Test
    public void exceptionInOnCompleteCancelsUpstreamSubscription() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        doThrow(new IllegalStateException(""won't be propagated to handler caller"")).when(obs).onCompleted();
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub = mock(Subscription.class);
        handler.onSubscribe(sub);
        
        handler.onComplete();
        verify(obs).cancel(anyString(), any(Throwable.class));
        verify(obs).onError(any(Throwable.class));
    }
"
"    @Test
    public void onSubscribeCancelsSecondSubscription() {
        ClientCallStreamObserver<Object> obs = mock(ClientCallStreamObserver.class);
        ReactivePublisherBackpressureOnReadyHandlerClient<Object> handler = new ReactivePublisherBackpressureOnReadyHandlerClient<Object>(obs);
        Subscription sub1 = mock(Subscription.class);
        Subscription sub2 = mock(Subscription.class);

        handler.onSubscribe(sub1);
        handler.onSubscribe(sub2);
        
        verify(sub2).cancel();
    }
"
"    @Test
    public void clientCanCancelServerStreamExplicitly() throws InterruptedException {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());
        TestSubscriber<NumberProto.Number> subscription = Single.just(Empty.getDefaultInstance())
                .as(stub::responsePressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""))
                .test();

        Thread.sleep(250);
        subscription.dispose();
        Thread.sleep(250);

        subscription.awaitTerminalEvent(3, TimeUnit.SECONDS);
        // Cancellation may or may not deliver the last generated message due to delays in the gRPC processing thread
        assertThat(Math.abs(subscription.valueCount() - svc.getLastNumberProduced())).isLessThanOrEqualTo(3);
        assertThat(svc.wasCanceled()).isTrue();

        errorRule.verifyNoError();
    }
"
"    @Test
    public void clientCanCancelServerStreamImplicitly() throws InterruptedException {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());
        TestSubscriber<NumberProto.Number> subscription =  Single.just(Empty.getDefaultInstance())
                .as(stub::responsePressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .doOnComplete(() -> System.out.println(""Completed""))
                .doOnCancel(() -> System.out.println(""Client canceled""))
                .take(10)
                .test();

        // Consume some work
        Thread.sleep(TimeUnit.SECONDS.toMillis(1));
        subscription.dispose();

        subscription.awaitTerminalEvent(3, TimeUnit.SECONDS);
        subscription.assertValueCount(10);
        subscription.assertTerminated();
        assertThat(svc.wasCanceled()).isTrue();

        errorRule.verifyNoError();
    }
"
"    @Test
    public void serverCanCancelClientStreamImplicitly() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        svc.setExplicitCancel(false);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flowable<NumberProto.Number> request = Flowable
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delay(10, TimeUnit.MILLISECONDS)
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(x -> {
                    requestDidProduce.set(true);
                    System.out.println(""Produced: "" + x.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        TestObserver<NumberProto.Number> observer = request
                .as(stub::requestPressure)
                .doOnSuccess(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .test();

        observer.awaitTerminalEvent(3, TimeUnit.SECONDS);
        observer.assertComplete();
        observer.assertTerminated();

        await().atMost(Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();

        errorRule.verifyNoError();
    }
"
"    @Test
    public void serverCanCancelClientStreamExplicitly() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        svc.setExplicitCancel(true);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flowable<NumberProto.Number> request = Flowable
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delay(10, TimeUnit.MILLISECONDS)
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(n -> {
                    requestDidProduce.set(true);
                    System.out.println(""P: "" + n.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        TestObserver<NumberProto.Number> observer = request
                .as(stub::requestPressure)
                .doOnSuccess(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .test();

        observer.awaitTerminalEvent();
        observer.assertComplete();
        observer.assertTerminated();

        await().atMost(Duration.FIVE_HUNDRED_MILLISECONDS).untilTrue(requestWasCanceled);

        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();

        errorRule.verifyNoError();
    }
"
"    @Test
    public void serverCanCancelClientStreamImplicitlyBidi() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        svc.setExplicitCancel(false);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flowable<NumberProto.Number> request = Flowable
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delay(10, TimeUnit.MILLISECONDS)
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(x -> {
                    requestDidProduce.set(true);
                    System.out.println(""Produced: "" + x.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        TestSubscriber<NumberProto.Number> observer = request
                .compose(stub::twoWayPressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .test();

        observer.awaitTerminalEvent(3, TimeUnit.SECONDS);
        observer.assertTerminated();
        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();

        errorRule.verifyNoError();
    }
"
"    @Test
    public void serverCanCancelClientStreamExplicitlyBidi() {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        svc.setExplicitCancel(true);

        AtomicBoolean requestWasCanceled = new AtomicBoolean(false);
        AtomicBoolean requestDidProduce = new AtomicBoolean(false);

        Flowable<NumberProto.Number> request = Flowable
                .fromIterable(IntStream.range(0, NUMBER_OF_STREAM_ELEMENTS)::iterator)
                .delay(10, TimeUnit.MILLISECONDS)
                .map(CancellationPropagationIntegrationTest::protoNum)
                .doOnNext(n -> {
                    requestDidProduce.set(true);
                    System.out.println(""P: "" + n.getNumber(0));
                })
                .doOnCancel(() -> {
                    requestWasCanceled.set(true);
                    System.out.println(""Client canceled"");
                });

        TestSubscriber<NumberProto.Number> observer = request
                .compose(stub::twoWayPressure)
                .doOnNext(number -> System.out.println(number.getNumber(0)))
                .doOnError(throwable -> System.out.println(throwable.getMessage()))
                .test();

        observer.awaitTerminalEvent();
        observer.assertTerminated();
        assertThat(requestWasCanceled.get()).isTrue();
        assertThat(requestDidProduce.get()).isTrue();

        errorRule.verifyNoError();
    }
"
"    @Test
    public void prematureResponseStreamDisposalShouldNotThrowUnhandledException() throws Exception {
        TestService svc = new TestService();
        serverRule.getServiceRegistry().addService(svc);

        RxNumbersGrpc.RxNumbersStub stub = RxNumbersGrpc.newRxStub(serverRule.getChannel());

        // slowly process the response stream
        Disposable subscription = stub.responsePressure(Empty.getDefaultInstance()).subscribe(n -> {
            Thread.sleep(1000);
        });

        subscription.dispose();

        Thread.sleep(200);
        errorRule.verifyNoError();
    }
"
"    @Test
    public void oneToOne() {
        RxGreeterGrpc.RxGreeterStub stub = RxGreeterGrpc.newRxStub(channel);
        Single<HelloResponse> resp = Single.just(HelloRequest.getDefaultInstance()).compose(stub::sayHello);
        TestObserver<HelloResponse> test = resp.test();

        test.awaitTerminalEvent(3, TimeUnit.SECONDS);
        test.assertError(t -> t instanceof StatusRuntimeException);
        test.assertError(t -> ((StatusRuntimeException)t).getStatus() == Status.INTERNAL);
    }
"
"	@BeforeEach
	public void beforeEach() {
		super.beforeEach();
	}
"
"	@Test
	public void concatMapCB() throws Exception {
		System.out.println(""Start concatMapCB"");
		System.out.println(""\n******** Using concatMap() *********"");
		ParallelFlux<GetResult> concat = Flux.fromIterable(keyList).parallel(2).runOn(Schedulers.parallel())
				.concatMap(item -> cbGet(item)
						/* rCollection.get(item) */.doOnSubscribe((x) -> System.out.println("" +"" + rCat.incrementAndGet()))
						.doOnTerminate(() -> System.out.println("" -"" + rCat.decrementAndGet())));
		System.out.println(concat.sequential().collectList().block());
	}
"
"	@Test
	public void cbse() {
		LinkedList<LinkedList<Airport>> listOfLists = new LinkedList<>();
		Airport a = new Airport(UUID.randomUUID().toString(), ""iata"", ""lowp"");
		String last = null;
		for (int i = 0; i < 5; i++) {
			LinkedList<Airport> list = new LinkedList<>();
			for (int j = 0; j < 10; j++) {
				list.add(a.withId(UUID.randomUUID().toString()));
				last = a.getId();
			}
			listOfLists.add(list);
		}
		Flux<Object> af = Flux.fromIterable(listOfLists).concatMap(catalogToStore -> Flux.fromIterable(catalogToStore)
				.parallel(4).runOn(Schedulers.parallel()).concatMap((entity) -> airportRepository.save(entity)));
		List<Object> saved = af.collectList().block();
		System.out.println(""results.size() : "" + saved.size());

		String statement = ""select * from `"" + /*config().bucketname()*/ ""_default"" + ""` where META().id >= '"" + last + ""'"";
		System.out.println(""statement: "" + statement);
		try {
			QueryResult qr = couchbaseTemplate.getCouchbaseClientFactory().getScope().query(statement,
					QueryOptions.queryOptions().profile(QueryProfile.PHASES));
			List<RemoveResult> rr = couchbaseTemplate.removeByQuery(Airport.class)
					.withOptions(QueryOptions.queryOptions().scanConsistency(QueryScanConsistency.REQUEST_PLUS)).all();
			System.out.println(qr.metaData().profile().get());
		} catch (Exception e) {
			e.printStackTrace();
			throw e;
		}
		List<Airport> airports = airportRepository.findAll().collectList().block();
		assertEquals(0, airports.size(), ""should have been all deleted"");
	}
"
"	@Test
	public void pairIdAndResult() {
		LinkedList<Airport> list = new LinkedList<>();
		Airport a = new Airport(UUID.randomUUID().toString(), ""iata"", ""lowp"");
		for (int i = 0; i < 5; i++) {
			list.add(a.withId(UUID.randomUUID().toString()));
		}
		Flux<Object> af = Flux.fromIterable(list).concatMap((entity) -> airportRepository.save(entity));
		List<Object> saved = af.collectList().block();
		System.out.println(""results.size() : "" + saved.size());
		Flux<Pair<String, Mono<Airport>>> pairFlux = Flux.fromIterable(list)
				.map((airport) -> Pair.of(airport.getId(), airportRepository.findById(airport.getId())));
		List<Pair<String, Mono<Airport>>> airportPairs = pairFlux.collectList().block();
		for (Pair<String, Mono<Airport>> airportPair : airportPairs) {
			System.out.println(""id: "" + airportPair.getFirst() + "" airport: "" + airportPair.getSecond().block());
		}

	}
"
"	@Test
	public void flatMapCB() throws Exception {
		System.out.println(""Start flatMapCB"");
		ParallelFlux<GetResult> concat = Flux.fromIterable(keyList).parallel(2).runOn(Schedulers.parallel())
				.flatMap(item -> cbGet(item) /* rCollection.get(item) */
						.doOnSubscribe((x) -> System.out.println("" +"" + rCat.incrementAndGet()))
						.doOnTerminate(() -> System.out.println("" -"" + rCat.decrementAndGet())));
		System.out.println(concat.sequential().collectList().block());
	}
"
"	@Test
	public void flatMapSyncCB() throws Exception {
		System.out.println(""Start flatMapSyncCB"");
		System.out.println(""\n******** Using flatSyncMap() *********"");
		ParallelFlux<GetResult> concat = Flux.fromIterable(keyList).parallel(2).runOn(Schedulers.parallel())
				.flatMap(item -> Flux.just(cbGetSync(item) /* collection.get(item) */));
		System.out.println(concat.sequential().collectList().block());
		;
	}
"
"	@Test
	public void flatMapVsConcatMapCB2() throws Exception {
		System.out.println(""Start flatMapCB2"");
		System.out.println(""\n******** Using flatMap() *********"");
		ParallelFlux<GetResult> flat = Flux.fromIterable(keyList).parallel(1).runOn(Schedulers.parallel())
				.flatMap(item -> rCollection.get(item).doOnSubscribe((x) -> System.out.println("" +"" + rCat.incrementAndGet()))
						.doOnTerminate(() -> System.out.println("" -"" + rCat.getAndDecrement())));
		System.out.println(flat.sequential().collectList().block());
		System.out.println(""Start concatMapCB"");
		System.out.println(""\n******** Using concatMap() *********"");
		ParallelFlux<GetResult> concat = Flux.fromIterable(keyList).parallel(2).runOn(Schedulers.parallel())
				.concatMap(item -> cbGet(item).doOnSubscribe((x) -> System.out.println("" +"" + rCat.incrementAndGet()))
						.doOnTerminate(() -> System.out.println("" -"" + rCat.getAndDecrement())));
		System.out.println(concat.sequential().collectList().block());
		;
	}
"
"	@BeforeEach
	public void beforeEach() {
		super.beforeEach();
		// already setup by JavaIntegrationTests.beforeAll()
		// ApplicationContext ac = new AnnotationConfigApplicationContext(Config.class);
		// couchbaseTemplate = (CouchbaseTemplate) ac.getBean(COUCHBASE_TEMPLATE);
		// reactiveCouchbaseTemplate = (ReactiveCouchbaseTemplate) ac.getBean(REACTIVE_COUCHBASE_TEMPLATE);
		// ensure each test starts with clean state

		couchbaseTemplate.removeByQuery(User.class).all();
		couchbaseTemplate.findByQuery(User.class).withConsistency(QueryScanConsistency.REQUEST_PLUS).all();
	}
"
"	@BeforeEach
	public void beforeEach() {
		super.beforeEach();
		couchbaseTemplate.removeByQuery(User.class).all();
		couchbaseTemplate.removeByQuery(UserAnnotated.class).all();
		couchbaseTemplate.removeByQuery(UserAnnotated2.class).all();
		couchbaseTemplate.removeByQuery(UserAnnotated3.class).all();
		couchbaseTemplate.removeByQuery(User.class).withConsistency(QueryScanConsistency.REQUEST_PLUS).all();
	}
"
"	@BeforeEach
	public void beforeEach() {
		super.beforeEach();
		List<RemoveResult> r1 = reactiveCouchbaseTemplate.removeByQuery(User.class).all().collectList().block();
		List<RemoveResult> r2 = reactiveCouchbaseTemplate.removeByQuery(UserAnnotated.class).all().collectList().block();
		List<RemoveResult> r3 = reactiveCouchbaseTemplate.removeByQuery(UserAnnotated2.class).all().collectList().block();
	}
"
"	@BeforeEach
	public void beforeEach() {
		// first call the super method
		super.beforeEach();
		// then do processing for this class
		couchbaseTemplate.removeByQuery(User.class).inCollection(collectionName).all();
		couchbaseTemplate.findByQuery(User.class).withConsistency(QueryScanConsistency.REQUEST_PLUS)
				.inCollection(collectionName).all();
		couchbaseTemplate.removeByQuery(Airport.class).inScope(scopeName).inCollection(collectionName).all();
		couchbaseTemplate.findByQuery(Airport.class).withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(scopeName)
				.inCollection(collectionName).all();
		couchbaseTemplate.removeByQuery(Airport.class).inScope(otherScope).inCollection(otherCollection).all();
		couchbaseTemplate.findByQuery(Airport.class).withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(otherScope)
				.inCollection(otherCollection).all();
	}
"
"	@AfterEach
	public void afterEach() {
		// first do processing for this class
		couchbaseTemplate.removeByQuery(User.class).inCollection(collectionName).all();
		// query with REQUEST_PLUS to ensure that the remove has completed.
		couchbaseTemplate.findByQuery(User.class).withConsistency(QueryScanConsistency.REQUEST_PLUS)
				.inCollection(collectionName).all();
		// then call the super method
		super.afterEach();
	}
"
"	@Test
	public void existsById() { // 1
		GetOptions options = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		ExistsOptions existsOptions = ExistsOptions.existsOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(scopeName).inCollection(collectionName).one(vie.withIcao(""low7"")).block();
		try {
			Boolean exists = template.existsById().inScope(scopeName).inCollection(collectionName).withOptions(existsOptions)
					.one(saved.getId()).block();
			assertTrue(exists, ""Airport should exist: "" + saved.getId());
		} finally {
			template.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void findByAnalytics() { // 2
		AnalyticsOptions options = AnalyticsOptions.analyticsOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(scopeName).inCollection(collectionName).one(vie.withIcao(""low8"")).block();
		try {
			List<Airport> found = template.findByAnalytics(Airport.class).inScope(scopeName).inCollection(collectionName)
					.withOptions(options).all().collectList().block();
			assertEquals(saved, found);
		} finally {
			template.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void findById() { // 3
		GetOptions options = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(scopeName).inCollection(collectionName).one(vie.withIcao(""low9"")).block();
		try {
			Airport found = template.findById(Airport.class).inScope(scopeName).inCollection(collectionName)
					.withOptions(options).one(saved.getId()).block();
			assertEquals(saved, found);
		} finally {
			template.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void findByQuery() { // 4
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(scopeName).inCollection(collectionName).one(vie.withIcao(""lowa"")).block();
		try {
			List<Airport> found = template.findByQuery(Airport.class).withConsistency(QueryScanConsistency.REQUEST_PLUS)
					.inScope(scopeName).inCollection(collectionName).withOptions(options).all().collectList().block();
			assertEquals(saved.getId(), found.get(0).getId());
		} finally {
			template.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void findFromReplicasById() { // 5
		GetAnyReplicaOptions options = GetAnyReplicaOptions.getAnyReplicaOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(scopeName).inCollection(collectionName).one(vie.withIcao(""lowb"")).block();
		try {
			Airport found = template.findFromReplicasById(Airport.class).inScope(scopeName).inCollection(collectionName)
					.withOptions(options).any(saved.getId()).block();
			assertEquals(saved, found);
		} finally {
			template.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void insertById() { // 6
		InsertOptions options = InsertOptions.insertOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.withOptions(options).one(vie.withIcao(""lowc"").withId(UUID.randomUUID().toString())).block();
		try {
			Airport found = template.findById(Airport.class).inScope(scopeName).inCollection(collectionName)
					.withOptions(getOptions).one(saved.getId()).block();
			assertEquals(saved, found);
		} finally {
			template.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void removeById() { // 7
		RemoveOptions options = RemoveOptions.removeOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(scopeName).inCollection(collectionName).one(vie.withIcao(""lowd"")).block();
		RemoveResult removeResult = template.removeById().inScope(scopeName).inCollection(collectionName)
				.withOptions(options).one(saved.getId()).block();
		assertEquals(saved.getId(), removeResult.getId());
	}
"
"	@Test
	public void removeByQuery() { // 8
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(scopeName).inCollection(collectionName).one(vie.withIcao(""lowe"")).block();
		List<RemoveResult> removeResults = template.removeByQuery(Airport.class)
				.withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(scopeName).inCollection(collectionName)
				.withOptions(options).matching(Query.query(QueryCriteria.where(""iata"").is(vie.getIata()))).all().collectList()
				.block();
		assertEquals(saved.getId(), removeResults.get(0).getId());
	}
"
"	@Test
	public void replaceById() { // 9
		InsertOptions insertOptions = InsertOptions.insertOptions().timeout(Duration.ofSeconds(10));
		ReplaceOptions options = ReplaceOptions.replaceOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.withOptions(insertOptions).one(vie.withIcao(""lowe"")).block();
		Airport replaced = template.replaceById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.withOptions(options).one(vie.withIcao(""newIcao"")).block();
		try {
			Airport found = template.findById(Airport.class).inScope(scopeName).inCollection(collectionName)
					.withOptions(getOptions).one(saved.getId()).block();
			assertEquals(replaced, found);
		} finally {
			template.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void upsertById() { // 10
		UpsertOptions options = UpsertOptions.upsertOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));

		Airport saved = template.upsertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.withOptions(options).one(vie.withIcao(""lowf"")).block();
		try {
			Airport found = template.findById(Airport.class).inScope(scopeName).inCollection(collectionName)
					.withOptions(getOptions).one(saved.getId()).block();
			assertEquals(saved, found);
		} finally {
			template.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void existsByIdOther() { // 1
		GetOptions options = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		ExistsOptions existsOptions = ExistsOptions.existsOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection).one(vie.withIcao(""lowg""))
				.block();
		try {
			Boolean exists = template.existsById().inScope(otherScope).inCollection(otherCollection)
					.withOptions(existsOptions).one(saved.getId()).block();
			assertTrue(exists, ""Airport should exist: "" + saved.getId());
		} finally {
			template.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void findByAnalyticsOther() { // 2
		AnalyticsOptions options = AnalyticsOptions.analyticsOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection).one(vie.withIcao(""lowh""))
				.block();
		try {
			List<Airport> found = template.findByAnalytics(Airport.class).inScope(otherScope).inCollection(otherCollection)
					.withOptions(options).all().collectList().block();
			assertEquals(saved, found);
		} finally {
			template.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void findByIdOther() { // 3
		GetOptions options = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection).one(vie.withIcao(""lowi""))
				.block();
		try {
			Airport found = template.findById(Airport.class).inScope(otherScope).inCollection(otherCollection)
					.withOptions(options).one(saved.getId()).block();
			assertEquals(saved, found);
		} finally {
			template.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void findByQueryOther() { // 4
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection).one(vie.withIcao(""lowj""))
				.block();
		try {
			List<Airport> found = template.findByQuery(Airport.class).withConsistency(QueryScanConsistency.REQUEST_PLUS)
					.inScope(otherScope).inCollection(otherCollection).withOptions(options).all().collectList().block();
			assertEquals(saved.getId(), found.get(0).getId());
		} finally {
			template.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void findFromReplicasByIdOther() { // 5
		GetAnyReplicaOptions options = GetAnyReplicaOptions.getAnyReplicaOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection).one(vie.withIcao(""lowk""))
				.block();
		try {
			Airport found = template.findFromReplicasById(Airport.class).inScope(otherScope).inCollection(otherCollection)
					.withOptions(options).any(saved.getId()).block();
			assertEquals(saved, found);
		} finally {
			template.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void insertByIdOther() { // 6
		InsertOptions options = InsertOptions.insertOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.withOptions(options).one(vie.withIcao(""lowl"").withId(UUID.randomUUID().toString())).block();
		try {
			Airport found = template.findById(Airport.class).inScope(otherScope).inCollection(otherCollection)
					.withOptions(getOptions).one(saved.getId()).block();
			assertEquals(saved, found);
		} finally {
			template.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void removeByIdOther() { // 7
		RemoveOptions options = RemoveOptions.removeOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection).one(vie.withIcao(""lowm""))
				.block();
		RemoveResult removeResult = template.removeById().inScope(otherScope).inCollection(otherCollection)
				.withOptions(options).one(saved.getId()).block();
		assertEquals(saved.getId(), removeResult.getId());
	}
"
"	@Test
	public void removeByQueryOther() { // 8
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection).one(vie.withIcao(""lown""))
				.block();
		List<RemoveResult> removeResults = template.removeByQuery(Airport.class)
				.withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(otherScope).inCollection(otherCollection)
				.withOptions(options).matching(Query.query(QueryCriteria.where(""iata"").is(vie.getIata()))).all().collectList()
				.block();
		assertEquals(saved.getId(), removeResults.get(0).getId());
	}
"
"	@Test
	public void replaceByIdOther() { // 9
		InsertOptions insertOptions = InsertOptions.insertOptions().timeout(Duration.ofSeconds(10));
		ReplaceOptions options = ReplaceOptions.replaceOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.withOptions(insertOptions).one(vie.withIcao(""lown"")).block();
		Airport replaced = template.replaceById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.withOptions(options).one(vie.withIcao(""newIcao"")).block();
		try {
			Airport found = template.findById(Airport.class).inScope(otherScope).inCollection(otherCollection)
					.withOptions(getOptions).one(saved.getId()).block();
			assertEquals(replaced, found);
		} finally {
			template.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void upsertByIdOther() { // 10
		UpsertOptions options = UpsertOptions.upsertOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));

		Airport saved = template.upsertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.withOptions(options).one(vie.withIcao(""lowo"")).block();
		try {
			Airport found = template.findById(Airport.class).inScope(otherScope).inCollection(otherCollection)
					.withOptions(getOptions).one(saved.getId()).block();
			assertEquals(saved, found);
		} finally {
			template.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void existsByIdOptions() { // 1 - Options
		ExistsOptions options = ExistsOptions.existsOptions().timeout(Duration.ofNanos(10));
		assertThrows(UnambiguousTimeoutException.class, () -> template.existsById().inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie.getId()).block());
	}
"
"	@Test
	public void findByAnalyticsOptions() { // 2
		AnalyticsOptions options = AnalyticsOptions.analyticsOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class, () -> template.findByAnalytics(Airport.class).inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).all().collectList().block());
	}
"
"	@Test
	public void findByIdOptions() { // 3
		GetOptions options = GetOptions.getOptions().timeout(Duration.ofNanos(10));
		assertThrows(UnambiguousTimeoutException.class, () -> template.findById(Airport.class).inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie.getId()).block());
	}
"
"	@Test
	public void findByQueryOptions() { // 4
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class,
				() -> template.findByQuery(Airport.class).withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(otherScope)
						.inCollection(otherCollection).withOptions(options).all().collectList().block());
	}
"
"	@Test
	public void findFromReplicasByIdOptions() { // 5
		GetAnyReplicaOptions options = GetAnyReplicaOptions.getAnyReplicaOptions().timeout(Duration.ofNanos(1000));
		Airport saved = template.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection).one(vie)
				.block();
		try {
			Airport found = template.findFromReplicasById(Airport.class).inScope(otherScope).inCollection(otherCollection)
					.withOptions(options).any(saved.getId()).block();
			assertNull(found, ""should not have found document in short timeout"");
		} finally {
			template.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId()).block();
		}
	}
"
"	@Test
	public void insertByIdOptions() { // 6
		InsertOptions options = InsertOptions.insertOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class, () -> template.insertById(Airport.class).inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie.withId(UUID.randomUUID().toString())).block());
	}
"
"	@Test
	public void removeByIdOptions() { // 7 - options
		Airport saved = template.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection).one(vie)
				.block();
		RemoveOptions options = RemoveOptions.removeOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class, () -> template.removeById().inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie.getId()).block());

	}
"
"	@Test
	public void removeByQueryOptions() { // 8 - options
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class,
				() -> template.removeByQuery(Airport.class).withConsistency(QueryScanConsistency.REQUEST_PLUS)
						.inScope(otherScope).inCollection(otherCollection).withOptions(options)
						.matching(Query.query(QueryCriteria.where(""iata"").is(vie.getIata()))).all().collectList().block());
	}
"
"	@Test
	public void replaceByIdOptions() { // 9 - options
		ReplaceOptions options = ReplaceOptions.replaceOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class, () -> template.replaceById(Airport.class).inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie.withIcao(""newIcao"")).block());
	}
"
"	@Test
	public void upsertByIdOptions() { // 10 - options
		UpsertOptions options = UpsertOptions.upsertOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class, () -> template.upsertById(Airport.class).inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie).block());
	}
"
"	@Test
	public void testNullValue() {
		QueryCriteria c = where(i(""name"")).is(null);
		assertEquals(""`name` = null"", c.export());
	}
"
"	@BeforeEach
	public void beforeEach() {
		// first call the super method
		super.beforeEach();
		// then do processing for this class
		couchbaseTemplate.removeByQuery(User.class).inCollection(collectionName).all();
		couchbaseTemplate.findByQuery(User.class).withConsistency(QueryScanConsistency.REQUEST_PLUS)
				.inCollection(collectionName).all();
		couchbaseTemplate.removeByQuery(Airport.class).inScope(scopeName).inCollection(collectionName).all();
		couchbaseTemplate.findByQuery(Airport.class).withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(scopeName)
				.inCollection(collectionName).all();
		couchbaseTemplate.removeByQuery(Airport.class).inScope(otherScope).inCollection(otherCollection).all();
		couchbaseTemplate.findByQuery(Airport.class).withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(otherScope)
				.inCollection(otherCollection).all();
	}
"
"	@AfterEach
	public void afterEach() {
		// first do processing for this class
		couchbaseTemplate.removeByQuery(User.class).inCollection(collectionName).all();
		// query with REQUEST_PLUS to ensure that the remove has completed.
		couchbaseTemplate.findByQuery(User.class).withConsistency(QueryScanConsistency.REQUEST_PLUS)
				.inCollection(collectionName).all();
		// then call the super method
		super.afterEach();
	}
"
"	@Test
	public void existsById() { // 1
		GetOptions options = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		ExistsOptions existsOptions = ExistsOptions.existsOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.one(vie);
		try {
			Boolean exists = couchbaseTemplate.existsById().inScope(scopeName).inCollection(collectionName)
					.withOptions(existsOptions).one(saved.getId());
			assertTrue(exists, ""Airport should exist: "" + saved.getId());
		} finally {
			couchbaseTemplate.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId());
		}
	}
"
"	@Test
	public void findByAnalytics() { // 2
		AnalyticsOptions options = AnalyticsOptions.analyticsOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.one(vie);
		try {
			List<Airport> found = couchbaseTemplate.findByAnalytics(Airport.class).inScope(scopeName)
					.inCollection(collectionName).withOptions(options).all();
			assertEquals(saved, found);
		} finally {
			couchbaseTemplate.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId());
		}
	}
"
"	@Test
	public void findById() { // 3
		GetOptions options = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.one(vie);
		try {
			Airport found = couchbaseTemplate.findById(Airport.class).inScope(scopeName).inCollection(collectionName)
					.withOptions(options).one(saved.getId());
			assertEquals(saved, found);
		} finally {
			couchbaseTemplate.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId());
		}
	}
"
"	@Test
	public void findByQuery() { // 4
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.one(vie);
		try {
			List<Airport> found = couchbaseTemplate.findByQuery(Airport.class)
					.withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(scopeName).inCollection(collectionName)
					.withOptions(options).all();
			assertEquals(saved.getId(), found.get(0).getId());
		} finally {
			couchbaseTemplate.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId());
		}
	}
"
"	@Test
	public void findFromReplicasById() { // 5
		GetAnyReplicaOptions options = GetAnyReplicaOptions.getAnyReplicaOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.one(vie);
		try {
			Airport found = couchbaseTemplate.findFromReplicasById(Airport.class).inScope(scopeName)
					.inCollection(collectionName).withOptions(options).any(saved.getId());
			assertEquals(saved, found);
		} finally {
			couchbaseTemplate.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId());
		}
	}
"
"	@Test
	public void insertById() { // 6
		InsertOptions options = InsertOptions.insertOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.withOptions(options).one(vie.withId(UUID.randomUUID().toString()));
		try {
			Airport found = couchbaseTemplate.findById(Airport.class).inScope(scopeName).inCollection(collectionName)
					.withOptions(getOptions).one(saved.getId());
			assertEquals(saved, found);
		} finally {
			couchbaseTemplate.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId());
		}
	}
"
"	@Test
	public void removeById() { // 7
		RemoveOptions options = RemoveOptions.removeOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.one(vie);
		RemoveResult removeResult = couchbaseTemplate.removeById().inScope(scopeName).inCollection(collectionName)
				.withOptions(options).one(saved.getId());
		assertEquals(saved.getId(), removeResult.getId());
	}
"
"	@Test
	public void removeByQuery() { // 8
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.one(vie);
		List<RemoveResult> removeResults = couchbaseTemplate.removeByQuery(Airport.class)
				.withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(scopeName).inCollection(collectionName)
				.withOptions(options).matching(Query.query(QueryCriteria.where(""iata"").is(vie.getIata()))).all();
		assertEquals(saved.getId(), removeResults.get(0).getId());
	}
"
"	@Test
	public void replaceById() { // 9
		InsertOptions insertOptions = InsertOptions.insertOptions().timeout(Duration.ofSeconds(10));
		ReplaceOptions options = ReplaceOptions.replaceOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.withOptions(insertOptions).one(vie);
		Airport replaced = couchbaseTemplate.replaceById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.withOptions(options).one(vie.withIcao(""newIcao""));
		try {
			Airport found = couchbaseTemplate.findById(Airport.class).inScope(scopeName).inCollection(collectionName)
					.withOptions(getOptions).one(saved.getId());
			assertEquals(replaced, found);
		} finally {
			couchbaseTemplate.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId());
		}
	}
"
"	@Test
	public void upsertById() { // 10
		UpsertOptions options = UpsertOptions.upsertOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));

		Airport saved = couchbaseTemplate.upsertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.withOptions(options).one(vie);
		try {
			Airport found = couchbaseTemplate.findById(Airport.class).inScope(scopeName).inCollection(collectionName)
					.withOptions(getOptions).one(saved.getId());
			assertEquals(saved, found);
		} finally {
			couchbaseTemplate.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId());
		}
	}
"
"	@Test
	public void existsByIdOther() { // 1
		GetOptions options = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		ExistsOptions existsOptions = ExistsOptions.existsOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.one(vie);
		try {
			Boolean exists = couchbaseTemplate.existsById().inScope(otherScope).inCollection(otherCollection)
					.withOptions(existsOptions).one(saved.getId());
			assertTrue(exists, ""Airport should exist: "" + saved.getId());
		} finally {
			couchbaseTemplate.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId());
		}
	}
"
"	@Test
	public void findByAnalyticsOther() { // 2
		AnalyticsOptions options = AnalyticsOptions.analyticsOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.one(vie);
		try {
			List<Airport> found = couchbaseTemplate.findByAnalytics(Airport.class).inScope(otherScope)
					.inCollection(otherCollection).withOptions(options).all();
			assertEquals(saved, found);
		} finally {
			couchbaseTemplate.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId());
		}
	}
"
"	@Test
	public void findByIdOther() { // 3
		GetOptions options = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.one(vie);
		try {
			Airport found = couchbaseTemplate.findById(Airport.class).inScope(otherScope).inCollection(otherCollection)
					.withOptions(options).one(saved.getId());
			assertEquals(saved, found);
		} finally {
			couchbaseTemplate.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId());
		}
	}
"
"	@Test
	public void findByQueryOther() { // 4
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.one(vie);
		try {
			List<Airport> found = couchbaseTemplate.findByQuery(Airport.class)
					.withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(otherScope).inCollection(otherCollection)
					.withOptions(options).all();
			assertEquals(saved.getId(), found.get(0).getId());
		} finally {
			couchbaseTemplate.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId());
		}
	}
"
"	@Test
	public void findFromReplicasByIdOther() { // 5
		GetAnyReplicaOptions options = GetAnyReplicaOptions.getAnyReplicaOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.one(vie);
		try {
			Airport found = couchbaseTemplate.findFromReplicasById(Airport.class).inScope(otherScope)
					.inCollection(otherCollection).withOptions(options).any(saved.getId());
			assertEquals(saved, found);
		} finally {
			couchbaseTemplate.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId());
		}
	}
"
"	@Test
	public void insertByIdOther() { // 6
		InsertOptions options = InsertOptions.insertOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.withOptions(options).one(vie.withId(UUID.randomUUID().toString()));
		try {
			Airport found = couchbaseTemplate.findById(Airport.class).inScope(otherScope).inCollection(otherCollection)
					.withOptions(getOptions).one(saved.getId());
			assertEquals(saved, found);
		} finally {
			couchbaseTemplate.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId());
		}
	}
"
"	@Test
	public void removeByIdOther() { // 7
		RemoveOptions options = RemoveOptions.removeOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.one(vie);
		RemoveResult removeResult = couchbaseTemplate.removeById().inScope(otherScope).inCollection(otherCollection)
				.withOptions(options).one(saved.getId());
		assertEquals(saved.getId(), removeResult.getId());
	}
"
"	@Test
	public void removeByQueryOther() { // 8
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.one(vie);
		List<RemoveResult> removeResults = couchbaseTemplate.removeByQuery(Airport.class)
				.withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(otherScope).inCollection(otherCollection)
				.withOptions(options).matching(Query.query(QueryCriteria.where(""iata"").is(vie.getIata()))).all();
		assertEquals(saved.getId(), removeResults.get(0).getId());
	}
"
"	@Test
	public void replaceByIdOther() { // 9
		InsertOptions insertOptions = InsertOptions.insertOptions().timeout(Duration.ofSeconds(10));
		ReplaceOptions options = ReplaceOptions.replaceOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.withOptions(insertOptions).one(vie);
		Airport replaced = couchbaseTemplate.replaceById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.withOptions(options).one(vie.withIcao(""newIcao""));
		try {
			Airport found = couchbaseTemplate.findById(Airport.class).inScope(otherScope).inCollection(otherCollection)
					.withOptions(getOptions).one(saved.getId());
			assertEquals(replaced, found);
		} finally {
			couchbaseTemplate.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId());
		}
	}
"
"	@Test
	public void upsertByIdOther() { // 10
		UpsertOptions options = UpsertOptions.upsertOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));

		Airport saved = couchbaseTemplate.upsertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.withOptions(options).one(vie);
		try {
			Airport found = couchbaseTemplate.findById(Airport.class).inScope(otherScope).inCollection(otherCollection)
					.withOptions(getOptions).one(saved.getId());
			assertEquals(saved, found);
		} finally {
			couchbaseTemplate.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId());
		}
	}
"
"	@Test
	public void existsByIdOptions() { // 1 - Options
		ExistsOptions options = ExistsOptions.existsOptions().timeout(Duration.ofNanos(10));
		assertThrows(UnambiguousTimeoutException.class, () -> couchbaseTemplate.existsById().inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie.getId()));
	}
"
"	@Test
	public void findByAnalyticsOptions() { // 2
		AnalyticsOptions options = AnalyticsOptions.analyticsOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class, () -> couchbaseTemplate.findByAnalytics(Airport.class)
				.inScope(otherScope).inCollection(otherCollection).withOptions(options).all());
	}
"
"	@Test
	public void findByIdOptions() { // 3
		GetOptions options = GetOptions.getOptions().timeout(Duration.ofNanos(10));
		assertThrows(UnambiguousTimeoutException.class, () -> couchbaseTemplate.findById(Airport.class).inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie.getId()));
	}
"
"	@Test
	public void findByQueryOptions() { // 4
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class,
				() -> couchbaseTemplate.findByQuery(Airport.class).withConsistency(QueryScanConsistency.REQUEST_PLUS)
						.inScope(otherScope).inCollection(otherCollection).withOptions(options).all());
	}
"
"	@Test
	public void findFromReplicasByIdOptions() { // 5
		GetAnyReplicaOptions options = GetAnyReplicaOptions.getAnyReplicaOptions().timeout(Duration.ofNanos(1000));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.one(vie);
		try {
			Airport found = couchbaseTemplate.findFromReplicasById(Airport.class).inScope(otherScope)
					.inCollection(otherCollection).withOptions(options).any(saved.getId());
			assertNull(found, ""should not have found document in short timeout"");
		} finally {
			couchbaseTemplate.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId());
		}
	}
"
"	@Test
	public void insertByIdOptions() { // 6
		InsertOptions options = InsertOptions.insertOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class, () -> couchbaseTemplate.insertById(Airport.class).inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie.withId(UUID.randomUUID().toString())));
	}
"
"	@Test
	public void removeByIdOptions() { // 7 - options
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.one(vie);
		RemoveOptions options = RemoveOptions.removeOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class, () -> couchbaseTemplate.removeById().inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie.getId()));

	}
"
"	@Test
	public void removeByQueryOptions() { // 8 - options
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class,
				() -> couchbaseTemplate.removeByQuery(Airport.class).withConsistency(QueryScanConsistency.REQUEST_PLUS)
						.inScope(otherScope).inCollection(otherCollection).withOptions(options)
						.matching(Query.query(QueryCriteria.where(""iata"").is(vie.getIata()))).all());
	}
"
"	@Test
	public void replaceByIdOptions() { // 9 - options
		ReplaceOptions options = ReplaceOptions.replaceOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class, () -> couchbaseTemplate.replaceById(Airport.class).inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie.withIcao(""newIcao"")));
	}
"
"	@Test
	public void upsertByIdOptions() { // 10 - options
		UpsertOptions options = UpsertOptions.upsertOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class, () -> couchbaseTemplate.upsertById(Airport.class).inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie));
	}
"
"	@Test
	public void testScopeCollectionAnnotation() {
		UserCol user = new UserCol(""1"", ""Dave"", ""Wilson"");
		Query query = Query.query(QueryCriteria.where(""firstname"").is(user.getFirstname()));
		try {
			UserCol saved = couchbaseTemplate.insertById(UserCol.class).inScope(scopeName).inCollection(collectionName)
					.one(user);
			List<UserCol> found = couchbaseTemplate.findByQuery(UserCol.class)
					.withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(scopeName).inCollection(collectionName)
					.matching(query).all();
			assertEquals(saved, found.get(0), ""should have found what was saved"");
			List<UserCol> notfound = couchbaseTemplate.findByQuery(UserCol.class).inScope(CollectionIdentifier.DEFAULT_SCOPE)
					.inCollection(CollectionIdentifier.DEFAULT_COLLECTION).matching(query).all();
			assertEquals(0, notfound.size(), ""should not have found what was saved"");
			couchbaseTemplate.removeByQuery(UserCol.class).inScope(scopeName).inCollection(collectionName).matching(query)
					.all();
		} finally {
			try {
				couchbaseTemplate.removeByQuery(UserCol.class).inScope(scopeName).inCollection(collectionName).matching(query)
						.all();
			} catch (DataRetrievalFailureException drfe) {}
		}
	}
"
"	@Test
	public void testScopeCollectionRepoWith() {
		UserCol user = new UserCol(""1"", ""Dave"", ""Wilson"");
		Query query = Query.query(QueryCriteria.where(""firstname"").is(user.getFirstname()));
		try {
			UserCol saved = couchbaseTemplate.insertById(UserCol.class).inScope(scopeName).inCollection(collectionName)
					.one(user);
			List<UserCol> found = couchbaseTemplate.findByQuery(UserCol.class)
					.withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(scopeName).inCollection(collectionName)
					.matching(query).all();
			assertEquals(saved, found.get(0), ""should have found what was saved"");
			List<UserCol> notfound = couchbaseTemplate.findByQuery(UserCol.class).inScope(CollectionIdentifier.DEFAULT_SCOPE)
					.inCollection(CollectionIdentifier.DEFAULT_COLLECTION).matching(query).all();
			assertEquals(0, notfound.size(), ""should not have found what was saved"");
			couchbaseTemplate.removeByQuery(UserCol.class).inScope(scopeName).inCollection(collectionName).matching(query)
					.all();
		} finally {
			try {
				couchbaseTemplate.removeByQuery(UserCol.class).inScope(scopeName).inCollection(collectionName).matching(query)
						.all();
			} catch (DataRetrievalFailureException drfe) {}
		}
	}
"
"	@Test
		public String getConnectionString() {
			return connectionString();
		}
"
"	@Test
		public String getId() {
			return springId;
		}
"
"	@Test
		public String convert(Integer source) {
			return source % 2 == 0 ? ""even"" : ""odd"";
		}
"
"	@BeforeEach
	public void beforeEach() {
		context = new CouchbaseMappingContext();
		converter = new MappingCouchbaseConverter(context);
		bucketName = ""sample-bucket"";
	}
"
"	@BeforeEach
	public void beforeEach() {
		context = new CouchbaseMappingContext();
		converter = new MappingCouchbaseConverter(context);
		ApplicationContext ac = new AnnotationConfigApplicationContext(Config.class);
		couchbaseTemplate = (CouchbaseTemplate) ac.getBean(COUCHBASE_TEMPLATE);
	}
"
"	@Test
		public String getConnectionString() {
			return connectionString();
		}
"
"	@BeforeEach
	public void beforeEach() {
		context = new CouchbaseMappingContext();
		converter = new MappingCouchbaseConverter(context);
		ApplicationContext ac = new AnnotationConfigApplicationContext(Config.class);
		couchbaseTemplate = (CouchbaseTemplate) ac.getBean(COUCHBASE_TEMPLATE);
	}
"
"	@Test
		public String getConnectionString() {
			return connectionString();
		}
"
"	@BeforeEach
	public void beforeEach() {
		// first call the super method
		super.beforeEach();
		// then do processing for this class
		couchbaseTemplate.removeByQuery(User.class).inCollection(collectionName).all();
		couchbaseTemplate.removeByQuery(UserCol.class).inScope(otherScope).inCollection(otherCollection).all();
		ApplicationContext ac = new AnnotationConfigApplicationContext(Config.class);
		// seems that @Autowired is not adequate, so ...
		airportRepository = (AirportRepository) ac.getBean(""airportRepository"");
		userColRepository = (UserColRepository) ac.getBean(""userColRepository"");
	}
"
"	@AfterEach
	public void afterEach() {
		// first do processing for this class
		// no-op
		// then call the super method
		super.afterEach();
	}
"
"	@Test
	public void myTest() {

		AirportRepository ar = airportRepository.withScope(scopeName).withCollection(collectionName);
		Airport vie = new Airport(""airports::vie"", ""vie"", ""loww"");
		try {
			Airport saved = ar.save(vie);
			Airport airport2 = ar.save(saved);
		} catch (Exception e) {
			e.printStackTrace();
			throw e;
		} finally {
			ar.delete(vie);
		}

	}
"
"	@Test
	public void testScopeCollectionAnnotation() {
		// template default scope is my_scope
		// UserCol annotation scope is other_scope
		UserCol user = new UserCol(""1"", ""Dave"", ""Wilson"");
		try {
			UserCol saved = userColRepository.withCollection(otherCollection).save(user); // should use UserCol annotation
																																										// scope
			List<UserCol> found = userColRepository.withCollection(otherCollection).findByFirstname(user.getFirstname());
			assertEquals(saved, found.get(0), ""should have found what was saved"");
			List<UserCol> notfound = userColRepository.withScope(DEFAULT_SCOPE)
					.withCollection(CollectionIdentifier.DEFAULT_COLLECTION).findByFirstname(user.getFirstname());
			assertEquals(0, notfound.size(), ""should not have found what was saved"");
		} finally {
			try {
				userColRepository.withScope(otherScope).withCollection(otherCollection).delete(user);
			} catch (DataRetrievalFailureException drfe) {}
		}
	}
"
"	@Test
	public void testScopeCollectionAnnotationSwap() {
		// UserCol annotation scope is other_scope, collection is other_collection
		// airportRepository relies on Config.setScopeName(scopeName) (""my_scope"") from CollectionAwareIntegrationTests.
		// using airportRepository without specified a collection should fail.
		// This test ensures that airportRepository.save(airport) doesn't get the
		// collection from CrudMethodMetadata of UserCol.save()
		UserCol userCol = new UserCol(""1"", ""Dave"", ""Wilson"");
		Airport airport = new Airport(""3"", ""myIata"", ""myIcao"");
		UserCol savedCol = userColRepository.save(userCol); // uses UserCol annotation scope, populates CrudMethodMetadata
		userColRepository.delete(userCol); // uses UserCol annotation scope, populates CrudMethodMetadata
		assertThrows(IllegalStateException.class, () -> airportRepository.save(airport));
	}
"
"	@Test
	public void testScopeCollectionRepoWith() {
		UserCol user = new UserCol(""1"", ""Dave"", ""Wilson"");
		try {
			UserCol saved = userColRepository.withScope(scopeName).withCollection(collectionName).save(user);
			List<UserCol> found = userColRepository.withScope(scopeName).withCollection(collectionName)
					.findByFirstname(user.getFirstname());
			assertEquals(saved, found.get(0), ""should have found what was saved"");
			List<UserCol> notfound = userColRepository.withScope(DEFAULT_SCOPE)
					.withCollection(CollectionIdentifier.DEFAULT_COLLECTION).findByFirstname(user.getFirstname());
			assertEquals(0, notfound.size(), ""should not have found what was saved"");
			userColRepository.withScope(scopeName).withCollection(collectionName).delete(user);
		} finally {
			try {
				userColRepository.withScope(scopeName).withCollection(collectionName).delete(user);
			} catch (DataRetrievalFailureException drfe) {}
		}
	}
"
"	@BeforeEach
	public void beforeEach() {
		// first call the super method
		super.beforeEach();
		// then do processing for this class
		couchbaseTemplate.removeByQuery(User.class).inCollection(collectionName).all();
		couchbaseTemplate.removeByQuery(UserCol.class).inScope(otherScope).inCollection(otherCollection).all();

		ApplicationContext ac = new AnnotationConfigApplicationContext(Config.class);
		// seems that @Autowired is not adequate, so ...
		airportRepository = (ReactiveAirportRepository) ac.getBean(""reactiveAirportRepository"");
		userColRepository = (ReactiveUserColRepository) ac.getBean(""reactiveUserColRepository"");
	}
"
"	@AfterEach
	public void afterEach() {
		// first do processing for this class
		// no-op
		// then call the super method
		super.afterEach();
	}
"
"	@Test
	public void myTest() {

		ReactiveAirportRepository ar = airportRepository.withScope(scopeName).withCollection(collectionName);
		Airport vie = new Airport(""airports::vie"", ""vie"", ""loww"");
		try {
			Airport saved = ar.save(vie).block();
			Airport airport2 = ar.save(saved).block();
		} catch (Exception e) {
			e.printStackTrace();
			throw e;
		} finally {
			ar.delete(vie).block();
		}

	}
"
"	@Test
	public void testScopeCollectionAnnotation() {
		// template default scope is my_scope
		// UserCol annotation scope is other_scope
		UserCol user = new UserCol(""1"", ""Dave"", ""Wilson"");
		try {
			UserCol saved = userColRepository.withCollection(otherCollection).save(user).block(); // should use UserCol
																																														// annotation
			// scope
			List<UserCol> found = userColRepository.withCollection(otherCollection).findByFirstname(user.getFirstname())
					.collectList().block();
			assertEquals(saved, found.get(0), ""should have found what was saved"");
			List<UserCol> notfound = userColRepository.withScope(CollectionIdentifier.DEFAULT_SCOPE)
					.withCollection(CollectionIdentifier.DEFAULT_COLLECTION).findByFirstname(user.getFirstname()).collectList()
					.block();
			assertEquals(0, notfound.size(), ""should not have found what was saved"");
		} finally {
			try {
				userColRepository.withScope(otherScope).withCollection(otherCollection).delete(user);
			} catch (DataRetrievalFailureException drfe) {}
		}
	}
"
"	@Test
	public void testScopeCollectionRepoWith() {
		UserCol user = new UserCol(""1"", ""Dave"", ""Wilson"");
		try {
			UserCol saved = userColRepository.withScope(scopeName).withCollection(collectionName).save(user).block();
			List<UserCol> found = userColRepository.withScope(scopeName).withCollection(collectionName)
					.findByFirstname(user.getFirstname()).collectList().block();
			assertEquals(saved, found.get(0), ""should have found what was saved"");
			List<UserCol> notfound = userColRepository.withScope(CollectionIdentifier.DEFAULT_SCOPE)
					.withCollection(CollectionIdentifier.DEFAULT_COLLECTION).findByFirstname(user.getFirstname()).collectList()
					.block();
			assertEquals(0, notfound.size(), ""should not have found what was saved"");
			userColRepository.withScope(scopeName).withCollection(collectionName).delete(user).block();
		} finally {
			try {
				userColRepository.withScope(scopeName).withCollection(collectionName).delete(user).block();
			} catch (DataRetrievalFailureException drfe) {}
		}
	}
"
"	@Test
		public String getConnectionString() {
			return connectionString();
		}
"
"	@Test
	public void testCas() {
		User user = new User(""1"", ""Dave"", ""Wilson"");
		userRepository.save(user).block();
		user.setVersion(user.getVersion() - 1);
		assertThrows(DataIntegrityViolationException.class, () -> userRepository.save(user).block());
		user.setVersion(0);
		userRepository.save(user).block();
		userRepository.delete(user).block();
	}
"
"	@Test
	public Mono<Airport> getPolicyByIdAndEffectiveDateTime(String policyId, Instant effectiveDateTime) {
		return airportRepository
				.findPolicySnapshotByPolicyIdAndEffectiveDateTime(policyId, effectiveDateTime.toEpochMilli())
				// .map(Airport::getEntity)
				.doOnError(
						error -> System.out.println(""MSG='Exception happened while retrieving Policy by Id and effectiveDateTime', ""
								+ ""policyId={}, effectiveDateTime={}""));
	}
"
"	@Test
		public String getConnectionString() {
			return connectionString();
		}
"
"    @Test
    public void testThorwExceptionOnNotAllowedMethod() throws Exception {
        final String filename = ""com/opensymphony/xwork2/config/providers/xwork-test-allowed-methods.xml"";
        loadConfigurationProviders(new XmlConfigurationProvider(filename));
        DefaultActionProxy dap = new DefaultActionProxy(new MockActionInvocation(), ""strict"", ""Default"", ""notAllowed"", true, true);
        container.inject(dap);

        try {
            dap.prepare();
            fail(""Must throw exception!"");
        } catch (Exception e) {
            assertEquals(e.getMessage(), ""Method notAllowed for action Default is not allowed!"");
        }
    }
"
"    @Test
    public void testNullObject() throws Exception {
        // given
        RequiredFieldValidator rfv = container.inject(RequiredFieldValidator.class);
        rfv.setValueStack(ActionContext.getContext().getValueStack());
        rfv.setFieldName(""stringValue"");
        rfv.setDefaultMessage(""${fieldName} field is required!"");
        ValidationAction action = new ValidationAction();
        DummyValidatorContext context = new DummyValidatorContext(action, container.getInstance(TextProviderFactory.class));
        rfv.setValidatorContext(context);

        // when
        rfv.validate(action);

        // then
        assertTrue(context.hasFieldErrors());
        assertEquals(1, context.getFieldErrors().size());
        assertNotNull(context.getFieldErrors().get(""stringValue""));
        assertEquals(""stringValue field is required!"", context.getFieldErrors().get(""stringValue"").get(0));
    }
"
"    @Test
    public void testArrayObject() throws Exception {
        // given
        RequiredFieldValidator rfv = container.inject(RequiredFieldValidator.class);
        rfv.setValueStack(ActionContext.getContext().getValueStack());
        rfv.setFieldName(""ints"");
        rfv.setDefaultMessage(""${fieldName} field is required!"");
        ValidationAction action = new ValidationAction();
        action.setInts(new Integer[]{});
        DummyValidatorContext context = new DummyValidatorContext(action, container.getInstance(TextProviderFactory.class));
        rfv.setValidatorContext(context);

        // when
        rfv.validate(action);

        // then
        assertTrue(context.hasFieldErrors());
        assertEquals(1, context.getFieldErrors().size());
        assertNotNull(context.getFieldErrors().get(""ints""));
        assertEquals(""ints field is required!"", context.getFieldErrors().get(""ints"").get(0));
    }
"
"    @Test
    public void testCollectionObject() throws Exception {
        // given
        RequiredFieldValidator rfv = container.inject(RequiredFieldValidator.class);
        rfv.setValueStack(ActionContext.getContext().getValueStack());
        rfv.setFieldName(""shorts"");
        rfv.setDefaultMessage(""${fieldName} field is required!"");
        ValidationAction action = new ValidationAction();
        action.setShorts(new ArrayList<Short>());
        DummyValidatorContext context = new DummyValidatorContext(action, container.getInstance(TextProviderFactory.class));
        rfv.setValidatorContext(context);

        // when
        rfv.validate(action);

        // then
        assertTrue(context.hasFieldErrors());
        assertEquals(1, context.getFieldErrors().size());
        assertNotNull(context.getFieldErrors().get(""shorts""));
        assertEquals(""shorts field is required!"", context.getFieldErrors().get(""shorts"").get(0));
    }
"
"    @Test
        public void testRun() {
            ran = true;
            mgr = this.configurationManager;
        }
"
"    @Test
    public void testCompile() {
        NamedVariablePatternMatcher matcher = new NamedVariablePatternMatcher();

        assertNull(matcher.compilePattern(null));
        assertNull(matcher.compilePattern(""""));

        CompiledPattern pattern = matcher.compilePattern(""foo"");
        assertEquals(""foo"", pattern.getPattern().pattern());

        pattern = matcher.compilePattern(""foo{jim}"");
        assertEquals(""foo([^/]+)"", pattern.getPattern().pattern());
        assertEquals(""jim"", pattern.getVariableNames().get(0));

        pattern = matcher.compilePattern(""foo{jim}/{bob}"");
        assertEquals(""foo([^/]+)/([^/]+)"", pattern.getPattern().pattern());
        assertEquals(""jim"", pattern.getVariableNames().get(0));
        assertEquals(""bob"", pattern.getVariableNames().get(1));
        assertTrue(pattern.getPattern().matcher(""foostar/jie"").matches());
        assertFalse(pattern.getPattern().matcher(""foo/star/jie"").matches());
    }
"
"    @Test(expected = IllegalArgumentException.class)
    public void testCompileWithMismatchedBracketsParses() {
        NamedVariablePatternMatcher matcher = new NamedVariablePatternMatcher();

        matcher.compilePattern(""}"");
"
"    @Test
    public void testMatch() {
        NamedVariablePatternMatcher matcher = new NamedVariablePatternMatcher();

        Map<String, String> vars = new HashMap<>();
        CompiledPattern pattern = new CompiledPattern(Pattern.compile(""foo([^/]+)""), Arrays.asList(""bar""));

        assertTrue(matcher.match(vars, ""foobaz"", pattern));
        assertEquals(""baz"", vars.get(""bar""));
    }
"
"    @Test
    public void testIsLiteral() {
        NamedVariablePatternMatcher matcher = new NamedVariablePatternMatcher();

        assertTrue(matcher.isLiteral(""bob""));
        assertFalse(matcher.isLiteral(""bob{jim}""));
    }
"
"    @Test(dataProvider = ""paramValues"")
    public void shouldConvertRequestValuesToStringArrays(Object input, String[] expected) {
        Parameter.Request request = new Parameter.Request(PARAM_NAME, input);

        String[] result = request.getMultipleValues();

        assertEquals(result, expected);
        assertNotSame(result, input);
    }
"
"    @Test
    public void unknownContentLength() throws IOException {
        HttpServletRequest request = Mockito.mock(HttpServletRequest.class);
        Mockito.when(request.getContentType()).thenReturn(""multipart/form-data; charset=utf-8; boundary=__X_BOUNDARY__"");
        Mockito.when(request.getMethod()).thenReturn(""POST"");
        Mockito.when(request.getContentLength()).thenReturn(Integer.valueOf(-1));
        StringBuilder entity = new StringBuilder();
        entity.append(""\r\n--__X_BOUNDARY__\r\n"");
        entity.append(""Content-Disposition: form-data; name=\""upload\""; filename=\""test.csv\""\r\n"");
        entity.append(""Content-Type: text/csv\r\n\r\n1,2\r\n\r\n"");
        entity.append(""--__X_BOUNDARY__\r\n"");
        entity.append(""Content-Disposition: form-data; name=\""upload2\""; filename=\""test2.csv\""\r\n"");
        entity.append(""Content-Type: text/csv\r\n\r\n3,4\r\n\r\n"");
        entity.append(""--__X_BOUNDARY__--\r\n"");
        Mockito.when(request.getInputStream()).thenReturn(new DelegatingServletInputStream(new ByteArrayInputStream(entity.toString().getBytes(StandardCharsets.UTF_8))));
        multiPart.setMaxSize(""4"");
        multiPart.parse(request, tempDir.toString());
        LocalizedMessage next = multiPart.getErrors().iterator().next();
        Assert.assertEquals(next.getTextKey(), ""struts.messages.upload.error.SizeLimitExceededException"");
    }
"
"    @Test
    public void testRegister() throws Exception {
        final ConstantConfig constantConfig = new ConstantConfig();
        constantConfig.setDevMode(true);

        final String expectedUnknownHandler = ""expectedUnknownHandler"";

        StrutsJavaConfiguration javaConfig = new StrutsJavaConfiguration() {
            @Override
            public List<String> unknownHandlerStack() {
                return Arrays.asList(expectedUnknownHandler);
            }
"
"    @Test
    public void testBeanConfToString() throws Exception {
        ConstantConfig constantConfig = new ConstantConfig();

        String actual = constantConfig.beanConfToString(null);
        Assert.assertEquals(null, actual);

        actual = constantConfig.beanConfToString(new BeanConfig(TestBean.class));
        Assert.assertEquals(Container.DEFAULT_NAME, actual);

        String expectedName = ""expectedTestBeanName"";
        actual = constantConfig.beanConfToString(new BeanConfig(TestBean.class, expectedName));
        Assert.assertEquals(expectedName, actual);
    }
"
"    @Test
    public void testGetAllAsStringsMap() throws Exception {
        ConstantConfig constantConfig = new ConstantConfig();

        boolean expectedDevMode = true;
        constantConfig.setDevMode(expectedDevMode);

        String expectedActionExtensions = "".action,.some,.another"";
        constantConfig.setActionExtension(Arrays.asList(expectedActionExtensions.split("","")));

        String expectedLanguage = ""fr"";
        constantConfig.setLocale(new Locale(expectedLanguage));

        Map<String, String> map = constantConfig.getAllAsStringsMap();

        Assert.assertEquals(String.valueOf(expectedDevMode), map.get(StrutsConstants.STRUTS_DEVMODE));
        Assert.assertEquals(expectedActionExtensions, map.get(StrutsConstants.STRUTS_ACTION_EXTENSION));
        Assert.assertEquals(null, map.get(StrutsConstants.STRUTS_I18N_RELOAD));
        Assert.assertEquals(expectedLanguage, map.get(StrutsConstants.STRUTS_LOCALE));
    }
"
"    @Test
    public void testEmptyClassesToString() throws Exception {
        ConstantConfig constantConfig = new ConstantConfig();

        constantConfig.setExcludedClasses(new HashSet<Class<?>>());

        Map<String, String> map = constantConfig.getAllAsStringsMap();
        Assert.assertEquals(null, map.get(StrutsConstants.STRUTS_EXCLUDED_CLASSES));
    }
"
"    @Test
    public void testClassesToString() throws Exception {
        ConstantConfig constantConfig = new ConstantConfig();

        Set<Class<?>> excludedClasses = new LinkedHashSet<>();
        excludedClasses.add(Object.class);
        excludedClasses.add(Runtime.class);
        excludedClasses.add(System.class);

        constantConfig.setExcludedClasses(excludedClasses);

        Map<String, String> map = constantConfig.getAllAsStringsMap();
        Assert.assertEquals(""java.lang.Object,java.lang.Runtime,java.lang.System"",
                map.get(StrutsConstants.STRUTS_EXCLUDED_CLASSES));
    }
"
"    @Test
    public void testConstructor() throws Exception {
        Class<TestBean> expectedClass = TestBean.class;

        BeanConfig beanConfig = new BeanConfig(expectedClass);

        Assert.assertEquals(expectedClass, beanConfig.getClazz());
        Assert.assertEquals(Container.DEFAULT_NAME, beanConfig.getName());
        Assert.assertEquals(Scope.SINGLETON, beanConfig.getScope());
        Assert.assertEquals(expectedClass, beanConfig.getType());
        Assert.assertFalse(beanConfig.isOnlyStatic());
        Assert.assertFalse(beanConfig.isOptional());
    }
"
"    @Test
    public void testConstructor2() throws Exception {
        Class<TestBean> expectedClass = TestBean.class;
        String expectedName = ""expectedBeanName"";
        Class<Object> expectedType = Object.class;
        Scope expectedScope = Scope.PROTOTYPE;
        boolean expectedOnlyStatic = true;
        boolean expectedOptional = true;

        BeanConfig beanConfig = new BeanConfig(expectedClass, expectedName, expectedType, expectedScope,
                expectedOnlyStatic, expectedOptional);

        Assert.assertEquals(expectedClass, beanConfig.getClazz());
        Assert.assertEquals(expectedName, beanConfig.getName());
        Assert.assertEquals(expectedScope, beanConfig.getScope());
        Assert.assertEquals(expectedType, beanConfig.getType());
        Assert.assertEquals(expectedOnlyStatic, beanConfig.isOnlyStatic());
        Assert.assertEquals(expectedOptional, beanConfig.isOptional());
    }
"
"    @Test
    public void testURLDecodeStringInvalid() {
        // %n rather than %nn should throw an IAE according to the Javadoc
        Exception exception = null;
        try {
            URLDecoderUtil.decode(""%5xxxxx"", ""ISO-8859-1"");
        } catch (Exception e) {
            exception = e;
        }
        assertTrue(exception instanceof IllegalArgumentException);

        // Edge case trying to trigger ArrayIndexOutOfBoundsException
        exception = null;
        try {
            URLDecoderUtil.decode(""%5"", ""ISO-8859-1"");
        } catch (Exception e) {
            exception = e;
        }
        assertTrue(exception instanceof IllegalArgumentException);
    }
"
"    @Test
    public void testURLDecodeStringValidIso88591Start() {

        String result = URLDecoderUtil.decode(""%41xxxx"", ""ISO-8859-1"");
        assertEquals(""Axxxx"", result);
    }
"
"    @Test
    public void testURLDecodeStringValidIso88591Middle() {

        String result = URLDecoderUtil.decode(""xx%41xx"", ""ISO-8859-1"");
        assertEquals(""xxAxx"", result);
    }
"
"    @Test
    public void testURLDecodeStringValidIso88591End() {

        String result = URLDecoderUtil.decode(""xxxx%41"", ""ISO-8859-1"");
        assertEquals(""xxxxA"", result);
    }
"
"    @Test
    public void testURLDecodeStringValidUtf8Start() {
        String result = URLDecoderUtil.decode(""%c3%aaxxxx"", ""UTF-8"");
        assertEquals(""\u00eaxxxx"", result);
    }
"
"    @Test
    public void testURLDecodeStringValidUtf8Middle() {

        String result = URLDecoderUtil.decode(""xx%c3%aaxx"", ""UTF-8"");
        assertEquals(""xx\u00eaxx"", result);
    }
"
"    @Test
    public void testURLDecodeStringValidUtf8End() {

        String result = URLDecoderUtil.decode(""xxxx%c3%aa"", ""UTF-8"");
        assertEquals(""xxxx\u00ea"", result);
    }
"
"    @Test
    public void testURLDecodePlusCharAsSpace() {

        String result = URLDecoderUtil.decode(""a+b"", ""UTF-8"", true);
        assertEquals(""a b"", result);
    }
"
"    @Test
    public void convertUploadedFileToFile() throws Exception {
        // given
        UploadedFileConverter ufc = new UploadedFileConverter();
        UploadedFile uploadedFile = new StrutsUploadedFile(tempFile);

        // when
        Object result = ufc.convertValue(context, target, member, propertyName, uploadedFile, File.class);

        // then
        assertThat(result).isInstanceOf(File.class);
        File file = (File) result;
        assertThat(file.length()).isEqualTo(tempFile.length());
        assertThat(file.getAbsolutePath()).isEqualTo(tempFile.getAbsolutePath());
    }
"
"    @Test
    public void convertUploadedFileArrayToFile() throws Exception {
        // given
        UploadedFileConverter ufc = new UploadedFileConverter();
        UploadedFile[] uploadedFile = new UploadedFile[] { new StrutsUploadedFile(tempFile) };

        // when
        Object result = ufc.convertValue(context, target, member, propertyName, uploadedFile, File.class);

        // then
        assertThat(result).isInstanceOf(File.class);
        File file = (File) result;
        assertThat(file.length()).isEqualTo(tempFile.length());
        assertThat(file.getAbsolutePath()).isEqualTo(tempFile.getAbsolutePath());
    }
"
"    @Test
    public void testConventionUrl() throws Exception {
        // Output is filled out only for FreeMarker and Velocity templates
        // If you wanna use JSP check response.getForwardedUrl()
        String output = executeAction(""/view.action"");

        assertTrue(output.contains(""This is the view Hello World""));

        ViewAction action = this.getAction();
        assertEquals(""Hello World"", action.getMessage());
    }
"
"    @Test
    public void testExecuteActionAgainstCustomStrutsConfigFile() throws Exception {
        String output = executeAction(""/test/testAction-2.action"");
        Assert.assertEquals(""Test-2"", output);
    }
"
"    @Test
    public void testSessionInitialized() throws Exception {
        ActionProxy proxy = getActionProxy(""/test/testAction-2.action"");
        Assert.assertNotNull(""invocation session should being initialized"",
                proxy.getInvocation().getInvocationContext().getSession());
    }
"
"    @Test
    public void shouldPortletContextBeAvailable() throws Exception {
        // given
        assertNull(ActionContext.getContext().get(StrutsStatics.STRUTS_PORTLET_CONTEXT));

        // when
        String output = executeAction(""/test/testAction.action"");
        assertEquals(""Hello"", output);

        // then
        Object portletContext = ActionContext.getContext().get(StrutsStatics.STRUTS_PORTLET_CONTEXT);
        assertNotNull(portletContext);
        assertTrue(portletContext instanceof PortletContext);
    }
"
"    @Test
    public void shouldAdditionalContextParamsBeAvailable() throws Exception {
        // given
        String key = ""my-param"";
        assertNull(ActionContext.getContext().get(key));

        // when
        String output = executeAction(""/test/testAction.action"");
        assertEquals(""Hello"", output);

        // then
        assertNotNull(ActionContext.getContext().get(key));
    }
"
"	@Test
    public void getActionMapping() {
        ActionMapping mapping = getActionMapping(""/test/testAction.action"");
        Assert.assertNotNull(mapping);
        Assert.assertEquals(""/test"", mapping.getNamespace());
        Assert.assertEquals(""testAction"", mapping.getName());
    }
"
"	@Test
    public void getActionProxy() throws Exception {
        //set parameters before calling getActionProxy
        request.setParameter(""name"", ""FD"");
        
        ActionProxy proxy = getActionProxy(""/test/testAction.action"");
        Assert.assertNotNull(proxy);

        JUnitTestAction action = (JUnitTestAction) proxy.getAction();
        Assert.assertNotNull(action);

        String result = proxy.execute();
        Assert.assertEquals(Action.SUCCESS, result);
        Assert.assertEquals(""FD"", action.getName());
    }
"
"	@Test
    public void executeAction() throws ServletException, UnsupportedEncodingException {
        String output = executeAction(""/test/testAction.action"");
        Assert.assertEquals(""Hello"", output);
    }
"
"	@Test
    public void getValueFromStack() throws ServletException, UnsupportedEncodingException {
        request.setParameter(""name"", ""FD"");
        executeAction(""/test/testAction.action"");
        String name = (String) findValueAfterExecute(""name"");
        Assert.assertEquals(""FD"", name);
    }
"
"    @Test
    public void testPersistingSessionValues() throws Exception {
        String output = executeAction(""/sessiontest/sessionSet.action"");
        Assert.assertEquals(""sessionValue"", output);

        this.finishExecution();

        String output2 = executeAction(""/sessiontest/sessionGet.action"");
        Assert.assertEquals(""sessionValue"", output2);
    }
"
"        @Test 
        public void testRun() {
            ran = true;
            mgr = this.configurationManager;
            du = Dispatcher.getInstance();
        }
"
"    @Test
    public void findAnnotationSingleAction() {
        StrutsTilesAnnotationProcessor annotationProcessor = new StrutsTilesAnnotationProcessor();
        TilesDefinition tilesDefinition = annotationProcessor.findAnnotation(new TilesTestActionSingleAnnotation(), null);
        Assert.assertNotNull(tilesDefinition);
        Assert.assertEquals(""definition-name"", tilesDefinition.name());
    }
"
"    @Test
    public void findAnnotationMultipleActionNameNull() {
        StrutsTilesAnnotationProcessor annotationProcessor = new StrutsTilesAnnotationProcessor();
        TilesDefinition tilesDefinition = annotationProcessor.findAnnotation(new TilesTestActionMultipleAnnotations(), null);
        Assert.assertNotNull(tilesDefinition);
        Assert.assertEquals(""def1"", tilesDefinition.name());
    }
"
"    @Test
    public void findAnnotationMultipleActionNameGiven() {
        StrutsTilesAnnotationProcessor annotationProcessor = new StrutsTilesAnnotationProcessor();
        TilesDefinition tilesDefinition = annotationProcessor.findAnnotation(new TilesTestActionMultipleAnnotations(), ""def2"");
        Assert.assertNotNull(tilesDefinition);
        Assert.assertEquals(""def2"", tilesDefinition.name());
    }
"
"    @Test
    public void findAnnotationMultipleActionNotFound() {
        StrutsTilesAnnotationProcessor annotationProcessor = new StrutsTilesAnnotationProcessor();
        TilesDefinition tilesDefinition = annotationProcessor.findAnnotation(new TilesTestActionMultipleAnnotations(), ""def3"");
        Assert.assertNull(tilesDefinition);
    }
"
"    @Test
    public void buildDefiniton() {
        StrutsTilesAnnotationProcessor annotationProcessor = new StrutsTilesAnnotationProcessor();
        TilesDefinition tilesDefinition = annotationProcessor.findAnnotation(new TilesTestActionSingleAnnotation(), null);

        Definition definition = annotationProcessor.buildTilesDefinition(""tileName"", tilesDefinition);

        Assert.assertNotNull(definition);
        Assert.assertEquals(""tileName"", definition.getName());
        Assert.assertEquals(""preparer"", definition.getPreparer());
        Assert.assertEquals(""base-definition"", definition.getExtends());
        Attribute templateAttribute = definition.getTemplateAttribute();
        Assert.assertEquals(""template"", templateAttribute.getValue());
        Assert.assertEquals(""type"", templateAttribute.getRenderer());
        Assert.assertEquals(""role"", templateAttribute.getRole());
        Expression definitionExpressionObject = templateAttribute.getExpressionObject();
        Assert.assertEquals(""templ*"", definitionExpressionObject.getExpression());
        Assert.assertNull(definitionExpressionObject.getLanguage());

        Attribute putAttribute = definition.getAttribute(""put-attr"");
        Assert.assertNotNull(putAttribute);
        Assert.assertEquals(""attr-val"", putAttribute.getValue());
        Assert.assertEquals(""attr-type"", putAttribute.getRenderer());
        Assert.assertEquals(""attr-role"", putAttribute.getRole());
        Expression putAttrExpressionObject = putAttribute.getExpressionObject();
        Assert.assertEquals(""expr"", putAttrExpressionObject.getExpression());
        Assert.assertEquals(""lang"", putAttrExpressionObject.getLanguage());

        Attribute listAttribute = definition.getAttribute(""list-name"");
        Assert.assertEquals(""list-role"", listAttribute.getRole());
        List<Attribute> listValue = getListValue(listAttribute);
        Assert.assertEquals(2, listValue.size());

        Attribute addAttribute = listValue.get(0);
        Assert.assertEquals(""list-attr-role"", addAttribute.getRole());
        Assert.assertEquals(""list-attr-val"", addAttribute.getValue());
        Assert.assertEquals(""list-attr-type"", addAttribute.getRenderer());
        Expression addAttrExpressionObject = addAttribute.getExpressionObject();
        Assert.assertEquals(""list-attr-expr"", addAttrExpressionObject.getExpression());

        Attribute addListAttribute = listValue.get(1);
        Assert.assertEquals(""list-list-attr-role"", addListAttribute.getRole());
        List<Attribute> addListValue = getListValue(addListAttribute);
        Assert.assertEquals(1, addListValue.size());
        Assert.assertEquals(""list-list-add-attr"", addListValue.get(0).getValue());

        Set<String> cascadedAttributeNames = definition.getCascadedAttributeNames();
        Assert.assertEquals(2, cascadedAttributeNames.size());
        Assert.assertTrue(cascadedAttributeNames.contains(""put-attr""));
        Assert.assertTrue(cascadedAttributeNames.contains(""list-name""));
    }
"
"    @Test
    public void buildDefinitonAllEmpty() {
        StrutsTilesAnnotationProcessor annotationProcessor = new StrutsTilesAnnotationProcessor();
        TilesDefinition tilesDefinition = annotationProcessor.findAnnotation(new TilesTestActionSingleAnnotationAllEmpty(), null);

        Definition definition = annotationProcessor.buildTilesDefinition(null, tilesDefinition);

        Assert.assertNotNull(definition);
        Assert.assertNull(definition.getName());
        Assert.assertNull(definition.getPreparer());
        Assert.assertNull(definition.getExtends());
        Attribute templateAttribute = definition.getTemplateAttribute();
        Assert.assertNull(templateAttribute.getValue());
        Assert.assertNull(templateAttribute.getRole());
        Assert.assertNull(templateAttribute.getExpressionObject());

        Attribute putAttribute = definition.getAttribute(""put-attr"");
        Assert.assertNotNull(putAttribute);
        Assert.assertNull(putAttribute.getValue());
        Assert.assertNull(putAttribute.getRenderer());
        Assert.assertNull(putAttribute.getRole());
        Assert.assertNull(putAttribute.getExpressionObject());

        Attribute listAttribute = definition.getAttribute(""list-name"");
        Assert.assertNull(listAttribute.getRole());
        List<Attribute> listValue = getListValue(listAttribute);
        Assert.assertEquals(2, listValue.size());

        Attribute addAttribute = listValue.get(0);
        Assert.assertNull(addAttribute.getRole());
        Assert.assertNull(addAttribute.getValue());
        Assert.assertNull(addAttribute.getRenderer());
        Assert.assertNull(addAttribute.getExpressionObject());

        Attribute addListAttribute = listValue.get(1);
        Assert.assertNull(addListAttribute.getRole());
        List<Attribute> addListValue = getListValue(addListAttribute);
        Assert.assertEquals(1, addListValue.size());
        Assert.assertNull(addListValue.get(0).getValue());

        Set<String> cascadedAttributeNames = definition.getCascadedAttributeNames();
        Assert.assertNull(cascadedAttributeNames);
    }
"
"    @Test
    public void testFindBeanManager() throws Exception {
        assertNotNull(new CdiObjectFactory().findBeanManager());
    }
"
"    @Test
    public void testGetBean() throws Exception {
        final CdiObjectFactory cdiObjectFactory = new CdiObjectFactory();
        FooConsumer fooConsumer = (FooConsumer) cdiObjectFactory.buildBean(FooConsumer.class.getCanonicalName(), null, false);
        assertNotNull(fooConsumer);
        assertNotNull(fooConsumer.fooService);
    }
"
"    @Test
    public void testExponentialNumber() throws Exception {
        Object ret = reader.read(""5e-5"");
        assertNotNull(ret);
        assertEquals(Double.class, ret.getClass());
        assertEquals(5.0E-5, ret);
    }
"
"    @Test
    public void testExponentialNumber2() throws Exception {
        Object ret = reader.read(""123.4e10"");
        assertNotNull(ret);
        assertEquals(Double.class, ret.getClass());
        assertEquals(123.4e10, ret);
    }
"
"    @Test
    public void testDecimalNumber() throws Exception {
        Object ret = reader.read(""3.2"");
        assertNotNull(ret);
        assertEquals(Double.class, ret.getClass());
        assertEquals(3.2, ret);
    }
"
"    @Test
    public void testNaturalNumber() throws Exception {
        Object ret = reader.read(""123"");
        assertNotNull(ret);
        assertEquals(Long.class, ret.getClass());
        assertEquals(123L, ret);
    }
"
"    @Test
    public void testWrite() throws Exception {
        Bean bean1=new Bean();
        bean1.setStringField(""str"");
        bean1.setBooleanField(true);
        bean1.setCharField('s');
        bean1.setDoubleField(10.1);
        bean1.setFloatField(1.5f);
        bean1.setIntField(10);
        bean1.setLongField(100);
        bean1.setEnumField(AnEnum.ValueA);
        bean1.setEnumBean(AnEnumBean.Two);

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);
        String json = jsonWriter.write(bean1);
        TestUtils.assertEquals(DefaultJSONWriter.class.getResource(""jsonwriter-write-bean-01.txt""), json);
    }
"
"    @Test
    public void testWriteExcludeNull() throws Exception {
        BeanWithMap bean1=new BeanWithMap();
        bean1.setStringField(""str"");
        bean1.setBooleanField(true);
        bean1.setCharField('s');
        bean1.setDoubleField(10.1);
        bean1.setFloatField(1.5f);
        bean1.setIntField(10);
        bean1.setLongField(100);
        bean1.setEnumField(AnEnum.ValueA);
        bean1.setEnumBean(AnEnumBean.Two);

        Map m = new LinkedHashMap();
        m.put(""a"", ""x"");
        m.put(""b"", null);
        m.put(""c"", ""z"");
        bean1.setMap(m);

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);
        jsonWriter.setIgnoreHierarchy(false);
        String json = jsonWriter.write(bean1, null, null, true);
        TestUtils.assertEquals(DefaultJSONWriter.class.getResource(""jsonwriter-write-bean-03.txt""), json);
    }
"
"    @Test
    public void testWriteAnnotatedBean() throws Exception {
        AnnotatedBean bean1=new AnnotatedBean();
        bean1.setStringField(""str"");
        bean1.setBooleanField(true);
        bean1.setCharField('s');
        bean1.setDoubleField(10.1);
        bean1.setFloatField(1.5f);
        bean1.setIntField(10);
        bean1.setLongField(100);
        bean1.setEnumField(AnEnum.ValueA);
        bean1.setEnumBean(AnEnumBean.Two);
        bean1.setUrl(new URL(""http://www.google.com""));

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);
        jsonWriter.setIgnoreHierarchy(false);
        String json = jsonWriter.write(bean1);
        TestUtils.assertEquals(DefaultJSONWriter.class.getResource(""jsonwriter-write-bean-02.txt""), json);
    }
"
"    @Test
    public void testWriteBeanWithList() throws Exception {
        BeanWithList bean1 = new BeanWithList();
        bean1.setStringField(""str"");
        bean1.setBooleanField(true);
        bean1.setCharField('s');
        bean1.setDoubleField(10.1);
        bean1.setFloatField(1.5f);
        bean1.setIntField(10);
        bean1.setLongField(100);
        bean1.setEnumField(AnEnum.ValueA);
        bean1.setEnumBean(AnEnumBean.Two);
        List<String> errors = new ArrayList<String>();
        errors.add(""Field is required"");
        bean1.setErrors(errors);

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);
        jsonWriter.setIgnoreHierarchy(false);
        String json = jsonWriter.write(bean1);
        TestUtils.assertEquals(DefaultJSONWriter.class.getResource(""jsonwriter-write-bean-04.txt""), json);
    }
"
"    @Test
    public void testCanSerializeADate() throws Exception {
        SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss z"");

        SingleDateBean dateBean = new SingleDateBean();
        dateBean.setDate(sdf.parse(""2012-12-23 10:10:10 GMT""));

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);

        TimeZone.setDefault(TimeZone.getTimeZone(""GMT""));
        String json = jsonWriter.write(dateBean);
        assertEquals(""{\""date\"":\""2012-12-23T10:10:10\""}"", json);
    }
"
"    @Test
    public void testCanSetDefaultDateFormat() throws Exception {
        SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss z"");

        SingleDateBean dateBean = new SingleDateBean();
        dateBean.setDate(sdf.parse(""2012-12-23 10:10:10 GMT""));

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);
        jsonWriter.setDateFormatter(""MM-dd-yyyy"");
        String json = jsonWriter.write(dateBean);
        assertEquals(""{\""date\"":\""12-23-2012\""}"", json);
    }
"
"            // @Test(expected = JSONException.class)
        }
    }
"
"            // @Test(expected = JSONException.class)
    public void testSMDDisabledSMD() throws Exception {
        // request
        setRequestContent(""smd-3.txt"");
        this.request.addHeader(""Content-Type"", ""application/json-rpc"");

        JSONInterceptor interceptor = new JSONInterceptor();
        JSONUtil jsonUtil = new JSONUtil();
        jsonUtil.setWriter(new DefaultJSONWriter());
        interceptor.setJsonUtil(jsonUtil);
        SMDActionTest1 action = new SMDActionTest1();

        this.invocation.setAction(action);

        // SMD was not enabled so invocation must happen
        try {
            interceptor.intercept(this.invocation);
        } catch (JSONException e) {
            fail(""Should have not thrown an exception"");
        }

    }
"
"	@Test
	public void testSanitizeInputPathShouldAllowSimpleParameter() throws Exception {
		assertEquals(""foo"", fileDownloadAction.sanitizeInputPath(""foo""));
	}
"
"	@Test
	public void testSanitizeInputPathShouldReturnNullForNullInput() throws Exception {
		assertNull(fileDownloadAction.sanitizeInputPath(null));
	}
"
"	@Test
	public void testSanitizeInputPathShouldReturnNullForLeadingWebInf() throws Exception {
		assertNull(fileDownloadAction.sanitizeInputPath(""WEB-INF/foo""));
	}
"
"	@Test
	public void testSanitizeInputPathShouldReturnNullForNonLeadingWebInf() throws Exception {
		assertNull(fileDownloadAction.sanitizeInputPath(""./WEB-INF/foo""));
	}
"
"	@Test
	public void testSanitizeInputPathShouldReturnNullForNonUppercaseWebInf() throws Exception {
		assertNull(fileDownloadAction.sanitizeInputPath(""./wEB-Inf/foo""));
	}
"
"    @Test
    public void enable() {
        terminal.expectCommand(""systemctl --quiet is-enabled docker 2>&1"", 1, """")
                .expectCommand(""systemctl enable docker 2>&1"")
                .expectCommand(""systemctl --quiet is-enabled docker 2>&1"");

        SystemCtl.SystemCtlEnable enableDockerService = new SystemCtl(terminal).enable(""docker"");
        assertTrue(enableDockerService.converge(taskContext));
        assertFalse(""Already converged"", enableDockerService.converge(taskContext));
    }
"
"    @Test
    public void enableCommandFailure() {
        terminal.expectCommand(""systemctl --quiet is-enabled docker 2>&1"", 1, """")
                .expectCommand(""systemctl enable docker 2>&1"", 1, ""error enabling service"");
        SystemCtl.SystemCtlEnable enableDockerService = new SystemCtl(terminal).enable(""docker"");
        try {
            enableDockerService.converge(taskContext);
            fail();
        } catch (ChildProcessFailureException e) {
            // success
        }
    }
"
"    @Test
    public void start() {
        terminal.expectCommand(
                        ""systemctl show docker 2>&1"",
                        0,
                        ""a=b\n"" +
                                ""ActiveState=failed\n"" +
                                ""bar=zoo\n"")
                .expectCommand(""systemctl start docker 2>&1"", 0, """");

        SystemCtl.SystemCtlStart startDockerService = new SystemCtl(terminal).start(""docker"");
        assertTrue(startDockerService.converge(taskContext));
    }
"
"    @Test
    public void startIsNoop() {
        terminal.expectCommand(
                        ""systemctl show docker 2>&1"",
                        0,
                        ""a=b\n"" +
                                ""ActiveState=active\n"" +
                                ""bar=zoo\n"")
                .expectCommand(""systemctl start docker 2>&1"", 0, """");

        SystemCtl.SystemCtlStart startDockerService = new SystemCtl(terminal).start(""docker"");
        assertFalse(startDockerService.converge(taskContext));
    }
"
"    @Test
    public void startCommandFailre() {
        terminal.expectCommand(""systemctl show docker 2>&1"", 1, ""error"");
        SystemCtl.SystemCtlStart startDockerService = new SystemCtl(terminal).start(""docker"");
        try {
            startDockerService.converge(taskContext);
            fail();
        } catch (ChildProcessFailureException e) {
            // success
        }
    }
"
"    @Test
    public void disable() {
        terminal.expectCommand(""systemctl --quiet is-enabled docker 2>&1"")
                .expectCommand(""systemctl disable docker 2>&1"")
                .expectCommand(""systemctl --quiet is-enabled docker 2>&1"", 1, """");

        assertTrue(new SystemCtl(terminal).disable(""docker"").converge(taskContext));
        assertFalse(""Already converged"", new SystemCtl(terminal).disable(""docker"").converge(taskContext));
    }
"
"    @Test
    public void stop() {
        terminal.expectCommand(
                        ""systemctl show docker 2>&1"",
                        0,
                        ""a=b\n"" +
                                ""ActiveState=active\n"" +
                                ""bar=zoo\n"")
                .expectCommand(""systemctl stop docker 2>&1"", 0, """");

        assertTrue(new SystemCtl(terminal).stop(""docker"").converge(taskContext));
    }
"
"    @Test
    public void restart() {
        terminal.expectCommand(""systemctl restart docker 2>&1"", 0, """");
        assertTrue(new SystemCtl(terminal).restart(""docker"").converge(taskContext));
    }
"
"    @Test
    public void testUnitExists() {
        SystemCtl systemCtl = new SystemCtl(terminal);

        terminal.expectCommand(""systemctl list-unit-files foo.service 2>&1"", 0,
                ""UNIT FILE STATE\n"" +
                        ""\n"" +
                        ""0 unit files listed.\n"");
        assertFalse(systemCtl.serviceExists(taskContext, ""foo""));

        terminal.expectCommand(""systemctl list-unit-files foo.service 2>&1"", 0,
                ""UNIT FILE           STATE  \n"" +
                        ""foo.service enabled\n"" +
                        ""\n"" +
                        ""1 unit files listed.\n"");
        assertTrue(systemCtl.serviceExists(taskContext, ""foo""));

        terminal.expectCommand(""systemctl list-unit-files foo.service 2>&1"", 0, ""garbage"");
        try {
            systemCtl.serviceExists(taskContext, ""foo"");
            fail();
        } catch (Exception e) {
            assertThat(e.getMessage(), containsString(""garbage""));
        }
    }
"
"    @Test
    public void withSudo() {
        SystemCtl systemCtl = new SystemCtl(terminal).withSudo();
        terminal.expectCommand(""sudo systemctl restart docker 2>&1"", 0, """");
        assertTrue(systemCtl.restart(""docker"").converge(taskContext));
    }
"
"    @Test
    public void return_expectations() {
        assertSystemCtlMethod(sct -> sct.expectEnable(unit), sc -> sc.enable(unit).converge(context));
        assertSystemCtlMethod(sct -> sct.expectDisable(unit), sc -> sc.disable(unit).converge(context));
        assertSystemCtlMethod(sct -> sct.expectStart(unit), sc -> sc.start(unit).converge(context));
        assertSystemCtlMethod(sct -> sct.expectStop(unit), sc -> sc.stop(unit).converge(context));
        assertSystemCtlMethod(sct -> sct.expectServiceExists(unit), sc -> sc.serviceExists(context, unit));
        assertSystemCtlMethod(sct -> sct.expectIsActive(unit), sc -> sc.isActive(context, unit));
    }
"
"    @Test
    public void void_tests() {
        systemCtl.expectRestart(unit);
        systemCtl.restart(unit).converge(context);
        terminal.verifyAllCommandsExecuted();

        systemCtl.expectDaemonReload();
        systemCtl.daemonReload(context);
        terminal.verifyAllCommandsExecuted();
    }
"
"    @Test
    public void testSpawn() {
        CommandLine commandLine = mock(CommandLine.class);
        when(commandLine.getArguments()).thenReturn(List.of(""program""));
        when(commandLine.getRedirectStderrToStdoutInsteadOfDiscard()).thenReturn(true);
        when(commandLine.programName()).thenReturn(""program"");
        Path outputPath;
        try (ChildProcess2Impl child = processFactory.spawn(commandLine)) {
            outputPath = child.getOutputPath();
            assertTrue(Files.exists(outputPath));
            assertEquals(""rw-------"", new UnixPath(outputPath).getPermissions());
            ArgumentCaptor<ProcessBuilder> processBuilderCaptor =
                    ArgumentCaptor.forClass(ProcessBuilder.class);
            verify(starter).start(processBuilderCaptor.capture());
            ProcessBuilder processBuilder = processBuilderCaptor.getValue();
            assertTrue(processBuilder.redirectErrorStream());
            ProcessBuilder.Redirect redirect = processBuilder.redirectOutput();
            assertEquals(ProcessBuilder.Redirect.Type.WRITE, redirect.type());
            assertEquals(outputPath.toFile(), redirect.file());
        }

        assertFalse(Files.exists(outputPath));
    }
"
"    @Test
    public void testSpawnWithPersistentOutputFile() {

        class TemporaryFile implements AutoCloseable {
            private final Path path;
            private TemporaryFile() {
                String outputFileName = ProcessFactoryImplTest.class.getSimpleName() + ""-temporary-test-file.out"";
                FileAttribute<Set<PosixFilePermission>> fileAttribute = PosixFilePermissions.asFileAttribute(
                        PosixFilePermissions.fromString(""rw-------""));
                path = uncheck(() -> Files.createTempFile(outputFileName, "".out"", fileAttribute));
            }
            @Override public void close() { uncheck(() -> Files.deleteIfExists(path)); }
        }

        try (TemporaryFile outputPath = new TemporaryFile()) {
"
"    @Test
    public void testStrings() {
        terminal.expectCommand(
                ""/bin/bash \""with space\"" \""speci&l\"" \""\"" \""double\\\""quote\"" 2>&1"",
                0,
                """");
        commandLine.add(""/bin/bash"", ""with space"", ""speci&l"", """", ""double\""quote"").execute();
        assertEquals(""bash"", commandLine.programName());
    }
"
"    @Test
    public void testBasicExecute() {
        terminal.expectCommand(""foo bar 2>&1"", 0, ""line1\nline2\n\n"");
        CommandResult result = commandLine.add(""foo"", ""bar"").execute();
        assertEquals(0, result.getExitCode());
        assertEquals(""line1\nline2"", result.getOutput());
        assertEquals(""line1\nline2\n\n"", result.getUntrimmedOutput());
        assertEquals(List.of(""line1"", ""line2""), result.getOutputLines());
        assertEquals(1, context.getSystemModificationLog().size());
        assertEquals(""Executing command: foo bar 2>&1"", context.getSystemModificationLog().get(0));

        List<CommandLine> commandLines = terminal.getTestProcessFactory().getMutableCommandLines();
        assertEquals(1, commandLines.size());
        assertTrue(commandLine == commandLines.get(0));

        int lines = result.map(r -> r.getOutputLines().size());
        assertEquals(2, lines);
    }
"
"    @Test
    public void verifyDefaults() {
        assertEquals(CommandLine.DEFAULT_TIMEOUT, commandLine.getTimeout());
        assertEquals(CommandLine.DEFAULT_MAX_OUTPUT_BYTES, commandLine.getMaxOutputBytes());
        assertEquals(CommandLine.DEFAULT_SIGTERM_GRACE_PERIOD, commandLine.getSigTermGracePeriod());
        assertEquals(CommandLine.DEFAULT_SIGKILL_GRACE_PERIOD, commandLine.getSigKillGracePeriod());
        assertEquals(0, commandLine.getArguments().size());
        assertEquals(Optional.empty(), commandLine.getOutputFile());
        assertEquals(StandardCharsets.UTF_8, commandLine.getOutputEncoding());
        assertTrue(commandLine.getRedirectStderrToStdoutInsteadOfDiscard());
        Predicate<Integer> defaultExitCodePredicate = commandLine.getSuccessfulExitCodePredicate();
        assertTrue(defaultExitCodePredicate.test(0));
        assertFalse(defaultExitCodePredicate.test(1));
    }
"
"    @Test
    public void executeSilently() {
        terminal.ignoreCommand("""");
        commandLine.add(""foo"", ""bar"").executeSilently();
        assertEquals(0, context.getSystemModificationLog().size());
        commandLine.recordSilentExecutionAsSystemModification();
        assertEquals(1, context.getSystemModificationLog().size());
        assertEquals(""Executed command: foo bar 2>&1"", context.getSystemModificationLog().get(0));
    }
"
"    @Test(expected = NegativeArraySizeException.class)
    public void processFactorySpawnFails() {
        terminal.interceptCommand(
                        commandLine.toString(),
                        command -> { throw new NegativeArraySizeException(); });
        commandLine.add(""foo"").execute();
    }
"
"    @Test
    public void waitingForTerminationExceptionStillClosesChild() {
        TestChildProcess2 child = new TestChildProcess2(0, """");
        child.throwInWaitForTermination(new NegativeArraySizeException());
        terminal.interceptCommand(commandLine.toString(), command -> child);
        assertFalse(child.closeCalled());
        try {
            commandLine.add(""foo"").execute();
            fail();
        } catch (NegativeArraySizeException e) {
            // OK
        }

        assertTrue(child.closeCalled());
    }
"
"    @Test
    public void programFails() {
        terminal.expectCommand(""foo 2>&1"", 1, """");
        try {
            commandLine.add(""foo"").execute();
            fail();
        } catch (ChildProcessFailureException e) {
            assertEquals(
                    ""Command 'foo 2>&1' terminated with exit code 1: stdout/stderr: ''"",
                    e.getMessage());
        }
    }
"
"    @Test
    public void mapException() {
        terminal.ignoreCommand(""output"");
        CommandResult result = terminal.newCommandLine(context).add(""program"").execute();
        IllegalArgumentException exception = new IllegalArgumentException(""foo"");
        try {
            result.mapOutput(output -> { throw exception; });
            fail();
        } catch (UnexpectedOutputException e) {
            assertEquals(""Command 'program 2>&1' output was not of the expected format: "" +
                    ""Failed to map output: stdout/stderr: 'output'"", e.getMessage());
            assertTrue(e.getCause() == exception);
        }
    }
"
"    @Test
    public void testMapEachLine() {
        assertEquals(
                1 + 2 + 3,
                terminal.ignoreCommand(""1\n2\n3\n"")
                        .newCommandLine(context)
                        .add(""foo"")
                        .execute()
                        .mapEachLine(Integer::valueOf)
                        .stream()
                        .mapToInt(i -> i)
                        .sum());
    }
"
"    @Test
    public void addTokensWithMultipleWhiteSpaces() {
        terminal.expectCommand(""iptables -L 2>&1"");
        commandLine.addTokens(""iptables  -L"").execute();

        terminal.verifyAllCommandsExecuted();
    }
"
"    @Test
    public void addTokensWithSpecialCharacters() {
        terminal.expectCommand(""find . ! -name hei 2>&1"");
        commandLine.addTokens(""find . ! -name hei"").execute();

        terminal.verifyAllCommandsExecuted();
    }
"
"    @Test
    public void testSuccess() throws Exception {
        when(commandLine.getTimeout()).thenReturn(Duration.ofHours(1));
        when(commandLine.getMaxOutputBytes()).thenReturn(10L);
        when(commandLine.getOutputEncoding()).thenReturn(StandardCharsets.UTF_8);
        when(commandLine.getSigTermGracePeriod()).thenReturn(Duration.ofMinutes(2));
        when(commandLine.getSigKillGracePeriod()).thenReturn(Duration.ofMinutes(3));
        when(commandLine.toString()).thenReturn(""program arg"");

        when(timer.currentTime()).thenReturn(
                Instant.ofEpochMilli(1),
                Instant.ofEpochMilli(2));

        when(processApi.waitFor(anyLong(), any())).thenReturn(true);

        try (ChildProcess2Impl child =
                     new ChildProcess2Impl(commandLine, processApi, temporaryFile, timer)) {
            child.waitForTermination();
        }
    }
"
"    @Test
    public void testTimeout() throws Exception {
        when(commandLine.getTimeout()).thenReturn(Duration.ofSeconds(1));
        when(commandLine.getMaxOutputBytes()).thenReturn(10L);
        when(commandLine.getOutputEncoding()).thenReturn(StandardCharsets.UTF_8);
        when(commandLine.getSigTermGracePeriod()).thenReturn(Duration.ofMinutes(2));
        when(commandLine.getSigKillGracePeriod()).thenReturn(Duration.ofMinutes(3));
        when(commandLine.toString()).thenReturn(""program arg"");

        when(timer.currentTime()).thenReturn(
                Instant.ofEpochSecond(0),
                Instant.ofEpochSecond(2));

        when(processApi.waitFor(anyLong(), any())).thenReturn(true);

        try (ChildProcess2Impl child =
                     new ChildProcess2Impl(commandLine, processApi, temporaryFile, timer)) {
            try {
                child.waitForTermination();
                fail();
            } catch (TimeoutChildProcessException e) {
                assertEquals(
                        ""Command 'program arg' timed out after PT1S: stdout/stderr: ''"",
                        e.getMessage());
            }
        }
    }
"
"    @Test
    public void testMaxOutputBytes() throws Exception {
        when(commandLine.getTimeout()).thenReturn(Duration.ofSeconds(1));
        when(commandLine.getMaxOutputBytes()).thenReturn(10L);
        when(commandLine.getOutputEncoding()).thenReturn(StandardCharsets.UTF_8);
        when(commandLine.getSigTermGracePeriod()).thenReturn(Duration.ofMinutes(2));
        when(commandLine.getSigKillGracePeriod()).thenReturn(Duration.ofMinutes(3));
        when(commandLine.toString()).thenReturn(""program arg"");

        when(timer.currentTime()).thenReturn(
                Instant.ofEpochMilli(0),
                Instant.ofEpochMilli(1));

        when(processApi.waitFor(anyLong(), any())).thenReturn(true);

        Files.write(temporaryFile, ""1234567890123"".getBytes(StandardCharsets.UTF_8));

        try (ChildProcess2Impl child =
                     new ChildProcess2Impl(commandLine, processApi, temporaryFile, timer)) {
            try {
                child.waitForTermination();
                fail();
            } catch (LargeOutputChildProcessException e) {
                assertEquals(
                        ""Command 'program arg' output more than 13 bytes: stdout/stderr: '1234567890123'"",
                        e.getMessage());
            }
        }
    }
"
"    @Test
    public void testUnkillable() throws Exception {
        when(commandLine.getTimeout()).thenReturn(Duration.ofSeconds(1));
        when(commandLine.getMaxOutputBytes()).thenReturn(10L);
        when(commandLine.getOutputEncoding()).thenReturn(StandardCharsets.UTF_8);
        when(commandLine.getSigTermGracePeriod()).thenReturn(Duration.ofMinutes(2));
        when(commandLine.getSigKillGracePeriod()).thenReturn(Duration.ofMinutes(3));
        when(commandLine.toString()).thenReturn(""program arg"");

        when(timer.currentTime()).thenReturn(
                Instant.ofEpochMilli(0),
                Instant.ofEpochMilli(1));

        when(processApi.waitFor(anyLong(), any())).thenReturn(false);

        Files.write(temporaryFile, ""1234567890123"".getBytes(StandardCharsets.UTF_8));

        try (ChildProcess2Impl child =
                     new ChildProcess2Impl(commandLine, processApi, temporaryFile, timer)) {
            try {
                child.waitForTermination();
                fail();
            } catch (UnkillableChildProcessException e) {
                assertEquals(
                        ""Command 'program arg' did not terminate even after SIGTERM, +PT2M, SIGKILL, and +PT3M: stdout/stderr: '1234567890123'"",
                        e.getMessage());
            }
        }
    }
"
"    @Test
    public void bytes_to_display_count_test() {
        assertEquals(""-1 bytes"", DiskSize.of(-1).asString());
        assertEquals(""123 bytes"", DiskSize.of(123).asString());
        assertEquals(""1 kB"", DiskSize.of(1_000).asString());
        assertEquals(""15 MB"", DiskSize.of(15_000_000).asString());
        assertEquals(""123 GB"", DiskSize.of(123_456_789_012L).asString());
        assertEquals(""988 TB"", DiskSize.of(987_654_321_098_765L).asString());
        assertEquals(""987.7 TB"", DiskSize.of(987_654_321_098_765L).asString(1));
        assertEquals(""987.65 TB"", DiskSize.of(987_654_321_098_765L).asString(2));
        assertEquals(""2 PB"", DiskSize.of(2_000_000_000_000_000L).asString());
        assertEquals(""9 EB"", DiskSize.of(Long.MAX_VALUE).asString());
    }
"
"    @Test
    public void newDirectory() {
        verifySystemModifications(
                ""Creating directory "" + path,
                ""Changing owner of /parent/dir from user to test-owner"",
                ""Changing group of /parent/dir from group to test-group"");

        owner = ""new-owner"";
        verifySystemModifications(""Changing owner of /parent/dir from test-owner to new-owner"");

        group = ""new-group"";
        verifySystemModifications(""Changing group of /parent/dir from test-group to new-group"");

        permissions = ""--x---r--"";
        verifySystemModifications(""Changing permissions of /parent/dir from rwxr----x to --x---r--"");
    }
"
"    @Test
    public void exceptionIfMissingParent() {
        String path = ""/parent/dir"";
        MakeDirectory makeDirectory = new MakeDirectory(fileSystem.getPath(path));

        try {
            makeDirectory.converge(context);
        } catch (UncheckedIOException e) {
            if (e.getCause() instanceof NoSuchFileException) {
                return;
            }
            throw e;
        }
        fail();
    }
"
"    @Test
    public void okIfParentExists() {
        String path = ""/dir"";
        MakeDirectory makeDirectory = new MakeDirectory(fileSystem.getPath(path));
        assertTrue(makeDirectory.converge(context));
        assertTrue(Files.isDirectory(fileSystem.getPath(path)));

        MakeDirectory makeDirectory2 = new MakeDirectory(fileSystem.getPath(path));
        assertFalse(makeDirectory2.converge(context));
    }
"
"    @Test
    public void storedBoolean() {
        assertFalse(storedBoolean.value());
        storedBoolean.set(context);
        assertTrue(storedBoolean.value());
        storedBoolean.clear(context);
        assertFalse(storedBoolean.value());
    }
"
"    @Test
    public void testCompatibility() throws IOException {
        StoredInteger storedInteger = new StoredInteger(path);
        assertFalse(storedBoolean.value());

        storedInteger.write(context, 1);
        assertTrue(storedBoolean.value());

        storedInteger.write(context, 2);
        assertTrue(storedBoolean.value());

        storedInteger.write(context, 0);
        assertFalse(storedBoolean.value());

        Files.delete(path);
        assertFalse(storedBoolean.value());
    }
"
"    @Test
    public void fileDoesNotExist() {
        assertFalse(fileSnapshot.exists());
        assertFalse(fileSnapshot.attributes().isPresent());
        assertFalse(fileSnapshot.content().isPresent());
        assertEquals(path.toPath(), fileSnapshot.path());
    }
"
"    @Test
    public void directory() {
        path.createParents().createDirectory();
        fileSnapshot = fileSnapshot.snapshot();
        assertTrue(fileSnapshot.exists());
        assertTrue(fileSnapshot.attributes().isPresent());
        assertTrue(fileSnapshot.attributes().get().isDirectory());
    }
"
"    @Test
    public void regularFile() {
        path.createParents().writeUtf8File(""file content"");
        fileSnapshot = fileSnapshot.snapshot();
        assertTrue(fileSnapshot.exists());
        assertTrue(fileSnapshot.attributes().isPresent());
        assertTrue(fileSnapshot.attributes().get().isRegularFile());
        assertTrue(fileSnapshot.utf8Content().isPresent());
        assertEquals(""file content"", fileSnapshot.utf8Content().get());

        FileSnapshot newFileSnapshot = fileSnapshot.snapshot();
        assertSame(fileSnapshot, newFileSnapshot);
    }
"
"    @Test
    public void fileRemoval() {
        path.createParents().writeUtf8File(""file content"");
        fileSnapshot = fileSnapshot.snapshot();
        assertTrue(fileSnapshot.exists());
        path.deleteIfExists();
        fileSnapshot = fileSnapshot.snapshot();
        assertFalse(fileSnapshot.exists());
    }
"
"    @Test
    public void testEdit() {
        path.writeUtf8File(joinLines(""first"", ""second"", ""third""));

        LineEditor lineEditor = mock(LineEditor.class);
        when(lineEditor.edit(any())).thenReturn(
                LineEdit.none(), // don't edit the first line
                LineEdit.remove(), // remove the second
                LineEdit.replaceWith(""replacement"")); // replace the third

        Editor editor = new Editor(path.toPath(), lineEditor);
        TaskContext context = mock(TaskContext.class);

        assertTrue(editor.converge(context));

        verify(lineEditor, times(3)).edit(any());

        // Verify the system modification message
        ArgumentCaptor<String> modificationMessage = ArgumentCaptor.forClass(String.class);
        verify(context).recordSystemModification(any(), modificationMessage.capture());
        assertEquals(
                ""Patching file /file:\n-second\n-third\n+replacement\n"",
                modificationMessage.getValue());

        // Verify the new contents of the file:
        assertEquals(joinLines(""first"", ""replacement""), path.readUtf8File());
    }
"
"    @Test
    public void testInsert() {
        path.writeUtf8File(joinLines(""second"", ""eight"", ""fifth"", ""seventh""));

        LineEditor lineEditor = mock(LineEditor.class);
        when(lineEditor.edit(any())).thenReturn(
                LineEdit.insertBefore(""first""), // insert first, and keep the second line
                LineEdit.replaceWith(""third"", ""fourth""), // remove eight, and replace with third and fourth instead
                LineEdit.none(), // Keep fifth
                LineEdit.insert(List.of(""sixth""), // insert sixth before seventh
                        List.of(""eight""))); // add eight after seventh

        Editor editor = new Editor(path.toPath(), lineEditor);
        TaskContext context = mock(TaskContext.class);

        assertTrue(editor.converge(context));

        // Verify the system modification message
        ArgumentCaptor<String> modificationMessage = ArgumentCaptor.forClass(String.class);
        verify(context).recordSystemModification(any(), modificationMessage.capture());
        assertEquals(
                ""Patching file /file:\n"" +
                        ""+first\n"" +
                        ""-eight\n"" +
                        ""+third\n"" +
                        ""+fourth\n"" +
                        ""+sixth\n"" +
                        ""+eight\n"",
                modificationMessage.getValue());

        // Verify the new contents of the file:
        assertEquals(joinLines(""first"", ""second"", ""third"", ""fourth"", ""fifth"", ""sixth"", ""seventh"", ""eight""),
                path.readUtf8File());
    }
"
"    @Test
    public void noop() {
        path.writeUtf8File(""line\n"");

        LineEditor lineEditor = mock(LineEditor.class);
        when(lineEditor.edit(any())).thenReturn(LineEdit.none());

        Editor editor = new Editor(path.toPath(), lineEditor);
        TaskContext context = mock(TaskContext.class);

        assertFalse(editor.converge(context));

        verify(lineEditor, times(1)).edit(any());

        // Verify the system modification message
        verify(context, times(0)).recordSystemModification(any(), any());

        // Verify same contents
        assertEquals(""line\n"", path.readUtf8File());
    }
"
"    @Test
    public void testMissingFile() {
        LineEditor lineEditor = mock(LineEditor.class);
        when(lineEditor.onComplete()).thenReturn(List.of(""line""));

        TaskContext context = mock(TaskContext.class);
        var editor = new Editor(path.toPath(), lineEditor);
        editor.converge(context);

        assertEquals(""line\n"", path.readUtf8File());
    }
"
"    @Test
    public void trivial() {
        assertConvergence(""Creating file /dir/file.txt"",
                ""Changing owner of /dir/file.txt from user to owner"",
                ""Changing group of /dir/file.txt from group to group1"",
                ""Changing permissions of /dir/file.txt from rw-r--r-- to rw-r-xr--"");

        content = ""new-content"";
        assertConvergence(""Patching file /dir/file.txt"");

        owner = ""new-owner"";
        assertConvergence(""Changing owner of /dir/file.txt from owner to "" +
                        owner);

        group = ""new-group1"";
        assertConvergence(""Changing group of /dir/file.txt from group1 to new-group1"");

        permissions = ""rwxr--rwx"";
        assertConvergence(""Changing permissions of /dir/file.txt from rw-r-xr-- to "" +
                permissions);
    }
"
"        @Test
        public void all_files_non_recursive() {
            assertFileHelper(FileFinder.files(testRoot())
                            .maxDepth(1),

                    of(""file-1.json"", ""test.json"", ""test.txt""),
                    of(""test"", ""test/file.txt"", ""test/data.json"", ""test/subdir-1"", ""test/subdir-1/test"", ""test/subdir-2""));
        }
"
"        @Test
        public void all_files_recursive() {
            assertFileHelper(FileFinder.files(testRoot()),

                    of(""file-1.json"", ""test.json"", ""test.txt"", ""test/file.txt"", ""test/data.json"", ""test/subdir-1/test""),
                    of(""test"", ""test/subdir-1"", ""test/subdir-2""));
        }
"
"        @Test
        public void all_files_recursive_with_prune_relative() {
            assertFileHelper(FileFinder.files(testRoot()).prune(fileSystem.getPath(""test"")),

                    of(""file-1.json"", ""test.json"", ""test.txt""),
                    of(""test"", ""test/file.txt"", ""test/data.json"", ""test/subdir-1"", ""test/subdir-1/test"", ""test/subdir-2""));
        }
"
"        @Test
        public void all_files_recursive_with_prune_absolute() {
            assertFileHelper(FileFinder.files(testRoot()).prune(testRoot().resolve(""test/subdir-1"")),

                    of(""file-1.json"", ""test.json"", ""test.txt"", ""test/file.txt"", ""test/data.json""),
                    of(""test"", ""test/subdir-1"", ""test/subdir-1/test"", ""test/subdir-2""));
        }
"
"        @Test(expected = IllegalArgumentException.class)
        public void throws_if_prune_path_not_under_base_path() {
            FileFinder.files(Paths.get(""/some/path"")).prune(Paths.get(""/other/path""));
        }
"
"        @Test
        public void with_file_filter_recursive() {
            assertFileHelper(FileFinder.files(testRoot())
                            .match(FileFinder.nameEndsWith("".json"")),

                    of(""file-1.json"", ""test.json"", ""test/data.json""),
                    of(""test.txt"", ""test"", ""test/file.txt"", ""test/subdir-1"", ""test/subdir-1/test"", ""test/subdir-2""));
        }
"
"        @Test
        public void all_files_limited_depth() {
            assertFileHelper(FileFinder.files(testRoot())
                            .maxDepth(2),

                    of(""test.txt"", ""file-1.json"", ""test.json"", ""test/file.txt"", ""test/data.json""),
                    of(""test"", ""test/subdir-1"", ""test/subdir-1/test"", ""test/subdir-2""));
        }
"
"        @Test
        public void directory_with_filter() {
            assertFileHelper(FileFinder.directories(testRoot())
                            .match(FileFinder.nameStartsWith(""subdir""))
                            .maxDepth(2),

                    of(""test/subdir-1"", ""test/subdir-2""),
                    of(""file-1.json"", ""test.json"", ""test.txt"", ""test"", ""test/file.txt"", ""test/data.json""));
        }
"
"        @Test
        public void match_file_and_directory_with_same_name() {
            assertFileHelper(FileFinder.from(testRoot())
                            .match(FileFinder.nameEndsWith(""test"")),

                    of(""test"", ""test/subdir-1/test""),
                    of(""file-1.json"", ""test.json"", ""test.txt""));
        }
"
"        @Test
        public void all_contents() {
            assertFileHelper(FileFinder.from(testRoot())
                            .maxDepth(1),

                    of(""file-1.json"", ""test.json"", ""test.txt"", ""test""),
                    of());

            assertTrue(Files.exists(testRoot()));
        }
"
"        @Test
        public void age_filter_test() {
            Path path = Paths.get(""/my/fake/path"");
            when(attributes.lastModifiedTime()).thenReturn(FileTime.from(Instant.now().minus(Duration.ofHours(1))));
            FileFinder.FileAttributes fileAttributes = new FileFinder.FileAttributes(path, attributes);

            assertFalse(FileFinder.olderThan(Duration.ofMinutes(61)).test(fileAttributes));
            assertTrue(FileFinder.olderThan(Duration.ofMinutes(59)).test(fileAttributes));

            assertTrue(FileFinder.youngerThan(Duration.ofMinutes(61)).test(fileAttributes));
            assertFalse(FileFinder.youngerThan(Duration.ofMinutes(59)).test(fileAttributes));
        }
"
"        @Test
        public void size_filters() {
            Path path = Paths.get(""/my/fake/path"");
            when(attributes.size()).thenReturn(100L);
            FileFinder.FileAttributes fileAttributes = new FileFinder.FileAttributes(path, attributes);

            assertFalse(FileFinder.largerThan(101).test(fileAttributes));
            assertTrue(FileFinder.largerThan(99).test(fileAttributes));

            assertTrue(FileFinder.smallerThan(101).test(fileAttributes));
            assertFalse(FileFinder.smallerThan(99).test(fileAttributes));
        }
"
"        @Test
        public void filename_filters() {
            Path path = Paths.get(""/my/fake/path/some-12352-file.json"");
            FileFinder.FileAttributes fileAttributes = new FileFinder.FileAttributes(path, attributes);

            assertTrue(FileFinder.nameStartsWith(""some-"").test(fileAttributes));
            assertFalse(FileFinder.nameStartsWith(""som-"").test(fileAttributes));

            assertTrue(FileFinder.nameEndsWith("".json"").test(fileAttributes));
            assertFalse(FileFinder.nameEndsWith(""file"").test(fileAttributes));

            assertTrue(FileFinder.nameMatches(Pattern.compile(""some-[0-9]+-file.json"")).test(fileAttributes));
            assertTrue(FileFinder.nameMatches(Pattern.compile(""^some-[0-9]+-file.json$"")).test(fileAttributes));
            assertFalse(FileFinder.nameMatches(Pattern.compile(""some-[0-9]-file.json"")).test(fileAttributes));
        }
"
"    @Test
    public void test() {
        Templar templar = new Templar(""x y <%= foo %>, some other <%=bar%> text"");
        templar.set(""foo"", ""fidelity"")
                .set(""bar"", ""halimov"")
                .set(""not"", ""used"");

        assertEquals(""x y fidelity, some other halimov text"", templar.resolve());
    }
"
"    @Test
    public void testWrite() {
        final String content = ""content"";
        final String permissions = ""rwxr-xr-x"";
        final String owner = ""owner"";
        final String group = ""group"";

        Path path = fileSystem.getPath(""/opt/vespa/tmp/file.txt"");
        FileWriter writer = new FileWriter(path, () -> content)
                .withPermissions(permissions)
                .withOwner(owner)
                .withGroup(group)
                .onlyIfFileDoesNotAlreadyExist();
        assertTrue(writer.converge(context));
        verify(context, times(1)).recordSystemModification(any(), eq(""Creating file "" + path));

        UnixPath unixPath = new UnixPath(path);
        assertEquals(content, unixPath.readUtf8File());
        assertEquals(permissions, unixPath.getPermissions());
        assertEquals(owner, unixPath.getOwner());
        assertEquals(group, unixPath.getGroup());
        Instant fileTime = unixPath.getLastModifiedTime();

        // Second time is a no-op.
        assertFalse(writer.converge(context));
        assertEquals(fileTime, unixPath.getLastModifiedTime());
    }
"
"    @Test
    public void testAtomicWrite() {
        FileWriter writer = new FileWriter(fileSystem.getPath(""/foo/bar""))
                .atomicWrite(true);

        assertTrue(writer.converge(context, ""content""));

        verify(context).recordSystemModification(any(), eq(""Creating file /foo/bar""));
        assertEquals(""content"", new UnixPath(writer.path()).readUtf8File());
    }
"
"    @Test
    public void deleteExisting() {
        assertFalse(deleter.converge(context));
        path.createParents().writeUtf8File(""bar"");
        assertTrue(deleter.converge(context));
        assertFalse(deleter.converge(context));
    }
"
"    @Test
    public void basic() {
        FileSystem fileSystem = TestFileSystem.create();
        Path templatePath = fileSystem.getPath(""/example.vm"");
        String templateContent = ""a $x, $y b"";
        new UnixPath(templatePath).writeUtf8File(templateContent);

        Path toPath = fileSystem.getPath(""/example"");
        TaskContext taskContext = mock(TaskContext.class);
        boolean converged = Template.at(templatePath)
                .set(""x"", ""foo"")
                .set(""y"", ""bar"")
                .getFileWriterTo(toPath)
                .converge(taskContext);

        assertTrue(converged);

        String actualContent = new UnixPath(toPath).readUtf8File();
        assertEquals(""a foo, bar b"", actualContent);
    }
"
"    @Test
    public void get() {
        when(unixPath.readBytes()).thenReturn(content);
        assertArrayEquals(content, cache.get(Instant.ofEpochMilli(0)));
        verify(unixPath, times(1)).readBytes();
        verifyNoMoreInteractions(unixPath);

        // cache hit
        assertArrayEquals(content, cache.get(Instant.ofEpochMilli(0)));
        verify(unixPath, times(1)).readBytes();
        verifyNoMoreInteractions(unixPath);

        // cache miss
        when(unixPath.readBytes()).thenReturn(newContent);
        assertArrayEquals(newContent, cache.get(Instant.ofEpochMilli(1)));
        verify(unixPath, times(1 + 1)).readBytes();
        verifyNoMoreInteractions(unixPath);

        // cache hit both at times 0 and 1
        assertArrayEquals(newContent, cache.get(Instant.ofEpochMilli(0)));
        verify(unixPath, times(1 + 1)).readBytes();
        verifyNoMoreInteractions(unixPath);
        assertArrayEquals(newContent, cache.get(Instant.ofEpochMilli(1)));
        verify(unixPath, times(1 + 1)).readBytes();
        verifyNoMoreInteractions(unixPath);
    }
"
"    @Test
    public void updateWith() {
        cache.updateWith(content, Instant.ofEpochMilli(2));
        assertArrayEquals(content, cache.get(Instant.ofEpochMilli(2)));
        verifyNoMoreInteractions(unixPath);

        cache.updateWith(newContent, Instant.ofEpochMilli(4));
        assertArrayEquals(newContent, cache.get(Instant.ofEpochMilli(4)));
        verifyNoMoreInteractions(unixPath);
    }
"
"    @Test
    public void createParents() {
        Path parentDirectory = fs.getPath(""/a/b/c"");
        Path filePath = parentDirectory.resolve(""bar"");
        UnixPath path = new UnixPath(filePath);

        assertFalse(Files.exists(fs.getPath(""/a"")));
        path.createParents();
        assertTrue(Files.exists(parentDirectory));
    }
"
"    @Test
    public void utf8File() {
        String original = ""foo\nbar\n"";
        UnixPath path = new UnixPath(fs.getPath(""example.txt""));
        path.writeUtf8File(original);
        String fromFile = path.readUtf8File();
        assertEquals(original, fromFile);
    }
"
"    @Test
    public void permissions() {
        String expectedPermissions = ""rwxr-x---"";
        UnixPath path = new UnixPath(fs.getPath(""file.txt""));
        path.writeUtf8File(""foo"");
        path.setPermissions(expectedPermissions);
        assertEquals(expectedPermissions, path.getPermissions());
    }
"
"    @Test(expected = IllegalArgumentException.class)
    public void badPermissionsString() {
        new UnixPath(fs.getPath(""file.txt"")).setPermissions(""abcdefghi"");
    }
"
"    @Test
    public void owner() {
        Path path = fs.getPath(""file.txt"");
        UnixPath unixPath = new UnixPath(path);
        unixPath.writeUtf8File(""foo"");

        unixPath.setOwner(""owner"");
        assertEquals(""owner"", unixPath.getOwner());

        unixPath.setGroup(""group"");
        assertEquals(""group"", unixPath.getGroup());
    }
"
"    @Test
    public void createDirectoryWithPermissions() {
        Path path = fs.getPath(""dir"");
        UnixPath unixPath = new UnixPath(path);
        String permissions = ""rwxr-xr--"";
        unixPath.createDirectory(permissions);
        assertTrue(unixPath.isDirectory());
        assertEquals(permissions, unixPath.getPermissions());
    }
"
"    @Test
    public void createSymbolicLink() {
        String original = ""foo\nbar\n"";
        UnixPath path = new UnixPath(fs.getPath(""example.txt""));
        path.writeUtf8File(original);
        String fromFile = path.readUtf8File();
        assertEquals(original, fromFile);

        UnixPath link = path.createSymbolicLink(fs.getPath(""link-to-example.txt""));
        assertEquals(original, link.readUtf8File());
    }
"
"    @Test
    public void readBytesIfExists() {
        UnixPath path = new UnixPath(fs.getPath(""example.txt""));
        assertFalse(path.readBytesIfExists().isPresent());
        path.writeBytes(new byte[]{42});
        assertArrayEquals(new byte[]{42}, path.readBytesIfExists().get());
    }
"
"    @Test
    public void deleteRecursively() throws Exception {
        // Create the following file tree:
        //
        // /dir1
        //  |--- dir2
        //      |--- file1
        // /link1 -> /dir1/dir2
        //
        var dir1 = fs.getPath(""/dir1"");
        var dir2 = dir1.resolve(""dir2"");
        var file1 = dir2.resolve(""file1"");
        Files.createDirectories(dir2);
        Files.writeString(file1, ""file1"");
        var link1 = Files.createSymbolicLink(fs.getPath(""/link1""), dir2);

        new UnixPath(link1).deleteRecursively();
        assertTrue(""Deleting "" + link1 + "" recursively does not remove "" + dir2, Files.exists(dir2));
        assertTrue(""Deleting "" + link1 + "" recursively does not remove "" + file1, Files.exists(file1));

        new UnixPath(dir1).deleteRecursively();
        assertFalse(dir1 + "" deleted recursively"", Files.exists(file1));
        assertFalse(dir1 + "" deleted recursively"", Files.exists(dir2));
        assertFalse(dir1 + "" deleted recursively"", Files.exists(dir1));
    }
"
"    @Test
    public void atomicWrite() {
        var path = new UnixPath(fs.getPath(""/dir/foo""));
        path.createParents();
        path.writeUtf8File(""bar"");
        path.atomicWriteUt8(""bar v2"");
        assertEquals(""bar v2"", path.readUtf8File());
    }
"
"    @Test
    public void testParentAndFilename() {
        var absolutePath = new UnixPath(""/foo/bar"");
        assertEquals(""/foo"", absolutePath.getParent().toString());
        assertEquals(""bar"", absolutePath.getFilename());

        var pathWithoutSlash = new UnixPath(""foo"");
        assertRuntimeException(IllegalStateException.class, ""Path has no parent directory: 'foo'"", () -> pathWithoutSlash.getParent());
        assertEquals(""foo"", pathWithoutSlash.getFilename());

        var pathWithSlash = new UnixPath(""/foo"");
        assertEquals(""/"", pathWithSlash.getParent().toString());
        assertEquals(""foo"", pathWithSlash.getFilename());

        assertRuntimeException(IllegalStateException.class, ""Path has no parent directory: '/'"", () -> new UnixPath(""/"").getParent());
        assertRuntimeException(IllegalStateException.class, ""Path has no filename: '/'"", () -> new UnixPath(""/"").getFilename());
    }
"
"    @Test
    public void exists() {
        UnixPath unixPath = mock(UnixPath.class);
        FileAttributesCache cache = new FileAttributesCache(unixPath);

        when(unixPath.getAttributesIfExists()).thenReturn(Optional.empty());
        assertFalse(cache.get().isPresent());
        verify(unixPath, times(1)).getAttributesIfExists();
        verifyNoMoreInteractions(unixPath);

        FileAttributes attributes = mock(FileAttributes.class);
        when(unixPath.getAttributesIfExists()).thenReturn(Optional.of(attributes));
        assertTrue(cache.get().isPresent());
        verify(unixPath, times(1 + 1)).getAttributesIfExists();
        verifyNoMoreInteractions(unixPath);

        assertEquals(attributes, cache.getOrThrow());
        verifyNoMoreInteractions(unixPath);
    }
"
"    @Test
    public void testBasics() {
        assertCursor(0, 0, """");

        cursor.write(""hello"");
        assertCursor(0, 5, ""hello"");

        cursor.write(""one\ntwo"");
        assertCursor(1, 3, ""helloone\ntwo"");

        cursor.deleteAll();
        assertCursor(0, 0, """");

        cursor.moveForward();
        assertCursor(0, 0, """");

        cursor.writeLine(""foo"");
        assertCursor(1, 0, ""foo\n"");

        cursor.writeLines(""one"", ""two"");
        assertCursor(3, 0, ""foo\none\ntwo\n"");

        cursor.deleteBackward();
        assertCursor(2, 3, ""foo\none\ntwo"");

        cursor.deleteBackward(2);
        assertCursor(2, 1, ""foo\none\nt"");

        Mark mark = cursor.createMark();

        cursor.moveToStartOfPreviousLine().moveBackward(2);
        assertCursor(0, 2, ""foo\none\nt"");

        assertEquals(""o\none\nt"", cursor.getTextTo(mark));

        cursor.deleteTo(mark);
        assertCursor(0, 2, ""fo"");

        cursor.deleteBackward(2);
        assertCursor(0, 0, """");

        cursor.writeLines(""one"", ""two"", ""three"").moveToStartOfBuffer();
        assertCursor(0, 0, ""one\ntwo\nthree\n"");

        Pattern pattern = Pattern.compile(""t(.)"");
        Optional<Match> match = cursor.moveForwardToEndOfMatch(pattern);
        assertCursor(1, 2, ""one\ntwo\nthree\n"");
        assertTrue(match.isPresent());
        assertEquals(""tw"", match.get().match());
        assertEquals("""", match.get().prefix());
        assertEquals(""o"", match.get().suffix());
        assertEquals(new Position(1, 0), match.get().startOfMatch());
        assertEquals(new Position(1, 2), match.get().endOfMatch());
        assertEquals(1, match.get().groupCount());
        assertEquals(""w"", match.get().group(1));

        match = cursor.moveForwardToEndOfMatch(pattern);
        assertCursor(2, 2, ""one\ntwo\nthree\n"");
        assertTrue(match.isPresent());
        assertEquals(""th"", match.get().match());
        assertEquals(1, match.get().groupCount());
        assertEquals(""h"", match.get().group(1));

        match = cursor.moveForwardToEndOfMatch(pattern);
        assertCursor(2, 2, ""one\ntwo\nthree\n"");
        assertFalse(match.isPresent());

        assertTrue(cursor.skipBackward(""h""));
        assertCursor(2, 1, ""one\ntwo\nthree\n"");
        assertFalse(cursor.skipBackward(""x""));

        assertTrue(cursor.skipForward(""hre""));
        assertCursor(2, 4, ""one\ntwo\nthree\n"");
        assertFalse(cursor.skipForward(""x""));

        try {
            cursor.moveTo(mark);
            fail();
        } catch (IllegalArgumentException e) {
            // expected
        }

        mark = cursor.createMark();
        cursor.moveToStartOfBuffer();
        assertEquals(new Position(0, 0), cursor.getPosition());
        cursor.moveTo(mark);
        assertEquals(new Position(2, 4), cursor.getPosition());

        cursor.moveTo(1, 2);
        assertCursor(1, 2, ""one\ntwo\nthree\n"");

        cursor.deleteSuffix();
        assertCursor(1, 2, ""one\ntw\nthree\n"");

        cursor.deletePrefix();
        assertCursor(1, 0, ""one\n\nthree\n"");

        cursor.deleteLine();
        assertCursor(1, 0, ""one\nthree\n"");

        cursor.deleteLine();
        assertCursor(1, 0, ""one\n"");

        cursor.deleteLine();
        assertCursor(1, 0, ""one\n"");

        cursor.moveToStartOfBuffer().moveForward().writeNewlineAfter();
        assertCursor(0, 1, ""o\nne\n"");

        cursor.deleteAll().writeLines(""one"", ""two"", ""three"", ""four"");
        cursor.moveToStartOfBuffer().moveToStartOfNextLine();
        assertCursor(1, 0, ""one\ntwo\nthree\nfour\n"");
        Pattern pattern2 = Pattern.compile(""(o)(.)?"");
        int count = cursor.replaceMatches(pattern2, m -> {
            String prefix = m.group(2) == null ? """" : m.group(2);
            return prefix + m.match() + m.group(1);
        });
        assertCursor(3, 5, ""one\ntwoo\nthree\nfuouor\n"");
        assertEquals(2, count);

        cursor.moveToStartOfBuffer().moveToEndOfLine();
        Pattern pattern3 = Pattern.compile(""o"");
        count = cursor.replaceMatches(pattern3, m -> ""a"");
        assertEquals(4, count);
        assertCursor(3, 5, ""one\ntwaa\nthree\nfuauar\n"");
    }
"
"    @Test
    public void testWrite() {
        assertEquals("""", textBuffer.getString());
        assertWrite(2, 0, ""foo\nbar\n"",
                0, 0, ""foo\nbar\n"");

        assertWrite(1, 6, ""fofirst\nsecondo\nbar\n"",
                0, 2, ""first\nsecond"");

        assertWrite(3, 1, ""fofirst\nsecondo\nbar\na"",
                3, 0, ""a"");
        assertWrite(4, 0, ""fofirst\nsecondo\nbar\na\n"",
                3, 1, ""\n"");
    }
"
"    @Test
    public void testDelete() {
        write(0, 0, ""foo\nbar\nzoo\n"");
        delete(0, 2, 2, 1);
        assertEquals(""fooo\n"", textBuffer.getString());

        delete(0, 4, 1, 0);
        assertEquals(""fooo"", textBuffer.getString());

        delete(0, 0, 0, 4);
        assertEquals("""", textBuffer.getString());

        delete(0, 0, 0, 0);
        assertEquals("""", textBuffer.getString());
    }
"
"    @Test
    public void choose_sitelocal_ipv4_over_public() {
        mock.addAddress(""localhost"", ""38.3.4.2"")
                .addAddress(""localhost"", ""10.0.2.2"")
                .addAddress(""localhost"", ""fe80::1"")
                .addAddress(""localhost"", ""2001::1"");

        assertEquals(InetAddresses.forString(""10.0.2.2""), mock.getIPv4Address(""localhost"").get());
    }
"
"    @Test
    public void choose_ipv6_public_over_local() {
        mock.addAddress(""localhost"", ""38.3.4.2"")
                .addAddress(""localhost"", ""10.0.2.2"")
                .addAddress(""localhost"", ""fe80::1"")
                .addAddress(""localhost"", ""2001::1"");

        assertEquals(InetAddresses.forString(""2001::1""), mock.getIPv6Address(""localhost"").get());
    }
"
"    @Test(expected = RuntimeException.class)
    public void throws_when_multiple_ipv6_addresses() {
        mock.addAddress(""localhost"", ""2001::1"")
                .addAddress(""localhost"", ""2001::2"");
        mock.getIPv6Address(""localhost"");
    }
"
"    @Test(expected = RuntimeException.class)
    public void throws_when_multiple_private_ipv4_addresses() {
        mock.addAddress(""localhost"", ""38.3.4.2"")
                .addAddress(""localhost"", ""10.0.2.2"")
                .addAddress(""localhost"", ""10.0.2.3"");
        mock.getIPv4Address(""localhost"");
    }
"
"    @Test
    public void translator_with_valid_parameters() {

        // Test simplest possible address
        Inet6Address original = (Inet6Address) InetAddresses.forString(""2001:db8::1"");
        Inet6Address prefix = (Inet6Address) InetAddresses.forString(""fd00::"");
        InetAddress translated = IPAddresses.prefixTranslate(original, prefix, 8);
        assertEquals(""fd00:0:0:0:0:0:0:1"", translated.getHostAddress());


        // Test an actual aws address we use
        original = (Inet6Address) InetAddresses.forString(""2600:1f16:f34:5300:ccc6:1703:b7c2:369d"");
        translated = IPAddresses.prefixTranslate(original, prefix, 8);
        assertEquals(""fd00:0:0:0:ccc6:1703:b7c2:369d"", translated.getHostAddress());

        // Test different subnet size
        translated = IPAddresses.prefixTranslate(original, prefix, 6);
        assertEquals(""fd00:0:0:5300:ccc6:1703:b7c2:369d"", translated.getHostAddress());
    }
"
"    @Test
    public void default_env_is_correctly_rewritten() throws IOException {
        Path tempFile = temporaryFolder.newFile().toPath();
        Files.copy(EXAMPLE_FILE, tempFile, REPLACE_EXISTING);

        DefaultEnvWriter writer = new DefaultEnvWriter();
        writer.addOverride(""VESPA_HOSTNAME"", ""my-new-hostname"");
        writer.addFallback(""VESPA_CONFIGSERVER"", ""new-fallback-configserver"");
        writer.addOverride(""VESPA_TLS_CONFIG_FILE"", ""/override/path/to/config.file"");

        boolean modified = writer.updateFile(context, tempFile);

        assertTrue(modified);
        assertEquals(Files.readString(EXPECTED_RESULT_FILE), Files.readString(tempFile));
        verify(context, times(1)).log(any(Logger.class), any(String.class));

        modified = writer.updateFile(context, tempFile);
        assertFalse(modified);
        assertEquals(Files.readString(EXPECTED_RESULT_FILE), Files.readString(tempFile));
        verify(context, times(1)).log(any(Logger.class), any(String.class));
    }
"
"    @Test
    public void generates_default_env_content() throws IOException {
        DefaultEnvWriter writer = new DefaultEnvWriter();
        writer.addOverride(""VESPA_HOSTNAME"", ""my-new-hostname"");
        writer.addFallback(""VESPA_CONFIGSERVER"", ""new-fallback-configserver"");
        writer.addOverride(""VESPA_TLS_CONFIG_FILE"", ""/override/path/to/config.file"");
        writer.addUnset(""VESPA_LEGACY_OPTION"");
        String generatedContent = writer.generateContent();
        assertEquals(Files.readString(EXPECTED_RESULT_FILE), generatedContent);
    }
"
"    @Test
    public void generic_yum_methods() {
        assertYumMethod(yum -> yum.expectInstall(packages).withEnableRepo(repos),
                yum -> yum.install(List.of(packages)).enableRepo(repos).converge(context));

        assertYumMethod(yum -> yum.expectUpdate(packages).withEnableRepo(repos),
                yum -> yum.upgrade(List.of(packages)).enableRepo(repos).converge(context));

        assertYumMethod(yum -> yum.expectRemove(packages).withEnableRepo(repos),
                yum -> yum.remove(List.of(packages)).enableRepo(repos).converge(context));

        assertYumMethod(yum -> yum.expectInstallFixedVersion(minimalPackage.toName()).withEnableRepo(repos),
                yum -> yum.installFixedVersion(minimalPackage).enableRepo(repos).converge(context));
    }
"
"    @Test
    public void expect_query_installed() {
        Stream.of(minimalPackage, fullPackage, null).forEach(pkg -> {
            yum.expectQueryInstalled(packages[0]).andReturn(pkg);
            assertEquals(Optional.ofNullable(pkg), yum.queryInstalled(context, packages[0]));
            terminal.verifyAllCommandsExecuted();
        });
    }
"
"    @Test
    public void testBuilder() {
        YumPackageName yumPackage = new YumPackageName.Builder(""docker"")
                .setEpoch(""2"")
                .setVersion(""1.12.6"")
                .setRelease(""71.git3e8e77d.el7.centos.1"")
                .setArchitecture(""x86_64"")
                .build();
        assertEquals(""2:docker-1.12.6-71.git3e8e77d.el7.centos.1.x86_64"", yumPackage.toName());
    }
"
"    @Test
    public void testAllValidFormats() {
        // name
        verifyPackageName(
                ""docker-engine-selinux"",
                null,
                ""docker-engine-selinux"",
                null,
                null,
                null,
                ""docker-engine-selinux"",
                null);

        // name.arch
        verifyPackageName(
                ""docker-engine-selinux.x86_64"",
                null,
                ""docker-engine-selinux"",
                null,
                null,
                ""x86_64"",
                ""docker-engine-selinux.x86_64"",
                null);

        // name-ver-rel
        verifyPackageName(""docker-engine-selinux-1.12.6-1.el7"",
                null,
                ""docker-engine-selinux"",
                ""1.12.6"",
                ""1.el7"",
                null,
                ""docker-engine-selinux-1.12.6-1.el7"",
                ""0:docker-engine-selinux-1.12.6-1.el7.*"");

        // name-ver-rel.arch
        verifyPackageName(""docker-engine-selinux-1.12.6-1.el7.x86_64"",
                null,
                ""docker-engine-selinux"",
                ""1.12.6"",
                ""1.el7"",
                ""x86_64"",
                ""docker-engine-selinux-1.12.6-1.el7.x86_64"",
                ""0:docker-engine-selinux-1.12.6-1.el7.*"");

        // name-epoch:ver-rel.arch
        verifyPackageName(
                ""docker-2:1.12.6-71.git3e8e77d.el7.centos.1.x86_64"",
                ""2"",
                ""docker"",
                ""1.12.6"",
                ""71.git3e8e77d.el7.centos.1"",
                ""x86_64"",
                ""2:docker-1.12.6-71.git3e8e77d.el7.centos.1.x86_64"",
                ""2:docker-1.12.6-71.git3e8e77d.el7.centos.1.*"");

        // epoch:name-ver-rel.arch
        verifyPackageName(
                ""2:docker-1.12.6-71.git3e8e77d.el7.centos.1.x86_64"",
                ""2"",
                ""docker"",
                ""1.12.6"",
                ""71.git3e8e77d.el7.centos.1"",
                ""x86_64"",
                ""2:docker-1.12.6-71.git3e8e77d.el7.centos.1.x86_64"",
                ""2:docker-1.12.6-71.git3e8e77d.el7.centos.1.*"");
    }
"
"    @Test
    public void testArchitectures() {
        assertEquals(""x86_64"", YumPackageName.fromString(""docker.x86_64"").getArchitecture().get());
        assertEquals(""i686"", YumPackageName.fromString(""docker.i686"").getArchitecture().get());
        assertEquals(""noarch"", YumPackageName.fromString(""docker.noarch"").getArchitecture().get());
    }
"
"    @Test
    public void unrecognizedArchitectureGetsGobbledUp() {
        YumPackageName packageName = YumPackageName.fromString(""docker-engine-selinux-1.12.6-1.el7.i486"");
        // This is not a great feature - please use YumPackageName.Builder instead.
        assertEquals(""1.el7.i486"", packageName.getRelease().get());
    }
"
"    @Test
    public void failParsingOfPackageNameWithEpochAndArchitecture() {
        try {
            YumPackageName.fromString(""epoch:docker-engine-selinux-1.12.6-1.el7.x86_64"");
            fail();
        } catch (IllegalArgumentException e) {
            assertThat(e.getMessage(), containsStringIgnoringCase(""epoch""));
        }
    }
"
"    @Test
    public void testSubset() {
        YumPackageName yumPackage = new YumPackageName.Builder(""docker"")
                .setVersion(""1.12.6"")
                .build();

        assertTrue(yumPackage.isSubsetOf(yumPackage));
        assertTrue(yumPackage.isSubsetOf(new YumPackageName.Builder(""docker"")
                .setVersion(""1.12.6"")
                .setEpoch(""2"")
                .setRelease(""71.git3e8e77d.el7.centos.1"")
                .setArchitecture(""x86_64"")
                .build()));
        assertFalse(yumPackage.isSubsetOf(new YumPackageName.Builder(""docker"")
                .setVersion(""1.13.1"")
                .build()));
    }
"
"    @Test
    public void testQueryInstalledNevra() {
        terminal.expectCommand(
                ""rpm -q docker --queryformat \""%{NAME}\\\\n%{EPOCH}\\\\n%{VERSION}\\\\n%{RELEASE}\\\\n%{ARCH}\"" 2>&1"",
                0,
                ""docker\n2\n1.13.1\n74.git6e3bb8e.el7.centos\nx86_64"");

        Optional<YumPackageName> installed = yum.queryInstalled(taskContext, ""docker"");

        assertTrue(installed.isPresent());
        assertEquals(""docker"", installed.get().getName());
        assertEquals(""2"", installed.get().getEpoch().get());
        assertEquals(""1.13.1"", installed.get().getVersion().get());
        assertEquals(""74.git6e3bb8e.el7.centos"", installed.get().getRelease().get());
        assertEquals(""x86_64"", installed.get().getArchitecture().get());
    }
"
"    @Test
    public void testQueryInstalledPartial() {
        terminal.expectCommand(
                ""rpm -q vespa-node-admin --queryformat \""%{NAME}\\\\n%{EPOCH}\\\\n%{VERSION}\\\\n%{RELEASE}\\\\n%{ARCH}\"" 2>&1"",
                0,
                ""vespa-node-admin\n(none)\n6.283.62\n1.el7\nnoarch"");

        Optional<YumPackageName> installed = yum.queryInstalled(taskContext, ""vespa-node-admin"");

        assertTrue(installed.isPresent());
        assertEquals(""vespa-node-admin"", installed.get().getName());
        assertFalse(installed.get().getEpoch().isPresent());
        assertEquals(""6.283.62"", installed.get().getVersion().get());
        assertEquals(""1.el7"", installed.get().getRelease().get());
        assertEquals(""noarch"", installed.get().getArchitecture().get());
    }
"
"    @Test
    public void testQueryNotInstalled() {
        terminal.expectCommand(
                ""rpm -q fake-package --queryformat \""%{NAME}\\\\n%{EPOCH}\\\\n%{VERSION}\\\\n%{RELEASE}\\\\n%{ARCH}\"" 2>&1"",
                1,
                ""package fake-package is not installed"");

        Optional<YumPackageName> installed = yum.queryInstalled(taskContext, ""fake-package"");

        assertFalse(installed.isPresent());
    }
"
"    @Test
    public void testAlreadyInstalled() {
        terminal.expectCommand(
                ""yum install --assumeyes --enablerepo=repo1 --enablerepo=repo2 --setopt skip_missing_names_on_install=False package-1 package-2 2>&1"",
                0,
                ""foobar\nNothing to do\n"");

        assertFalse(yum
                .install(""package-1"", ""package-2"")
                .enableRepo(""repo1"", ""repo2"")
                .converge(taskContext));
    }
"
"    @Test
    public void testAlreadyUpgraded() {
        terminal.expectCommand(
                ""yum upgrade --assumeyes --setopt skip_missing_names_on_update=False package-1 package-2 2>&1"",
                0,
                ""foobar\nNo packages marked for update\n"");

        assertFalse(yum
                .upgrade(""package-1"", ""package-2"")
                .converge(taskContext));
    }
"
"    @Test
    public void testAlreadyRemoved() {
        terminal.expectCommand(
                ""yum remove --assumeyes package-1 package-2 2>&1"",
                0,
                ""foobar\nNo Packages marked for removal\n"");

        assertFalse(yum
                .remove(""package-1"", ""package-2"")
                .converge(taskContext));
    }
"
"    @Test
    public void testFallback() {
        HystrixCommand<Integer> superCmd = new SuperCommand(""cache"", false);
        assertEquals(2, superCmd.execute().intValue());

        HystrixCommand<Integer> subNoOverridesCmd = new SubCommandNoOverride(""cache"", false);
        assertEquals(2, subNoOverridesCmd.execute().intValue());

        HystrixCommand<Integer> subOverriddenFallbackCmd = new SubCommandOverrideFallback(""cache"", false);
        assertEquals(3, subOverriddenFallbackCmd.execute().intValue());
    }
"
"    @Test
    public void testRequestCacheSuperClass() {
        HystrixCommand<Integer> superCmd1 = new SuperCommand(""cache"", true);
        assertEquals(1, superCmd1.execute().intValue());
        HystrixCommand<Integer> superCmd2 = new SuperCommand(""cache"", true);
        assertEquals(1, superCmd2.execute().intValue());
        HystrixCommand<Integer> superCmd3 = new SuperCommand(""no-cache"", true);
        assertEquals(1, superCmd3.execute().intValue());
        System.out.println(""REQ LOG : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        HystrixRequestLog reqLog = HystrixRequestLog.getCurrentRequest();
        assertEquals(3, reqLog.getAllExecutedCommands().size());
        List<HystrixInvokableInfo<?>> infos = new ArrayList<HystrixInvokableInfo<?>>(reqLog.getAllExecutedCommands());
        HystrixInvokableInfo<?> info1 = infos.get(0);
        assertEquals(""SuperCommand"", info1.getCommandKey().name());
        assertEquals(1, info1.getExecutionEvents().size());
        HystrixInvokableInfo<?> info2 = infos.get(1);
        assertEquals(""SuperCommand"", info2.getCommandKey().name());
        assertEquals(2, info2.getExecutionEvents().size());
        assertEquals(HystrixEventType.RESPONSE_FROM_CACHE, info2.getExecutionEvents().get(1));
        HystrixInvokableInfo<?> info3 = infos.get(2);
        assertEquals(""SuperCommand"", info3.getCommandKey().name());
        assertEquals(1, info3.getExecutionEvents().size());
    }
"
"    @Test
    public void testRequestCacheSubclassNoOverrides() {
        HystrixCommand<Integer> subCmd1 = new SubCommandNoOverride(""cache"", true);
        assertEquals(1, subCmd1.execute().intValue());
        HystrixCommand<Integer> subCmd2 = new SubCommandNoOverride(""cache"", true);
        assertEquals(1, subCmd2.execute().intValue());
        HystrixCommand<Integer> subCmd3 = new SubCommandNoOverride(""no-cache"", true);
        assertEquals(1, subCmd3.execute().intValue());
        System.out.println(""REQ LOG : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        HystrixRequestLog reqLog = HystrixRequestLog.getCurrentRequest();
        assertEquals(3, reqLog.getAllExecutedCommands().size());
        List<HystrixInvokableInfo<?>> infos = new ArrayList<HystrixInvokableInfo<?>>(reqLog.getAllExecutedCommands());
        HystrixInvokableInfo<?> info1 = infos.get(0);
        assertEquals(""SubCommandNoOverride"", info1.getCommandKey().name());
        assertEquals(1, info1.getExecutionEvents().size());
        HystrixInvokableInfo<?> info2 = infos.get(1);
        assertEquals(""SubCommandNoOverride"", info2.getCommandKey().name());
        assertEquals(2, info2.getExecutionEvents().size());
        assertEquals(HystrixEventType.RESPONSE_FROM_CACHE, info2.getExecutionEvents().get(1));
        HystrixInvokableInfo<?> info3 = infos.get(2);
        assertEquals(""SubCommandNoOverride"", info3.getCommandKey().name());
        assertEquals(1, info3.getExecutionEvents().size());
    }
"
"    @Test
    public void testRequestLogSuperClass() {
        HystrixCommand<Integer> superCmd = new SuperCommand(""cache"", true);
        assertEquals(1, superCmd.execute().intValue());
        System.out.println(""REQ LOG : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        HystrixRequestLog reqLog = HystrixRequestLog.getCurrentRequest();
        assertEquals(1, reqLog.getAllExecutedCommands().size());
        HystrixInvokableInfo<?> info = reqLog.getAllExecutedCommands().iterator().next();
        assertEquals(""SuperCommand"", info.getCommandKey().name());
    }
"
"    @Test
    public void testRequestLogSubClassNoOverrides() {
        HystrixCommand<Integer> subCmd = new SubCommandNoOverride(""cache"", true);
        assertEquals(1, subCmd.execute().intValue());
        System.out.println(""REQ LOG : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        HystrixRequestLog reqLog = HystrixRequestLog.getCurrentRequest();
        assertEquals(1, reqLog.getAllExecutedCommands().size());
        HystrixInvokableInfo<?> info = reqLog.getAllExecutedCommands().iterator().next();
        assertEquals(""SubCommandNoOverride"", info.getCommandKey().name());
    }
"
"	@Test
	public void shouldYieldNoExecutedTasksOnStartup() throws Exception {
		//given
		final Collection<HystrixThreadPoolMetrics> instances = HystrixThreadPoolMetrics.getInstances();

		//then
		assertEquals(0, instances.size());

	}
"
"	@Test
	public void shouldReturnOneExecutedTask() throws Exception {
		//given
		final Collection<HystrixThreadPoolMetrics> instances = HystrixThreadPoolMetrics.getInstances();
		RollingThreadPoolEventCounterStream.getInstance(tpKey, 10, 100).startCachingStreamValuesIfUnstarted();

		//when
		new NoOpHystrixCommand().execute();

		//then
		Thread.sleep(100);
		assertEquals(1, instances.size());
		assertEquals(1, instances.iterator().next().getRollingCountThreadsExecuted());
	}
"
"    @Test
    public void testExecutionHookSemaphoreSuccess() {
        assertHooksOnSuccess(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, FallbackResult.SUCCESS);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreBadRequestException() {
        assertHooksOnFailure(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.BAD_REQUEST, FallbackResult.SUCCESS);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreExceptionNoFallback() {
        assertHooksOnFailure(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.FAILURE, FallbackResult.UNIMPLEMENTED);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreExceptionSuccessfulFallback() {
        assertHooksOnSuccess(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.FAILURE, FallbackResult.SUCCESS);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreExceptionUnsuccessfulFallback() {
        assertHooksOnFailure(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.FAILURE, FallbackResult.FAILURE);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreRejectedNoFallback() {
        assertHooksOnFailFast(
                new Func0<C>() {
                    @Override
                    public C call() {
                        AbstractCommand.TryableSemaphore semaphore = new AbstractCommand.TryableSemaphoreActual(HystrixProperty.Factory.asProperty(2));

                        final C cmd1 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 500, FallbackResult.UNIMPLEMENTED, semaphore);
                        final C cmd2 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 500, FallbackResult.UNIMPLEMENTED, semaphore);

                        //saturate the semaphore
                        new Thread() {
                            @Override
                            public void run() {
                                cmd1.observe();
                            }
"
"    @Test
    public void testExecutionHookSemaphoreRejectedSuccessfulFallback() {
        assertHooksOnSuccess(
                new Func0<C>() {
                    @Override
                    public C call() {
                        AbstractCommand.TryableSemaphore semaphore = new AbstractCommand.TryableSemaphoreActual(HystrixProperty.Factory.asProperty(2));

                        final C cmd1 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 1500, FallbackResult.SUCCESS, semaphore);
                        final C cmd2 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 1500, FallbackResult.SUCCESS, semaphore);

                        //saturate the semaphore
                        new Thread() {
                            @Override
                            public void run() {
                                cmd1.observe();
                            }
"
"    @Test
    public void testExecutionHookSemaphoreRejectedUnsuccessfulFallback() {
        assertHooksOnFailFast(
                new Func0<C>() {
                    @Override
                    public C call() {
                        AbstractCommand.TryableSemaphore semaphore = new AbstractCommand.TryableSemaphoreActual(HystrixProperty.Factory.asProperty(2));

                        final C cmd1 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 500, FallbackResult.FAILURE, semaphore);
                        final C cmd2 = getLatentCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, 500, FallbackResult.FAILURE, semaphore);

                        //saturate the semaphore
                        new Thread() {
                            @Override
                            public void run() {
                                cmd1.observe();
                            }
"
"    @Test
    public void testExecutionHookSemaphoreShortCircuitNoFallback() {
        assertHooksOnFailFast(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCircuitOpenCommand(ExecutionIsolationStrategy.SEMAPHORE, FallbackResult.UNIMPLEMENTED);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreShortCircuitSuccessfulFallback() {
        assertHooksOnSuccess(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCircuitOpenCommand(ExecutionIsolationStrategy.SEMAPHORE, FallbackResult.SUCCESS);
                    }
"
"    @Test
    public void testExecutionHookSemaphoreShortCircuitUnsuccessfulFallback() {
        assertHooksOnFailFast(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCircuitOpenCommand(ExecutionIsolationStrategy.SEMAPHORE, FallbackResult.FAILURE);
                    }
"
"    @Test
    public void testGetErrorPercentage() {
        String key = ""cmd-metrics-A"";
        try {
            HystrixCommand<Boolean> cmd1 = new SuccessCommand(key, 1);
            HystrixCommandMetrics metrics = cmd1.metrics;
            cmd1.execute();
            Thread.sleep(100);
            assertEquals(0, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd2 = new FailureCommand(key, 1);
            cmd2.execute();
            Thread.sleep(100);
            assertEquals(50, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd3 = new SuccessCommand(key, 1);
            HystrixCommand<Boolean> cmd4 = new SuccessCommand(key, 1);
            cmd3.execute();
            cmd4.execute();
            Thread.sleep(100);
            assertEquals(25, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd5 = new TimeoutCommand(key);
            HystrixCommand<Boolean> cmd6 = new TimeoutCommand(key);
            cmd5.execute();
            cmd6.execute();
            Thread.sleep(100);
            assertEquals(50, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd7 = new SuccessCommand(key, 1);
            HystrixCommand<Boolean> cmd8 = new SuccessCommand(key, 1);
            HystrixCommand<Boolean> cmd9 = new SuccessCommand(key, 1);
            cmd7.execute();
            cmd8.execute();
            cmd9.execute();

            // latent
            HystrixCommand<Boolean> cmd10 = new SuccessCommand(key, 60);
            cmd10.execute();

            // 6 success + 1 latent success + 1 failure + 2 timeout = 10 total
            // latent success not considered error
            // error percentage = 1 failure + 2 timeout / 10
            Thread.sleep(100);
            assertEquals(30, metrics.getHealthCounts().getErrorPercentage());

        } catch (Exception e) {
            e.printStackTrace();
            fail(""Error occurred: "" + e.getMessage());
        }

    }
"
"    @Test
    public void testBadRequestsDoNotAffectErrorPercentage() {
        String key = ""cmd-metrics-B"";
        try {

            HystrixCommand<Boolean> cmd1 = new SuccessCommand(key ,1);
            HystrixCommandMetrics metrics = cmd1.metrics;
            cmd1.execute();
            Thread.sleep(100);
            assertEquals(0, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd2 = new FailureCommand(key, 1);
            cmd2.execute();
            Thread.sleep(100);
            assertEquals(50, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd3 = new BadRequestCommand(key, 1);
            HystrixCommand<Boolean> cmd4 = new BadRequestCommand(key, 1);
            try {
                cmd3.execute();
            } catch (HystrixBadRequestException ex) {
                System.out.println(""Caught expected HystrixBadRequestException from cmd3"");
            }
            try {
                cmd4.execute();
            } catch (HystrixBadRequestException ex) {
                System.out.println(""Caught expected HystrixBadRequestException from cmd4"");
            }
            Thread.sleep(100);
            assertEquals(50, metrics.getHealthCounts().getErrorPercentage());

            HystrixCommand<Boolean> cmd5 = new FailureCommand(key, 1);
            HystrixCommand<Boolean> cmd6 = new FailureCommand(key, 1);
            cmd5.execute();
            cmd6.execute();
            Thread.sleep(100);
            assertEquals(75, metrics.getHealthCounts().getErrorPercentage());
        } catch (Exception e) {
            e.printStackTrace();
            fail(""Error occurred : "" + e.getMessage());
        }
    }
"
"    @Test
    public void testCurrentConcurrentExecutionCount() throws InterruptedException {
        String key = ""cmd-metrics-C"";

        HystrixCommandMetrics metrics = null;
        List<Observable<Boolean>> cmdResults = new ArrayList<Observable<Boolean>>();

        int NUM_CMDS = 8;
        for (int i = 0; i < NUM_CMDS; i++) {
            HystrixCommand<Boolean> cmd = new SuccessCommand(key, 900);
            if (metrics == null) {
                metrics = cmd.metrics;
            }
            Observable<Boolean> eagerObservable = cmd.observe();
            cmdResults.add(eagerObservable);
        }

        try {
            Thread.sleep(150);
        } catch (InterruptedException ie) {
            fail(ie.getMessage());
        }
        System.out.println(""ReqLog: "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertEquals(NUM_CMDS, metrics.getCurrentConcurrentExecutionCount());

        final CountDownLatch latch = new CountDownLatch(1);
        Observable.merge(cmdResults).subscribe(new Subscriber<Boolean>() {
            @Override
            public void onCompleted() {
                System.out.println(""All commands done"");
                latch.countDown();
            }
"
"    @Test
    public void testCommandRequiresContextConcurrencyStrategyProvidesItContextSetUpCorrectly() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(true);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is set up properly
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute());
        printRequestLog();
        assertNotNull(HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertNotNull(cmd.currentRequestLog);
        context.shutdown();
    }
"
"    @Test
    public void testCommandRequiresContextConcurrencyStrategyProvidesItContextLeftUninitialized() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(true);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is not set up
        HystrixRequestContext.setContextOnCurrentThread(null);
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute()); //command execution not affected by missing context
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
    }
"
"    @Test
    public void testCommandRequiresContextConcurrencyStrategyDoesNotProvideItContextSetUpCorrectly() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(false);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is set up properly
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute());
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
        context.shutdown();
    }
"
"    @Test
    public void testCommandRequiresContextConcurrencyStrategyDoesNotProvideItContextLeftUninitialized() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(false);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is not set up
        HystrixRequestContext.setContextOnCurrentThread(null);
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute()); //command execution not affected by missing context
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
    }
"
"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyProvidesItContextSetUpCorrectly() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(true);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is set up properly
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        HystrixCommand<Boolean> cmd = new TestCommand(false, false);
        assertTrue(cmd.execute());
        printRequestLog();
        assertNotNull(HystrixRequestLog.getCurrentRequest());
        assertNotNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
        context.shutdown();
    }
"
"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyProvidesItContextLeftUninitialized() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(true);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is not set up
        HystrixRequestContext.setContextOnCurrentThread(null);
        HystrixCommand<Boolean> cmd = new TestCommand(false, false);
        assertTrue(cmd.execute()); //command execution not affected by missing context
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
    }
"
"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyDoesNotProvideItContextSetUpCorrectly() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(false);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is set up properly
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute());
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
        context.shutdown();
    }
"
"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyDoesNotProvideItContextLeftUninitialized() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(false);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is not set up
        HystrixRequestContext.setContextOnCurrentThread(null);
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute()); //command execution unaffected by missing context
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
    }
"
"    @Test
    public void testNested1() {
        HystrixProperty<String> a = Factory.asProperty(""a"");
        assertEquals(""a"", a.get());

        HystrixProperty<String> aWithDefault = Factory.asProperty(a, ""b"");
        assertEquals(""a"", aWithDefault.get());
    }
"
"    @Test
    public void testNested2() {
        HystrixProperty<String> nullValue = Factory.nullProperty();

        HystrixProperty<String> withDefault = Factory.asProperty(nullValue, ""b"");
        assertEquals(""b"", withDefault.get());
    }
"
"    @Test
    public void testNested3() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, ""a"");

        HystrixProperty<String> withDefault = Factory.asProperty(a, ""b"");
        assertEquals(""a"", withDefault.get());
    }
"
"    @Test
    public void testNested4() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, null);

        HystrixProperty<String> withDefault = Factory.asProperty(a, ""b"");
        assertEquals(""b"", withDefault.get());
    }
"
"    @Test
    public void testNested5() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, null);

        @SuppressWarnings(""unchecked"")
        HystrixProperty<String> withDefault = Factory.asProperty(a, Factory.asProperty(""b""));
        assertEquals(""b"", withDefault.get());
    }
"
"    @Test
    public void testSeries1() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, null);

        @SuppressWarnings(""unchecked"")
        HystrixProperty<String> withDefault = Factory.asProperty(a, nullValue, nullValue, Factory.asProperty(""b""));
        assertEquals(""b"", withDefault.get());
    }
"
"    @Test
    public void testSeries2() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, null);

        @SuppressWarnings(""unchecked"")
        HystrixProperty<String> withDefault = Factory.asProperty(a, nullValue, Factory.asProperty(""b""), nullValue, Factory.asProperty(""c""));
        assertEquals(""b"", withDefault.get());
    }
"
"    @Test
    public void testString() throws Exception {

        DynamicStringProperty pString = new DynamicStringProperty(""defaultString"", ""default-default"");
        HystrixPropertiesChainedArchaiusProperty.StringProperty fString = new HystrixPropertiesChainedArchaiusProperty.StringProperty(""overrideString"", pString);

        assertTrue(""default-default"".equals(fString.get()));

        ConfigurationManager.getConfigInstance().setProperty(""defaultString"", ""default"");
        assertTrue(""default"".equals(fString.get()));

        ConfigurationManager.getConfigInstance().setProperty(""overrideString"", ""override"");
        assertTrue(""override"".equals(fString.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""overrideString"");
        assertTrue(""default"".equals(fString.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""defaultString"");
        assertTrue(""default-default"".equals(fString.get()));
    }
"
"    @Test
    public void testInteger() throws Exception {

        DynamicIntegerProperty pInt = new DynamicIntegerProperty(""defaultInt"", -1);
        HystrixPropertiesChainedArchaiusProperty.IntegerProperty fInt = new HystrixPropertiesChainedArchaiusProperty.IntegerProperty(""overrideInt"", pInt);

        assertTrue(-1 == fInt.get());

        ConfigurationManager.getConfigInstance().setProperty(""defaultInt"", 10);
        assertTrue(10 == fInt.get());

        ConfigurationManager.getConfigInstance().setProperty(""overrideInt"", 11);
        assertTrue(11 == fInt.get());

        ConfigurationManager.getConfigInstance().clearProperty(""overrideInt"");
        assertTrue(10 == fInt.get());

        ConfigurationManager.getConfigInstance().clearProperty(""defaultInt"");
        assertTrue(-1 == fInt.get());
    }
"
"    @Test
    public void testBoolean() throws Exception {

        DynamicBooleanProperty pBoolean = new DynamicBooleanProperty(""defaultBoolean"", true);
        HystrixPropertiesChainedArchaiusProperty.BooleanProperty fBoolean = new HystrixPropertiesChainedArchaiusProperty.BooleanProperty(""overrideBoolean"", pBoolean);

        System.out.println(""pBoolean: "" + pBoolean.get());
        System.out.println(""fBoolean: "" + fBoolean.get());

        assertTrue(fBoolean.get());

        ConfigurationManager.getConfigInstance().setProperty(""defaultBoolean"", Boolean.FALSE);

        System.out.println(""pBoolean: "" + pBoolean.get());
        System.out.println(""fBoolean: "" + fBoolean.get());

        assertFalse(fBoolean.get());

        ConfigurationManager.getConfigInstance().setProperty(""overrideBoolean"", Boolean.TRUE);
        assertTrue(fBoolean.get());

        ConfigurationManager.getConfigInstance().clearProperty(""overrideBoolean"");
        assertFalse(fBoolean.get());

        ConfigurationManager.getConfigInstance().clearProperty(""defaultBoolean"");
        assertTrue(fBoolean.get());
    }
"
"    @Test
    public void testChainingString() throws Exception {

        DynamicStringProperty node1 = new DynamicStringProperty(""node1"", ""v1"");
        StringProperty node2 = new HystrixPropertiesChainedArchaiusProperty.StringProperty(""node2"", node1);

        HystrixPropertiesChainedArchaiusProperty.StringProperty node3 = new HystrixPropertiesChainedArchaiusProperty.StringProperty(""node3"", node2);

        assertTrue("""" + node3.get(), ""v1"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node1"", ""v11"");
        assertTrue(""v11"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node2"", ""v22"");
        assertTrue(""v22"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""node1"");
        assertTrue(""v22"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node3"", ""v33"");
        assertTrue(""v33"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""node2"");
        assertTrue(""v33"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node2"", ""v222"");
        assertTrue(""v33"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""node3"");
        assertTrue(""v222"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().clearProperty(""node2"");
        assertTrue(""v1"".equals(node3.get()));

        ConfigurationManager.getConfigInstance().setProperty(""node2"", ""v2222"");
        assertTrue(""v2222"".equals(node3.get()));
    }
"
"    @Test
    public void testChainingInteger() throws Exception {

        DynamicIntegerProperty node1 = new DynamicIntegerProperty(""node1"", 1);
        IntegerProperty node2 = new HystrixPropertiesChainedArchaiusProperty.IntegerProperty(""node2"", node1);

        HystrixPropertiesChainedArchaiusProperty.IntegerProperty node3 = new HystrixPropertiesChainedArchaiusProperty.IntegerProperty(""node3"", node2);

        assertTrue("""" + node3.get(), 1 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node1"", 11);
        assertTrue(11 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node2"", 22);
        assertTrue(22 == node3.get());

        ConfigurationManager.getConfigInstance().clearProperty(""node1"");
        assertTrue(22 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node3"", 33);
        assertTrue(33 == node3.get());

        ConfigurationManager.getConfigInstance().clearProperty(""node2"");
        assertTrue(33 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node2"", 222);
        assertTrue(33 == node3.get());

        ConfigurationManager.getConfigInstance().clearProperty(""node3"");
        assertTrue(222 == node3.get());

        ConfigurationManager.getConfigInstance().clearProperty(""node2"");
        assertTrue(1 == node3.get());

        ConfigurationManager.getConfigInstance().setProperty(""node2"", 2222);
        assertTrue(2222 == node3.get());
    }
"
"    @Test
    public void testAddCallback() throws Exception {

        final DynamicStringProperty node1 = new DynamicStringProperty(""n1"", ""n1"");
        final HystrixPropertiesChainedArchaiusProperty.StringProperty node2 = new HystrixPropertiesChainedArchaiusProperty.StringProperty(""n2"", node1);

        final AtomicInteger callbackCount = new AtomicInteger(0);

        node2.addCallback(new Runnable() {
            @Override
            public void run() {
                callbackCount.incrementAndGet();
            }
"
"    @Test
    public void testRequestContextPropagatesAcrossObserveOnPool() {
        new SimpleCommand().execute();
        new SimpleCommand().observe().map(new Func1<String, String>() {

            @Override
            public String call(String s) {
                System.out.println(""Map => Commands: "" + HystrixRequestLog.getCurrentRequest().getAllExecutedCommands());
                return s;
            }
"
"    @Test
    public void testThreadContextOnTimeout() {
        final AtomicBoolean isInitialized = new AtomicBoolean();
        new TimeoutCommand().toObservable()
                .doOnError(new Action1<Throwable>() {
                    @Override
                    public void call(Throwable throwable) {
                        isInitialized.set(HystrixRequestContext.isCurrentThreadInitialized());
                    }
"
"    @Test
    public void testNoRequestContextOnSimpleConcurencyStrategyWithoutException() throws Exception {
        shutdownContextIfExists();
        ConfigurationManager.getConfigInstance().setProperty(""hystrix.command.default.requestLog.enabled"", ""false"");

        new SimpleCommand().execute();

        assertTrue(""We are able to run the simple command without a context initialization error."", true);
    }
"
"    @Test(timeout = 2500)
    public void testUnsubscribeWrappedScheduler() throws InterruptedException {
        Scheduler s = Schedulers.newThread();
        final AtomicBoolean interrupted = new AtomicBoolean();
        final CountDownLatch start = new CountDownLatch(1);
        final CountDownLatch end = new CountDownLatch(1);

        HystrixContextScheduler hcs = new HystrixContextScheduler(s);

        Scheduler.Worker w = hcs.createWorker();
        try {
            w.schedule(new Action0() {
                @Override
                public void call() {
                    start.countDown();
                    try {
                        try {
                            Thread.sleep(5000);
                        } catch (InterruptedException ex) {
                            interrupted.set(true);
                        }
                    } finally {
                        end.countDown();
                    }
                }
"
"    @Test
    public void testSingleInitializePerKey() {
        final TestHystrixMetricsPublisher publisher = new TestHystrixMetricsPublisher();
        HystrixPlugins.getInstance().registerMetricsPublisher(publisher);
        final HystrixMetricsPublisherFactory factory = new HystrixMetricsPublisherFactory();
        ArrayList<Thread> threads = new ArrayList<Thread>();
        for (int i = 0; i < 20; i++) {
            threads.add(new Thread(new Runnable() {

                @Override
                public void run() {
                    factory.getPublisherForCommand(TestCommandKey.TEST_A, null, null, null, null);
                    factory.getPublisherForCommand(TestCommandKey.TEST_B, null, null, null, null);
                    factory.getPublisherForThreadPool(TestThreadPoolKey.TEST_A, null, null);
                }
"
"    @Test
    public void testMetricsPublisherReset() {
        // precondition: HystrixMetricsPublisherFactory class is not loaded. Calling HystrixPlugins.reset() here should be good enough to run this with other tests.

        // set first custom publisher
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""key"");
        HystrixMetricsPublisherCommand firstCommand = new HystrixMetricsPublisherCommandDefault(key, null, null, null, null);
        HystrixMetricsPublisher firstPublisher = new CustomPublisher(firstCommand);
        HystrixPlugins.getInstance().registerMetricsPublisher(firstPublisher);

        // ensure that first custom publisher is used
        HystrixMetricsPublisherCommand cmd = HystrixMetricsPublisherFactory.createOrRetrievePublisherForCommand(key, null, null, null, null);
        assertSame(firstCommand, cmd);

        // reset, then change to second custom publisher
        HystrixPlugins.reset();
        HystrixMetricsPublisherCommand secondCommand = new HystrixMetricsPublisherCommandDefault(key, null, null, null, null);
        HystrixMetricsPublisher secondPublisher = new CustomPublisher(secondCommand);
        HystrixPlugins.getInstance().registerMetricsPublisher(secondPublisher);

        // ensure that second custom publisher is used
        cmd = HystrixMetricsPublisherFactory.createOrRetrievePublisherForCommand(key, null, null, null, null);
        assertNotSame(firstCommand, cmd);
        assertSame(secondCommand, cmd);
    }
"
"    @Test
    public void testDynamicProperties() throws Exception {
        fakeServiceLoaderResource = 
                ""FAKE_META_INF_SERVICES/com.netflix.hystrix.strategy.properties.HystrixDynamicProperties"";
        HystrixPlugins plugins = setupMockServiceLoader();
        HystrixDynamicProperties properties = plugins.getDynamicProperties();
        plugins.getCommandExecutionHook();
        plugins.getPropertiesStrategy();
        assertTrue(properties instanceof MockHystrixDynamicPropertiesTest);

        assertEvents(
                ""[serviceloader: META-INF/services/com.netflix.hystrix.strategy.properties.HystrixDynamicProperties""
                        + "", debug: [Created HystrixDynamicProperties instance by loading from ServiceLoader. Using class: {}, com.netflix.hystrix.strategy.HystrixPluginsTest.MockHystrixDynamicPropertiesTest]""
                        + "", property: hystrix.plugin.HystrixCommandExecutionHook.implementation""
                        + "", serviceloader: META-INF/services/com.netflix.hystrix.strategy.executionhook.HystrixCommandExecutionHook""
                        + "", property: hystrix.plugin.HystrixPropertiesStrategy.implementation""
                        + "", serviceloader: META-INF/services/com.netflix.hystrix.strategy.properties.HystrixPropertiesStrategy]"");
    }
"
"    @Test(expected=ServiceConfigurationError.class)
    public void testDynamicPropertiesFailure() throws Exception {
        /*
         * James Bond: Do you expect me to talk?
         * Auric Goldfinger: No, Mr. Bond, I expect you to die!
         */
        fakeServiceLoaderResource = 
                ""FAKE_META_INF_SERVICES/com.netflix.hystrix.strategy.properties.HystrixDynamicPropertiesFail"";
        HystrixPlugins plugins = setupMockServiceLoader();
        plugins.getDynamicProperties();

    }
"
"    @Test
    public void testDynamicSystemProperties() throws Exception {
        //On the off chance this is the first test lets not screw up all the other tests
        HystrixPlugins.getInstance();
        
        System.setProperty(""hystrix.plugin.HystrixDynamicProperties.implementation"", 
                ""com.netflix.hystrix.strategy.properties.HystrixDynamicPropertiesSystemProperties"");
        
        HystrixPlugins plugins = setupMockServiceLoader();
        assertTrue(plugins.getDynamicProperties() instanceof HystrixDynamicPropertiesSystemProperties);
        
        HystrixDynamicProperties p = plugins.getDynamicProperties();
        //Some minimum testing of system properties wrapper
        //this probably should be in its own test class.
        assertTrue(p.getBoolean(""USE_DEFAULT"", true).get());
        assertEquals(""string"", p.getString(""USE_DEFAULT"", ""string"").get());
        assertEquals(1L, p.getLong(""USE_DEFAULT"", 1L).get().longValue());
        assertEquals(1, p.getInteger(""USE_DEFAULT"", 1).get().intValue());
        assertNotNull(p.getString(""path.separator"", null).get());
        
        assertEvents(""[debug: [Created HystrixDynamicProperties instance from System property named \""hystrix.plugin.HystrixDynamicProperties.implementation\"". Using class: {}, com.netflix.hystrix.strategy.properties.HystrixDynamicPropertiesSystemProperties]]"");

        System.clearProperty(""hystrix.plugin.HystrixDynamicProperties.implementation"");

    }
"
"    /*    @Test
    public void testCommandExecutionHookDefaultImpl() {
        HystrixCommandExecutionHook impl = HystrixPlugins.getInstance().getCommandExecutionHook();
        assertTrue(impl instanceof HystrixCommandExecutionHookDefault);
    }
"
"    @Test
    public void testCommandExecutionHookViaRegisterMethod() {
        HystrixPlugins.getInstance().registerCommandExecutionHook(new HystrixCommandExecutionHookTestImpl());
        HystrixCommandExecutionHook impl = HystrixPlugins.getInstance().getCommandExecutionHook();
        assertTrue(impl instanceof HystrixCommandExecutionHookTestImpl);
	}*/
"
"    /*@Test
    public void testEventNotifierDefaultImpl() {
        HystrixEventNotifier impl = HystrixPlugins.getInstance().getEventNotifier();
        assertTrue(impl instanceof HystrixEventNotifierDefault);
    }
"
"    @Test
    public void testEventNotifierViaRegisterMethod() {
        HystrixPlugins.getInstance().registerEventNotifier(new HystrixEventNotifierTestImpl());
        HystrixEventNotifier impl = HystrixPlugins.getInstance().getEventNotifier();
        assertTrue(impl instanceof HystrixEventNotifierTestImpl);
    }
"
"    @Test
    public void testEventNotifierViaProperty() {
        try {
            String fullClass = HystrixEventNotifierTestImpl.class.getName();
            System.setProperty(""hystrix.plugin.HystrixEventNotifier.implementation"", fullClass);
            HystrixEventNotifier impl = HystrixPlugins.getInstance().getEventNotifier();
            assertTrue(impl instanceof HystrixEventNotifierTestImpl);
        } finally {
            System.clearProperty(""hystrix.plugin.HystrixEventNotifier.implementation"");
        }
	}*/
"
"    /*@Test
    public void testConcurrencyStrategyDefaultImpl() {
        HystrixConcurrencyStrategy impl = HystrixPlugins.getInstance().getConcurrencyStrategy();
        assertTrue(impl instanceof HystrixConcurrencyStrategyDefault);
    }
"
"    @Test
    public void testConcurrencyStrategyViaRegisterMethod() {
        HystrixPlugins.getInstance().registerConcurrencyStrategy(new HystrixConcurrencyStrategyTestImpl());
        HystrixConcurrencyStrategy impl = HystrixPlugins.getInstance().getConcurrencyStrategy();
        assertTrue(impl instanceof HystrixConcurrencyStrategyTestImpl);
    }
"
"    @Test
    public void testConcurrencyStrategyViaProperty() {
        try {
            String fullClass = HystrixConcurrencyStrategyTestImpl.class.getName();
            System.setProperty(""hystrix.plugin.HystrixConcurrencyStrategy.implementation"", fullClass);
            HystrixConcurrencyStrategy impl = HystrixPlugins.getInstance().getConcurrencyStrategy();
            assertTrue(impl instanceof HystrixConcurrencyStrategyTestImpl);
        } finally {
            System.clearProperty(""hystrix.plugin.HystrixConcurrencyStrategy.implementation"");
        }
	}*/
"
"    /*@Test
    public void testMetricsPublisherDefaultImpl() {
        HystrixMetricsPublisher impl = HystrixPlugins.getInstance().getMetricsPublisher();
        assertTrue(impl instanceof HystrixMetricsPublisherDefault);
    }
"
"    @Test
    public void testMetricsPublisherViaRegisterMethod() {
        HystrixPlugins.getInstance().registerMetricsPublisher(new HystrixMetricsPublisherTestImpl());
        HystrixMetricsPublisher impl = HystrixPlugins.getInstance().getMetricsPublisher();
        assertTrue(impl instanceof HystrixMetricsPublisherTestImpl);
    }
"
"    @Test
    public void testMetricsPublisherViaProperty() {
        try {
            String fullClass = HystrixMetricsPublisherTestImpl.class.getName();
            System.setProperty(""hystrix.plugin.HystrixMetricsPublisher.implementation"", fullClass);
            HystrixMetricsPublisher impl = HystrixPlugins.getInstance().getMetricsPublisher();
            assertTrue(impl instanceof HystrixMetricsPublisherTestImpl);
        } finally {
            System.clearProperty(""hystrix.plugin.HystrixMetricsPublisher.implementation"");
        }
	}*/
"
"    /*@Test
    public void testPropertiesStrategyDefaultImpl() {
        HystrixPropertiesStrategy impl = HystrixPlugins.getInstance().getPropertiesStrategy();
        assertTrue(impl instanceof HystrixPropertiesStrategyDefault);
    }
"
"    @Test
    public void testPropertiesStrategyViaRegisterMethod() {
        HystrixPlugins.getInstance().registerPropertiesStrategy(new HystrixPropertiesStrategyTestImpl());
        HystrixPropertiesStrategy impl = HystrixPlugins.getInstance().getPropertiesStrategy();
        assertTrue(impl instanceof HystrixPropertiesStrategyTestImpl);
    }
"
"    @Test
    public void testPropertiesStrategyViaProperty() {
        try {
            String fullClass = HystrixPropertiesStrategyTestImpl.class.getName();
            System.setProperty(""hystrix.plugin.HystrixPropertiesStrategy.implementation"", fullClass);
            HystrixPropertiesStrategy impl = HystrixPlugins.getInstance().getPropertiesStrategy();
            assertTrue(impl instanceof HystrixPropertiesStrategyTestImpl);
        } finally {
            System.clearProperty(""hystrix.plugin.HystrixPropertiesStrategy.implementation"");
        }
	}*/
"
"    /*@Test
    public void testRequestContextViaPluginInTimeout() {
        HystrixPlugins.getInstance().registerConcurrencyStrategy(new HystrixConcurrencyStrategy() {
            @Override
            public <T> Callable<T> wrapCallable(final Callable<T> callable) {
                return new RequestIdCallable<T>(callable);
            }
        });

        HystrixRequestContext context = HystrixRequestContext.initializeContext();

        testRequestIdThreadLocal.set(""foobar"");
        final AtomicReference<String> valueInTimeout = new AtomicReference<String>();

        new DummyCommand().toObservable()
                .doOnError(new Action1<Throwable>() {
                    @Override
                    public void call(Throwable throwable) {
                        System.out.println(""initialized = "" + HystrixRequestContext.isCurrentThreadInitialized());
                        System.out.println(""requestId (timeout) = "" + testRequestIdThreadLocal.get());
                        valueInTimeout.set(testRequestIdThreadLocal.get());
                    }
"
"    @Test
    public void testSetResponseSuccess() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(""theResponse"");

        // fetch value
        assertEquals(""theResponse"", v.get());
    }
"
"    @Test
    public void testSetNullResponseSuccess() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(null);

        // fetch value
        assertEquals(null, v.get());
    }
"
"    @Test
    public void testSetException() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setException(new RuntimeException(""anException""));

        // fetch value
        try {
            v.get();
            fail(""expected exception"");
        } catch (ExecutionException e) {
            assertEquals(""anException"", e.getCause().getMessage());
        }
    }
"
"    @Test
    public void testSetExceptionAfterResponse() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(""theResponse"");

        try {
            cr.setException(new RuntimeException(""anException""));
            fail(""expected IllegalState"");
        } catch (IllegalStateException e) {

        }

        assertEquals(""theResponse"", v.get());
    }
"
"    @Test
    public void testSetResponseAfterException() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setException(new RuntimeException(""anException""));

        try {
            cr.setResponse(""theResponse"");
            fail(""expected IllegalState"");
        } catch (IllegalStateException e) {

        }

        try {
            v.get();
            fail(""expected exception"");
        } catch (ExecutionException e) {
            assertEquals(""anException"", e.getCause().getMessage());
        }
    }
"
"    @Test
    public void testSetResponseDuplicate() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(""theResponse"");

        try {
            cr.setResponse(""theResponse2"");
            fail(""expected IllegalState"");
        } catch (IllegalStateException e) {

        }

        assertEquals(""theResponse"", v.get());
    }
"
"    @Test(expected = CancellationException.class)
    public void testSetResponseAfterUnsubscribe() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> f = o.toBlocking().toFuture();

        // cancel/unsubscribe
        f.cancel(true);

        try {
            cr.setResponse(""theResponse"");
        } catch (IllegalStateException e) {
            fail(""this should have done nothing as it was unsubscribed already"");
        }

        // expect CancellationException after cancelling
        f.get();
    }
"
"    @Test(expected = CancellationException.class)
    public void testSetExceptionAfterUnsubscribe() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> f = o.toBlocking().toFuture();

        // cancel/unsubscribe
        f.cancel(true);

        try {
            cr.setException(new RuntimeException(""anException""));
        } catch (IllegalStateException e) {
            fail(""this should have done nothing as it was unsubscribed already"");
        }

        // expect CancellationException after cancelling
        f.get();
    }
"
"    @Test
    public void testUnsubscribeAfterSetResponse() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(""theResponse"");

        // unsubscribe after the value is sent
        v.cancel(true);

        // still get value as it was set before canceling
        assertEquals(""theResponse"", v.get());
    }
"
"    @Test
    public void testShutdown() {
        // other unit tests will probably have run before this so get the count
        int count = Factory.threadPools.size();

        HystrixThreadPool pool = Factory.getInstance(HystrixThreadPoolKey.Factory.asKey(""threadPoolFactoryTest""),
                HystrixThreadPoolProperties.Setter.getUnitTestPropertiesBuilder());

        assertEquals(count + 1, Factory.threadPools.size());
        assertFalse(pool.getExecutor().isShutdown());

        Factory.shutdown();

        // ensure all pools were removed from the cache
        assertEquals(0, Factory.threadPools.size());
        assertTrue(pool.getExecutor().isShutdown());
    }
"
"    @Test
    public void testShutdownWithWait() {
        // other unit tests will probably have run before this so get the count
        int count = Factory.threadPools.size();

        HystrixThreadPool pool = Factory.getInstance(HystrixThreadPoolKey.Factory.asKey(""threadPoolFactoryTest""),
                HystrixThreadPoolProperties.Setter.getUnitTestPropertiesBuilder());

        assertEquals(count + 1, Factory.threadPools.size());
        assertFalse(pool.getExecutor().isShutdown());

        Factory.shutdown(1, TimeUnit.SECONDS);

        // ensure all pools were removed from the cache
        assertEquals(0, Factory.threadPools.size());
        assertTrue(pool.getExecutor().isShutdown());
    }
"
"    @Test
    public void ensureThreadPoolInstanceIsTheOneRegisteredWithMetricsPublisherAndThreadPoolCache() throws IllegalAccessException, NoSuchFieldException {
        HystrixPlugins.getInstance().registerMetricsPublisher(new HystrixMetricsPublisher() {
            @Override
            public HystrixMetricsPublisherThreadPool getMetricsPublisherForThreadPool(HystrixThreadPoolKey threadPoolKey, HystrixThreadPoolMetrics metrics, HystrixThreadPoolProperties properties) {
                return new HystrixMetricsPublisherThreadPoolContainer(metrics);
            }
"
"    @Test(timeout = 2500)
    public void testUnsubscribeHystrixThreadPool() throws InterruptedException {
        // methods are package-private so can't test it somewhere else
        HystrixThreadPool pool = Factory.getInstance(HystrixThreadPoolKey.Factory.asKey(""threadPoolFactoryTest""),
                HystrixThreadPoolProperties.Setter.getUnitTestPropertiesBuilder());
        
        final AtomicBoolean interrupted = new AtomicBoolean();
        final CountDownLatch start = new CountDownLatch(1);
        final CountDownLatch end = new CountDownLatch(1);

        HystrixContextScheduler hcs = new HystrixContextScheduler(HystrixPlugins.getInstance().getConcurrencyStrategy(), pool);

        Scheduler.Worker w = hcs.createWorker();

        try {
            w.schedule(new Action0() {
                @Override
                public void call() {
                    start.countDown();
                    try {
                        try {
                            Thread.sleep(5000);
                        } catch (InterruptedException ex) {
                            interrupted.set(true);
                        }
                    } finally {
                        end.countDown();
                    }
                }
"
"    @Test
    public void testTimeoutRace() throws InterruptedException {
        final int NUM_TRIALS = 10;

        for (int i = 0; i < NUM_TRIALS; i++) {
            List<Observable<String>> observables = new ArrayList<Observable<String>>();
            HystrixRequestContext context = null;

            try {
                context = HystrixRequestContext.initializeContext();
                for (int j = 0; j < NUM_CONCURRENT_COMMANDS; j++) {
                    observables.add(new TestCommand().observe());
                }

                Observable<String> overall = Observable.merge(observables);

                List<String> results = overall.toList().toBlocking().first(); //wait for all commands to complete

                for (String s : results) {
                    if (s == null) {
                        System.err.println(""Received NULL!"");
                        throw new RuntimeException(""Received NULL"");
                    }
                }

                for (HystrixInvokableInfo<?> hi : HystrixRequestLog.getCurrentRequest().getAllExecutedCommands()) {
                    if (!hi.isResponseTimedOut()) {
                        System.err.println(""Timeout not found in executed command"");
                        throw new RuntimeException(""Timeout not found in executed command"");
                    }
                    if (hi.isResponseTimedOut() && hi.getExecutionEvents().size() == 1) {
                        System.err.println(""Missing fallback status!"");
                        throw new RuntimeException(""Missing fallback status on timeout."");
                    }
                }

            } catch (Exception e) {
                System.err.println(""Error: "" + e.getMessage());
                e.printStackTrace();
                throw new RuntimeException(e);
            } finally {
                System.out.println(HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
                if (context != null) {
                    context.shutdown();
                }
            }

            System.out.println(""*************** TRIAL "" + i + "" ******************"");
            System.out.println();
            Thread.sleep(50);
        }

        Hystrix.reset();
    }
"
"    @Test
    public void testEmptyStreamProducesEmptyDistributions() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""Collapser-Batch-Size-A"");
        stream = RollingCollapserBatchSizeDistributionStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().skip(10).take(10).subscribe(new Subscriber<CachedValuesHistogram>() {
            @Override
            public void onCompleted() {
                latch.countDown();
            }
"
"    @Test
    public void testBatches() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""Collapser-Batch-Size-B"");
        stream = RollingCollapserBatchSizeDistributionStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(10).subscribe(new Subscriber<CachedValuesHistogram>() {
            @Override
            public void onCompleted() {
                latch.countDown();
            }
"
"    @Test
    public void testBatchesAgeOut() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""Collapser-Batch-Size-B"");
        stream = RollingCollapserBatchSizeDistributionStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(30).subscribe(new Subscriber<CachedValuesHistogram>() {
            @Override
            public void onCompleted() {
                latch.countDown();
            }
"
"    @Test
    public void testEmptyStreamProducesZeros() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-A"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(10).subscribe(getSubscriber(latch));

        //no writes

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        assertEquals(0, stream.getLatest(HystrixEventType.Collapser.ADDED_TO_BATCH));
        assertEquals(0, stream.getLatest(HystrixEventType.Collapser.BATCH_EXECUTED));
        assertEquals(0, stream.getLatest(HystrixEventType.Collapser.RESPONSE_FROM_CACHE));
    }
"
"    @Test
    public void testCollapsed() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-B"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(10).subscribe(getSubscriber(latch));

        for (int i = 0; i < 3; i++) {
            CommandStreamTest.Collapser.from(key, i).observe();
        }

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.Collapser.values().length];
        expected[HystrixEventType.Collapser.BATCH_EXECUTED.ordinal()] = 1;
        expected[HystrixEventType.Collapser.ADDED_TO_BATCH.ordinal()] = 3;
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testCollapsedAndResponseFromCache() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-C"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(10).subscribe(getSubscriber(latch));

        for (int i = 0; i < 3; i++) {
            CommandStreamTest.Collapser.from(key, i).observe();
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
        }

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.Collapser.values().length];
        expected[HystrixEventType.Collapser.BATCH_EXECUTED.ordinal()] = 1;
        expected[HystrixEventType.Collapser.ADDED_TO_BATCH.ordinal()] = 3;
        expected[HystrixEventType.Collapser.RESPONSE_FROM_CACHE.ordinal()] = 6;
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testCollapsedAndResponseFromCacheAgeOutOfCumulativeWindow() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-D"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(30).subscribe(getSubscriber(latch));

        for (int i = 0; i < 3; i++) {
            CommandStreamTest.Collapser.from(key, i).observe();
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
        }

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.Collapser.values().length];
        expected[HystrixEventType.Collapser.BATCH_EXECUTED.ordinal()] = 1;
        expected[HystrixEventType.Collapser.ADDED_TO_BATCH.ordinal()] = 3;
        expected[HystrixEventType.Collapser.RESPONSE_FROM_CACHE.ordinal()] = 6;
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testEmptyStreamProducesZeros() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-A"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //no writes

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        assertFalse(hasData(stream.getLatest()));
    }
"
"    @Test
    public void testSingleSuccess() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-B"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.SUCCESS, 20);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.SUCCESS.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testSingleFailure() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-C"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.FAILURE, 20);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 1;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testSingleTimeout() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-D"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.TIMEOUT);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.TIMEOUT.ordinal()] = 1;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testSingleBadRequest() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-E"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.BAD_REQUEST);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.BAD_REQUEST.ordinal()] = 1;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testRequestFromCache() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-F"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd1 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 20);
        Command cmd2 = Command.from(groupKey, key, HystrixEventType.RESPONSE_FROM_CACHE);
        Command cmd3 = Command.from(groupKey, key, HystrixEventType.RESPONSE_FROM_CACHE);

        cmd1.observe();
        cmd2.observe();
        cmd3.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }

        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.SUCCESS.ordinal()] = 1;
        expected[HystrixEventType.RESPONSE_FROM_CACHE.ordinal()] = 2;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testShortCircuited() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-G"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //3 failures in a row will trip circuit.  let bucket roll once then submit 2 requests.
        //should see 3 FAILUREs and 2 SHORT_CIRCUITs and then 5 FALLBACK_SUCCESSes

        Command failure1 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20);
        Command failure2 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20);
        Command failure3 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20);

        Command shortCircuit1 = Command.from(groupKey, key, HystrixEventType.SUCCESS);
        Command shortCircuit2 = Command.from(groupKey, key, HystrixEventType.SUCCESS);

        failure1.observe();
        failure2.observe();
        failure3.observe();

        try {
            Thread.sleep(500);
        } catch (InterruptedException ie) {
            fail(ie.getMessage());
        }

        shortCircuit1.observe();
        shortCircuit2.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }

        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertTrue(shortCircuit1.isResponseShortCircuited());
        assertTrue(shortCircuit2.isResponseShortCircuited());
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 3;
        expected[HystrixEventType.SHORT_CIRCUITED.ordinal()] = 2;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 5;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testSemaphoreRejected() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-H"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //10 commands will saturate semaphore when called from different threads.
        //submit 2 more requests and they should be SEMAPHORE_REJECTED
        //should see 10 SUCCESSes, 2 SEMAPHORE_REJECTED and 2 FALLBACK_SUCCESSes

        List<Command> saturators = new ArrayList<Command>();

        for (int i = 0; i < 10; i++) {
            saturators.add(Command.from(groupKey, key, HystrixEventType.SUCCESS, 500, HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE));
        }

        Command rejected1 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0, HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE);
        Command rejected2 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0, HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE);

        for (final Command saturator : saturators) {
            new Thread(new HystrixContextRunnable(new Runnable() {
                @Override
                public void run() {
                    saturator.observe();
                }
"
"    @Test
    public void testThreadPoolRejected() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-I"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //10 commands will saturate threadpools when called concurrently.
        //submit 2 more requests and they should be THREADPOOL_REJECTED
        //should see 10 SUCCESSes, 2 THREADPOOL_REJECTED and 2 FALLBACK_SUCCESSes

        List<Command> saturators = new ArrayList<Command>();

        for (int i = 0; i < 10; i++) {
            saturators.add(Command.from(groupKey, key, HystrixEventType.SUCCESS, 500));
        }

        Command rejected1 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0);
        Command rejected2 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0);

        for (final Command saturator : saturators) {
            saturator.observe();
        }

        try {
            Thread.sleep(100);
        } catch (InterruptedException ie) {
            fail(ie.getMessage());
        }

        rejected1.observe();
        rejected2.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }

        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertTrue(rejected1.isResponseThreadPoolRejected());
        assertTrue(rejected2.isResponseThreadPoolRejected());
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.SUCCESS.ordinal()] = 10;
        expected[HystrixEventType.THREAD_POOL_REJECTED.ordinal()] = 2;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 2;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testFallbackFailure() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-J"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_FAILURE);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 1;
        expected[HystrixEventType.FALLBACK_FAILURE.ordinal()] = 1;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testFallbackMissing() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-K"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_MISSING);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 1;
        expected[HystrixEventType.FALLBACK_MISSING.ordinal()] = 1;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testFallbackRejection() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-L"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //fallback semaphore size is 5.  So let 5 commands saturate that semaphore, then
        //let 2 more commands go to fallback.  they should get rejected by the fallback-semaphore

        List<Command> fallbackSaturators = new ArrayList<Command>();
        for (int i = 0; i < 5; i++) {
            fallbackSaturators.add(Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_SUCCESS, 400));
        }

        Command rejection1 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_SUCCESS, 0);
        Command rejection2 = Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_SUCCESS, 0);

        for (Command saturator: fallbackSaturators) {
            saturator.observe();
        }

        try {
            Thread.sleep(70);
        } catch (InterruptedException ex) {
            fail(ex.getMessage());
        }

        rejection1.observe();
        rejection2.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 7;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 5;
        expected[HystrixEventType.FALLBACK_REJECTION.ordinal()] = 2;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 2;
        assertArrayEquals(expected, stream.getLatest());
    }
"
"    @Test
    public void testCancelled() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-M"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command toCancel = Command.from(groupKey, key, HystrixEventType.SUCCESS, 500);

        System.out.println(System.currentTimeMillis() + "" : "" + Thread.currentThread().getName() + "" : about to observe and subscribe"");
        Subscription s = toCancel.observe().
                doOnUnsubscribe(new Action0() {
                    @Override
                    public void call() {
                        System.out.println(System.currentTimeMillis() + "" : "" + Thread.currentThread().getName() + "" : UnSubscribe from command.observe()"");
                    }
"
"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.hero"", attachment.getContentType());
    }
"
"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.audio"", attachment.getContentType());
    }
"
"    @Test
    public void GetConversationReference() {
        Activity activity = createActivity();
        ConversationReference conversationReference = activity.getConversationReference();

        Assert.assertEquals(activity.getId(), conversationReference.getActivityId());
        Assert.assertEquals(activity.getFrom().getId(), conversationReference.getUser().getId());
        Assert.assertEquals(activity.getRecipient().getId(), conversationReference.getBot().getId());
        Assert.assertEquals(activity.getConversation().getId(), conversationReference.getConversation().getId());
        Assert.assertEquals(activity.getLocale(), conversationReference.getLocale());
        Assert.assertEquals(activity.getChannelId(), conversationReference.getChannelId());
        Assert.assertEquals(activity.getServiceUrl(), conversationReference.getServiceUrl());

        activity.setType(ActivityTypes.CONVERSATION_UPDATE);
        conversationReference = activity.getConversationReference();
        Assert.assertNull(conversationReference.getActivityId());

    }
"
"    @Test
    public void GetReplyConversationReference() {
        Activity activity = createActivity();

        ResourceResponse reply = new ResourceResponse();
        reply.setId(""1234"");

        ConversationReference conversationReference = activity.getReplyConversationReference(reply);

        Assert.assertEquals(reply.getId(), conversationReference.getActivityId());
        Assert.assertEquals(activity.getFrom().getId(), conversationReference.getUser().getId());
        Assert.assertEquals(activity.getRecipient().getId(), conversationReference.getBot().getId());
        Assert.assertEquals(activity.getConversation().getId(), conversationReference.getConversation().getId());
        Assert.assertEquals(activity.getLocale(), conversationReference.getLocale());
        Assert.assertEquals(activity.getChannelId(), conversationReference.getChannelId());
        Assert.assertEquals(activity.getServiceUrl(), conversationReference.getServiceUrl());
    }
"
"    @Test
    public void ApplyConversationReference_isIncoming() {
        Activity activity = createActivity();

        ConversationReference conversationReference = new ConversationReference();
        conversationReference.setChannelId(""cr_123"");
        conversationReference.setServiceUrl(""cr_serviceUrl"");
        ConversationAccount conversation = new ConversationAccount();
        conversation.setId(""cr_456"");
        conversationReference.setConversation(conversation);
        ChannelAccount userAccount = new ChannelAccount();
        userAccount.setId(""cr_abc"");
        conversationReference.setUser(userAccount);
        ChannelAccount botAccount = new ChannelAccount();
        botAccount.setId(""cr_def"");
        conversationReference.setBot(botAccount);
        conversationReference.setActivityId(""cr_12345"");
        // Intentionally oddly-cased to check that it isn't defaulted somewhere, but
        // tests stay in English
        conversationReference.setLocale(""en-uS"");

        activity.applyConversationReference(conversationReference, true);

        Assert.assertEquals(conversationReference.getChannelId(), activity.getChannelId());
        Assert.assertEquals(conversationReference.getLocale(), activity.getLocale());
        Assert.assertEquals(conversationReference.getServiceUrl(), activity.getServiceUrl());
        Assert.assertEquals(conversationReference.getConversation().getId(), activity.getConversation().getId());

        Assert.assertEquals(conversationReference.getUser().getId(), activity.getFrom().getId());
        Assert.assertEquals(conversationReference.getBot().getId(), activity.getRecipient().getId());
        Assert.assertEquals(conversationReference.getActivityId(), activity.getId());
    }
"
"    @Test
    public void ApplyConversationReference() {
        Activity activity = createActivity();

        ConversationReference conversationReference = new ConversationReference();
        conversationReference.setChannelId(""123"");
        conversationReference.setServiceUrl(""serviceUrl"");
        ConversationAccount conversation = new ConversationAccount();
        conversation.setId(""456"");
        conversationReference.setConversation(conversation);
        ChannelAccount userAccount = new ChannelAccount();
        userAccount.setId(""abc"");
        conversationReference.setUser(userAccount);
        ChannelAccount botAccount = new ChannelAccount();
        botAccount.setId(""def"");
        conversationReference.setBot(botAccount);
        conversationReference.setActivityId(""12345"");
        // Intentionally oddly-cased to check that it isn't defaulted somewhere, but
        // tests stay in English
        conversationReference.setLocale(""en-uS"");

        activity.applyConversationReference(conversationReference, false);

        Assert.assertEquals(conversationReference.getChannelId(), activity.getChannelId());
        Assert.assertEquals(conversationReference.getLocale(), activity.getLocale());
        Assert.assertEquals(conversationReference.getServiceUrl(), activity.getServiceUrl());
        Assert.assertEquals(conversationReference.getConversation().getId(), activity.getConversation().getId());

        Assert.assertEquals(conversationReference.getBot().getId(), activity.getFrom().getId());
        Assert.assertEquals(conversationReference.getUser().getId(), activity.getRecipient().getId());
        Assert.assertEquals(conversationReference.getActivityId(), activity.getReplyToId());
    }
"
"    @Test
    public void ApplyConversationReferenceOverload() {
        Activity activity = createActivity();

        ConversationReference conversationReference = new ConversationReference();
        conversationReference.setChannelId(""123"");
        conversationReference.setServiceUrl(""serviceUrl"");
        ConversationAccount conversation = new ConversationAccount();
        conversation.setId(""456"");
        conversationReference.setConversation(conversation);
        ChannelAccount userAccount = new ChannelAccount();
        userAccount.setId(""abc"");
        conversationReference.setUser(userAccount);
        ChannelAccount botAccount = new ChannelAccount();
        botAccount.setId(""def"");
        conversationReference.setBot(botAccount);
        conversationReference.setActivityId(""12345"");
        // Intentionally oddly-cased to check that it isn't defaulted somewhere, but
        // tests stay in English
        conversationReference.setLocale(""en-uS"");

        activity.applyConversationReference(conversationReference);

        Assert.assertEquals(conversationReference.getChannelId(), activity.getChannelId());
        Assert.assertEquals(conversationReference.getLocale(), activity.getLocale());
        Assert.assertEquals(conversationReference.getServiceUrl(), activity.getServiceUrl());
        Assert.assertEquals(conversationReference.getConversation().getId(), activity.getConversation().getId());

        Assert.assertEquals(conversationReference.getBot().getId(), activity.getFrom().getId());
        Assert.assertEquals(conversationReference.getUser().getId(), activity.getRecipient().getId());
        Assert.assertEquals(conversationReference.getActivityId(), activity.getReplyToId());
    }
"
"    @Test
    public void ApplyConversationReferenceOverloadAlternatePaths() {
        Activity activity = createActivity();

        ConversationReference conversationReference = new ConversationReference();
        conversationReference.setChannelId(""123"");
        conversationReference.setServiceUrl(""serviceUrl"");
        ConversationAccount conversation = new ConversationAccount();
        conversation.setId(""456"");
        conversationReference.setConversation(conversation);
        ChannelAccount userAccount = new ChannelAccount();
        userAccount.setId(""abc"");
        conversationReference.setUser(userAccount);
        ChannelAccount botAccount = new ChannelAccount();
        botAccount.setId(""def"");
        conversationReference.setBot(botAccount);
        conversationReference.setActivityId(null);
        conversationReference.setLocale(null);

        activity.applyConversationReference(conversationReference, false);

        Assert.assertEquals(conversationReference.getChannelId(), activity.getChannelId());
        Assert.assertEquals(""en-uS"", activity.getLocale());
        Assert.assertEquals(conversationReference.getServiceUrl(), activity.getServiceUrl());
        Assert.assertEquals(conversationReference.getConversation().getId(), activity.getConversation().getId());

        Assert.assertEquals(conversationReference.getBot().getId(), activity.getFrom().getId());
        Assert.assertEquals(conversationReference.getUser().getId(), activity.getRecipient().getId());
        Assert.assertEquals(conversationReference.getActivityId(), activity.getReplyToId());

        activity.applyConversationReference(conversationReference, true);

        Assert.assertEquals(conversationReference.getChannelId(), activity.getChannelId());
        Assert.assertEquals(""en-uS"", activity.getLocale());
        Assert.assertEquals(conversationReference.getServiceUrl(), activity.getServiceUrl());
        Assert.assertEquals(conversationReference.getConversation().getId(), activity.getConversation().getId());

        Assert.assertEquals(conversationReference.getUser().getId(), activity.getFrom().getId());
        Assert.assertEquals(conversationReference.getBot().getId(), activity.getRecipient().getId());
        Assert.assertEquals(conversationReference.getActivityId(), activity.getReplyToId());
    }
"
"    @Test
    public void CreateTraceAllowsNullRecipient() {
        Activity activity = createActivity();
        activity.setRecipient(null);
        Activity trace = activity.createTrace(""test"");

        Assert.assertNull(trace.getFrom().getId());
    }
"
"    @Test
    public void DeserializeActivity() throws IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();
        Activity activity = objectMapper.readValue(this.serializedActivity, Activity.class);

        Assert.assertNotNull(activity.getTimestamp());
        Assert.assertEquals(""b18a1c99-7a29-4801-ac0c-579f2c36d52c"", activity.getConversation().getId());
        Assert.assertNotNull(activity.getValue());
    }
"
"    @Test
    public void DeserializeActivityWithDifferentTimeZone() throws IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();
        Activity activity = objectMapper.readValue(this.serializedActivityWithDifferentTimeZone, Activity.class);

        Assert.assertNotNull(activity.getTimestamp());
        Assert.assertEquals(""b18a1c99-7a29-4801-ac0c-579f2c36d52c"", activity.getConversation().getId());
        Assert.assertNotNull(activity.getValue());
    }
"
"    @Test
    public void GetInformationForMicrosoftTeams() throws JsonProcessingException, IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();
        Activity activity = objectMapper.readValue(ActivityTest.serializedActivityFromTeams, Activity.class);
        Assert.assertEquals(""19:123cb42aa5a0a7e56f83@thread.skype"", activity.teamsGetChannelId());
        Assert.assertEquals(""19:104f2cb42aa5a0a7e56f83@thread.skype"", activity.teamsGetTeamId());
        Assert.assertEquals(true, activity.isTeamsActivity());

        activity = objectMapper.readValue(ActivityTest.serializedActivityFromTeamsWithoutTeamsChannelIdorTeamId,
                Activity.class);

        Assert.assertEquals(""channel_id"", activity.teamsGetChannelId());
        Assert.assertEquals(""team_id"", activity.teamsGetTeamId());

        TeamsChannelData teamsChannelData = activity.getChannelData(TeamsChannelData.class);
        Assert.assertEquals(""channel_id"", teamsChannelData.getChannel().getId());
        Assert.assertEquals(""channel_name"", teamsChannelData.getChannel().getName());
        Assert.assertEquals(""team_id"", teamsChannelData.getTeam().getId());
        Assert.assertEquals(""team_name"", teamsChannelData.getTeam().getName());
        Assert.assertEquals(""aad_groupid"", teamsChannelData.getTeam().getAadGroupId());
        Assert.assertEquals(true, teamsChannelData.getNotification().getAlert());
        Assert.assertEquals(""teamMemberAdded"", teamsChannelData.getEventType());
        Assert.assertEquals(""tenant_id"", teamsChannelData.getTenant().getId());
    }
"
"    @Test
    public void GetTeamsChannelIdBadChannelData() {
        Activity activity = new Activity();
        activity.setChannelData(""badChannelData"");
        String channelId = activity.teamsGetChannelId();
        Assert.assertNull(channelId);
    }
"
"    @Test
    public void GetTeamsTeamIdBadChannelData() {
        Activity activity = new Activity();
        activity.setChannelData(""badChannelData"");
        String channelId = activity.teamsGetTeamId();
        Assert.assertNull(channelId);
    }
"
"    @Test
    public void GetTeamsTeamIdNullChannelData() {
        Activity activity = new Activity();
        String channelId = activity.teamsGetTeamId();
        Assert.assertNull(channelId);
    }
"
"    @Test
    public void GetTeamsGetInfo() throws JsonProcessingException, IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();

        Activity activity = objectMapper.readValue(
            ActivityTest.serializedActivityFromTeamsWithoutTeamsChannelIdorTeamId, Activity.class);

        TeamInfo teamsInfo = activity.teamsGetTeamInfo();
        Assert.assertNotNull(teamsInfo);
    }
"
"    @Test
    public void GetTeamsGetInfoBadChannelData() {
        Activity activity = new Activity();
        activity.setChannelData(""badChannelData"");
        TeamInfo teamInfo = activity.teamsGetTeamInfo();
        Assert.assertNull(teamInfo);
    }
"
"    @Test
    public void TeamsNotifyUser() throws JsonProcessingException, IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();
        Activity activity = objectMapper.readValue(
            ActivityTest.serializedActivityFromTeamsWithoutNotificationTeamsChannelIdOrTeamId, Activity.class);

        TeamsChannelData channelData = activity.teamsGetChannelData();
        Assert.assertNull(channelData.getNotification());
        activity.teamsNotifyUser();
        Assert.assertNotNull(activity.teamsGetChannelData().getNotification());
    }
"
"    @Test
    public void TeamsNotifyUserBadChannelData() throws JsonProcessingException, IOException {
        Activity activity = new Activity();
        activity.setChannelData(""badChannelData"");

        TeamsChannelData channelData = activity.teamsGetChannelData();
        Assert.assertNull(channelData);
        activity.teamsNotifyUser();
        Assert.assertNotNull(activity.teamsGetChannelData().getNotification());
    }
"
"    @Test
    public void TeamsNotifyUserAlertInMeeting() throws JsonProcessingException, IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();
        Activity activity = objectMapper.readValue(
            ActivityTest.serializedActivityFromTeamsWithoutNotificationTeamsChannelIdOrTeamId, Activity.class);

        TeamsChannelData channelData = activity.teamsGetChannelData();
        Assert.assertNull(channelData.getNotification());
        activity.teamsNotifyUser(true, ""externalresourceURL"");
        Assert.assertNotNull(activity.teamsGetChannelData().getNotification());
        Assert.assertEquals(activity.teamsGetChannelData().getNotification().getExternalResourceUrl(),
                            ""externalresourceURL"");
        Assert.assertTrue(activity.teamsGetChannelData().getNotification().getAlertInMeeting());
    }
"
"    @Test
    public void TeamsNotifyUserAlertInMeetingBadChannelData() throws JsonProcessingException, IOException {
        Activity activity = new Activity();
        activity.setChannelData(""badChannelData"");

        Assert.assertNull(activity.teamsGetChannelData());
        activity.teamsNotifyUser(true, ""externalresourceURL"");
        Assert.assertNotNull(activity.teamsGetChannelData().getNotification());
        Assert.assertEquals(activity.teamsGetChannelData().getNotification().getExternalResourceUrl(),
                            ""externalresourceURL"");
        Assert.assertTrue(activity.teamsGetChannelData().getNotification().getAlertInMeeting());
    }
"
"    @Test
    public void TeamsGetMeetingInfoNull() throws JsonProcessingException, IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.findAndRegisterModules();
        Activity activity = objectMapper.readValue(
            ActivityTest.serializedActivityFromTeamsWithoutNotificationTeamsChannelIdOrTeamId, Activity.class);

        TeamsMeetingInfo meetingInfo = activity.teamsGetMeetingInfo();
        Assert.assertNull(meetingInfo);
    }
"
"    @Test
    public void TeamsGetMeetingInfo() throws JsonProcessingException, IOException {
        Activity activity = new Activity();
        TeamsChannelData channelData = new TeamsChannelData();
        TeamsMeetingInfo meeting = new TeamsMeetingInfo();
        meeting.setId(""meetingId"");
        channelData.setMeeting(meeting);
        activity.setChannelData(channelData);

        TeamsMeetingInfo meetingInfo = activity.teamsGetMeetingInfo();
        Assert.assertNotNull(meetingInfo);
        Assert.assertEquals(meetingInfo.getId(), ""meetingId"");
    }
"
"    @Test
    public void TeamsGetMeetingInfoBadChannelData() throws JsonProcessingException, IOException {
        Activity activity = new Activity();
        activity.setChannelData(""badChannelData"");

        TeamsMeetingInfo meetingInfo = activity.teamsGetMeetingInfo();
        Assert.assertNull(meetingInfo);
    }
"
"    @Test
    public void CreateMessageActivity() {
        Activity activity = Activity.createMessageActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.MESSAGE);
    }
"
"    @Test
    public void CreateContactRelationUpdateActivity() {
        Activity activity = Activity.createContactRelationUpdateActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.CONTACT_RELATION_UPDATE);
    }
"
"    @Test
    public void CreateConversationUpdateActivity() {
        Activity activity = Activity.createConversationUpdateActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.CONVERSATION_UPDATE);
    }
"
"    @Test
    public void CreateTypingActivity() {
        Activity activity = Activity.createTypingActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.TYPING);
    }
"
"    @Test
    public void CreateHandoffActivity() {
        Activity activity = Activity.createHandoffActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.HANDOFF);
    }
"
"    @Test
    public void CreateEndOfConversationActivity() {
        Activity activity = Activity.createEndOfConversationActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.END_OF_CONVERSATION);
    }
"
"    @Test
    public void CreateEventActivity() {
        Activity activity = Activity.createEventActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.EVENT);
    }
"
"    @Test
    public void CreateInvokeActivity() {
        Activity activity = Activity.createInvokeActivity();

        Assert.assertEquals(activity.getType(), ActivityTypes.INVOKE);
    }
"
"    @Test
    public void CreateTraceActivity() {
        String name = ""test-activity"";
        String valueType = ""string"";
        String value = ""test-value"";
        String label = ""test-label"";

        Activity activity = Activity.createTraceActivity(name, valueType, value, label);

        Assert.assertEquals(activity.getType(), ActivityTypes.TRACE);
        Assert.assertEquals(activity.getName(), name);
        Assert.assertEquals(activity.getValueType(), valueType);
        Assert.assertEquals(activity.getValue(), value);
        Assert.assertEquals(activity.getLabel(), label);

        Activity secondActivity = Activity.createTraceActivity(name);
        Assert.assertEquals(secondActivity.getType(), ActivityTypes.TRACE);
        Assert.assertEquals(secondActivity.getName(), name);

        Activity thirdActivity = Activity.createTraceActivity(name, null, value, label);
        Assert.assertEquals(thirdActivity.getType(), ActivityTypes.TRACE);
        Assert.assertEquals(thirdActivity.getName(), name);

        Assert.assertTrue(thirdActivity.isType(ActivityTypes.TRACE));
    }
"
"    @Test
    public void CreateTraceActivityWithoutValueType() {
        String name = ""test-activity"";
        String value = ""test-value"";
        String label = ""test-label"";

        Activity activity = Activity.createTraceActivity(name, null, value, label);

        Assert.assertEquals(activity.getType(), ActivityTypes.TRACE);
        Assert.assertEquals(activity.getValueType(), value.getClass().getTypeName());
        Assert.assertEquals(activity.getLabel(), label);
    }
"
"    @Test
    public void CreateReply() {
        Activity activity = createActivity();

        String text = ""test-reply"";
        String locale = ""en-us"";

        Activity reply = activity.createReply(text, locale);

        Assert.assertEquals(reply.getType(), ActivityTypes.MESSAGE);
        Assert.assertEquals(reply.getText(), text);
        Assert.assertEquals(reply.getLocale(), locale);

        activity.setFrom(null);
        activity.setRecipient(null);
        activity.setConversation(null);
        Activity reply2 = activity.createReply(text);
        Assert.assertEquals(reply2.getType(), ActivityTypes.MESSAGE);
        Assert.assertEquals(reply2.getText(), text);
        Assert.assertEquals(reply2.getLocale(), ""en-uS"");
        Assert.assertTrue(reply2.getFrom() != null);
        Assert.assertTrue(reply2.getRecipient() != null);
        Assert.assertTrue(reply2.getConversation() != null);
    }
"
"    @Test
    public void CreateReplyWithoutArguments() {
        Activity activity = createActivity();

        Activity reply = activity.createReply();

        Assert.assertEquals(reply.getType(), ActivityTypes.MESSAGE);
        Assert.assertEquals(reply.getText(), """");
        Assert.assertEquals(reply.getLocale(), activity.getLocale());
    }
"
"    @Test
    public void HasContentIsFalseWhenActivityTextHasNoContent() {
        Activity activity = createActivity();

        boolean result = activity.hasContent();

        Assert.assertEquals(result, false);
    }
"
"    @Test
    public void HasContentIsTrueWhenActivityTextHasContent() {
        Activity activity = createActivity();

        activity.setText(""test-text"");

        boolean result = activity.hasContent();

        Assert.assertEquals(result, true);
    }
"
"    @Test
    public void HasContentIsTrueWhenActivitySummaryContent() {
        Activity activity = createActivity();

        activity.setText(null);
        activity.setSummary(""test-summary"");

        boolean result = activity.hasContent();

        Assert.assertEquals(result, true);
    }
"
"    @Test
    public void HasContentIsTrueWhenActivityAttachmentsHaveContent() {
        Activity activity = createActivity();
        ArrayList<Attachment> attachments = new ArrayList<>();
        attachments.add(CreateAttachment());

        activity.setText(null);
        activity.setSummary(null);
        activity.setAttachments(attachments);

        boolean result = activity.hasContent();

        Assert.assertEquals(result, true);
    }
"
"    @Test
    public void HasContentIsTrueWhenActivityChannelDataHasContent() {
        Activity activity = createActivity();

        activity.setText(null);
        activity.setSummary(null);
        activity.setChannelData(""test-channelData"");

        boolean result = activity.hasContent();

        Assert.assertEquals(result, true);
    }
"
"    @Test
    public void GetMentions() {
        ArrayList<Entity> mentions = new ArrayList<Entity>();

        Entity mentionEntity = new Entity();
        mentionEntity.setType(""mention"");
        mentions.add(mentionEntity);
        Entity reactionEntity = new Entity();
        reactionEntity.setType(""reaction"");
        mentions.add(reactionEntity);

        Activity activity = createActivity();

        activity.setEntities(mentions);

        List<Mention> mentionsResult = activity.getMentions();

        Assert.assertEquals(mentionsResult.size(), 1);
        Assert.assertEquals(mentionsResult.get(0).getType(), ""mention"");
    }
"
"    @Test
    public void GetMentionsNull() {
        Activity activity = createActivity();
        activity.setEntities(null);
        Assert.assertTrue(activity.getMentions() != null);
    }
"
"    @Test
    public void CreateTraceForConversationUpdateActivity() {
        Activity activity = createActivity();
        activity.setType(ActivityTypes.CONVERSATION_UPDATE);
        Activity trace = activity.createTrace(""test"");
        Assert.assertNull(trace.getReplyToId());
    }
"
"    @Test
    public void CreateReplyForConversationUpdateActivity() {
        Activity activity = createActivity();
        activity.setType(ActivityTypes.CONVERSATION_UPDATE);
        Activity reply = activity.createReply(""test"");
        Assert.assertNull(reply.getReplyToId());
    }
"
"    @Test
    public void CreateTrace() {
        Activity activity = createActivity();

        String name = ""test-activity"";
        String value = ""test-value"";
        String valueType = ""string"";
        String label = ""test-label"";

        Activity trace = activity.createTrace(name, value, valueType, label);

        Assert.assertEquals(trace.getType(), ActivityTypes.TRACE);
        Assert.assertEquals(trace.getName(), name);
        Assert.assertEquals(trace.getValue(), value);
        Assert.assertEquals(trace.getValueType(), valueType);
        Assert.assertEquals(trace.getLabel(), label);

        Activity secondActivity = createActivity();
        secondActivity.setRecipient(null);
        secondActivity.setFrom(null);
        Activity secondTrace = secondActivity.createTrace(name, value, null, label);
        Assert.assertEquals(secondTrace.getType(), ActivityTypes.TRACE);
        Assert.assertEquals(secondTrace.getName(), name);
        Assert.assertEquals(secondTrace.getValue(), value);
        Assert.assertEquals(secondTrace.getValueType(), value.getClass().getTypeName());
        Assert.assertEquals(secondTrace.getLabel(), label);
        Assert.assertTrue(secondTrace.getRecipient() != null);
        Assert.assertTrue(secondTrace.getFrom() != null);
    }
"
"    @Test
    public void IsFromStreamingConnection() {
        ArrayList<String> nonStreaming = new ArrayList<>();
        nonStreaming.add(""http://yayay.com"");
        nonStreaming.add(""https://yayay.com"");
        nonStreaming.add(""HTTP://yayay.com"");
        nonStreaming.add(""HTTPS://yayay.com"");

        ArrayList<String> streaming = new ArrayList<>();
        streaming.add(""urn:botframework:WebSocket:wss://beep.com"");
        streaming.add(""urn:botframework:WebSocket:http://beep.com"");
        streaming.add(""URN:botframework:WebSocket:wss://beep.com"");
        streaming.add(""URN:botframework:WebSocket:http://beep.com"");

        Activity activity = createActivity();
        activity.setServiceUrl(null);

        Assert.assertFalse(activity.isFromStreamingConnection());

        nonStreaming.forEach(s ->
        {
            activity.setServiceUrl(s);
            Assert.assertFalse(activity.isFromStreamingConnection());
        });

        streaming.forEach(s ->
        {
            activity.setServiceUrl(s);
            Assert.assertTrue(activity.isFromStreamingConnection());
        });
    }
"
"    @Test
    public void ActivityCloneTest() throws JsonProcessingException {
        Activity activity = new Activity(ActivityTypes.MESSAGE);
        activity.setAction(""TestAction"");

        Attachment attachment = new Attachment();
        attachment.setContentType(""testContentType"");
        attachment.setContentUrl(""testContentUrl"");
        attachment.setContent(""testContent"");
        attachment.setName(""testName"");
        attachment.setThumbnailUrl(""testThumbnailUrl"");
        attachment.setProperties(""testProperty"", getTestNode());
        activity.setAttachment(attachment);

        activity.setCallerId(""testCallerId"");
        activity.setChannelData(""testChannelData"");
        activity.setCode(EndOfConversationCodes.BOT_TIMED_OUT);

        ConversationAccount conversation = new ConversationAccount(""testConversation"");
        activity.setConversation(conversation);

        activity.setDeliveryMode(""testDeliveryMode"");

        List<Entity> entityList = new ArrayList<Entity>();
        Entity entity1 = new Entity();
        entity1.setType(""testEntity"");
        entityList.add(entity1);
        activity.setEntities(entityList);

        LocalDateTime expiration = LocalDateTime.now();
        activity.setExpiration(expiration);

        ChannelAccount fromChannel = new ChannelAccount(""fromChannel"");
        activity.setFrom(fromChannel);

        activity.setHistoryDisclosed(true);
        activity.setId(""testId"");
        activity.setImportance(""testImportance"");
        activity.setInputHint(InputHints.ACCEPTING_INPUT);
        activity.setLabel(""testLabel"");

        List<String> listen = new ArrayList<String>();
        listen.add(""listen1"");
        listen.add(""listen2"");
        activity.setListenFor(listen);

        activity.setLocalTimeZone(""testLocalTimeZone"");
        OffsetDateTime offsetDateTime = OffsetDateTime.now();
        activity.setLocalTimestamp(offsetDateTime);
        activity.setLocale(""testLocale"");

        List<ChannelAccount> membersAdded = new ArrayList<ChannelAccount>();
        ChannelAccount firstMember = new ChannelAccount(""firstMember"");
        ChannelAccount secondMember = new ChannelAccount(""secondMember"");
        membersAdded.add(firstMember);
        membersAdded.add(secondMember);
        activity.setMembersAdded(membersAdded);

        List<ChannelAccount> membersRemoved = new ArrayList<ChannelAccount>();
        ChannelAccount firstMemberRemoved = new ChannelAccount(""firstMember"");
        ChannelAccount secondMemberRemoved = new ChannelAccount(""secondMember"");
        membersRemoved.add(firstMemberRemoved);
        membersRemoved.add(secondMemberRemoved);
        activity.setMembersRemoved(membersRemoved);

        List<Mention> mentions = new ArrayList<Mention>();
        Mention firstMention = new Mention();
        firstMention.setText(""testTest"");
        firstMention.setMentioned(firstMember);
        Mention secondMention = new Mention();
        secondMention.setText(""testTest"");
        secondMention.setMentioned(firstMember);
        mentions.add(secondMention);
        activity.setMentions(mentions);

        activity.setName(""testName"");
        activity.setProperties(""testProperty"", getTestNode());

        List<MessageReaction> reactionsAdded = new ArrayList<MessageReaction>();
        MessageReaction firstReaction = new MessageReaction();
        firstReaction.setType(""testType"");
        reactionsAdded.add(firstReaction);
        MessageReaction secondReaction = new MessageReaction();
        secondReaction.setType(""testType"");
        reactionsAdded.add(secondReaction);
        activity.setReactionsAdded(reactionsAdded);

        List<MessageReaction> reactionsRemoved = new ArrayList<MessageReaction>();
        MessageReaction firstReactionRemoved = new MessageReaction();
        firstReactionRemoved.setType(""testType"");
        reactionsRemoved.add(firstReactionRemoved);
        MessageReaction secondReactionRemoved = new MessageReaction();
        secondReactionRemoved.setType(""testType"");
        reactionsRemoved.add(secondReactionRemoved);
        activity.setReactionsRemoved(reactionsRemoved);

        ChannelAccount recipientRemoved = new ChannelAccount();
        recipientRemoved.setId(""testRecipient"");
        activity.setRecipient(recipientRemoved);

        ConversationReference relatesToReference = new ConversationReference();
        relatesToReference.setActivityId(""testActivityId"");
        activity.setRelatesTo(relatesToReference);

        activity.setReplyToId(""testReplyToId"");
        activity.setServiceUrl(""testServiceUrl"");
        activity.setText(""testText"");
        activity.setTextFormat(TextFormatTypes.MARKDOWN);

        List<TextHighlight> textHighlights = new ArrayList<TextHighlight>();
        TextHighlight firstTextHighlight = new TextHighlight();
        firstTextHighlight.setText(""testText"");
        textHighlights.add(firstTextHighlight);
        TextHighlight secondTextHighlight = new TextHighlight();
        secondTextHighlight.setText(""testText"");
        textHighlights.add(secondTextHighlight);
        activity.setTextHighlights(textHighlights);

        OffsetDateTime timestamp = OffsetDateTime.now();
        activity.setTimestamp(timestamp);

        activity.setTopicName(""testTopicName"");
        activity.setType(""testType"");
        activity.setValue(""testValue"");
        activity.setValueType(""testValueType"");

        Activity clonedActivity = Activity.clone(activity);

        Assert.assertEquals(activity.getAction(), clonedActivity.getAction());
        Assert.assertEquals(activity.getCallerId(), clonedActivity.getCallerId());
        Assert.assertEquals(activity.getChannelData(), clonedActivity.getChannelData());
        Assert.assertEquals(activity.getDeliveryMode(), clonedActivity.getDeliveryMode());
        Assert.assertEquals(activity.getId(), clonedActivity.getId());
        Assert.assertEquals(activity.getImportance(), clonedActivity.getImportance());
        Assert.assertEquals(activity.getLabel(), clonedActivity.getLabel());
        Assert.assertEquals(activity.getLocalTimezone(), clonedActivity.getLocalTimezone());
        Assert.assertEquals(activity.getLocale(), clonedActivity.getLocale());
        Assert.assertEquals(activity.getName(), clonedActivity.getName());
        Assert.assertEquals(activity.getReplyToId(), clonedActivity.getReplyToId());
        Assert.assertEquals(activity.getServiceUrl(), clonedActivity.getServiceUrl());
        Assert.assertEquals(activity.getSpeak(), clonedActivity.getSpeak());
        Assert.assertEquals(activity.getSummary(), clonedActivity.getSummary());
        Assert.assertEquals(activity.getText(), clonedActivity.getText());
        Assert.assertEquals(activity.getTopicName(), clonedActivity.getTopicName());
        Assert.assertEquals(activity.getType(), clonedActivity.getType());
        Assert.assertEquals(activity.getValue(), clonedActivity.getValue());
        Assert.assertEquals(activity.getValueType(), clonedActivity.getValueType());
        Assert.assertEquals(activity.getAttachmentLayout(), clonedActivity.getAttachmentLayout());
        Assert.assertEquals(activity.getAttachments().get(0).getName(),
                            clonedActivity.getAttachments().get(0).getName());
        Assert.assertEquals(activity.getChannelData(ChannelAccount.class).getId(),
                            clonedActivity.getChannelData(ChannelAccount.class).getId());
        Assert.assertEquals(activity.getCode(), clonedActivity.getCode());
        Assert.assertEquals(activity.getConversation().getName(), clonedActivity.getConversation().getName());
        Assert.assertEquals(activity.getConversationReference().getChannelId(),
                            clonedActivity.getConversationReference().getChannelId());
        Assert.assertEquals(activity.getEntities().get(0).getType(), clonedActivity.getEntities().get(0).getType());
        Assert.assertEquals(activity.getExpiration(), clonedActivity.getExpiration());
        Assert.assertEquals(activity.getFrom().getId(), clonedActivity.getFrom().getId());
        Assert.assertEquals(activity.getInputHint(), clonedActivity.getInputHint());
        Assert.assertEquals(activity.getListenFor(), clonedActivity.getListenFor());
        Assert.assertEquals(activity.getLocalTimestamp(), clonedActivity.getLocalTimestamp());
        Assert.assertEquals(activity.getMembersAdded().get(0).getId(), clonedActivity.getMembersAdded().get(0).getId());
        Assert.assertEquals(activity.getMembersRemoved().get(0).getId(),
                            clonedActivity.getMembersRemoved().get(0).getId());
        Assert.assertEquals(activity.getMentions().get(0).getText(), clonedActivity.getMentions().get(0).getText());
        Assert.assertEquals(activity.getProperties(), clonedActivity.getProperties());
        Assert.assertEquals(activity.getReactionsAdded().get(0).getType(),
                            clonedActivity.getReactionsAdded().get(0).getType());
        Assert.assertEquals(activity.getReactionsRemoved().get(0).getType(),
                            clonedActivity.getReactionsRemoved().get(0).getType());
        Assert.assertEquals(activity.getRecipient().getId(), clonedActivity.getRecipient().getId());
        Assert.assertEquals(activity.getRelatesTo().getActivityId(), clonedActivity.getRelatesTo().getActivityId());
        // add activity.getReplyConversationReference(reply)
        Assert.assertEquals(activity.getSuggestedActions(), clonedActivity.getSuggestedActions());
        Assert.assertEquals(activity.getTextFormat(), clonedActivity.getTextFormat());
        Assert.assertEquals(activity.getTextHighlights(), clonedActivity.getTextHighlights());
        Assert.assertEquals(activity.getTimestamp(), clonedActivity.getTimestamp());
    }
"
"    @Test
    public void EnsureCloneAddsIdIfMissing() {
        Activity testActivity = new Activity(ActivityTypes.COMMAND);
        Assert.assertTrue(testActivity.getId() == null);
        Activity clonedActivity = Activity.clone(testActivity);
        Assert.assertTrue(clonedActivity.getId() != null);
    }
"
"    @Test
    public void TryGetChannelData() {
        Activity activity = createActivity();
        ResultPair<TeamsChannelData> channelData = activity.tryGetChannelData(
            TeamsChannelData.class
        );

        activity.setChannelData(new TeamsChannelData());
        channelData = activity.tryGetChannelData(
            TeamsChannelData.class
        );
        Assert.assertTrue(channelData.getLeft());

        activity.setChannelData(null);
        Assert.assertNull(activity.teamsGetChannelData());
    }
"
"    @Test
    public void TryGetChannelDataBadChannelData() {
        Activity activity = createActivity();
        activity.setChannelData(""badChannelData"");
        ResultPair<TeamsChannelData> channelData = activity.tryGetChannelData(
            TeamsChannelData.class
        );
        Assert.assertFalse(channelData.getLeft());
        Assert.assertNull(channelData.getRight());
    }
"
"    @Test
    public void RemoveRecipientMention() {
        Activity activity = createActivity();
        activity.setText(""<at>firstName</at> lastName\n"");
        String expectedStrippedName = ""lastName"";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);

        String strippedActivityText = activity.removeRecipientMention();
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
"
"    @Test
    public void RemoveRecipientMentionImmutable() {
        Activity activity = createActivity();
        activity.setText(""<at>firstName</at> lastName\n"");
        String expectedStrippedName = ""lastName"";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);

        String strippedActivityText = Activity.removeRecipientMentionImmutable(activity);
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
"
"    @Test
    public void RemoveRecipientMentionNoRecipient() {
        Activity activity = createActivity();
        activity.setText(""<at>firstName</at> lastName\n"");
        String expectedStrippedName = ""<at>firstName</at> lastName\n"";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);
        activity.setRecipient(null);

        String strippedActivityText = activity.removeRecipientMention();
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
"
"    @Test
    public void RemoveRecipientMentionImmutableNoRecipient() {
        Activity activity = createActivity();
        activity.setText(""<at>firstName</at> lastName\n"");
        String expectedStrippedName = ""<at>firstName</at> lastName\n"";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);
        activity.setRecipient(null);

        String strippedActivityText = Activity.removeRecipientMentionImmutable(activity);
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
"
"    @Test
    public void RemoveRecipientMentionText() {
        Activity activity = createActivity();
        activity.setText(""<at>firstName</at> lastName\n"");
        String expectedStrippedName = ""<at>firstName</at>"";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        mention.setText(""lastName"");
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);

        String strippedActivityText = activity.removeRecipientMention();
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
"
"    @Test
    public void RemoveRecipientMentionTextNoId() {
        Activity activity = createActivity();
        activity.setText(""<at>firstName</at> lastName\n"");
        String expectedStrippedName = ""<at>firstName</at> lastName\n"";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        mention.setText(""lastName"");
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);

        String strippedActivityText = Activity.removeMentionTextImmutable(activity, null);
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
"
"    @Test
    public void RemoveRecipientMentionTextNoText() {
        Activity activity = createActivity();
        activity.setText("""");
        String expectedStrippedName = """";

        List<Mention> mentionList = new ArrayList<Mention>();
        Mention mention = new Mention();
        mention.setText(""lastName"");
        ChannelAccount channelAccount = new ChannelAccount();
        channelAccount.setId(activity.getRecipient().getId());
        channelAccount.setName(""firstName"");
        mention.setMentioned(channelAccount);
        mentionList.add(mention);
        activity.setMentions(mentionList);

        String strippedActivityText = Activity.removeMentionTextImmutable(activity, ""lastName"");
        Assert.assertEquals(strippedActivityText, expectedStrippedName);
    }
"
"    @Test
    public void IsActivity() {
        class MyActivity extends Activity {
            @Override
            public boolean isActivity(String activityType) {
                return super.isActivity(activityType);
            }
"
"    @Test
    public void IsActivityNoType() {
        class MyActivity extends Activity {
            @Override
            public boolean isActivity(String activityType) {
                return super.isActivity(activityType);
            }
"
"    @Test
    public void IsActivityExtendedType() {
        class MyActivity extends Activity {
            @Override
            public boolean isActivity(String activityType) {
                return super.isActivity(activityType);
            }
"
"    @Test
    public void IsActivityExtendedTypeNoMatch() {
        class MyActivity extends Activity {
            @Override
            public boolean isActivity(String activityType) {
                return super.isActivity(activityType);
            }
"
"    @Test
    public void IsActivityNoMatch() {
        class MyActivity extends Activity {
            @Override
            public boolean isActivity(String activityType) {
                return super.isActivity(activityType);
            }
"
"    @Test
    public void IsActivityShorterTypeName() {
        class MyActivity extends Activity {
            @Override
            public boolean isActivity(String activityType) {
                return super.isActivity(activityType);
            }
"
"    @Test
    public void TestPropertySetterGetter() {
        MediaCard mediaCard = new MediaCard();
        mediaCard.setAspect(""aspect"");
        mediaCard.setAutoloop(true);
        mediaCard.setAutostart(true);

        List<CardAction> buttons = new ArrayList<CardAction>();
        CardAction cardAction1 = new CardAction(ActionTypes.CALL, ""test1"");
        CardAction cardAction2 = new CardAction(ActionTypes.DOWNLOAD_FILE, ""test2"");
        buttons.add(cardAction1);
        buttons.add(cardAction2);
        mediaCard.setButtons(buttons);

        mediaCard.setDuration(""duration"");

        ThumbnailUrl thumbnailUrl = new ThumbnailUrl();
        thumbnailUrl.setAlt(""alt"");
        thumbnailUrl.setUrl(""testUrl"");
        mediaCard.setImage(thumbnailUrl);

        mediaCard.setShareable(true);
        mediaCard.setSubtitle(""subTitle"");
        mediaCard.setText(""text"");
        mediaCard.setTitle(""title"");
        mediaCard.setValue(""value"");

        Assert.assertEquals(mediaCard.getAspect(), ""aspect"");
        Assert.assertEquals(mediaCard.getAutoloop(), true);
        Assert.assertEquals(mediaCard.getAutostart(), true);
        Assert.assertEquals(mediaCard.getButtons().size(), 2);
        Assert.assertEquals(mediaCard.getButtons().get(0).getType(), ActionTypes.CALL);
        Assert.assertEquals(mediaCard.getButtons().get(0).getTitle(), ""test1"");
        Assert.assertEquals(mediaCard.getButtons().get(1).getType(), ActionTypes.DOWNLOAD_FILE);
        Assert.assertEquals(mediaCard.getButtons().get(1).getTitle(), ""test2"");
        Assert.assertEquals(mediaCard.getDuration(), ""duration"");
        Assert.assertEquals(mediaCard.getImage().getUrl(), ""testUrl"");
        Assert.assertEquals(mediaCard.getImage().getAlt(), ""alt"");
        Assert.assertEquals(mediaCard.getShareable(), true);
        Assert.assertEquals(mediaCard.getSubtitle(), ""subTitle"");
        Assert.assertEquals(mediaCard.getText(), ""text"");
        Assert.assertEquals(mediaCard.getTitle(), ""title"");
        Assert.assertEquals(mediaCard.getValue(), ""value"");
    }
"
"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.receipt"", attachment.getContentType());
    }
"
"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.signin"", attachment.getContentType());
    }
"
"    @Test
    public void TestMessageActionPayloadConstructor(){
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        Assert.assertNotNull(messageActionsPayload);
    }
"
"    @Test
    public void TestGetId(){
        String id = ""testId"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setId(id);
        String result = messageActionsPayload.getId();

        Assert.assertEquals(result, id);
    }
"
"    @Test
    public void TestGetReplyToId(){
        String replyToId = ""testReplyToId"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setReplyToId(replyToId);
        String result = messageActionsPayload.getReplyToId();

        Assert.assertEquals(result, replyToId);
    }
"
"    @Test
    public void TestGetMessageType(){
        String messageType = ""testMessageType"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setMessageType(messageType);
        String result = messageActionsPayload.getMessageType();

        Assert.assertEquals(result, messageType);
    }
"
"    @Test
    public void TestGetCreatedDateTime(){
        String createdDateTime = ""2000-01-01"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setCreatedDateTime(createdDateTime);
        String result = messageActionsPayload.getCreatedDateTime();

        Assert.assertEquals(result, createdDateTime);
    }
"
"    @Test
    public void TestGetLastModifiedDateTime(){
        String lastModifiedDateTime = ""2000-01-01"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setLastModifiedDateTime(lastModifiedDateTime);
        String result = messageActionsPayload.getLastModifiedDateTime();

        Assert.assertEquals(result, lastModifiedDateTime);
    }
"
"    @Test
    public void TestGetDeleted(){
        Boolean deleted = false;
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setDeleted(deleted);
        Boolean result = messageActionsPayload.getDeleted();

        Assert.assertEquals(result, deleted);
    }
"
"    @Test
    public void TestGetSubject(){
        String subject = ""testSubject"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setSubject(subject);
        String result = messageActionsPayload.getSubject();

        Assert.assertEquals(result, subject);
    }
"
"    @Test
    public void TestGetSummary(){
        String summary = ""testSummary"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setSummary(summary);
        String result = messageActionsPayload.getSummary();

        Assert.assertEquals(result, summary);
    }
"
"    @Test
    public void TestGetImportance(){
        String importance = ""normal"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setImportance(importance);
        String result = messageActionsPayload.getImportance();

        Assert.assertEquals(result, importance);
    }
"
"    @Test
    public void TestGetLinkToMessage(){
        String linkToMessage = ""https://teams.microsoft.com/l/message/testing-id"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setLinkToMessage(linkToMessage);
        String result = messageActionsPayload.getLinkToMessage();

        Assert.assertEquals(result, linkToMessage);
    }
"
"    @Test
    public void TestGetLocale(){
        String locale = ""US"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setLocale(locale);
        String result = messageActionsPayload.getLocale();

        Assert.assertEquals(result, locale);
    }
"
"    @Test
    public void TestGetFrom(){
        MessageActionsPayloadFrom from = new MessageActionsPayloadFrom();
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setFrom(from);
        MessageActionsPayloadFrom result = messageActionsPayload.getFrom();

        Assert.assertEquals(result, from);
    }
"
"    @Test
    public void TestGetBody(){
        MessageActionsPayloadBody body = new MessageActionsPayloadBody();
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setBody(body);
        MessageActionsPayloadBody result = messageActionsPayload.getBody();

        Assert.assertEquals(result, body);
    }
"
"    @Test
    public void TestGetAttachmentLayout(){
        String attachmentLayout = ""testAttachmentLayout"";
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setAttachmentLayout(attachmentLayout);
        String result = messageActionsPayload.getAttachmentLayout();

        Assert.assertEquals(result, attachmentLayout);
    }
"
"    @Test
    public void TestGetAttachments(){
        List<MessageActionsPayloadAttachment> attachments = new ArrayList<MessageActionsPayloadAttachment>();
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setAttachments(attachments);
        List<MessageActionsPayloadAttachment> result = messageActionsPayload.getAttachments();

        Assert.assertEquals(result, attachments);
    }
"
"    @Test
    public void TestGetMentions(){
        List<MessageActionsPayloadMention> mentions = new ArrayList<MessageActionsPayloadMention>();
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setMentions(mentions);
        List<MessageActionsPayloadMention> result = messageActionsPayload.getMentions();

        Assert.assertEquals(result, mentions);
    }
"
"    @Test
    public void TestGetReactions(){
        List<MessageActionsPayloadReaction> reactions = new ArrayList<MessageActionsPayloadReaction>();
        MessageActionsPayload messageActionsPayload = new MessageActionsPayload();
        messageActionsPayload.setReactions(reactions);
        List<MessageActionsPayloadReaction> result = messageActionsPayload.getReactions();

        Assert.assertEquals(result, reactions);
    }
"
"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.oauth"", attachment.getContentType());
    }
"
"    @Test
    public void EntityTests_GeoCoordinatesSerializationDeserializationTest() {
        GeoCoordinates geoCoordinates = new GeoCoordinates();
        geoCoordinates.setLatitude(22.00);
        geoCoordinates.setLongitude(23.00);

        Assert.assertEquals(""GeoCoordinates"", geoCoordinates.getType());

        Entity deserializedEntity = new Entity().setAs(geoCoordinates);
        Assert.assertEquals(deserializedEntity.getType(), geoCoordinates.getType());

        GeoCoordinates geoDeserialized = deserializedEntity.getAs(GeoCoordinates.class);
        Assert.assertEquals(geoCoordinates.getType(), geoDeserialized.getType());
        Assert.assertEquals(
            geoCoordinates.getLatitude(), geoDeserialized.getLatitude(), Double.MAX_VALUE
        );
        Assert.assertEquals(
            geoCoordinates.getLongitude(), geoDeserialized.getLongitude(), Double.MAX_VALUE
        );
    }
"
"    @Test
    public void EntityTests_MentionSerializationDeserializationTest() {
        Mention mentionEntity = new Mention();
        mentionEntity.setText(""TESTTEST"");

        Assert.assertEquals(""mention"", mentionEntity.getType());

        Entity deserializedEntity = new Entity().setAs(mentionEntity);
        Assert.assertEquals(deserializedEntity.getType(), mentionEntity.getType());
        Assert.assertEquals(
            deserializedEntity.getProperties().get(""text"").textValue(), mentionEntity.getText()
        );

        Mention mentionDeserialized = deserializedEntity.getAs(Mention.class);
        Assert.assertEquals(mentionEntity.getType(), mentionDeserialized.getType());
        Assert.assertEquals(
            deserializedEntity.getProperties().get(""text"").textValue(), mentionEntity.getText()
        );
    }
"
"    @Test
    public void EntityTests_PlaceSerializationDeserializationTest() {
        Place placeEntity = new Place();
        placeEntity.setName(""TESTTEST"");

        Assert.assertEquals(""Place"", placeEntity.getType());

        Entity deserializedEntity = new Entity().setAs(placeEntity);
        Assert.assertEquals(deserializedEntity.getType(), placeEntity.getType());

        Place placeDeserialized = deserializedEntity.getAs(Place.class);
        Assert.assertEquals(placeEntity.getType(), placeDeserialized.getType());
    }
"
"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.thumbnail"", attachment.getContentType());
    }
"
"    @Test
    public void testToAttachment() {
        Attachment attachment = getCard().toAttachment();
        Assert.assertNotNull(attachment);
        Assert.assertEquals(""application/vnd.microsoft.card.animation"", attachment.getContentType());
    }
"
"    @Test
    public void TestImplicitConversation() {
        SuggestedActions actions = new SuggestedActions(
            new CardAction[] { new CardAction(""x""), new CardAction(""y""), new CardAction(""z"") }
        );

        Assert.assertEquals(""x"", actions.getActions().get(0).getTitle());
        Assert.assertEquals(""x"", actions.getActions().get(0).getValue());
        Assert.assertEquals(""y"", actions.getActions().get(1).getTitle());
        Assert.assertEquals(""y"", actions.getActions().get(1).getValue());
        Assert.assertEquals(""z"", actions.getActions().get(2).getTitle());
        Assert.assertEquals(""z"", actions.getActions().get(2).getValue());
    }
"
"    @Test
    public void TestClone() {

        CardAction cardAction =  new CardAction();
        cardAction.setChannelData(""channelData"");
        cardAction.setDisplayText(""displayTest"");
        cardAction.setImage(""image"");
        cardAction.setImageAltText(""imageAltText"");
        cardAction.setText(""text"");
        cardAction.setTitle(""title"");
        cardAction.setType(ActionTypes.CALL);
        cardAction.setValue(""value"");

        CardAction newCardAction = CardAction.clone(cardAction);

        Assert.assertEquals(cardAction.getChannelData(), newCardAction.getChannelData());
        Assert.assertEquals(cardAction.getDisplayText(), newCardAction.getDisplayText());
        Assert.assertEquals(cardAction.getImage(), newCardAction.getImage());
        Assert.assertEquals(cardAction.getImageAltText(), newCardAction.getImageAltText());
        Assert.assertEquals(cardAction.getText(), newCardAction.getText());
        Assert.assertEquals(cardAction.getTitle(), newCardAction.getTitle());
        Assert.assertEquals(cardAction.getType(), newCardAction.getType());
        Assert.assertEquals(cardAction.getValue(), newCardAction.getValue());
    }
"
"    @Test
    public void TestCloneNull() {
        CardAction newCardAction = CardAction.clone(null);
        Assert.assertNull(newCardAction);
    }
"
"    @Test
    public void TestConstructorTwoParams() {
        CardAction cardAction =  new CardAction(ActionTypes.CALL, ""title"");
        Assert.assertEquals(cardAction.getType(), ActionTypes.CALL);
        Assert.assertEquals(cardAction.getTitle(), ""title"");
    }
"
"    @Test
    public void TestConstructorThreeParams() {
        CardAction cardAction =  new CardAction(ActionTypes.CALL, ""title"", ""value"");
        Assert.assertEquals(cardAction.getType(), ActionTypes.CALL);
        Assert.assertEquals(cardAction.getTitle(), ""title"");
        Assert.assertEquals(cardAction.getValue(), ""value"");
    }
"
"    @Test
    public void testGetAs() {
        Activity activity = createActivity();
        JsonNode activityNode = Serialization.objectToTree(activity);
        Activity resultActivity = Serialization.getAs(activityNode, Activity.class);
        Assert.assertEquals(activity.getId(), resultActivity.getId());
        Assert.assertEquals(activity.getFrom().getId(), resultActivity.getFrom().getId());
        Assert.assertEquals(activity.getConversation().getId(), resultActivity.getConversation().getId());
    }
"
"    @Test
    public void testGetAsNull() {
        Activity resultActivity = Serialization.getAs(null, Activity.class);
        Assert.assertNull(resultActivity);
    }
"
"    @Test
    public void testClone() {
        Activity activity = createActivity();
        Activity resultActivity = (Activity) Serialization.clone((Object) activity);
        Assert.assertEquals(activity.getId(), resultActivity.getId());
        Assert.assertEquals(activity.getFrom().getId(), resultActivity.getFrom().getId());
        Assert.assertEquals(activity.getConversation().getId(), resultActivity.getConversation().getId());
    }
"
"    @Test
    public void testCloneNull() {
        Activity resultActivity = (Activity) Serialization.clone((Object) null);
        Assert.assertNull(resultActivity);
    }
"
"    @Test
    public void testAllSubredditFields() {
        
        // Field values
        String submit_text_html = null;
        Boolean user_is_banned = null;
        String id = ""SubredditID"";
        String kind = Kind.SUBREDDIT.value();
        String submit_text = ""submit text for subreddit"";
        String display_name = ""subredditDisplayName"";
        String header_img = ""http://a.thumbs.redditmedia.com/yyL5sveWcgkCPKbr.png"";
        String description_html = ""&lt;div&gt;HTML description for subreddit&lt;/d&gt;"";
        String title = ""SubredditTitle"";
        Boolean over18 = false;
        Boolean user_is_moderator = null;
        String header_title = ""Header title for subreddit"";
        String description = ""Description for subreddit"";
        String submit_link_label = ""Submit link label"";
        String accounts_active = null;
        Boolean public_traffic = true;
        JSONArray header_size = JsonHelpers.jsonArrayOf(160, 64);
        long subscribers = 289252;
        String submit_text_label = ""Submit text label"";
        String name = kind + ""_"" + id;
        double created = 1201242956.0;
        String url = ""/r/"" + display_name;
        double created_utc = 1201242956.0;
        Boolean user_is_contributor = null;
        String public_description = ""Public description of subreddit"";
        long comment_score_hide_mins = 0;
        String subreddit_type = ""public"";
        String submission_type = ""any"";
        Boolean user_is_subscriber = null;
        
        // Create JSON Object
        JSONObject data = new JSONObject();
        data.put(""submit_text_html"", submit_text_html);
        data.put(""user_is_banned"", user_is_banned);
        data.put(""id"", id);
        data.put(""submit_text"", submit_text);
        data.put(""display_name"", display_name);
        data.put(""header_img"", header_img);
        data.put(""description_html"", description_html);
        data.put(""title"", title);
        data.put(""over18"", over18);
        data.put(""user_is_moderator"", user_is_moderator);
        data.put(""header_title"", header_title);
        data.put(""description"", description);
        data.put(""submit_link_label"", submit_link_label);
        data.put(""accounts_active"", accounts_active);
        data.put(""public_traffic"", public_traffic);
        data.put(""header_size"", header_size);
        data.put(""subscribers"", subscribers);
        data.put(""submit_text_label"", submit_text_label);
        data.put(""name"", name);
        data.put(""created"", created);
        data.put(""url"", url);
        data.put(""created_utc"", created_utc);
        data.put(""user_is_contributor"", user_is_contributor);
        data.put(""public_description"", public_description);
        data.put(""comment_score_hide_mins"", comment_score_hide_mins);
        data.put(""subreddit_type"", subreddit_type);
        data.put(""submission_type"", submission_type);
        data.put(""user_is_subscriber"", user_is_subscriber);
        
        // Parse
        Subreddit s = new Subreddit(data);
        
        // Test data fields
        assertEquals(s.getDisplayName(), display_name);
        assertEquals(s.getTitle(), title);
        assertEquals(s.getURL(), url);
        assertEquals(s.getCreated(), created, 0);
        assertEquals(s.getCreatedUTC(), created_utc, 0);
        assertEquals(s.isNSFW(), over18);
        assertEquals(s.getSubscribers(), subscribers);
        assertEquals(s.getDescription(), description);
        assertEquals(s.getSubredditType(), subreddit_type);
        
        // Possible tests to activate:
//        assertEquals(s.getSubmitTextHTML(), submit_text_html);
//        assertEquals(s.isUserBanned(), user_is_banned);
//        assertEquals(s.getSubmitText(), submit_text);
//        assertEquals(s.getHeaderIMG(), header_img);
//        assertEquals(s.getDescriptionHTML(), description_html);
//        assertEquals(s.isUserModerator(), user_is_moderator);
//        assertEquals(s.getHeaderTitle(), header_title);
//        assertEquals(s.getSubmitLinkLabel(), submit_link_label);
//        assertEquals(s.getAccountsActive(), accounts_active);
//        assertEquals(s.getPublicTraffic(), public_traffic);
//        assertEquals(s.getHeaderSize(), header_size);
//        assertEquals(s.getSubmitTextLabel(), submit_text_label);
//        assertEquals(s.isUserContributor(), user_is_contributor);
//        assertEquals(s.getPublicDescription(), public_description);
//        assertEquals(s.getCommentScoreHideMins(), comment_score_hide_mins, 0);
//        assertEquals(s.getSubmissionType(), submission_type);
//        assertEquals(s.isUserSubscriber(), user_is_subscriber);
        
    }
"
"    @Test
    public void testConstructor() {
        
        // Variables
        long count = 2894;
        String parent_id = ""djk9fa"";
        String child_id_1 = ""ddafe2"";
        String child_id_2 = ""ddaf22"";
        
        // Create JSON Object
        JSONObject data = new JSONObject();
        data.put(""count"", count);
        data.put(""parent_id"", parent_id);
        JSONArray array = new JSONArray();
        array.add(child_id_1);
        array.add(child_id_2);
        data.put(""children"", array);
        
        // Parse
        More m = new More(data);
        
        Assert.assertEquals((Long) count, m.getCount());
        Assert.assertEquals(parent_id, m.getParentId());
        Assert.assertEquals(2, m.getChildrenSize());
        Assert.assertEquals(child_id_1, m.getChildren().get(0));
        Assert.assertEquals(child_id_2, m.getChildren().get(1));
        
        // Test that the toString does not throw an exception an is not null
       Assert.assertNotNull(m.toString());
        
    }
"
"    @Test
    public void testAllCommentFields() {
        
        // Field values
        String subreddit_id = ""SubrID"";
        String banned_by = null;
        String subreddit = ""SubredditName"";
        String likes = null;
        String replies = """";
        boolean saved = false;
        String id = ""CommID"";
        String kind = ""t1"";
        long gilded = 0;
        String author = ""author"";
        String parent_id = ""ParID"";
        long score = 2;
        String approved_by = null;
        long controversiality = 0;
        String body = ""comment body"";
        boolean edited = false;
        String author_flair_css_class = null;
        long downs = 0;
        String body_html = ""&lt;div&gt;"" + body + ""&lt;/div&gt;"";
        String link_id = ""LinkIdentifier"";
        boolean score_hidden = false;
        String name = kind + ""_"" + id;
        double created = 1404969798.0;
        String author_flair_text = null;
        double created_utc = 1404940998.0;
        long ups = 2;
        String num_reports = null;
        String distinguished = null;
        
        // Create JSON Object
        JSONObject data = new JSONObject();
        data.put(""subreddit_id"", subreddit_id);
        data.put(""banned_by"", banned_by);
        data.put(""subreddit"", subreddit);
        data.put(""likes"", likes);
        data.put(""replies"", replies);
        data.put(""saved"", saved);
        data.put(""id"", id);
        data.put(""gilded"", gilded);
        data.put(""author"", author);
        data.put(""parent_id"", parent_id);
        data.put(""score"", score);
        data.put(""approved_by"", approved_by);
        data.put(""controversiality"", controversiality);
        data.put(""body"", body);
        data.put(""edited"", edited);
        data.put(""author_flair_css_class"", author_flair_css_class);
        data.put(""downs"", downs);
        data.put(""body_html"", body_html);
        data.put(""link_id"", link_id);
        data.put(""score_hidden"", score_hidden);
        data.put(""name"", name);
        data.put(""created"", created);
        data.put(""author_flair_text"", author_flair_text);
        data.put(""created_utc"", created_utc);
        data.put(""ups"", ups);
        data.put(""num_reports"", num_reports);
        data.put(""distinguished"", distinguished);
        
        // Parse
        Comment c = new Comment(data);
        
        // Test data fields
        assertEquals(c.getFullName(), name);
        assertEquals(c.getAuthor(), author);
        assertEquals(c.getBody(), body);
        assertEquals(c.getCreated(), created, 0);
        assertEquals(c.getCreatedUTC(), created_utc, 0);
        assertEquals(c.getDownvotes(), downs, 0);
        assertEquals(c.getEdited(), edited);
        assertEquals(c.getGilded(), gilded, 0);
        assertEquals(c.getIdentifier(), id);
       // assertEquals(c.getKind(), kind);
        assertEquals(c.getParentId(), parent_id);
        assertEquals(c.getScore(), score, 0);
        assertEquals(c.getUpvotes(), ups, 0);
        assertEquals(c.getSubreddit(), subreddit);
        assertEquals(c.getSubredditId(), subreddit_id);
        assertEquals(c.getLinkId(), link_id);
        assertEquals(c.getBodyHTML(), body_html);
        assertEquals(c.isScoreHidden(), score_hidden);
        
        // Possible tests to activate:
//        assertEquals(c.getBannedBy(), banned_by);
//        assertEquals(c.getLikes(), likes);
//        assertEquals(c.getApprovedBy(), approved_by);
//        assertEquals(c.getAuthorFlairCSSClass(), author_flair_css_class);
//        assertEquals(c.getAuthorFlairText(), author_flair_text);
//        assertEquals(c.getNumReports(), num_reports);
//        assertEquals(c.getDistinguised(), distinguished);
        
    }
"
"    @Test
    public void testMatchSuccess() {
        Assert.assertEquals(Kind.COMMENT, Kind.match(Kind.COMMENT.value()));
    }
"
"    @Test
    public void testMatchFailure() {
        // Match a string that most likely will never become a Kind's value
        Assert.assertNull(Kind.match(""djkaskjsf7s98f989389589a9f8a998935""));
    }
"
"    @Test
    public void testAllSubmissionFields() {
        
        // Field values
        String kind = Kind.LINK.value();
        String domain = ""imgur.com"";
        String banned_by = null;
        JSONObject media_embed = JsonHelpers.createMediaEmbedObject();
        String subreddit = ""subredditName"";
        String selftext_html = ""Self text HTML"";
        String selftext = ""Self text"";
        String likes = null;
        Boolean secure_media = null;
        String link_flair_text = null;
        String id = ""SubmID"";
        Long gilded = (long) 0;
        JSONObject secure_media_embed = new JSONObject();
        Boolean clicked = false;
        Boolean stickied = false;
        String author = ""authorName"";
        JSONObject media = JsonHelpers.createMediaObject();
        Long score = (long) 613;
        String approved_by = null;
        Boolean over_18 = true;
        Boolean hidden = false;
        String thumbnail = ""nsfw"";
        String subreddit_id = Kind.SUBREDDIT.value() + ""_"" + ""SubrID"";
        Boolean edited = false;
        String link_flair_css_class = null;
        String author_flair_css_class = null;
        Long downs = (long) 0;
        Boolean saved = false;
        Boolean is_self = false;
        String title = ""submTitle"";
        String permalink = ""/r/"" + subreddit + ""/comments"" + id + ""/"" + title + ""/"";
        String name = kind + ""_"" + id;
        Double created = 1405093719.0;
        String url = ""http://imgur.com/a/dxHTq"";
        String author_flair_text = null;
        Double created_utc = 1405064919.0;
        Long ups = (long) 613;
        Long num_comments = (long) 112;
        Boolean visited = false;
        Long num_reports = null;
        String distinguished = null;
        String from = ""t3_djjksjk"";
        String from_id = ""djjksjk"";
        String from_kind = ""t3"";
        String removal_reason = ""Just because"";
        Double upvote_ratio = 0.89;
             
        // Create JSON Object
        JSONObject data = new JSONObject();
        data.put(""kind"", kind);
        data.put(""domain"", domain);
        data.put(""banned_by"", banned_by);
        data.put(""media_embed"", media_embed);
        data.put(""subreddit"", subreddit);
        data.put(""selftext_html"", selftext_html);
        data.put(""selftext"", selftext);
        data.put(""likes"", likes);
        data.put(""secure_media"", secure_media);
        data.put(""link_flair_text"", link_flair_text);
        data.put(""id"", id);
        data.put(""gilded"", gilded);
        data.put(""secure_media_embed"", secure_media_embed);
        data.put(""clicked"", clicked);
        data.put(""stickied"", stickied);
        data.put(""author"", author);
        data.put(""media"", media);
        data.put(""score"", score);
        data.put(""approved_by"", approved_by);
        data.put(""over_18"", over_18);
        data.put(""hidden"", hidden);
        data.put(""thumbnail"", thumbnail);
        data.put(""subreddit_id"", subreddit_id);
        data.put(""edited"", edited);
        data.put(""link_flair_css_class"", link_flair_css_class);
        data.put(""author_flair_css_class"", author_flair_css_class);
        data.put(""downs"", downs);
        data.put(""saved"", saved);
        data.put(""is_self"", is_self);
        data.put(""title"", title);
        data.put(""permalink"", permalink);
        data.put(""name"", name);
        data.put(""created"", created);
        data.put(""url"", url);
        data.put(""author_flair_text"", author_flair_text);
        data.put(""created_utc"", created_utc);
        data.put(""ups"", ups);
        data.put(""num_comments"", num_comments);
        data.put(""visited"", visited);
        data.put(""num_reports"", num_reports);
        data.put(""distinguished"", distinguished);
        data.put(""from"", from);
        data.put(""from_id"", from_id);
        data.put(""from_kind"", from_kind);
        data.put(""removal_reason"", removal_reason);
        data.put(""upvote_ratio"", upvote_ratio);
        
        // Parse
        Submission s = new Submission(data);
        
        // Test data fields
        assertEquals(s.getKind(), Kind.match(kind));
        assertEquals(s.getDomain(), domain);
        assertEquals(s.getBannedBy(), banned_by);
        //assertEquals(s.getMediaEmbed(), media_embed);
        assertEquals(s.getSubreddit(), subreddit);
        assertEquals(s.getSelftextHTML(), selftext_html);
        assertEquals(s.getSelftext(), selftext);
        assertEquals(s.getLikes(), likes);
        //assertEquals(s.getSecureMedia(), secure_media);
        assertEquals(s.getLinkFlairText(), link_flair_text);
        assertEquals(s.getIdentifier(), id);
        assertEquals(s.getGilded(), gilded);
        //assertEquals(s.getSecureMediaEmbed(), secure_media_embed);
        assertEquals(s.isClicked(), clicked);
        assertEquals(s.isStickied(), stickied);
        assertEquals(s.getAuthor(), author);
        //assertEquals(s.getMedia(), media);
        assertEquals(s.getScore(), score);
        assertEquals(s.getApprovedBy(), approved_by);
        assertEquals(s.isNSFW(), over_18);
        assertEquals(s.isHidden(), hidden);
        assertEquals(s.getThumbnail(), thumbnail);
        assertEquals(s.getSubredditId(), subreddit_id);
        assertEquals(s.isEdited(), edited);
        assertEquals(s.getLinkFlairCSSClass(), link_flair_css_class);
        assertEquals(s.getAuthorFlairCSSClass(), author_flair_css_class);
        assertEquals(s.getDownVotes(), downs);
        assertEquals(s.isSaved(), saved);
        assertEquals(s.isSelf(), is_self);
        assertEquals(s.getTitle(), title);
        assertEquals(s.getPermalink(), permalink);
        assertEquals(s.getFullName(), name);
        assertEquals(s.getCreated(), created, 0);
        assertEquals(s.getURL(), url);
        assertEquals(s.getAuthorFlairText(), author_flair_text);
        assertEquals(s.getCreatedUTC(), created_utc, 0);
        assertEquals(s.getUpVotes(), ups);
        assertEquals(s.getCommentCount(), num_comments);
        assertEquals(s.isVisited(), visited);
        assertEquals(s.getReportCount(), num_reports);
        assertEquals(s.getDistinguished(), distinguished);
        assertEquals(s.getFrom(), from);
        assertEquals(s.getFromId(), from_id);
        assertEquals(s.getFromKind(), from_kind);
        assertEquals(s.getRemovalReason(), removal_reason);
        assertEquals(s.getUpvoteRatio(), upvote_ratio);
        
    }
"
"    @Test
    public void testSafeJsonToString() {
        Assert.assertNull(JsonUtils.safeJsonToString(null));
        Assert.assertEquals(""123"", JsonUtils.safeJsonToString(123));
        Assert.assertEquals(""abcd"", JsonUtils.safeJsonToString(""abcd""));
        Assert.assertEquals("""", JsonUtils.safeJsonToString(""""));
    }
"
"    @Test
    public void testSafeJsonToDouble() {
        Assert.assertNull(JsonUtils.safeJsonToDouble(null));
        Assert.assertNull(JsonUtils.safeJsonToDouble(""abcd""));
        Assert.assertNull(JsonUtils.safeJsonToDouble(""""));
        Assert.assertEquals((Double) (double) 35141, JsonUtils.safeJsonToDouble(""35141""), 0);
        Assert.assertEquals((Double) (double) 0, JsonUtils.safeJsonToDouble(""0""), 0);
    }
"
"    @Test
    public void testSafeJsonToInteger() {
        Assert.assertNull(JsonUtils.safeJsonToInteger(null));
        Assert.assertNull(JsonUtils.safeJsonToInteger(""abcd""));
        Assert.assertNull(JsonUtils.safeJsonToInteger(""""));
        Assert.assertEquals((Integer) 355, (Integer) JsonUtils.safeJsonToInteger(""355""));
        Assert.assertNull(JsonUtils.safeJsonToInteger(""25275738927589278572891""));
        Assert.assertNull(JsonUtils.safeJsonToInteger(""-25275738927589278572891""));
        Assert.assertEquals((Integer) 0, JsonUtils.safeJsonToInteger(""0""));
    }
"
"    @Test
    public void testSafeJsonToBoolean() {
        Assert.assertNull(JsonUtils.safeJsonToBoolean(null));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""abcd""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""3522""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""25275738927589278572891""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""-25275738927589278572891""));
        Assert.assertTrue(JsonUtils.safeJsonToBoolean(""true""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""false""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""0""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""1""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""yes""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""no""));
    }
"
"    @Test
    public void testSafeJsonToLong() {
        Assert.assertNull(JsonUtils.safeJsonToLong(null));
        Assert.assertNull(JsonUtils.safeJsonToLong(""abcd""));
        Assert.assertNull(JsonUtils.safeJsonToLong(""""));
        Assert.assertEquals((Long) (long) 355, (Long) JsonUtils.safeJsonToLong(""355""));
        Assert.assertNull(JsonUtils.safeJsonToLong(""25275738927589278572891""));
        Assert.assertNull(JsonUtils.safeJsonToLong(""-25275738927589278572891""));
        Assert.assertEquals((Long) Long.MAX_VALUE, (Long) JsonUtils.safeJsonToLong("""" + Long.MAX_VALUE));
        Assert.assertEquals((Long) Long.MIN_VALUE, (Long) JsonUtils.safeJsonToLong("""" + Long.MIN_VALUE));
        Assert.assertEquals((Long) (long) 0, JsonUtils.safeJsonToLong(""0""));
    }
"
"    @Test
    public void testGetters() {
        
        RedditToken subject = new RedditToken(jsonToken);
        RedditToken subjectUserProvided = new RedditToken(accessToken, tokenType, expiresIn, scope);
        assertEquals(accessToken, subject.getAccessToken());
        assertEquals(refreshToken, subject.getRefreshToken());
        assertEquals(tokenType, subject.getTokenType());
        assertEquals(expiresIn, subject.getExpirationSpan());
        assertTrue(subject.hasScope(RedditScope.EDIT));
        assertTrue(subject.hasScope(RedditScope.FLAIR));
        assertFalse(subject.hasScope(RedditScope.PRIVATEMESSAGE));
        assertTrue(subject.isRefreshable());
        assertFalse(subjectUserProvided.isRefreshable());
        
    }
"
"    @Test
    public void testRefresh() {
        
        RedditToken subject = new RedditToken(jsonToken);
        assertEquals(accessToken, subject.getAccessToken());
        assertEquals(refreshToken, subject.getRefreshToken());
        assertEquals(tokenType, subject.getTokenType());
        assertEquals(expiresIn, subject.getExpirationSpan());
        assertTrue(subject.hasScope(RedditScope.EDIT));
        assertTrue(subject.hasScope(RedditScope.FLAIR));
        
        subject.refresh(refreshJsonToken);
        
        assertEquals(accessToken2, subject.getAccessToken());
        assertEquals(refreshToken, subject.getRefreshToken());
        assertEquals(tokenType2, subject.getTokenType());
        assertEquals(expiresIn2, subject.getExpirationSpan());
        assertTrue(subject.hasScope(RedditScope.EDIT));
        assertFalse(subject.hasScope(RedditScope.FLAIR));
        
    }
"
"    @Test
    public void testTimeSensitiveExpiration() {
        
        RedditToken subject = new RedditToken(jsonToken);
        RedditToken subjectUserProvided = new RedditToken(accessToken, tokenType, expiresIn2, scope);
        
        assertFalse(subjectUserProvided.willExpireIn(expiresIn2 - 60));
        assertTrue(subjectUserProvided.willExpireIn(expiresIn2 + 60));
        assertFalse(subjectUserProvided.isExpired());
        
        try {
            Thread.sleep(2000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        
        assertTrue(subject.isExpired());
        assertTrue(subject.getExpiration() < (System.currentTimeMillis() / 1000));
        
    }
"
"    @Test
    public void testDefaultConstructor() {
        RedditApp app = new RedditWebApp(clientID, clientSecret, redirectURI);
        new RedditOAuthAgent(userAgent, app);
        app = new RedditScriptApp(clientID, clientSecret, redirectURI);
        new RedditOAuthAgent(userAgent, app);
        app = new RedditInstalledApp(clientID, redirectURI);
        new RedditOAuthAgent(userAgent, app);
    }
"
"    @Test
    public void testGenerateCodeFlowURI() {
        RedditScopeBuilder builder = new RedditScopeBuilder();
        builder.addScope(RedditScope.EDIT);
        String url = subject.generateCodeFlowURI(builder, RedditDuration.PERMANENT);
        UrlValidator urlValidator = new UrlValidator();
        assertTrue(urlValidator.isValid(url));
    }
"
"    @Test
    public void testGenerateImplicitFlowURI() {
        RedditScopeBuilder builder = new RedditScopeBuilder();
        builder.addScope(RedditScope.FLAIR);
        String url = subject.generateImplicitFlowURI(builder);
        UrlValidator urlValidator = new UrlValidator();
        assertTrue(urlValidator.isValid(url));
    }
"
"    @Test
    public void testTokenFromInfo() {
        RedditToken token = subject.tokenFromInfo(accessToken, tokenType, expiresIn, scope);
        assertEquals(accessToken, token.getAccessToken());
        assertEquals(tokenType, token.getTokenType());
        assertEquals(expiresIn, token.getExpirationSpan());
        assertTrue(token.hasScope(RedditScope.EDIT));
        assertTrue(token.hasScope(RedditScope.FLAIR));
        assertFalse(token.hasScope(RedditScope.PRIVATEMESSAGE));
    }
"
"    @Test
    public void testToken() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        
        // Captor for the request that is executed
        ArgumentCaptor<OAuthClientRequest> clientCaptor = ArgumentCaptor.forClass(OAuthClientRequest.class);
        
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenReturn(jsonToken);
        
        // Run subject
        RedditToken token = subject.token(code);
        
        // Verify and capture
        verify(mockOAuthClient).accessToken(clientCaptor.capture());
        
        OAuthClientRequest request = clientCaptor.getValue();
        
        assertNotNull(request.getHeader(""Authorization"")); // This is Base64 encoded
        assertEquals(request.getHeader(""User-Agent""), userAgent);
        
        assertEquals(accessToken, token.getAccessToken());
        assertEquals(refreshToken, token.getRefreshToken());
        assertEquals(tokenType, token.getTokenType());
        assertEquals(expiresIn, token.getExpirationSpan());
        assertTrue(token.hasScope(RedditScope.EDIT));
        assertTrue(token.hasScope(RedditScope.FLAIR));
        assertFalse(token.hasScope(RedditScope.PRIVATEMESSAGE));

    }
"
"    @Test(expected=RedditOAuthException.class)
    public void testTokenOAuthSystemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(new OAuthSystemException());
        subject.token(code);
    }
"
"    @Test(expected=RedditOAuthException.class)
    public void testTokenOAuthProblemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(OAuthProblemException.error(""Error""));
        subject.token(code);
    }
"
"    @Test
    public void testRefreshTokenFailure() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        assertFalse(subject.refreshToken(mockRedditToken));
    }
"
"    @Test
    public void testRefreshTokenSuccess() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        assertTrue(subject.refreshToken(mockRedditTokenRefreshable));
        verify(mockOAuthClient).accessToken(any(OAuthClientRequest.class));
        verify(mockRedditTokenRefreshable).refresh(null);
    }
"
"    @Test(expected=RedditOAuthException.class)
    public void testRefreshTokenOAuthSystemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(new OAuthSystemException());
        subject.refreshToken(mockRedditTokenRefreshable);
    }
"
"    @Test(expected=RedditOAuthException.class)
    public void testRefreshTokenOAuthProblemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(OAuthProblemException.error(""Error""));
        subject.refreshToken(mockRedditTokenRefreshable);
    }
"
"    @Test
    public void testTokenAppOnlyConfidential() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        
        // Captor for the request that is executed
        ArgumentCaptor<OAuthClientRequest> clientCaptor = ArgumentCaptor.forClass(OAuthClientRequest.class);
        
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenReturn(jsonTokenNonRefreshable);
        
        // Run subject
        RedditToken token = subject.tokenAppOnly(true);
        
        // Verify and capture
        verify(mockOAuthClient).accessToken(clientCaptor.capture());
        
        OAuthClientRequest request = clientCaptor.getValue();
        
        assertNotNull(request.getHeader(""Authorization"")); // This is Base64 encoded
        assertEquals(request.getHeader(""User-Agent""), userAgent);
        
        assertEquals(accessToken, token.getAccessToken());
        assertNull(token.getRefreshToken());
        assertEquals(tokenType, token.getTokenType());
        assertEquals(expiresIn, token.getExpirationSpan());
        assertTrue(token.hasScope(RedditScope.EDIT));
        assertTrue(token.hasScope(RedditScope.FLAIR));
        assertFalse(token.hasScope(RedditScope.PRIVATEMESSAGE));

    }
"
"    @Test
    public void testTokenAppOnly() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        
        // Captor for the request that is executed
        ArgumentCaptor<OAuthClientRequest> clientCaptor = ArgumentCaptor.forClass(OAuthClientRequest.class);
        
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenReturn(jsonTokenNonRefreshable);
        
        // Run subject
        RedditToken token = subject.tokenAppOnly(false);
        
        // Verify and capture
        verify(mockOAuthClient).accessToken(clientCaptor.capture());
        
        OAuthClientRequest request = clientCaptor.getValue();
        
        assertNotNull(request.getHeader(""Authorization"")); // This is Base64 encoded
        assertEquals(request.getHeader(""User-Agent""), userAgent);
        
        assertEquals(accessToken, token.getAccessToken());
        assertNull(token.getRefreshToken());
        assertEquals(tokenType, token.getTokenType());
        assertEquals(expiresIn, token.getExpirationSpan());
        assertTrue(token.hasScope(RedditScope.EDIT));
        assertTrue(token.hasScope(RedditScope.FLAIR));
        assertFalse(token.hasScope(RedditScope.PRIVATEMESSAGE));

    }
"
"    @Test(expected=RedditOAuthException.class)
    public void testTokenAppOnlyOAuthSystemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(new OAuthSystemException());
        subject.tokenAppOnly(false);
    }
"
"    @Test(expected=RedditOAuthException.class)
    public void testTokenAppOnlyOAuthProblemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(OAuthProblemException.error(""Error""));
        subject.tokenAppOnly(false);
    }
"
"    @Test
    public void testRevoke() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        assertTrue(subject.revoke(null, false));
    }
"
"    @Test
    public void testEmpty() {
        assertEquals("""", builder.build());
    }
"
"    @Test
    public void testAddRemove() {
        builder.addScope(RedditScope.EDIT);
        builder.removeScope(RedditScope.EDIT);
        assertEquals("""", builder.build());
    }
"
"    @Test
    public void testAddRemoveMultiple() {
        builder.addScopes(RedditScope.EDIT, RedditScope.MODPOSTS);
        builder.removeScopes(RedditScope.EDIT, RedditScope.MODPOSTS, RedditScope.MODCONFIG);
        assertEquals("""", builder.build());
    }
"
"    @Test
    public void testAdd() {
        builder.addScope(RedditScope.EDIT);
        assertEquals(RedditScope.EDIT.value(), builder.build());
        builder.removeScope(RedditScope.EDIT);
    }
"
"    @Test
    public void testAddDouble() {
        builder.addScopes(RedditScope.EDIT, RedditScope.EDIT);
        builder.addScope(RedditScope.EDIT);
        assertEquals(RedditScope.EDIT.value(), builder.build());
        builder.removeScope(RedditScope.EDIT);
        assertEquals("""", builder.build());
    }
"
"    @Test
    public void testAddMultiple() {
        builder.addScopes(RedditScope.EDIT, RedditScope.FLAIR);
        assertTrue(
                (RedditScope.EDIT.value() + RedditScope.SEPARATOR + RedditScope.FLAIR.value()).equals(builder.build()) 
                ||
                (RedditScope.FLAIR.value() + RedditScope.SEPARATOR + RedditScope.EDIT.value()).equals(builder.build()) 
                );
        builder.removeScopes(RedditScope.EDIT, RedditScope.FLAIR);
    }
"
"  @Test
  public void findsTarget() {
    final SootMethod sootMethod = prepareTarget(""<"" + TEST_TARGET_CLASS + "": void helloWorld()>"", TEST_TARGET_CLASS);
    Assert.assertNotNull(""Could not find target method. System test setup seems to be incorrect."", sootMethod);
    Assert.assertTrue(sootMethod.isConcrete());
    Assert.assertNotNull(sootMethod.retrieveActiveBody());
  }
"
"  @Test
  public void findsTarget() {
    String methodSignature = methodSigFromComponents(TEST_TARGET_CLASS, ""void"", ""unambiguousMethod"", """");
    final SootMethod sootMethod = prepareTarget(methodSignature, TEST_TARGET_CLASS);
    Assert.assertTrue(sootMethod.isConcrete());

    Body body = sootMethod.retrieveActiveBody();
    Assert.assertNotNull(body);
    // validate individual method
    body.validate();

    for (Unit u : body.getUnits()) {
      if (u instanceof AssignStmt) {
        Value right = ((AssignStmt) u).getRightOp();
        if (right instanceof InvokeExpr) {
          SootMethod m = ((InvokeExpr) right).getMethodRef().resolve();
          Assert.assertFalse(m.isPhantom());
          Assert.assertTrue(m.isDeclared());
          if (m.getName().equals(""invoke"")) {
            Assert.assertTrue(m.isNative());
          }
        }
      }
    }
  }
"
"  @Test
  public void handlesAmbiguousMethod() {
    String methodSignature = methodSigFromComponents(TEST_TARGET_CLASS, ""void"", ""ambiguousMethod"", """");
    final SootMethod sootMethod = prepareTarget(methodSignature, TEST_TARGET_CLASS);
    Assert.assertTrue(sootMethod.isConcrete());

    Body body = sootMethod.retrieveActiveBody();
    Assert.assertNotNull(body);
    // validate individual method
    body.validate();

    for (Unit u : body.getUnits()) {
      if (u instanceof AssignStmt) {
        Value right = ((AssignStmt) u).getRightOp();
        if (right instanceof InvokeExpr) {
          SootMethod m = ((InvokeExpr) right).getMethodRef().resolve();
          Assert.assertFalse(m.isPhantom());
          Assert.assertTrue(m.isDeclared());
          if (m.getName().equals(""invoke"")) {
            Assert.assertTrue(m.isNative());
          }
        }
      }
    }
  }
"
"  @Test
  public void nullAssignment() {
    SootMethod target =
        prepareTarget(
            methodSigFromComponents(TEST_TARGET_CLASS, ""void"", ""nullAssignment""),
            TEST_TARGET_CLASS);

    Body body = target.retrieveActiveBody();

    Optional<Unit> unit =
        body.getUnits().stream()
            .filter(
                u ->
                    u.toString()
                        .equals(
                            ""staticinvoke <soot.jimple.PropagateLineNumberTag: soot.jimple.PropagateLineNumberTag$A foo(soot.jimple.PropagateLineNumberTag$A)>(null)""))
            .findFirst();

    assertTrue(unit.isPresent());

    List<ValueBox> useBoxes = unit.get().getUseBoxes();

    assertEquals(2, useBoxes.size());
    ValueBox valueBox = useBoxes.get(0);
    assertTrue(valueBox instanceof ImmediateBox);
    assertEquals(1, valueBox.getTags().size());
    assertTrue(valueBox.getTags().get(0) instanceof LineNumberTag);
    assertEquals(33, valueBox.getJavaSourceStartLineNumber());
  }
"
"  @Test
  public void transitiveNullAssignment() {
    SootMethod target =
        prepareTarget(
            methodSigFromComponents(TEST_TARGET_CLASS, ""void"", ""transitiveNullAssignment""),
            TEST_TARGET_CLASS);

    Body body = target.retrieveActiveBody();

    // first call to foo
    Optional<Unit> unit =
        body.getUnits().stream()
            .filter(
                u ->
                    u.toString()
                        .equals(
                            ""staticinvoke <soot.jimple.PropagateLineNumberTag: soot.jimple.PropagateLineNumberTag$A foo(soot.jimple.PropagateLineNumberTag$A)>(null)""))
            .findFirst();

    assertTrue(unit.isPresent());

    List<ValueBox> useBoxes = unit.get().getUseBoxes();

    assertEquals(2, useBoxes.size());
    ValueBox valueBox = useBoxes.get(0);
    assertTrue(valueBox instanceof ImmediateBox);
    assertEquals(1, valueBox.getTags().size());
    assertTrue(valueBox.getTags().get(0) instanceof LineNumberTag);
    assertEquals(39, valueBox.getJavaSourceStartLineNumber());

    // second call to foo
    unit =
        body.getUnits().stream()
            .filter(
                u ->
                    u.toString()
                        .equals(
                            ""staticinvoke <soot.jimple.PropagateLineNumberTag: soot.jimple.PropagateLineNumberTag$A foo(soot.jimple.PropagateLineNumberTag$A)>(null)""))
            .skip(1)
            .findFirst();

    assertTrue(unit.isPresent());
    useBoxes = unit.get().getUseBoxes();
    assertEquals(2, useBoxes.size());
    valueBox = useBoxes.get(0);
    assertTrue(valueBox instanceof ImmediateBox);
    assertEquals(1, valueBox.getTags().size());
    assertTrue(valueBox.getTags().get(0) instanceof LineNumberTag);
    assertEquals(39, valueBox.getJavaSourceStartLineNumber());
  }
"
"    @Test
    public void TestAsyncTaskBasicCG() {
        prepareTarget(methodSigFromComponents(TARGET_CLASS, TARGET_METHOD), TARGET_CLASS);
        boolean found = false;
        for (Edge edge : Scene.v().getCallGraph()) {
            //String sig = edge.getTgt().method().toString();
            System.out.println(edge);
            String sig = edge.getTgt().method().toString();

            if (edge.toString().contains(""AHelper"") && edge.toString().contains(""handle""))
                found = true;
        }

        //Assert.assertTrue(found);
    }
"
"    @Test
    public void TestAsyncTaskBasicCG() {
        prepareTarget(methodSigFromComponents(TARGET_CLASS, TARGET_METHOD), TARGET_CLASS);

        asyncFuncMaps.clear();
        asyncFuncMaps.put(""doInBackground"", DO_IN_BG);
        asyncFuncMaps.put(""onPreExecute"", ON_PRE_EXE);
        asyncFuncMaps.put(""onPostExecute"", ON_POS_EXE);
        asyncFuncMaps.put(""onProgressUpdate"", ON_PRO_UPD);

        int full = 0, ret = 0;
        for(String key: asyncFuncMaps.keySet())
        {
            full |= asyncFuncMaps.get(key);
        }

        for (Edge edge : Scene.v().getCallGraph()) {
            String sig = edge.getTgt().method().toString();
            for (String key : asyncFuncMaps.keySet()) {
                if (sig.contains(key))
                    ret |= asyncFuncMaps.get(key);
            }
        }

        //The four functions shall all appear in call graph
        Assert.assertEquals(ret, full);
    }
"
"  @Test
  public void anySubTypePointsToResolution() {
    SootMethod entryPoint = prepareTarget(TEST_PTA_ENTRY_POINT, TEST_PACKAGE);
    commonInvokeTest(entryPoint);
  }
"
"  @Test
  public void anySubTypeTypestateResolution() {
    SootMethod entryPoint = prepareTarget(TEST_TYPESTATE_ENTRY_POINT, TEST_PACKAGE);
    commonInvokeTest(entryPoint);
  }
"
"  @Test
  public void iterator() {
    // statements at the beginning of a for loop should have the line number as for the branching
    // statement and not the last line number after the branch that leads outside the loop
    SootMethod target = prepareTarget(methodSigFromComponents(TEST_TARGET_CLASS, ""void"", ""iterator""), TEST_TARGET_CLASS);

    Body body = target.retrieveActiveBody();

    Optional<Unit> unit = body.getUnits().stream()
        .filter(u -> u.toString().contains(""<java.util.Iterator: java.lang.Object next()>()"")).findFirst();

    Assert.assertTrue(unit.isPresent());

    Assert.assertEquals(31, unit.get().getJavaSourceStartLineNumber());
  }
"
"  @Test
  public void localNaming() {
    // This test ensures that local names are preserved in the Jimple code.
    final String className = ""soot.asm.LocalNaming"";
    final String[] params = { ""java.lang.String"", ""java.lang.Integer"", ""byte[]"", ""java.lang.StringBuilder"" };
    SootMethod target = prepareTarget(methodSigFromComponents(className, ""void"", ""localNaming"", params), className);
    Body body = target.retrieveActiveBody();
    Set<String> localNames = body.getLocals().stream().map(Local::getName).collect(Collectors.toSet());

    // All expected Local names are present
    Assert.assertTrue(localNames.contains(""alpha""));
    Assert.assertTrue(localNames.contains(""beta""));
    Assert.assertTrue(localNames.contains(""gamma""));
    Assert.assertTrue(localNames.contains(""delta""));
    Assert.assertTrue(localNames.contains(""epsilon""));
    Assert.assertTrue(localNames.contains(""zeta""));
    Assert.assertTrue(localNames.contains(""eta""));
    Assert.assertTrue(localNames.contains(""theta""));
    Assert.assertTrue(localNames.contains(""iota""));
    Assert.assertTrue(localNames.contains(""omega""));

    // No Local name contains ""$stack""
    Assert.assertTrue(localNames.stream().allMatch(n -> !n.contains(""$stack"")));
  }
"
"  @Test
  public void testSilsDisabled() {
    final String className = ""soot.asm.LocalNaming"";
    final String[] params = {};
    SootMethod target = prepareTarget(methodSigFromComponents(className, ""void"", ""test"", params), className);
    Body body = target.retrieveActiveBody();
    Set<String> localNames = body.getLocals().stream().map(Local::getName).collect(Collectors.toSet());
    // test if all expected Local names are present
    Assert.assertTrue(localNames.contains(""d""));
    Assert.assertTrue(localNames.contains(""f""));
    Assert.assertTrue(localNames.contains(""arr""));
  }
"
"  @Test
  public void testInner() {
    NopStmt[] nops = new NopStmt[6];
    for (int i = 0; i < nops.length; i++) {
      nops[i] = Jimple.v().newNopStmt();
    }
    UnitPatchingChain chainNew = new UnitPatchingChain(new HashChain<Unit>());
    UnitContainer container = new UnitContainer(nops[0], new UnitContainer(nops[1], new UnitContainer(nops[2]), nops[3]),
        nops[4], new UnitContainer(nops[5]));
    AsmMethodSource.emitUnits(container, chainNew);
    UnitPatchingChain chainOld = new UnitPatchingChain(new HashChain<Unit>());
    oldEmitImplementation(container, chainOld);

    Assert.assertEquals(chainOld.size(), chainNew.size());
    Iterator<Unit> itO = chainOld.iterator();
    Iterator<Unit> itN = chainNew.iterator();
    while (itO.hasNext()) {
      Unit oo = itO.next();
      Unit nn = itN.next();
      if (oo != nn) {
        Assert.fail();
      }
    }
  }
"
"  @Test
  public void nonInner() {
    // statements at the beginning of a for loop should have the line number as for the branching
    // statement and not the last line number after the branch that leads outside the loop
    SootMethod target =
        prepareTarget(
            methodSigFromComponents(TEST_TARGET_CLASS, ""void"", ""method""), TEST_TARGET_CLASS);
    assertEquals(2, Scene.v().getApplicationClasses().size());
    assertFalse(target.getDeclaringClass().hasOuterClass());
    assertFalse(target.getDeclaringClass().isInnerClass());
    InnerClassTag tag = (InnerClassTag) target.getDeclaringClass().getTag(InnerClassTag.NAME);
    // the class has inner classes
    assertNotNull(tag);
  }
"
"  @Test
  public void InnerStatic() {
    SootMethod target2 =
        prepareTarget(
            methodSigFromComponents(TEST_TARGET_CLASS + ""$Inner"", ""void"", ""<init>""),
            TEST_TARGET_CLASS + ""$Inner"");
    assertEquals(2, Scene.v().getApplicationClasses().size());
    assertTrue(target2.getDeclaringClass().hasOuterClass());
    assertTrue(target2.getDeclaringClass().isInnerClass());
    InnerClassTag tag2 = (InnerClassTag) target2.getDeclaringClass().getTag(InnerClassTag.NAME);
    assertNotNull(tag2);
    assertEquals(""soot/asm/ScopeFinderTarget$Inner"", tag2.getInnerClass());
    assertEquals(""soot/asm/ScopeFinderTarget"", tag2.getOuterClass());
    assertTrue(Modifier.isStatic(tag2.getAccessFlags()));
  }
"
"  @Test
  public void InnerStaticInner() {
    SootMethod target3 =
        prepareTarget(
            methodSigFromComponents(TEST_TARGET_CLASS + ""$Inner$InnerInner"", ""void"", ""method""),
            TEST_TARGET_CLASS + ""$Inner$InnerInner"");
    // one dummy
    assertEquals(2, Scene.v().getApplicationClasses().size());
    assertTrue(target3.getDeclaringClass().hasOuterClass());
    assertTrue(target3.getDeclaringClass().isInnerClass());
    InnerClassTag innerClassTag = null;
    for (Tag tag : target3.getDeclaringClass().getTags()) {
      // FIXME: we have multiple innerclasstags? for a parent it makes sense but for a child class?
      if (tag instanceof InnerClassTag) {
        boolean inner =
            ((InnerClassTag) tag)
                .getInnerClass()
                .equals(""soot/asm/ScopeFinderTarget$Inner$InnerInner"");
        if (inner) {
          innerClassTag = (InnerClassTag) tag;
          break;
        }
      }
    }
    assertNotNull(innerClassTag);
    assertEquals(""soot/asm/ScopeFinderTarget$Inner$InnerInner"", innerClassTag.getInnerClass());
    assertEquals(""soot/asm/ScopeFinderTarget$Inner"", innerClassTag.getOuterClass());
    assertFalse(Modifier.isStatic(innerClassTag.getAccessFlags()));
  }
"
"  @Test
  public void testWriterToUTF8Buffered1() {
    final String clazz = ""org.apache.xml.serializer.WriterToUTF8Buffered"";
    final String[] params = { ""char[]"", ""int"", ""int"" };
    runXalanTest(prepareTarget(methodSigFromComponents(clazz, ""void"", ""write"", params), clazz));
  }
"
"  @Test
  public void testWriterToUTF8Buffered2() {
    final String clazz = ""org.apache.xml.serializer.WriterToUTF8Buffered"";
    final String[] params = { ""java.lang.String"" };
    runXalanTest(prepareTarget(methodSigFromComponents(clazz, ""void"", ""write"", params), clazz));
  }
"
"  @Test
  public void testElemApplyTemplates() {
    final String clazz = ""org.apache.xalan.templates.ElemApplyTemplates"";
    final String[] params = { ""org.apache.xalan.transformer.TransformerImpl"" };
    runXalanTest(prepareTarget(methodSigFromComponents(clazz, ""void"", ""transformSelectedNodes"", params), clazz));
  }
"
"  @Test
  public void testXNodeSet() {
    final String clazz = ""org.apache.xpath.objects.XNodeSet"";
    final String[] params = { ""org.apache.xpath.objects.XObject"", ""org.apache.xpath.objects.Comparator"" };
    runXalanTest(prepareTarget(methodSigFromComponents(clazz, ""boolean"", ""compare"", params), clazz));
  }
"
"  @Test
  public void testSilsEnabled() {
    final String className = ""soot.asm.LocalNaming"";
    final String[] params = {};
    SootMethod target = prepareTarget(methodSigFromComponents(className, ""void"", ""test"", params), className);
    Body body = target.retrieveActiveBody();
    Set<String> localNames = body.getLocals().stream().map(Local::getName).collect(Collectors.toSet());
    // test if all expected Local names are present
    // currently d, f are not preserved.
    Assert.assertTrue(localNames.contains(""d""));
    Assert.assertTrue(localNames.contains(""f""));
    Assert.assertTrue(localNames.contains(""arr""));
  }
"
"  @Test
  public void initializedInMethodRef() {
    prepareTarget(methodSigFromComponents(TEST_TARGET_CLASS, ""void"", ""<init>""), TEST_TARGET_CLASS);
    SootClass sootClass = Scene.v().getSootClass(""java.util.ArrayDeque"");
    assertEquals(SootClass.SIGNATURES, sootClass.resolvingLevel());
  }
"
"  @Test
  public void initializedInConstructor() {
    prepareTarget(methodSigFromComponents(TEST_TARGET_CLASS, ""void"", ""<init>""), TEST_TARGET_CLASS);
    SootClass sootClass = Scene.v().getSootClass(""java.util.LinkedList"");
    assertEquals(SootClass.SIGNATURES, sootClass.resolvingLevel());
  }
"
"  @Test
  public void SubClassTest() throws FileNotFoundException, UnsupportedEncodingException {		
	  
	  String testClass = ""soot.defaultInterfaceMethods.JavaNCSSCheck"";
	  String abstractClass = ""soot.defaultInterfaceDifferentPackage.AbstractCheck"";
	  String classToAnalyze = ""soot.defaultInterfaceDifferentPackage.AbstractCheck"";
	  final SootMethod target =
		        prepareTarget(
		            methodSigFromComponents(testClass, voidType, mainClass),
		            testClass,
		            classToAnalyze);
		
		ArrayList<Edge> edges = GetCallGraph();
		
		assertEquals(edges.get(0).getTgt(), Scene.v().getMethod(""<soot.defaultInterfaceDifferentPackage.AbstractCheck: void log(java.lang.String,java.lang.String)>""));		
		
	}
"
"  @Test
  public void simpleDefaultInterfaceTest() {

    String testClass = ""soot.defaultInterfaceMethods.SimpleDefaultInterface"";
    String defaultClass = ""soot.defaultInterfaceMethods.Default"";
    String classToAnalyze = ""soot.defaultInterfaceMethods.Default"";

    final SootMethod target =
        prepareTarget(
            methodSigFromComponents(testClass, voidType, mainClass),
            testClass,
            classToAnalyze);

    SootMethod defaultMethod =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.Default: void target()>"");
    Body body = target.retrieveActiveBody();
    SootMethod targetMethod = resolveMethodRefInBody(body.getUnits(), ""void target()"");
    SootMethod resolvedMethod =
        VirtualCalls.v()
            .resolveNonSpecial(Scene.v().getRefType(testClass), defaultMethod.makeRef(), false);
    SootMethod concreteImpl =
        Scene.v()
            .getFastHierarchy()
            .resolveConcreteDispatch(Scene.v().getSootClass(testClass), defaultMethod);
    SootMethod concreteImplViaResolveMethod =
        Scene.v()
            .getFastHierarchy()
            .resolveMethod(Scene.v().getSootClass(testClass), defaultMethod, false);
    Set<SootMethod> abstractImpl =
        Scene.v()
            .getFastHierarchy()
            .resolveAbstractDispatch(Scene.v().getSootClass(defaultClass), defaultMethod);

    boolean edgePresent = checkInEdges(defaultMethod, target);
    final ReachableMethods reachableMethods = Scene.v().getReachableMethods();
    /* Arguments for assert function */

    assertEquals(defaultMethod, resolvedMethod);
    assertEquals(defaultMethod, targetMethod);
    assertEquals(defaultMethod.getName(), ""target"");
    assertNotNull(defaultMethod);
    assertTrue(reachableMethods.contains(defaultMethod));
    assertTrue(edgePresent);
    assertEquals(defaultMethod, concreteImpl);
    assertEquals(concreteImpl, concreteImplViaResolveMethod);
    assertTrue(
        abstractImpl.contains(
            Scene.v().getMethod(""<soot.defaultInterfaceMethods.Default: void target()>"")));
  }
"
"  @Test
  public void interfaceSameSignatureTest() {
    String testClassSig = ""soot.defaultInterfaceMethods.InterfaceSameSignature"";
    String interfaceReadSig = ""soot.defaultInterfaceMethods.Read"";
    String interfaceWriteSig = ""soot.defaultInterfaceMethods.Write"";    

    final SootMethod target =
        prepareTarget(
            methodSigFromComponents(testClassSig, voidType, mainClass),
            testClassSig,
            interfaceReadSig,
            interfaceWriteSig);

    SootClass testClass = Scene.v().getSootClass(testClassSig);
    SootClass interfaceRead = Scene.v().getSootClass(interfaceReadSig);
    SootClass interfaceWrite = Scene.v().getSootClass(interfaceWriteSig);

    SootMethod mainPrintMethod =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.InterfaceSameSignature: void print()>"");
    SootMethod readInterfacePrint =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.Read: void print()>"");
    SootMethod writeInterfacePrint =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.Write: void print()>"");
    SootMethod readInterfaceRead =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.Read: void read()>"");
    SootMethod writeInterfaceWrite =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.Write: void write()>"");

    Body mainBody = target.retrieveActiveBody();
    Body mainPrintBody = mainPrintMethod.retrieveActiveBody();

    SootMethod refMainMethod = resolveMethodRefInBody(mainBody.getUnits(), ""void print()"");
    SootMethod refWritePrintMethod =
        resolveMethodRefInBody(
            mainPrintBody.getUnits(), ""soot.defaultInterfaceMethods.Write: void print()"");
    SootMethod refReadPrintMethod =
        resolveMethodRefInBody(
            mainPrintBody.getUnits(), ""soot.defaultInterfaceMethods.Read: void print()"");
    SootMethod refDefaultRead = resolveMethodRefInBody(mainBody.getUnits(), ""void read()"");
    SootMethod refDefaultWrite = resolveMethodRefInBody(mainBody.getUnits(), ""void write()"");

    SootMethod resolvedMainMethod =
        VirtualCalls.v()
            .resolveNonSpecial(
                Scene.v().getRefType(testClassSig), mainPrintMethod.makeRef(), false);
    SootMethod resolvedWritePrintMethod =
        VirtualCalls.v()
            .resolveNonSpecial(
                Scene.v().getRefType(testClassSig), writeInterfacePrint.makeRef(), false);
    SootMethod resolvedReadPrintMethod =
        VirtualCalls.v()
            .resolveNonSpecial(
                Scene.v().getRefType(testClassSig), readInterfacePrint.makeRef(), false);
    SootMethod resolvedDefaultReadMethod =
        VirtualCalls.v()
            .resolveNonSpecial(
                Scene.v().getRefType(testClassSig), readInterfaceRead.makeRef(), false);
    SootMethod resolvedDefaultWriteMethod =
        VirtualCalls.v()
            .resolveNonSpecial(
                Scene.v().getRefType(testClassSig), writeInterfaceWrite.makeRef(), false);

    FastHierarchy fh = Scene.v().getFastHierarchy();
    SootMethod concreteImplMainPrint = fh.resolveConcreteDispatch(testClass, mainPrintMethod);
    SootMethod concreteImplWritePrint = fh.resolveConcreteDispatch(testClass, refWritePrintMethod);
    SootMethod concreteImplReadPrint = fh.resolveConcreteDispatch(testClass, refReadPrintMethod);
    SootMethod concreteImplDefaultRead = fh.resolveConcreteDispatch(testClass, refDefaultRead);
    SootMethod concreteImplDefaultWrite = fh.resolveConcreteDispatch(testClass, refDefaultWrite);

    assertEquals(
        Sets.newHashSet(readInterfaceRead),
        fh.resolveAbstractDispatch(interfaceRead, refDefaultRead));
    assertEquals(
        Sets.newHashSet(writeInterfaceWrite),
        fh.resolveAbstractDispatch(interfaceWrite, refDefaultWrite));
    assertEquals(
        Sets.newHashSet(mainPrintMethod),
        fh.resolveAbstractDispatch(interfaceRead, refReadPrintMethod));
    assertEquals(
        Sets.newHashSet(mainPrintMethod),
        fh.resolveAbstractDispatch(interfaceWrite, refWritePrintMethod));

    /* Edges should be present */
    boolean edgeMainPrintToReadPrint = checkInEdges(readInterfacePrint, mainPrintMethod);
    boolean edgeMainPrintToWritePrint = checkInEdges(writeInterfacePrint, mainPrintMethod);
    boolean edgeMainMethodToPrint = checkInEdges(mainPrintMethod, target);
    boolean edgeMainMethodToReadMethod = checkInEdges(readInterfaceRead, target);
    boolean edgeMainMethodToWriteMethod = checkInEdges(writeInterfaceWrite, target);

    /* Edges should not be present */
    boolean edgeMainMethodToReadPrint = checkInEdges(readInterfacePrint, target);
    boolean edgeMainMethodToWritePrint = checkInEdges(writeInterfacePrint, target);

    final ReachableMethods reachableMethods = Scene.v().getReachableMethods();

    /* Arguments for assert function */
    Map<SootMethod, String> targetMethods =
        new HashMap<SootMethod, String>() {
          {
            put(mainPrintMethod, ""print"");
            put(readInterfacePrint, ""print"");
            put(writeInterfacePrint, ""print"");
            put(readInterfaceRead, ""read"");
            put(writeInterfaceWrite, ""write"");
          }
        };

    Map<SootMethod, SootMethod> resolvedMethods =
        new HashMap<SootMethod, SootMethod>() {
          {
            put(mainPrintMethod, resolvedMainMethod);
            put(mainPrintMethod, resolvedWritePrintMethod);
            put(mainPrintMethod, resolvedReadPrintMethod);
            put(readInterfaceRead, resolvedDefaultReadMethod);
            put(writeInterfaceWrite, resolvedDefaultWriteMethod);
          }
        };

    Map<SootMethod, SootMethod> methodRef =
        new HashMap<SootMethod, SootMethod>() {
          {
            put(mainPrintMethod, refMainMethod);
            put(writeInterfacePrint, refWritePrintMethod);
            put(readInterfacePrint, refReadPrintMethod);
            put(readInterfaceRead, refDefaultRead);
            put(writeInterfaceWrite, refDefaultWrite);
          }
        };

    Map<SootMethod, SootMethod> concreteImpl =
        new HashMap<SootMethod, SootMethod>() {
          {
            put(mainPrintMethod, concreteImplMainPrint);
            put(mainPrintMethod, concreteImplWritePrint);
            put(mainPrintMethod, concreteImplReadPrint);
            put(readInterfaceRead, concreteImplDefaultRead);
            put(writeInterfaceWrite, concreteImplDefaultWrite);
          }
        };

    ArrayList<Boolean> edgePresent =
        new ArrayList<Boolean>() {
          {
            add(edgeMainPrintToReadPrint);
            add(edgeMainPrintToWritePrint);
            add(edgeMainMethodToPrint);
            add(edgeMainMethodToReadMethod);
            add(edgeMainMethodToWriteMethod);
          }
        };

    ArrayList<Boolean> edgeNotPresent =
        new ArrayList<Boolean>() {
          {
            add(edgeMainMethodToReadPrint);
            add(edgeMainMethodToWritePrint);
          }
        };

    for (Map.Entry<SootMethod, String> targetMethod : targetMethods.entrySet()) {
      assertNotNull(targetMethod.getKey());
    }
    for (Map.Entry<SootMethod, SootMethod> virtualResolvedMethod : resolvedMethods.entrySet()) {
      assertEquals(virtualResolvedMethod.getKey(), virtualResolvedMethod.getValue());
    }
    for (Map.Entry<SootMethod, SootMethod> methodRef1 : methodRef.entrySet()) {
      assertEquals(methodRef1.getKey(), methodRef1.getValue());
    }
    for (Map.Entry<SootMethod, String> targetMethod : targetMethods.entrySet()) {
      assertEquals(targetMethod.getKey().getName(), targetMethod.getValue());
    }
    for (Map.Entry<SootMethod, String> targetMethod : targetMethods.entrySet()) {
      assertTrue(reachableMethods.contains(targetMethod.getKey()));
    }
    for (boolean isPresent : edgePresent) {
      assertTrue(isPresent);
    }
    for (boolean notPresent : edgeNotPresent) {
      assertFalse(notPresent);
    }
    for (Map.Entry<SootMethod, SootMethod> concreteImpl1 : concreteImpl.entrySet()) {
      assertEquals(concreteImpl1.getKey(), concreteImpl1.getValue());
    }
  }
"
"  @Test
  public void classInterfaceWithSameSignatureTest() {
    String testClass = ""soot.defaultInterfaceMethods.ClassInterfaceSameSignature"";
    String defaultClass = ""soot.defaultInterfaceMethods.HelloWorld"";

    final SootMethod target =
        prepareTarget(
            methodSigFromComponents(testClass, voidType, mainClass),
            testClass,
            defaultClass);

    SootMethod mainPrintMethod =
        Scene.v()
            .getMethod(""<soot.defaultInterfaceMethods.ClassInterfaceSameSignature: void print()>"");
    SootMethod defaultPrintMethod =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.HelloWorld: void print()>"");

    Body mainBody = target.retrieveActiveBody();
    SootMethod refMainMethod = resolveMethodRefInBody(mainBody.getUnits(), ""void print()"");
    SootMethod resolvedMethod =
        VirtualCalls.v()
            .resolveNonSpecial(
                Scene.v().getRefType(testClass), defaultPrintMethod.makeRef(), false);
    SootMethod concreteImpl =
        Scene.v()
            .getFastHierarchy()
            .resolveConcreteDispatch(Scene.v().getSootClass(testClass), defaultPrintMethod);
    Set<SootMethod> abstractImpl =
        Scene.v()
            .getFastHierarchy()
            .resolveAbstractDispatch(Scene.v().getSootClass(defaultClass), defaultPrintMethod);
    boolean edgeMainMethodToMainPrint = checkInEdges(mainPrintMethod, target);
    boolean edgeMainPrintToDefaultPrint = checkInEdges(defaultPrintMethod, target);
    final ReachableMethods reachableMethods = Scene.v().getReachableMethods();

    Map<SootMethod, String> targetMethods =
        new HashMap<SootMethod, String>() {
          {
            put(mainPrintMethod, ""print"");
            put(defaultPrintMethod, ""print"");
          }
        };

    ArrayList<Boolean> edgePresent =
        new ArrayList<Boolean>() {
          {
            add(edgeMainMethodToMainPrint);
          }
        };

    for (Map.Entry<SootMethod, String> targetMethod : targetMethods.entrySet()) {
      assertNotNull(targetMethod.getKey());
    }
    assertEquals(mainPrintMethod, resolvedMethod);
    assertEquals(mainPrintMethod, refMainMethod);
    for (Map.Entry<SootMethod, String> targetMethod : targetMethods.entrySet()) {
      assertEquals(targetMethod.getKey().getName(), targetMethod.getValue());
    }

    assertTrue(reachableMethods.contains(mainPrintMethod));

    for (boolean isPresent : edgePresent) {
      assertTrue(isPresent);
    }
    assertEquals(mainPrintMethod, concreteImpl);
    assertTrue(
        abstractImpl.contains(
            Scene.v()
                .getMethod(
                    ""<soot.defaultInterfaceMethods.ClassInterfaceSameSignature: void print()>"")));
  }
"
"  @Test
  public void superClassInterfaceWithSameSignatureTest() {
    String testClass = ""soot.defaultInterfaceMethods.SuperClassInterfaceSameSignature"";
    String defaultClass = ""soot.defaultInterfaceMethods.PrintInterface"";
    String defaultSuperClass = ""soot.defaultInterfaceMethods.DefaultPrint"";
    String superClassImplementsInterface = ""soot.defaultInterfaceMethods.SuperClassImplementsInterface"";

    final SootMethod target =
        prepareTarget(
            methodSigFromComponents(testClass, voidType, mainClass),
            testClass,
            defaultClass,
            superClassImplementsInterface);

    SootMethod defaultSuperMainMethod =
        Scene.v()
            .getMethod(""<soot.defaultInterfaceMethods.SuperClassImplementsInterface: void main()>"");
    SootMethod mainMethod =
        Scene.v()
            .getMethod(
                ""<soot.defaultInterfaceMethods.SuperClassImplementsInterface: void print()>"");
    SootMethod defaultMethod =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.PrintInterface: void print()>"");
    SootMethod defaultSuperClassMethod =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.DefaultPrint: void print()>"");

    Body mainBody = target.retrieveActiveBody();
    SootMethod refMainMethod = resolveMethodRefInBody(mainBody.getUnits(), ""void print()"");

    SootMethod resolvedMethod =
        VirtualCalls.v()
            .resolveNonSpecial(Scene.v().getRefType(testClass), defaultMethod.makeRef(), false);
    SootMethod resolvedSuperClassDefaultMethod =
        VirtualCalls.v()
            .resolveNonSpecial(
                Scene.v().getRefType(testClass), defaultSuperClassMethod.makeRef(), false);

    SootMethod concreteImpl =
        Scene.v()
            .getFastHierarchy()
            .resolveConcreteDispatch(Scene.v().getSootClass(testClass), defaultMethod);

    Set<SootMethod> abstractImpl =
        Scene.v()
            .getFastHierarchy()
            .resolveAbstractDispatch(Scene.v().getSootClass(defaultClass), defaultMethod);
    Set<SootMethod> abstractImplSuperClass =
        Scene.v()
            .getFastHierarchy()
            .resolveAbstractDispatch(
                Scene.v().getSootClass(defaultSuperClass), defaultSuperClassMethod);

    boolean edgeMainToSuperClassPrint = checkInEdges(mainMethod, target);
    boolean edgeMainToDefaultPrint = checkInEdges(defaultMethod, target);
    boolean edgeMainToSuperDefaultPrint = checkInEdges(defaultSuperClassMethod, target);
    boolean edgeSuperMainToSuperPrint =
        checkInEdges(defaultSuperClassMethod, defaultSuperMainMethod);

    final ReachableMethods reachableMethods = Scene.v().getReachableMethods();

    List<SootMethod> targetMethods =
        new ArrayList<SootMethod>() {
          {
            add(mainMethod);
            add(defaultMethod);
            add(defaultSuperClassMethod);
          }
        };

    ArrayList<Boolean> edgeNotPresent =
        new ArrayList<Boolean>() {
          {
            add(edgeMainToDefaultPrint);
            add(edgeMainToSuperDefaultPrint);
            add(edgeSuperMainToSuperPrint);
          }
        };

    Map<SootMethod, SootMethod> resolvedMethods =
        new HashMap<SootMethod, SootMethod>() {
          {
            put(mainMethod, resolvedMethod);
            put(resolvedSuperClassDefaultMethod, resolvedMethod);
          }
        };

    for (SootMethod targetMethod : targetMethods) {
      assertNotNull(targetMethod);
    }
    assertEquals(targetMethods.get(0), refMainMethod);
    assertEquals(targetMethods.get(0).getName(), ""print"");
    assertTrue(edgeMainToSuperClassPrint);
    for (boolean notPresent : edgeNotPresent) {
      assertFalse(notPresent);
    }
    assertEquals(targetMethods.get(0), concreteImpl);
    assertNotEquals(targetMethods.get(1), concreteImpl);
    assertTrue(
        abstractImpl.contains(
            Scene.v()
                .getMethod(
                    ""<soot.defaultInterfaceMethods.SuperClassImplementsInterface: void print()>"")));
    assertTrue(
        abstractImplSuperClass.contains(
            Scene.v()
                .getMethod(
                    ""<soot.defaultInterfaceMethods.SuperClassImplementsInterface: void print()>"")));
  }
"
"  @Test
  public void derivedInterfacesTest() {
    String testClassSig = ""soot.defaultInterfaceMethods.DerivedInterfaces"";
    String defaultInterfaceOneSig = ""soot.defaultInterfaceMethods.InterfaceTestOne"";
    String defaultInterfaceTwoSig = ""soot.defaultInterfaceMethods.InterfaceTestTwo"";

    final SootMethod target =
        prepareTarget(
            methodSigFromComponents(testClassSig, voidType, mainClass),
            testClassSig,
            defaultInterfaceOneSig,
            defaultInterfaceTwoSig);

    FastHierarchy fh = Scene.v().getFastHierarchy();
    SootClass testClass = Scene.v().getSootClass(testClassSig);
    SootClass defaultInterfaceOne = Scene.v().getSootClass(defaultInterfaceOneSig);
    SootClass defaultInterfaceTwo = Scene.v().getSootClass(defaultInterfaceTwoSig);

    SootMethod interfaceOnePrint =
        Scene.v().getMethod(methodSigFromComponents(defaultInterfaceOneSig, ""void print()""));
    SootMethod interfaceTwoPrint =
        Scene.v().getMethod(methodSigFromComponents(defaultInterfaceTwoSig, ""void print()""));

    SootMethod refMainMethod =
        resolveMethodRefInBody(target.retrieveActiveBody().getUnits(), ""void print()"");

    SootMethod interfaceOneResolvedMethod =
        VirtualCalls.v().resolveNonSpecial(testClass.getType(), interfaceOnePrint.makeRef(), false);
    SootMethod interfaceTwoResolvedMethod =
        VirtualCalls.v().resolveNonSpecial(testClass.getType(), interfaceTwoPrint.makeRef(), false);

    SootMethod concreteImplInterfaceOne = fh.resolveConcreteDispatch(testClass, interfaceOnePrint);
    SootMethod concreteImplInterfaceTwo = fh.resolveConcreteDispatch(testClass, interfaceTwoPrint);

    Set<SootMethod> abstractImplInterfaceOne =
        fh.resolveAbstractDispatch(defaultInterfaceOne, interfaceOnePrint);

    boolean edgeMainToInterfaceTwoPrint = checkInEdges(interfaceTwoPrint, target);
    boolean edgeMainToInterfaceOnePrint = checkInEdges(interfaceOnePrint, target);

    final ReachableMethods reachableMethods = Scene.v().getReachableMethods();

    List<SootMethod> targetMethods =
        new ArrayList<SootMethod>() {
          {
            add(interfaceOnePrint);
            add(interfaceTwoPrint);
          }
        };

    Map<SootMethod, SootMethod> resolvedMethods =
        new HashMap<SootMethod, SootMethod>() {
          {
            put(interfaceTwoPrint, interfaceOneResolvedMethod);
            put(interfaceTwoPrint, interfaceTwoResolvedMethod);
          }
        };

    Map<SootMethod, SootMethod> concreteImplTrue =
        new HashMap<SootMethod, SootMethod>() {
          {
            put(interfaceTwoPrint, concreteImplInterfaceOne);
            put(interfaceTwoPrint, concreteImplInterfaceTwo);
          }
        };

    Map<SootMethod, SootMethod> concreteImplNotTrue =
        new HashMap<SootMethod, SootMethod>() {
          {
            put(interfaceOnePrint, concreteImplInterfaceOne);
            put(interfaceOnePrint, concreteImplInterfaceTwo);
          }
        };

    for (SootMethod targetMethod : targetMethods) {
      Assert.assertNotNull(targetMethod);
    }
    assertEquals(targetMethods.get(1), refMainMethod);
    assertEquals(targetMethods.get(1).getName(), ""print"");
    assertFalse(edgeMainToInterfaceOnePrint);
    assertTrue(edgeMainToInterfaceTwoPrint);
    assertTrue(reachableMethods.contains(targetMethods.get(1)));
    assertFalse(reachableMethods.contains(targetMethods.get(0)));
    for (Map.Entry<SootMethod, SootMethod> virtualResolvedMethod : resolvedMethods.entrySet()) {
      assertEquals(virtualResolvedMethod.getKey(), virtualResolvedMethod.getValue());
    }
    for (Map.Entry<SootMethod, SootMethod> concreteImpl : concreteImplTrue.entrySet()) {
      assertEquals(concreteImpl.getKey(), concreteImpl.getValue());
    }
    for (Map.Entry<SootMethod, SootMethod> concreteImpl : concreteImplNotTrue.entrySet()) {
      assertNotEquals(concreteImpl.getKey(), concreteImpl.getValue());
    }
    assertEquals(Sets.newHashSet(targetMethods.get(1)), abstractImplInterfaceOne);

    assertEquals(
        Sets.newHashSet(targetMethods.get(1)),
        fh.resolveAbstractDispatch(defaultInterfaceTwo, interfaceTwoPrint));
  }
"
"  @Test
  public void interfaceInheritanceTest() {
    String testClass = ""soot.defaultInterfaceMethods.InterfaceInheritance"";
    String defaultClass = ""soot.defaultInterfaceMethods.InterfaceTestA"";
    String defaultInterface = ""soot.defaultInterfaceMethods.InterfaceTestB"";

    final SootMethod target =
        prepareTarget(
            methodSigFromComponents(testClass, voidType, mainClass),
            testClass,
            defaultClass,
            defaultInterface);

    SootMethod interfaceTestAPrint =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.InterfaceTestA: void print()>"");
    SootMethod mainPrintMessageMethod =
        Scene.v()
            .getMethod(""<soot.defaultInterfaceMethods.InterfaceInheritance: void printMessage()>"");
    Body mainBody = target.retrieveActiveBody();
    SootMethod refMainMethod = resolveMethodRefInBody(mainBody.getUnits(), ""void print()"");
    SootMethod resolvedMethod =
        VirtualCalls.v()
            .resolveNonSpecial(
                Scene.v().getRefType(testClass), interfaceTestAPrint.makeRef(), false);
    SootMethod concreteImpl =
        Scene.v()
            .getFastHierarchy()
            .resolveConcreteDispatch(Scene.v().getSootClass(testClass), interfaceTestAPrint);
    Set<SootMethod> abstractImpl =
        Scene.v()
            .getFastHierarchy()
            .resolveAbstractDispatch(Scene.v().getSootClass(defaultClass), interfaceTestAPrint);

    boolean edgeMainToInterfaceTestAPrint = checkInEdges(interfaceTestAPrint, target);
    boolean edgeMainToMainPrintMessage = checkInEdges(mainPrintMessageMethod, target);
    final ReachableMethods reachableMethods = Scene.v().getReachableMethods();

    List<SootMethod> targetMethods =
        new ArrayList<SootMethod>() {
          {
            add(interfaceTestAPrint);
            add(mainPrintMessageMethod);
          }
        };

    for (SootMethod targetMethod : targetMethods) {
      Assert.assertNotNull(targetMethod);
    }
    assertEquals(targetMethods.get(0), refMainMethod);
    assertEquals(targetMethods.get(0).getName(), ""print"");
    assertTrue(edgeMainToInterfaceTestAPrint);
    assertFalse(edgeMainToMainPrintMessage);
    assertTrue(reachableMethods.contains(targetMethods.get(0)));
    assertFalse(reachableMethods.contains(targetMethods.get(1)));
    assertEquals(targetMethods.get(0), resolvedMethod);
    assertEquals(targetMethods.get(0), concreteImpl);
    assertTrue(abstractImpl.contains(targetMethods.get(0)));
  }
"
"  @Test
  public void interfaceReAbstractionTest() {
    String testClass = ""soot.defaultInterfaceMethods.InterfaceReAbstracting"";
    String defaultClass = ""soot.defaultInterfaceMethods.InterfaceA"";
    String defaultInterface = ""soot.defaultInterfaceMethods.InterfaceB"";

    final SootMethod target =
        prepareTarget(
            methodSigFromComponents(testClass, ""void"", ""main""),
            testClass,
            defaultClass,
            defaultInterface);

    SootMethod interfaceAPrint =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.InterfaceA: void print()>"");
    SootMethod mainMethodPrint =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.InterfaceReAbstracting: void print()>"");

    Body mainBody = target.retrieveActiveBody();
    SootMethod refMainMethod = resolveMethodRefInBody(mainBody.getUnits(), ""void print()"");
    SootMethod resolvedMethod =
        VirtualCalls.v()
            .resolveNonSpecial(Scene.v().getRefType(testClass), interfaceAPrint.makeRef(), false);
    SootMethod concreteImpl =
        Scene.v()
            .getFastHierarchy()
            .resolveConcreteDispatch(Scene.v().getSootClass(testClass), interfaceAPrint);
    Set<SootMethod> abstractImpl =
        Scene.v()
            .getFastHierarchy()
            .resolveAbstractDispatch(Scene.v().getSootClass(defaultClass), interfaceAPrint);

    boolean edgeMainMethodToMainPrint = checkInEdges(mainMethodPrint, target);
    boolean edgeMainMethodToInterfaceAPrint = checkInEdges(interfaceAPrint, target);
    final ReachableMethods reachableMethods = Scene.v().getReachableMethods();

    List<SootMethod> targetMethods =
        new ArrayList<SootMethod>() {
          {
            add(mainMethodPrint);
            add(interfaceAPrint);
          }
        };

    for (SootMethod targetMethod : targetMethods) {
      Assert.assertNotNull(targetMethod);
    }
    assertEquals(targetMethods.get(0), refMainMethod);
    assertEquals(targetMethods.get(0).getName(), ""print"");
    assertTrue(edgeMainMethodToMainPrint);
    assertFalse(edgeMainMethodToInterfaceAPrint);
    assertTrue(reachableMethods.contains(targetMethods.get(0)));
    assertFalse(reachableMethods.contains(targetMethods.get(1)));
    assertEquals(targetMethods.get(0), resolvedMethod);
    assertEquals(targetMethods.get(0), concreteImpl);
    assertNotEquals(targetMethods.get(1), concreteImpl);
    assertEquals(
        Sets.newHashSet(
            Scene.v()
                .getMethod(""<soot.defaultInterfaceMethods.InterfaceReAbstracting: void print()>"")),
        abstractImpl);
  }
"
"  @Test
  public void superClassPreferenceOverDefaultMethodTest() {
    String testClass = ""soot.defaultInterfaceMethods.SuperClassPreferenceOverDefaultMethod"";
    String defaultInterfaceOne = ""soot.defaultInterfaceMethods.InterfaceOne"";
    String defaultInterfaceTwo = ""soot.defaultInterfaceMethods.InterfaceTwo"";
    String defaultSuperClass = ""soot.defaultInterfaceMethods.SuperClass"";

    final SootMethod target =
        prepareTarget(
            methodSigFromComponents(testClass, voidType, mainClass),
            testClass,
            defaultInterfaceOne,
            defaultInterfaceTwo,
            defaultSuperClass);

    SootMethod interfaceOnePrint =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.InterfaceOne: void print()>"");
    SootMethod interfaceTwoPrint =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.InterfaceTwo: void print()>"");
    SootMethod superClassPrint =
        Scene.v().getMethod(""<soot.defaultInterfaceMethods.SuperClass: void print()>"");

    Body mainBody = target.retrieveActiveBody();
    SootMethod refMainMethod = resolveMethodRefInBody(mainBody.getUnits(), ""void print()"");

    SootMethod resolvedInterfaceOneDefaultMethod =
        VirtualCalls.v()
            .resolveNonSpecial(Scene.v().getRefType(testClass), interfaceOnePrint.makeRef(), false);
    SootMethod resolvedInterfaceTwoDefaultMethod =
        VirtualCalls.v()
            .resolveNonSpecial(Scene.v().getRefType(testClass), interfaceTwoPrint.makeRef(), false);

    SootMethod concreteImplInterfaceOne =
        Scene.v()
            .getFastHierarchy()
            .resolveConcreteDispatch(Scene.v().getSootClass(testClass), interfaceOnePrint);
    SootMethod concreteImplInterfaceTwo =
        Scene.v()
            .getFastHierarchy()
            .resolveConcreteDispatch(Scene.v().getSootClass(testClass), interfaceTwoPrint);

    Set<SootMethod> abstractImplInterfaceOne =
        Scene.v()
            .getFastHierarchy()
            .resolveAbstractDispatch(
                Scene.v().getSootClass(defaultInterfaceOne), interfaceOnePrint);
    Set<SootMethod> abstractImplInterfaceTwo =
        Scene.v()
            .getFastHierarchy()
            .resolveAbstractDispatch(
                Scene.v().getSootClass(defaultInterfaceTwo), interfaceTwoPrint);

    boolean edgeMainToInterfaceOnePrint = checkInEdges(interfaceOnePrint, target);
    boolean edgeMainToInterfaceTwoPrint = checkInEdges(interfaceTwoPrint, target);
    boolean edgeMainToSuperClassPrint = checkInEdges(superClassPrint, target);

    final ReachableMethods reachableMethods = Scene.v().getReachableMethods();

    List<SootMethod> targetMethods =
        new ArrayList<SootMethod>() {
          {
            add(superClassPrint);
            add(interfaceOnePrint);
            add(interfaceTwoPrint);
          }
        };

    ArrayList<Boolean> edgeNotPresent =
        new ArrayList<Boolean>() {
          {
            add(edgeMainToInterfaceOnePrint);
            add(edgeMainToInterfaceTwoPrint);
          }
        };

    Map<SootMethod, SootMethod> resolvedMethods =
        new HashMap<SootMethod, SootMethod>() {
          {
            put(superClassPrint, resolvedInterfaceOneDefaultMethod);
            put(superClassPrint, resolvedInterfaceTwoDefaultMethod);
          }
        };

    Map<SootMethod, SootMethod> concreteImplTrue =
        new HashMap<SootMethod, SootMethod>() {
          {
            put(superClassPrint, concreteImplInterfaceOne);
            put(superClassPrint, concreteImplInterfaceTwo);
          }
        };

    Map<SootMethod, SootMethod> concreteImplNotTrue =
        new HashMap<SootMethod, SootMethod>() {
          {
            put(interfaceOnePrint, concreteImplInterfaceOne);
            put(interfaceOnePrint, concreteImplInterfaceTwo);
          }
        };

    for (SootMethod targetMethod : targetMethods) {
      assertNotNull(targetMethod);
    }
    assertEquals(targetMethods.get(0), refMainMethod);
    assertEquals(targetMethods.get(0).getName(), ""print"");
    assertTrue(edgeMainToSuperClassPrint);
    for (boolean notPresent : edgeNotPresent) {
      assertFalse(notPresent);
    }
    assertTrue(reachableMethods.contains(targetMethods.get(0)));
    assertFalse(reachableMethods.contains(targetMethods.get(1)));
    assertFalse(reachableMethods.contains(targetMethods.get(2)));
    for (Map.Entry<SootMethod, SootMethod> virtualResolvedMethod : resolvedMethods.entrySet()) {
      assertEquals(virtualResolvedMethod.getKey(), virtualResolvedMethod.getValue());
    }
    for (Map.Entry<SootMethod, SootMethod> concreteImpl : concreteImplTrue.entrySet()) {
      assertEquals(concreteImpl.getKey(), concreteImpl.getValue());
    }
    for (Map.Entry<SootMethod, SootMethod> concreteImpl : concreteImplNotTrue.entrySet()) {
      assertNotEquals(concreteImpl.getKey(), concreteImpl.getValue());
    }
    assertTrue(
        abstractImplInterfaceOne.contains(
            Scene.v().getMethod(""<soot.defaultInterfaceMethods.SuperClass: void print()>"")));
    assertTrue(
        abstractImplInterfaceTwo.contains(
            Scene.v().getMethod(""<soot.defaultInterfaceMethods.SuperClass: void print()>"")));
  }
"
"  @Test
  public void maximallySpecificSuperInterface() {
    String targetClassName = ""soot.defaultInterfaceMethods.MaximallySpecificSuperInterface"";
    String superClass = ""soot.defaultInterfaceMethods.B"";
    String subInterface = ""soot.defaultInterfaceMethods.C"";
    String superInterface = ""soot.defaultInterfaceMethods.D"";

    final SootMethod mainMethod =
        prepareTarget(
            methodSigFromComponents(targetClassName, voidType, mainClass),
            targetClassName,
            superClass,
            subInterface,
            superInterface);

    SootClass testClass = mainMethod.getDeclaringClass();

    SootMethod subInterfacePrint =
        Scene.v().getMethod(methodSigFromComponents(subInterface, ""void print()""));
    SootMethod superInterfacePrint =
        Scene.v().getMethod(methodSigFromComponents(superInterface, ""void print()""));

    SootMethod methodRefResolved =
        resolveMethodRefInBody(mainMethod.retrieveActiveBody().getUnits(), ""void print()"");
    assertEquals(subInterfacePrint, methodRefResolved);

    SootMethod virtualCallsResolved =
        VirtualCalls.v()
            .resolveNonSpecial(testClass.getType(), superInterfacePrint.makeRef(), false);
    assertEquals(subInterfacePrint, virtualCallsResolved);

    SootMethod concreteImplI1 =
        Scene.v().getFastHierarchy().resolveConcreteDispatch(testClass, superInterfacePrint);
    assertEquals(subInterfacePrint, concreteImplI1);

    Set<SootMethod> abstractImpl =
        Scene.v()
            .getFastHierarchy()
            .resolveAbstractDispatch(superInterfacePrint.getDeclaringClass(), superInterfacePrint);
    assertEquals(Sets.newHashSet(subInterfacePrint), abstractImpl);

    assertTrue(checkInEdges(subInterfacePrint, mainMethod));
    assertTrue(Scene.v().getReachableMethods().contains(subInterfacePrint));
  }
"
"  @Test
  public void testCachingInvalidation() throws Exception {
    SootMethod m1 = prepareTarget(methodSigFromComponents(TEST_TARGET_CLASS, ""void"", ""m1""), TEST_TARGET_CLASS);
    final SootClass clas = m1.getDeclaringClass();

    // There are only 3 methods in the class originally.
    Assert.assertEquals(Arrays.asList(""<init>"", ""m1"", ""m2""),
        clas.getMethods().stream().map(SootMethod::getName).sorted().collect(Collectors.toList()));

    // Ensure the previous value of SootMethodRefImpl#resolveCache
    // is not used if the referenced method itself is modified.
    final Body b = m1.retrieveActiveBody();
    final SootMethodRef mRef = getMethodRef(b);
    Assert.assertEquals(""m2"", mRef.getName());

    // Get the original referenced method appearing in the test source (i.e. ""m2"")
    final SootMethod origM = mRef.resolve();
    Assert.assertTrue(!origM.isPhantom());
    Assert.assertEquals(""m2"", origM.getName());

    // Change the name of the method so the method reference no
    // longer refers to that method.
    origM.setName(""newMethodName"");
    Assert.assertEquals(""newMethodName"", origM.getName());

    // Changing the method itself does not change the reference
    Assert.assertEquals(""m2"", mRef.getName());

    // There are still just 3 methods in the class (but ""m2"" was renamed).
    Assert.assertEquals(Arrays.asList(""<init>"", ""m1"", ""newMethodName""),
        clas.getMethods().stream().map(SootMethod::getName).sorted().collect(Collectors.toList()));

    // When resolving the reference, the cached value is not used since the
    // original method was renamed. It now gives a different method (that was
    // created automatically since a method with the name ""m2"" no longer exists).
    final SootMethod newM = mRef.resolve();
    Assert.assertNotSame(origM, newM);
    Assert.assertEquals(""m2"", newM.getName());

    // There are now 4 methods since resolving ""m2"" created it again.
    Assert.assertEquals(Arrays.asList(""<init>"", ""m1"", ""m2"", ""newMethodName""),
        clas.getMethods().stream().map(SootMethod::getName).sorted().collect(Collectors.toList()));
  }
"
"  @Test
  public void lambdaNoCaptures() {
    String testClass = ""soot.lambdaMetaFactory.LambdaNoCaptures"";

    final SootMethod target = prepareTarget(methodSigFromComponents(testClass, TEST_METHOD_RET, TEST_METHOD_NAME), testClass,
        ""java.util.function.Function"");

    final CallGraph cg = Scene.v().getCallGraph();

    final String metaFactoryClass = getMetaFactoryNameLambda(testClass, TEST_METHOD_NAME);

    final SootMethod bootstrap
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.util.function.Function"", ""bootstrap$""));
    final SootMethod metaFactoryConstructor
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""void"", ""<init>""));
    final SootMethod apply
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.lang.Object"", ""apply"", ""java.lang.Object""));
    final SootMethod lambdaBody
        = Scene.v().getMethod(methodSigFromComponents(testClass, ""java.lang.String"", ""lambda$main$0"", ""java.lang.Integer""));
    final SootMethod staticCallee
        = Scene.v().getMethod(methodSigFromComponents(testClass, ""void"", ""staticCallee"", ""java.lang.Integer""));

    final List<Edge> edgesFromTarget = newArrayList(cg.edgesOutOf(target));

    assertTrue(""There should be an edge from main to the bootstrap method of the synthetic LambdaMetaFactory"",
        edgesFromTarget.stream().anyMatch(e -> e.tgt().equals(bootstrap) && e.isStatic()));
    assertTrue(""There should be an edge to the constructor of the LambdaMetaFactory in the bootstrap method"",
        newArrayList(cg.edgesOutOf(bootstrap)).stream()
            .anyMatch(e -> e.tgt().equals(metaFactoryConstructor) && e.isSpecial()));
    assertTrue(
        ""There should be an instance invocation on the synthetic LambdaMetaFactory's implementation of the functional interface in the main method"",
        edgesFromTarget.stream().anyMatch(e -> e.getTgt().equals(apply) && e.kind() == Kind.INTERFACE));
    assertTrue(
        ""There should be a static call to the lambda body implementation in the generated functional interface implementation of the synthetic LambdaMetaFactory"",
        newArrayList(cg.edgesOutOf(apply)).stream().anyMatch(e -> e.getTgt().equals(lambdaBody) && e.isStatic()));

    assertTrue(""There should be a static call to the staticCallee method in actual lambda body implementation"",
        newArrayList(cg.edgesOutOf(lambdaBody)).stream().anyMatch(e -> e.getTgt().equals(staticCallee) && e.isStatic()));

    validateAllBodies(target.getDeclaringClass(), bootstrap.getDeclaringClass());
  }
"
"  @Test
  public void lambdaWithCaptures() {
    String testClass = ""soot.lambdaMetaFactory.LambdaWithCaptures"";

    final SootMethod target
        = prepareTarget(methodSigFromComponents(testClass, TEST_METHOD_RET, TEST_METHOD_NAME), testClass);

    final CallGraph cg = Scene.v().getCallGraph();

    final String metaFactoryClass = getMetaFactoryNameLambda(testClass, TEST_METHOD_NAME);

    final SootMethod bootstrap = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.util.function.Supplier"",
        ""bootstrap$"", testClass, ""java.lang.String""));
    final SootMethod metaFactoryConstructor
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""void"", ""<init>"", testClass, ""java.lang.String""));
    final SootMethod get = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.lang.Object"", ""get""));
    final SootMethod lambdaBody
        = Scene.v().getMethod(methodSigFromComponents(testClass, ""java.lang.String"", ""lambda$main$0"", ""java.lang.String""));
    final SootMethod getString = Scene.v().getMethod(methodSigFromComponents(testClass, ""java.lang.String"", ""getString""));

    final List<Edge> edgesFromTarget = newArrayList(cg.edgesOutOf(target));

    assertTrue(""There should be an edge from main to the bootstrap method of the synthetic LambdaMetaFactory"",
        edgesFromTarget.stream().anyMatch(e -> e.tgt().equals(bootstrap) && e.isStatic()));
    assertTrue(""There should be an edge to the constructor of the LambdaMetaFactory in the bootstrap method"",
        newArrayList(cg.edgesOutOf(bootstrap)).stream()
            .anyMatch(e -> e.tgt().equals(metaFactoryConstructor) && e.isSpecial()));
    assertTrue(
        ""There should be an interface invocation on the synthetic LambdaMetaFactory's implementation of the functional interface in the main method"",
        edgesFromTarget.stream().anyMatch(e -> e.getTgt().equals(get) && e.kind() == Kind.INTERFACE));
    assertTrue(
        ""There should be a virtual call to the lambda body implementation in the generated functional interface implementation of the synthetic LambdaMetaFactory"",
        newArrayList(cg.edgesOutOf(get)).stream().anyMatch(e -> e.getTgt().equals(lambdaBody) && e.isVirtual()));

    assertTrue(""There should be a special call to the getString method in actual lambda body implementation"",
        newArrayList(cg.edgesOutOf(lambdaBody)).stream().anyMatch(e -> e.getTgt().equals(getString) && e.isSpecial()));

    validateAllBodies(target.getDeclaringClass(), bootstrap.getDeclaringClass());
  }
"
"  @Test
  public void markerInterfaces() {
    String testClass = ""soot.lambdaMetaFactory.MarkerInterfaces"";

    final SootMethod target
        = prepareTarget(methodSigFromComponents(testClass, TEST_METHOD_RET, TEST_METHOD_NAME), testClass);

    final CallGraph cg = Scene.v().getCallGraph();

    final String metaFactoryClass = getMetaFactoryNameLambda(testClass, TEST_METHOD_NAME);

    final SootMethod bootstrap = Scene.v()
        .getMethod(methodSigFromComponents(metaFactoryClass, ""java.util.function.Supplier"", ""bootstrap$"", testClass));
    final SootMethod metaFactoryConstructor
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""void"", ""<init>"", testClass));
    final SootMethod get = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.lang.Object"", ""get""));
    final SootMethod lambdaBody
        = Scene.v().getMethod(methodSigFromComponents(testClass, ""java.lang.Object"", ""lambda$main$0""));
    final SootMethod getString = Scene.v().getMethod(methodSigFromComponents(testClass, ""java.lang.String"", ""getString""));

    final List<Edge> edgesFromTarget = newArrayList(cg.edgesOutOf(target));

    assertTrue(""There should be an edge from main to the bootstrap method of the synthetic LambdaMetaFactory"",
        edgesFromTarget.stream().anyMatch(e -> e.tgt().equals(bootstrap) && e.isStatic()));
    assertTrue(""There should be an edge to the constructor of the LambdaMetaFactory in the bootstrap method"",
        newArrayList(cg.edgesOutOf(bootstrap)).stream()
            .anyMatch(e -> e.tgt().equals(metaFactoryConstructor) && e.isSpecial()));
    assertTrue(
        ""There should be an interface invocation on the synthetic LambdaMetaFactory's implementation of the functional interface in the main method"",
        edgesFromTarget.stream().anyMatch(e -> e.getTgt().equals(get) && e.kind() == Kind.INTERFACE));
    assertTrue(
        ""There should be a virtual call to the lambda body implementation in the generated functional interface implementation of the synthetic LambdaMetaFactory"",
        newArrayList(cg.edgesOutOf(get)).stream().anyMatch(e -> e.getTgt().equals(lambdaBody) && e.isVirtual()));

    assertTrue(""There should be a virtual call to the getString method in actual lambda body implementation"",
        newArrayList(cg.edgesOutOf(lambdaBody)).stream().anyMatch(e -> e.getTgt().equals(getString) && e.isVirtual()));

    validateAllBodies(target.getDeclaringClass(), bootstrap.getDeclaringClass());
  }
"
"  @Test
  public void staticMethodRef() {
    String testClass = ""soot.lambdaMetaFactory.StaticMethodRef"";

    final SootMethod target
        = prepareTarget(methodSigFromComponents(testClass, TEST_METHOD_RET, TEST_METHOD_NAME), testClass);

    final CallGraph cg = Scene.v().getCallGraph();

    final String referencedMethodName = ""staticMethod"";

    final String metaFactoryClass = getMetaFactoryNameMethodRef(testClass, referencedMethodName);

    final SootMethod bootstrap
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.util.function.Supplier"", ""bootstrap$""));
    final SootMethod metaFactoryConstructor
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""void"", ""<init>""));
    final SootMethod get = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.lang.Object"", ""get""));
    final SootMethod referencedMethod = Scene.v().getMethod(methodSigFromComponents(testClass, ""int"", referencedMethodName));

    final List<Edge> edgesFromTarget = newArrayList(cg.edgesOutOf(target));

    assertTrue(""There should be an edge from main to the bootstrap method of the synthetic LambdaMetaFactory"",
        edgesFromTarget.stream().anyMatch(e -> e.tgt().equals(bootstrap) && e.isStatic()));
    assertTrue(""There should be an edge to the constructor of the LambdaMetaFactory in the bootstrap method"",
        newArrayList(cg.edgesOutOf(bootstrap)).stream()
            .anyMatch(e -> e.tgt().equals(metaFactoryConstructor) && e.isSpecial()));
    assertTrue(
        ""There should be an interface invocation on the synthetic LambdaMetaFactory's implementation of the functional interface in the main method"",
        edgesFromTarget.stream().anyMatch(e -> e.getTgt().equals(get) && e.kind() == Kind.INTERFACE));
    assertTrue(""There should be a static call to the referenced method"",
        newArrayList(cg.edgesOutOf(get)).stream().anyMatch(e -> e.getTgt().equals(referencedMethod) && e.isStatic()));

    validateAllBodies(target.getDeclaringClass(), bootstrap.getDeclaringClass());
  }
"
"  @Test
  public void privateMethodRef() {
    String testClass = ""soot.lambdaMetaFactory.PrivateMethodRef"";

    final SootMethod target
        = prepareTarget(methodSigFromComponents(testClass, TEST_METHOD_RET, TEST_METHOD_NAME), testClass);

    final CallGraph cg = Scene.v().getCallGraph();

    final String referencedMethodName = ""privateMethod"";

    final String metaFactoryClass = getMetaFactoryNameMethodRef(testClass, referencedMethodName);

    final SootMethod bootstrap = Scene.v()
        .getMethod(methodSigFromComponents(metaFactoryClass, ""java.util.function.Supplier"", ""bootstrap$"", testClass));
    final SootMethod metaFactoryConstructor
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""void"", ""<init>"", testClass));
    final SootMethod get = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.lang.Object"", ""get""));
    final SootMethod referencedMethod = Scene.v().getMethod(methodSigFromComponents(testClass, ""int"", referencedMethodName));

    final List<Edge> edgesFromTarget = newArrayList(cg.edgesOutOf(target));

    assertTrue(""There should be an edge from main to the bootstrap method of the synthetic LambdaMetaFactory"",
        edgesFromTarget.stream().anyMatch(e -> e.tgt().equals(bootstrap) && e.isStatic()));
    assertTrue(""There should be an edge to the constructor of the LambdaMetaFactory in the bootstrap method"",
        newArrayList(cg.edgesOutOf(bootstrap)).stream()
            .anyMatch(e -> e.tgt().equals(metaFactoryConstructor) && e.isSpecial()));
    assertTrue(
        ""There should be an interface invocation on the synthetic LambdaMetaFactory's implementation of the functional interface in the main method"",
        edgesFromTarget.stream().anyMatch(e -> e.getTgt().equals(get) && e.kind() == Kind.INTERFACE));
    assertTrue(""There should be a virtual call to the referenced method"",
        newArrayList(cg.edgesOutOf(get)).stream().anyMatch(e -> e.getTgt().equals(referencedMethod) && e.isVirtual()));

    validateAllBodies(target.getDeclaringClass(), bootstrap.getDeclaringClass());
  }
"
"  @Test
  public void publicMethodRef() {
    String testClass = ""soot.lambdaMetaFactory.PublicMethodRef"";

    final SootMethod target
        = prepareTarget(methodSigFromComponents(testClass, TEST_METHOD_RET, TEST_METHOD_NAME), testClass);

    final CallGraph cg = Scene.v().getCallGraph();

    final String referencedMethodName = ""publicMethod"";

    final String metaFactoryClass = getMetaFactoryNameMethodRef(testClass, referencedMethodName);

    final SootMethod bootstrap = Scene.v()
        .getMethod(methodSigFromComponents(metaFactoryClass, ""java.util.function.Supplier"", ""bootstrap$"", testClass));
    final SootMethod metaFactoryConstructor
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""void"", ""<init>"", testClass));
    final SootMethod get = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.lang.Object"", ""get""));
    final SootMethod referencedMethod = Scene.v().getMethod(methodSigFromComponents(testClass, ""int"", referencedMethodName));

    final List<Edge> edgesFromTarget = newArrayList(cg.edgesOutOf(target));

    assertTrue(""There should be an edge from main to the bootstrap method of the synthetic LambdaMetaFactory"",
        edgesFromTarget.stream().anyMatch(e -> e.tgt().equals(bootstrap) && e.isStatic()));
    assertTrue(""There should be an edge to the constructor of the LambdaMetaFactory in the bootstrap method"",
        newArrayList(cg.edgesOutOf(bootstrap)).stream()
            .anyMatch(e -> e.tgt().equals(metaFactoryConstructor) && e.isSpecial()));
    assertTrue(
        ""There should be an interface invocation on the synthetic LambdaMetaFactory's implementation of the functional interface in the main method"",
        edgesFromTarget.stream().anyMatch(e -> e.getTgt().equals(get) && e.kind() == Kind.INTERFACE));
    assertTrue(""There should be a virtual call to the referenced method"",
        newArrayList(cg.edgesOutOf(get)).stream().anyMatch(e -> e.getTgt().equals(referencedMethod) && e.isVirtual()));

    validateAllBodies(target.getDeclaringClass(), bootstrap.getDeclaringClass());
  }
"
"  @Test
  public void constructorMethodRef() {
    String testClass = ""soot.lambdaMetaFactory.ConstructorMethodRef"";

    final SootMethod target
        = prepareTarget(methodSigFromComponents(testClass, TEST_METHOD_RET, TEST_METHOD_NAME), testClass);

    final CallGraph cg = Scene.v().getCallGraph();

    final String referencedMethodName = ""<init>"";

    final String metaFactoryClass = getMetaFactoryNameMethodRef(testClass, referencedMethodName);

    final SootMethod bootstrap
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.util.function.Supplier"", ""bootstrap$""));
    final SootMethod metaFactoryConstructor
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""void"", ""<init>""));
    final SootMethod get = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.lang.Object"", ""get""));
    final SootMethod referencedMethod
        = Scene.v().getMethod(methodSigFromComponents(testClass, ""void"", referencedMethodName));

    final List<Edge> edgesFromTarget = newArrayList(cg.edgesOutOf(target));

    assertTrue(""There should be an edge from main to the bootstrap method of the synthetic LambdaMetaFactory"",
        edgesFromTarget.stream().anyMatch(e -> e.tgt().equals(bootstrap) && e.isStatic()));
    assertTrue(""There should be an edge to the constructor of the LambdaMetaFactory in the bootstrap method"",
        newArrayList(cg.edgesOutOf(bootstrap)).stream()
            .anyMatch(e -> e.tgt().equals(metaFactoryConstructor) && e.isSpecial()));
    assertTrue(
        ""There should be an interface invocation on the synthetic LambdaMetaFactory's implementation of the functional interface  in the main method"",
        edgesFromTarget.stream().anyMatch(e -> e.getTgt().equals(get) && e.kind() == Kind.INTERFACE));
    assertTrue(""There should be a special call to the referenced method"",
        newArrayList(cg.edgesOutOf(get)).stream().anyMatch(e -> e.getTgt().equals(referencedMethod) && e.isSpecial()));

    validateAllBodies(target.getDeclaringClass(), bootstrap.getDeclaringClass());
  }
"
"  @Test
  public void inheritedMethodRef() {
    String testClass = ""soot.lambdaMetaFactory.InheritedMethodRef"";

    final SootMethod target
        = prepareTarget(methodSigFromComponents(testClass, TEST_METHOD_RET, TEST_METHOD_NAME), testClass);

    final CallGraph cg = Scene.v().getCallGraph();

    final String referencedMethodName = ""superMethod"";

    final String metaFactoryClass = getMetaFactoryNameLambda(testClass, TEST_METHOD_NAME);

    final SootMethod bootstrap = Scene.v()
        .getMethod(methodSigFromComponents(metaFactoryClass, ""java.util.function.Supplier"", ""bootstrap$"", testClass));
    final SootMethod metaFactoryConstructor
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""void"", ""<init>"", testClass));
    final SootMethod get = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.lang.Object"", ""get""));
    final SootMethod referencedMethod
        = Scene.v().getMethod(methodSigFromComponents(""soot.lambdaMetaFactory.Super"", ""int"", referencedMethodName));
    final SootMethod lambdaBody
        = Scene.v().getMethod(methodSigFromComponents(testClass, ""java.lang.Integer"", ""lambda$main$0""));

    final List<Edge> edgesFromTarget = newArrayList(cg.edgesOutOf(target));

    assertTrue(""There should be an edge from main to the bootstrap method of the synthetic LambdaMetaFactory"",
        edgesFromTarget.stream().anyMatch(e -> e.tgt().equals(bootstrap) && e.isStatic()));
    assertTrue(""There should be an edge to the constructor of the LambdaMetaFactory in the bootstrap method"",
        newArrayList(cg.edgesOutOf(bootstrap)).stream()
            .anyMatch(e -> e.tgt().equals(metaFactoryConstructor) && e.isSpecial()));
    assertTrue(
        ""There should be an interface invocation on the synthetic LambdaMetaFactory's implementation of the functional interface in the main method"",
        edgesFromTarget.stream().anyMatch(e -> e.getTgt().equals(get) && e.kind() == Kind.INTERFACE));
    //Call is from <soot.lambdaMetaFactory.InheritedMethodRef$lambda_main_0__1
    //to           <soot.lambdaMetaFactory.InheritedMethodRef: java.lang.Integer lambda$main$0()>
    //As such, it needs to be a virtual call.
    assertTrue(
        ""There should be a virtual call to the lambda body implementation in the generated functional interface implementation of the synthetic LambdaMetaFactory"",
        newArrayList(cg.edgesOutOf(get)).stream().anyMatch(e -> e.getTgt().equals(lambdaBody) && e.isVirtual()));
    assertTrue(""There should be a special call to the referenced method"", newArrayList(cg.edgesOutOf(lambdaBody)).stream()
        .anyMatch(e -> e.getTgt().equals(referencedMethod) && e.isSpecial()));

    validateAllBodies(target.getDeclaringClass(), bootstrap.getDeclaringClass());
  }
"
"  @Test
  public void methodRefWithParameters() {
    String testClass = ""soot.lambdaMetaFactory.MethodRefWithParameters"";

    final SootMethod target
        = prepareTarget(methodSigFromComponents(testClass, TEST_METHOD_RET, TEST_METHOD_NAME), testClass);

    final CallGraph cg = Scene.v().getCallGraph();

    final String referencedMethodName = ""staticWithCaptures"";

    final String metaFactoryClass = getMetaFactoryNameMethodRef(testClass, referencedMethodName);

    final SootMethod bootstrap
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.util.function.BiFunction"", ""bootstrap$""));
    final SootMethod metaFactoryConstructor
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""void"", ""<init>""));
    final SootMethod apply = Scene.v().getMethod(
        methodSigFromComponents(metaFactoryClass, ""java.lang.Object"", ""apply"", ""java.lang.Object"", ""java.lang.Object""));
    final SootMethod referencedMethod
        = Scene.v().getMethod(methodSigFromComponents(testClass, ""int"", referencedMethodName, ""int"", ""java.lang.Integer""));

    final List<Edge> edgesFromTarget = newArrayList(cg.edgesOutOf(target));

    assertTrue(""There should be an edge from main to the bootstrap method of the synthetic LambdaMetaFactory"",
        edgesFromTarget.stream().anyMatch(e -> e.tgt().equals(bootstrap) && e.isStatic()));
    assertTrue(""There should be an edge to the constructor of the LambdaMetaFactory in the bootstrap method"",
        newArrayList(cg.edgesOutOf(bootstrap)).stream()
            .anyMatch(e -> e.tgt().equals(metaFactoryConstructor) && e.isSpecial()));
    assertTrue(""There should be an interface invocation on the referenced method"",
        edgesFromTarget.stream().anyMatch(e -> e.getTgt().equals(apply) && e.kind() == Kind.INTERFACE));
    assertTrue(""There should be a static call to the referenced method"",
        newArrayList(cg.edgesOutOf(apply)).stream().anyMatch(e -> e.getTgt().equals(referencedMethod) && e.isStatic()));

    validateAllBodies(target.getDeclaringClass(), bootstrap.getDeclaringClass());
  }
"
"    @Test
    public void constructorReference() {
        String testClass = ""soot.lambdaMetaFactory.Issue1367"";

        final SootMethod target = prepareTarget(
                methodSigFromComponents(testClass, ""java.util.function.Supplier"", ""constructorReference""),
                testClass,
                ""java.util.function.Function"");

        validateAllBodies(target.getDeclaringClass());
    }
"
"  @Test
  public void testNewTest() {
    String testClass = ""soot.lambdaMetaFactory.Issue1292"";
    prepareTarget(
        methodSigFromComponents(testClass, ""void"", ""testNew"", ""java.util.List""),
        testClass,
        ""java.util.function.Function"");
    // if no exception is thrown, everything is working as intended
  }
"
"  @Test
  public void getVertragTest() {
    String testClass = ""soot.lambdaMetaFactory.Issue1146"";

    final SootMethod target = prepareTarget(
        methodSigFromComponents(testClass, ""soot.lambdaMetaFactory.Issue1146$Vertrag"", ""getVertrag"", ""java.lang.String""),
        testClass, ""java.util.function.Function"");
    // if no exception is thrown, everything is working as intended
  }
"
"  @Test
  public void getVertrag2Test() {
    String testClass = ""soot.lambdaMetaFactory.Issue1146"";

    final SootMethod target = prepareTarget(
        methodSigFromComponents(testClass, ""soot.lambdaMetaFactory.Issue1146$Vertrag"", ""getVertrag2"", ""java.lang.String""),
        testClass, ""java.util.function.Function"");
    // if no exception is thrown, everything is working as intended
  }
"
"  @Test
  public void parameterBoxing() {
    String testClass = ""soot.lambdaMetaFactory.Adapt"";

    final SootMethod target = prepareTarget(methodSigFromComponents(testClass, ""void"", ""parameterBoxingTarget""), testClass);

    // TODO more fine-grained testing

    validateAllBodies(target.getDeclaringClass());
  }
"
"  @Test
  public void parameterWidening() {
    String testClass = ""soot.lambdaMetaFactory.Adapt"";

    final SootMethod target = prepareTarget(methodSigFromComponents(testClass, ""void"", ""parameterWidening""), testClass);

    // TODO more fine-grained testing

    validateAllBodies(target.getDeclaringClass());
  }
"
"  @Test
  public void returnBoxing() {
    String testClass = ""soot.lambdaMetaFactory.Adapt"";

    final SootMethod target = prepareTarget(methodSigFromComponents(testClass, ""void"", ""returnBoxing""), testClass);

    // TODO more fine-grained testing

    validateAllBodies(target.getDeclaringClass());
  }
"
"  @Test
  public void returnWidening() {
    String testClass = ""soot.lambdaMetaFactory.Adapt"";

    final SootMethod target = prepareTarget(methodSigFromComponents(testClass, ""void"", ""returnWidening""), testClass);

    // TODO more fine-grained testing

    validateAllBodies(target.getDeclaringClass());
  }
"
"  @Test
  public void nullAssignment() {
    SootMethod target =
        prepareTarget(methodSigFromComponents(TEST_TARGET_CLASS, ""void"", ""prefixVariableNames""), TEST_TARGET_CLASS);

    Body body = target.retrieveActiveBody();
    Assert.assertTrue(body instanceof JimpleBody);

    // Assert all local names are distinct
    Assert.assertTrue(body.getLocals().stream().map(Local::getName).distinct().count() == body.getLocalCount());

    LocalPacker.v().transform(body);

    // Assert all local names are distinct
    Assert.assertTrue(body.getLocals().stream().map(Local::getName).distinct().count() == body.getLocalCount());
  }
"
"  @Test
  public void InvokePolymorphic1() {
    final SootMethod testTarget = prepareTarget(
        methodSigFromComponents(TARGET_CLASS, ""void invokePolymorphicTarget(java.lang.invoke.MethodHandle)""), TARGET_CLASS);

    // We model invokePolymorphic as invokeVirtual
    final List<InvokeExpr> invokes = invokesFromMethod(testTarget);
    Assert.assertEquals(1, invokes.size());
    final InvokeExpr invokePoly = invokes.get(0);
    Assert.assertTrue(invokePoly instanceof VirtualInvokeExpr);
    final SootMethodRef targetMethodRef = invokePoly.getMethodRef();
    Assert.assertEquals(methodSigFromComponents(METHOD_HANDLE_CLASS, METHOD_HANDLE_INVOKE_SUBSIG),
        targetMethodRef.getSignature());
  }
"
"  @Test
  public void InvokeCustom1() {
    final SootMethod testTarget
        = prepareTarget(methodSigFromComponents(TARGET_CLASS, ""void invokeCustomTarget()""), TARGET_CLASS);

    // We model invokeCustom as invokeDynamic
    final List<InvokeExpr> invokes = invokesFromMethod(testTarget);
    Assert.assertEquals(1, invokes.size());
    final InvokeExpr invokeCustom = invokes.get(0);
    Assert.assertTrue(invokeCustom instanceof DynamicInvokeExpr);
    final SootMethodRef targetMethodRef = invokeCustom.getMethodRef();
    Assert.assertEquals(methodSigFromComponents(SootClass.INVOKEDYNAMIC_DUMMY_CLASS_NAME, SUPPLIER_GET_SUBSIG),
        targetMethodRef.getSignature());
    final String callToLambdaMethaFactory
        = ""dynamicinvoke \""get\"" <java.util.function.Supplier ()>() <java.lang.invoke.LambdaMetafactory: java.lang.invoke.CallSite metafactory(java.lang.invoke.MethodHandles$Lookup,java.lang.String,java.lang.invoke.MethodType,java.lang.invoke.MethodType,java.lang.invoke.MethodHandle,java.lang.invoke.MethodType)>(methodtype: java.lang.Object __METHODTYPE__(), methodhandle: \""REF_INVOKE_STATIC\"" <soot.dexpler.instructions.DexBytecodeTarget: java.lang.String lambda$invokeCustomTarget$0()>, methodtype: java.lang.String __METHODTYPE__())"";
    Assert.assertEquals(callToLambdaMethaFactory, invokeCustom.toString());
  }
"
"    @Test
    public void testDisableCopyPropagatorInJBPhase() {
        {
            // default CopyPropagator enabled
            setup();
            Scene.v().loadNecessaryClasses();
            PackManager.v().runBodyPacks();
            SootClass cls = Scene.v().getSootClass(""Example"");
            SootMethod foo = cls.getMethodByName(""foo"");
            List<String> actual = bodyAsStrings(foo.getActiveBody());
            List<String> expected = expectedBody(""r0 := @this: Example"",
                    ""virtualinvoke r0.<Example: void bar(int,int)>(0, 2)"",
                    ""return"");
            assertEquals(expected, actual);
        }
        {
            // disable CopyPropagator
            setup();
            Options.v().setPhaseOption(""jb.sils"", ""enabled:false"");// this transformer calls a lot of other transformers
            Options.v().setPhaseOption(""jb.cp"", ""enabled:false"");
            Scene.v().loadNecessaryClasses();
            PackManager.v().runBodyPacks();
            SootClass cls = Scene.v().getSootClass(""Example"");
            SootMethod foo = cls.getMethodByName(""foo"");
            List<String> actual = bodyAsStrings(foo.getActiveBody());
            List<String> expected = expectedBody(""r0 := @this: Example"",
                    ""b0 = 0"",
                    ""b1 = 2"",
                    ""virtualinvoke r0.<Example: void bar(int,int)>(b0, b1)"",
                    ""return"");
            assertEquals(expected, actual);
        }
    }
"
"    @Test
    public void testDisableUnusedLocalEliminatorInJBPhase() {
        {
            // default UnusedLocalEliminator enabled
            setup();
            Scene.v().loadNecessaryClasses();
            PackManager.v().runBodyPacks();
            SootClass cls = Scene.v().getSootClass(""Example"");
            SootMethod bar = cls.getMethodByName(""bar"");
            List<String> actual = bodyAsStrings(bar.getActiveBody());
            List<String> expected = expectedBody(""r1 := @this: Example"",
                    ""i0 := @parameter0: int"",
                    ""i1 := @parameter1: int"",
                    ""i2 = i0 * i1"",
                    ""$r0 = <java.lang.System: java.io.PrintStream out>"",
                    ""virtualinvoke $r0.<java.io.PrintStream: void println(int)>(i2)"",
                    ""return"");
        }
        {
            //disable UnusedLocalEliminator
            setup();
            Options.v().setPhaseOption(""jb.sils"", ""enabled:false"");// this transformer calls a lot of other transformers
            Options.v().setPhaseOption(""jb.cp-ule"", ""enabled:false"");
            Scene.v().loadNecessaryClasses();
            PackManager.v().runBodyPacks();
            SootClass cls = Scene.v().getSootClass(""Example"");
            SootMethod bar = cls.getMethodByName(""bar"");
            List<String> actual = bodyAsStrings(bar.getActiveBody());
            List<String> expected = expectedBody(""r1 := @this: Example"",
                    ""i0 := @parameter0: int"",
                    ""i1 := @parameter1: int"",
                    ""i2 = i0 * i1"",
                    ""z0 = 0"",
                    ""$r0 = <java.lang.System: java.io.PrintStream out>"",
                    ""virtualinvoke $r0.<java.io.PrintStream: void println(int)>(i2)"",
                    ""return"");
        }
    }
"
"  @Test
  public void testLoadingJava9to11Class() {
    G.reset();
    Options.v().set_soot_modulepath(""VIRTUAL_FS_FOR_JDK"");
    Scene.v().loadBasicClasses();

    SootClass klass1
        = SootModuleResolver.v().resolveClass(""java.lang.invoke.VarHandle"", SootClass.BODIES, Optional.of(""java.base""));

    assertTrue(klass1.getName().equals(""java.lang.invoke.VarHandle""));
    assertTrue(klass1.moduleName.equals(""java.base""));

    SootClass klass2 = SootModuleResolver.v().resolveClass(""java.lang.invoke.ConstantBootstraps"", SootClass.BODIES,
        Optional.of(""java.base""));

    assertTrue(klass2.getName().equals(""java.lang.invoke.ConstantBootstraps""));
    assertTrue(klass2.moduleName.equals(""java.base""));

    Scene.v().loadNecessaryClasses();
  }
"
"  @Test
  public void testLoadingJava9ClassFromCI() {
    G.reset();
    Main.main(new String[] { ""-soot-modulepath"", ""VIRTUAL_FS_FOR_JDK"", ""-pp"", ""-src-prec"", ""only-class"",
        ""java.lang.invoke.VarHandle"" });

    SootClass klass = Scene.v().getSootClass(""java.lang.invoke.VarHandle"");
    assertTrue(klass.getName().equals(""java.lang.invoke.VarHandle""));
    assertTrue(klass.moduleName.equals(""java.base""));

  }
"
"  @Test
  public void testLoadingJava11ClassFromCI() {
    G.reset();
    Main.main(new String[] { ""-soot-modulepath"", ""VIRTUAL_FS_FOR_JDK"", ""-pp"", ""-src-prec"", ""only-class"",
        ""java.lang.invoke.ConstantBootstraps"" });

    SootClass klass = Scene.v().getSootClass(""java.lang.invoke.ConstantBootstraps"");
    assertTrue(klass.getName().equals(""java.lang.invoke.ConstantBootstraps""));
    assertTrue(klass.moduleName.equals(""java.base""));

  }
"
"	@Test
	public void testMerge() {
		G.reset();
		
		Scene.v().loadNecessaryClasses();
		
		SootClass sc1 = new SootClass(""Class1"");
		SootClass sc2 = new SootClass(""Class2"");
		SootClass sc3 = new SootClass(""Class3"");
		SootClass sc4 = new SootClass(""Class4"");
		SootClass sc5 = new SootClass(""Class5"");
		
		Scene.v().addClass(sc1);
		Scene.v().addClass(sc2);
		Scene.v().addClass(sc3);
		Scene.v().addClass(sc4);
		Scene.v().addClass(sc5);
		
		sc1.setSuperclass(Scene.v().getObjectType().getSootClass());
		sc2.setSuperclass(sc1);
		sc3.setSuperclass(sc2);
		sc4.setSuperclass(sc2);
		sc5.setSuperclass(sc4);
		
		Type tpMerged = sc5.getType().merge(sc3.getType(), Scene.v());
		Assert.assertEquals(""Class2"", ((RefType) tpMerged).getClassName()); 
	}
"
"    @Test
    public void testMethodWithNoInstruction() {
        setup();
        Options.v().set_output_format(Options.output_format_jimple);
        runTest();
        setup();
        Options.v().set_output_format(Options.output_format_grimp);
        runTest();
        setup();
        Options.v().set_output_format(Options.output_format_baf);
        runTest();
        setup();
        Options.v().set_output_format(Options.output_format_dava);
        runTest();
        setup();
        Options.v().set_output_format(Options.output_format_shimp);
        runTest();
        setup();
        Options.v().set_output_format(Options.output_format_class);
        runTest();
    }
"
"  @Test
  public void getName() {
    assertThat(ClassRenamer.v().getName(), equalTo(ClassRenamer.name));
  }
"
"  @Test
  public void getDependencies() {
    assertThat(ClassRenamer.v().getDependencies(), equalTo(new String[] { ClassRenamer.name }));
  }
"
"  @Test
  public void getPackageName() {
    assertNull(ClassRenamer.getPackageName(""""));
    assertNull(ClassRenamer.getPackageName(null));
    assertNull(ClassRenamer.getPackageName("".""));
    assertNull(ClassRenamer.getPackageName(""ClassName""));
    assertEquals(""com.sable"", ClassRenamer.getPackageName(""com.sable.Soot""));
  }
"
"  @Test
  public void getClassName() {
    assertNull(ClassRenamer.getClassName(""""));
    assertNull(ClassRenamer.getClassName(null));
    assertNull(ClassRenamer.getClassName("".""));
    assertEquals(""ClassName"", ClassRenamer.getClassName(""ClassName""));
    assertEquals(""Soot"", ClassRenamer.getClassName(""com.sable.Soot""));
    assertNull(ClassRenamer.getClassName(""com.sable.""));
  }
"
"  @Test
  public void getOrAddNewName_cachingName() {
    ClassRenamer.v().setRemovePackages(false);
    ClassRenamer.v().setRenamePackages(false);

    final String newName = ClassRenamer.v().getOrAddNewName(null, ""ClassName"");
    assertThat(newName, not(containsString(""."")));

    Map<String, String> mapping = ClassRenamer.v().getClassNameMapping((pOldName, pNewName) -> pOldName.equals(""ClassName""));
    assertThat(mapping, hasEntry(""ClassName"", newName));
    assertThat(mapping.size(), equalTo(1));

    assertThat(ClassRenamer.v().getOrAddNewName(null, ""ClassName""), equalTo(newName));

    mapping = ClassRenamer.v().getClassNameMapping((pOldName, pNewName) -> pOldName.equals(""ClassName""));
    assertThat(mapping, hasEntry(""ClassName"", newName));
    assertThat(mapping.size(), equalTo(1));
  }
"
"  @Test
  public void getOrAddNewName_cachingPackage() {
    ClassRenamer.v().setRemovePackages(false);
    ClassRenamer.v().setRenamePackages(false);

    final String newName = ClassRenamer.v().getOrAddNewName(""pac.age"", ""ClassName"");
    assertThat(newName, allOf(startsWith(""pac.age.""), not(endsWith(""ClassName""))));
    assertThat(newName.split(""\\."").length, equalTo(3));

    assertThat(ClassRenamer.v().getOrAddNewName(""pac.age"", ""ClassName""), equalTo(newName));
  }
"
"  @Test
  public void getOrAddNewName_nullClassName() {
    ClassRenamer.v().setRemovePackages(false);
    ClassRenamer.v().setRenamePackages(false);

    final String newName = ClassRenamer.v().getOrAddNewName(""pac.age"", null);
    assertThat(newName, startsWith(""pac.age.""));
    assertThat(newName.split(""\\."").length, equalTo(3));

    assertThat(ClassRenamer.v().getOrAddNewName(""pac.age"", null), not(equalTo(newName)));
  }
"
"  @Test
  public void getOrAddNewName_renamePackage() {
    ClassRenamer.v().setRemovePackages(false);
    ClassRenamer.v().setRenamePackages(true);

    final String newName = ClassRenamer.v().getOrAddNewName(""pac.age.getOrAddNewName_renamePackage"", ""ClassName"");
    assertThat(newName, allOf(not(startsWith(""pac.age.getOrAddNewName_renamePackage."")), not(endsWith(""ClassName""))));
    assertThat(newName.split(""\\."").length, equalTo(4));

    assertThat(ClassRenamer.v().getOrAddNewName(""pac.age.getOrAddNewName_renamePackage"", ""ClassName""), equalTo(newName));
  }
"
"  @Test
  public void getOrAddNewName_renamePackage_nullPackage() {
    ClassRenamer.v().setRemovePackages(false);
    ClassRenamer.v().setRenamePackages(true);

    final String newName = ClassRenamer.v().getOrAddNewName(null, ""ClassName"");
    assertThat(newName, allOf(not(endsWith(""ClassName"")), not(containsString("".""))));

    final String newName0 = ClassRenamer.v().getOrAddNewName(null, ""ClassName"");
    assertThat(newName0, equalTo(newName)); // package names and class names are equal

    final String newName1 = ClassRenamer.v().getOrAddNewName(null, ""ClassName1"");
    assertThat(newName1, not(equalTo(newName)));
    assertThat(newName1.split(""\\."").length, equalTo(2));
    assertThat(newName.split(""\\."")[0], equalTo(newName.split(""\\."")[0])); // package names are equal
  }
"
"  @Test
  public void getOrAddNewName_removePackage() {
    ClassRenamer.v().setRemovePackages(true);

    String newName = ClassRenamer.v().getOrAddNewName(""a.b.c"", ""ClassName"");
    assertThat(newName, allOf(not(endsWith(""ClassName"")), not(containsString("".""))));

    String packageName = ""a.b.c"";
    for (int i = 0; i < 100; i++) {
      packageName = packageName + "".p"" + i;
      newName = ClassRenamer.v().getOrAddNewName(packageName, ""ClassName"");
      assertThat(newName, allOf(not(endsWith(""ClassName"")), not(containsString("".""))));
    }
  }
"
"  @Test
  public void testConstant() throws Throwable {

    // First generate a classfile with a MethodHnadle
    ClassWriter cv = new ClassWriter(ClassWriter.COMPUTE_FRAMES | ClassWriter.COMPUTE_MAXS);
    cv.visit(Opcodes.V1_7, Opcodes.ACC_PUBLIC, ""HelloMethodHandles"", null, Type.getInternalName(Object.class), null);
    MethodVisitor mv = cv.visitMethod(Opcodes.ACC_STATIC | Opcodes.ACC_PUBLIC, ""getSquareRoot"",
        Type.getMethodDescriptor(Type.getType(java.lang.invoke.MethodHandle.class)), null, null);

    mv.visitCode();

    mv.visitLdcInsn(new Handle(Opcodes.H_INVOKESTATIC, Type.getInternalName(Math.class), ""sqrt"",
        Type.getMethodDescriptor(Type.DOUBLE_TYPE, Type.DOUBLE_TYPE), false));

    mv.visitInsn(Opcodes.ARETURN);
    mv.visitEnd();

    cv.visitEnd();

    File tempDir = Files.createTempDir();
    File classFile = new File(tempDir, ""HelloMethodHandles.class"");
    Files.write(cv.toByteArray(), classFile);

    G.reset();

    String[] commandLine = { ""-pp"", ""-cp"", tempDir.getAbsolutePath(), ""-O"", ""HelloMethodHandles"", };

    System.out.println(""Command Line: "" + Arrays.toString(commandLine));

    Main.main(commandLine);

    Class<?> clazz = validateClassFile(""HelloMethodHandles"");
    java.lang.invoke.MethodHandle methodHandle
        = (java.lang.invoke.MethodHandle) clazz.getMethod(""getSquareRoot"").invoke(null);

    assertThat((Double) methodHandle.invoke(16.0), equalTo(4.0));
  }
"
"  @Test
  public void testInvoke() throws IOException, ClassNotFoundException {

    // First generate a classfile with a MethodHnadle
    ClassWriter cv = new ClassWriter(ClassWriter.COMPUTE_FRAMES | ClassWriter.COMPUTE_MAXS);
    cv.visit(Opcodes.V1_7, Opcodes.ACC_PUBLIC, ""UniformDistribution"", null, Type.getInternalName(Object.class), null);

    MethodVisitor mv
        = cv.visitMethod(Opcodes.ACC_STATIC | Opcodes.ACC_PUBLIC, ""sample"", Type.getMethodDescriptor(Type.DOUBLE_TYPE,
            Type.getType(java.lang.invoke.MethodHandle.class) /* rng method */, Type.DOUBLE_TYPE /* max */), null, null);

    mv.visitCode();

    mv.visitVarInsn(Opcodes.ALOAD, 0); // load MethodHandle
    mv.visitInsn(Opcodes.ACONST_NULL); // null string... (just to test signatures with class names)


    // Call MethodHandle.invoke() with polymorphic signature: ()D
    mv.visitMethodInsn(Opcodes.INVOKEVIRTUAL, Type.getInternalName(java.lang.invoke.MethodHandle.class), ""invoke"",
        Type.getMethodDescriptor(Type.DOUBLE_TYPE, Type.getType(String.class)), false);

    mv.visitVarInsn(Opcodes.DLOAD, 1);
    mv.visitInsn(Opcodes.DMUL);
    mv.visitInsn(Opcodes.DRETURN);
    mv.visitEnd();
    cv.visitEnd();

    File tempDir = Files.createTempDir();
    File classFile = new File(tempDir, ""UniformDistribution.class"");
    Files.write(cv.toByteArray(), classFile);

    G.reset();

    String[] commandLine = { ""-pp"", ""-cp"", tempDir.getAbsolutePath(), ""-O"", ""UniformDistribution"" };

    System.out.println(""Command Line: "" + Arrays.toString(commandLine));

    Main.main(commandLine);
    validateClassFile(""UniformDistribution"");

  }
"
"    @Test
    public void constantBase() {
        genericLocalVsStringConstantTest(true);
    }
"
"    @Test
    public void localBase() {
        genericLocalVsStringConstantTest(false);
    }
"
"    @Test
    public void staticBase() {
        //TODO
    }
"
"  @Test
  public void keepArrayLength() {
    // create test method and body
    SootClass cl = new SootClass(""TestClass"", Modifier.PUBLIC);
    SootMethod method = new SootMethod(""testMethod"", Collections.singletonList(RefType.v(""java.lang.Object"")),
        ArrayType.v(IntType.v(), 1), Modifier.PUBLIC);
    cl.addMethod(method);
    JimpleBody body = Jimple.v().newBody(method);
    method.setActiveBody(body);

    // create locals
    Chain<Local> locals = body.getLocals();
    Local a = Jimple.v().newLocal(""a"", ArrayType.v(IntType.v(), 1));
    locals.add(a);
    Local b = Jimple.v().newLocal(""b"", IntType.v());
    locals.add(b);

    // create code
    UnitPatchingChain units = body.getUnits();
    Unit identity0 = Jimple.v().newIdentityStmt(a, Jimple.v().newParameterRef(RefType.v(""java.lang.Object""), 0));
    units.add(identity0);
    Unit cast0 = Jimple.v().newAssignStmt(b, Jimple.v().newLengthExpr(a));
    units.add(cast0);
    Unit ret = Jimple.v().newReturnStmt(b);
    units.add(ret);

    // execute transform
    DeadAssignmentEliminator.v().internalTransform(body, ""testPhase"", Collections.emptyMap());

    // check resulting code (length statement should be preserved)
    Iterator<Unit> it = units.iterator();
    assertEquals(identity0, it.next());
    assertEquals(cast0, it.next());
    assertEquals(ret, it.next());
    assertEquals(3, units.size());
  }
"
"  @Test
  public void keepEssentialCast() {
    // create test method and body
    SootClass cl = new SootClass(""TestClass"", Modifier.PUBLIC);
    SootMethod method = new SootMethod(""testMethod"", Collections.singletonList(RefType.v(""java.lang.Object"")),
        ArrayType.v(IntType.v(), 1), Modifier.PUBLIC);
    cl.addMethod(method);
    JimpleBody body = Jimple.v().newBody(method);
    method.setActiveBody(body);

    // create locals
    Chain<Local> locals = body.getLocals();
    Local a = Jimple.v().newLocal(""a"", IntType.v());
    locals.add(a);
    Local b = Jimple.v().newLocal(""b"", IntType.v());
    locals.add(b);
    Local c = Jimple.v().newLocal(""c"", IntType.v());
    locals.add(c);
    Local d = Jimple.v().newLocal(""d"", IntType.v());
    locals.add(d);

    // create code
    UnitPatchingChain units = body.getUnits();
    Unit identity0 = Jimple.v().newIdentityStmt(a, Jimple.v().newParameterRef(RefType.v(""java.lang.Object""), 0));
    units.add(identity0);
    Unit cast0 = Jimple.v().newAssignStmt(b, Jimple.v().newCastExpr(a, ArrayType.v(IntType.v(), 1)));
    units.add(cast0);
    Unit cast1 = Jimple.v().newAssignStmt(c, Jimple.v().newCastExpr(a, RefType.v(""java.lang.Number"")));
    units.add(cast1);
    Unit cast2 = Jimple.v().newAssignStmt(d, Jimple.v().newCastExpr(NullConstant.v(), RefType.v(""java.lang.Number"")));
    units.add(cast2);
    Unit ret = Jimple.v().newReturnStmt(b);
    units.add(ret);

    // execute transform
    DeadAssignmentEliminator.v().internalTransform(body, ""testPhase"", Collections.emptyMap());

    // check resulting code (cast should be removed)
    Iterator<Unit> it = units.iterator();
    assertEquals(identity0, it.next());
    assertEquals(cast0, it.next());
    assertEquals(cast1, it.next());
    assertEquals(ret, it.next());
    assertEquals(4, units.size());
  }
"
"  @Test
  public void removePrimitiveCast() {
    // create test method and body
    SootClass cl = new SootClass(""TestClass"", Modifier.PUBLIC);
    SootMethod method = new SootMethod(""testMethod"", Arrays.asList(IntType.v(), IntType.v()), IntType.v(), Modifier.PUBLIC);
    cl.addMethod(method);
    JimpleBody body = Jimple.v().newBody(method);
    method.setActiveBody(body);

    // create locals
    Chain<Local> locals = body.getLocals();
    Local a = Jimple.v().newLocal(""a"", IntType.v());
    locals.add(a);
    Local b = Jimple.v().newLocal(""b"", IntType.v());
    locals.add(b);
    Local c = Jimple.v().newLocal(""c"", IntType.v());
    locals.add(c);
    Local d = Jimple.v().newLocal(""d"", DoubleType.v());
    locals.add(d);

    // create code
    UnitPatchingChain units = body.getUnits();
    Unit identity0 = Jimple.v().newIdentityStmt(a, Jimple.v().newParameterRef(IntType.v(), 0));
    units.add(identity0);
    Unit identity1 = Jimple.v().newIdentityStmt(b, Jimple.v().newParameterRef(IntType.v(), 1));
    units.add(identity1);
    Unit addition = Jimple.v().newAssignStmt(c, Jimple.v().newAddExpr(a, b));
    units.add(addition);
    Unit cast = Jimple.v().newAssignStmt(d, Jimple.v().newCastExpr(a, DoubleType.v()));
    units.add(cast);
    Unit ret = Jimple.v().newReturnStmt(c);
    units.add(ret);

    // execute transform
    DeadAssignmentEliminator.v().internalTransform(body, ""testPhase"", Collections.emptyMap());

    // check resulting code (cast should be removed)
    Iterator<Unit> it = units.iterator();
    assertEquals(identity0, it.next());
    assertEquals(identity1, it.next());
    assertEquals(addition, it.next());
    assertEquals(ret, it.next());
    assertEquals(4, units.size());
  }
"
"  @Test
  public void testMostCommonTypingPairs_1() {

    logger.debug(""Starting Object Random Minimize"");

    List<Typing> typingList = new ArrayList<>();
    Type Type1 = serializableType;
    Type Type2 = comparableType;
    Local x1 = new JimpleLocal(""$x1"", null);
    Typing resultTyping;

    Typing typing1 = new Typing(Arrays.asList(x1));
    typing1.set(x1, Type1);
    typingList.add(typing1);
    resultTyping = typing1;

    Typing typing2 = new Typing(Arrays.asList(x1));
    typing2.set(x1, Type2);
    typingList.add(typing2);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(2, typingList.size());
    assertEquals(resultTyping, typingList.get(0));
  }
"
"  @Test
  public void testMostCommonTypingPairs_2() {

    logger.debug(""Starting Object Random Minimize"");

    List<Typing> typingList = new ArrayList<>();

    Type Type1 = serializableType;
    Type Type2 = comparableType;
    Type Type3 = numberType;
    Local x1 = new JimpleLocal(""$x1"", null);

    Typing typing1 = new Typing(Arrays.asList(x1));
    typing1.set(x1, Type1);
    typingList.add(typing1);

    Typing typing2 = new Typing(Arrays.asList(x1));
    typing2.set(x1, Type2);
    typingList.add(typing2);

    Typing typing3 = new Typing(Arrays.asList(x1));
    typing3.set(x1, Type3);
    typingList.add(typing3);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(2, typingList.size());
    assertThat(typingList, containsInAnyOrder(typing2, typing3));
  }
"
"  @Test
  public void testMostCommonTypingPairs_3() {

    List<Typing> typingList = new ArrayList<>();
    Type Type1 = randomAccessType;
    Type Type2 = listType;
    Type Type3 = abstractListType;
    Type Type4 = objectType;
    Local x1 = new JimpleLocal(""$x1"", null);

    Typing typing1 = new Typing(Arrays.asList(x1));
    typing1.set(x1, Type1);
    typingList.add(typing1);

    Typing typing2 = new Typing(Arrays.asList(x1));
    typing2.set(x1, Type2);
    typingList.add(typing2);

    Typing typing3 = new Typing(Arrays.asList(x1));
    typing3.set(x1, Type3);
    typingList.add(typing3);

    Typing typing4 = new Typing(Arrays.asList(x1));
    typing4.set(x1, Type4);
    typingList.add(typing4);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(2, typingList.size());
    assertThat(typingList, containsInAnyOrder(typing1, typing3));
  }
"
"  @Test
  public void testMostCommonTypingPairs_4() {

    List<Typing> typingList = new ArrayList<>();

    Type Type1 = cloneableType;
    Type Type2 = serializableType;
    Type Type3 = abstractMapType;

    Local x1 = new JimpleLocal(""$x1"", null);

    Typing typing1 = new Typing(Arrays.asList(x1));
    typing1.set(x1, Type1);
    typingList.add(typing1);

    Typing typing2 = new Typing(Arrays.asList(x1));
    typing2.set(x1, Type2);
    typingList.add(typing2);

    Typing typing3 = new Typing(Arrays.asList(x1));
    typing3.set(x1, Type3);
    typingList.add(typing3);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(3, typingList.size());

  }
"
"  @Test
  public void testHugeCommonTypingPair() {

    List<Typing> typingList = new ArrayList<>();

    Type Type1 = serializableType;
    Type Type2 = comparableType;
    Local x1 = new JimpleLocal(""$x1"", null);
    Local x2 = new JimpleLocal(""$x2"", null);
    Local x3 = new JimpleLocal(""$x3"", null);

    Typing typing1 = new Typing(Arrays.asList(x1, x2, x3));
    typing1.set(x1, Type1);
    typing1.set(x2, Type1);
    typing1.set(x3, Type1);
    typingList.add(typing1);

    Typing typing2 = new Typing(Arrays.asList(x1, x2, x3));
    typing2.set(x1, Type2);
    typing2.set(x2, Type1);
    typing2.set(x3, Type1);
    typingList.add(typing2);

    Typing typing3 = new Typing(Arrays.asList(x1, x2, x3));
    typing3.set(x1, Type1);
    typing3.set(x2, Type2);
    typing3.set(x3, Type1);
    typingList.add(typing3);

    Typing typing4 = new Typing(Arrays.asList(x1, x2, x3));
    typing4.set(x1, Type1);
    typing4.set(x2, Type1);
    typing4.set(x3, Type2);
    typingList.add(typing4);

    Typing typing5 = new Typing(Arrays.asList(x1, x2, x3));
    typing5.set(x1, Type2);
    typing5.set(x2, Type2);
    typing5.set(x3, Type1);
    typingList.add(typing5);

    Typing typing6 = new Typing(Arrays.asList(x1, x2, x3));
    typing6.set(x1, Type2);
    typing6.set(x2, Type1);
    typing6.set(x3, Type2);
    typingList.add(typing6);

    Typing typing7 = new Typing(Arrays.asList(x1, x2, x3));
    typing7.set(x1, Type1);
    typing7.set(x2, Type2);
    typing7.set(x3, Type2);
    typingList.add(typing7);

    Typing typing8 = new Typing(Arrays.asList(x1, x2, x3));
    typing8.set(x1, Type2);
    typing8.set(x2, Type2);
    typing8.set(x3, Type2);
    typingList.add(typing8);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(8, typingList.size());
    assertThat(typingList, containsInAnyOrder(typing1, typing2, typing3, typing4, typing5, typing6, typing7, typing8));
  }
"
"  @Test
  public void testAbstractInterfaceTyping() {

    List<Typing> typingList = new ArrayList<>();

    Local x1 = new JimpleLocal(""$x1"", null);

    Typing typing1 = new Typing(Arrays.asList(x1));
    typing1.set(x1, interfaceType);
    typingList.add(typing1);

    Typing typing2 = new Typing(Arrays.asList(x1));
    typing2.set(x1, abstractClass_Interface2Type);
    typingList.add(typing2);

    Typing typing3 = new Typing(Arrays.asList(x1));
    typing3.set(x1, class_AbstractInterfaceClassType);
    typingList.add(typing3);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(1, typingList.size());
    assertThat(typingList, containsInAnyOrder(typing3));
  }
"
"  @Test
  public void testAbstractAbstractTyping() {

    logger.debug(""Starting Object Random Minimize"");

    List<Typing> typingList = new ArrayList<>();
    Local x1 = new JimpleLocal(""$x1"", null);

    Typing typing1 = new Typing(Arrays.asList(x1));
    typing1.set(x1, interfaceType);
    typingList.add(typing1);

    Typing typing2 = new Typing(Arrays.asList(x1));
    typing2.set(x1, abstractClass_Interface1Type);
    typingList.add(typing2);

    Typing typing3 = new Typing(Arrays.asList(x1));
    typing3.set(x1, abstractClass_Interface2Type);
    typingList.add(typing3);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(1, typingList.size());
    assertThat(typingList, containsInAnyOrder(typing3));
  }
"
"  @Test
  public void testJavaInterfaceTyping() {

    List<Typing> typingList = new ArrayList<>();

    Local x1 = new JimpleLocal(""$x1"", null);

    Typing typing1 = new Typing(Arrays.asList(x1));
    typing1.set(x1, interfaceType);
    typingList.add(typing1);

    Typing typing2 = new Typing(Arrays.asList(x1));
    typing2.set(x1, integerType);
    typingList.add(typing2);

    Typing typing3 = new Typing(Arrays.asList(x1));
    typing3.set(x1, numberType);
    typingList.add(typing3);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(2, typingList.size());
    assertThat(typingList, containsInAnyOrder(typing2, typing1));
  }
"
"  @Test
  public void testInterfaceInterfaceTyping() {

    List<Typing> typingList = new ArrayList<>();

    Local x1 = new JimpleLocal(""$x1"", null);

    Typing typing1 = new Typing(Arrays.asList(x1));
    typing1.set(x1, interfaceType);
    typingList.add(typing1);

    Typing typing2 = new Typing(Arrays.asList(x1));
    typing2.set(x1, interfaceInterfaceType);
    typingList.add(typing2);

    Typing typing3 = new Typing(Arrays.asList(x1));
    typing3.set(x1, numberType);
    typingList.add(typing3);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(2, typingList.size());
    assertThat(typingList, containsInAnyOrder(typing2, typing3));
  }
"
"  @Test
  public void testAllRelatedClassesTyping() {

    List<Typing> typingList = new ArrayList<>();
    Local x1 = new JimpleLocal(""$x1"", null);

    Typing typing1 = new Typing(Arrays.asList(x1));
    typing1.set(x1, objectType);
    typingList.add(typing1);

    Typing typing2 = new Typing(Arrays.asList(x1));
    typing2.set(x1, stringType);
    typingList.add(typing2);

    Typing typing3 = new Typing(Arrays.asList(x1));
    typing3.set(x1, comparableType);
    typingList.add(typing3);

    Typing typing4 = new Typing(Arrays.asList(x1));
    typing4.set(x1, abstractClass_Interface2Type);
    typingList.add(typing4);

    Typing typing5 = new Typing(Arrays.asList(x1));
    typing5.set(x1, class_AbstractInterfaceClassType);
    typingList.add(typing5);

    Typing typing6 = new Typing(Arrays.asList(x1));
    typing6.set(x1, abstractClass_Interface1Type);
    typingList.add(typing6);

    Typing typing7 = new Typing(Arrays.asList(x1));
    typing7.set(x1, class_InterfaceType);
    typingList.add(typing7);

    Typing typing8 = new Typing(Arrays.asList(x1));
    typing8.set(x1, abstractType);
    typingList.add(typing8);

    Typing typing9 = new Typing(Arrays.asList(x1));
    typing9.set(x1, class_AbstractType);
    typingList.add(typing9);

    Typing typing10 = new Typing(Arrays.asList(x1));
    typing10.set(x1, fatherClassType);
    typingList.add(typing10);

    Typing typing11 = new Typing(Arrays.asList(x1));
    typing11.set(x1, childClassType);
    typingList.add(typing11);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(5, typingList.size());
    assertThat(typingList, containsInAnyOrder(typing2, typing5, typing7, typing9, typing11));
  }
"
"  @Test
  public void testAllNonRelatedClassesTyping() {

    List<Typing> typingList = new ArrayList<>();
    Local x1 = new JimpleLocal(""$x1"", null);

    Typing typing1 = new Typing(Arrays.asList(x1));
    typing1.set(x1, objectType);
    typingList.add(typing1);

    Typing typing2 = new Typing(Arrays.asList(x1));
    typing2.set(x1, stringType);
    typingList.add(typing2);

    Typing typing3 = new Typing(Arrays.asList(x1));
    typing3.set(x1, cloneableType);
    typingList.add(typing3);

    Typing typing4 = new Typing(Arrays.asList(x1));
    typing4.set(x1, integerType);
    typingList.add(typing4);

    Typing typing5 = new Typing(Arrays.asList(x1));
    typing5.set(x1, processType);
    typingList.add(typing5);

    Typing typing6 = new Typing(Arrays.asList(x1));
    typing6.set(x1, interfaceType);
    typingList.add(typing6);

    Typing typing7 = new Typing(Arrays.asList(x1));
    typing7.set(x1, abstractType);
    typingList.add(typing7);

    Typing typing8 = new Typing(Arrays.asList(x1));
    typing8.set(x1, fatherClassType);
    typingList.add(typing8);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(7, typingList.size());
    assertThat(typingList, containsInAnyOrder(typing2, typing3, typing4, typing5, typing6, typing7, typing8));
  }
"
"	@Test
	public void testClinitOf() {
		Path cp = Paths.get(""src"", ""test"", ""resources"", ""Clinit"", ""bin"");
		G.reset();
		Options.v().set_prepend_classpath(true);
		Options.v().set_process_dir(Collections.singletonList(cp.toFile().getAbsolutePath()));
		Options.v().set_src_prec(Options.src_prec_class);
		Options.v().set_allow_phantom_refs(true);
		Options.v().set_ignore_resolving_levels(true);
		Options.v().setPhaseOption(""cg.spark"", ""on"");
		Options.v().setPhaseOption(""cg.spark"", ""string-constants:true"");
		Options.v().set_whole_program(true);
		Scene.v().loadNecessaryClasses();
		SootMethod mainMethod = Scene.v().getMainMethod();
		Scene.v().setEntryPoints(Collections.singletonList(mainMethod));
		PackManager.v().getPack(""cg"").apply();
		CallGraph cg = Scene.v().getCallGraph();
		boolean found = false;
		for (Edge edge : cg) {
			if (edge.getSrc().method().getSignature().equals(""<soot.Main: void main(java.lang.String[])>"")) {
				if (edge.getTgt().method().getSignature().equals(""<soot.A: void <clinit>()>"")) { // A1 is used in main
					found = true;
					break;
				}
			}
		}
		assertTrue(found);
		SootClass a1 = Scene.v().getSootClassUnsafe(""soot.A1"");
		SootClass a = Scene.v().getSootClassUnsafe(""soot.A"");
		assertTrue(a1 != null);
		List<String> clinits1 = new ArrayList<>();
		EntryPoints.v().clinitsOf(a1).forEach(e -> {
			clinits1.add(e.toString());
		});
		List<String> clinits = new ArrayList<>();
		EntryPoints.v().clinitsOf(a).forEach(e -> {
			clinits.add(e.toString());
		});
		assertEquals(clinits1, clinits);
	}
"
"    @Test
    public void ownPackage() {
        G.reset();
        ModuleUtil moduleUtil = ModuleUtil.v();
        ModuleScene moduleScene = ModuleScene.v();

        SootModuleInfo moduleA = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleA"");
        moduleA.addExportedPackage(""de.upb"");
        moduleScene.addClassSilent(moduleA);


        String foundModule = moduleUtil.declaringModule(""de.upb"", ""moduleA"");
        Assert.assertEquals(""moduleA"", foundModule);
    }
"
"    @Test
    public void simpleExport() {
        G.reset();
        ModuleScene moduleScene = ModuleScene.v();

        SootModuleInfo moduleA = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleA"");
        moduleA.addExportedPackage(""de.upb"");
        moduleScene.addClassSilent(moduleA);

        SootModuleInfo moduleB = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleB"");
        moduleB.getRequiredModules().put(moduleA, Modifier.REQUIRES_STATIC);
        moduleScene.addClassSilent(moduleB);

        ModuleUtil moduleUtil = ModuleUtil.v();
        String foundModule = moduleUtil.declaringModule(""de.upb.A"", ""moduleB"");
        Assert.assertEquals(""moduleA"", foundModule);

    }
"
"    @Test
    public void simpleRequiresTransitiveExport() {
        G.reset();
        ModuleScene moduleScene = ModuleScene.v();

        SootModuleInfo moduleA = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleA"");
        moduleA.addExportedPackage(""de.upb"");
        moduleScene.addClassSilent(moduleA);

        SootModuleInfo moduleB = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleB"");
        moduleB.getRequiredModules().put(moduleA, Modifier.REQUIRES_TRANSITIVE);
        moduleScene.addClassSilent(moduleB);


        SootModuleInfo moduleC = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleC"");
        moduleC.getRequiredModules().put(moduleB, Modifier.REQUIRES_STATIC);
        moduleScene.addClassSilent(moduleC);

        ModuleUtil moduleUtil = ModuleUtil.v();
        String foundModule = moduleUtil.declaringModule(""de.upb.A"", ""moduleC"");
        Assert.assertEquals(""moduleA"", foundModule);

    }
"
"    @Test
    public void TwoLevelRequiresTransitiveExport() {
        G.reset();
        ModuleScene moduleScene = ModuleScene.v();

        SootModuleInfo moduleA = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleA"");
        moduleA.addExportedPackage(""de.upb"");
        moduleScene.addClassSilent(moduleA);

        SootModuleInfo moduleB = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleB"");
        moduleB.getRequiredModules().put(moduleA, Modifier.REQUIRES_TRANSITIVE);
        moduleScene.addClassSilent(moduleB);


        SootModuleInfo moduleC = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleC"");
        moduleC.getRequiredModules().put(moduleB, Modifier.REQUIRES_TRANSITIVE);
        moduleScene.addClassSilent(moduleC);


        SootModuleInfo moduleD = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleD"");
        moduleD.getRequiredModules().put(moduleC, Modifier.REQUIRES_STATIC);
        moduleScene.addClassSilent(moduleD);

        ModuleUtil moduleUtil = ModuleUtil.v();
        String foundModule = moduleUtil.declaringModule(""de.upb.A"", ""moduleD"");
        // output should be D, because module C, does NOT REQUIERS TRANSITIVE module B
        Assert.assertEquals(""moduleA"", foundModule);

    }
"
"    @Test
    public void TwoLevelRequiresTransitiveExportFailing() {
        G.reset();
        ModuleScene moduleScene = ModuleScene.v();

        SootModuleInfo moduleA = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleA"");
        moduleA.addExportedPackage(""de.upb"");
        moduleScene.addClassSilent(moduleA);

        SootModuleInfo moduleB = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleB"");
        moduleB.getRequiredModules().put(moduleA, Modifier.REQUIRES_TRANSITIVE);
        moduleScene.addClassSilent(moduleB);


        SootModuleInfo moduleC = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleC"");
        moduleC.getRequiredModules().put(moduleB, Modifier.REQUIRES_STATIC);
        moduleScene.addClassSilent(moduleC);


        SootModuleInfo moduleD = new SootModuleInfo(SootModuleInfo.MODULE_INFO, ""moduleD"");
        moduleD.getRequiredModules().put(moduleC, Modifier.REQUIRES_STATIC);
        moduleScene.addClassSilent(moduleD);

        ModuleUtil moduleUtil = ModuleUtil.v();
        String foundModule = moduleUtil.declaringModule(""de.upb.A"", ""moduleD"");
        // output should be D, because module C, does NOT REQUIERS TRANSITIVE module B
        Assert.assertEquals(""moduleD"", foundModule);

    }
"
"  @Test
  public void runTestAndCompareOutput() throws IOException {
    runSoot();
    String comparisonOutput = createComparison();

    /*
     * Print output for comparison to file for debugging purposes.
     */
    File compareFile = new File(""sootOutput/"" + getTargetClass() + "".asm.compare"");
    PrintWriter ow = new PrintWriter(compareFile);
    ow.print(comparisonOutput);
    ow.flush();
    ow.close();

    File targetFile = new File(""sootOutput/"" + getTargetClass() + "".asm"");
    assertTrue(String.format(""Soot output file %s not found"", targetFile.getAbsolutePath()), targetFile.exists());
    Scanner sootOutput = new Scanner(targetFile);
    Scanner compareOutput = new Scanner(comparisonOutput);

    try {
      System.out.println(
          String.format(""Comparing files %s and %s..."", compareFile.getAbsolutePath(), targetFile.getAbsolutePath()));
      int line = 1;
      while (compareOutput.hasNextLine()) {
        // Soot-output must have as much lines as the compared output.
        assertTrue(String.format(""Too few lines in Soot-output for class %s! Current line: %d. Comparison output: %s"",
            getTargetClass(), line, comparisonOutput), sootOutput.hasNextLine());

        // Get both lines
        String compare = compareOutput.nextLine();

        String output = sootOutput.nextLine();

        // Compare lines
        assertTrue(String.format(""Expected line %s, but got %s in line %d for class %s"", compare.trim(), output.trim(), line,
            getTargetClass()), compare.equals(output));
        ++line;
      }

      assertFalse(String.format(""Too many lines in Soot-output for class %s!"", getTargetClass()), sootOutput.hasNextLine());
      System.out.println(""File comparison successful."");
    } finally {
      sootOutput.close();
      compareOutput.close();
    }
  }
"
"  @Test
  public void testMinimalVersionAnnotation() {
    thrown.expect(IllegalArgumentException.class);
    thrown.expectMessage(""Enforced Java version 1.3 too low to support required features (1.5 required)"");
    runSoot(""soot.asm.backend.targets.AnnotatedClass"", ""1.3"");

  }
"
"  @Test
  public void testSufficientUserVersion() {
    try {
      runSoot(""soot.asm.backend.targets.AnnotatedClass"", ""1.7"");
      return;
    } catch (RuntimeException e) {
      fail(""Version 1.7 should be sufficient for features of pkg.AnnotatedClass!"");
    }
  }
"
"  @Test
  public void loadClass() {
    G.reset();
    // Location of the rt.jar
    String rtJar = System.getProperty(""java.home"") + File.separator + ""lib"" + File.separator + ""rt.jar"";

    // Run Soot and print output to .asm-files.
    Main.main(new String[] { ""-cp"", getClassPathFolder() + File.pathSeparator + rtJar, ""-process-dir"", getTargetFolder(),
        ""-src-prec"", ""only-class"", ""-output-format"", ""class"", ""-asm-backend"", ""-allow-phantom-refs"", ""-java-version"",
        getRequiredJavaVersion(), getTargetClass() });

    File file = new File(""./sootOutput/ConstantPool.class"");
    URL[] urls = null;
    try {
      URL url = file.toURI().toURL();
      urls = new URL[] { url };
      URLClassLoader cl = new URLClassLoader(urls);

      cl.loadClass(getTargetClass());

      // cl.close();
      // Java 6 backwards compatibility hack
      try {
        for (Method m : URLClassLoader.class.getDeclaredMethods()) {
          if (m.getName().equals(""close"")) {
            m.invoke(cl);
            break;
          }
        }
      } catch (Exception e) {
      }
      return;

    } catch (MalformedURLException e) {
      logger.error(e.getMessage(), e);
    } catch (ClassNotFoundException e) {
      logger.error(e.getMessage(), e);
    }

    fail();

  }
"
"  @Test
  public void shouldExtractMetricsFromPrometheusMetricsAndSerialiseJson()
      throws JsonProcessingException {
    when(prometheusMock.streamObservations()).thenReturn(getMockObservations().stream());
    final MetricsDataFactory metricsDataFactory = new MetricsDataFactory(prometheusMock);

    final List<BaseMetricData> baseMetricData = metricsDataFactory.getMetricData(timeProvider);
    assertThat(baseMetricData.size()).isEqualTo(3);
    final String beaconNode = jsonProvider.objectToJSON(baseMetricData.get(0));
    final String validator = jsonProvider.objectToJSON(baseMetricData.get(1));
    final String system = jsonProvider.objectToJSON(baseMetricData.get(2));

    BeaconNodeMetricData beaconNodeDeserialized =
        jsonProvider.jsonToObject(beaconNode, BeaconNodeMetricData.class);
    ValidatorMetricData validatorDeserialized =
        jsonProvider.jsonToObject(validator, ValidatorMetricData.class);
    SystemMetricData systemDeserialized = jsonProvider.jsonToObject(system, SystemMetricData.class);

    assertThat(baseMetricData.get(0)).isInstanceOf(BeaconNodeMetricData.class);
    assertThat(baseMetricData.get(1)).isInstanceOf(ValidatorMetricData.class);
    assertThat(baseMetricData.get(2)).isInstanceOf(SystemMetricData.class);

    assertThat(baseMetricData.get(0)).isEqualTo(beaconNodeDeserialized);
    assertThat(baseMetricData.get(1)).isEqualTo(validatorDeserialized);
    assertThat(baseMetricData.get(2)).isEqualTo(systemDeserialized);
  }
"
"  @Test
  public void shouldDeserializeObjectFromString() throws JsonProcessingException {
    when(prometheusMock.streamObservations()).thenReturn(getMockObservations().stream());
    final MetricsDataFactory metricsDataFactory = new MetricsDataFactory(prometheusMock);
    final List<BaseMetricData> baseMetricData = metricsDataFactory.getMetricData(timeProvider);
    assertThat(baseMetricData.size()).isEqualTo(3);

    String listOfMetrics = jsonProvider.objectToJSON(baseMetricData);
    DeserializedMetricDataObject[] base =
        jsonProvider.jsonToObject(listOfMetrics, DeserializedMetricDataObject[].class);

    assertThat(base.length).isEqualTo(3);
  }
"
"  @Test
  public void shouldSerializeObjectFromPrometheusMetricsWithDefaultValues()
      throws JsonProcessingException {
    when(prometheusMock.streamObservations()).thenReturn(new ArrayList<Observation>().stream());
    final MetricsDataFactory metricsDataFactory = new MetricsDataFactory(prometheusMock);

    final List<BaseMetricData> baseMetricData = metricsDataFactory.getMetricData(timeProvider);
    assertThat(baseMetricData.size()).isEqualTo(3);
    final String beaconNode = jsonProvider.objectToJSON(baseMetricData.get(0));
    final String validator = jsonProvider.objectToJSON(baseMetricData.get(1));
    final String system = jsonProvider.objectToJSON(baseMetricData.get(2));

    BeaconNodeMetricData beaconNodeDeserialized =
        jsonProvider.jsonToObject(beaconNode, BeaconNodeMetricData.class);
    ValidatorMetricData validatorDeserialized =
        jsonProvider.jsonToObject(validator, ValidatorMetricData.class);
    SystemMetricData systemDeserialized = jsonProvider.jsonToObject(system, SystemMetricData.class);

    assertThat(baseMetricData.get(0)).isInstanceOf(BeaconNodeMetricData.class);
    assertThat(baseMetricData.get(1)).isInstanceOf(ValidatorMetricData.class);
    assertThat(baseMetricData.get(2)).isInstanceOf(SystemMetricData.class);

    assertThat(baseMetricData.get(0)).isEqualTo(beaconNodeDeserialized);
    assertThat(baseMetricData.get(1)).isEqualTo(validatorDeserialized);
    assertThat(baseMetricData.get(2)).isEqualTo(systemDeserialized);

    assertThat(beaconNodeDeserialized.network_peers_connected).isNull();
    assertThat(validatorDeserialized.validator_total).isNull();
    assertThat(systemDeserialized.cpu_node_system_seconds_total).isNull();
  }
"
"  @Test
  public void shouldSerializeObject() throws JsonProcessingException {
    final ValidatorMetricData process =
        new ValidatorMetricData(
            1, UInt64.valueOf(10L).longValue(), ""system"", 11L, 12L, ""teku"", ""21.8"", 3, 4);
    final String data = jsonProvider.objectToJSON(process);
    assertThat(process).isEqualTo(jsonProvider.jsonToObject(data, ValidatorMetricData.class));
  }
"
"  @BeforeEach
  public void beforeEach() throws Exception {
    mockWebServer.start();
  }
"
"  @AfterEach
  public void afterEach() throws Exception {
    mockWebServer.shutdown();
  }
"
"  @Test
  public void shouldRunPublisherEveryXSeconds() throws InterruptedException, IOException {
    MetricsPublisherManager publisherManager =
        new MetricsPublisherManager(asyncRunnerFactory, timeProvider, metricsEndpoint);
    publisherManager.setMetricsPublisher(metricsPublisher);
    verify(metricsPublisher, times(0)).publishMetrics(anyString(), anyString());
    SafeFuture<?> safeFuture = publisherManager.doStart();
    assertThat(asyncRunnerFactory.getStubAsyncRunners().size()).isEqualTo(1);
    asyncRunnerFactory.getStubAsyncRunners().get(0).executeQueuedActions();
    verify(metricsPublisher, times(1)).publishMetrics(anyString(), anyString());
    asyncRunnerFactory.getStubAsyncRunners().get(0).executeQueuedActions();
    verify(metricsPublisher, times(2)).publishMetrics(anyString(), anyString());
    Assertions.assertThat(safeFuture).isEqualTo(SafeFuture.COMPLETE);
  }
"
"  @Test
  public void shouldReturnHTTPStatusOk() throws IOException {
    MetricsPublisherManager publisherManager =
        new MetricsPublisherManager(asyncRunnerFactory, timeProvider, metricsEndpoint);
    publisherManager.setMetricsPublisher(metricsPublisher);
    Assertions.assertThat(publisherManager.publishMetrics()).isEqualTo(200);
  }
"
"  @Test
  public void shouldStopGracefully() throws IOException {
    MetricsPublisherManager publisherManager =
        new MetricsPublisherManager(asyncRunnerFactory, timeProvider, metricsEndpoint);
    publisherManager.setMetricsPublisher(metricsPublisher);
    SafeFuture<?> safeFuture = publisherManager.doStart();
    Assertions.assertThat(safeFuture).isEqualTo(SafeFuture.COMPLETE);
    safeFuture = publisherManager.doStop();
    Assertions.assertThat(safeFuture).isEqualTo(SafeFuture.COMPLETE);
  }
"
"  @Test
  public void shouldReadSlashingProtectionFile_withEmptyGenesisValidatorsRoot(@TempDir Path tempDir)
      throws IOException, URISyntaxException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtection.yml"", tempDir), log::add);
    assertThat(log).containsExactly(""Exporting "" + pubkey);
    assertThat(error).isEmpty();

    final SlashingProtectionInterchangeFormat parsedData =
        jsonProvider.jsonToObject(
            exporter.getPrettyJson(), SlashingProtectionInterchangeFormat.class);
    final SlashingProtectionInterchangeFormat expectedData = getExportData(null, 327, 51, 1741);
    assertThat(parsedData).isEqualTo(expectedData);
  }
"
"  @Test
  public void shouldReadSlashingProtectionFile_withGenesisValidatorsRoot(@TempDir Path tempDir)
      throws IOException, URISyntaxException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtectionWithGenesisRoot.yml"", tempDir), log::add);
    assertThat(log).containsExactly(""Exporting "" + pubkey);
    assertThat(error).isEmpty();

    final SlashingProtectionInterchangeFormat parsedData =
        jsonProvider.jsonToObject(
            exporter.getPrettyJson(), SlashingProtectionInterchangeFormat.class);
    final SlashingProtectionInterchangeFormat expectedData =
        getExportData(validatorsRoot, 327, 51, 1741);
    assertThat(parsedData).isEqualTo(expectedData);
  }
"
"  @Test
  public void shouldReadFilesWithEmptyRootAfterGenesisRootIsDefined(@TempDir Path tempDir)
      throws URISyntaxException, IOException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtectionWithGenesisRoot.yml"", tempDir), log::add);
    assertThat(error).isEmpty();
    error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtection.yml"", tempDir), log::add);
    assertThat(error).isEmpty();

    assertThat(log).containsExactly(""Exporting "" + pubkey, ""Exporting "" + pubkey);
  }
"
"  @Test
  public void shouldReadFileWithGenesisRootDefinedSecond(@TempDir Path tempDir)
      throws URISyntaxException, IOException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtection.yml"", tempDir), log::add);
    assertThat(error).isEmpty();
    error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtectionWithGenesisRoot.yml"", tempDir), log::add);
    assertThat(error).isEmpty();

    assertThat(log).containsExactly(""Exporting "" + pubkey, ""Exporting "" + pubkey);
  }
"
"  @Test
  public void shouldNotAcceptDifferentGenesisValidatorsRoot(@TempDir Path tempDir)
      throws URISyntaxException, IOException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtectionWithGenesisRoot2.yml"", tempDir), LOG::debug);
    assertThat(error).isEmpty();
    error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtectionWithGenesisRoot.yml"", tempDir), LOG::debug);
    assertThat(error.orElse("""")).startsWith(""The genesisValidatorsRoot of"");
  }
"
"  @Test
  public void shouldRequirePubkeyInFilename(@TempDir Path tempDir) throws URISyntaxException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    final Optional<String> error =
        exporter.readSlashProtectionFile(
            new File(Resources.getResource(""slashProtectionWithGenesisRoot.yml"").toURI()),
            LOG::debug);
    assertThat(error.orElse(""""))
        .contains(""Public key in file slashProtectionWithGenesisRoot.yml does not appear valid."");
  }
"
"  @Test
  public void shouldPrintIfFileCannotBeRead(@TempDir Path tempDir)
      throws URISyntaxException, IOException {
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    final File file = usingResourceFile(""slashProtection.yml"", tempDir);
    OSUtils.makeNonReadable(file.toPath());
    // It's not always possible to remove read permissions from a file
    assumeThat(file.canRead()).describedAs(""Can read file %s"", file).isFalse();
    final Optional<String> error = exporter.readSlashProtectionFile(file, LOG::debug);
    assertThat(error.orElse("""")).startsWith(""Failed to read from file"");
  }
"
"  @Test
  public void shouldExportSlashProtection(@TempDir Path tempDir)
      throws IOException, URISyntaxException {
    final Path exportedFile = tempDir.resolve(""exportedFile.json"").toAbsolutePath();
    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);

    final Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtection.yml"", tempDir), LOG::debug);
    assertThat(error).isEmpty();
    assertThat(Files.exists(exportedFile)).isFalse();
    exporter.saveToFile(exportedFile.toString(), LOG::debug);
    assertThat(Files.exists(exportedFile)).isTrue();
  }
"
"  @Test
  public void shouldExportSlashProtection(@TempDir Path tempDir)
      throws IOException, URISyntaxException {
    final Path exportedFile = tempDir.resolve(""exportedFile.json"").toAbsolutePath();
    final SlashingProtectionIncrementalExporter exporter =
        new SlashingProtectionIncrementalExporter(tempDir);

    final Optional<String> error =
        exporter.readSlashProtectionFile(
            usingResourceFile(""slashProtection.yml"", tempDir), LOG::debug);
    assertThat(error).isEmpty();
    assertThat(Files.exists(exportedFile)).isFalse();
    exporter.saveToFile(exportedFile.toString(), LOG::debug);

    final String exportedData = exporter.finalise();
    final String expectedResult = resourceFileAsString(""shouldExportSlashProtection.json"");
    assertThat(exportedData).isEqualTo(expectedResult);
  }
"
"  @Test
  public void shouldNotUpdateFilesWithInvalidPubkeys(@TempDir Path tempDir) throws IOException {
    setupPathForTest(tempDir, Map.of(""a.yml"", Optional.of(validatorSigningRecord)));
    SlashingProtectionRepairer repairer =
        SlashingProtectionRepairer.create(subCommandLogger, tempDir, true);
    assertThat(repairer.hasUpdates()).isFalse();
    verify(subCommandLogger).display("" --- a.yml - invalid public key - ignoring file"");

    repairer.updateRecords(UInt64.MAX_VALUE, UInt64.MAX_VALUE);
    verifyNoMoreInteractions(subCommandLogger);

    assertThat(fileContents(tempDir.resolve(""a.yml"")))
        .isEqualTo(Optional.of(validatorSigningRecord));
  }
"
"  @Test
  public void shouldUpdateValidAndInvalidFiles(@TempDir Path tempDir) throws IOException {
    setupPathForTest(tempDir, testData);
    SlashingProtectionRepairer repairer =
        SlashingProtectionRepairer.create(subCommandLogger, tempDir, true);
    assertThat(repairer.hasUpdates()).isTrue();

    final UInt64 blockSlot = UInt64.valueOf(1023999);
    final UInt64 attestationEpoch = UInt64.valueOf(2344);
    repairer.updateRecords(blockSlot, attestationEpoch);

    final Optional<ValidatorSigningRecord> defaultRecord =
        Optional.of(
            new ValidatorSigningRecord(null, blockSlot, attestationEpoch, attestationEpoch));

    assertThat(fileContents(tempDir.resolve(keys.get(0)))).isEqualTo(defaultRecord);
    // all original values were lower, so the entire file should get updated
    assertThat(fileContents(tempDir.resolve(keys.get(1)))).isEqualTo(defaultRecord);
    // sourceAttestation changed, but other values were higher
    assertThat(fileContents(tempDir.resolve(keys.get(2))))
        .isEqualTo(
            optionalSigningRecord(UInt64.valueOf(1024000), attestationEpoch, UInt64.valueOf(2345)));
    // all original values were better
    assertThat(fileContents(tempDir.resolve(keys.get(3)))).isEqualTo(testData.get(keys.get(3)));
  }
"
"  @Test
  public void shouldUpdateInvalidFiles(@TempDir Path tempDir) throws IOException {
    setupPathForTest(tempDir, testData);
    SlashingProtectionRepairer repairer =
        SlashingProtectionRepairer.create(subCommandLogger, tempDir, false);
    assertThat(repairer.hasUpdates()).isTrue();

    final UInt64 blockSlot = UInt64.valueOf(1023999);
    final UInt64 attestationEpoch = UInt64.valueOf(2344);
    repairer.updateRecords(blockSlot, attestationEpoch);

    final Optional<ValidatorSigningRecord> defaultRecord =
        Optional.of(
            new ValidatorSigningRecord(null, blockSlot, attestationEpoch, attestationEpoch));

    assertThat(fileContents(tempDir.resolve(keys.get(0)))).isEqualTo(defaultRecord);
    assertThat(fileContents(tempDir.resolve(keys.get(1)))).isEqualTo(testData.get(keys.get(1)));
    assertThat(fileContents(tempDir.resolve(keys.get(2)))).isEqualTo(testData.get(keys.get(2)));
    assertThat(fileContents(tempDir.resolve(keys.get(3)))).isEqualTo(testData.get(keys.get(3)));
  }
"
"  @Test
  public void shouldFailWithParseError(@TempDir final Path tempDir)
      throws URISyntaxException, IOException {
    final String errorString = loadAndGetErrorText(""minimal_invalidKey.json"", tempDir);
    assertThat(errorString).startsWith(""Failed to load data"");
  }
"
"  @Test
  public void shouldFailWithInvalidJson(@TempDir final Path tempDir)
      throws URISyntaxException, IOException {
    final String errorString = loadAndGetErrorText(""invalid_json.json"", tempDir);
    assertThat(errorString).startsWith(""Json does not appear valid"");
  }
"
"  @Test
  public void shouldFailWithVersionCheckFailure(@TempDir final Path tempDir)
      throws URISyntaxException, IOException {
    final String errorString = loadAndGetErrorText(""oldMetadata.json"", tempDir);
    assertThat(errorString)
        .contains(""Required version is "" + Metadata.INTERCHANGE_VERSION.toString());
  }
"
"  @Test
  public void shouldFailIfMetadataNotPresent(@TempDir final Path tempDir)
      throws IOException, URISyntaxException {
    final String errorString = loadAndGetErrorText(""signedBlock.json"", tempDir);
    assertThat(errorString).contains(""does not appear to have metadata"");
  }
"
"  @Test
  public void shouldImportSingleRecord(@TempDir Path tempDir)
      throws URISyntaxException, IOException {
    final File ruleFile = usingResourceFile(""slashProtection.yml"", tempDir);
    final SlashingProtectionImporter importer = new SlashingProtectionImporter(tempDir);
    importer.initialise(ruleFile);
    final Optional<String> maybeError = importer.updateSigningRecord(publicKey, (__) -> {});
    assertThat(maybeError).isEmpty();
    assertThat(tempDir.resolve(pubkey + "".yml"").toFile()).exists();
  }
"
"  @Test
  public void shouldExportAndImportFile(@TempDir Path tempDir)
      throws IOException, URISyntaxException {
    final Path exportedFile = tempDir.resolve(""exportedFile.json"").toAbsolutePath();

    final SlashingProtectionExporter exporter = new SlashingProtectionExporter(tempDir);
    final File ruleFile = usingResourceFile(""slashProtection.yml"", tempDir);
    final Optional<String> exportError = exporter.readSlashProtectionFile(ruleFile, LOG::debug);
    final String originalFileContent = Files.readString(ruleFile.toPath());
    assertThat(exportError).isEmpty();

    assertThat(Files.exists(ruleFile.toPath())).isTrue();
    assertThat(Files.exists(exportedFile)).isFalse();
    exporter.saveToFile(exportedFile.toString(), LOG::debug);
    ruleFile.delete();
    assertThat(Files.exists(exportedFile)).isTrue();
    assertThat(Files.exists(ruleFile.toPath())).isFalse();

    SlashingProtectionImporter importer = new SlashingProtectionImporter(tempDir);
    importer.initialise(new File(exportedFile.toString()));
    final Map<BLSPublicKey, String> errors = importer.updateLocalRecords((__) -> {});
    assertThat(errors).isEmpty();
    assertThat(Files.exists(ruleFile.toPath())).isTrue();

    assertThat(originalFileContent).isEqualTo(Files.readString(ruleFile.toPath()));
  }
"
"  @Test
  public void shouldReadMetadataFromCompleteJson() throws IOException {
    final String minimalJson =
        Resources.toString(Resources.getResource(""format1_complete.json""), StandardCharsets.UTF_8);

    JsonNode jsonNode = mapper.readTree(minimalJson);
    JsonNode metadataJson = jsonNode.get(""metadata"");
    Metadata metadata = mapper.treeToValue(metadataJson, Metadata.class);
    assertThat(metadata).isEqualTo(new Metadata(INTERCHANGE_VERSION, GENESIS_ROOT));

    List<SigningHistory> completeSigningHistories =
        Arrays.asList(mapper.readValue(jsonNode.get(""data"").toString(), SigningHistory[].class));

    assertThat(completeSigningHistories)
        .containsExactly(
            new SigningHistory(
                blsPubKey,
                List.of(
                    new SignedBlock(
                        UInt64.valueOf(81952),
                        Bytes32.fromHexString(
                            ""0x0000000000000000000000000000000000000000000000000000000000001234""))),
                List.of(
                    new SignedAttestation(
                        UInt64.valueOf(2290),
                        UInt64.valueOf(3007),
                        Bytes32.fromHexString(
                            ""0x0000000000000000000000000000000000000000000000000000000000000123"")))));
  }
"
"  @Test
  public void shouldCreate() {
    final SignedAttestation signedAttestation = new SignedAttestation(source, target, signingRoot);
    assertThat(signedAttestation.sourceEpoch).isEqualTo(source);
    assertThat(signedAttestation.targetEpoch).isEqualTo(target);
    assertThat(signedAttestation.signingRoot).isEqualTo(signingRoot);
  }
"
"  @Test
  public void shouldSerialize() throws JsonProcessingException {
    final SignedAttestation signedAttestation = new SignedAttestation(source, target, signingRoot);
    String str = jsonProvider.objectToPrettyJSON(signedAttestation);
    assertThat(str).isEqualToNormalizingNewlines(jsonData);
  }
"
"  @Test
  public void shouldDeserialize() throws JsonProcessingException {
    final SignedAttestation signedAttestation =
        jsonProvider.jsonToObject(jsonData, SignedAttestation.class);
    assertThat(signedAttestation.sourceEpoch).isEqualTo(source);
    assertThat(signedAttestation.targetEpoch).isEqualTo(target);
    assertThat(signedAttestation.signingRoot).isEqualTo(signingRoot);
  }
"
"  @Test
  public void shouldReadMetadataFromMinimalJson() throws IOException {
    final String minimalJson =
        Resources.toString(Resources.getResource(""format2_minimal.json""), StandardCharsets.UTF_8);

    JsonNode jsonNode = mapper.readTree(minimalJson);
    JsonNode metadataJson = jsonNode.get(""metadata"");
    Metadata metadata = mapper.treeToValue(metadataJson, Metadata.class);
    assertThat(metadata).isEqualTo(new Metadata(INTERCHANGE_VERSION, GENESIS_ROOT));

    List<SigningHistory> minimalSigningHistoryList =
        Arrays.asList(mapper.readValue(jsonNode.get(""data"").toString(), SigningHistory[].class));

    SigningHistory element =
        new SigningHistory(
            blsPubKey,
            new ValidatorSigningRecord(
                GENESIS_ROOT, UInt64.valueOf(81952), UInt64.valueOf(2290), UInt64.valueOf(3007)));
    assertThat(minimalSigningHistoryList).containsExactly(element);
  }
"
"  @Test
  public void shouldSerializeMinimalFormat() throws JsonProcessingException {
    final Metadata metadata = new Metadata(INTERCHANGE_VERSION, root);
    assertThat(jsonProvider.objectToPrettyJSON(metadata)).isEqualToNormalizingNewlines(jsonData);
  }
"
"  @Test
  public void shouldSerializeWithoutRoot() throws JsonProcessingException {
    final Metadata metadata = new Metadata(INTERCHANGE_VERSION, null);
    assertThat(jsonProvider.objectToPrettyJSON(metadata))
        .isEqualToIgnoringWhitespace(""{\""interchange_format_version\"":\""5\""}"");
  }
"
"  @Test
  public void shouldSerializeCompleteFormat() throws JsonProcessingException {
    final Metadata metadata = new Metadata(INTERCHANGE_VERSION, root);
    assertThat(jsonProvider.objectToPrettyJSON(metadata)).isEqualToNormalizingNewlines(jsonData);
  }
"
"  @Test
  public void shouldDeserialize() throws JsonProcessingException {
    final Metadata metadata = jsonProvider.jsonToObject(jsonData, Metadata.class);
    assertThat(metadata.interchangeFormatVersion).isEqualTo(INTERCHANGE_VERSION);
    assertThat(metadata.genesisValidatorsRoot).isEqualTo(root);
  }
"
"  @Test
  public void shouldReadMetadataFromCompleteJson() throws IOException {
    final String completeJson =
        Resources.toString(Resources.getResource(""format1_complete.json""), StandardCharsets.UTF_8);

    JsonNode metadataJson = mapper.readTree(completeJson).get(""metadata"");
    Metadata metadata = mapper.treeToValue(metadataJson, Metadata.class);

    assertThat(metadata).isEqualTo(expectedMetadata);
  }
"
"  @Test
  public void shouldReadMetadataFromJson() throws IOException {
    final String minimalJson =
        Resources.toString(Resources.getResource(""format2_minimal.json""), StandardCharsets.UTF_8);

    JsonNode metadataJson = mapper.readTree(minimalJson).get(""metadata"");
    Metadata metadata = mapper.treeToValue(metadataJson, Metadata.class);
    assertThat(metadata).isEqualTo(expectedMetadata);
  }
"
"  @Test
  public void shouldSerialize() throws JsonProcessingException {
    final SignedBlock signedBlock = new SignedBlock(slot, signingRoot);
    String str = jsonProvider.objectToPrettyJSON(signedBlock);
    assertThat(str).isEqualToNormalizingNewlines(jsonData);
  }
"
"  @Test
  public void shouldDeserialize() throws JsonProcessingException {
    final SignedBlock signedBlock = jsonProvider.jsonToObject(jsonData, SignedBlock.class);
    assertThat(signedBlock.slot).isEqualTo(slot);
    assertThat(signedBlock.signingRoot).isEqualTo(signingRoot);
  }
"
"  @BeforeEach
  public void setup() {
    slot = UInt64.valueOf(specConfig.getSlotsPerEpoch() * 3L);
    actualBalance = specConfig.getMaxEffectiveBalance().plus(100000);
    storageSystem.chainUpdater().initializeGenesis(true, actualBalance, Optional.empty());
    bestBlock = storageSystem.chainUpdater().advanceChain(slot);
    storageSystem.chainUpdater().updateBestBlock(bestBlock);

    recentChainData = storageSystem.recentChainData();
    beaconStateInternal = bestBlock.getState();

    combinedChainDataClient = storageSystem.combinedChainDataClient();
    blockRoot = bestBlock.getRoot();
  }
"
"  @Test
  public void getChainHeads_shouldReturnChainHeads()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final SafeFuture<Optional<List<ChainHead>>> future = provider.getChainHeads();
    final Optional<List<ChainHead>> maybeResult = future.get();
    assertThat(maybeResult.orElse(emptyList()))
        .containsExactly(new ChainHead(bestBlock.getSlot(), blockRoot));
  }
"
"  @Test
  public void getGenesisTime_shouldThrowIfStoreNotAvailable() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, null, mockCombinedChainDataClient);
    when(mockCombinedChainDataClient.isStoreAvailable()).thenReturn(false);
    assertThatThrownBy(provider::getGenesisTime).isInstanceOf(ChainDataUnavailableException.class);
  }
"
"  @Test
  public void getGenesisTime_shouldReturnValueIfStoreAvailable() {
    final UInt64 genesis = beaconStateInternal.getGenesis_time();
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    final UInt64 result = provider.getGenesisTime();
    assertEquals(genesis, result);
  }
"
"  @Test
  public void getGenesisData_shouldThrowIfStoreNotAvailable() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, null, mockCombinedChainDataClient);
    when(mockCombinedChainDataClient.isStoreAvailable()).thenReturn(false);
    assertThatThrownBy(provider::getGenesisData).isInstanceOf(ChainDataUnavailableException.class);
  }
"
"  @Test
  public void getGenesisData_shouldReturnValueIfStoreAvailable() {
    final UInt64 genesisTime = beaconStateInternal.getGenesis_time();
    final Bytes32 genesisValidatorsRoot = beaconStateInternal.getGenesis_validators_root();
    final Bytes4 genesisForkVersion = spec.atEpoch(ZERO).getConfig().getGenesisForkVersion();

    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    final GenesisData result = provider.getGenesisData();
    assertThat(result)
        .isEqualTo(new GenesisData(genesisTime, genesisValidatorsRoot, genesisForkVersion));
  }
"
"  @Test
  public void getBeaconState_shouldReturnEmptyWhenRootNotFound()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    SafeFuture<Optional<BeaconState>> future =
        provider.getBeaconState(data.randomBytes32().toHexString());
    final Optional<BeaconState> maybeState = future.get();
    assertThat(maybeState).isEmpty();
  }
"
"  @Test
  public void getBeaconState_shouldFindHeadState() throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    SafeFuture<Optional<BeaconState>> future = provider.getBeaconState(""head"");
    final Optional<BeaconState> maybeState = future.get();
    assertThat(maybeState.get().asInternalBeaconState(spec).hashTreeRoot())
        .isEqualTo(beaconStateInternal.hashTreeRoot());
  }
"
"  @Test
  public void validatorParameterToIndex_shouldThrowWhenStoreNotFound() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, null, mockCombinedChainDataClient);
    assertThrows(
        ChainDataUnavailableException.class, () -> provider.validatorParameterToIndex(""1""));
  }
"
"  @Test
  public void validatorParameterToIndex_shouldAcceptValidatorRoot() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    Validator validator =
        new Validator(recentChainData.getBestState().get().getValidators().get(1));

    assertThat(provider.validatorParameterToIndex(validator.pubkey.toHexString()))
        .isEqualTo(Optional.of(1));
  }
"
"  @Test
  public void validatorParameterToIndex_shouldAcceptValidatorId() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThat(provider.validatorParameterToIndex(""2"")).isEqualTo(Optional.of(2));
  }
"
"  @Test
  public void validatorParameterToIndex_shouldThrowException() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThrows(BadRequestException.class, () -> provider.validatorParameterToIndex(""2a""));
  }
"
"  @Test
  public void validatorParameterToIndex_shouldDetectAboveMaxInt() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThrows(
        BadRequestException.class,
        () ->
            provider.validatorParameterToIndex(
                UInt64.valueOf(Integer.MAX_VALUE).increment().toString()));
  }
"
"  @Test
  public void validatorParameterToIndex_shouldThrowExceptionWithInvalidPublicKey() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThrows(
        BadRequestException.class,
        () -> provider.validatorParameterToIndex(Bytes32.EMPTY.toHexString()));
  }
"
"  @Test
  public void getBlockHeaderByBlockId_shouldGetHeadBlock()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final tech.pegasys.teku.spec.datastructures.blocks.SignedBeaconBlock block =
        combinedChainDataClient.getBestBlock().get();
    BlockHeader result = provider.getBlockHeader(""head"").get().get();
    final BeaconBlockHeader beaconBlockHeader =
        new BeaconBlockHeader(
            block.getSlot(),
            block.getMessage().getProposerIndex(),
            block.getParentRoot(),
            block.getStateRoot(),
            block.getRoot());
    final BlockHeader expected =
        new BlockHeader(
            block.getRoot(),
            true,
            new SignedBeaconBlockHeader(beaconBlockHeader, new BLSSignature(block.getSignature())));

    assertThat(result).isEqualTo(expected);
  }
"
"  @Test
  public void getStateRoot_shouldGetRootAtGenesis()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    final Optional<tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState> state =
        combinedChainDataClient.getStateAtSlotExact(ZERO).get();
    final Optional<Root> maybeStateRoot = provider.getStateRoot(""genesis"").get();
    assertThat(maybeStateRoot).isPresent();
    assertThat(maybeStateRoot.orElseThrow().root).isEqualTo(state.orElseThrow().hashTreeRoot());
  }
"
"  @Test
  public void getBlockHeaders_shouldGetHeadBlockIfNoParameters()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final tech.pegasys.teku.spec.datastructures.blocks.SignedBeaconBlock block =
        combinedChainDataClient.getBestBlock().get();
    List<BlockHeader> results = provider.getBlockHeaders(Optional.empty(), Optional.empty()).get();
    assertThat(results.get(0).root).isEqualTo(block.getRoot());
  }
"
"  @Test
  public void getBlockHeaders_shouldGetBlockGivenSlot()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final UInt64 slot = combinedChainDataClient.getCurrentSlot();
    List<BlockHeader> results = provider.getBlockHeaders(Optional.empty(), Optional.of(slot)).get();
    assertThat(results.get(0).header.message.slot).isEqualTo(slot);
  }
"
"  @Test
  public void shouldGetBlockHeadersOnEmptyChainHeadSlot() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    final UInt64 headSlot = recentChainData.getHeadSlot();
    storageSystem.chainUpdater().advanceChain(headSlot.plus(1));

    final SafeFuture<List<BlockHeader>> future =
        provider.getBlockHeaders(Optional.empty(), Optional.empty());
    final BlockHeader header = future.join().get(0);
    assertThat(header.header.message.slot).isEqualTo(headSlot);
  }
"
"  @Test
  public void filteredValidatorsList_shouldFilterByValidatorIndex() {

    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(1024);
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    List<Integer> indexes =
        provider.getFilteredValidatorList(internalState, List.of(""1"", ""33""), emptySet()).stream()
            .map(v -> v.index.intValue())
            .collect(toList());
    assertThat(indexes).containsExactly(1, 33);
  }
"
"  @Test
  public void filteredValidatorsList_shouldFilterByValidatorPubkey() {
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(1024);
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final String key = internalState.getValidators().get(12).getPubkeyBytes().toString();
    final String missingKey = data.randomPublicKey().toString();
    List<String> pubkeys =
        provider
            .getFilteredValidatorList(internalState, List.of(key, missingKey), emptySet())
            .stream()
            .map(v -> v.validator.pubkey.toHexString())
            .collect(toList());
    assertThat(pubkeys).containsExactly(key);
  }
"
"  @Test
  public void validatorParameterToIndex_shouldThrowBadRequestExceptionWhenIndexInvalid() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    assertThrows(BadRequestException.class, () -> provider.validatorParameterToIndex(""a""));
  }
"
"  @Test
  public void validatorParameterToIndex_shouldReturnEmptyIfIndexOutOfBounds() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    assertThat(provider.validatorParameterToIndex(""1024000"")).isEmpty();
  }
"
"  @Test
  public void validatorParameterToIndex_shouldThrowBadRequestExceptionWhenKeyNotFound() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    assertThrows(
        BadRequestException.class,
        () -> provider.validatorParameterToIndex(Bytes32.fromHexString(""0x00"").toHexString()));
  }
"
"  @Test
  public void filteredValidatorsList_shouldFilterByValidatorStatus() {
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(11);
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThat(
            provider.getFilteredValidatorList(
                internalState, emptyList(), Set.of(ValidatorStatus.pending_initialized)))
        .hasSize(11);
    assertThat(
            provider.getFilteredValidatorList(
                internalState, emptyList(), Set.of(ValidatorStatus.active_ongoing)))
        .hasSize(0);
  }
"
"  @Test
  public void getStateCommittees_shouldReturnEmptyIfStateNotFound()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    assertThat(
            provider
                .getStateCommittees(
                    data.randomBytes32().toHexString(),
                    Optional.empty(),
                    Optional.empty(),
                    Optional.empty())
                .get())
        .isEmpty();
  }
"
"  @Test
  public void getCommitteesFromState_shouldNotRequireFilters() {
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(64);
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThat(
            provider
                .getCommitteesFromState(
                    internalState, Optional.empty(), Optional.empty(), Optional.empty())
                .size())
        .isEqualTo(specConfig.getSlotsPerEpoch());
  }
"
"  @Test
  public void getCommitteesFromState_shouldFilterOnSlot() {
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(64);
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThat(
            provider
                .getCommitteesFromState(
                    internalState,
                    Optional.empty(),
                    Optional.empty(),
                    Optional.of(internalState.getSlot()))
                .size())
        .isEqualTo(1);
  }
"
"  @Test
  public void getStateFinalityCheckpoints_shouldGetEmptyCheckpointsBeforeFinalized()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    assertThat(provider.getStateFinalityCheckpoints(""genesis"").get().get())
        .isEqualTo(
            new FinalityCheckpointsResponse(
                tech.pegasys.teku.api.schema.Checkpoint.EMPTY,
                tech.pegasys.teku.api.schema.Checkpoint.EMPTY,
                tech.pegasys.teku.api.schema.Checkpoint.EMPTY));
  }
"
"  @Test
  public void getStateFinalityCheckpoints_shouldGetCheckpointsAfterFinalized()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, mockCombinedChainDataClient);
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(UInt64.valueOf(42));
    final FinalityCheckpointsResponse expected =
        new FinalityCheckpointsResponse(
            new tech.pegasys.teku.api.schema.Checkpoint(
                internalState.getPrevious_justified_checkpoint()),
            new tech.pegasys.teku.api.schema.Checkpoint(
                internalState.getCurrent_justified_checkpoint()),
            new tech.pegasys.teku.api.schema.Checkpoint(internalState.getFinalized_checkpoint()));

    when(mockCombinedChainDataClient.getBestState()).thenReturn(Optional.of(internalState));
    assertThat(provider.getStateFinalityCheckpoints(""head"").get().get()).isEqualTo(expected);
    verify(mockCombinedChainDataClient).getBestState();
  }
"
"  @Test
  public void getStateSyncCommittees_shouldGetCommittees()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider = setupAltairState();
    final List<UInt64> committeeIndices =
        List.of(UInt64.valueOf(6), UInt64.valueOf(9), UInt64.valueOf(0));

    final SafeFuture<Optional<StateSyncCommittees>> future =
        provider.getStateSyncCommittees(""head"", Optional.empty());
    assertThat(future).isCompleted();
    assertThat(future.get().get())
        .isEqualTo(new StateSyncCommittees(committeeIndices, List.of(committeeIndices)));
  }
"
"  @Test
  public void getStateSyncCommittees_shouldReturnEmptyListBeforeAltair()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState();
    when(mockCombinedChainDataClient.getBestState()).thenReturn(Optional.of(internalState));

    final SafeFuture<Optional<StateSyncCommittees>> future =
        provider.getStateSyncCommittees(""head"", Optional.empty());
    assertThat(future.get().get()).isEqualTo(new StateSyncCommittees(List.of(), List.of()));
  }
"
"  @Test
  public void getStateSyncCommittees_shouldRejectFarFutureEpoch() {
    final ChainDataProvider provider = setupAltairState();
    final SafeFuture<Optional<StateSyncCommittees>> future =
        provider.getStateSyncCommittees(""head"", Optional.of(UInt64.valueOf(""1024000"")));
    SafeFutureAssert.assertThatSafeFuture(future)
        .isCompletedExceptionallyWith(IllegalArgumentException.class);
  }
"
"  @Test
  public void getStateFork_shouldGetForkAtGenesis()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);

    final Bytes4 bytes4 = Bytes4.fromHexString(""0x00000001"");
    final Optional<Fork> response = provider.getStateFork(""genesis"").get();
    assertThat(response).isPresent();
    assertThat(response.get()).isEqualTo(new Fork(bytes4, bytes4, ZERO));
  }
"
"  @Test
  public void getValidatorBalancesFromState_shouldGetBalances() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(1024);
    assertThat(provider.getValidatorBalancesFromState(internalState, emptyList())).hasSize(1024);

    assertThat(
            provider.getValidatorBalancesFromState(
                internalState, List.of(""0"", ""100"", ""1023"", ""1024"", ""1024000"")))
        .hasSize(3);
  }
"
"  @Test
  public void getBlockRoot_shouldReturnRootOfBlock() throws Exception {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final Optional<Root> response = provider.getBlockRoot(""head"").get();
    assertThat(response).isPresent();
    assertThat(response.get()).isEqualTo(new Root(bestBlock.getRoot()));
  }
"
"  @Test
  public void getBlockAttestations_shouldReturnAttestationsOfBlock() throws Exception {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    ChainBuilder chainBuilder = storageSystem.chainBuilder();

    ChainBuilder.BlockOptions blockOptions = ChainBuilder.BlockOptions.create();
    AttestationGenerator attestationGenerator =
        new AttestationGenerator(spec, chainBuilder.getValidatorKeys());
    tech.pegasys.teku.spec.datastructures.operations.Attestation attestation1 =
        attestationGenerator.validAttestation(bestBlock.toUnsigned(), bestBlock.getSlot());
    tech.pegasys.teku.spec.datastructures.operations.Attestation attestation2 =
        attestationGenerator.validAttestation(
            bestBlock.toUnsigned(), bestBlock.getSlot().increment());
    blockOptions.addAttestation(attestation1);
    blockOptions.addAttestation(attestation2);
    SignedBlockAndState newHead =
        storageSystem
            .chainBuilder()
            .generateBlockAtSlot(bestBlock.getSlot().plus(10), blockOptions);
    storageSystem.chainUpdater().saveBlock(newHead);
    storageSystem.chainUpdater().updateBestBlock(newHead);

    final Optional<List<Attestation>> response = provider.getBlockAttestations(""head"").get();
    assertThat(response).isPresent();
    assertThat(response.get())
        .containsExactly(new Attestation(attestation1), new Attestation(attestation2));
  }
"
"  @Test
  public void headSelector_shouldGetBestBlock() throws ExecutionException, InterruptedException {
    when(client.getBestBlock()).thenReturn(Optional.of(block));
    List<SignedBeaconBlock> blockList = blockSelectorFactory.headSelector().getBlock().get();
    verify(client).getBestBlock();
    assertThat(blockList).containsExactly(block);
  }
"
"  @Test
  public void finalizedSelector_shouldGetFinalizedBlock()
      throws ExecutionException, InterruptedException {
    when(client.getFinalizedBlock()).thenReturn(Optional.of(block));
    List<SignedBeaconBlock> blockList = blockSelectorFactory.finalizedSelector().getBlock().get();
    verify(client).getFinalizedBlock();
    assertThat(blockList).containsExactly(block);
  }
"
"  @Test
  public void genesisSelector_shouldGetSlotZero() throws ExecutionException, InterruptedException {
    when(client.getBlockAtSlotExact(UInt64.ZERO))
        .thenReturn(SafeFuture.completedFuture(Optional.of(block)));
    List<SignedBeaconBlock> blockList = blockSelectorFactory.genesisSelector().getBlock().get();
    verify(client).getBlockAtSlotExact(UInt64.ZERO);
    assertThat(blockList).containsExactly(block);
  }
"
"  @Test
  public void blockRootSelector_shouldGetBlockByBlockRoot()
      throws ExecutionException, InterruptedException {
    when(client.getBlockByBlockRoot(any()))
        .thenReturn(SafeFuture.completedFuture(Optional.of(block)));
    List<SignedBeaconBlock> blockList =
        blockSelectorFactory.forBlockRoot(block.getRoot()).getBlock().get();
    verify(client).getBlockByBlockRoot(block.getRoot());
    assertThat(blockList).containsExactly(block);
  }
"
"  @Test
  public void slotSelector_shouldGetBlockAtSlotExact()
      throws ExecutionException, InterruptedException {
    when(client.getBlockAtSlotExact(block.getSlot()))
        .thenReturn(SafeFuture.completedFuture(Optional.of(block)));
    List<SignedBeaconBlock> blockList =
        blockSelectorFactory.forSlot(block.getSlot()).getBlock().get();
    verify(client).getBlockAtSlotExact(block.getSlot());
    assertThat(blockList).containsExactly(block);
  }
"
"  @Test
  public void defaultBlockSelector_shouldThrowBadRequestException() {
    assertThrows(BadRequestException.class, () -> blockSelectorFactory.defaultBlockSelector(""a""));
  }
"
"  @TestTemplate
  public void setup(SpecContext specContext) {
    spec = specContext.getSpec();
    dataStructureUtil = specContext.getDataStructureUtil();
    schemaProvider = new SchemaObjectProvider(spec);
    provider = new ValidatorDataProvider(spec, validatorApiChannel, combinedChainDataClient);
    blockInternal = dataStructureUtil.randomBeaconBlock(123);
    block = schemaProvider.getBeaconBlock(blockInternal);
  }
"
"  @TestTemplate
  public void submitSignedBlock_shouldReturn200ForSuccess()
      throws ExecutionException, InterruptedException {
    final SignedBeaconBlock internalSignedBeaconBlock =
        dataStructureUtil.randomSignedBeaconBlock(1);
    final tech.pegasys.teku.api.schema.SignedBeaconBlock signedBeaconBlock =
        tech.pegasys.teku.api.schema.SignedBeaconBlock.create(internalSignedBeaconBlock);

    final SafeFuture<SendSignedBlockResult> successImportResult =
        completedFuture(SendSignedBlockResult.success(internalSignedBeaconBlock.getRoot()));

    when(validatorApiChannel.sendSignedBlock(any())).thenReturn(successImportResult);

    final SafeFuture<ValidatorBlockResult> validatorBlockResultSafeFuture =
        provider.submitSignedBlock(signedBeaconBlock);

    assertThat(validatorBlockResultSafeFuture.get().getResponseCode()).isEqualTo(200);
  }
"
"  @TestTemplate
  public void submitSignedBlock_shouldReturn202ForInvalidBlock() {
    final SignedBeaconBlock internalSignedBeaconBlock =
        dataStructureUtil.randomSignedBeaconBlock(1);
    final tech.pegasys.teku.api.schema.SignedBeaconBlock signedBeaconBlock =
        tech.pegasys.teku.api.schema.SignedBeaconBlock.create(internalSignedBeaconBlock);
    final AtomicInteger failReasonCount = new AtomicInteger();

    Stream.of(FailureReason.values())
        .filter(failureReason -> !failureReason.equals(FailureReason.INTERNAL_ERROR))
        .forEach(
            failureReason -> {
              failReasonCount.getAndIncrement();

              final SafeFuture<SendSignedBlockResult> failImportResult =
                  completedFuture(SendSignedBlockResult.notImported(failureReason.name()));

              when(validatorApiChannel.sendSignedBlock(any())).thenReturn(failImportResult);

              final SafeFuture<ValidatorBlockResult> validatorBlockResultSafeFuture =
                  provider.submitSignedBlock(signedBeaconBlock);

              try {
                assertThat(validatorBlockResultSafeFuture.get().getResponseCode()).isEqualTo(202);
              } catch (final Exception e) {
                fail(""Exception while executing test."");
              }
            });

    // Assert that the check has run over each FailureReason except the 500.
    assertThat(failReasonCount.get()).isEqualTo(FailureReason.values().length - 1);
  }
"
"  @TestTemplate
  public void submitSignedBlock_shouldReturn500ForInternalError()
      throws ExecutionException, InterruptedException {
    final SignedBeaconBlock internalSignedBeaconBlock =
        dataStructureUtil.randomSignedBeaconBlock(1);
    final tech.pegasys.teku.api.schema.SignedBeaconBlock signedBeaconBlock =
        tech.pegasys.teku.api.schema.SignedBeaconBlock.create(internalSignedBeaconBlock);

    final SafeFuture<SendSignedBlockResult> failImportResult =
        completedFuture(SendSignedBlockResult.rejected(FailureReason.INTERNAL_ERROR.name()));

    when(validatorApiChannel.sendSignedBlock(any())).thenReturn(failImportResult);

    final SafeFuture<ValidatorBlockResult> validatorBlockResultSafeFuture =
        provider.submitSignedBlock(signedBeaconBlock);

    assertThat(validatorBlockResultSafeFuture.get().getResponseCode()).isEqualTo(500);
  }
"
"  @TestTemplate
  public void getAttesterDuties_shouldHandleEmptyIndexesList() {
    final Bytes32 previousTargetRoot = dataStructureUtil.randomBytes32();
    when(validatorApiChannel.getAttestationDuties(eq(ONE), any()))
        .thenReturn(
            completedFuture(
                Optional.of(
                    new tech.pegasys.teku.validator.api.AttesterDuties(
                        previousTargetRoot, emptyList()))));
    final SafeFuture<Optional<PostAttesterDutiesResponse>> future =
        provider.getAttesterDuties(UInt64.ONE, List.of());
    assertThat(future).isCompleted();
    Optional<PostAttesterDutiesResponse> maybeData = future.join();
    assertThat(maybeData.isPresent()).isTrue();
    assertThat(maybeData.get().data).isEmpty();
  }
"
"  @TestTemplate
  public void getAttesterDuties_shouldReturnDutiesForKnownValidator() {
    AttesterDuty v1 = new AttesterDuty(BLSTestUtil.randomPublicKey(0), 1, 2, 3, 15, 4, ONE);
    AttesterDuty v2 = new AttesterDuty(BLSTestUtil.randomPublicKey(1), 11, 12, 13, 15, 14, ZERO);
    when(validatorApiChannel.getAttestationDuties(eq(ONE), any()))
        .thenReturn(
            completedFuture(
                Optional.of(
                    new AttesterDuties(dataStructureUtil.randomBytes32(), List.of(v1, v2)))));

    final SafeFuture<Optional<PostAttesterDutiesResponse>> future =
        provider.getAttesterDuties(ONE, List.of(1, 11));
    assertThat(future).isCompleted();
    final Optional<PostAttesterDutiesResponse> maybeList = future.join();
    final PostAttesterDutiesResponse list = maybeList.orElseThrow();
    assertThat(list.data).containsExactlyInAnyOrder(asAttesterDuty(v1), asAttesterDuty(v2));
  }
"
"  @Test
  public void headSelector_shouldGetBestState() throws ExecutionException, InterruptedException {
    when(client.getBestState()).thenReturn(Optional.of(state));
    Optional<BeaconState> result = factory.headSelector().getState().get();
    assertThat(result).isEqualTo(Optional.of(state));
    verify(client).getBestState();
  }
"
"  @Test
  public void finalizedSelector_shouldGetFinalizedState()
      throws ExecutionException, InterruptedException {
    when(client.getFinalizedState()).thenReturn(Optional.of(state));
    Optional<BeaconState> result = factory.finalizedSelector().getState().get();
    assertThat(result).isEqualTo(Optional.of(state));
    verify(client).getFinalizedState();
  }
"
"  @Test
  public void justifiedSelector_shouldGetJustifiedState()
      throws ExecutionException, InterruptedException {
    when(client.getJustifiedState()).thenReturn(SafeFuture.completedFuture(Optional.of(state)));
    Optional<BeaconState> result = factory.justifiedSelector().getState().get();
    assertThat(result).isEqualTo(Optional.of(state));
    verify(client).getJustifiedState();
  }
"
"  @Test
  public void genesisSelector_shouldGetStateAtSlotExact()
      throws ExecutionException, InterruptedException {
    when(client.getStateAtSlotExact(ZERO))
        .thenReturn(SafeFuture.completedFuture(Optional.of(state)));
    Optional<BeaconState> result = factory.genesisSelector().getState().get();
    assertThat(result).isEqualTo(Optional.of(state));
    verify(client).getStateAtSlotExact(ZERO);
  }
"
"  @Test
  public void forSlot_shouldGetStateAtSlotExact() throws ExecutionException, InterruptedException {
    when(client.getStateAtSlotExact(state.getSlot()))
        .thenReturn(SafeFuture.completedFuture(Optional.of(state)));
    Optional<BeaconState> result = factory.forSlot(state.getSlot()).getState().get();
    assertThat(result).isEqualTo(Optional.of(state));
    verify(client).getStateAtSlotExact(state.getSlot());
  }
"
"  @Test
  public void forStateRoot_shouldGetStateAtSlotExact()
      throws ExecutionException, InterruptedException {
    when(client.getStateByStateRoot(state.hashTreeRoot()))
        .thenReturn(SafeFuture.completedFuture(Optional.of(state)));
    Optional<BeaconState> result = factory.forStateRoot(state.hashTreeRoot()).getState().get();
    assertThat(result).isEqualTo(Optional.of(state));
    verify(client).getStateByStateRoot(state.hashTreeRoot());
  }
"
"  @Test
  public void defaultStateSelector_shouldThrowBadRequestException() {
    assertThrows(BadRequestException.class, () -> factory.defaultStateSelector(""a""));
  }
"
"  @Test
  public void byBlockRootSelector_shouldThrowBadRequestException() {
    assertThrows(BadRequestException.class, () -> factory.byBlockRootStateSelector(""a""));
  }
"
"  @Test
  public void stateSelector_shouldReturnEmptyWhenPreForkChoice()
      throws ExecutionException, InterruptedException {
    final StorageQueryChannel historicalChainData = mock(StorageQueryChannel.class);
    final RecentChainData recentChainData = mock(RecentChainData.class);
    final CombinedChainDataClient client1 =
        new CombinedChainDataClient(recentChainData, historicalChainData, spec);
    final StateSelectorFactory factory = new StateSelectorFactory(client1);
    when(recentChainData.isPreGenesis()).thenReturn(false);
    when(recentChainData.isPreForkChoice()).thenReturn(true);
    final SafeFuture<Optional<BeaconState>> future =
        factory.defaultStateSelector(ZERO.toString()).getState();
    assertThat(future.get()).isEmpty();
  }
"
"  @Test
  public void defaultBlockSelector_shouldThrowBadRequestForBadHexState() {
    assertThrows(BadRequestException.class, () -> factory.defaultStateSelector(""0xzz""));
  }
"
"  @TestTemplate
  public void validatorsResponseShouldConformToDefaults(SpecContext ctx) {
    BeaconState beaconState = ctx.getDataStructureUtil().randomBeaconState();
    SszList<Validator> validatorList = beaconState.getValidators();
    BeaconValidators response = new BeaconValidators(beaconState, FAR_FUTURE_EPOCH);
    assertThat(response.total_size).isEqualTo(beaconState.getValidators().size());
    assertThat(response.validators.size())
        .isEqualTo(Math.min(validatorList.size(), PAGE_SIZE_DEFAULT));
    int expectedNextPageToken =
        validatorList.size() < PAGE_SIZE_DEFAULT ? 0 : PAGE_TOKEN_DEFAULT + 1;
    assertThat(response.next_page_token).isEqualTo(expectedNextPageToken);
    assertThat(response.validators.get(0).validator.activation_eligibility_epoch)
        .isEqualToComparingFieldByField(validatorList.get(0).getActivation_eligibility_epoch());
    assertThat(response.validators.get(0).validator_index).isEqualTo(0);
  }
"
"    @Test
    public void testSuperClass() {
        assertThat(classNode.superName)
                .doesNotStartWith(SHADED_PACKAGE_PATH);
    }
"
"    @Test
    public void testInterfaces() {
        assertThat(classNode.interfaces)
                .allSatisfy(it -> assertThat(it).doesNotStartWith(SHADED_PACKAGE_PATH));
    }
"
"    @Test
    public void testMethodReturnTypes() {
        assertThat(classNode.methods)
                .filteredOn(it -> (it.access & (Opcodes.ACC_PUBLIC | Opcodes.ACC_PROTECTED)) != 0)
                .allSatisfy(it -> assertThat(Type.getReturnType(it.desc).getClassName()).doesNotStartWith(SHADED_PACKAGE));
    }
"
"    @Test
    public void testMethodArguments() {
        assertThat(classNode.methods)
                .filteredOn(it -> (it.access & (Opcodes.ACC_PUBLIC | Opcodes.ACC_PROTECTED)) != 0)
                .allSatisfy(method -> assertThat(Arrays.asList(Type.getArgumentTypes(method.desc)))
                        .extracting(Type::getClassName)
                        .allSatisfy(it -> assertThat(it).doesNotStartWith(SHADED_PACKAGE))
                );
    }
"
"    @Test
    public void testFields() {
        assertThat(classNode.fields)
                .filteredOn(it -> (it.access & (Opcodes.ACC_PUBLIC | Opcodes.ACC_PROTECTED)) != 0)
                .allSatisfy(it -> assertThat(Type.getType(it.desc).getClassName())
                        .doesNotStartWith(SHADED_PACKAGE)
                );
    }
"
"    @Test
    public void testPackages() throws Exception {
        assertThatFileList(root).containsOnly(
                ""docker-java.properties"",
                ""org"",
                ""META-INF"",
                ""com""
        );

        assertThatFileList(root.resolve(""org"")).containsOnly(
                ""testcontainers""
        );

        assertThatFileList(root.resolve(""com"")).containsOnly(
                ""github""
        );

        assertThatFileList(root.resolve(""com"").resolve(""github"")).containsOnly(
                ""dockerjava""
        );
    }
"
"    @Test
    public void testMetaInf() throws Exception {
        assertThatFileList(root.resolve(""META-INF"")).containsOnly(
                ""MANIFEST.MF"",
                ""services"",
                ""native""
        );

        assertThatFileList(root.resolve(""META-INF"").resolve(""native"")).containsOnly(
                ""liborg-testcontainers-shaded-netty-transport-native-epoll.so"",
                ""liborg-testcontainers-shaded-netty-transport-native-kqueue.jnilib""
        );
    }
"
"    @Test
    public void testMetaInfServices() throws Exception {
        assertThatFileList(root.resolve(""META-INF"").resolve(""services""))
                .allMatch(it -> it.startsWith(""org.testcontainers.""));
    }
"
"    @Test
    public void testForExistingNames() {
        LicenseAcceptance.assertLicenseAccepted(""a"");
        LicenseAcceptance.assertLicenseAccepted(""b"");
    }
"
"    @Test(expected = IllegalStateException.class)
    public void testForMissingNames() {
        LicenseAcceptance.assertLicenseAccepted(""c"");
    }
"
"    @Test
    public void validNames() {
        testValid(""myname:latest"");
        testValid(""myname:latest"");
        testValid(""repo/my-name:1.0"");
        testValid(""repo.foo.com:1234/my-name:1.0"");
        testValid(""repo.foo.com/my-name:1.0"");
        testValid(""repo.foo.com:1234/repo_here/my-name:1.0"");
        testValid(""repo.foo.com:1234/repo-here/my-name@sha256:1234abcd1234abcd1234abcd1234abcd"");
        testValid(""repo.foo.com:1234/my-name@sha256:1234abcd1234abcd1234abcd1234abcd"");
        testValid(""1.2.3.4/my-name:1.0"");
        testValid(""1.2.3.4:1234/my-name:1.0"");
        testValid(""1.2.3.4/repo-here/my-name:1.0"");
        testValid(""1.2.3.4:1234/repo-here/my-name:1.0"");
    }
"
"    @Test
    public void invalidNames() {
        testInvalid(""myname"");
        testInvalid("":latest"");
        testInvalid(""/myname:latest"");
        testInvalid(""/myname@sha256:latest"");
        testInvalid(""/myname@sha256:gggggggggggggggggggggggggggggggg"");
        testInvalid(""repo:notaport/myname:latest"");
    }
"
"    @Test
    public void testLazyness() throws Exception {
        AtomicInteger counter = new AtomicInteger();

        Future<Integer> lazyFuture = new LazyFuture<Integer>() {
            @Override
            protected Integer resolve() {
                return counter.incrementAndGet();
            }
        };

        assertEquals(""No resolve() invocations before get()"", 0, counter.get());
        assertEquals(""get() call returns proper result"", 1, lazyFuture.get());
        assertEquals(""resolve() was called only once after single get() call"", 1, counter.get());

        counter.incrementAndGet();
        assertEquals(""result of resolve() must be cached"", 1, lazyFuture.get());
    }
"
"    @Test(timeout = 5_000)
    public void timeoutWorks() throws Exception {
        Future<Void> lazyFuture = new LazyFuture<Void>() {
            @Override
            @SneakyThrows(InterruptedException.class)
            protected Void resolve() {
                TimeUnit.MINUTES.sleep(1);
                return null;
            }
        };

        assertThrows(""Should timeout"", TimeoutException.class, () -> lazyFuture.get(10, TimeUnit.MILLISECONDS));
        pass(""timeout works"");
    }
"
"    @Test(timeout = 5_000)
    public void testThreadSafety() throws Exception {
        final int numOfThreads = 3;
        CountDownLatch latch = new CountDownLatch(numOfThreads);
        AtomicInteger counter = new AtomicInteger();

        Future<Integer> lazyFuture = new LazyFuture<Integer>() {
            @Override
            @SneakyThrows(InterruptedException.class)
            protected Integer resolve() {
                latch.await();
                return counter.incrementAndGet();
            }
        };

        Future<List<Integer>> task = new ForkJoinPool(numOfThreads).submit(() -> {
            return IntStream.rangeClosed(1, numOfThreads).parallel().mapToObj(i -> Futures.getUnchecked(lazyFuture)).collect(toList());
        });

        while (latch.getCount() > 0) {
            latch.countDown();
        }

        assertEquals(""All threads receives the same result"", Collections.nCopies(numOfThreads, 1), task.get());
    }
"
"    @Test
    public void testRunning() throws Exception {
        assertTrue(DockerStatus.isContainerRunning(running, minimumDuration, now));
        assertTrue(DockerStatus.isContainerRunning(runningVariant, minimumDuration, now));
        assertFalse(DockerStatus.isContainerRunning(shortRunning, minimumDuration, now));
        assertFalse(DockerStatus.isContainerRunning(created, minimumDuration, now));
        assertFalse(DockerStatus.isContainerRunning(createdVariant, minimumDuration, now));
        assertFalse(DockerStatus.isContainerRunning(exited, minimumDuration, now));
        assertFalse(DockerStatus.isContainerRunning(paused, minimumDuration, now));
    }
"
"    @Test
    public void testStopped() throws Exception {
        assertFalse(DockerStatus.isContainerStopped(running));
        assertFalse(DockerStatus.isContainerStopped(runningVariant));
        assertFalse(DockerStatus.isContainerStopped(shortRunning));
        assertFalse(DockerStatus.isContainerStopped(created));
        assertFalse(DockerStatus.isContainerStopped(createdVariant));
        assertTrue(DockerStatus.isContainerStopped(exited));
        assertFalse(DockerStatus.isContainerStopped(paused));
    }
"
"    @Test
    public void testCompareVersionGreaterThanSameMajor() {
        assertTrue(""1.22 > 1.20"", new ComparableVersion(""1.22"").compareTo(new ComparableVersion(""1.20"")) == 1);
    }
"
"    @Test
    public void testCompareVersionEqual() {
        assertTrue(""1.20 == 1.20"", new ComparableVersion(""1.20"").compareTo(new ComparableVersion(""1.20"")) == 0);
    }
"
"    @Test
    public void testCompareVersionGreaterThan() {
        assertTrue(""2.10 > 1.20"", new ComparableVersion(""2.10"").compareTo(new ComparableVersion(""1.20"")) == 1);
    }
"
"    @Test
    public void testCompareVersionIgnoresExcessLength() {
        assertTrue(""1.20 == 1.20.3"", new ComparableVersion(""1.20"").compareTo(new ComparableVersion(""1.20.3"")) == 0);
    }
"
"    @Test
    public void forClasspathResource() throws Exception {
        final MountableFile mountableFile = MountableFile.forClasspathResource(""mappable-resource/test-resource.txt"");

        performChecks(mountableFile);
    }
"
"    @Test
    public void forClasspathResourceWithAbsolutePath() throws Exception {
        final MountableFile mountableFile = MountableFile.forClasspathResource(""/mappable-resource/test-resource.txt"");

        performChecks(mountableFile);
    }
"
"    @Test
    public void forClasspathResourceFromJar() throws Exception {
        final MountableFile mountableFile = MountableFile.forClasspathResource(""META-INF/dummy_unique_name.txt"");

        performChecks(mountableFile);
    }
"
"    @Test
    public void forClasspathResourceFromJarWithAbsolutePath() throws Exception {
        final MountableFile mountableFile = MountableFile.forClasspathResource(""/META-INF/dummy_unique_name.txt"");

        performChecks(mountableFile);
    }
"
"    @Test
    public void forHostPath() throws Exception {
        final Path file = createTempFile(""somepath"");
        final MountableFile mountableFile = MountableFile.forHostPath(file.toString());

        performChecks(mountableFile);
    }
"
"    @Test
    public void forHostPathWithSpaces() throws Exception {
        final Path file = createTempFile(""some path"");
        final MountableFile mountableFile = MountableFile.forHostPath(file.toString());

        performChecks(mountableFile);

        assertTrue(""The resolved path contains the original space"", mountableFile.getResolvedPath().contains("" ""));
        assertFalse(""The resolved path does not contain an escaped space"", mountableFile.getResolvedPath().contains(""\\ ""));
    }
"
"    @Test
    public void forHostPathWithPlus() throws Exception {
        final Path file = createTempFile(""some+path"");
        final MountableFile mountableFile = MountableFile.forHostPath(file.toString());

        performChecks(mountableFile);

        assertTrue(""The resolved path contains the original space"", mountableFile.getResolvedPath().contains(""+""));
        assertFalse(""The resolved path does not contain an escaped space"", mountableFile.getResolvedPath().contains("" ""));
    }
"
"    @Test
    public void forClasspathResourceWithPermission() throws Exception {
        final MountableFile mountableFile = MountableFile.forClasspathResource(""mappable-resource/test-resource.txt"",
                TEST_FILE_MODE);

        performChecks(mountableFile);
        assertEquals(""Valid file mode."", BASE_FILE_MODE | TEST_FILE_MODE, mountableFile.getFileMode());
    }
"
"    @Test
    public void forHostFilePathWithPermission() throws Exception {
        final Path file = createTempFile(""somepath"");
        final MountableFile mountableFile = MountableFile.forHostPath(file.toString(), TEST_FILE_MODE);
        performChecks(mountableFile);
        assertEquals(""Valid file mode."", BASE_FILE_MODE | TEST_FILE_MODE, mountableFile.getFileMode());
    }
"
"    @Test
    public void forHostDirPathWithPermission() throws Exception {
        final Path dir = createTempDir();
        final MountableFile mountableFile = MountableFile.forHostPath(dir.toString(), TEST_FILE_MODE);
        performChecks(mountableFile);
        assertEquals(""Valid dir mode."", BASE_DIR_MODE | TEST_FILE_MODE, mountableFile.getFileMode());
    }
"
"    @Test
    public void simpleRecursiveFileTest() throws TimeoutException {

        WaitingConsumer wait = new WaitingConsumer();

        final ToStringConsumer toString = new ToStringConsumer();

        GenericContainer container = new GenericContainer(
                new ImageFromDockerfile()
                        .withDockerfileFromBuilder(builder ->
                                builder.from(""alpine:3.3"")
                                        .copy(""/tmp/foo"", ""/foo"")
                                        .cmd(""cat /foo/src/test/resources/test-recursive-file.txt"")
                                        .build()
                        ).withFileFromFile(""/tmp/foo"", new File(""."")))  // '.' is expected to be the project base directory, so all source code/resources should be copied in
                .withStartupCheckStrategy(new OneShotStartupCheckStrategy())
                .withLogConsumer(wait.andThen(toString));

        container.start();
        wait.waitUntilEnd(60, TimeUnit.SECONDS);

        final String results = toString.toUtf8String();

        assertTrue(""The container has a file that was copied in via a recursive copy"", results.contains(""Used for DirectoryTarResourceTest""));
    }
"
"    @Test
    public void simpleRecursiveFileWithPermissionTest() throws TimeoutException {

        WaitingConsumer wait = new WaitingConsumer();

        final ToStringConsumer toString = new ToStringConsumer();

        GenericContainer container = new GenericContainer(
                new ImageFromDockerfile()
                        .withDockerfileFromBuilder(builder ->
                                builder.from(""alpine:3.3"")
                                        .copy(""/tmp/foo"", ""/foo"")
                                        .cmd(""ls"", ""-al"", ""/"")
                                        .build()
                        ).withFileFromFile(""/tmp/foo"", new File(""/mappable-resource/test-resource.txt""),
                        0754))
                .withStartupCheckStrategy(new OneShotStartupCheckStrategy())
                .withLogConsumer(wait.andThen(toString));

        container.start();
        wait.waitUntilEnd(60, TimeUnit.SECONDS);

        String listing = toString.toUtf8String();

        assertThat(""Listing shows that file is copied with mode requested."",
                Arrays.asList(listing.split(""\\n"")),
                exactlyNItems(1, allOf(containsString(""-rwxr-xr--""), containsString(""foo""))));
    }
"
"    @Test
    public void simpleRecursiveClasspathResourceTest() throws TimeoutException {
        // This test combines the copying of classpath resources from JAR files with the recursive TAR approach, to allow JARed classpath resources to be copied in to an image

        WaitingConsumer wait = new WaitingConsumer();

        final ToStringConsumer toString = new ToStringConsumer();

        GenericContainer container = new GenericContainer(
                new ImageFromDockerfile()
                        .withDockerfileFromBuilder(builder ->
                                builder.from(""alpine:3.3"")
                                        .copy(""/tmp/foo"", ""/foo"")
                                        .cmd(""ls -lRt /foo"")
                                        .build()
                        ).withFileFromClasspath(""/tmp/foo"", ""/recursive/dir""))          // here we use /org/junit as a directory that really should exist on the classpath
                .withStartupCheckStrategy(new OneShotStartupCheckStrategy())
                .withLogConsumer(wait.andThen(toString));

        container.start();
        wait.waitUntilEnd(60, TimeUnit.SECONDS);

        final String results = toString.toUtf8String();

        // ExternalResource.class is known to exist in a subdirectory of /org/junit so should be successfully copied in
        assertTrue(""The container has a file that was copied in via a recursive copy from a JAR resource"", results.contains(""content.txt""));
    }
"
"    @Test
    public void testWaitOnListeningPort() {
        final DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/compose-test.yml""))
            .withExposedService(""redis_1"", REDIS_PORT, Wait.forListeningPort());

        try {
            environment.starting(Description.createTestDescription(Object.class, ""name""));
            VisibleAssertions.pass(""Docker compose should start after waiting for listening port"");
        } catch (RuntimeException e) {
            VisibleAssertions.fail(""Docker compose should start after waiting for listening port with failed with: "" + e);
        }
    }
"
"    @Test
    public void testWaitOnMultipleStrategiesPassing() {
        final DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/compose-test.yml""))
            .withExposedService(""redis_1"", REDIS_PORT, Wait.forListeningPort())
            .withExposedService(""db_1"", 3306, Wait.forLogMessage("".*ready for connections.*\\s"", 1))
            .withTailChildContainers(true);

        try {
            environment.starting(Description.createTestDescription(Object.class, ""name""));
            VisibleAssertions.pass(""Docker compose should start after waiting for listening port"");
        } catch (RuntimeException e) {
            VisibleAssertions.fail(""Docker compose should start after waiting for listening port with failed with: "" + e);
        }
    }
"
"    @Test
    public void testWaitingFails() {
        final DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/compose-test.yml""))
            .withExposedService(""redis_1"", REDIS_PORT, Wait.forHttp(""/test"").withStartupTimeout(Duration.ofSeconds(10)));
        VisibleAssertions.assertThrows(""waiting on an invalid http path times out"",
            RuntimeException.class,
            () -> environment.starting(Description.createTestDescription(Object.class, ""name"")));
    }
"
"    @Test
    public void testWaitOnOneOfMultipleStrategiesFailing() {
        final DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/compose-test.yml""))
            .withExposedService(""redis_1"", REDIS_PORT, Wait.forListeningPort().withStartupTimeout(Duration.ofSeconds(10)))
            .waitingFor(""db_1"", Wait.forLogMessage("".*test test test.*\\s"", 1).withStartupTimeout(Duration.ofSeconds(10)))
            .withTailChildContainers(true);

        VisibleAssertions.assertThrows(""waiting on one failing strategy to time out"",
            RuntimeException.class,
            () -> environment.starting(Description.createTestDescription(Object.class, ""name"")));
    }
"
"    @Test
    public void checkOutput() {
        String listing = toStringConsumer.toUtf8String();

        assertTrue(""Directory listing contains expected /etc content"", listing.contains(""hostname""));
        assertTrue(""Directory listing contains expected /etc content"", listing.contains(""init.d""));
        assertTrue(""Directory listing contains expected /etc content"", listing.contains(""passwd""));
    }
"
"    @Test(timeout = 60_000L)
    public void pullingNonExistentImageFailsGracefully() {

        assertThrows(""Pulling a nonexistent container will cause an exception to be thrown"",
                ContainerFetchException.class, () -> {
                    return new GenericContainer(""richnorth/nonexistent:latest"");
                });
    }
"
"    @Test
    public void simpleTest() {
        Jedis jedis = new Jedis(getEnvironment().getServiceHost(""redis_1"", REDIS_PORT), getEnvironment().getServicePort(""redis_1"", REDIS_PORT));

        jedis.incr(""test"");
        jedis.incr(""test"");
        jedis.incr(""test"");

        assertEquals(""A redis instance defined in compose can be used in isolation"", ""3"", jedis.get(""test""));
    }
"
"    @Test
    public void secondTest() {
        // used in manual checking for cleanup in between tests
        Jedis jedis = new Jedis(getEnvironment().getServiceHost(""redis_1"", REDIS_PORT), getEnvironment().getServicePort(""redis_1"", REDIS_PORT));

        jedis.incr(""test"");
        jedis.incr(""test"");
        jedis.incr(""test"");

        assertEquals(""Tests use fresh container instances"", ""3"", jedis.get(""test""));
        // if these end up using the same container one of the test methods will fail.
        // However, @Rule creates a separate DockerComposeContainer instance per test, so this just shouldn't happen
    }
"
"    @Test
    public void simpleTest() {

        for (int i = 0; i < 3; i++) {
            clients[i].incr(""somekey"");

            assertEquals(""Each redis instance is separate"", ""1"", clients[i].get(""somekey""));
        }
    }
"
"    @Test
    public void testGetServicePort() {
        int serviceWithInstancePort = environment.getServicePort(""redis_1"", REDIS_PORT);
        assertNotNull(""Port is set for service with instance number"", serviceWithInstancePort);
        int serviceWithoutInstancePort = environment.getServicePort(""redis"", REDIS_PORT);
        assertNotNull(""Port is set for service with instance number"", serviceWithoutInstancePort);
        assertEquals(""Service ports are the same"", serviceWithInstancePort, serviceWithoutInstancePort);
    }
"
"    @Test
    public void testFetchStdout() throws TimeoutException {

        WaitingConsumer consumer = new WaitingConsumer();

        container.followOutput(consumer, STDOUT);

        consumer.waitUntil(frame -> frame.getType() == STDOUT && frame.getUtf8String().contains(""seq=2""),
                30, TimeUnit.SECONDS);
    }
"
"    @Test
    public void testFetchStdoutWithTimeout() throws TimeoutException {

        WaitingConsumer consumer = new WaitingConsumer();

        container.followOutput(consumer, STDOUT);

        assertThrows(""a TimeoutException should be thrown"", TimeoutException.class, () -> {
            consumer.waitUntil(frame -> frame.getType() == STDOUT && frame.getUtf8String().contains(""seq=5""),
                    2, TimeUnit.SECONDS);
            return true;
        });
    }
"
"    @Test
    public void testFetchStdoutWithNoLimit() throws TimeoutException {

        WaitingConsumer consumer = new WaitingConsumer();

        container.followOutput(consumer, STDOUT);

        consumer.waitUntil(frame -> frame.getType() == STDOUT && frame.getUtf8String().contains(""seq=2""));
    }
"
"    @Test
    public void testLogConsumer() throws TimeoutException {

        WaitingConsumer waitingConsumer = new WaitingConsumer();
        Slf4jLogConsumer logConsumer = new Slf4jLogConsumer(LOGGER);

        Consumer<OutputFrame> composedConsumer = logConsumer.andThen(waitingConsumer);
        container.followOutput(composedConsumer);

        waitingConsumer.waitUntil(frame -> frame.getType() == STDOUT && frame.getUtf8String().contains(""seq=2""));
    }
"
"    @Test
    public void testToStringConsumer() throws TimeoutException {

        WaitingConsumer waitingConsumer = new WaitingConsumer();
        ToStringConsumer toStringConsumer = new ToStringConsumer();

        Consumer<OutputFrame> composedConsumer = toStringConsumer.andThen(waitingConsumer);
        container.followOutput(composedConsumer);

        waitingConsumer.waitUntilEnd(30, TimeUnit.SECONDS);

        String utf8String = toStringConsumer.toUtf8String();
        assertTrue(""the expected first value was found"", utf8String.contains(""seq=1""));
        assertTrue(""the expected last value was found"", utf8String.contains(""seq=4""));
        assertFalse(""a non-expected value was found"", utf8String.contains(""seq=42""));
    }
"
"    @Test
    public void testFixedHostPortMapping() throws IOException {
        // first find a free port on the docker host that will work for testing
        GenericContainer portDiscoveryRedis = new GenericContainer(""redis:3.0.2"").withExposedPorts(REDIS_PORT);
        portDiscoveryRedis.start();
        Integer freePort = portDiscoveryRedis.getMappedPort(REDIS_PORT);
        portDiscoveryRedis.stop();


        // Set up a FixedHostPortGenericContainer as if this were a @Rule
        FixedHostPortGenericContainer redis = new FixedHostPortGenericContainer(""redis:3.0.2"").withFixedExposedPort(freePort, REDIS_PORT);
        redis.start();

//        Config redisConfig = new Config();
//        redisConfig.useSingleServer().setAddress(redis.getContainerIpAddress() + "":"" + freePort);
//        Redisson redisson = Redisson.create(redisConfig);
//
//        redisson.getBucket(""test"").set(""foo"");
//
//        assertEquals(""The bucket content was successfully set"", ""foo"", redisson.getBucket(""test"").get());
//        assertEquals(""The container returns the fixed port from getMappedPort(...)"", freePort, redis.getMappedPort(REDIS_PORT));
    }
"
"    @Test(timeout = 30_000)
    public void testEnvVar() throws IOException {
        BufferedReader br = Unreliables.retryUntilSuccess(10, TimeUnit.SECONDS, () -> {
            Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS);

            Socket socket = new Socket(compose.getServiceHost(""alpine_1"", 3000), compose.getServicePort(""alpine_1"", 3000));
            return new BufferedReader(new InputStreamReader(socket.getInputStream()));
        });

        Unreliables.retryUntilTrue(10, TimeUnit.SECONDS, () -> {
            while (br.ready()) {
                String line = br.readLine();
                if (line.contains(DOCKER_COMPOSE_OVERRIDE_TEST_OVERRIDE_ENV)) {
                    pass(""Mapped environment variable was found"");
                    return true;
                }
            }
            info(""Mapped environment variable was not found yet - process probably not ready"");
            Uninterruptibles.sleepUninterruptibly(100, TimeUnit.MILLISECONDS);
            return false;
        });

    }
"
"    @Test
    public void testContainerInstanceProperties() {
        final ContainerState container = waitStrategy.getContainer();

        //check environment variable was set
        assertThat(""Environment variable set correctly"", Arrays.asList(Objects.requireNonNull(container.getContainerInfo()
            .getConfig().getEnv())), hasItem(""bar=bar""));

        //check other container properties
        assertNotNull(""Container id is not null"", container.getContainerId());
        assertNotNull(""Port mapped"", container.getMappedPort(3000));
        assertThat(""Exposed Ports"", container.getExposedPorts(), hasItem(3000));

    }
"
"    @Test(timeout = 30_000)
    public void testEnvVar() throws IOException {
        BufferedReader br = Unreliables.retryUntilSuccess(10, TimeUnit.SECONDS, () -> {
            Uninterruptibles.sleepUninterruptibly(1, TimeUnit.SECONDS);

            Socket socket = new Socket(compose.getServiceHost(""alpine_1"", 3000), compose.getServicePort(""alpine_1"", 3000));
            return new BufferedReader(new InputStreamReader(socket.getInputStream()));
        });

        Unreliables.retryUntilTrue(10, TimeUnit.SECONDS, () -> {
            while (br.ready()) {
                String line = br.readLine();
                if (line.contains(DOCKER_COMPOSE_OVERRIDE_TEST_BASE_ENV)) {
                    pass(""Mapped environment variable was found"");
                    return true;
                }
            }
            info(""Mapped environment variable was not found yet - process probably not ready"");
            Uninterruptibles.sleepUninterruptibly(100, TimeUnit.MILLISECONDS);
            return false;
        });

    }
"
"    @Test
    public void testNoNetworkContainer() throws TimeoutException {
        String output = getContainerOutput(noNetwork);

        assertTrue(""'none' network causes a network access error"", output.contains(""bad address""));
    }
"
"    @Test
    public void testHostNetworkContainer() throws TimeoutException {
        String output = getContainerOutput(hostNetwork);

        assertTrue(""'host' network can access the internet"", output.contains(""seq=1""));
    }
"
"    @Test
    public void testBridgedNetworkContainer() throws TimeoutException {
        String output = getContainerOutput(bridgedNetwork);

        assertTrue(""'bridge' network can access the internet"", output.contains(""seq=1""));
    }
"
"    @Test
    public void testLogConsumer() throws TimeoutException {
        WaitingConsumer logConsumer = new WaitingConsumer();
        DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/v2-compose-test.yml""))
            .withExposedService(""redis_1"", 6379)
            .withLogConsumer(""redis_1"", logConsumer);

        try {
            environment.starting(Description.EMPTY);
            logConsumer.waitUntil(frame -> frame.getType() == STDOUT && frame.getUtf8String().contains(""Ready to accept connections""), 5, TimeUnit.SECONDS);
        } finally {
            environment.finished(Description.EMPTY);
        }
    }
"
"    @Test
    public void simpleDockerfileWorks() {
        ImageFromDockerfile image = new ImageFromDockerfile()
                .withFileFromString(""folder/someFile.txt"", ""hello"")
                .withFileFromClasspath(""test.txt"", ""mappable-resource/test-resource.txt"")
                .withFileFromClasspath(""Dockerfile"", ""mappable-dockerfile/Dockerfile"");

        verifyImage(image);
    }
"
"    @Test
    public void customizableImage() {
        ImageFromDockerfile image = new ImageFromDockerfile() {
            @Override
            protected void configure(BuildImageCmd buildImageCmd) {
                super.configure(buildImageCmd);

                List<String> dockerfile = Arrays.asList(
                        ""FROM alpine:3.2"",
                        ""RUN echo 'hello from Docker build process'"",
                        ""CMD yes""
                );
                withFileFromString(""Dockerfile"", String.join(""\n"", dockerfile));

                buildImageCmd.withNoCache(true);
            }
        };

        verifyImage(image);
    }
"
"    @Test
    public void dockerfileBuilderWorks() {
        ImageFromDockerfile image = new ImageFromDockerfile()
                .withFileFromClasspath(""test.txt"", ""mappable-resource/test-resource.txt"")
                .withFileFromString(""folder/someFile.txt"", ""hello"")
                .withDockerfileFromBuilder(builder -> builder
                        .from(""alpine:3.2"")
                        .workDir(""/app"")
                        .add(""test.txt"", ""test file.txt"")
                        .run(""ls"", ""-la"", ""/app/test file.txt"")
                        .copy(""folder/someFile.txt"", ""/someFile.txt"")
                        .expose(80, 8080)
                        .cmd(""while true; do cat /someFile.txt | nc -l -p 80; done"")
                );

        verifyImage(image);
    }
"
"    @Test
    public void filePermissions() throws TimeoutException {

        WaitingConsumer consumer = new WaitingConsumer();

        ImageFromDockerfile image = new ImageFromDockerfile()
                .withFileFromTransferable(""/someFile.txt"", new Transferable() {
                    @Override
                    public long getSize() {
                        return 0;
                    }
"
"//    @Test
//    public void simpleRedisTest() {
//        String ipAddress = redis.getContainerIpAddress();
//        Integer port = redis.getMappedPort(REDIS_PORT);
//
//        // Use Redisson to obtain a List that is backed by Redis
//        Config redisConfig = new Config();
//        redisConfig.useSingleServer().setAddress(ipAddress + "":"" + port);
//
//        Redisson redisson = Redisson.create(redisConfig);
//
//        List<String> testList = redisson.getList(""test"");
//        testList.add(""foo"");
//        testList.add(""bar"");
//        testList.add(""baz"");
//
//        List<String> testList2 = redisson.getList(""test"");
//        assertEquals(""The list contains the expected number of items (redis is working!)"", 3, testList2.size());
//        assertTrue(""The list contains an item that was put in (redis is working!)"", testList2.contains(""foo""));
//        assertTrue(""The list contains an item that was put in (redis is working!)"", testList2.contains(""bar""));
//        assertTrue(""The list contains an item that was put in (redis is working!)"", testList2.contains(""baz""));
//    }
"
"    @Test
    public void testIsRunning() {
        try (GenericContainer container = new GenericContainer().withCommand(""top"")) {
            assertFalse(""Container is not started and not running"", container.isRunning());
            container.start();
            assertTrue(""Container is started and running"", container.isRunning());
        }
    }
"
"    @Test
    public void simpleRabbitMqTest() throws IOException, TimeoutException {
        ConnectionFactory factory = new ConnectionFactory();
        factory.setHost(rabbitMq.getContainerIpAddress());
        factory.setPort(rabbitMq.getMappedPort(RABBITMQ_PORT));
        Connection connection = factory.newConnection();

        Channel channel = connection.createChannel();
        channel.exchangeDeclare(RABBIQMQ_TEST_EXCHANGE, ""direct"", true);
        String queueName = channel.queueDeclare().getQueue();
        channel.queueBind(queueName, RABBIQMQ_TEST_EXCHANGE, RABBITMQ_TEST_ROUTING_KEY);

        // Set up a consumer on the queue
        final boolean[] messageWasReceived = new boolean[1];
        channel.basicConsume(queueName, false, new DefaultConsumer(channel) {
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
                messageWasReceived[0] = Arrays.equals(body, RABBITMQ_TEST_MESSAGE.getBytes());
            }
"
"    @Test
    public void simpleMongoDbTest() {
        MongoClient mongoClient = new MongoClient(mongo.getContainerIpAddress(), mongo.getMappedPort(MONGO_PORT));
        MongoDatabase database = mongoClient.getDatabase(""test"");
        MongoCollection<Document> collection = database.getCollection(""testCollection"");

        Document doc = new Document(""name"", ""foo"")
                .append(""value"", 1);
        collection.insertOne(doc);

        Document doc2 = collection.find(new Document(""name"", ""foo"")).first();
        assertEquals(""A record can be inserted into and retrieved from MongoDB"", 1, doc2.get(""value""));
    }
"
"    @Test
    public void environmentAndCustomCommandTest() throws IOException {
        String line = getReaderForContainerPort80(alpineEnvVar).readLine();

        assertEquals(""An environment variable can be passed into a command"", ""42"", line);
    }
"
"    @Test
    public void environmentFromMapTest() throws IOException {
        String line = getReaderForContainerPort80(alpineEnvVarFromMap).readLine();

        assertEquals(""Environment variables can be passed into a command from a map"", ""42 and 50"", line);
    }
"
"    @Test
    public void customLabelTest() {
        try (final GenericContainer alpineCustomLabel = new GenericContainer(""alpine:3.2"")
            .withLabel(""our.custom"", ""label"")
            .withCommand(""top"")) {

            alpineCustomLabel.start();

            Map<String, String> labels = alpineCustomLabel.getCurrentContainerInfo().getConfig().getLabels();
            assertTrue(""org.testcontainers label is present"", labels.containsKey(""org.testcontainers""));
            assertTrue(""our.custom label is present"", labels.containsKey(""our.custom""));
            assertEquals(""our.custom label value is label"", labels.get(""our.custom""), ""label"");
        }
    }
"
"    @Test
    public void exceptionThrownWhenTryingToOverrideTestcontainersLabels() {
        assertThrows(""When trying to overwrite an 'org.testcontainers' label, withLabel() throws an exception"",
            IllegalArgumentException.class,
            () -> {
                new GenericContainer(""alpine:3.2"")
                    .withLabel(""org.testcontainers.foo"", ""false"");
            }
        );
    }
"
"    @Test
    public void customClasspathResourceMappingTest() throws IOException {
        // Note: This functionality doesn't work if you are running your build inside a Docker container;
        // in that case this test will fail.
        String line = getReaderForContainerPort80(alpineClasspathResource).readLine();

        assertEquals(""Resource on the classpath can be mapped using calls to withClasspathResourceMapping"", ""FOOBAR"", line);
    }
"
"    @Test
    public void customClasspathResourceMappingWithSelinuxTest() throws IOException {
        String line = getReaderForContainerPort80(alpineClasspathResourceSelinux).readLine();
        assertEquals(""Resource on the classpath can be mapped using calls to withClasspathResourceMappingSelinux"", ""FOOBAR"", line);
    }
"
"    @Test
    public void exceptionThrownWhenMappedPortNotFound() throws IOException {
        assertThrows(""When the requested port is not mapped, getMappedPort() throws an exception"",
                IllegalArgumentException.class,
                () -> {
                    return redis.getMappedPort(666);
                });
    }
"
"    @Test @Ignore //TODO investigate intermittent failures
    public void failFastWhenContainerHaltsImmediately() throws Exception {

        long startingTimeMs = System.currentTimeMillis();
        final GenericContainer failsImmediately = new GenericContainer(""alpine:3.2"")
              .withCommand(""/bin/sh"", ""-c"", ""return false"")
              .withMinimumRunningDuration(Duration.ofMillis(100));

        try {
            assertThrows(
                  ""When we start a container that halts immediately, an exception is thrown"",
                  RetryCountExceededException.class,
                  () -> {
                      failsImmediately.start();
                      return null;
                  });

            // Check how long it took, to verify that we ARE bailing out early.
            // Want to strike a balance here; too short and this test will fail intermittently
            // on slow systems and/or due to GC variation, too long and we won't properly test
            // what we're intending to test.
            int allowedSecondsToFailure =
                GenericContainer.CONTAINER_RUNNING_TIMEOUT_SEC / 2;
            long completedTimeMs = System.currentTimeMillis();
            assertTrue(""container should not take long to start up"",
                  completedTimeMs - startingTimeMs < 1000L * allowedSecondsToFailure);
        } finally {
            failsImmediately.stop();
        }
    }
"
"    @Test
    public void testExecInContainer() throws Exception {

        // The older ""lxc"" execution driver doesn't support ""exec"". At the time of writing (2016/03/29),
        // that's the case for CircleCI.
        // Once they resolve the issue, this clause can be removed.
        Assume.assumeTrue(TestEnvironment.dockerExecutionDriverSupportsExec());

        final GenericContainer.ExecResult result = redis.execInContainer(""redis-cli"", ""role"");
        assertTrue(""Output for \""redis-cli role\"" command should start with \""master\"""", result.getStdout().startsWith(""master""));
        assertEquals(""Stderr for \""redis-cli role\"" command should be empty"", """", result.getStderr());
        // We expect to reach this point for modern Docker versions.
    }
"
"    @Test
    public void extraHostTest() throws IOException {
        BufferedReader br = getReaderForContainerPort80(alpineExtrahost);

        // read hosts file from container
        StringBuffer hosts = new StringBuffer();
        String line = br.readLine();
        while (line != null) {
            hosts.append(line);
            hosts.append(""\n"");
            line = br.readLine();
        }

        Matcher matcher = Pattern.compile(""^192.168.1.10\\s.*somehost"", Pattern.MULTILINE).matcher(hosts.toString());
        assertTrue(""The hosts file of container contains extra host"", matcher.find());
    }
"
"    @Test
    public void createContainerCmdHookTest() {
        // Use random name to avoid the conflicts between the tests
        String randomName = Base58.randomString(5);
        try(
                GenericContainer container = new GenericContainer<>(""redis:3.0.2"")
                        .withCommand(""redis-server"", ""--help"")
                        .withCreateContainerCmdModifier(cmd -> cmd.withName(""overrideMe""))
                        // Preserves the order
                        .withCreateContainerCmdModifier(cmd -> cmd.withName(randomName))
                        // Allows to override pre-configured values by GenericContainer
                        .withCreateContainerCmdModifier(cmd -> cmd.withCmd(""redis-server"", ""--port"", ""6379""))
        ) {
            container.start();

            assertEquals(""Name is configured"", ""/"" + randomName, container.getContainerInfo().getName());
            assertEquals(""Command is configured"", ""[redis-server, --port, 6379]"", Arrays.toString(container.getContainerInfo().getConfig().getCmd()));
        }
    }
"
"    @Test
    public void copyToContainerTest() throws Exception {
        final File tempResultFolder = Files.createTempDir();

        try (final GenericContainer alpineCopyToContainer = new GenericContainer(""alpine:3.2"")
                    .withCommand(""top"")){

            alpineCopyToContainer.start();
            final MountableFile mountableFile = MountableFile.forClasspathResource(""test_copy_to_container.txt"");
            alpineCopyToContainer.copyFileToContainer(mountableFile, ""/home/"");
            alpineCopyToContainer.copyFileFromContainer(""/home/test_copy_to_container.txt"",
                    tempResultFolder.getAbsolutePath() + ""/test_copy_to_container.txt"");

            File expectedFile = new File(mountableFile.getResolvedPath());
            File actualFile = new File(tempResultFolder.getAbsolutePath() + ""/test_copy_to_container.txt"");
            assertTrue(""Files aren't same "", FileUtils.contentEquals(expectedFile,actualFile));
        }
    }
"
"    @Test(expected = NotFoundException.class)
    public void copyFromContainerShouldFailBecauseNoFileTest() throws NotFoundException, IOException, InterruptedException {

        try (final GenericContainer alpineCopyToContainer = new GenericContainer(""alpine:3.2"")
                        .withCommand(""top"")) {
            alpineCopyToContainer.start();
            alpineCopyToContainer.copyFileFromContainer(""/home/test.txt"", ""src/test/resources/copy-from/test.txt"");
        }
    }
"
"    @Test
    public void shouldCopyFileFromContainerTest() throws IOException, InterruptedException {
        final File tempResultFolder = Files.createTempDir();

        try (final GenericContainer alpineCopyToContainer = new GenericContainer(""alpine:3.2"")
                .withCommand(""top"")) {

            alpineCopyToContainer.start();
            final MountableFile mountableFile = MountableFile.forClasspathResource(""test_copy_to_container.txt"");
            alpineCopyToContainer.copyFileToContainer(mountableFile, ""/home/"");
            alpineCopyToContainer.copyFileFromContainer(""/home/test_copy_to_container.txt"",
                    tempResultFolder.getAbsolutePath() + ""/test_copy_from_container.txt"");

            File expectedFile = new File(mountableFile.getResolvedPath());
            File actualFile = new File(tempResultFolder.getAbsolutePath() + ""/test_copy_from_container.txt"");
            assertTrue(""Files aren't same "", FileUtils.contentEquals(expectedFile,actualFile));
        }
    }
"
"    @Test
    public void addExposedPortAfterWithExposedPortsTest() {
        redis.addExposedPort(8987);
        assertThat(""Both ports should be exposed"", redis.getExposedPorts().size(), equalTo(2));
        assertTrue(""withExposedPort should be exposed"", redis.getExposedPorts().contains(REDIS_PORT));
        assertTrue(""addExposedPort should be exposed"", redis.getExposedPorts().contains(8987));
    }
"
"    @Test
    public void simpleDslTest() throws IOException {
        String address = String.format(""http://%s:%s"", dslContainer.getContainerIpAddress(), dslContainer.getMappedPort(80));

        CloseableHttpClient httpClient = HttpClientBuilder.create().build();
        HttpGet get = new HttpGet(address);

        try (CloseableHttpResponse response = httpClient.execute(get)) {
            assertEquals(""A container built from a dockerfile can run nginx as expected, and returns a good status code"",
                            200,
                            response.getStatusLine().getStatusCode());
            assertTrue(""A container built from a dockerfile can run nginx as expected, and returns an expected Server header"",
                            response.getHeaders(""Server"")[0].getValue().contains(""nginx""));
        }
    }
"
"    @Test
    public void simpleTest() throws Exception {
        final String release = container.execInContainer(""cat"", ""/etc/alpine-release"").getStdout();

        assertTrue(""/etc/alpine-release starts with "" + expectedVersion,
                release.startsWith(expectedVersion));
    }
"
"    @Test
    public void simpleTest() {

        DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/invalid-compose.yml""))
                    .withExposedService(""something"", 123);

        VisibleAssertions.assertThrows(""starting with an invalid docker-compose file throws an exception"",
                ContainerLaunchException.class,
                () -> {
                    environment.starting(Description.createTestDescription(Object.class, ""name""));
                });
    }
"
"    @Test
    public void testWaitUntilReadyWithSuccess() {
        waitUntilReadyAndSucceed(createShellCommand(""200 OK"", GOOD_RESPONSE_BODY));
    }
"
"    @Test
    public void testWaitUntilReadyWithUnauthorizedWithLambda() {
        waitUntilReadyAndSucceed(startContainerWithCommand(createShellCommand(""401 UNAUTHORIZED"", GOOD_RESPONSE_BODY),
            createHttpWaitStrategy(ready)
                .forStatusCodeMatching(it -> it >= 200 && it < 300 || it == 401)
        ));
    }
"
"    @Test
    public void testWaitUntilReadyWithManyStatusCodes() {
        waitUntilReadyAndSucceed(startContainerWithCommand(createShellCommand(""401 UNAUTHORIZED"", GOOD_RESPONSE_BODY),
            createHttpWaitStrategy(ready)
                .forStatusCode(300)
                .forStatusCode(401)
                .forStatusCode(500)
        ));
    }
"
"    @Test
    public void testWaitUntilReadyWithManyStatusCodesAndLambda() {
        waitUntilReadyAndSucceed(startContainerWithCommand(createShellCommand(""401 UNAUTHORIZED"", GOOD_RESPONSE_BODY),
            createHttpWaitStrategy(ready)
                .forStatusCode(300)
                .forStatusCode(500)
                .forStatusCodeMatching(it -> it == 401)
        ));
    }
"
"    @Test
    public void testWaitUntilReadyWithTimeoutAndWithManyStatusCodesAndLambda() {
        waitUntilReadyAndTimeout(startContainerWithCommand(createShellCommand(""401 UNAUTHORIZED"", GOOD_RESPONSE_BODY),
            createHttpWaitStrategy(ready)
                .forStatusCode(300)
                .forStatusCodeMatching(it -> it == 500)
        ));
    }
"
"    @Test
    public void testWaitUntilReadyWithTimeout() {
        waitUntilReadyAndTimeout(createShellCommand(""400 Bad Request"", GOOD_RESPONSE_BODY));
    }
"
"    @Test
    public void testWaitUntilReadyWithTimeoutAndBadResponseBody() {
        waitUntilReadyAndTimeout(createShellCommand(""200 OK"", ""Bad Response""));
    }
"
"    @Test
    public void testWaitUntilReadyWithSpecificPort() {
        waitUntilReadyAndSucceed(startContainerWithCommand(
            createShellCommand(""200 OK"", GOOD_RESPONSE_BODY, 9090),
            createHttpWaitStrategy(ready)
                .forPort(9090),
            7070, 8080, 9090
        ));
    }
"
"    @Test
    public void testWaitUntilReady_Success() {
        waitUntilReadyAndSucceed(""echo -e \"""" + READY_MESSAGE + ""\"";"" +
                ""echo -e \""foobar\"";"" +
                ""echo -e \"""" + READY_MESSAGE + ""\"";"" +
                ""sleep 300"");
    }
"
"    @Test
    public void testWaitUntilReady_Timeout() {
        waitUntilReadyAndTimeout(""echo -e \"""" + READY_MESSAGE + ""\"";"" +
                ""echo -e \""foobar\"";"" +
                ""sleep 300"");
    }
"
"    @Test
    public void testWaiting() {
        pass(""Container starts after waiting"");
    }
"
"    @Test
    public void multilineTest() throws Exception {
        ImmutableMap<String, String> pairs = ImmutableMap.<String, String>builder()
                .put(""line1"", ""1"")
                .put(""line2"", ""2"")
                .put(""line3"", ""3"")
                .build();

        assertStatement(new KeyValuesStatement(""TEST"", pairs));
    }
"
"    @Test
    public void keyWithSpacesTest() throws Exception {
        assertStatement(new KeyValuesStatement(""TEST"", Collections.singletonMap(""key with spaces"", ""1"")));
    }
"
"    @Test
    public void keyWithNewLinesTest() throws Exception {
        assertStatement(new KeyValuesStatement(""TEST"", Collections.singletonMap(""key\nwith\nnewlines"", ""1"")));
    }
"
"    @Test
    public void keyWithTabsTest() throws Exception {
        assertStatement(new KeyValuesStatement(""TEST"", Collections.singletonMap(""key\twith\ttab"", ""1"")));
    }
"
"    @Test
    public void valueIsEscapedTest() throws Exception {
        ImmutableMap<String, String> pairs = ImmutableMap.<String, String>builder()
                .put(""1"", ""value with spaces"")
                .put(""2"", ""value\nwith\nnewlines"")
                .put(""3"", ""value\twith\ttab"")
                .build();

        assertStatement(new KeyValuesStatement(""TEST"", pairs));
    }
"
"    @Test
    public void simpleTest() throws Exception {
        assertStatement(new MultiArgsStatement(""TEST"", ""a"", ""b"", ""c""));
    }
"
"  @Test
    public int compareTo(Version o) {
      return toString().compareTo(o.toString());
    }
"
"@TestInstance(TestInstance.Lifecycle.PER_CLASS)
    public void complete(int status) {
      complete(() -> status, null);
    }
"
"  @Test
  public void testSimple() {
    PortAllocator portAllocator = getPortAllocator((port) -> true);
    int next = PortAllocator.RANGE_MIN + 1;
    for (int i = 0; i < 1000; i++) {
      Assertions.assertEquals(next, portAllocator.getPort());
      next++;
      if (next % PortAllocator.CHUNK_SIZE == 0) {
        next++;
      }
    }
    Assertions.assertEquals(next, portAllocator.getPorts(10));
    Assertions.assertEquals(12101, portAllocator.getPorts(PortAllocator.CHUNK_SIZE - 1));
    assertThatThrownBy(() -> portAllocator.getPorts(PortAllocator.CHUNK_SIZE + 1))
        .isInstanceOf(IllegalStateException.class);
  }
"
"  @Test
  public void testEven() {
    PortAllocator portAllocator = getPortAllocator((port) -> port % 2 == 0);
    int next = PortAllocator.RANGE_MIN + 2;
    for (int i = 0; i < 1000; i++) {
      Assertions.assertEquals(next, portAllocator.getPort());
      next += 2;
      if (next % PortAllocator.CHUNK_SIZE == 0) {
        next += 2;
      }
    }
    assertThatThrownBy(() -> portAllocator.getPorts(2)).isInstanceOf(IllegalStateException.class);
  }
"
"  @Test
  public void shouldMapNestedField() {

    // given
    AwsSdkRequest awsSdkRequest = UpdateTable;
    MethodHandleFactory methodHandleFactory = new MethodHandleFactory();
    Serializer serializer = mock(Serializer.class);
    FieldMapper underTest = new FieldMapper(serializer, methodHandleFactory);
    UpdateTableRequest sdkRequest =
        UpdateTableRequest.builder()
            .provisionedThroughput(
                ProvisionedThroughput.builder()
                    .readCapacityUnits(55L)
                    .writeCapacityUnits(77L)
                    .build())
            .build();
    given(serializer.serialize(55L)).willReturn(""55"");
    given(serializer.serialize(77L)).willReturn(""77"");

    Span span = mock(Span.class);
    // when
    underTest.mapToAttributes(sdkRequest, awsSdkRequest, span);
    // then
    verify(span).setAttribute(""aws.dynamodb.provisioned_throughput.read_capacity_units"", ""55"");
    verify(span).setAttribute(""aws.dynamodb.provisioned_throughput.write_capacity_units"", ""77"");
    verifyNoMoreInteractions(span);
  }
"
"  @Test
  public void shouldMapRequestFieldsOnly() {

    // given
    AwsSdkRequest awsSdkRequest = BatchWriteItem;
    MethodHandleFactory methodHandleFactory = new MethodHandleFactory();
    Serializer serializer = mock(Serializer.class);
    FieldMapper underTest = new FieldMapper(serializer, methodHandleFactory);
    Map<String, Collection<WriteRequest>> items = new HashMap();
    BatchWriteItemRequest sdkRequest = BatchWriteItemRequest.builder().requestItems(items).build();
    given(serializer.serialize(items)).willReturn(""firstTable,secondTable"");

    Span span = mock(Span.class);
    // when
    underTest.mapToAttributes(sdkRequest, awsSdkRequest, span);
    // then
    verify(span).setAttribute(""aws.dynamodb.table_names"", ""firstTable,secondTable"");
    verifyNoMoreInteractions(span);
  }
"
"  @Test
  public void shouldMapResponseFieldsOnly() {

    // given
    AwsSdkRequest awsSdkRequest = BatchWriteItem;
    MethodHandleFactory methodHandleFactory = new MethodHandleFactory();
    Serializer serializer = mock(Serializer.class);
    FieldMapper underTest = new FieldMapper(serializer, methodHandleFactory);
    Map<String, Collection<ItemCollectionMetrics>> items = new HashMap();
    BatchWriteItemResponse sdkResponse =
        BatchWriteItemResponse.builder()
            .consumedCapacity(ConsumedCapacity.builder().build())
            .itemCollectionMetrics(items)
            .build();
    given(serializer.serialize(sdkResponse.consumedCapacity())).willReturn(""consumedCapacity"");
    given(serializer.serialize(items)).willReturn(""itemCollectionMetrics"");

    Span span = mock(Span.class);
    // when
    underTest.mapToAttributes(sdkResponse, awsSdkRequest, span);
    // then
    verify(span).setAttribute(""aws.dynamodb.consumed_capacity"", ""consumedCapacity"");
    verify(span).setAttribute(""aws.dynamodb.item_collection_metrics"", ""itemCollectionMetrics"");
    verifyNoMoreInteractions(span);
  }
"
"  @Test
  public void shouldSerializeSimpleString() {
    // given
    // when
    String serialized = new Serializer().serialize(""simpleString"");
    // then
    assertThat(serialized).isEqualTo(""simpleString"");
  }
"
"  @Test
  public void shouldSerializeSdkPojo() {
    // given
    SdkPojo sdkPojo =
        ProvisionedThroughput.builder().readCapacityUnits(1L).writeCapacityUnits(2L).build();
    // when
    String serialized = new Serializer().serialize(sdkPojo);
    // then
    assertThat(serialized).isEqualTo(""{\""ReadCapacityUnits\"":1,\""WriteCapacityUnits\"":2}"");
  }
"
"  @Test
  public void shouldSerializeCollection() {
    // given
    List<String> collection = Arrays.asList(""one"", ""two"", ""three"");
    // when
    String serialized = new Serializer().serialize(collection);
    // then
    assertThat(serialized).isEqualTo(""[one,two,three]"");
  }
"
"  @Test
  public void shouldSerializeEmptyCollectionAsNull() {
    // given
    List<String> collection = Collections.emptyList();
    // when
    String serialized = new Serializer().serialize(collection);
    // then
    assertThat(serialized).isNull();
  }
"
"  @Test
  public void shouldSerializeMapAsKeyCollection() {
    // given
    Map<String, Object> map = new HashMap<>();
    map.put(""uno"", 1L);
    map.put(""dos"", new LinkedHashMap<>());
    map.put(""tres"", ""cuatro"");
    // when
    String serialized = new Serializer().serialize(map);
    // then
    assertThat(serialized).isEqualTo(""[uno,dos,tres]"");
  }
"
"  @Test
  public void shouldAddSlashBetweenContextAndSpanName() {
    Context contextWithEmptyPath = ServletContextPath.init(Context.root(), p -> p, """");
    Context contextWithPath = ServletContextPath.init(Context.root(), p -> p, ""/context"");

    assertThat(ServletContextPath.prepend(contextWithEmptyPath, ""spanName"")).isEqualTo(""spanName"");
    assertThat(ServletContextPath.prepend(contextWithPath, ""spanName""))
        .isEqualTo(""/context/spanName"");
  }
"
"  @Test
  public void shouldNotResultInDuplicateSlash() {
    Context contextWithEmptyPath = ServletContextPath.init(Context.root(), p -> p, """");
    Context contextWithPath = ServletContextPath.init(Context.root(), p -> p, ""/context"");

    assertThat(ServletContextPath.prepend(contextWithEmptyPath, ""/spanName""))
        .isEqualTo(""/spanName"");
    assertThat(ServletContextPath.prepend(contextWithPath, ""/spanName""))
        .isEqualTo(""/context/spanName"");
  }
"
"  @Test
  public void shouldIgnoreEmptySpanName() {
    Context contextWithEmptyPath = ServletContextPath.init(Context.root(), p -> p, """");
    Context contextWithPath = ServletContextPath.init(Context.root(), p -> p, ""/context"");

    assertThat(ServletContextPath.prepend(contextWithEmptyPath, """")).isEqualTo("""");
    assertThat(ServletContextPath.prepend(contextWithPath, """")).isEqualTo(""/context"");

    assertThat(ServletContextPath.prepend(contextWithEmptyPath, null)).isEqualTo(null);
    assertThat(ServletContextPath.prepend(contextWithPath, null)).isEqualTo(""/context"");
  }
"
"  @TestConfiguration
    public OpenTelemetry customOpenTelemetry() {
      return OpenTelemetry.noop();
    }
"
"  @BeforeEach
          public String[] getParameterNames(Method method) {
            return new String[] {""discoveredName"", null, ""parameter"", ""nullAttribute"", ""notTraced""};
          }
"
"  @Test
  public void testSuccess() {
    AggregatedHttpResponse response = client.get(getAddress(""hello/world"")).aggregate().join();

    assertThat(response.status().code()).isEqualTo(200);
    assertThat(response.contentUtf8()).isEqualTo(""hello world"");

    testing.waitAndAssertTraces(
        trace ->
            trace.hasSpansSatisfyingExactly(
                span -> span.hasName(""/hello/{name}"").hasKind(SpanKind.SERVER).hasNoParent(),
                span ->
                    span.hasName(""HelloController.hello"")
                        .hasKind(SpanKind.INTERNAL)
                        .hasParent(trace.getSpan(0))));
  }
"
"  @Test
  public void shouldUseHttpIfAwsParentNotSampled() {
    // given
    Map<String, String> headers =
        ImmutableMap.of(
            ""X-b3-traceId"",
            ""4fd0b6131f19f39af59518d127b0cafe"",
            ""x-b3-spanid"",
            ""0000000000000123"",
            ""X-B3-Sampled"",
            ""true"");
    environmentVariables.set(
        ""_X_AMZN_TRACE_ID"",
        ""Root=1-8a3c60f7-d188f8fa79d48a391a778fa6;Parent=0000000000000456;Sampled=0"");

    // when
    Context context = ParentContextExtractor.extract(headers, INSTRUMENTER);
    // then
    Span span = Span.fromContext(context);
    SpanContext spanContext = span.getSpanContext();
    assertThat(spanContext.isValid()).isTrue();
    assertThat(spanContext.isValid()).isTrue();
    assertThat(spanContext.getSpanId()).isEqualTo(""0000000000000123"");
    assertThat(spanContext.getTraceId()).isEqualTo(""4fd0b6131f19f39af59518d127b0cafe"");
  }
"
"  @Test
  public void shouldPreferAwsParentHeaderIfValidAndSampled() {
    // given
    Map<String, String> headers =
        ImmutableMap.of(
            ""X-b3-traceId"",
            ""4fd0b6131f19f39af59518d127b0cafe"",
            ""x-b3-spanid"",
            ""0000000000000456"",
            ""X-B3-Sampled"",
            ""true"");
    environmentVariables.set(
        ""_X_AMZN_TRACE_ID"",
        ""Root=1-8a3c60f7-d188f8fa79d48a391a778fa6;Parent=0000000000000456;Sampled=1"");

    // when
    Context context = ParentContextExtractor.extract(headers, INSTRUMENTER);
    // then
    Span span = Span.fromContext(context);
    SpanContext spanContext = span.getSpanContext();
    assertThat(spanContext.isValid()).isTrue();
    assertThat(spanContext.isValid()).isTrue();
    assertThat(spanContext.getSpanId()).isEqualTo(""0000000000000456"");
    assertThat(spanContext.getTraceId()).isEqualTo(""8a3c60f7d188f8fa79d48a391a778fa6"");
  }
"
"  @Test
  public void shouldExtractCaseInsensitiveHeaders() {
    // given
    Map<String, String> headers =
        ImmutableMap.of(
            ""X-b3-traceId"",
            ""4fd0b6131f19f39af59518d127b0cafe"",
            ""x-b3-spanid"",
            ""0000000000000456"",
            ""X-B3-Sampled"",
            ""true"");

    // when
    Context context = ParentContextExtractor.extract(headers, INSTRUMENTER);
    // then
    Span span = Span.fromContext(context);
    SpanContext spanContext = span.getSpanContext();
    assertThat(spanContext.isValid()).isTrue();
    assertThat(spanContext.isValid()).isTrue();
    assertThat(spanContext.getSpanId()).isEqualTo(""0000000000000456"");
    assertThat(spanContext.getTraceId()).isEqualTo(""4fd0b6131f19f39af59518d127b0cafe"");
  }
"
"  @Test
  public void shouldReadHeadersFromStream() {
    // given
    String json =
        ""{""
            + ""\""headers\"" : {""
            + ""\""X-B3-TraceId\"": \""4fd0b6131f19f39af59518d127b0cafe\"", \""X-B3-SpanId\"": \""0000000000000456\"", \""X-B3-Sampled\"": \""true\""""
            + ""},""
            + ""\""body\"" : \""hello\""""
            + ""}"";
    InputStream inputStream = new ByteArrayInputStream(json.getBytes(Charset.defaultCharset()));
    // when
    Map<String, String> headers = HeadersFactory.ofStream(inputStream);
    // then
    assertThat(headers).isNotNull();
    assertThat(headers.size()).isEqualTo(3);
    assertThat(headers)
        .containsOnly(
            entry(""X-B3-TraceId"", ""4fd0b6131f19f39af59518d127b0cafe""),
            entry(""X-B3-SpanId"", ""0000000000000456""),
            entry(""X-B3-Sampled"", ""true""));
  }
"
"  @Test
  public void shouldReturnNullIfNoHeadersInStream() {
    // given
    String json = ""{\""something\"" : \""else\""}"";
    InputStream inputStream = new ByteArrayInputStream(json.getBytes(Charset.defaultCharset()));
    // when
    Map<String, String> headers = HeadersFactory.ofStream(inputStream); // then
    assertThat(headers).isNull();
  }
"
"  @Test
  public void shouldCreateNoopRequestIfNoPropagatorsSet() throws IOException {
    // given
    InputStream mock = mock(InputStream.class);
    GlobalOpenTelemetry.set(OpenTelemetry.noop());
    // when
    ApiGatewayProxyRequest created = ApiGatewayProxyRequest.forStream(mock);
    // then
    assertThat(created.freshStream()).isEqualTo(mock);
    assertThat(created.getHeaders()).isEmpty();
  }
"
"  @Test
  public void shouldCreateNoopRequestIfXrayPropagatorsSet() throws IOException {
    // given
    InputStream mock = mock(InputStream.class);
    GlobalOpenTelemetry.set(
        OpenTelemetry.propagating(ContextPropagators.create(AwsXrayPropagator.getInstance())));
    // when
    ApiGatewayProxyRequest created = ApiGatewayProxyRequest.forStream(mock);
    // then
    assertThat(created.freshStream()).isEqualTo(mock);
    assertThat(created.getHeaders()).isEmpty();
  }
"
"  @Test
  public void shouldUseStreamMarkingIfHttpPropagatorsSet() throws IOException {
    // given
    InputStream mock = mock(InputStream.class);
    given(mock.markSupported()).willReturn(true);
    GlobalOpenTelemetry.set(
        OpenTelemetry.propagating(ContextPropagators.create(B3Propagator.injectingSingleHeader())));
    // when
    ApiGatewayProxyRequest created = ApiGatewayProxyRequest.forStream(mock);
    // then
    assertThat(created.freshStream()).isEqualTo(mock);
    then(mock).should(atLeastOnce()).mark(Integer.MAX_VALUE);
    then(mock).should().reset();
  }
"
"  @Test
  public void shouldUseCopyIfMarkingNotAvailableAndHttpPropagatorsSet() throws IOException {
    // given
    InputStream mock = mock(InputStream.class);
    given(mock.markSupported()).willReturn(false);
    given(mock.read(any(byte[].class))).willReturn(-1);
    GlobalOpenTelemetry.set(
        OpenTelemetry.propagating(ContextPropagators.create(B3Propagator.injectingSingleHeader())));
    // when
    ApiGatewayProxyRequest created = ApiGatewayProxyRequest.forStream(mock);
    // then
    assertThat(created.freshStream()).isInstanceOf(ByteArrayInputStream.class);
    then(mock).should(never()).mark(any(Integer.class));
    then(mock).should(never()).reset();
    then(mock).should().read(any());
  }
"
"  @Test
  public void test() {
    ProcessMetrics.registerObservers();

    waitAndAssertMetrics(
        metric ->
            metric
                .hasName(""runtime.java.memory"")
                .hasUnit(""bytes"")
                .hasLongGauge()
                .points()
                .anySatisfy(point -> assertThat(point.getValue()).isPositive()),
        metric ->
            metric
                .hasName(""runtime.java.cpu_time"")
                .hasUnit(""seconds"")
                .hasDoubleGauge()
                .points()
                .anySatisfy(point -> assertThat(point.getValue()).isPositive()));
  }
"
"  @Test
  public void test() {
    SystemMetrics.registerObservers();

    waitAndAssertMetrics(
        metric ->
            metric
                .hasName(""system.memory.usage"")
                .hasUnit(""By"")
                .hasLongGauge()
                .points()
                .anySatisfy(point -> assertThat(point.getValue()).isPositive()),
        metric ->
            metric
                .hasName(""system.memory.utilization"")
                .hasUnit(""1"")
                .hasDoubleGauge()
                .points()
                .anySatisfy(point -> assertThat(point.getValue()).isPositive()),
        metric -> metric.hasName(""system.network.io"").hasUnit(""By"").hasLongGauge(),
        metric -> metric.hasName(""system.network.packets"").hasUnit(""packets"").hasLongGauge(),
        metric -> metric.hasName(""system.network.errors"").hasUnit(""errors"").hasLongGauge(),
        metric -> metric.hasName(""system.disk.operations"").hasUnit(""operations"").hasLongGauge());
  }
"
"  @ParameterizedTest
  public void testHelloRequest(String path, String className) {
    AggregatedHttpResponse response = client.get(url.resolve(path).toString()).aggregate().join();

    assertThat(response.status().code()).isEqualTo(200);
    assertThat(response.contentUtf8()).isEqualTo(""hello"");

    testing.waitAndAssertTraces(
        trace ->
            trace.hasSpansSatisfyingExactly(
                span ->
                    span.hasName(getContextRoot() + path).hasKind(SpanKind.SERVER).hasNoParent(),
                span -> span.hasName(className + "".hello"").hasParent(trace.getSpan(0))));
  }
"
"  @Test
    public void execute(JobExecutionContext context) {
      GlobalOpenTelemetry.getTracer(""jobtracer"").spanBuilder(""child"").startSpan().end();
    }
"
"  @ParameterizedTest
  public void testHelloRequest(String service) {
    String soapMessage =
        ""<soapenv:Envelope xmlns:soapenv=\""http://schemas.xmlsoap.org/soap/envelope/\"" xmlns:hel=\""http://opentelemetry.io/test/hello-web-service\"">""
            + ""   <soapenv:Header/>""
            + ""   <soapenv:Body>""
            + ""      <hel:helloRequest>""
            + ""         <name>Test</name>""
            + ""      </hel:helloRequest>""
            + ""   </soapenv:Body>""
            + ""</soapenv:Envelope>"";

    AggregatedHttpResponse response =
        client.post(getAddress(service), soapMessage).aggregate().join();
    Document doc = Jsoup.parse(response.contentUtf8());

    assertThat(response.status().code()).isEqualTo(200);
    assertThat(doc.selectFirst(""message"").text()).isEqualTo(""Hello Test"");

    String methodName = ""hello"";
    testing.waitAndAssertTraces(
        trace ->
            trace.hasSpansSatisfyingExactly(
                span -> assertServerSpan(span, serverSpanName(service, methodName)).hasNoParent(),
                span -> assertHandlerSpan(span, service, methodName).hasParent(trace.getSpan(0)),
                span ->
                    assertAnnotationHandlerSpan(span, service, methodName)
                        .hasParent(trace.getSpan(1))));
  }
"
"  @Test
  public void shouldExtractHttpParentForHttpEndpoint() throws Exception {

    // given
    Endpoint endpoint = new HttpEndpoint("""", new HttpComponent(), URI.create(""""));
    Map<String, Object> exchangeHeaders =
        Collections.singletonMap(
            ""uber-trace-id"", ""1f7f8dab3f0043b1b9cf0a75caf57510:a13825abcb764bd3:0:1"");

    // when
    Context parent = CamelPropagationUtil.extractParent(exchangeHeaders, endpoint);

    // then
    Span parentSpan = Span.fromContext(parent);
    SpanContext parentSpanContext = parentSpan.getSpanContext();
    assertThat(parentSpanContext.getTraceId()).isEqualTo(""1f7f8dab3f0043b1b9cf0a75caf57510"");
    assertThat(parentSpanContext.getSpanId()).isEqualTo(""a13825abcb764bd3"");
  }
"
"  @Test
  public void shouldNotFailExtractingNullHttpParentForHttpEndpoint() throws Exception {

    // given
    Endpoint endpoint = new HttpEndpoint("""", new HttpComponent(), URI.create(""""));
    Map<String, Object> exchangeHeaders = Collections.singletonMap(""uber-trace-id"", null);

    // when
    Context parent = CamelPropagationUtil.extractParent(exchangeHeaders, endpoint);

    // then
    Span parentSpan = Span.fromContext(parent);
    SpanContext parentSpanContext = parentSpan.getSpanContext();
    assertThat(parentSpanContext.isValid()).isEqualTo(false);
  }
"
"  @Test
  public void shouldNotFailExtractingNullAwsParentForSqsEndpoint() {

    // given
    Endpoint endpoint = new SqsEndpoint("""", new SqsComponent(), new SqsConfiguration());
    Map<String, Object> exchangeHeaders = Collections.singletonMap(""AWSTraceHeader"", null);

    // when
    Context parent = CamelPropagationUtil.extractParent(exchangeHeaders, endpoint);

    // then
    Span parentSpan = Span.fromContext(parent);
    SpanContext parentSpanContext = parentSpan.getSpanContext();
    assertThat(parentSpanContext.isValid()).isEqualTo(false);
  }
"
"  @Test
  public void shouldExtractAwsParentForSqsEndpoint() {

    // given
    Endpoint endpoint = new SqsEndpoint("""", new SqsComponent(), new SqsConfiguration());
    Map<String, Object> exchangeHeaders =
        Collections.singletonMap(
            ""AWSTraceHeader"",
            ""Root=1-5759e988-bd862e3fe1be46a994272793;Parent=53995c3f42cd8ad8;Sampled=1\n"");

    // when
    Context parent = CamelPropagationUtil.extractParent(exchangeHeaders, endpoint);

    // then
    Span parentSpan = Span.fromContext(parent);
    SpanContext parentSpanContext = parentSpan.getSpanContext();
    assertThat(parentSpanContext.getTraceId()).isEqualTo(""5759e988bd862e3fe1be46a994272793"");
    assertThat(parentSpanContext.getSpanId()).isEqualTo(""53995c3f42cd8ad8"");
  }
"
"  @Test
  public void methodBodyCreatesReferences() {
    ReferenceCollector collector = new ReferenceCollector((String s) -> false);

    collector.collectReferencesFromAdvice(MethodBodyAdvice.class.getName());
    collector.prune();
    Map<String, ClassRef> references = collector.getReferences();

    assertThat(references)
        .containsOnlyKeys(
            MethodBodyAdvice.A.class.getName(),
            MethodBodyAdvice.B.class.getName(),
            MethodBodyAdvice.SomeInterface.class.getName(),
            MethodBodyAdvice.SomeImplementation.class.getName());

    ClassRef refB = references.get(MethodBodyAdvice.B.class.getName());
    ClassRef refA = references.get(MethodBodyAdvice.A.class.getName());

    // interface flags
    assertThat(refB.getFlags()).contains(ManifestationFlag.NON_INTERFACE);
    assertThat(references.get(MethodBodyAdvice.SomeInterface.class.getName()).getFlags())
        .contains(ManifestationFlag.INTERFACE);

    // class access flags
    assertThat(refA.getFlags()).contains(PACKAGE_OR_HIGHER);
    assertThat(refB.getFlags()).contains(PACKAGE_OR_HIGHER);

    // method refs
    assertMethod(
        refB,
        ""method"",
        ""(Ljava/lang/String;)Ljava/lang/String;"",
        PROTECTED_OR_HIGHER,
        OwnershipFlag.NON_STATIC);
    assertMethod(
        refB, ""methodWithPrimitives"", ""(Z)V"", PROTECTED_OR_HIGHER, OwnershipFlag.NON_STATIC);
    assertMethod(refB, ""staticMethod"", ""()V"", PROTECTED_OR_HIGHER, OwnershipFlag.STATIC);
    assertMethod(
        refB,
        ""methodWithArrays"",
        ""([Ljava/lang/String;)[Ljava/lang/Object;"",
        PROTECTED_OR_HIGHER,
        OwnershipFlag.NON_STATIC);

    // field refs
    assertThat(refB.getFields()).isEmpty();
    assertThat(refA.getFields()).hasSize(2);
    assertField(refA, ""publicB"", PACKAGE_OR_HIGHER, OwnershipFlag.NON_STATIC);
    assertField(refA, ""staticB"", PACKAGE_OR_HIGHER, OwnershipFlag.STATIC);
  }
"
"  @Test
  public void protectedRefTest() {
    ReferenceCollector collector = new ReferenceCollector(s -> false);
    collector.collectReferencesFromAdvice(MethodBodyAdvice.B2.class.getName());
    collector.prune();
    Map<String, ClassRef> references = collector.getReferences();

    assertMethod(
        references.get(MethodBodyAdvice.B.class.getName()),
        ""protectedMethod"",
        ""()V"",
        PROTECTED_OR_HIGHER,
        OwnershipFlag.NON_STATIC);
  }
"
"  @Test
  public void ldcCreatesReferences() {
    ReferenceCollector collector = new ReferenceCollector(s -> false);
    collector.collectReferencesFromAdvice(LdcAdvice.class.getName());
    collector.prune();
    Map<String, ClassRef> references = collector.getReferences();

    assertThat(references).containsKey(MethodBodyAdvice.A.class.getName());
  }
"
"  @Test
  public void instanceofCreatesReferences() {
    ReferenceCollector collector = new ReferenceCollector(s -> false);
    collector.collectReferencesFromAdvice(TestClasses.InstanceofAdvice.class.getName());
    collector.prune();
    Map<String, ClassRef> references = collector.getReferences();

    assertThat(references).containsKey(MethodBodyAdvice.A.class.getName());
  }
"
"  @Test
  public void invokedynamicCreatesReferences() {
    ReferenceCollector collector = new ReferenceCollector(s -> false);
    collector.collectReferencesFromAdvice(TestClasses.InvokeDynamicAdvice.class.getName());
    collector.prune();
    Map<String, ClassRef> references = collector.getReferences();

    assertThat(references).containsKey(""muzzle.TestClasses$MethodBodyAdvice$SomeImplementation"");
    assertMethod(
        references.get(""muzzle.TestClasses$MethodBodyAdvice$SomeImplementation""),
        ""someMethod"",
        ""()V"",
        PROTECTED_OR_HIGHER,
        OwnershipFlag.NON_STATIC);
    assertThat(references).containsKey(""muzzle.TestClasses$MethodBodyAdvice$B"");
    assertMethod(
        references.get(""muzzle.TestClasses$MethodBodyAdvice$B""),
        ""staticMethod"",
        ""()V"",
        PROTECTED_OR_HIGHER,
        OwnershipFlag.STATIC);
    assertThat(references).containsKey(""muzzle.TestClasses$MethodBodyAdvice$A"");
    assertMethod(
        references.get(""muzzle.TestClasses$MethodBodyAdvice$A""),
        ""<init>"",
        ""()V"",
        PROTECTED_OR_HIGHER,
        OwnershipFlag.NON_STATIC);
  }
"
"  @Test
  public void shouldCreateReferencesForHelperClasses() {
    ReferenceCollector collector = new ReferenceCollector(s -> false);
    collector.collectReferencesFromAdvice(HelperAdvice.class.getName());
    Map<String, ClassRef> references = collector.getReferences();

    assertThat(references)
        .containsOnlyKeys(
            TestHelperClasses.Helper.class.getName(),
            TestHelperClasses.HelperSuperClass.class.getName(),
            TestHelperClasses.HelperInterface.class.getName());

    ClassRef helperSuperClass = references.get(TestHelperClasses.HelperSuperClass.class.getName());
    assertThat(helperSuperClass.getFlags()).contains(ManifestationFlag.ABSTRACT);
    assertHelperSuperClassMethod(helperSuperClass, true);
    assertMethod(
        helperSuperClass,
        ""finalMethod"",
        ""()Ljava/lang/String;"",
        VisibilityFlag.PUBLIC,
        OwnershipFlag.NON_STATIC,
        ManifestationFlag.FINAL);

    ClassRef helperInterface = references.get(TestHelperClasses.HelperInterface.class.getName());
    assertThat(helperInterface.getFlags()).contains(ManifestationFlag.ABSTRACT);
    assertHelperInterfaceMethod(helperInterface, true);

    ClassRef helperClass = references.get(TestHelperClasses.Helper.class.getName());
    assertThat(helperClass.getFlags()).contains(ManifestationFlag.NON_FINAL);
    assertHelperSuperClassMethod(helperClass, false);
    assertHelperInterfaceMethod(helperClass, false);
  }
"
"  @Test
  public void shouldCollectFieldDeclarationReferences() {
    ReferenceCollector collector =
        new ReferenceCollector(s -> s.equals(DeclaredFieldTestClass.Helper.class.getName()));
    collector.collectReferencesFromAdvice(DeclaredFieldTestClass.Advice.class.getName());
    collector.prune();
    Map<String, ClassRef> references = collector.getReferences();

    ClassRef helperClass = references.get(DeclaredFieldTestClass.Helper.class.getName());
    FieldRef superField = findField(helperClass, ""superField"");
    assertThat(superField).isNotNull();
    assertThat(superField.isDeclared()).isFalse();

    FieldRef field = findField(helperClass, ""helperField"");
    assertThat(field).isNotNull();
    assertThat(field.isDeclared()).isTrue();

    ClassRef libraryBaseClass =
        references.get(DeclaredFieldTestClass.LibraryBaseClass.class.getName());
    assertThat(libraryBaseClass.getFields()).isEmpty();
  }
"
"  @Test
  public void shouldFindAllHelperClasses() {
    ReferenceCollector collector = new ReferenceCollector(s -> false);
    collector.collectReferencesFromAdvice(HelperAdvice.class.getName());
    collector.prune();
    List<String> helperClasses = collector.getSortedHelperClasses();

    assertThat(helperClasses)
        .containsSubsequence(
            Arrays.asList(
                TestHelperClasses.HelperInterface.class.getName(),
                TestHelperClasses.Helper.class.getName()));
    assertThat(helperClasses)
        .containsSubsequence(
            Arrays.asList(
                TestHelperClasses.HelperSuperClass.class.getName(),
                TestHelperClasses.Helper.class.getName()));
  }
"
"  @Test
  public void shouldCorrectlyFindHelperClassesFromMultipleAdviceClasses() {
    ReferenceCollector collector = new ReferenceCollector(s -> false);
    collector.collectReferencesFromAdvice(HelperAdvice.class.getName());
    collector.collectReferencesFromAdvice(TestClasses.HelperOtherAdvice.class.getName());
    collector.prune();
    List<String> helperClasses = collector.getSortedHelperClasses();

    assertThat(helperClasses)
        .containsSubsequence(
            Arrays.asList(
                TestHelperClasses.HelperInterface.class.getName(),
                TestHelperClasses.Helper.class.getName()));
    assertThat(helperClasses)
        .containsSubsequence(
            Arrays.asList(
                TestHelperClasses.HelperSuperClass.class.getName(),
                TestHelperClasses.Helper.class.getName()));
    assertThat(helperClasses)
        .containsSubsequence(
            Arrays.asList(
                OtherTestHelperClasses.TestEnum.class.getName(),
                OtherTestHelperClasses.TestEnum.class.getName() + ""$1""));

    assertThat(helperClasses)
        .containsExactlyInAnyOrder(
            TestHelperClasses.HelperSuperClass.class.getName(),
            TestHelperClasses.HelperInterface.class.getName(),
            TestHelperClasses.Helper.class.getName(),
            OtherTestHelperClasses.Bar.class.getName(),
            OtherTestHelperClasses.Foo.class.getName(),
            OtherTestHelperClasses.TestEnum.class.getName(),
            OtherTestHelperClasses.TestEnum.class.getName() + ""$1"",
            OtherTestHelperClasses.class.getName() + ""$1"");
  }
"
"  @Test
  public void shouldCorrectlyFindExternalInstrumentationClasses() {
    ReferenceCollector collector =
        new ReferenceCollector(s -> s.startsWith(""external.instrumentation""));
    collector.collectReferencesFromAdvice(
        TestClasses.ExternalInstrumentationAdvice.class.getName());
    collector.prune();

    Map<String, ClassRef> references = collector.getReferences();
    assertThat(references.get(""external.NotInstrumentation"")).isNotNull();

    List<String> helperClasses = collector.getSortedHelperClasses();
    assertThat(helperClasses).containsExactly(ExternalHelper.class.getName());
  }
"
"  @ParameterizedTest
  public void shouldCollectHelperClassesFromResourceFile(
      @SuppressWarnings(""unused"") String desc, String resource) {
    ReferenceCollector collector = new ReferenceCollector(s -> false);
    collector.collectReferencesFromResource(HelperResource.create(resource, resource));
    collector.prune();

    List<String> helperClasses = collector.getSortedHelperClasses();
    assertThat(helperClasses)
        .containsSubsequence(
            Arrays.asList(
                TestHelperClasses.HelperInterface.class.getName(),
                TestHelperClasses.Helper.class.getName()));
    assertThat(helperClasses)
        .containsSubsequence(
            Arrays.asList(
                TestHelperClasses.HelperSuperClass.class.getName(),
                TestHelperClasses.Helper.class.getName()));
  }
"
"  @Test
  public void shouldIgnoreArbitraryResourceFile() {
    ReferenceCollector collector = new ReferenceCollector(s -> false);
    collector.collectReferencesFromResource(
        HelperResource.create(""application.properties"", ""application.properties""));
    collector.prune();

    assertThat(collector.getReferences()).isEmpty();
    assertThat(collector.getSortedHelperClasses()).isEmpty();
  }
"
"  @Test
  public void shouldCollectVirtualFields() {
    ReferenceCollector collector = new ReferenceCollector(s -> false);
    collector.collectReferencesFromAdvice(VirtualFieldTestClasses.ValidAdvice.class.getName());
    collector.prune();

    VirtualFieldMappings virtualFieldMappings = collector.getVirtualFieldMappings();
    assertThat(virtualFieldMappings.entrySet())
        .containsExactlyInAnyOrder(
            entry(VirtualFieldTestClasses.Key1.class.getName(), Context.class.getName()),
            entry(VirtualFieldTestClasses.Key2.class.getName(), Context.class.getName()));
  }
"
"  @Test
  public void shouldCollectMultipleVirtualFieldsForSingleClass() {
    ReferenceCollector collector = new ReferenceCollector(s -> false);
    collector.collectReferencesFromAdvice(
        VirtualFieldTestClasses.TwoVirtualFieldsInTheSameClassAdvice.class.getName());
    collector.prune();

    VirtualFieldMappings virtualFieldMappings = collector.getVirtualFieldMappings();
    assertThat(virtualFieldMappings.entrySet())
        .containsExactlyInAnyOrder(
            entry(VirtualFieldTestClasses.Key1.class.getName(), Context.class.getName()),
            entry(VirtualFieldTestClasses.Key1.class.getName(), State.class.getName()));
  }
"
"  @ParameterizedTest(name = ""{0}"")
  public void shouldNotCollectVirtualFieldsForInvalidScenario(
      @SuppressWarnings(""unused"") String desc, String adviceClassName) {
    ReferenceCollector collector = new ReferenceCollector(s -> false);

    Assertions.assertThatExceptionOfType(MuzzleCompilationException.class)
        .isThrownBy(
            () -> {
              collector.collectReferencesFromAdvice(adviceClassName);
              collector.prune();
            });
  }
"
"  @Test
  public void shouldCollectArrayVirtualField() {
    ReferenceCollector collector = new ReferenceCollector(s -> false);
    collector.collectReferencesFromAdvice(
        VirtualFieldTestClasses.UsingArrayAsFieldAdvice.class.getName());
    collector.prune();

    VirtualFieldMappings virtualFieldMappings = collector.getVirtualFieldMappings();
    assertThat(virtualFieldMappings.entrySet())
        .containsExactly(
            entry(
                VirtualFieldTestClasses.Key1.class.getName(),
                Type.getType(Context[].class).getClassName()));
  }
"
"  @Test
  public void getItemFromCache() throws Exception {
    Cache<Method, String> cache = new MethodCache<>();
    Method key = TestClass.class.getDeclaredMethod(""method"");
    String value = ""Value"";

    cache.put(key, value);

    assertThat(cache.get(key)).isEqualTo(""Value"");
  }
"
"  @Test
  public void extensionsAreLoadedFromJar() throws IOException, InterruptedException {
    startTarget(""/opentelemetry-extensions.jar"");

    testAndVerify();

    stopTarget();
  }
"
"  @Test
  public void extensionsAreLoadedFromFolder() throws IOException, InterruptedException {
    startTarget(""/"");

    testAndVerify();

    stopTarget();
  }
"
"  @Test
  public void extensionsAreLoadedFromJavaagent() throws IOException, InterruptedException {
    startTargetWithExtendedAgent();

    testAndVerify();

    stopTarget();
  }
"
"  @Test
  public void springBootSmokeTestOnJDK() throws IOException, InterruptedException {
    startTarget(8);
    String url = String.format(""http://localhost:%d/greeting"", target.getMappedPort(8080));
    Request request = new Request.Builder().url(url).get().build();

    String currentAgentVersion =
        (String)
            new JarFile(agentPath)
                .getManifest()
                .getMainAttributes()
                .get(Attributes.Name.IMPLEMENTATION_VERSION);

    Response response = client.newCall(request).execute();
    System.out.println(response.headers().toString());

    Collection<ExportTraceServiceRequest> traces = waitForTraces();

    Assertions.assertNotNull(response.header(""X-server-id""));
    Assertions.assertEquals(1, response.headers(""X-server-id"").size());
    Assertions.assertTrue(TraceId.isValid(response.header(""X-server-id"")));
    Assertions.assertEquals(""Hi!"", response.body().string());
    Assertions.assertEquals(1, countSpansByName(traces, ""/greeting""));
    Assertions.assertEquals(0, countSpansByName(traces, ""WebController.greeting""));
    Assertions.assertEquals(1, countSpansByName(traces, ""WebController.withSpan""));
    Assertions.assertEquals(2, countSpansByAttributeValue(traces, ""custom"", ""demo""));
    Assertions.assertNotEquals(
        0, countResourcesByValue(traces, ""telemetry.auto.version"", currentAgentVersion));
    Assertions.assertNotEquals(0, countResourcesByValue(traces, ""custom.resource"", ""demo""));

    stopTarget();
  }
"
"  @Test
    public boolean equals(Object obj) {
      if (obj == this) {
        return true;
      }
      if (!(obj instanceof MethodSignature)) {
        return false;
      }
      MethodSignature other = (MethodSignature) obj;
      return Objects.equals(name, other.name)
          && Objects.equals(parameterTypes, other.parameterTypes)
          && Objects.equals(returnType, other.returnType);
    }
"
"  @Test
  public void extractForwarded() {
    assertEquals(""1.1.1.1"", HttpServerTracer.extractForwarded(""for=1.1.1.1""));
  }
"
"  @Test
  public void extractForwardedIpv6() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwarded(""for=\""[1111:1111:1111:1111:1111:1111:1111:1111]\""""));
  }
"
"  @Test
  public void extractForwardedWithPort() {
    assertEquals(""1.1.1.1"", HttpServerTracer.extractForwarded(""for=\""1.1.1.1:2222\""""));
  }
"
"  @Test
  public void extractForwardedIpv6WithPort() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwarded(
            ""for=\""[1111:1111:1111:1111:1111:1111:1111:1111]:2222\""""));
  }
"
"  @Test
  public void extractForwardedCaps() {
    assertEquals(""1.1.1.1"", HttpServerTracer.extractForwarded(""For=1.1.1.1""));
  }
"
"  @Test
  public void extractForwardedMalformed() {
    assertNull(HttpServerTracer.extractForwarded(""for=;for=1.1.1.1""));
  }
"
"  @Test
  public void extractForwardedEmpty() {
    assertNull(HttpServerTracer.extractForwarded(""""));
  }
"
"  @Test
  public void extractForwardedEmptyValue() {
    assertNull(HttpServerTracer.extractForwarded(""for=""));
  }
"
"  @Test
  public void extractForwardedEmptyValueWithSemicolon() {
    assertNull(HttpServerTracer.extractForwarded(""for=;""));
  }
"
"  @Test
  public void extractForwardedNoFor() {
    assertNull(HttpServerTracer.extractForwarded(""by=1.1.1.1;test=1.1.1.1""));
  }
"
"  @Test
  public void extractForwardedMultiple() {
    assertEquals(""1.1.1.1"", HttpServerTracer.extractForwarded(""for=1.1.1.1;for=1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedMultipleIpV6() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwarded(
            ""for=\""[1111:1111:1111:1111:1111:1111:1111:1111]\"";for=1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedMultipleWithPort() {
    assertEquals(""1.1.1.1"", HttpServerTracer.extractForwarded(""for=\""1.1.1.1:2222\"";for=1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedMultipleIpV6WithPort() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwarded(
            ""for=\""[1111:1111:1111:1111:1111:1111:1111:1111]:2222\"";for=1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedMixedSplitter() {
    assertEquals(
        ""1.1.1.1"",
        HttpServerTracer.extractForwarded(""test=abcd; by=1.2.3.4, for=1.1.1.1;for=1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedMixedSplitterIpv6() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwarded(
            ""test=abcd; by=1.2.3.4, for=\""[1111:1111:1111:1111:1111:1111:1111:1111]\"";for=1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedMixedSplitterWithPort() {
    assertEquals(
        ""1.1.1.1"",
        HttpServerTracer.extractForwarded(
            ""test=abcd; by=1.2.3.4, for=\""1.1.1.1:2222\"";for=1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedMixedSplitterIpv6WithPort() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwarded(
            ""test=abcd; by=1.2.3.4, for=\""[1111:1111:1111:1111:1111:1111:1111:1111]:2222\"";for=1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedFor() {
    assertEquals(""1.1.1.1"", HttpServerTracer.extractForwardedFor(""1.1.1.1""));
  }
"
"  @Test
  public void extractForwardedForIpv6() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwardedFor(""\""[1111:1111:1111:1111:1111:1111:1111:1111]\""""));
  }
"
"  @Test
  public void extractForwardedForIpv6Unquoted() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwardedFor(""[1111:1111:1111:1111:1111:1111:1111:1111]""));
  }
"
"  @Test
  public void extractForwardedForIpv6Unbracketed() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwardedFor(""1111:1111:1111:1111:1111:1111:1111:1111""));
  }
"
"  @Test
  public void extractForwardedForWithPort() {
    assertEquals(""1.1.1.1"", HttpServerTracer.extractForwardedFor(""1.1.1.1:2222""));
  }
"
"  @Test
  public void extractForwardedForIpv6WithPort() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwardedFor(""\""[1111:1111:1111:1111:1111:1111:1111:1111]:2222\""""));
  }
"
"  @Test
  public void extractForwardedForIpv6UnquotedWithPort() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwardedFor(""[1111:1111:1111:1111:1111:1111:1111:1111]:2222""));
  }
"
"  @Test
  public void extractForwardedForEmpty() {
    assertNull(HttpServerTracer.extractForwardedFor(""""));
  }
"
"  @Test
  public void extractForwardedForMultiple() {
    assertEquals(""1.1.1.1"", HttpServerTracer.extractForwardedFor(""1.1.1.1,1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedForMultipleIpv6() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwardedFor(
            ""\""[1111:1111:1111:1111:1111:1111:1111:1111]\"",1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedForMultipleIpv6Unquoted() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwardedFor(""[1111:1111:1111:1111:1111:1111:1111:1111],1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedForMultipleIpv6Unbracketed() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwardedFor(""1111:1111:1111:1111:1111:1111:1111:1111,1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedForMultipleWithPort() {
    assertEquals(""1.1.1.1"", HttpServerTracer.extractForwardedFor(""1.1.1.1:2222,1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedForMultipleIpv6WithPort() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwardedFor(
            ""\""[1111:1111:1111:1111:1111:1111:1111:1111]:2222\"",1.2.3.4""));
  }
"
"  @Test
  public void extractForwardedForMultipleIpv6UnquotedWithPort() {
    assertEquals(
        ""1111:1111:1111:1111:1111:1111:1111:1111"",
        HttpServerTracer.extractForwardedFor(
            ""[1111:1111:1111:1111:1111:1111:1111:1111]:2222,1.2.3.4""));
  }
"
"  @Test
  public void doesNotSetDuplicateAttributes() {
    // given
    Map<String, String> request = new HashMap<>();
    request.put(""transport"", ""TCP"");
    request.put(""peerName"", ""1.2.3.4"");
    request.put(""peerIp"", ""1.2.3.4"");
    request.put(""peerPort"", ""123"");

    Map<String, String> response = new HashMap<>();
    response.put(""peerName"", ""4.3.2.1"");
    response.put(""peerPort"", ""42"");
    response.put(""peerIp"", ""4.3.2.1"");

    TestNetServerAttributesExtractor extractor = new TestNetServerAttributesExtractor();

    // when
    AttributesBuilder startAttributes = Attributes.builder();
    extractor.onStart(startAttributes, request);

    AttributesBuilder endAttributes = Attributes.builder();
    extractor.onEnd(endAttributes, request, response, null);

    // then
    assertThat(startAttributes.build())
        .containsOnly(
            entry(SemanticAttributes.NET_TRANSPORT, ""TCP""),
            entry(SemanticAttributes.NET_PEER_PORT, 123L),
            entry(SemanticAttributes.NET_PEER_IP, ""1.2.3.4""));

    assertThat(endAttributes.build()).isEmpty();
  }
"
"  @Test
  public void doesNotSetNegativePort() {
    // given
    Map<String, String> request = new HashMap<>();
    request.put(""peerPort"", ""-42"");

    Map<String, String> response = new HashMap<>();
    response.put(""peerPort"", ""-1"");

    TestNetServerAttributesExtractor extractor = new TestNetServerAttributesExtractor();

    // when
    AttributesBuilder startAttributes = Attributes.builder();
    extractor.onStart(startAttributes, request);

    AttributesBuilder endAttributes = Attributes.builder();
    extractor.onEnd(endAttributes, request, response, null);

    // then
    assertThat(startAttributes.build()).isEmpty();
    assertThat(endAttributes.build()).isEmpty();
  }
"
"  @Test
  public void doesNotSetDuplicateAttributes() {
    // given
    Map<String, String> request = new HashMap<>();
    request.put(""transport"", ""TCP"");
    request.put(""peerName"", ""1.2.3.4"");
    request.put(""peerIp"", ""1.2.3.4"");
    request.put(""peerPort"", ""123"");

    Map<String, String> response = new HashMap<>();
    response.put(""peerName"", ""4.3.2.1"");
    response.put(""peerPort"", ""42"");
    response.put(""peerIp"", ""4.3.2.1"");

    TestNetClientAttributesExtractor extractor = new TestNetClientAttributesExtractor();

    // when
    AttributesBuilder startAttributes = Attributes.builder();
    extractor.onStart(startAttributes, request);

    AttributesBuilder endAttributes = Attributes.builder();
    extractor.onEnd(endAttributes, request, response, null);

    // then
    assertThat(startAttributes.build()).isEmpty();

    assertThat(endAttributes.build())
        .containsOnly(
            entry(SemanticAttributes.NET_PEER_PORT, 42L),
            entry(SemanticAttributes.NET_PEER_IP, ""4.3.2.1""));
  }
"
"  @Test
  public void doesNotSetNegativePort() {
    // given
    Map<String, String> request = new HashMap<>();
    request.put(""peerPort"", ""-42"");

    Map<String, String> response = new HashMap<>();
    response.put(""peerPort"", ""-1"");

    TestNetClientAttributesExtractor extractor = new TestNetClientAttributesExtractor();

    // when
    AttributesBuilder startAttributes = Attributes.builder();
    extractor.onStart(startAttributes, request);

    AttributesBuilder endAttributes = Attributes.builder();
    extractor.onEnd(endAttributes, request, response, null);

    // then
    assertThat(startAttributes.build()).isEmpty();
    assertThat(endAttributes.build()).isEmpty();
  }
"
"  @Test
    public Iterable<String> keys(Map<String, String> carrier) {
      return carrier.keySet();
    }
"
"  @Test
  public void serverSpan() {
    // SpanKey.SERVER will never be passed to SpanSuppressionStrategy.from(), it cannot be
    // automatically determined by te builder - thus it does not make any sense to test it (for now)
    SpanSuppressionStrategy strategy = SpanSuppressionStrategy.from(emptySet());

    Context context = strategy.storeInContext(Context.root(), SpanKind.SERVER, SPAN);

    assertThat(strategy.shouldSuppress(context, SpanKind.SERVER)).isTrue();
    Stream.of(SpanKind.CLIENT, SpanKind.CONSUMER, SpanKind.PRODUCER)
        .forEach(spanKind -> assertThat(strategy.shouldSuppress(context, spanKind)).isFalse());

    verifySpanKey(SpanKey.SERVER, context);
  }
"
"  @ParameterizedTest
  public void consumerSpan(SpanKey spanKey) {
    SpanSuppressionStrategy strategy = SpanSuppressionStrategy.from(singleton(spanKey));

    verifyNoSuppression(strategy, Context.root());

    Context context = strategy.storeInContext(Context.root(), SpanKind.CONSUMER, SPAN);

    assertThat(strategy.shouldSuppress(context, SpanKind.SERVER)).isFalse();
    Stream.of(SpanKind.CLIENT, SpanKind.CONSUMER, SpanKind.PRODUCER)
        .forEach(spanKind -> assertThat(strategy.shouldSuppress(context, spanKind)).isTrue());

    verifySpanKey(spanKey, context);
  }
"
"  @ParameterizedTest
  public void clientSpan(SpanKey spanKey) {
    SpanSuppressionStrategy strategy = SpanSuppressionStrategy.from(singleton(spanKey));

    verifyNoSuppression(strategy, Context.root());

    Context context = strategy.storeInContext(Context.root(), SpanKind.CLIENT, SPAN);

    assertThat(strategy.shouldSuppress(context, SpanKind.SERVER)).isFalse();
    Stream.of(SpanKind.CLIENT, SpanKind.CONSUMER, SpanKind.PRODUCER)
        .forEach(spanKind -> assertThat(strategy.shouldSuppress(context, spanKind)).isTrue());

    verifySpanKey(spanKey, context);
  }
"
"  @Test
  public void producerSpan() {
    SpanSuppressionStrategy strategy = SpanSuppressionStrategy.from(singleton(SpanKey.PRODUCER));

    verifyNoSuppression(strategy, Context.root());

    Context context = strategy.storeInContext(Context.root(), SpanKind.PRODUCER, SPAN);

    assertThat(strategy.shouldSuppress(context, SpanKind.SERVER)).isFalse();
    Stream.of(SpanKind.CLIENT, SpanKind.CONSUMER, SpanKind.PRODUCER)
        .forEach(spanKind -> assertThat(strategy.shouldSuppress(context, spanKind)).isTrue());

    verifySpanKey(SpanKey.PRODUCER, context);
  }
"
"    @Test
    public void serve1() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response = client.get(""/http-serve"").aggregate().get();
        assertThat(response.status()).isEqualTo(HttpStatus.OK);

        assertThat(response.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response.headers().contains(""RateLimit-Reset"")).isFalse();
        assertThat(response.headers().contains(""X-RateLimit-Reset"")).isFalse();
        assertThat(response.headers().contains(""X-Rate-Limit-Reset"")).isFalse();
        assertThat(response.headers().contains(""RateLimit-Limit"")).isFalse();
        assertThat(response.headers().contains(""X-RateLimit-Limit"")).isFalse();
        assertThat(response.headers().contains(""X-Rate-Limit-Limit"")).isFalse();
    }
"
"    @Test
    public void throttle1() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle1"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isTrue();
        final long reset1 = Long.parseLong(response1.headers().get(""X-RateLimit-Reset""));
        assertThat(reset1).isBetween(0L, 10L);
        assertThat(response1.headers().contains(""X-RateLimit-Limit"")).isFalse();

        final AggregatedHttpResponse response2 = client.get(""/http-throttle1"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.TOO_MANY_REQUESTS);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER)).isTrue();
        final long retryAfter2 = Long.parseLong(response2.headers().get(HttpHeaderNames.RETRY_AFTER));
        assertThat(retryAfter2).isBetween(0L, 10L);
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"")).isTrue();
        final long reset = Long.parseLong(response2.headers().get(""X-RateLimit-Reset""));
        assertThat(reset).isEqualTo(retryAfter2);
        assertThat(response2.headers().contains(""X-RateLimit-Limit"")).isFalse();
    }
"
"    @Test
    public void throttle2() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle2"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isTrue();
        final long reset1 = Long.parseLong(response1.headers().get(""X-RateLimit-Reset""));
        assertThat(reset1).isBetween(0L, 10L);
        assertThat(response1.headers().get(""X-RateLimit-Limit"")).isEqualTo(""1, 1;window=10"");

        final AggregatedHttpResponse response2 = client.get(""/http-throttle2"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.TOO_MANY_REQUESTS);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER, ""15"")).isTrue();
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"", ""15"")).isTrue();
        assertThat(response1.headers().get(""X-RateLimit-Limit"")).isEqualTo(""1, 1;window=10"");
    }
"
"    @Test
    public void throttle3() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle3"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isFalse();

        final AggregatedHttpResponse response2 = client.get(""/http-throttle3"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.TOO_MANY_REQUESTS);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER)).isTrue();
        final long retryAfter2 = Long.parseLong(response2.headers().get(HttpHeaderNames.RETRY_AFTER));
        assertThat(retryAfter2).isBetween(0L, 10L);
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"")).isFalse();
    }
"
"    @Test
    public void throttle4() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle4"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isFalse();

        final AggregatedHttpResponse response2 = client.get(""/http-throttle4"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.SERVICE_UNAVAILABLE);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER)).isTrue();
        final long retryAfter2 = Long.parseLong(response2.headers().get(HttpHeaderNames.RETRY_AFTER));
        assertThat(retryAfter2).isBetween(5L, 10L);
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"")).isFalse();
    }
"
"    @Test
    public void shouldBeDifferentToEachOther() throws UnsupportedEncodingException {
        final SamlRequestIdManager manager =
                SamlRequestIdManager.ofJwt(""me"", ""test"", 60, 5);

        final String id1 = manager.newId();
        final String id2 = manager.newId();
        final String id3 = manager.newId();

        assertThat(id1).isNotEqualTo(id2).isNotEqualTo(id3);
        assertThat(id2).isNotEqualTo(id3);
    }
"
"    @Test
    public void shouldMatchJWTPattern() throws UnsupportedEncodingException {
        final Pattern p = Pattern.compile(""[a-zA-Z0-9-_]+\\.[a-zA-Z0-9-_]+\\.[a-zA-Z0-9-_]+"");
        final SamlRequestIdManager manager =
                SamlRequestIdManager.ofJwt(""me"", ""test"", 60, 5);
        final String id = manager.newId();
        assertThat(p.matcher(id).matches()).isTrue();
        assertThat(manager.validateId(id)).isTrue();
    }
"
"    @Test
    public void shouldBeExpired() throws InterruptedException, UnsupportedEncodingException {
        final SamlRequestIdManager manager =
                SamlRequestIdManager.ofJwt(""me"", ""test"", 1, 0);

        final Instant started = Instant.now();
        final String id = manager.newId();
        assertThat(manager.validateId(id)).isTrue();

        await().pollDelay(Durations.TWO_HUNDRED_MILLISECONDS)
               .atMost(Durations.FIVE_SECONDS)
               .untilAsserted(() -> assertThat(manager.validateId(id)).isFalse());

        assertThat(java.time.Duration.between(started, Instant.now()).toMillis())
                .isGreaterThan(TimeUnit.SECONDS.toMillis(1));
    }
"
"    @Test
    public void shouldBeAcceptedBecauseOfLeeway() throws InterruptedException, UnsupportedEncodingException {
        final SamlRequestIdManager manager =
                SamlRequestIdManager.ofJwt(""me"", ""test"", 1, 1);

        final Instant started = Instant.now();
        final String id = manager.newId();
        assertThat(manager.validateId(id)).isTrue();

        await().pollDelay(Durations.TWO_HUNDRED_MILLISECONDS)
               .atMost(Durations.FIVE_SECONDS)
               .untilAsserted(() -> assertThat(manager.validateId(id)).isFalse());

        assertThat(java.time.Duration.between(started, Instant.now()).toMillis())
                .isGreaterThan(TimeUnit.SECONDS.toMillis(2));
    }
"
"    @Test
    public void shouldFail() {
        assertThatThrownBy(() -> SamlRequestIdManager.ofJwt(""me"", ""test"", 0, 0))
                .isInstanceOf(IllegalArgumentException.class);
        assertThatThrownBy(() -> SamlRequestIdManager.ofJwt(""me"", ""test"", -1, 0))
                .isInstanceOf(IllegalArgumentException.class);
        assertThatThrownBy(() -> SamlRequestIdManager.ofJwt(""me"", ""test"", 1, -1))
                .isInstanceOf(IllegalArgumentException.class);
    }
"
"    @Test
    public void shouldRespondAuthnRequest_HttpRedirect() throws Exception {
        final AggregatedHttpResponse resp = client.get(""/redirect"").aggregate().join();
        assertThat(resp.status()).isEqualTo(HttpStatus.FOUND);

        // Check the order of the parameters in the quest string.
        final String location = resp.headers().get(HttpHeaderNames.LOCATION);
        final Pattern p = Pattern.compile(
                ""http://idp\\.example\\.com/saml/sso/redirect\\?"" +
                ""SAMLRequest=([^&]+)&RelayState=([^&]+)&SigAlg=([^&]+)&Signature=(.+)$"");
        assertThat(location).isNotNull();
        assertThat(p.matcher(location).matches()).isTrue();

        assertThat(QueryParams.fromQueryString(location)
                              .get(SIGNATURE_ALGORITHM)).isEqualTo(signatureAlgorithm);
    }
"
"    @Test
    public void shouldRespondAuthnRequest_HttpPost() throws Exception {
        final AggregatedHttpResponse resp = client.get(""/post"").aggregate().join();
        assertThat(resp.status()).isEqualTo(HttpStatus.OK);
        assertThat(resp.contentType()).isEqualTo(MediaType.HTML_UTF_8);

        final Document doc = Jsoup.parse(resp.contentUtf8());
        assertThat(doc.body().attr(""onLoad"")).isEqualTo(""document.forms[0].submit()"");

        // SAMLRequest will be posted to the IdP's SSO URL.
        final Element form = doc.body().child(0);
        assertThat(form.attr(""method"")).isEqualTo(""post"");
        assertThat(form.attr(""action"")).isEqualTo(""http://idp.example.com/saml/sso/post"");
        assertThat(form.child(0).attr(""name"")).isEqualTo(SAML_REQUEST);
        assertThat(form.child(1).attr(""name"")).isEqualTo(RELAY_STATE);
    }
"
"    @Test
    public void shouldBeAlreadyAuthenticated() throws Exception {
        final RequestHeaders req = RequestHeaders.of(HttpMethod.GET, ""/redirect"",
                                                     HttpHeaderNames.COOKIE, ""test=test"");
        final AggregatedHttpResponse resp = client.execute(req).aggregate().join();
        assertThat(resp.status()).isEqualTo(HttpStatus.OK);
        assertThat(resp.contentUtf8()).isEqualTo(""authenticated"");
    }
"
"    @Test
    public void shouldRespondMetadataWithoutAuthentication() throws Exception {
        final AggregatedHttpResponse resp = client.get(""/saml/metadata"").aggregate().join();
        assertThat(resp.status()).isEqualTo(HttpStatus.OK);
        assertThat(resp.contentType()).isEqualTo(CONTENT_TYPE_SAML_METADATA);

        final EntityDescriptor metadata =
                (EntityDescriptor) deserialize(resp.contentUtf8().getBytes());
        assertThat(metadata).isNotNull();

        final SPSSODescriptor sp = metadata.getSPSSODescriptor(SAMLConstants.SAML20P_NS);
        assertThat(sp.isAuthnRequestsSigned()).isTrue();
        assertThat(sp.getWantAssertionsSigned()).isTrue();

        final List<KeyDescriptor> kd = sp.getKeyDescriptors();
        assertThat(kd.get(0).getUse().name()).isEqualToIgnoringCase(""signing"");
        assertThat(kd.get(1).getUse().name()).isEqualToIgnoringCase(""encryption"");

        final List<SingleLogoutService> slo = sp.getSingleLogoutServices();
        assertThat(slo.get(0).getLocation())
                .isEqualTo(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/slo/post"");
        assertThat(slo.get(0).getBinding()).isEqualTo(SAMLConstants.SAML2_POST_BINDING_URI);
        assertThat(slo.get(1).getLocation())
                .isEqualTo(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/slo/redirect"");
        assertThat(slo.get(1).getBinding()).isEqualTo(SAMLConstants.SAML2_REDIRECT_BINDING_URI);

        final List<AssertionConsumerService> acs = sp.getAssertionConsumerServices();
        // index 0 (default)
        assertThat(acs.get(0).getIndex()).isEqualTo(0);
        assertThat(acs.get(0).isDefault()).isTrue();
        assertThat(acs.get(0).getLocation())
                .isEqualTo(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/acs/post"");
        assertThat(acs.get(0).getBinding()).isEqualTo(SAMLConstants.SAML2_POST_BINDING_URI);
        // index 1
        assertThat(acs.get(1).getIndex()).isEqualTo(1);
        assertThat(acs.get(1).isDefault()).isFalse();
        assertThat(acs.get(1).getLocation())
                .isEqualTo(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/acs/redirect"");
        assertThat(acs.get(1).getBinding()).isEqualTo(SAMLConstants.SAML2_REDIRECT_BINDING_URI);
    }
"
"    @Test
    public void shouldConsumeAssertion_HttpPost() throws Exception {
        final Response response =
                getAuthResponse(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/acs/post"");
        final AggregatedHttpResponse res = sendViaHttpPostBindingProtocol(""/saml/acs/post"",
                                                                          SAML_RESPONSE, response);

        assertThat(res.status()).isEqualTo(HttpStatus.FOUND);
        assertThat(res.headers().get(HttpHeaderNames.LOCATION)).isEqualTo(""/"");
    }
"
"    @Test
    public void shouldConsumeAssertion_HttpRedirect() throws Exception {
        final Response response =
                getAuthResponse(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/acs/redirect"");
        final AggregatedHttpResponse res = sendViaHttpRedirectBindingProtocol(""/saml/acs/redirect"",
                                                                              SAML_RESPONSE, response);

        assertThat(res.status()).isEqualTo(HttpStatus.FOUND);
        assertThat(res.headers().get(HttpHeaderNames.LOCATION)).isEqualTo(""/"");
    }
"
"    @Test
    public void shouldConsumeLogoutRequest_HttpPost() throws Exception {
        final LogoutRequest logoutRequest =
                getLogoutRequest(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/slo/post"",
                                 ""http://idp.example.com/post"");

        final AggregatedHttpResponse res = sendViaHttpPostBindingProtocol(""/saml/slo/post"",
                                                                          SAML_REQUEST, logoutRequest);

        assertThat(res.status()).isEqualTo(HttpStatus.OK);
        assertThat(res.contentType()).isEqualTo(MediaType.HTML_UTF_8);

        final Document doc = Jsoup.parse(res.contentUtf8());
        assertThat(doc.body().attr(""onLoad"")).isEqualTo(""document.forms[0].submit()"");

        // SAMLResponse will be posted to the IdP's logout response URL.
        final Element form = doc.body().child(0);
        assertThat(form.attr(""method"")).isEqualTo(""post"");
        assertThat(form.attr(""action"")).isEqualTo(""http://idp.example.com/saml/slo/post"");
        assertThat(form.child(0).attr(""name"")).isEqualTo(SAML_RESPONSE);
    }
"
"    @Test
    public void shouldConsumeLogoutRequest_HttpRedirect() throws Exception {
        final LogoutRequest logoutRequest =
                getLogoutRequest(""http://"" + spHostname + ':' + rule.httpPort() + ""/saml/slo/redirect"",
                                 ""http://idp.example.com/redirect"");

        final AggregatedHttpResponse res =
                sendViaHttpRedirectBindingProtocol(""/saml/slo/redirect"", SAML_REQUEST, logoutRequest);

        assertThat(res.status()).isEqualTo(HttpStatus.FOUND);

        // Check the order of the parameters in the quest string.
        final String location = res.headers().get(HttpHeaderNames.LOCATION);
        final Pattern p = Pattern.compile(
                ""http://idp\\.example\\.com/saml/slo/redirect\\?"" +
                ""SAMLResponse=([^&]+)&SigAlg=([^&]+)&Signature=(.+)$"");
        assertThat(location).isNotNull();
        assertThat(p.matcher(location).matches()).isTrue();
    }
"
"    @Test
    public void expectSuccessWithFile() throws Exception {
        final File file = folder.newFile();

        assertThat(file.length()).isZero();

        final KeyStore keyStore = KeyStore.getInstance(""JKS"");
        keyStore.load(null, null);
        keyStore.store(new FileOutputStream(file), """".toCharArray());

        assertThat(file.length()).isGreaterThan(0);
        assertThat(file.canRead()).isTrue();
        assertThat(file.exists()).isTrue();

        new KeyStoreCredentialResolverBuilder(file).build();
    }
"
"    @Test
    public void expectSuccessWithResource() throws Exception {
        new KeyStoreCredentialResolverBuilder(getClass().getClassLoader(), ""keystore/test.jks"").build();
    }
"
"    @Test
    public void expectNotFound() throws Exception {
        assertThatThrownBy(
                () -> new KeyStoreCredentialResolverBuilder(new File(""/not_exist"")).build())
                .isInstanceOf(FileNotFoundException.class);
        assertThatThrownBy(
                () -> new KeyStoreCredentialResolverBuilder(getClass().getClassLoader(), ""not_exist"").build())
                .isInstanceOf(FileNotFoundException.class)
                .hasMessageContaining(""Resource not found"");
    }
"
"    @Test
        public void onComplete(String response) {
            resultHandler.onComplete(response);
        }
"
"    @Test
    public void callbackContextIsFromInvocationTime_root() {
        try (SafeCloseable ignored = serverContext().push()) {
            super.callbackContextIsFromInvocationTime_root();
        }
    }
"
"    @Test
    public void addsStatusCodeWhenNotOk_async() {
        try (SafeCloseable ignored = serverContext().push()) {
            super.addsStatusCodeWhenNotOk_async();
        }
    }
"
"    @Test
    public void usesParentFromInvocationTime() {
        try (SafeCloseable ignored = serverContext().push()) {
            super.usesParentFromInvocationTime();
        }
    }
"
"    @Test
    public void clientTimestampAndDurationEnclosedByParent() {
    }
"
"    @Test
    public void callbackContextIsFromInvocationTime() {
        // TODO(trustin): Can't make this pass because span is updated *after* we invoke the callback
        //                ITHttpAsyncClient gave us.
    }
"
"    @Test
    public void redirect() {
        throw new AssumptionViolatedException(""Armeria does not support client redirect."");
    }
"
"    @Test
    public void get_returnsNullWhenNoCurrentRequestContext() {
        assertThat(currentTraceContext.get()).isNull();
    }
"
"    @Test
    public void get_returnsNullWhenCurrentRequestContext_hasNoTraceAttribute() {
        try (SafeCloseable requestContextScope = ctx.push()) {
            assertThat(currentTraceContext.get()).isNull();
        }
    }
"
"    @Test
    public void newScope_appliesWhenNoCurrentRequestContext() {
        try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
            assertThat(traceContextScope).hasToString(""ThreadLocalScope"");
            assertThat(currentTraceContext.get()).isEqualTo(traceContext);
        }
    }
"
"    @Test
    public void newScope_appliesWhenCurrentRequestContext() {
        try (SafeCloseable requestContextScope = ctx.push()) {
            try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
                assertThat(traceContextScope).hasToString(""InitialRequestScope"");
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);
            }
        }
    }
"
"    @Test
    public void newScope_closeDoesntClearFirstScope() {
        final TraceContext traceContext2 = TraceContext.newBuilder().traceId(1).spanId(2).build();

        try (SafeCloseable requestContextScope = ctx.push()) {
            try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
                assertThat(traceContextScope).hasToString(""InitialRequestScope"");
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);

                try (Scope traceContextScope2 = currentTraceContext.newScope(traceContext2)) {
                    assertThat(traceContextScope2).hasToString(""RequestContextTraceContextScope"");
                    assertThat(currentTraceContext.get()).isEqualTo(traceContext2);
                }
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);
            }
            // the first scope is attached to the request context and cleared when that's destroyed
            assertThat(currentTraceContext.get()).isEqualTo(traceContext);
        }
    }
"
"    @Test
    public void newScope_notOnEventLoop() {
        final TraceContext traceContext2 = TraceContext.newBuilder().traceId(1).spanId(2).build();

        try (SafeCloseable requestContextScope = ctx.push()) {
            try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
                assertThat(traceContextScope).hasToString(""InitialRequestScope"");
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);

                when(eventLoop.inEventLoop()).thenReturn(false);
                try (Scope traceContextScope2 = currentTraceContext.newScope(traceContext2)) {
                    assertThat(traceContextScope2).hasToString(""ThreadLocalScope"");
                    assertThat(currentTraceContext.get()).isEqualTo(traceContext2);
                }
                when(eventLoop.inEventLoop()).thenReturn(true);
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);
            }
            // the first scope is attached to the request context and cleared when that's destroyed
            assertThat(currentTraceContext.get()).isEqualTo(traceContext);
        }
    }
"
"    @Test
    public void newScope_canClearScope() {
        try (SafeCloseable requestContextScope = ctx.push()) {
            try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
                try (Scope traceContextScope2 = currentTraceContext.newScope(null)) {
                    assertThat(currentTraceContext.get()).isNull();
                }
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);
            }
        }
    }
"
"    @Test
    public void newScope_respondsToPing() {
        final PingPongExtra extra = new PingPongExtra();
        final TraceContext extraContext = TraceContext.newBuilder().traceId(1).spanId(1)
                                                      .addExtra(extra).build();

        try (Scope traceContextScope = currentTraceContext.newScope(extraContext)) {
            assertThat(traceContextScope).hasToString(""NoopScope"");
            assertThat(extra.isPong()).isTrue();
        }
    }
"
"    @Test
    public void shouldSetPongIfOnlyExtra() {
        final PingPongExtra extra = new PingPongExtra();

        final TraceContext context = TraceContext.newBuilder().traceId(1).spanId(1)
                                                 .addExtra(extra).build();

        TraceContextUtil.PingPongExtra.maybeSetPong(context);

        assertThat(extra.isPong()).isTrue();
    }
"
"    @Test
    public void notFound() {
        throw new AssumptionViolatedException(
                ""Armeria yields 'get /*' as a span name for a non-existent mapping."");
    }
"
"    @Test
    public void httpStatusCodeSettable_onUncaughtException() {
        throw new AssumptionViolatedException(
            ""Can't currently control the HTTP status code on uncaught exception. #2656"");
    }
"
"    @Test
    public void httpStatusCodeSettable_onUncaughtException_async() {
        throw new AssumptionViolatedException(
            ""Can't currently control the HTTP status code on uncaught exception. #2656"");
    }
"
"    @AfterEach
    public void tearDown() {
        Tracing.current().close();
    }
"
"    @Test
            public HttpResponse serve(ServiceRequestContext ctx, HttpRequest req) throws Exception {
                return HttpResponse.of(HttpStatus.OK);
            }
"
"    @Test
            public void pop(RequestContext current, @Nullable RequestContext toRestore) {
                popped.set(true);
                super.pop(current, toRestore);
            }
"
"    @Test
    public void contextLoads() {
        assertThat(greetingController).isNotNull();
    }
"
"    @Test
    public void verifyTomcatVersion() {
        assertThat(TomcatVersion.major()).isEqualTo(tomcatMajorVersion);
        assertThat(TomcatVersion.minor()).isEqualTo(tomcatMinorVersion);
    }
"
"    @Test
    public void verifySingleConnector() {
        // Relevant to Tomcat 9.0
        assertThat(applicationContext).isInstanceOf(WebServerApplicationContext.class);
        final WebServer webServer = ((WebServerApplicationContext) applicationContext).getWebServer();
        assertThat(webServer).isInstanceOf(TomcatWebServer.class);
        assertThat(((TomcatWebServer) webServer).getTomcat()
                                                .getEngine()
                                                .getService()
                                                .findConnectors()).hasSize(1);
    }
"
"    @Test
    public void greetingShouldReturnDefaultMessage() throws Exception {
        assertThat(restTemplate.getForObject(""http://localhost:"" +
                                             httpPort +
                                             ""/tomcat/api/rest/v1/greeting"",
                                             String.class))
                .contains(""Hello, World!"");
    }
"
"    @Test
    public void greetingShouldReturnUsersMessage() throws Exception {
        assertThat(restTemplate.getForObject(""http://localhost:"" +
                                             httpPort +
                                             ""/tomcat/api/rest/v1/greeting?name=Armeria"",
                                             String.class))
                .contains(""Hello, Armeria!"");
    }
"
"    @Test
    public void greetingShouldReturn404() throws Exception {
        assertThat(restTemplate.getForEntity(""http://localhost:"" +
                                             httpPort +
                                             ""/tomcat/api/rest/v1/greet"",
                                             Void.class)
                               .getStatusCode()).isEqualByComparingTo(HttpStatus.NOT_FOUND);
    }
"
"    @Test
    public void contextLoads() {
        assertThat(applicationContext.getBean(ArmeriaAutoConfiguration.class)).isNotNull();
        assertThatThrownBy(() -> {
            applicationContext.getBean(ArmeriaReactiveWebServerFactory.class);
        }).isInstanceOf(BeansException.class);
    }
"
"    @Test
    public void contextLoads() {
        assertThat(applicationContext.getBean(ArmeriaReactiveWebServerFactory.class)).isNotNull();
        assertThatThrownBy(() -> {
            applicationContext.getBean(ArmeriaAutoConfiguration.class);
        }).isInstanceOf(BeansException.class);
    }
"
"    @Test(expected = NotAllMetaRegionsOnlineException.class)
    public void testGuavaConflict() throws Exception {
        // Make sure Armeria is available in the class path.
        assertThat(Version.getAll(Server.class.getClassLoader())).isNotNull();
        // Make sure newer Guava is available in the class path.
        assertThat(Stopwatch.class.getDeclaredConstructor().getModifiers()).is(new Condition<>(
                value -> !Modifier.isPublic(value),
                ""Recent Guava Stopwatch should have non-public default constructor.""));

        final MetaTableLocator locator = new MetaTableLocator();
        final ZooKeeperWatcher zkw = mock(ZooKeeperWatcher.class);
        final RecoverableZooKeeper zk = mock(RecoverableZooKeeper.class);
        when(zkw.getRecoverableZooKeeper()).thenReturn(zk);
        when(zk.exists(any(), any())).thenReturn(new Stat(0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0));

        locator.waitMetaRegionLocation(zkw, 100);
    }
"
"    @Test
    public void normal() {
        try (ClientFactory clientFactory =
                     ClientFactory.builder()
                                  .tlsCustomizer(ctx -> ctx.keyManager(clientCert.certificateFile(),
                                                                       clientCert.privateKeyFile()))
                                  .tlsNoVerify()
                                  .build()) {
            final WebClient client = WebClient.builder(rule.httpsUri())
                                              .factory(clientFactory)
                                              .decorator(LoggingClient.builder().newDecorator())
                                              .build();
            assertThat(client.get(""/"").aggregate().join().status()).isEqualTo(HttpStatus.OK);
        }
    }
"
"    @Test
    public void proxyWithTrailers() throws Throwable {
        final WebClient client = WebClient.of(frontendServer.httpUri());

        final AtomicBoolean headersReceived = new AtomicBoolean();
        final AtomicBoolean complete = new AtomicBoolean();
        final AtomicReference<Throwable> error = new AtomicReference<>();

        client.get(""/trailers"").subscribe(new Subscriber<HttpObject>() {
            @Override
            public void onSubscribe(Subscription s) {
                s.request(Long.MAX_VALUE);
            }
"
"    @Test
    public void proxyWithTrailersOnly() throws Throwable {
        final WebClient client = WebClient.of(frontendServer.httpUri());

        final AtomicBoolean complete = new AtomicBoolean();
        final AtomicReference<Throwable> error = new AtomicReference<>();

        client.get(""/trailers-only"").subscribe(new Subscriber<HttpObject>() {
            @Override
            public void onSubscribe(Subscription s) {
                s.request(Long.MAX_VALUE);
            }
"
"    @Test
        public void onSettingsRead(ChannelHandlerContext ctx, Http2Settings settings) {
            assertThat(settings.pushEnabled()).isFalse();
        }
"
"    @Test
    public void testExtractHost() {
        // additionalRequestHeaders has the highest precedence.
        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, ""foo"")),
                               HttpRequest.of(RequestHeaders.of(HttpMethod.GET, ""/"",
                                                                HttpHeaderNames.AUTHORITY, ""bar:8080"")),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""foo"");

        // Request header
        assertThat(extractHost(context(HttpHeaders.of()),
                               HttpRequest.of(RequestHeaders.of(HttpMethod.GET, ""/"",
                                                                HttpHeaderNames.AUTHORITY, ""bar:8080"")),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""bar"");

        // Endpoint.host() has the lowest precedence.
        assertThat(extractHost(context(HttpHeaders.of()),
                               HttpRequest.of(HttpMethod.GET, ""/""),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""baz"");

        // IPv6 address authority
        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, ""[::1]:8443"")),
                               HttpRequest.of(HttpMethod.GET, ""/""),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""::1"");

        // An invalid authority should be ignored.
        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, ""[::1"")),
                               HttpRequest.of(HttpMethod.GET, ""/""),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""baz"");

        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, "":8080"")),
                               HttpRequest.of(HttpMethod.GET, ""/""),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""baz"");

        // If additionalRequestHeader's authority is invalid but req.authority() is valid,
        // use the authority from 'req'.
        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, ""[::1"")),
                               HttpRequest.of(RequestHeaders.of(HttpMethod.GET, ""/"",
                                                                HttpHeaderNames.AUTHORITY, ""bar"")),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""bar"");

        assertThat(extractHost(context(HttpHeaders.of(HttpHeaderNames.AUTHORITY, "":8080"")),
                               HttpRequest.of(RequestHeaders.of(HttpMethod.GET, ""/"",
                                                                HttpHeaderNames.AUTHORITY, ""bar"")),
                               Endpoint.of(""baz"", 8080))).isEqualTo(""bar"");
    }
"
"    @Test
            public void connectionOpen(SessionProtocol protocol, InetSocketAddress remoteAddr,
                                       InetSocketAddress localAddr, AttributeMap attrs) throws Exception {
                openRunnable.run();
            }
"
"    @Test
        public HttpResponse execute(ClientRequestContext ctx, HttpRequest req) throws Exception {
            // Will never reach here.
            throw new Error();
        }
"
"    @Test
            public void onSubscribe(Subscription s) {
                s.request(Long.MAX_VALUE);
            }
"
"    @Test
    public void notEmpty() {
        final StreamDecoder decoder = newDecoder();
        final ByteBuf buf = ByteBufAllocator.DEFAULT.buffer();
        buf.writeBytes(PAYLOAD);
        final HttpData data = decoder.decode(HttpData.wrap(buf));
        assertThat(buf.refCnt()).isZero();
        assertThat(data.byteBuf().refCnt()).isOne();
        data.close();
    }
"
"    @Test
    public void empty_unpooled() {
        final StreamDecoder decoder = newDecoder();
        final HttpData data = decoder.decode(HttpData.empty());
        assertThat(data.isPooled()).isFalse();
    }
"
"    @Test
    public void empty_pooled() {
        final StreamDecoder decoder = newDecoder();
        final ByteBuf buf = ByteBufAllocator.DEFAULT.buffer();
        final HttpData data = decoder.decode(HttpData.wrap(buf));
        assertThat(buf.refCnt()).isZero();

        // Even for a pooled empty input, the result is unpooled since there's no point in pooling empty
        // buffers.
        assertThat(data.isPooled()).isFalse();
    }
"
"    @Test
    public void testPropertyFileWatcherRunnableExitsOnInterrupt() throws InterruptedException {
        final WatchService watchService = mock(WatchService.class);
        final FileWatcherRunnable fileWatcherRunnable = new FileWatcherRunnable(watchService, mock(
                FileSystemWatchContext.class));
        when(watchService.take()).then(invocation -> {
            while (!Thread.currentThread().isInterrupted()) {
                Thread.yield();
            }
            return null;
        });
        final Thread thread = new Thread(fileWatcherRunnable);
        thread.start();
        thread.interrupt();
        await().untilAsserted(() -> assertThat(thread.isAlive()).isFalse());
    }
"
"    @Test
            public Endpoint selectNow(ClientRequestContext ctx) {
                final List<Endpoint> endpoints = endpointGroup.endpoints();
                return endpoints.isEmpty() ? null : endpoints.get(0);
            }
"
"    @Test
    public void testGetEndpointGroupName() throws Exception {
        assertNull(getEndpointGroupName(""http://myGroupName/""));
        assertNull(getEndpointGroupName(""http://myGroupName:8080/xxx""));
        assertNull(getEndpointGroupName(""http://group1:myGroupName:8080/""));
        assertNull(getEndpointGroupName(""http://username:password@myGroupName:8080/""));

        assertEquals(""myGroupName"", getEndpointGroupName(""http://"" + endpointGroupMark + ""myGroupName/""));
        assertEquals(""myGroupName"", getEndpointGroupName(""http://"" + endpointGroupMark + ""myGroupName:8080/""));
        assertEquals(""myGroupName"", getEndpointGroupName(""http://"" + endpointGroupMark + ""myGroupName:8080/""));
        assertEquals(""myGroupName"", getEndpointGroupName(""http://username:password@"" + endpointGroupMark +
                                                         ""myGroupName:8080/""));
    }
"
"    @Test
    public void testReplace() throws Exception {
        final String replacement = ""127.0.0.1:1234"";
        assertEquals(""http://myGroupName/"",
                     replaceEndpointGroup(""http://myGroupName/"", replacement));
        assertEquals(""http://myGroupName:8080/xxx"",
                     replaceEndpointGroup(""http://myGroupName:8080/xxx"", replacement));
        assertEquals(""http://group1:myGroupName:8080/"",
                     replaceEndpointGroup(""http://group1:myGroupName:8080/"", replacement));
        assertEquals(""http://username:password@myGroupName:8080/"",
                     replaceEndpointGroup(""http://username:password@myGroupName:8080/"", replacement));

        assertEquals(""http://127.0.0.1:1234/"",
                     replaceEndpointGroup(""http://"" + endpointGroupMark + ""myGroupName/"", replacement));
        assertEquals(""http://127.0.0.1:1234/"",
                     replaceEndpointGroup(""http://"" + endpointGroupMark + ""myGroupName:8080/"", replacement));
        assertEquals(""http://127.0.0.1:1234/xxx"",
                     replaceEndpointGroup(""http://"" + endpointGroupMark + ""myGroupName:8080/xxx"", replacement));
        assertEquals(""http://username:password@127.0.0.1:1234/xxx"",
                     replaceEndpointGroup(""http://username:password@"" + endpointGroupMark +
                                          ""myGroupName:8080/xxx"", replacement));
    }
"
"    @Test
        public int compare(Endpoint o1, Endpoint o2) {
            if (o1.equals(o2) && o1.weight() == o2.weight()) {
                return 0;
            }
            return -1;
        }
"
"    @Test
    public void testRestartableThreadRestartBehavior() {
        final RestartableThread restartableThread =
                new RestartableThread(testName.getMethodName(), () -> () -> {
                    while (!Thread.currentThread().isInterrupted()) {
                        Thread.yield();
                    }
                });

        restartableThread.start();
        assertThat(restartableThread.isRunning()).isTrue();
        restartableThread.stop();
        assertThat(restartableThread.isRunning()).isFalse();
        restartableThread.start();
        assertThat(restartableThread.isRunning()).isTrue();
        restartableThread.stop();
        assertThat(restartableThread.isRunning()).isFalse();
    }
"
"    @Test
    public void emptyGroupStopsBackgroundThread() throws Exception {

        final File file = folder.newFile(""temp-file.properties"");
        final File file2 = folder.newFile(""temp-file2.properties"");

        final FileWatcherRegistry fileWatcherRegistry =
                new FileWatcherRegistry();
        final FileWatchRegisterKey key1 = fileWatcherRegistry.register(file.toPath(), () -> {});
        final FileWatchRegisterKey key2 = fileWatcherRegistry.register(file2.toPath(), () -> {});

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key1);

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key2);

        assertThat(fileWatcherRegistry.isRunning()).isFalse();
    }
"
"    @Test
    public void closeEndpointGroupStopsRegistry() throws Exception {

        final File file = folder.newFile(""temp-file.properties"");

        final FileWatcherRegistry fileWatcherRegistry = new FileWatcherRegistry();
        fileWatcherRegistry.register(file.toPath(), () -> {});

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.close();

        assertThat(fileWatcherRegistry.isRunning()).isFalse();
    }
"
"    @Test
    public void runnableWithExceptionContinuesRun() throws Exception {

        final File file = folder.newFile(""temp-file.properties"");
        final FileWatcherRegistry fileWatcherRegistry = new FileWatcherRegistry();

        final AtomicInteger val = new AtomicInteger(0);
        final FileWatchRegisterKey key = fileWatcherRegistry.register(file.toPath(), () -> {
            try {
                final BufferedReader bufferedReader = new BufferedReader(new FileReader(file));
                val.set(Integer.valueOf(bufferedReader.readLine()));
            } catch (IOException e) {
                // do nothing
            }
            throw new RuntimeException();
        });

        PrintWriter printWriter = new PrintWriter(file);
        printWriter.print(1);
        printWriter.close();

        await().untilAsserted(() -> assertThat(val.get()).isEqualTo(1));

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        printWriter = new PrintWriter(file);
        printWriter.print(2);
        printWriter.close();

        await().untilAsserted(() -> assertThat(val.get()).isEqualTo(2));

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key);

        assertThat(fileWatcherRegistry.isRunning()).isFalse();

        fileWatcherRegistry.close();
    }
"
"    @Test
    public void testMultipleFileSystems() throws Exception {

        final FileWatcherRegistry fileWatcherRegistry = new FileWatcherRegistry();

        final Path path1 = createMockedPath();
        final Path path2 = createMockedPath();

        final FileWatchRegisterKey key1 = fileWatcherRegistry.register(path1, () -> {});
        final FileWatchRegisterKey key2 = fileWatcherRegistry.register(path2, () -> {});
        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key1);
        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key2);
        assertThat(fileWatcherRegistry.isRunning()).isFalse();
    }
"
"    @Test
        public void updateCandidates(List<Endpoint> candidates) {
            this.candidates = candidates;
            selectedCandidates = ImmutableList.copyOf(candidates);
        }
"
"    @Test
    public void propertiesWithoutDefaultPort() {
        final PropertiesEndpointGroup endpointGroup = PropertiesEndpointGroup.of(PROPS, ""serverA.hosts"");

        assertThat(endpointGroup.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                        Endpoint.parse(""127.0.0.1:8081""),
                                                                        Endpoint.parse(""127.0.0.1""));
    }
"
"    @Test
    public void propertiesWithDefaultPort() {
        final PropertiesEndpointGroup endpointGroupA = PropertiesEndpointGroup.builder(PROPS, ""serverA.hosts"")
                                                                              .defaultPort(80)
                                                                              .build();
        final PropertiesEndpointGroup endpointGroupB = PropertiesEndpointGroup.builder(PROPS, ""serverB.hosts"")
                                                                              .defaultPort(8080)
                                                                              .build();

        assertThat(endpointGroupA.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                         Endpoint.parse(""127.0.0.1:8081""),
                                                                         Endpoint.parse(""127.0.0.1:80""));
        assertThat(endpointGroupB.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8082""),
                                                                         Endpoint.parse(""127.0.0.1:8083""));
    }
"
"    @Test
    public void resourceWithoutDefaultPort() {
        final PropertiesEndpointGroup endpointGroup = PropertiesEndpointGroup.of(
                getClass().getClassLoader(), ""server-list.properties"", ""serverA.hosts"");

        assertThat(endpointGroup.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                        Endpoint.parse(""127.0.0.1:8081""),
                                                                        Endpoint.parse(""127.0.0.1""));
    }
"
"    @Test
    public void resourceWithDefaultPort() {
        final PropertiesEndpointGroup endpointGroupA =
                PropertiesEndpointGroup.builder(getClass().getClassLoader(),
                                                ""server-list.properties"",
                                                ""serverA.hosts"")
                                       .defaultPort(80)
                                       .build();

        final PropertiesEndpointGroup endpointGroupB =
                PropertiesEndpointGroup.builder(getClass().getClassLoader(),
                                                ""server-list.properties"",
                                                ""serverB.hosts"")
                                       .defaultPort(8080)
                                       .build();

        assertThat(endpointGroupA.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                         Endpoint.parse(""127.0.0.1:8081""),
                                                                         Endpoint.parse(""127.0.0.1:80""));
        assertThat(endpointGroupB.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8082""),
                                                                         Endpoint.parse(""127.0.0.1:8083""));
    }
"
"    @Test
    public void pathWithDefaultPort() throws Exception {
        final URL resourceUrl = getClass().getClassLoader().getResource(""server-list.properties"");
        assert resourceUrl != null;
        final Path resourcePath = new File(resourceUrl.getFile()).toPath();
        final PropertiesEndpointGroup endpointGroupA = PropertiesEndpointGroup.builder(
                resourcePath, ""serverA.hosts"").defaultPort(80).build();
        assertThat(endpointGroupA.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                         Endpoint.parse(""127.0.0.1:8081""),
                                                                         Endpoint.parse(""127.0.0.1:80""));
        endpointGroupA.close();
    }
"
"    @Test
    public void pathWithoutDefaultPort() {
        final URL resourceUrl = getClass().getClassLoader().getResource(""server-list.properties"");
        assert resourceUrl != null;
        final Path resourcePath = new File(resourceUrl.getFile()).toPath();
        final PropertiesEndpointGroup endpointGroup = PropertiesEndpointGroup.of(
                resourcePath, ""serverA.hosts"");
        assertThat(endpointGroup.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                        Endpoint.parse(""127.0.0.1:8081""),
                                                                        Endpoint.parse(""127.0.0.1""));
        endpointGroup.close();
    }
"
"    @Test
    public void testWithPrefixThatEndsWithDot() {
        final PropertiesEndpointGroup endpointGroup = PropertiesEndpointGroup.of(
                getClass().getClassLoader(), ""server-list.properties"", ""serverA.hosts."");

        assertThat(endpointGroup.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                        Endpoint.parse(""127.0.0.1:8081""),
                                                                        Endpoint.parse(""127.0.0.1""));
    }
"
"    @Test
    public void containsNoHosts() {
        assertThat(PropertiesEndpointGroup.builder(getClass().getClassLoader(),
                                                   ""server-list.properties"", ""serverC.hosts"")
                                          .defaultPort(8080)
                                          .build()
                                          .endpoints()).isEmpty();
    }
"
"    @Test
    public void illegalDefaultPort() {
        assertThatThrownBy(() -> PropertiesEndpointGroup.builder(getClass().getClassLoader(),
                                                                 ""server-list.properties"", ""serverA.hosts"")
                                                        .defaultPort(0))
                .isInstanceOf(IllegalArgumentException.class)
                .hasMessageContaining(""defaultPort"");
    }
"
"    @Test
    public void propertiesFileUpdatesCorrectly() throws Exception {
        final File file = folder.newFile(""temp-file.properties"");

        PrintWriter printWriter = new PrintWriter(file);
        Properties props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.store(printWriter, """");
        printWriter.close();

        final PropertiesEndpointGroup endpointGroupA = PropertiesEndpointGroup.of(
                file.toPath(), ""serverA.hosts"");

        await().untilAsserted(() -> assertThat(endpointGroupA.endpoints()).hasSize(1));

        // Update resource
        printWriter = new PrintWriter(file);
        props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.setProperty(""serverA.hosts.1"", ""127.0.0.1:8081"");
        props.store(printWriter, """");
        printWriter.close();

        await().untilAsserted(() -> assertThat(endpointGroupA.endpoints()).hasSize(2));

        endpointGroupA.close();
    }
"
"    @Test
    public void duplicateResourceUrl() throws IOException {
        final File file = folder.newFile(""temp-file.properties"");
        final PropertiesEndpointGroup propertiesEndpointGroupA =
                PropertiesEndpointGroup.of(file.toPath(), ""serverA.hosts"");
        final PropertiesEndpointGroup propertiesEndpointGroupB =
                PropertiesEndpointGroup.of(file.toPath(), ""serverA.hosts"");
        propertiesEndpointGroupA.close();
        propertiesEndpointGroupB.close();
    }
"
"    @Test
    public void propertiesFileRestart() throws Exception {
        final File file = folder.newFile(""temp-file.properties"");

        PrintWriter printWriter = new PrintWriter(file);
        Properties props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.store(printWriter, """");
        printWriter.close();

        final PropertiesEndpointGroup endpointGroupA = PropertiesEndpointGroup.of(
                file.toPath(), ""serverA.hosts"");
        await().untilAsserted(() -> assertThat(endpointGroupA.endpoints()).hasSize(1));
        endpointGroupA.close();

        final PropertiesEndpointGroup endpointGroupB = PropertiesEndpointGroup.of(
                file.toPath(), ""serverB.hosts"");
        await().untilAsserted(() -> assertThat(endpointGroupB.endpoints()).isEmpty());

        printWriter = new PrintWriter(file);
        props = new Properties();
        props.setProperty(""serverB.hosts.0"", ""127.0.0.1:8080"");
        props.setProperty(""serverB.hosts.1"", ""127.0.0.1:8081"");
        props.store(printWriter, """");
        printWriter.close();

        await().untilAsserted(() -> assertThat(endpointGroupB.endpoints()).hasSize(2));
        endpointGroupB.close();
    }
"
"    @Test
    public void endpointChangePropagatesToListeners() throws Exception {
        final File file = folder.newFile(""temp-file.properties"");

        PrintWriter printWriter = new PrintWriter(file);
        Properties props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.setProperty(""serverA.hosts.1"", ""127.0.0.1:8081"");
        props.store(printWriter, """");
        printWriter.close();

        final PropertiesEndpointGroup propertiesEndpointGroup = PropertiesEndpointGroup.of(
                file.toPath(), ""serverA.hosts"");
        final EndpointGroup fallbackEndpointGroup = Endpoint.of(""127.0.0.1"", 8081);
        final EndpointGroup endpointGroup = propertiesEndpointGroup.orElse(fallbackEndpointGroup);

        await().untilAsserted(() -> assertThat(endpointGroup.endpoints()).hasSize(2));

        printWriter = new PrintWriter(file);
        props = new Properties();
        props.store(printWriter, """");
        printWriter.close();

        await().untilAsserted(() -> assertThat(endpointGroup.endpoints()).hasSize(1));

        printWriter = new PrintWriter(file);
        props = new Properties();
        props.setProperty(""serverA.hosts.0"", ""127.0.0.1:8080"");
        props.setProperty(""serverA.hosts.1"", ""127.0.0.1:8081"");
        props.setProperty(""serverA.hosts.2"", ""127.0.0.1:8082"");
        props.store(printWriter, """");
        printWriter.close();

        await().untilAsserted(() -> assertThat(endpointGroup.endpoints()).hasSize(3));
        propertiesEndpointGroup.close();
    }
"
"    @Test
    public void ipV4Only() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""foo.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""foo.com."", ""1.1.1.1""))
                                         .addRecord(ANSWER, newAddressRecord(""unrelated.com"", ""1.2.3.4"")),
                new DefaultDnsQuestion(""foo.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""foo.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""foo.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_ONLY)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""foo.com"", 8080).withIpAddr(""1.1.1.1""));
            }
        }
    }
"
"    @Test
    public void ipV6Only() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""bar.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""bar.com."", ""1.1.1.1"")),
                new DefaultDnsQuestion(""bar.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""bar.com."", ""::1""))
                                         .addRecord(ANSWER, newAddressRecord(""bar.com."", ""::1234:5678:90ab""))
                                         .addRecord(ANSWER, newAddressRecord(""bar.com."",
                                                                             ""2404:6800:4004:806::2013""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""bar.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV6_ONLY)
                                                .build()) {

                assertThat(group.whenReady().get(10, TimeUnit.SECONDS)).containsExactly(
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""2404:6800:4004:806::2013""),
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""::1""),
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""::1234:5678:90ab""));
            }
        }
    }
"
"    @Test
    public void ipV4AndIpV6() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""baz.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""baz.com."", ""1.1.1.1"")),
                new DefaultDnsQuestion(""baz.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""baz.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""baz.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""baz.com"", 8080).withIpAddr(""1.1.1.1""),
                        Endpoint.of(""baz.com"", 8080).withIpAddr(""::1""));
            }
        }
    }
"
"    @Test
    public void platformDefault() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""baz.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""baz.com."", ""1.1.1.1"")),
                new DefaultDnsQuestion(""baz.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""baz.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""baz.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .build()) {

                assertThat(group.whenReady().get()).contains(
                        Endpoint.of(""baz.com"", 8080).withIpAddr(""1.1.1.1""));
            }
        }
    }
"
"    @Test
    public void cname() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""a.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newBadAddressRecord(""a.com."", true))
                                         .addRecord(ANSWER, newCnameRecord(""a.com."", ""b.com.""))
                                         .addRecord(ANSWER, newAddressRecord(""b.com."", ""1.1.1.1"")),
                new DefaultDnsQuestion(""a.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newBadAddressRecord(""a.com."", false))
                                         .addRecord(ANSWER, newCnameRecord(""a.com."", ""b.com.""))
                                         .addRecord(ANSWER, newAddressRecord(""b.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""a.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""a.com"", 8080).withIpAddr(""1.1.1.1""),
                        Endpoint.of(""a.com"", 8080).withIpAddr(""::1""));
            }
        }
    }
"
"    @Test
    public void mixedLoopbackAddresses() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""foo.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""foo.com."", ""127.0.0.1"")),
                new DefaultDnsQuestion(""foo.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""foo.com."", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""foo.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""foo.com"", 8080).withIpAddr(""127.0.0.1""));
            }
        }
    }
"
"    @Test
    public void ipV4MappedOrCompatibleAddresses() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""bar.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newCompatibleAddressRecord(""bar.com."", ""1.1.1.1""))
                                         .addRecord(ANSWER, newCompatibleAddressRecord(""bar.com."", ""1.1.1.2""))
                                         .addRecord(ANSWER, newMappedAddressRecord(""bar.com."", ""1.1.1.1""))
                                         .addRecord(ANSWER, newMappedAddressRecord(""bar.com."", ""1.1.1.3""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""bar.com"")
                                                .port(8080)
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV6_ONLY)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""1.1.1.1""),
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""1.1.1.2""),
                        Endpoint.of(""bar.com"", 8080).withIpAddr(""1.1.1.3""));
            }
        }
    }
"
"    @Test
    public void noPort() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""no-port.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""no-port.com"", ""1.1.1.1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""no-port.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_ONLY)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""no-port.com"").withIpAddr(""1.1.1.1""));
            }
        }
    }
"
"    @Test
    public void backoff() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of())) { // Respond nothing.
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""backoff.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .backoff(Backoff.fixed(500))
                                                .build()) {

                await().untilAsserted(() -> assertThat(group.attemptsSoFar).isGreaterThan(2));
                assertThat(group.endpoints()).isEmpty();

                // Start to respond correctly.
                server.setResponses(ImmutableMap.of(
                        new DefaultDnsQuestion(""backoff.com."", A),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""backoff.com"", ""1.1.1.1"", 1)),
                        new DefaultDnsQuestion(""backoff.com."", AAAA),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""backoff.com"", ""::1"", 1))));

                await().untilAsserted(() -> assertThat(group.endpoints()).containsExactly(
                        Endpoint.of(""backoff.com"").withIpAddr(""1.1.1.1""),
                        Endpoint.of(""backoff.com"").withIpAddr(""::1"")));
            }
        }
    }
"
"    @Test
    public void backoffOnEmptyResponse() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                // Respond with empty records.
                new DefaultDnsQuestion(""empty.com."", A), new DefaultDnsResponse(0),
                new DefaultDnsQuestion(""empty.com."", AAAA), new DefaultDnsResponse(0)
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""empty.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .backoff(Backoff.fixed(500))
                                                .build()) {

                await().untilAsserted(() -> assertThat(group.attemptsSoFar).isGreaterThan(2));
                assertThat(group.endpoints()).isEmpty();

                // Start to respond correctly.
                server.setResponses(ImmutableMap.of(
                        new DefaultDnsQuestion(""empty.com."", A),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""empty.com"", ""1.1.1.1"", 1)),
                        new DefaultDnsQuestion(""empty.com."", AAAA),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""empty.com"", ""::1"", 1))));

                await().untilAsserted(() -> assertThat(group.endpoints()).containsExactly(
                        Endpoint.of(""empty.com"").withIpAddr(""1.1.1.1""),
                        Endpoint.of(""empty.com"").withIpAddr(""::1"")));
            }
        }
    }
"
"    @ParameterizedTest
    public void partialIpV4Response(ResolvedAddressTypes resolvedAddressTypes) throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                // Respond A record only.
                // Respond with NXDOMAIN for AAAA.
                new DefaultDnsQuestion(""partial.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""partial.com"", ""1.1.1.1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""partial.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(resolvedAddressTypes)
                                                .backoff(Backoff.fixed(500))
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""partial.com"").withIpAddr(""1.1.1.1""));
            }
        }
    }
"
"    @ParameterizedTest
    public void partialIpV6Response(ResolvedAddressTypes resolvedAddressTypes) throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                // Respond AAAA record only.
                // Respond with NXDOMAIN for A.
                new DefaultDnsQuestion(""partial.com."", AAAA),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""partial.com"", ""::1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""partial.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(resolvedAddressTypes)
                                                .backoff(Backoff.fixed(500))
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""partial.com"").withIpAddr(""::1""));
            }
        }
    }
"
"    @Test
    public void srv() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""foo.com."", SRV),
                new DefaultDnsResponse(0).addRecord(ANSWER, newSrvRecord(""foo.com."", 1, 2, ""a.foo.com.""))
                                         .addRecord(ANSWER, newSrvRecord(""foo.com."", 3, 4, ""b.foo.com.""))
                                         .addRecord(ANSWER, newSrvRecord(""unrelated.com."", 0, 0, ""asdf.com.""))
                                         .addRecord(ANSWER, newTooShortSrvRecord(""foo.com.""))
                                         .addRecord(ANSWER, newBadNameSrvRecord(""foo.com.""))
        ))) {
            try (DnsServiceEndpointGroup group =
                         DnsServiceEndpointGroup.builder(""foo.com"")
                                                .serverAddresses(server.addr())
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""a.foo.com"", 2).withWeight(1),
                        Endpoint.of(""b.foo.com"", 4).withWeight(3));
            }
        }
    }
"
