id,project,test_name,full_code,label,category
91393,OpenLCB_OpenLCB_Java,JdomCdiReaderTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        JdomCdiReader t = new JdomCdiReader();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
118766,netty_netty,ByteBufUtilTest.testDecodeUsAscii,"    @Test
    public void testDecodeUsAscii() {
        testDecodeString(""This is a test"", CharsetUtil.US_ASCII);
    }
",non-flaky,5
33901,apache_camel,FhirReadIT.testResourceByUrlAndStringResource,"    @Test
    public void testResourceByUrlAndStringResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.resourceClass"", ""Patient"");
        // parameter type is String
        headers.put(""CamelFhir.url"", this.patient.getId());

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_URL_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
110142,Wikidata_wikidata-toolkit,ClientConfigurationTest.testReportArgumentsLong,"	@Test
	public void testReportArgumentsLong() {
		String[] args = new String[] { ""--report"", ""output/report.txt"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertEquals(""output/report.txt"", config.getReportFileName());
	}
",non-flaky,5
96950,apache_avro,TestAvroCharSequenceComparator.testCompareUtf8,"  @Test
  public void testCompareUtf8() {
    assertEquals(0, mComparator.compare(new Utf8(""""), new Utf8("""")));
    assertThat(mComparator.compare(new Utf8(""""), new Utf8(""a"")), lessThan(0));
    assertThat(mComparator.compare(new Utf8(""a""), new Utf8("""")), greaterThan(0));

    assertEquals(0, mComparator.compare(new Utf8(""a""), new Utf8(""a"")));
    assertThat(mComparator.compare(new Utf8(""a""), new Utf8(""b"")), lessThan(0));
    assertThat(mComparator.compare(new Utf8(""b""), new Utf8(""a"")), greaterThan(0));

    assertEquals(0, mComparator.compare(new Utf8(""ab""), new Utf8(""ab"")));
    assertThat(mComparator.compare(new Utf8(""a""), new Utf8(""aa"")), lessThan(0));
    assertThat(mComparator.compare(new Utf8(""aa""), new Utf8(""a"")), greaterThan(0));

    assertThat(mComparator.compare(new Utf8(""abc""), new Utf8(""abcdef"")), lessThan(0));
    assertThat(mComparator.compare(new Utf8(""abcdef""), new Utf8(""abc"")), greaterThan(0));
  }
",non-flaky,5
33906,apache_camel,TouchProducerIntegrationIT.configure,"    @Test
            public void configure() {
                from(""direct:start"").to(""beanstalk:"" + tubeName + ""?command=touch"").to(""mock:result"");
            }
",non-flaky,5
30929,camunda-cloud_zeebe,MsgPackReadingBoundaryCheckingExceptionTest.shouldNotReadNegativeValue,"  @Test
  public void shouldNotReadNegativeValue() {
    // given
    final DirectBuffer negativeTestingBuf = new UnsafeBuffer(testingBuf);
    reader.wrap(negativeTestingBuf, 0, negativeTestingBuf.capacity());

    // then
    exception.expect(MsgpackReaderException.class);
    exception.expectMessage(exceptionMessage);

    // when
    codeUnderTest.accept(reader);
  }
",non-flaky,5
112631,tbsalling_aismessages,AISMessageTest.isSerializable,"    @Test
    public void isSerializable() {
        // Type 1
        assertTrue(isSerializable(AISMessage.create(
            NMEAMessage.fromString(""!BSVDM,1,1,,A,1:02Ih001U0d=V:Op85<2aT>0<0F,0*3B"")
        )));

        // Type 4
        assertTrue(isSerializable(AISMessage.create(
            NMEAMessage.fromString(""!AIVDM,1,1,,B,4h3Ovk1udp6I9o>jPHEdjdW000S:,0*0C"")
        )));

        // Type 5
        assertTrue(isSerializable(AISMessage.create(
            NMEAMessage.fromString(""!BSVDM,2,1,5,A,5:02Ih01WrRsEH57J20H5P8u8N222222222222167H66663k085QBS1H,0*55""),
            NMEAMessage.fromString(""!BSVDM,2,2,5,A,888888888888880,2*38"")
        )));
    }
",non-flaky,5
98084,vert-x3_vertx-mongo-client,WriteConcernParserTest.testConnStringNoWriteConcern,"  @Test
  public void testConnStringNoWriteConcern() {
    final ConnectionString connString = new ConnectionString(""mongodb://localhost:27017/mydb?replicaSet=myapp"");
    WriteConcern rp = new WriteConcernParser(connString, new JsonObject()).writeConcern();
    assertNull(rp);
  }
",non-flaky,5
78234,apache_beam,SimplePushbackSideInputDoFnRunnerTest.processElementSideInputNotReadyMultipleWindows,"  @Test
  public void processElementSideInputNotReadyMultipleWindows() {
    when(reader.isReady(Mockito.eq(singletonView), Mockito.any(BoundedWindow.class)))
        .thenReturn(false);

    SimplePushbackSideInputDoFnRunner<Integer, Integer> runner =
        createRunner(ImmutableList.of(singletonView));

    WindowedValue<Integer> multiWindow =
        WindowedValue.of(
            2,
            new Instant(-2),
            ImmutableList.of(
                new IntervalWindow(new Instant(-500L), new Instant(0L)),
                new IntervalWindow(BoundedWindow.TIMESTAMP_MIN_VALUE, new Instant(250L)),
                GlobalWindow.INSTANCE),
            PaneInfo.ON_TIME_AND_ONLY_FIRING);
    Iterable<WindowedValue<Integer>> multiWindowPushback =
        runner.processElementInReadyWindows(multiWindow);
    assertThat(multiWindowPushback, equalTo(multiWindow.explodeWindows()));
    assertThat(underlying.inputElems, emptyIterable());
  }
",non-flaky,5
177190,line_armeria,RequestContextCurrentTraceContextTest.newScope_canClearScope,"    @Test
    public void newScope_canClearScope() {
        try (SafeCloseable requestContextScope = ctx.push()) {
            try (Scope traceContextScope = currentTraceContext.newScope(traceContext)) {
                try (Scope traceContextScope2 = currentTraceContext.newScope(null)) {
                    assertThat(currentTraceContext.get()).isNull();
                }
                assertThat(currentTraceContext.get()).isEqualTo(traceContext);
            }
        }
    }
",non-flaky,5
97961,ReactiveX_RxJava,IntervalDemo.call,"	@Test public void demoInterval() throws Exception {
	public void testLongObservable(Observable<Long> o, final String testname) throws Exception {
		final List<Long> l = new ArrayList<Long>();
		Action1<Long> onNext = new Action1<Long>() {
			public void call(Long i) { 
				l.add(i);
				System.out.println(testname + "" got "" + i);
			}
",non-flaky,5
98394,ONSdigital_rm-collection-exercise-service,MandatoryEventValidatorTest.testMandatoryEventsCannotBeChangedIfCollectionExerciseIsReadyForLive,"  @Test
  public void testMandatoryEventsCannotBeChangedIfCollectionExerciseIsReadyForLive() {
    final List<Event> events = new ArrayList<>();

    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now().plus(1, ChronoUnit.MINUTES)));

    CTPException actualException = null;
    try {
      mandatoryValidator.validate(events, mpsEvent, CollectionExerciseState.READY_FOR_LIVE);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Mandatory events cannot be changed if collection exercise is set to live, executed, validated or locked"",
        actualException.getMessage());
  }
",non-flaky,5
92658,apache_dubbo,RegistryConfigTest.testVersion,"    @Test
    public void testVersion() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setVersion(""1.0.0"");
        assertThat(registry.getVersion(), equalTo(""1.0.0""));
    }
",non-flaky,5
26711,MundaneImmortal_pair-distribution-app,PairTest.testEqualDifferentPairs,"	@Test
	public void testEqualDifferentPairs()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev2"")));
		
		assertThat(subject.equals(subject2), is(false));
	}
",non-flaky,5
98089,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.one_should_be_able_to_enable_ssl_support_via_config_property,"  @Test
  public void one_should_be_able_to_enable_ssl_support_via_config_property() {
    // given
    final JsonObject withSSLEnabled = new JsonObject().put(""ssl"", true);

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLEnabled).settings().getSslSettings();

    // then
    assertTrue(sslSettings.isEnabled());
  }
",non-flaky,5
177981,aosp-mirror_platform_frameworks_support,BidiFormatterTest.testBuilderIsRtlContext,"    @Test
    public void testBuilderIsRtlContext() {
        assertEquals(false, new BidiFormatter.Builder(false).build().isRtlContext());
        assertEquals(true, new BidiFormatter.Builder(true).build().isRtlContext());
    }
",non-flaky,5
136472,doanduyhai_Achilles,TestEntityWithDSESearch.should_search_numeric_gte_and_lte,"    @Test
    public void should_search_numeric_gte_and_lte() throws Exception {
        //Given

        //When
        final List<EntityWithDSESearch> actual = manager
                .indexed()
                .select()
                .allColumns_FromBaseTable()
                .where()
                .numeric().Gte_And_Lte(87.39f, 138.47f)
                .getList();

        //Then
        assertThat(actual).hasSize(3);
        assertThat(actual.stream().map(EntityWithDSESearch::getNumeric).collect(toList()))
                .contains(87.39f, 100.03f, 138.47f);
    }
",non-flaky,5
162408,testcontainers_testcontainers-java,OutputStreamTest.testToStringConsumer,"    @Test
    public void testToStringConsumer() throws TimeoutException {

        WaitingConsumer waitingConsumer = new WaitingConsumer();
        ToStringConsumer toStringConsumer = new ToStringConsumer();

        Consumer<OutputFrame> composedConsumer = toStringConsumer.andThen(waitingConsumer);
        container.followOutput(composedConsumer);

        waitingConsumer.waitUntilEnd(30, TimeUnit.SECONDS);

        String utf8String = toStringConsumer.toUtf8String();
        assertTrue(""the expected first value was found"", utf8String.contains(""seq=1""));
        assertTrue(""the expected last value was found"", utf8String.contains(""seq=4""));
        assertFalse(""a non-expected value was found"", utf8String.contains(""seq=42""));
    }
",non-flaky,5
179425,abel533_Mapper,ColumnTypeTest.testColumn,"    @Test
    public void testColumn(){
        EntityHelper.initEntityNameMap(UserColumn.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserColumn.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""user_name"", column.getColumn());
            Assert.assertEquals(""name"", column.getProperty());

            Assert.assertEquals(""user_name = #{name}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""user_name = #{record.name}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{name}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.name}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.name}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.namesuffix},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[USER_NAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""user_name"", resultMapping.getColumn());
        Assert.assertEquals(""name"", resultMapping.getProperty());
        Assert.assertNull(resultMapping.getJdbcType());
        Assert.assertEquals(StringTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
",non-flaky,5
114035,aws_aws-sdk-java-v2,MyDynamoDbStreamsFunctionTest.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        MyDynamoDbStreamsFunction function = new MyDynamoDbStreamsFunction();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
306,apache_hadoop,TestRpcProgramNfs3.testWrite,"  @Test(timeout = 60000)
  public void testWrite() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(""/tmp/bar"");
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);

    byte[] buffer = new byte[10];
    for (int i = 0; i < 10; i++) {
      buffer[i] = (byte) i;
    }

    WRITE3Request writeReq = new WRITE3Request(handle, 0, 10,
        WriteStableHow.DATA_SYNC, ByteBuffer.wrap(buffer));
    XDR xdr_req = new XDR();
    writeReq.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    WRITE3Response response1 = nfsd.write(xdr_req.asReadOnlyWrap(),
        null, 1, securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code:"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    WRITE3Response response2 = nfsd.write(xdr_req.asReadOnlyWrap(),
        null, 1, securityHandler,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect response:"", null, response2);
  }
",non-flaky,5
60910,apache_druid,PostAveragerAggregatorCalculatorTest.testApply,"  @Test
  public void testApply()
  {
    event.put(""count"", 10.0);
    event.put(""avgCount"", 12.0);

    Row result = pac.apply(row);

    Assert.assertEquals(10.0f / 12.0f, result.getMetric(""avgCountRatio"").floatValue(), 0.0);
  }
",non-flaky,5
179481,abel533_Mapper,SafeUpdateByMethodTest.testSafeUpdate,"    @Test(expected = PersistenceException.class)
    public void testSafeUpdate() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.updateByExample(new Country(), new Example(Country.class));
        } finally {
            sqlSession.close();
        }
    }
",non-flaky,5
156143,soot-oss_soot,ClassRenamerTest.getDependencies,"  @Test
  public void getDependencies() {
    assertThat(ClassRenamer.v().getDependencies(), equalTo(new String[] { ClassRenamer.name }));
  }
",non-flaky,5
38284,palantir_atlasdb,AbstractTransactionTest.testKeyValueRangeReverse,"    @Test
    public void testKeyValueRangeReverse() {
        if (!supportsReverse()) {
            return;
        }
        putDirect(""row1"", ""col1"", """", 0);
        putDirect(""row2"", ""col1"", """", 0);
        putDirect(""row2"", ""col2"", """", 0);

        RangeRequest allRange = RangeRequest.reverseBuilder().batchHint(3).build();
        ClosableIterator<RowResult<Value>> range = keyValueService.getRange(TEST_TABLE, allRange, 1);
        ImmutableList<RowResult<Value>> list = ImmutableList.copyOf(range);
        assertEquals(2, list.size());
        assertEquals(""row2"", PtBytes.toString(list.iterator().next().getRowName()));
    }
",non-flaky,5
122582,vespa-engine_vespa,EditorTest.noop,"    @Test
    public void noop() {
        path.writeUtf8File(""line\n"");

        LineEditor lineEditor = mock(LineEditor.class);
        when(lineEditor.edit(any())).thenReturn(LineEdit.none());

        Editor editor = new Editor(path.toPath(), lineEditor);
        TaskContext context = mock(TaskContext.class);

        assertFalse(editor.converge(context));

        verify(lineEditor, times(1)).edit(any());

        // Verify the system modification message
        verify(context, times(0)).recordSystemModification(any(), any());

        // Verify same contents
        assertEquals(""line\n"", path.readUtf8File());
    }
",non-flaky,5
77473,opensearch-project_OpenSearch,ClusterApplierServiceTests.onSuccess,"    @TestLogging(value = ""org.opensearch.cluster.service:WARN"", reason = ""to ensure that we log cluster state events on WARN level"")
    public void testLongClusterStateUpdateLogging() throws Exception {
        MockLogAppender mockAppender = new MockLogAppender();
        mockAppender.start();
        mockAppender.addExpectation(
                new MockLogAppender.UnseenEventExpectation(
                        ""test1 shouldn't see because setting is too low"",
                        ClusterApplierService.class.getCanonicalName(),
                        Level.WARN,
                        ""*cluster state applier task [test1] took [*] which is above the warn threshold of *""));
        mockAppender.addExpectation(
                new MockLogAppender.SeenEventExpectation(
                        ""test2"",
                        ClusterApplierService.class.getCanonicalName(),
                        Level.WARN,
                        ""*cluster state applier task [test2] took [32s] which is above the warn threshold of [*]: "" +
                            ""[running task [test2]] took [*""));
        mockAppender.addExpectation(
                new MockLogAppender.SeenEventExpectation(
                        ""test4"",
                        ClusterApplierService.class.getCanonicalName(),
                        Level.WARN,
                        ""*cluster state applier task [test3] took [34s] which is above the warn threshold of [*]: "" +
                            ""[running task [test3]] took [*""));

        Logger clusterLogger = LogManager.getLogger(ClusterApplierService.class);
        Loggers.addAppender(clusterLogger, mockAppender);
        try {
            final CountDownLatch latch = new CountDownLatch(4);
            final CountDownLatch processedFirstTask = new CountDownLatch(1);
            clusterApplierService.currentTimeOverride = threadPool.relativeTimeInMillis();
            clusterApplierService.runOnApplierThread(""test1"",
                currentState -> clusterApplierService.currentTimeOverride += TimeValue.timeValueSeconds(1).millis(),
                new ClusterApplyListener() {
                    @Override
                    public void onSuccess(String source) {
                        latch.countDown();
                        processedFirstTask.countDown();
                    }
",non-flaky,5
98635,nutzam_nutz,SimpleAdaptorTest.test_err_param_with_pathargs,"    @Test
    public void test_err_param_with_pathargs() {
        get(""/adaptor/err/param/pathargs/a?id=ABC"");
        assertEquals(200, resp.getStatus());

        get(""/adaptor/err/param/pathargs/a/ABC"");
        assertEquals(200, resp.getStatus());
    }
",non-flaky,5
97957,ReactiveX_RxJava,ConcatTests.testConcatCovariance,"    @Test
    public void testConcatCovariance() {
        Observable<Media> o1 = Observable.<Media> from(new HorrorMovie(), new Movie());
        Observable<Media> o2 = Observable.from(new Media(), new HorrorMovie());

        Observable<Observable<Media>> os = Observable.from(o1, o2);

        List<Media> values = Observable.concat(os).toList().toBlockingObservable().single();
    }
",non-flaky,5
162692,OpenAPITools_openapi-generator,TypeHolderDefaultTest.arrayItemTest,"    @Test
    public void arrayItemTest() {
        // TODO: test arrayItem
    }
",non-flaky,5
160424,ConsenSys_teku,ValidatorDataProviderTest.setup,"  @TestTemplate
  public void setup(SpecContext specContext) {
    spec = specContext.getSpec();
    dataStructureUtil = specContext.getDataStructureUtil();
    schemaProvider = new SchemaObjectProvider(spec);
    provider = new ValidatorDataProvider(spec, validatorApiChannel, combinedChainDataClient);
    blockInternal = dataStructureUtil.randomBeaconBlock(123);
    block = schemaProvider.getBeaconBlock(blockInternal);
  }
",non-flaky,5
110191,Wikidata_wikidata-toolkit,RdfConverterTest.testWriteStatementRankTriple,"	@Test
	public void testWriteStatementRankTriple() throws RDFHandlerException,
			RDFParseException, IOException {
		StatementRank rank = StatementRank.DEPRECATED;
		Resource subject = this.rdfFactory
				.createIRI(""http://www.wikidata.org/Q10Snone"");
		this.rdfConverter.writeStatementRankTriple(subject, rank);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""StatementRankTriple.rdf"")), model);
	}
",non-flaky,5
136462,doanduyhai_Achilles,TestEntityWithDSESearch.should_search_text_using_suffix,"    @Test
    public void should_search_text_using_suffix() throws Exception {
        //Given

        //When
        final List<EntityWithDSESearch> actual = manager
                .indexed()
                .select()
                .allColumns_FromBaseTable()
                .where()
                .string().EndWith(""run"")
                .getList();

        //Then
        assertThat(actual).hasSize(2);
        assertThat(actual.stream().map(EntityWithDSESearch::getString).collect(toList()))
                .contains(""long run"", ""speedrun"");
    }
",non-flaky,5
354,apache_struts,13d9053050c9e4fb2ef049db6a37d3f6eebf48fa.testRender_ok.2,"@Test
public void testRender_ok() {
    final Mock mockResponse = mock(RenderResponse.class);
    mockResponse.stubs().method(ANYTHING);
    PortletMode mode = PortletMode.VIEW;
    Map<String, String[]> requestParams = new HashMap<String, String[]>();
    requestParams.put(ACTION_PARAM, new String[] { ""/view/testAction"" });
    requestParams.put(EVENT_ACTION, new String[] { ""true"" });
    requestParams.put(MODE_PARAM, new String[] { mode.toString() });
    Map<String, Object> sessionMap = new HashMap<String, Object>();
    Map<String, String> initParams = new HashMap<String, String>();
    initParams.put(""viewNamespace"", ""/view"");
    initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE,
    ""true"");
    initPortletConfig(initParams, new HashMap<String, Object>());
    initRequest(requestParams, new HashMap<String, Object>(), sessionMap,
    PortletMode.VIEW, WindowState.NORMAL, false, null);
    setupActionFactory(""/view"", ""testAction"", ""success"",
    EasyMock.createNiceMock(ValueStack.class));
    mockInvocation.expects(once()).method(""getStack"")
    .will(returnValue(null));
    try {
        dispatcher
        .setActionProxyFactory((ActionProxyFactory) mockActionFactory
        .proxy());
        dispatcher.init((PortletConfig) mockConfig.proxy());
        dispatcher.render((RenderRequest) mockRequest.proxy(),
        (RenderResponse) mockResponse.proxy());
    } catch (Exception e) {
        e.printStackTrace();
        fail(""Error occured"");
    }
}",test order dependency,4
110896,pushtorefresh_storio,InsertTest.insertAndDeleteTwice,"    @Test
    public void insertAndDeleteTwice() {
        final User user = TestFactory.newUser();

        for (int i = 0; i < 2; i++) {
            putUserBlocking(user);

            final List<User> existUsers = getAllUsersBlocking();

            assertThat(existUsers).isNotNull();
            assertThat(existUsers).hasSize(1);

            final Cursor cursorAfterPut = db.query(UserTableMeta.TABLE, null, null, null, null, null, null);
            assertThat(cursorAfterPut.getCount()).isEqualTo(1);
            cursorAfterPut.close();

            deleteUserBlocking(user);

            final Cursor cursorAfterDelete = db.query(UserTableMeta.TABLE, null, null, null, null, null, null);
            assertThat(cursorAfterDelete.getCount()).isEqualTo(0);
            cursorAfterDelete.close();
        }
    }
",non-flaky,5
110199,Wikidata_wikidata-toolkit,RdfConverterTest.testWriteInterPropertyLinks,"	@Test
	public void testWriteInterPropertyLinks() throws RDFHandlerException,
			RDFParseException, IOException {
		PropertyDocument document = this.dataObjectFactory.getPropertyDocument(
				this.dataObjectFactory.getPropertyIdValue(""P17"",
						""http://www.wikidata.org/""), Collections
						.<MonolingualTextValue> emptyList(), Collections
						.<MonolingualTextValue> emptyList(), Collections
						.<MonolingualTextValue> emptyList(), Collections
						.<StatementGroup> emptyList(), this.dataObjectFactory
						.getDatatypeIdValue(DatatypeIdValue.DT_ITEM), 0);
		this.rdfConverter.writeInterPropertyLinks(document);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(out.toString());

		assertEquals(RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""InterPropertyLinks.rdf"")), model);
	}
",non-flaky,5
113985,apache_struts,ConstantConfigTest.testClassesToString,"    @Test
    public void testClassesToString() throws Exception {
        ConstantConfig constantConfig = new ConstantConfig();

        Set<Class<?>> excludedClasses = new LinkedHashSet<>();
        excludedClasses.add(Object.class);
        excludedClasses.add(Runtime.class);
        excludedClasses.add(System.class);

        constantConfig.setExcludedClasses(excludedClasses);

        Map<String, String> map = constantConfig.getAllAsStringsMap();
        Assert.assertEquals(""java.lang.Object,java.lang.Runtime,java.lang.System"",
                map.get(StrutsConstants.STRUTS_EXCLUDED_CLASSES));
    }
",non-flaky,5
70828,apache_kafka,PluginDescTest.testPluginDescComparison,"    @Test
    public void testPluginDescComparison() {
        PluginDesc<Connector> connectorDescPluginPath = new PluginDesc<>(
                Connector.class,
                regularVersion,
                pluginLoader
        );

        PluginDesc<Connector> connectorDescClasspath = new PluginDesc<>(
                Connector.class,
                newerVersion,
                systemLoader
        );

        assertNewer(connectorDescPluginPath, connectorDescClasspath);

        PluginDesc<Converter> converterDescPluginPath = new PluginDesc<>(
                Converter.class,
                noVersion,
                pluginLoader
        );

        PluginDesc<Converter> converterDescClasspath = new PluginDesc<>(
                Converter.class,
                snaphotVersion,
                systemLoader
        );

        assertNewer(converterDescPluginPath, converterDescClasspath);

        PluginDesc<Transformation> transformDescPluginPath = new PluginDesc<>(
                Transformation.class,
                null,
                pluginLoader
        );

        PluginDesc<Transformation> transformDescClasspath = new PluginDesc<>(
                Transformation.class,
                regularVersion,
                systemLoader
        );

        assertNewer(transformDescPluginPath, transformDescClasspath);
    }
",non-flaky,5
159642,liquibase_liquibase,AbstractIntegrationTest.testOutputChangeLog,"    @Test
    public void testOutputChangeLog() throws Exception {
        assumeNotNull(this.getDatabase());

        StringWriter output = new StringWriter();
        Liquibase liquibase;
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter(""loginuser"", getUsername());
        liquibase.update(this.contexts, output);

        String outputResult = output.getBuffer().toString();
        assertNotNull(""generated output change log must not be empty"", outputResult);
        assertTrue(""generated output change log is at least 100 bytes long"", outputResult.length() > 100);

        // TODO should better written to a file so CI servers can pick it up as test artifacts.
        System.out.println(outputResult);
        assertTrue(""create databasechangelog command not found in: \n"" + outputResult, outputResult.contains(""CREATE TABLE ""+database.escapeTableName(database.getLiquibaseCatalogName(), database.getLiquibaseSchemaName(), database.getDatabaseChangeLogTableName())));
        assertTrue(""create databasechangeloglock command not found in: \n"" + outputResult, outputResult.contains(""CREATE TABLE ""+database.escapeTableName(database.getLiquibaseCatalogName(), database.getLiquibaseSchemaName(), database.getDatabaseChangeLogLockTableName())));

        assertTrue(""generated output contains a correctly encoded Euro sign"", outputResult.contains(""â¬""));

        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));
        assertEquals(""no database objects were actually created during creation of the output changelog"",
                0, snapshot.get(Schema.class).iterator().next().getDatabaseObjects(Table.class).size());
    }
",non-flaky,5
92642,apache_dubbo,RegistryConfigTest.testProtocol,"    @Test
    public void testProtocol() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setProtocol(""protocol"");
        assertThat(registry.getProtocol(), equalTo(registry.getProtocol()));
    }
",non-flaky,5
135024,undertow-io_undertow,Http2ClientTestCase.run,"    @Test
    public void testSimpleBasic() throws Exception {
        //
        final UndertowClient client = createClient();

        final List<ClientResponse> responses = new CopyOnWriteArrayList<>();
        final CountDownLatch latch = new CountDownLatch(10);
        final ClientConnection connection = client.connect(ADDRESS, worker, new UndertowXnioSsl(worker.getXnio(), OptionMap.EMPTY, DefaultServer.getClientSSLContext()), DefaultServer.getBufferPool(), OptionMap.create(UndertowOptions.ENABLE_HTTP2, true)).get();
        try {
            connection.getIoThread().execute(new Runnable() {
                @Override
                public void run() {
                    for (int i = 0; i < 10; i++) {
                        final ClientRequest request = new ClientRequest().setMethod(Methods.GET).setPath(MESSAGE);
                        request.getRequestHeaders().put(Headers.HOST, DefaultServer.getHostAddress());
                        connection.sendRequest(request, createClientCallback(responses, latch));
                    }
                }
",non-flaky,5
175770,GoogleCloudPlatform_google-cloud-eclipse,FlexDeployPreferencesDialogTest.testFlexPricingLabel,"  @Test
  public void testFlexPricingLabel() {
    dialog.setBlockOnOpen(false);
    dialog.open();
    Composite dialogArea = (Composite) dialog.createDialogArea(shellResource.getShell());

    assertNotNull(findGcpPricingLink(dialogArea));
  }
",non-flaky,5
98424,ONSdigital_rm-collection-exercise-service,CollectionExerciseServiceTest.testUpdateCollectionExerciseDoesNotExist,"  @Test
  public void testUpdateCollectionExerciseDoesNotExist() throws Exception {
    CollectionExerciseDTO toUpdate =
        FixtureHelper.loadClassFixtures(CollectionExerciseDTO[].class).get(0);
    UUID updateUuid = UUID.randomUUID();

    try {
      this.collectionExerciseService.updateCollectionExercise(updateUuid, toUpdate);
      fail(""Update of non-existent collection exercise succeeded"");
    } catch (CTPException e) {
      assertEquals(CTPException.Fault.RESOURCE_NOT_FOUND, e.getFault());
    }
  }
",non-flaky,5
162744,OpenAPITools_openapi-generator,CategoryTest.nameTest,"    @Test
    public void nameTest() {
        // TODO: test name
    }
",non-flaky,5
96928,apache_avro,TestSequenceFileReader.testReadSequenceFile,"  @Test
  public void testReadSequenceFile() throws Exception {
    checkFile(new SequenceFileReader<>(file()));
  }
",non-flaky,5
96870,apache_avro,TestSpecificCompiler.testSettingOutputCharacterEncoding,"  @Test
  public void testSettingOutputCharacterEncoding() throws Exception {
    SpecificCompiler compiler = createCompiler();
    // Generated file in default encoding
    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
    byte[] fileInDefaultEncoding = new byte[(int) this.outputFile.length()];
    FileInputStream is = new FileInputStream(this.outputFile);
    is.read(fileInDefaultEncoding);
    is.close(); //close input stream otherwise delete might fail
    if (!this.outputFile.delete()) {
      throw new IllegalStateException(""unable to delete "" + this.outputFile); //delete otherwise compiler might not overwrite because src timestamp hasn't changed.
    }
    // Generate file in another encoding (make sure it has different number of bytes per character)
    String differentEncoding = Charset.defaultCharset().equals(Charset.forName(""UTF-16"")) ? ""UTF-32"" : ""UTF-16"";
    compiler.setOutputCharacterEncoding(differentEncoding);
    compiler.compileToDestination(this.src, this.OUTPUT_DIR.getRoot());
    byte[] fileInDifferentEncoding = new byte[(int) this.outputFile.length()];
    is = new FileInputStream(this.outputFile);
    is.read(fileInDifferentEncoding);
    is.close();
    // Compare as bytes
    assertThat(""Generated file should contain different bytes after setting non-default encoding"",
      fileInDefaultEncoding, not(equalTo(fileInDifferentEncoding)));
    // Compare as strings
    assertThat(""Generated files should contain the same characters in the proper encodings"",
      new String(fileInDefaultEncoding), equalTo(new String(fileInDifferentEncoding, differentEncoding)));
  }
",non-flaky,5
42975,fabiomaffioletti_jsondoc,ApiMethodDocTest.testEqual,"	@Test
	public void testEqual() {
		first = new ApiMethodDoc();
		first.setPath(Sets.newHashSet(""/test""));
		first.setVerb(Sets.newHashSet(ApiVerb.GET));
		second = new ApiMethodDoc();
		second.setPath(Sets.newHashSet(""/test""));
		second.setVerb(Sets.newHashSet(ApiVerb.GET));
		Assert.assertEquals(0, first.compareTo(second));
	}
",non-flaky,5
104159,spring-cloud_spring-cloud-config,CipherEnvironmentEncryptorTests.shouldDecryptEnvironment,"	@Test
	public void shouldDecryptEnvironment() {
		// given
		String secret = randomUUID().toString();

		// when
		Environment environment = new Environment(""name"", ""profile"", ""label"");
		environment.add(new PropertySource(""a"", Collections.<Object, Object>singletonMap(
				environment.getName(), ""{cipher}"" + this.textEncryptor.encrypt(secret))));

		// then
		assertThat(this.encryptor.decrypt(environment).getPropertySources().get(0)
				.getSource().get(environment.getName())).isEqualTo(secret);
	}
",non-flaky,5
104154,spring-cloud_spring-cloud-config,EncryptionControllerTests.formDataIn,"	@Test
	public void formDataIn() {
		this.controller = new EncryptionController(
				new SingleTextEncryptorLocator(new RsaSecretEncryptor()));
		// Add space to input
		String cipher = this.controller.encrypt(""foo bar="",
				MediaType.APPLICATION_FORM_URLENCODED);
		String decrypt = this.controller.decrypt(cipher + ""="",
				MediaType.APPLICATION_FORM_URLENCODED);
		assertThat(decrypt).as(""Wrong decrypted plaintext: "" + decrypt)
				.isEqualTo(""foo bar"");
	}
",non-flaky,5
92683,apache_dubbo,ProviderConfigTest.testThreads,"    @Test
    public void testThreads() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setThreads(10);
        assertThat(provider.getThreads(), is(10));
    }
",non-flaky,5
159656,liquibase_liquibase,AbstractIntegrationTest.testRollbackToChange,"    @Test
    public void testRollbackToChange() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(rollbackChangeLog);
        wipeDatabase();

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(this.contexts);

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.rollback(8, this.contexts);

        liquibase.tag(""testRollbackToChange"");

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.update(this.contexts);

        liquibase = createLiquibase(rollbackChangeLog);
        liquibase.rollback(""testRollbackToChange"", this.contexts);
    }
",non-flaky,5
64,apache_ignite,testFlowNoConflictsWithClients,"@Test
public void testFlowNoConflictsWithClients() throws Exception {
    startComputation(0, stopFlag0);
    if (!tcpDiscovery())
    return;
    startComputation(1, stopFlag1);
    startComputation(2, stopFlag2);
    startComputation(3, stopFlag3);
    startComputation(4, stopFlag4);
    final Set<Integer> deafClientObservedIds = new ConcurrentHashSet<>();
    startListening(5, true, deafClientObservedIds);
    final Set<Integer> regClientObservedIds = new ConcurrentHashSet<>();
    startListening(6, false, regClientObservedIds);
    START_LATCH.countDown();
    Thread killer = new Thread(new ServerNodeKiller());
    Thread resurrection = new Thread(new ServerNodeResurrection());
    killer.setName(""node-killer-thread"");
    killer.start();
    resurrection.setName(""node-resurrection-thread"");
    resurrection.start();
    while (!updatesQueue.isEmpty())
    Thread.sleep(1000);
    killer.interrupt();
    resurrection.interrupt();
}",concurrency,1
156100,soot-oss_soot,AsmMethodSourceOrigNamesTest.testXNodeSet,"  @Test
  public void testXNodeSet() {
    final String clazz = ""org.apache.xpath.objects.XNodeSet"";
    final String[] params = { ""org.apache.xpath.objects.XObject"", ""org.apache.xpath.objects.Comparator"" };
    runXalanTest(prepareTarget(methodSigFromComponents(clazz, ""boolean"", ""compare"", params), clazz));
  }
",non-flaky,5
175771,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testContructor_nonAbsoluteBasePath,"  @Test
  public void testContructor_nonAbsoluteBasePath() {
    try {
      when(appYamlPath.getValue()).thenReturn(""app.yaml"");
      new AppYamlValidator(new Path(""non/absolute/base/path""), appYamlPath);
      fail();
    } catch (IllegalArgumentException ex) {
      assertEquals(""basePath is not absolute."", ex.getMessage());
    }
  }
",non-flaky,5
33909,apache_camel,ConsumerIntegrationIT.configure,"    @Test
            public void configure() {
                from(""beanstalk:"" + tubeName).to(""mock:result"");
            }
",non-flaky,5
38696,apache_pulsar,ElasticSearchSinkTests.testNullValueFailure,"    @Test(expectedExceptions = PulsarClientException.InvalidMessageException.class)
    public void testNullValueFailure() throws Exception {
        String index = ""testnullvaluefail"";
        map.put(""indexName"", index);
        map.put(""keyIgnore"", ""false"");
        map.put(""nullValueAction"", ""FAIL"");
        sink.open(map, mockSinkContext);
        MockRecordNullValue mockRecordNullValue = new MockRecordNullValue();
        sink.write(mockRecordNullValue);
    }
",non-flaky,5
133978,CorfuDB_CorfuDB,LogUnitHandlerTest.testDataCorruptionError,"    @Test
    public void testDataCorruptionError() {
        long sampleAddress = 5L;
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getDataCorruptionErrorMsg(sampleAddress)
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed exceptionally.
        verify(mockClientRouter, never()).completeRequest(anyLong(), any());
        verify(mockClientRouter).completeExceptionally(
                eq(response.getHeader().getRequestId()), any(DataCorruptionException.class));
    }
",non-flaky,5
162739,OpenAPITools_openapi-generator,ModelApiResponseTest.codeTest,"    @Test
    public void codeTest() {
        // TODO: test code
    }
",non-flaky,5
160397,ConsenSys_teku,ChainDataProviderTest.getBlockHeaders_shouldGetHeadBlockIfNoParameters,"  @Test
  public void getBlockHeaders_shouldGetHeadBlockIfNoParameters()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final tech.pegasys.teku.spec.datastructures.blocks.SignedBeaconBlock block =
        combinedChainDataClient.getBestBlock().get();
    List<BlockHeader> results = provider.getBlockHeaders(Optional.empty(), Optional.empty()).get();
    assertThat(results.get(0).root).isEqualTo(block.getRoot());
  }
",non-flaky,5
96936,apache_avro,TestWordCountTether.testJob,"  @Test
  public void testJob() throws Exception {
    _runjob(""sasl"");
  }
",non-flaky,5
35689,cdapio_cdap,TimeEventQueueProcessorTest.test,"  @Test
  public void test() throws Exception {
    LoggerContext loggerContext = LogPipelineTestUtil.createLoggerContext(""WARN"",
                                                                          ImmutableMap.of(""test.logger"", ""INFO""),
                                                                          MockAppender.class.getName());
    LogProcessorPipelineContext context = new LogProcessorPipelineContext(CConfiguration.create(),
                                                                          ""test"", loggerContext, NO_OP_METRICS_CONTEXT,
                                                                          0);
    context.start();
    TimeEventQueueProcessor<TestOffset> processor = new TimeEventQueueProcessor<>(context, 50, 1,
                                                                                  ImmutableList.of(0));
    long now = System.currentTimeMillis();
    List<ILoggingEvent> events = ImmutableList.of(
      LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""1"", now - 1000),
      LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""3"", now - 700),
      LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""5"", now - 500),
      LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""2"", now - 900),
      LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.ERROR, ""4"", now - 600),
      LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""6"", now - 100));

    ProcessedEventMetadata<TestOffset> metadata = processor.process(0, new TransformingIterator(events.iterator()));
    // all 6 events should be processed. This is because when the buffer is full after 5 events, time event queue
    // processor should append existing buffered events and enqueue 6th event
    Assert.assertEquals(6, metadata.getTotalEventsProcessed());
    for (Map.Entry<Integer, Checkpoint<TestOffset>> entry : metadata.getCheckpoints().entrySet()) {
      Checkpoint<TestOffset> value = entry.getValue();
      // offset should be max offset processed so far
      Assert.assertEquals(6, value.getOffset().getOffset());
    }
  }
",non-flaky,5
26212,Ericsson_ecchronos,TestRepairSchedulerImpl.testConfigureTwoTables,"    @Test
    public void testConfigureTwoTables()
    {
        RepairSchedulerImpl repairSchedulerImpl = defaultRepairSchedulerImplBuilder().build();

        repairSchedulerImpl.putConfiguration(TABLE_REFERENCE, RepairConfiguration.DEFAULT);
        repairSchedulerImpl.putConfiguration(TABLE_REFERENCE2, RepairConfiguration.DEFAULT);

        verify(scheduleManager, timeout(1000).times(2)).schedule(any(ScheduledJob.class));
        verify(scheduleManager, never()).deschedule(any(ScheduledJob.class));
        verify(myRepairStateFactory).create(eq(TABLE_REFERENCE), eq(RepairConfiguration.DEFAULT), any());
        verify(myRepairStateFactory).create(eq(TABLE_REFERENCE2), eq(RepairConfiguration.DEFAULT), any());
        verify(myRepairState, atLeastOnce()).update();

        repairSchedulerImpl.close();
        verify(scheduleManager, times(2)).deschedule(any(ScheduledJob.class));

        verifyNoMoreInteractions(ignoreStubs(myTableRepairMetrics));
        verifyNoMoreInteractions(myRepairStateFactory);
        verifyNoMoreInteractions(scheduleManager);
    }
",non-flaky,5
77132,networknt_json-schema-validator,Issue285Test.nestedValidation,"    @Test
    public void nestedValidation() throws IOException {
        JsonSchema jsonSchema = schemaFactory.getSchema(schemaStr);
        Set<ValidationMessage> validationMessages = jsonSchema.validate(mapper.readTree(person));

        System.err.println(""\n"" + Arrays.toString(validationMessages.toArray()));

        assertFalse(validationMessages.isEmpty());


    }
",non-flaky,5
76676,quarkusio_quarkus,CustomAuthEmbeddedBase.testSecureRoleFailure,"    @Test()
    public void testSecureRoleFailure() {
        RestAssured.given().auth().preemptive().basic(""jdoe"", ""p4ssw0rd"")
                .when().get(""/secure-test"").then()
                .statusCode(403);
    }
",non-flaky,5
110125,Wikidata_wikidata-toolkit,ClientTest.testWriteReport,"	@Test
	public void testWriteReport() throws IOException {
		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);

		MockDirectoryManager mdm = new MockDirectoryManager(
				Paths.get(""/output/""), false);

		String[] args = {""-n"", ""-a"", ""rdf"", ""--rdftasks"", ""aliases"", ""-o"",
				""/output/wikidata.rdf"", ""-r"", ""/output/report.txt"" };

		Client client = new Client(mockDpc, args);
		DumpProcessingAction action = client.clientConfiguration.actions.get(0);
		action.open();
		action.close();
		client.writeReport();
		assertTrue(IOUtils
				.toString(
						mdm.getInputStreamForFile(""report.txt"",
								CompressionType.NONE))
				.matches(
						""RdfSerializationAction: Finished serialization of \\d+ RDF triples in file /output/wikidata.rdf""
								+ System.lineSeparator()));

	}
",non-flaky,5
360,apache_hadoop,TestPeerCache.testExpiry,"@Test
public void testExpiry() throws Exception {
    final int CAPACITY = 3;
    final int EXPIRY_PERIOD = 10;
    PeerCache cache = PeerCache.getInstance(CAPACITY, EXPIRY_PERIOD);
    DatanodeID dnIds[] = new DatanodeID[CAPACITY];
    FakePeer peers[] = new FakePeer[CAPACITY];
    for (int i = 0; i < CAPACITY; ++i) {
        dnIds[i] = new DatanodeID(""192.168.0.1"",
        ""fakehostname_"" + i, ""fake_storage_id"",
        100, 101, 102);
        peers[i] = new FakePeer(dnIds[i], false);
    }
    for (int i = 0; i < CAPACITY; ++i) {
        cache.put(dnIds[i], peers[i]);
    }
    Thread.sleep(EXPIRY_PERIOD * 50);
    assertEquals(0, cache.size());
    for (int i = 0; i < CAPACITY; ++i) {
        assertTrue(peers[i].isClosed());
    }
    Thread.sleep(EXPIRY_PERIOD * 50);
    cache.close();
}",test order dependency,4
38630,apache_pulsar,TestAbstractConfigurationProvider.testChannelThrowsExceptionDuringConfiguration,"    @Test
    public void testChannelThrowsExceptionDuringConfiguration() throws Exception {
        String agentName = ""agent1"";
        String sourceType = ""seq"";
        String channelType = UnconfigurableChannel.class.getName();
        String sinkType = ""null"";
        Map<String, String> properties = getProperties(agentName, sourceType,
                channelType, sinkType);
        MemoryConfigurationProvider provider =
                new MemoryConfigurationProvider(agentName, properties);
        MaterializedConfiguration config = provider.getConfiguration();
        assertEquals(config.getSourceRunners().size(), 0);
        assertEquals(config.getChannels().size(), 0);
        assertEquals(config.getSinkRunners().size(), 0);
    }
",non-flaky,5
77175,networknt_json-schema-validator,V4JsonSchemaTest.testSchemaFromClasspath,"    @Test
    public void testSchemaFromClasspath() throws Exception {
        runTestFile(""draft4/classpath/schema.json"");
    }
",non-flaky,5
133994,CorfuDB_CorfuDB,CorfuClusterParamsTest.testFullNodeName,"    @Test
    public void testFullNodeName() {
        final String clusterName = ""mycluster"";
        final int port = ServerUtil.getRandomOpenPort();

        CorfuServerParams param = CorfuServerParams
                .serverParamsBuilder()
                .port(port)
                .clusterName(clusterName)
                .serverVersion(""1.0.0"")
                .build();

        SortedSet<CorfuServerParams> corfuServers = new TreeSet<>(Collections.singletonList(param));

        CorfuClusterParams clusterParams = CorfuClusterParams.builder()
                .name(clusterName)
                .nodes(corfuServers)
                .serverVersion(""1.0.0"")
                .build();

        String fqdn = clusterParams.getFullNodeName(""node"" + port);

        assertThat(fqdn).isEqualTo(clusterName + ""-corfu-"" + ""node"" + port);
    }
",non-flaky,5
84635,apache_zookeeper,GetAllChildrenNumberTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();

        zk.close();
    }
",non-flaky,5
353,apache_hadoop,TestNetworkTopology.testChooseRandomExcludedRack,"  @Test
  public void testChooseRandomExcludedRack() {
    Map<Node, Integer> frequency = pickNodesAtRandom(100, ""~"" + ""/d2"", null);
    // all the nodes on the second rack should be zero
    for (int j = 0; j < dataNodes.length; j++) {
      int freq = frequency.get(dataNodes[j]);
      if (dataNodes[j].getNetworkLocation().startsWith(""/d2"")) {
        assertEquals(0, freq);
      } else {
        assertTrue(freq > 0);
      }
    }
  }
",non-flaky,5
177158,line_armeria,TokenBucketThrottlingStrategyTest.throttle2,"    @Test
    public void throttle2() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle2"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isTrue();
        final long reset1 = Long.parseLong(response1.headers().get(""X-RateLimit-Reset""));
        assertThat(reset1).isBetween(0L, 10L);
        assertThat(response1.headers().get(""X-RateLimit-Limit"")).isEqualTo(""1, 1;window=10"");

        final AggregatedHttpResponse response2 = client.get(""/http-throttle2"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.TOO_MANY_REQUESTS);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER, ""15"")).isTrue();
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"", ""0"")).isTrue();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"", ""15"")).isTrue();
        assertThat(response1.headers().get(""X-RateLimit-Limit"")).isEqualTo(""1, 1;window=10"");
    }
",non-flaky,5
70837,apache_kafka,WorkerSourceTaskTest.testCommit,"    @Test
    public void testCommit() throws Exception {
        // Test that the task commits properly when prompted
        createWorkerTask();

        sourceTask.initialize(EasyMock.anyObject(SourceTaskContext.class));
        EasyMock.expectLastCall();
        sourceTask.start(TASK_PROPS);
        EasyMock.expectLastCall();
        statusListener.onStartup(taskId);
        EasyMock.expectLastCall();

        // We'll wait for some data, then trigger a flush
        final CountDownLatch pollLatch = expectPolls(1);
        expectOffsetFlush(true);

        sourceTask.stop();
        EasyMock.expectLastCall();
        expectOffsetFlush(true);

        statusListener.onShutdown(taskId);
        EasyMock.expectLastCall();

        producer.close(EasyMock.anyObject(Duration.class));
        EasyMock.expectLastCall();

        transformationChain.close();
        EasyMock.expectLastCall();

        PowerMock.replayAll();

        workerTask.initialize(TASK_CONFIG);
        Future<?> taskFuture = executor.submit(workerTask);

        assertTrue(awaitLatch(pollLatch));
        assertTrue(workerTask.commitOffsets());
        workerTask.stop();
        assertTrue(workerTask.awaitStop(1000));

        taskFuture.get();
        assertPollMetrics(1);

        PowerMock.verifyAll();
    }
",non-flaky,5
162445,testcontainers_testcontainers-java,HttpWaitStrategyTest.testWaitUntilReadyWithManyStatusCodes,"    @Test
    public void testWaitUntilReadyWithManyStatusCodes() {
        waitUntilReadyAndSucceed(startContainerWithCommand(createShellCommand(""401 UNAUTHORIZED"", GOOD_RESPONSE_BODY),
            createHttpWaitStrategy(ready)
                .forStatusCode(300)
                .forStatusCode(401)
                .forStatusCode(500)
        ));
    }
",non-flaky,5
112642,tbsalling_aismessages,BinaryBroadcastMessageTest.canDecodeMultiSentenceUnknownApplicationSpecificMessage,"    @Test
    public void canDecodeMultiSentenceUnknownApplicationSpecificMessage() {
        AISMessage aisMessage = AISMessage.create(
                NMEAMessage.fromString(""!AIVDM,2,1,8,A,803Iw60F14m1CPH4mDT4RDi@000003RP9iHb@001irBQ0@4gAaI00000261Q,0*04""),
                NMEAMessage.fromString(""!AIVDM,2,2,8,A,pGp07IiTPi@BkU5pSwrrbs8219RW=R19RV=R19RVER19RVKtDb>jq20000>4,0*47"")
        );

        System.out.println(aisMessage.toString());

        assertEquals(88, ((BinaryBroadcastMessage) aisMessage).getDesignatedAreaCode().intValue());
        assertEquals(4, ((BinaryBroadcastMessage) aisMessage).getFunctionalId().intValue());
        assertEquals(UnknownApplicationSpecificMessage.class, ((BinaryBroadcastMessage) aisMessage).getApplicationSpecificMessage().getClass());
    }
",non-flaky,5
178026,aosp-mirror_platform_frameworks_support,ListRowDataAdapterTest.adapterSize_visibleRowRemoved,"    @Test
    public void adapterSize_visibleRowRemoved() {
        int itemCount = 4;
        ArrayObjectAdapter adapter = new ArrayObjectAdapter(presenterSelector);
        adapter.add(new SectionRow(""section 1""));
        for (int i = 0; i < itemCount; i++) {
            HeaderItem headerItem = new HeaderItem(i, ""header ""+i);
            adapter.add(new ListRow(headerItem, createListRowAdapter()));
        }

        ListRowDataAdapter listRowDataAdapter = new ListRowDataAdapter(adapter);
        assertEquals(5, listRowDataAdapter.size());
        adapter.add(new DividerRow());
        assertEquals(5, listRowDataAdapter.size());

        listRowDataAdapter.registerObserver(dataObserver);
        adapter.removeItems(2, 2);
        verify(dataObserver, times(1)).onItemRangeRemoved(2, 2);
        assertEquals(3, listRowDataAdapter.size());
    }
",non-flaky,5
76946,Tencent_Firestorm,ShuffleReadClientImplTest.readTest7,"  @Test
  public void readTest7() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest7"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<Long, byte[]> expectedData1 = Maps.newHashMap();
    Map<Long, byte[]> expectedData2 = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 10, 30, 0, expectedData1, blockIdBitmap1);

    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    writeTestData(writeHandler, 10, 30, 0, expectedData2, blockIdBitmap2);

    writeTestData(writeHandler, 10, 30, 0, expectedData1, blockIdBitmap1);

    ShuffleReadClientImpl readClient1 = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 0, 100, 2, 10, 100,
        basePath, blockIdBitmap1, taskIdBitmap, Lists.newArrayList(), new Configuration());
    ShuffleReadClientImpl readClient2 = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 100,
        basePath, blockIdBitmap2, taskIdBitmap, Lists.newArrayList(), new Configuration());
    TestUtils.validateResult(readClient1, expectedData1);
    readClient1.checkProcessedBlockIds();
    readClient1.close();

    TestUtils.validateResult(readClient2, expectedData2);
    readClient2.checkProcessedBlockIds();
    readClient2.close();
  }
",non-flaky,5
118702,netty_netty,SmtpRequestEncoderTest.testThrowsIfContentExpected,"    @Test(expected = EncoderException.class)
    public void testThrowsIfContentExpected() {
        EmbeddedChannel channel = new EmbeddedChannel(new SmtpRequestEncoder());
        try {
            assertTrue(channel.writeOutbound(SmtpRequests.data()));
            channel.writeOutbound(SmtpRequests.noop());
        } finally {
            channel.finishAndReleaseAll();
        }
    }
",non-flaky,5
162442,testcontainers_testcontainers-java,DockerComposeErrorHandlingTest.simpleTest,"    @Test
    public void simpleTest() {

        DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/invalid-compose.yml""))
                    .withExposedService(""something"", 123);

        VisibleAssertions.assertThrows(""starting with an invalid docker-compose file throws an exception"",
                ContainerLaunchException.class,
                () -> {
                    environment.starting(Description.createTestDescription(Object.class, ""name""));
                });
    }
",non-flaky,5
114056,aws_aws-sdk-java-v2,EnhancedTypeTest.nonStaticInnerTypesWork,"    @Test
    public void nonStaticInnerTypesWork() {
        EnhancedType<InnerType> enhancedType = new EnhancedType<InnerType>(){};
        assertThat(enhancedType.rawClass()).isEqualTo(InnerType.class);
    }
",non-flaky,5
26705,MundaneImmortal_pair-distribution-app,PairTest.testIsCompleteWithOneDev,"	@Test
	public void testIsCompleteWithOneDev()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.isComplete(), is(false));
	}
",non-flaky,5
30963,camunda-cloud_zeebe,POJOArrayTest.shouldNotSerializeRemovedEntry,"  @Test
  public void shouldNotSerializeRemovedEntry() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    pojo.wrap(buffer);
    final Iterator<MinimalPOJO> iterator = pojo.simpleArray().iterator();
    iterator.next();
    iterator.next();
    iterator.next();

    // when
    iterator.remove();

    // then
    final int writeLength = pojo.getLength();
    final UnsafeBuffer pojoBuffer = new UnsafeBuffer(new byte[writeLength]);
    pojo.write(pojoBuffer, 0);

    final Map<String, Object> msgPackMap = MsgPackUtil.asMap(pojoBuffer, 0, pojoBuffer.capacity());
    assertThat(msgPackMap)
        .containsOnly(
            entry(
                ""simpleArray"", ""[{longProp=123}, {longProp=456}, {longProp=555}, {longProp=777}]""));
  }
",non-flaky,5
113920,spring-projects_spring-data-couchbase,CouchbaseTemplateQueryCollectionIntegrationTests.removeByQueryOther,"	@Test
	public void removeByQueryOther() { // 8
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.one(vie);
		List<RemoveResult> removeResults = couchbaseTemplate.removeByQuery(Airport.class)
				.withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(otherScope).inCollection(otherCollection)
				.withOptions(options).matching(Query.query(QueryCriteria.where(""iata"").is(vie.getIata()))).all();
		assertEquals(saved.getId(), removeResults.get(0).getId());
	}
",non-flaky,5
114033,apache_struts,FileDownloadActionTest.testSanitizeInputPathShouldReturnNullForNonUppercaseWebInf,"	@Test
	public void testSanitizeInputPathShouldReturnNullForNonUppercaseWebInf() throws Exception {
		assertNull(fileDownloadAction.sanitizeInputPath(""./wEB-Inf/foo""));
	}
",non-flaky,5
340,apache_hadoop,TestExportsTable.testViewFsInternalExportPoint,"  @Test
  public void testViewFsInternalExportPoint() throws IOException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    String clusterName = RandomStringUtils.randomAlphabetic(10);

    String exportPoint = ""/hdfs1/subpath"";
    config.setStrings(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY, exportPoint);
    config.set(CommonConfigurationKeysPublic.FS_DEFAULT_NAME_KEY,
        FsConstants.VIEWFS_SCHEME + ""://"" + clusterName);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    config.set(""nfs.http.address"", ""0.0.0.0:0"");

    try {
      cluster =
          new MiniDFSCluster.Builder(config).nnTopology(
              MiniDFSNNTopology.simpleFederatedTopology(2))
              .numDataNodes(2)
              .build();
      cluster.waitActive();
      DistributedFileSystem hdfs1 = cluster.getFileSystem(0);
      DistributedFileSystem hdfs2 = cluster.getFileSystem(1);
      cluster.waitActive();
      Path base1 = new Path(""/user1"");
      Path base2 = new Path(""/user2"");
      hdfs1.delete(base1, true);
      hdfs2.delete(base2, true);
      hdfs1.mkdirs(base1);
      hdfs2.mkdirs(base2);
      ConfigUtil.addLink(config, clusterName, ""/hdfs1"",
          hdfs1.makeQualified(base1).toUri());
      ConfigUtil.addLink(config, clusterName, ""/hdfs2"",
          hdfs2.makeQualified(base2).toUri());
      Path subPath = new Path(base1, ""subpath"");
      hdfs1.delete(subPath, true);
      hdfs1.mkdirs(subPath);

      // Start nfs
      final Nfs3 nfsServer = new Nfs3(config);
      nfsServer.startServiceInternal(false);

      Mountd mountd = nfsServer.getMountd();
      RpcProgramMountd rpcMount = (RpcProgramMountd) mountd.getRpcProgram();
      assertTrue(rpcMount.getExports().size() == 1);

      String exportInMountd = rpcMount.getExports().get(0);
      assertTrue(exportInMountd.equals(exportPoint));
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
114114,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterInvalidFormatTest,"    @Test
    public void InstantAsStringAttributeConverterInvalidFormatTest() {
        assertFails(() -> transformTo(CONVERTER, EnhancedAttributeValue.fromString(""X"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
104661,apache_pinot,OfflineClusterIntegrationTest.testDistinctCountHll,"  @Test
  public void testDistinctCountHll()
      throws Exception {
    String query;

    // The Accurate value is 6538.
    query = ""SELECT distinctCount(FlightNum) FROM mytable "";
    assertEquals(postQuery(query).get(""aggregationResults"").get(0).get(""value"").asLong(), 6538);
    assertEquals(postSqlQuery(query, _brokerBaseApiUrl).get(""resultTable"").get(""rows"").get(0).get(0).asLong(), 6538);

    // Expected distinctCountHll with different log2m value from 2 to 19. The Accurate value is 6538.
    long[] expectedResults = new long[]{
        3504, 6347, 8877, 9729, 9046, 7672, 7538, 6993, 6649, 6651, 6553, 6525, 6459, 6523, 6532, 6544, 6538, 6539
    };

    for (int i = 2; i < 20; i++) {
      query = String.format(""SELECT distinctCountHLL(FlightNum, %d) FROM mytable "", i);
      assertEquals(postQuery(query).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResults[i - 2]);
      assertEquals(postSqlQuery(query, _brokerBaseApiUrl).get(""resultTable"").get(""rows"").get(0).get(0).asLong(),
          expectedResults[i - 2]);
    }

    // Default HLL is set as log2m=12
    query = ""SELECT distinctCountHLL(FlightNum) FROM mytable "";
    assertEquals(postQuery(query).get(""aggregationResults"").get(0).get(""value"").asLong(), expectedResults[10]);
    assertEquals(postSqlQuery(query, _brokerBaseApiUrl).get(""resultTable"").get(""rows"").get(0).get(0).asLong(),
        expectedResults[10]);
  }
",non-flaky,5
76705,quarkusio_quarkus,MongoDbRestDataPanacheIT.testDevServicesProperties,"    @Test
    public void testDevServicesProperties() {
        assertThat(context.devServicesProperties()).hasSize(1).containsKey(""quarkus.mongodb.connection-string"");
    }
",non-flaky,5
179455,abel533_Mapper,VersionTest.testUpdateInt,"    @Test
    public void testUpdateInt() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserIntMapper mapper = sqlSession.getMapper(UserIntMapper.class);
            UserInt user = mapper.selectByPrimaryKey(999);
            assertNotNull(user);
            Integer age = user.getAge();
            int count = mapper.updateByPrimaryKey(user);
            assertEquals(1, count);

            user = mapper.selectByPrimaryKey(999);
            assertFalse(age.equals(user.getAge()));
        } finally {
            sqlSession.close();
        }
    }
",non-flaky,5
156109,soot-oss_soot,DefaultInterfaceTest.derivedInterfacesTest,"  @Test
  public void derivedInterfacesTest() {
    String testClassSig = ""soot.defaultInterfaceMethods.DerivedInterfaces"";
    String defaultInterfaceOneSig = ""soot.defaultInterfaceMethods.InterfaceTestOne"";
    String defaultInterfaceTwoSig = ""soot.defaultInterfaceMethods.InterfaceTestTwo"";

    final SootMethod target =
        prepareTarget(
            methodSigFromComponents(testClassSig, voidType, mainClass),
            testClassSig,
            defaultInterfaceOneSig,
            defaultInterfaceTwoSig);

    FastHierarchy fh = Scene.v().getFastHierarchy();
    SootClass testClass = Scene.v().getSootClass(testClassSig);
    SootClass defaultInterfaceOne = Scene.v().getSootClass(defaultInterfaceOneSig);
    SootClass defaultInterfaceTwo = Scene.v().getSootClass(defaultInterfaceTwoSig);

    SootMethod interfaceOnePrint =
        Scene.v().getMethod(methodSigFromComponents(defaultInterfaceOneSig, ""void print()""));
    SootMethod interfaceTwoPrint =
        Scene.v().getMethod(methodSigFromComponents(defaultInterfaceTwoSig, ""void print()""));

    SootMethod refMainMethod =
        resolveMethodRefInBody(target.retrieveActiveBody().getUnits(), ""void print()"");

    SootMethod interfaceOneResolvedMethod =
        VirtualCalls.v().resolveNonSpecial(testClass.getType(), interfaceOnePrint.makeRef(), false);
    SootMethod interfaceTwoResolvedMethod =
        VirtualCalls.v().resolveNonSpecial(testClass.getType(), interfaceTwoPrint.makeRef(), false);

    SootMethod concreteImplInterfaceOne = fh.resolveConcreteDispatch(testClass, interfaceOnePrint);
    SootMethod concreteImplInterfaceTwo = fh.resolveConcreteDispatch(testClass, interfaceTwoPrint);

    Set<SootMethod> abstractImplInterfaceOne =
        fh.resolveAbstractDispatch(defaultInterfaceOne, interfaceOnePrint);

    boolean edgeMainToInterfaceTwoPrint = checkInEdges(interfaceTwoPrint, target);
    boolean edgeMainToInterfaceOnePrint = checkInEdges(interfaceOnePrint, target);

    final ReachableMethods reachableMethods = Scene.v().getReachableMethods();

    List<SootMethod> targetMethods =
        new ArrayList<SootMethod>() {
          {
            add(interfaceOnePrint);
            add(interfaceTwoPrint);
          }
        };

    Map<SootMethod, SootMethod> resolvedMethods =
        new HashMap<SootMethod, SootMethod>() {
          {
            put(interfaceTwoPrint, interfaceOneResolvedMethod);
            put(interfaceTwoPrint, interfaceTwoResolvedMethod);
          }
        };

    Map<SootMethod, SootMethod> concreteImplTrue =
        new HashMap<SootMethod, SootMethod>() {
          {
            put(interfaceTwoPrint, concreteImplInterfaceOne);
            put(interfaceTwoPrint, concreteImplInterfaceTwo);
          }
        };

    Map<SootMethod, SootMethod> concreteImplNotTrue =
        new HashMap<SootMethod, SootMethod>() {
          {
            put(interfaceOnePrint, concreteImplInterfaceOne);
            put(interfaceOnePrint, concreteImplInterfaceTwo);
          }
        };

    for (SootMethod targetMethod : targetMethods) {
      Assert.assertNotNull(targetMethod);
    }
    assertEquals(targetMethods.get(1), refMainMethod);
    assertEquals(targetMethods.get(1).getName(), ""print"");
    assertFalse(edgeMainToInterfaceOnePrint);
    assertTrue(edgeMainToInterfaceTwoPrint);
    assertTrue(reachableMethods.contains(targetMethods.get(1)));
    assertFalse(reachableMethods.contains(targetMethods.get(0)));
    for (Map.Entry<SootMethod, SootMethod> virtualResolvedMethod : resolvedMethods.entrySet()) {
      assertEquals(virtualResolvedMethod.getKey(), virtualResolvedMethod.getValue());
    }
    for (Map.Entry<SootMethod, SootMethod> concreteImpl : concreteImplTrue.entrySet()) {
      assertEquals(concreteImpl.getKey(), concreteImpl.getValue());
    }
    for (Map.Entry<SootMethod, SootMethod> concreteImpl : concreteImplNotTrue.entrySet()) {
      assertNotEquals(concreteImpl.getKey(), concreteImpl.getValue());
    }
    assertEquals(Sets.newHashSet(targetMethods.get(1)), abstractImplInterfaceOne);

    assertEquals(
        Sets.newHashSet(targetMethods.get(1)),
        fh.resolveAbstractDispatch(defaultInterfaceTwo, interfaceTwoPrint));
  }
",non-flaky,5
133953,CorfuDB_CorfuDB,BaseHandlerTest.testHandleNotBootstrappedError,"    @Test
    public void testHandleNotBootstrappedError() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getNotBootstrappedErrorMsg()
        );

        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed exceptionally (once)
        // with the expected exception
        verify(mockClientRouter, never()).completeRequest(anyLong(), any());
        verify(mockClientRouter).completeExceptionally(
                eq(response.getHeader().getRequestId()), any(NoBootstrapException.class));
    }
",non-flaky,5
150152,apache_hive,TestHplsqlLocal.testDatatypes,"  @Test
  public void testDatatypes() throws Exception {
    run(""datatypes"");
  }
",non-flaky,5
178005,aosp-mirror_platform_frameworks_support,BrowseSupportFragmentTest.run,"    @Test
    public void testSelectCardOnARow() throws Throwable {
        final int selectRow = 10;
        final int selectItem = 20;
        Intent intent = new Intent();
        final long dataLoadingDelay = 1000;
        intent.putExtra(BrowseSupportFragmentTestActivity.EXTRA_LOAD_DATA_DELAY, dataLoadingDelay);
        intent.putExtra(BrowseSupportFragmentTestActivity.EXTRA_ADD_TO_BACKSTACK , true);
        mActivity = activityTestRule.launchActivity(intent);

        Thread.sleep(dataLoadingDelay + TRANSITION_LENGTH);

        Presenter.ViewHolderTask itemTask = Mockito.spy(
                new ItemSelectionTask(mActivity, selectRow));

        final ListRowPresenter.SelectItemViewHolderTask task =
                new ListRowPresenter.SelectItemViewHolderTask(selectItem);
        task.setItemTask(itemTask);

        mActivity.runOnUiThread(new Runnable() {
            @Override
            public void run() {
                mActivity.getBrowseTestSupportFragment().setSelectedPosition(selectRow, true, task);
            }
",non-flaky,5
104659,apache_pinot,OfflineClusterIntegrationTest.testCaseInsensitivityWithColumnNameContainsTableName,"  @Test
  public void testCaseInsensitivityWithColumnNameContainsTableName() {
    int daysSinceEpoch = 16138;
    int hoursSinceEpoch = 16138 * 24;
    int secondsSinceEpoch = 16138 * 24 * 60 * 60;
    List<String> baseQueries = Arrays.asList(""SELECT * FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by DaysSinceEpoch ""
            + ""limit 10000"",
        ""SELECT DaysSinceEpoch, timeConvert(DaysSinceEpoch,'DAYS','SECONDS') FROM mytable order by timeConvert""
            + ""(DaysSinceEpoch,'DAYS','SECONDS') DESC limit 10000"",
        ""SELECT count(*) FROM mytable WHERE DaysSinceEpoch = "" + daysSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','HOURS') = "" + hoursSinceEpoch,
        ""SELECT count(*) FROM mytable WHERE timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch,
        ""SELECT MAX(timeConvert(DaysSinceEpoch,'DAYS','SECONDS')) FROM mytable"",
        ""SELECT COUNT(*) FROM mytable GROUP BY dateTimeConvert(DaysSinceEpoch,'1:DAYS:EPOCH','1:HOURS:EPOCH',""
            + ""'1:HOURS')"");
    List<String> queries = new ArrayList<>();
    baseQueries
        .forEach(q -> queries.add(q.replace(""mytable"", ""MYTABLE"").replace(""DaysSinceEpoch"", ""MYTABLE.DAYSSinceEpOch"")));
    baseQueries.forEach(
        q -> queries.add(q.replace(""mytable"", ""MYDB.MYTABLE"").replace(""DaysSinceEpoch"", ""MYTABLE.DAYSSinceEpOch"")));

    for (String query : queries) {
      try {
        JsonNode response = postQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""PQL: "" + query + "" failed"");

        response = postSqlQuery(query);
        assertTrue(response.get(""numSegmentsProcessed"").asLong() >= 1L, ""SQL: "" + query + "" failed"");
      } catch (Exception e) {
        // Fail the test when exception caught
        throw new RuntimeException(""Got Exceptions from query - "" + query);
      }
    }
  }
",non-flaky,5
38685,apache_pulsar,ElasticSearchBWCTests.getSchemaType,"    @Test
    public void testGenericRecord() throws Exception {
        String json = ""{\""c\"":\""1\"",\""d\"":1,\""e\"":{\""a\"":\""a\"",\""b\"":true,\""d\"":1.0,\""f\"":1.0,\""i\"":1,\""l\"":10}}"";

        ElasticSearchSink elasticSearchSink = new ElasticSearchSink();
        elasticSearchSink.open(ImmutableMap.of(""elasticSearchUrl"", ""http://localhost:9200"", ""schemaEnable"", ""true""), null);
        Pair<String, String> pair = elasticSearchSink.extractIdAndDocument(new Record<GenericObject>() {
            @Override
            public GenericObject getValue() {
                return new GenericObject() {
                    @Override
                    public SchemaType getSchemaType() {
                        return SchemaType.BYTES;
                    }
",non-flaky,5
133974,CorfuDB_CorfuDB,LogUnitHandlerTest.testFlushCache,"    @Test
    public void testFlushCache() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getFlushCacheResponseMsg()
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
26231,Ericsson_ecchronos,TestRepairResource.testRepairResourceEquality,"    @Test
    public void testRepairResourceEquality()
    {
        RepairResource repairResource = new RepairResource(""dc1"", ""my-resource"");
        RepairResource equalRepairResource = new RepairResource(""dc1"", ""my-resource"");
        RepairResource repairResourceWithDifferentDc = new RepairResource(""dc2"", ""my-resource"");
        RepairResource repairResourceWithDifferentResource = new RepairResource(""dc1"", ""not-my-resource"");

        assertThat(repairResource).isEqualTo(equalRepairResource);
        assertThat(repairResource).isNotEqualTo(repairResourceWithDifferentDc);
        assertThat(repairResource).isNotEqualTo(repairResourceWithDifferentResource);
    }
",non-flaky,5
96939,apache_avro,TestSortedKeyValueFile.testNamedCodecs,"  @Test
  public void testNamedCodecs() throws IOException {
    Configuration conf = new Configuration();
    Path myfile = new Path(mTempDir.getRoot().getPath(), ""myfile"");
    Schema key = Schema.create(Schema.Type.STRING);
    Schema value = Schema.create(Schema.Type.STRING);
    Schema recordSchema = AvroKeyValue.getSchema(key, value);
    DatumReader<GenericRecord> datumReader = SpecificData.get().createDatumReader(recordSchema);
    DataFileReader<GenericRecord> reader;

    SortedKeyValueFile.Writer.Options options = new SortedKeyValueFile.Writer.Options()
        .withKeySchema(key)
        .withValueSchema(value)
        .withConfiguration(conf)
        .withPath(myfile);

    SortedKeyValueFile.Writer<CharSequence, CharSequence> writer;

    for(String codec : new String[]{""null"", ""deflate"", ""snappy"", ""bzip2""}) {
        LOG.debug(""Using "" + codec + ""codec for a SortedKeyValueFile..."");

        options.withCodec(codec);

        writer = new SortedKeyValueFile.Writer<>(options);
        writer.close();

        reader = new DataFileReader<>(
            new FsInput(new Path(myfile, SortedKeyValueFile.DATA_FILENAME), conf),
            datumReader);

        assertEquals(codec, reader.getMetaString(""avro.codec""));
        reader.close();
    }
  }
",non-flaky,5
136503,doanduyhai_Achilles,FrozenNestedTypeStrategyTest.should_not_fail_for_non_frozen_list_tuple,"    @Test
    public void should_not_fail_for_non_frozen_list_tuple() throws Exception {
        setExec(aptUtils -> {
            final NestedTypeValidator2_1 strategy = new NestedTypeValidator2_1();
            final String className = TestEntityWithNestedTypes.class.getCanonicalName();
            final TypeName rawClass = ClassName.get(TestEntityWithNestedTypes.class);
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            // private List<Tuple3<Integer, String, String>> listTuple;
            VariableElement elm = findFieldInType(typeElement, ""listTuple"");
            final AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils, globalParsingContext, elm);
            strategy.validate(aptUtils, annotationTree, ""listTuple"", rawClass);
        });
        launchTest(TestEntityWithNestedTypes.class);
    }
",non-flaky,5
156064,jReddit_jReddit,RedditOAuthAgentTest.testTokenOAuthSystemException,"    @Test(expected=RedditOAuthException.class)
    public void testTokenOAuthSystemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(new OAuthSystemException());
        subject.token(code);
    }
",non-flaky,5
91475,strapdata_elassandra,SpecificMasterNodesIT.testSimpleOnlyMasterNodeElection,"@TestLogging(""_root:DEBUG,org.elasticsearch.action.admin.cluster.state:TRACE"")
    public void testSimpleOnlyMasterNodeElection() throws IOException {
        logger.info(""--> start data node / non master node"");
        internalCluster().startNode(Settings.builder().put(Node.NODE_DATA_SETTING.getKey(), true).put(Node.NODE_MASTER_SETTING.getKey(), false)
            .put(""discovery.initial_state_timeout"", ""1s""));
        try {
            assertThat(client().admin().cluster().prepareState().setMasterNodeTimeout(""100ms"").execute().actionGet().getState().nodes().getMasterNodeId(), nullValue());
            fail(""should not be able to find master"");
        } catch (MasterNotDiscoveredException e) {
            // all is well, no master elected
        }
        logger.info(""--> start master node"");
        final String masterNodeName = internalCluster().startNode(Settings.builder().put(Node.NODE_DATA_SETTING.getKey(), false).put(Node.NODE_MASTER_SETTING.getKey(), true));
        assertThat(internalCluster().nonMasterClient().admin().cluster().prepareState().execute().actionGet().getState().nodes().getMasterNode().getName(), equalTo(masterNodeName));
        assertThat(internalCluster().masterClient().admin().cluster().prepareState().execute().actionGet().getState().nodes().getMasterNode().getName(), equalTo(masterNodeName));

        logger.info(""--> stop master node"");
        internalCluster().stopCurrentMasterNode();

        try {
            assertThat(client().admin().cluster().prepareState().setMasterNodeTimeout(""100ms"").execute().actionGet().getState().nodes().getMasterNodeId(), nullValue());
            fail(""should not be able to find master"");
        } catch (MasterNotDiscoveredException e) {
            // all is well, no master elected
        }

        logger.info(""--> start master node"");
        final String nextMasterEligibleNodeName = internalCluster().startNode(Settings.builder().put(Node.NODE_DATA_SETTING.getKey(), false).put(Node.NODE_MASTER_SETTING.getKey(), true));
        assertThat(internalCluster().nonMasterClient().admin().cluster().prepareState().execute().actionGet().getState().nodes().getMasterNode().getName(), equalTo(nextMasterEligibleNodeName));
        assertThat(internalCluster().masterClient().admin().cluster().prepareState().execute().actionGet().getState().nodes().getMasterNode().getName(), equalTo(nextMasterEligibleNodeName));
    }
",non-flaky,5
162683,OpenAPITools_openapi-generator,UserApiTest.getUserByNameTest,"    @Test
    public void getUserByNameTest() {
        String username = null;
        //User response = api.getUserByName(username);
        //assertNotNull(response);
        // TODO: test validations
        
        
    }
",non-flaky,5
113994,apache_struts,URLDecoderUtilTest.testURLDecodeStringValidUtf8End,"    @Test
    public void testURLDecodeStringValidUtf8End() {

        String result = URLDecoderUtil.decode(""xxxx%c3%aa"", ""UTF-8"");
        assertEquals(""xxxx\u00ea"", result);
    }
",non-flaky,5
96904,apache_avro,TestSchemaResolver.testIsUnresolvedSchemaError1,"  @Test(expected = IllegalArgumentException.class)
  public void testIsUnresolvedSchemaError1() {
    // No ""org.apache.avro.compiler.idl.unresolved.name"" property
    Schema s = SchemaBuilder.record(""R"").fields().endRecord();
    SchemaResolver.getUnresolvedSchemaName(s);
  }
",non-flaky,5
77517,dropwizard_dropwizard,DAOTestRuleTest.rollsBackTransaction,"    @Test
    public void rollsBackTransaction() {
        // given a successfully persisted entity
        final TestEntity testEntity = new TestEntity(""description"");
        daoTestRule.inTransaction(() -> persist(testEntity));

        // when we prepare an update of that entity
        testEntity.setDescription(""newDescription"");
        // ... but cause a constraint violation during the actual update
        assertThatExceptionOfType(ConstraintViolationException.class)
            .isThrownBy(() -> daoTestRule.inTransaction(() -> {
                persist(testEntity);
                persist(new TestEntity(null));
            }));
        // ... the entity has the original value
        assertThat(get(testEntity.getId()).getDescription()).isEqualTo(""description"");
    }
",non-flaky,5
89318,apache_samza,TestKafkaSystemAdminWithMock.testGetSSPMetadataShouldTerminateAfterFiniteRetriesOnException,"  @Test(expected = SamzaException.class)
  public void testGetSSPMetadataShouldTerminateAfterFiniteRetriesOnException() throws Exception {
    SystemStreamPartition oneSSP = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    SystemStreamPartition otherSSP = new SystemStreamPartition(TEST_SYSTEM, ""otherTopic"", new Partition(1));

    ImmutableSet<SystemStreamPartition> ssps = ImmutableSet.of(oneSSP, otherSSP);
    List<TopicPartition> topicPartitions = ssps.stream()
        .map(ssp -> new TopicPartition(ssp.getStream(), ssp.getPartition().getPartitionId()))
        .collect(Collectors.toList());

    when(mockKafkaConsumer.beginningOffsets(topicPartitions)).thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException());

    kafkaSystemAdmin.getSSPMetadata(ssps, new ExponentialSleepStrategy(2,
        1, 1));
  }
",non-flaky,5
156103,soot-oss_soot,ResolveFieldInitializersTest.initializedInConstructor,"  @Test
  public void initializedInConstructor() {
    prepareTarget(methodSigFromComponents(TEST_TARGET_CLASS, ""void"", ""<init>""), TEST_TARGET_CLASS);
    SootClass sootClass = Scene.v().getSootClass(""java.util.LinkedList"");
    assertEquals(SootClass.SIGNATURES, sootClass.resolvingLevel());
  }
",non-flaky,5
38218,palantir_atlasdb,TextUtilsTest.testPluralization,"    @Test
    public void testPluralization() throws Exception {
        assertEquals("""", TextUtils.pluralize(null));
        assertEquals("""", TextUtils.pluralize(""""));
        assertEquals(""dogs"", TextUtils.pluralize(""dog""));
        assertEquals(""keywords"", TextUtils.pluralize(""keywords""));
    }
",non-flaky,5
59623,looly_hutool,JschUtilTest.bindRemotePort,"	@Test
	public void bindRemotePort() throws InterruptedException {
		// å»ºç«ä¼è¯
		Session session = JschUtil.getSession(""looly.centos"", 22, ""test"", ""123456"");
		// ç»å®sshæå¡ç«¯8089ç«¯å£å°æ¬æºç8000ç«¯å£ä¸
		boolean b = JschUtil.bindRemotePort(session, 8089, ""localhost"", 8000);
		Assert.assertTrue(b);
		// ä¿è¯ä¸ç´è¿è¡
//		while (true){
//			Thread.sleep(3000);
//		}
	}
",non-flaky,5
113981,apache_struts,StrutsJavaConfigurationProviderTest.unknownHandlerStack,"    @Test
    public void testRegister() throws Exception {
        final ConstantConfig constantConfig = new ConstantConfig();
        constantConfig.setDevMode(true);

        final String expectedUnknownHandler = ""expectedUnknownHandler"";

        StrutsJavaConfiguration javaConfig = new StrutsJavaConfiguration() {
            @Override
            public List<String> unknownHandlerStack() {
                return Arrays.asList(expectedUnknownHandler);
            }
",non-flaky,5
110890,pushtorefresh_storio,InterceptorTest.putCollection,"    @Test
    public void putCollection() {
        storIOSQLite.put()
                .objects(Collections.singleton(createTweet()))
                .prepare()
                .executeAsBlocking();
        checkInterceptorsCalls();
    }
",non-flaky,5
162378,testcontainers_testcontainers-java,TestEnvironmentTest.testCompareVersionEqual,"    @Test
    public void testCompareVersionEqual() {
        assertTrue(""1.20 == 1.20"", new ComparableVersion(""1.20"").compareTo(new ComparableVersion(""1.20"")) == 0);
    }
",non-flaky,5
33871,apache_camel,FhirUpdateIT.testResourceNoId,"    @Test
    public void testResourceNoId() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resource"", this.patient);
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
",non-flaky,5
38211,palantir_atlasdb,RocksDbKeyValueServiceTest.testGetRangeCellOverlap2,"    @Test
    public void testGetRangeCellOverlap2() {
        final Cell cell = Cell.create(""1"".getBytes(), ""1"".getBytes());
        final Cell cell2 = Cell.create(""12"".getBytes(), ""0"".getBytes());
        final Cell cell3 = Cell.create(""1"".getBytes(), ""3"".getBytes());
        db.put(TABLE, ImmutableMap.of(cell, ""v1"".getBytes()), 2);
        db.put(TABLE, ImmutableMap.of(cell2, ""v2"".getBytes()), 2);
        db.put(TABLE, ImmutableMap.of(cell3, ""v3"".getBytes()), 2);
        final ClosableIterator<? extends RowResult<Value>> it = db.getRange(TABLE, RangeRequest.builder().build(), 3);
        try {
            assertEquals(2, Iterators.size(it));
        } finally {
            it.close();
        }
    }
",non-flaky,5
96071,stanfordnlp_CoreNLP,QuantifiableEntityNormalizingAnnotatorITest.testQuantifiableEntityNormalizingAnnotator,"  @Test
  public void testQuantifiableEntityNormalizingAnnotator() {
    Annotation document = new Annotation(text);
    pipeline.annotate(document);

    int i = 0;
    for (CoreMap sentence: document.get(CoreAnnotations.SentencesAnnotation.class)) {
        List<CoreLabel> tokens = sentence.get(CoreAnnotations.TokensAnnotation.class);
        for (CoreLabel token : tokens) {
          System.out.println(token.get(CoreAnnotations.TextAnnotation.class) + "": "" + token.get(CoreAnnotations.NamedEntityTagAnnotation.class) + "", "" + token.get(CoreAnnotations.NormalizedNamedEntityTagAnnotation.class));
        }
      for (CoreLabel token : tokens) {
        String normalization = token.get(CoreAnnotations.NormalizedNamedEntityTagAnnotation.class);
        if (normalization != null) {
          Assert.assertEquals(answer_text[i], token.get(CoreAnnotations.OriginalTextAnnotation.class));
          Assert.assertEquals(answer_time[i], normalization);
          i++;
        }
      }
    }
    Assert.assertEquals(answer_text.length, i);
    Assert.assertEquals(answer_time.length, i);
  }
",non-flaky,5
57247,apache_ozone,TestReconNodeManager.testReconNodeDB,"  @Test
  public void testReconNodeDB() throws IOException, NodeNotFoundException {
    ReconStorageConfig scmStorageConfig = new ReconStorageConfig(conf);
    EventQueue eventQueue = new EventQueue();
    NetworkTopology clusterMap = new NetworkTopologyImpl(conf);
    Table<UUID, DatanodeDetails> nodeTable =
        ReconSCMDBDefinition.NODES.getTable(store);
    ReconNodeManager reconNodeManager = new ReconNodeManager(conf,
        scmStorageConfig, eventQueue, clusterMap, nodeTable, versionManager);
    ReconNewNodeHandler reconNewNodeHandler =
        new ReconNewNodeHandler(reconNodeManager);
    assertTrue(reconNodeManager.getAllNodes().isEmpty());

    DatanodeDetails datanodeDetails = randomDatanodeDetails();
    String uuidString = datanodeDetails.getUuidString();

    // Register a random datanode.
    reconNodeManager.register(datanodeDetails, null, null);
    reconNewNodeHandler.onMessage(reconNodeManager.getNodeByUuid(uuidString),
        null);

    assertEquals(1, reconNodeManager.getAllNodes().size());
    assertNotNull(reconNodeManager.getNodeByUuid(uuidString));

    // If any commands are added to the eventQueue without using the onMessage
    // interface, then they should be filtered out and not returned to the DN
    // when it heartbeats.
    // This command should never be returned by Recon
    reconNodeManager.addDatanodeCommand(datanodeDetails.getUuid(),
        new SetNodeOperationalStateCommand(1234,
        DECOMMISSIONING, 0));

    // This one should be returned
    reconNodeManager.addDatanodeCommand(datanodeDetails.getUuid(),
        new ReregisterCommand());

    // OperationalState sanity check
    final DatanodeDetails dnDetails =
        reconNodeManager.getNodeByUuid(datanodeDetails.getUuidString());
    assertEquals(HddsProtos.NodeOperationalState.IN_SERVICE,
        dnDetails.getPersistedOpState());
    assertEquals(dnDetails.getPersistedOpState(),
        reconNodeManager.getNodeStatus(dnDetails)
            .getOperationalState());
    assertEquals(dnDetails.getPersistedOpStateExpiryEpochSec(),
        reconNodeManager.getNodeStatus(dnDetails)
            .getOpStateExpiryEpochSeconds());

    // Upon processing the heartbeat, the illegal command should be filtered out
    List<SCMCommand> returnedCmds =
        reconNodeManager.processHeartbeat(datanodeDetails,
            defaultLayoutVersionProto());
    assertEquals(1, returnedCmds.size());
    assertEquals(SCMCommandProto.Type.reregisterCommand,
        returnedCmds.get(0).getType());

    // Now feed a DECOMMISSIONED heartbeat of the same DN
    datanodeDetails.setPersistedOpState(
        HddsProtos.NodeOperationalState.DECOMMISSIONED);
    datanodeDetails.setPersistedOpStateExpiryEpochSec(12345L);
    reconNodeManager.processHeartbeat(datanodeDetails,
        defaultLayoutVersionProto());
    // Check both persistedOpState and NodeStatus#operationalState
    assertEquals(HddsProtos.NodeOperationalState.DECOMMISSIONED,
        dnDetails.getPersistedOpState());
    assertEquals(dnDetails.getPersistedOpState(),
        reconNodeManager.getNodeStatus(dnDetails)
            .getOperationalState());
    assertEquals(12345L, dnDetails.getPersistedOpStateExpiryEpochSec());
    assertEquals(dnDetails.getPersistedOpStateExpiryEpochSec(),
        reconNodeManager.getNodeStatus(dnDetails)
            .getOpStateExpiryEpochSeconds());

    // Close the DB, and recreate the instance of Recon Node Manager.
    eventQueue.close();
    reconNodeManager.close();
    reconNodeManager = new ReconNodeManager(conf, scmStorageConfig, eventQueue,
        clusterMap, nodeTable, versionManager);

    // Verify that the node information was persisted and loaded back.
    assertEquals(1, reconNodeManager.getAllNodes().size());
    assertNotNull(
        reconNodeManager.getNodeByUuid(datanodeDetails.getUuidString()));
  }
",non-flaky,5
43053,trinodb_trino,BaseConnectorTest.testSortItemsReflectedInExplain,"    @Test
    public void testSortItemsReflectedInExplain()
    {
        // Even if the sort items are pushed down into the table scan, it should still be reflected in EXPLAIN (via ConnectorTableHandle.toString)
        @Language(""RegExp"") String expectedPattern = hasBehavior(SUPPORTS_TOPN_PUSHDOWN)
                ? ""sortOrder=\\[(?i:nationkey):.* DESC NULLS LAST] limit=5""
                : ""\\[5 by \\((?i:nationkey) DESC NULLS LAST\\)]"";

        assertExplain(
                ""EXPLAIN SELECT name FROM nation ORDER BY nationkey DESC NULLS LAST LIMIT 5"",
                expectedPattern);
    }
",non-flaky,5
160395,ConsenSys_teku,ChainDataProviderTest.getBlockHeaderByBlockId_shouldGetHeadBlock,"  @Test
  public void getBlockHeaderByBlockId_shouldGetHeadBlock()
      throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    final tech.pegasys.teku.spec.datastructures.blocks.SignedBeaconBlock block =
        combinedChainDataClient.getBestBlock().get();
    BlockHeader result = provider.getBlockHeader(""head"").get().get();
    final BeaconBlockHeader beaconBlockHeader =
        new BeaconBlockHeader(
            block.getSlot(),
            block.getMessage().getProposerIndex(),
            block.getParentRoot(),
            block.getStateRoot(),
            block.getRoot());
    final BlockHeader expected =
        new BlockHeader(
            block.getRoot(),
            true,
            new SignedBeaconBlockHeader(beaconBlockHeader, new BLSSignature(block.getSignature())));

    assertThat(result).isEqualTo(expected);
  }
",non-flaky,5
110194,Wikidata_wikidata-toolkit,RdfConverterTest.testStatementNoValue,"	@Test
	public void testStatementNoValue() throws RDFHandlerException,
			RDFParseException, IOException {
		PropertyIdValue pid = dataObjectFactory.getPropertyIdValue(""P31"", ""http://www.wikidata.org/"");
		Statement statement = StatementBuilder
				.forSubjectAndProperty(ItemIdValue.NULL, pid)
				.withNoValue().build();
		this.rdfConverter.writeStatement(statement);
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(model, RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""StatementNoValue.rdf"")));
	}
",non-flaky,5
179471,abel533_Mapper,DateTimeTest.testInsert3,"    @Test
    public void testInsert3() {
        SqlSession sqlSession = getSqlSession();
        try {
            TimeModel3Mapper mapper = sqlSession.getMapper(TimeModel3Mapper.class);
            TimeModel3 timeModel = new TimeModel3();
            timeModel.setId(3);
            Date now = new Date();
            timeModel.setTestDate(now);
            timeModel.setTestTime(now);
            timeModel.setTestDatetime(now);
            /*
                insert æ¥å¿è½ææ¾çå°å¶å® jdbcType åçåºå«

                DEBUG [main] - ==>  Preparing: INSERT INTO test_timestamp ( id,test_date,test_time,test_datetime ) VALUES( ?,?,?,? )
                DEBUG [main] - ==> Parameters: 3(Integer), 2018-02-25(Date), 11:50:18(Time), 2018-02-25 11:50:18.263(Timestamp)
             */
            Assert.assertEquals(1, mapper.insert(timeModel));

            timeModel = mapper.selectByPrimaryKey(3);

            //ä¿å­åæ°æ®åºä¸­ä¸å­å¨æ¶é´é¨å
            Assert.assertEquals(toDate(now), toDate(timeModel.getTestDate()));
            Assert.assertEquals(toDate(now) + "" 00:00:00"", toDatetime(timeModel.getTestDate()));

            //æ¶é´
            Assert.assertEquals(toTime(now), toTime(timeModel.getTestTime()));
            //ç±äºæå¥æ°æ®åºæ¶æå®ç jdbcType=TIMEï¼æä»¥ä¸é¢æ¯æ²¡ææ¥æé¨åç
            Assert.assertEquals(""1970-01-01 "" + toTime(now), toDatetime(timeModel.getTestTime()));

            Assert.assertEquals(toDatetime(now), toDatetime(timeModel.getTestDatetime()));
        } finally {
            sqlSession.close();
        }
    }
",non-flaky,5
78258,apache_beam,StateInternalsTest.testMapReadable,"  @Test
  public void testMapReadable() throws Exception {
    MapState<String, Integer> value = underTest.state(NAMESPACE_1, STRING_MAP_ADDR);

    // test iterable, should just return a iterable view of the values contained in this map.
    // The iterable is backed by the map, so changes to the map are reflected in the iterable.
    ReadableState<Iterable<String>> keys = value.keys();
    ReadableState<Iterable<Integer>> values = value.values();
    ReadableState<Iterable<Map.Entry<String, Integer>>> entries = value.entries();
    value.put(""A"", 1);
    assertFalse(Iterables.isEmpty(keys.read()));
    assertFalse(Iterables.isEmpty(values.read()));
    assertFalse(Iterables.isEmpty(entries.read()));

    // test get
    ReadableState<Integer> get = value.get(""B"");
    value.put(""B"", 2);
    assertNull(get.read());

    // test addIfAbsent
    value.putIfAbsent(""C"", 3);
    assertThat(value.get(""C"").read(), equalTo(3));
  }
",non-flaky,5
176921,OryxProject_oryx,MultiRescorerProviderTest.testMultiRecommendRescorer,"  @Test
  public void testMultiRecommendRescorer() {
    RescorerProvider multi = new MultiRescorerProvider(
        new SimpleModRescorerProvider(2), new SimpleModRescorerProvider(3));
    
    Rescorer provider = multi.getRecommendRescorer(Collections.singletonList(""ABCDE""), null);
    assertNull(provider);

    Rescorer provider2 = multi.getRecommendRescorer(Collections.singletonList(""AB""), null);
    assertNotNull(provider2);
    assertFalse(provider2 instanceof MultiRescorer);
    assertTrue(provider2.isFiltered(""ABC""));
    assertFalse(provider2.isFiltered(""AB""));

    Rescorer provider3 = multi.getRecommendRescorer(Collections.singletonList(""ABCDEF""), null);
    assertNotNull(provider3);
    assertTrue(provider3 instanceof MultiRescorer);
    assertTrue(provider3.isFiltered(""ABC""));
    assertTrue(provider3.isFiltered(""AB""));
    assertFalse(provider3.isFiltered(""ABCDEFABCDEF""));
  }
",non-flaky,5
162673,OpenAPITools_openapi-generator,PetApiTest.findPetsByStatusTest,"    @Test
    public void findPetsByStatusTest() {
        List<String> status = null;
        //List<Pet> response = api.findPetsByStatus(status);
        //assertNotNull(response);
        // TODO: test validations
        
        
    }
",non-flaky,5
84583,apache_zookeeper,WriteLockTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        if (nodes != null) {
            for (int i = 0; i < nodes.length; i++) {
                WriteLock node = nodes[i];
                if (node != null) {
                    System.out.println(""Closing node: "" + i);
                    node.close();
                    if (workAroundClosingLastZNodeFails && i == nodes.length - 1) {
                        System.out.println(""Not closing zookeeper: "" + i + "" due to bug!"");
                    } else {
                        System.out.println(""Closing zookeeper: "" + i);
                        node.getZookeeper().close();
                        System.out.println(""Closed zookeeper: "" + i);
                    }
                }
            }
        }
        System.out.println(""Now lets stop the server"");
        super.tearDown();

    }
",non-flaky,5
104152,spring-cloud_spring-cloud-config,EncryptionControllerTests.publicKey,"	@Test
	public void publicKey() {
		this.controller = new EncryptionController(
				new SingleTextEncryptorLocator(new RsaSecretEncryptor()));
		String key = this.controller.getPublicKey();
		assertThat(key.startsWith(""ssh-rsa"")).as(""Wrong key format: "" + key).isTrue();
	}
",non-flaky,5
43119,trinodb_trino,BaseConnectorSmokeTest.testInsert,"    @Test
    public void testInsert()
    {
        if (!hasBehavior(SUPPORTS_INSERT)) {
            assertQueryFails(""INSERT INTO region (regionkey) VALUES (42)"", ""This connector does not support inserts"");
            return;
        }

        if (!hasBehavior(SUPPORTS_CREATE_TABLE)) {
            throw new AssertionError(""Cannot test INSERT without CREATE TABLE, the test needs to be implemented in a connector-specific way"");
        }

        try (TestTable table = new TestTable(getQueryRunner()::execute, ""test_insert_"", ""(a bigint, b double)"")) {
            assertUpdate(""INSERT INTO "" + table.getName() + "" (a, b) VALUES (42, -38.5)"", 1);
            assertThat(query(""SELECT CAST(a AS bigint), b FROM "" + table.getName()))
                    .matches(""VALUES (BIGINT '42', -385e-1)"");
        }
    }
",non-flaky,5
77158,networknt_json-schema-validator,V4JsonSchemaTest.testMinPropertiesValidator,"    @Test
    public void testMinPropertiesValidator() throws Exception {
        runTestFile(""draft4/minProperties.json"");
    }
",non-flaky,5
98374,ONSdigital_rm-collection-exercise-service,ReminderEventValidatorTest.returnTrueAndDoNothingIfNotReminder,"  @Test
  public void returnTrueAndDoNothingIfNotReminder() throws CTPException {
    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now()));
    final List<Event> events = new ArrayList<>();
    reminderValidator.validate(events, mpsEvent, CollectionExerciseState.CREATED);

    verify(eventDateOrderChecker, never()).isEventDatesInOrder(anyList());
  }
",non-flaky,5
179411,abel533_Mapper,KeySqlTest.testUseGeneratedKeys,"    @Test
    public void testUseGeneratedKeys(){
        EntityHelper.initEntityNameMap(UserJDBC.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserJDBC.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""JDBC"", column.getGenerator());
            Assert.assertTrue(column.isIdentity());
        }
    }
",non-flaky,5
114038,aws_aws-sdk-java-v2,MyWafRegionalFunctionTest.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        MyWafRegionalFunction function = new MyWafRegionalFunction();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
160417,ConsenSys_teku,ChainDataProviderTest.getBlockAttestations_shouldReturnAttestationsOfBlock,"  @Test
  public void getBlockAttestations_shouldReturnAttestationsOfBlock() throws Exception {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    ChainBuilder chainBuilder = storageSystem.chainBuilder();

    ChainBuilder.BlockOptions blockOptions = ChainBuilder.BlockOptions.create();
    AttestationGenerator attestationGenerator =
        new AttestationGenerator(spec, chainBuilder.getValidatorKeys());
    tech.pegasys.teku.spec.datastructures.operations.Attestation attestation1 =
        attestationGenerator.validAttestation(bestBlock.toUnsigned(), bestBlock.getSlot());
    tech.pegasys.teku.spec.datastructures.operations.Attestation attestation2 =
        attestationGenerator.validAttestation(
            bestBlock.toUnsigned(), bestBlock.getSlot().increment());
    blockOptions.addAttestation(attestation1);
    blockOptions.addAttestation(attestation2);
    SignedBlockAndState newHead =
        storageSystem
            .chainBuilder()
            .generateBlockAtSlot(bestBlock.getSlot().plus(10), blockOptions);
    storageSystem.chainUpdater().saveBlock(newHead);
    storageSystem.chainUpdater().updateBestBlock(newHead);

    final Optional<List<Attestation>> response = provider.getBlockAttestations(""head"").get();
    assertThat(response).isPresent();
    assertThat(response.get())
        .containsExactly(new Attestation(attestation1), new Attestation(attestation2));
  }
",non-flaky,5
92717,apache_dubbo,ProtocolConfigTest.testIothreads,"    @Test
    public void testIothreads() throws Exception {
        ProtocolConfig protocol = new ProtocolConfig();
        protocol.setIothreads(10);
        assertThat(protocol.getIothreads(), is(10));
    }
",non-flaky,5
26757,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testGetPastPairByTrackForMissingTrack,"	@Test
	public void testGetPastPairByTrackForMissingTrack() {
		DevPairCombinations devPairCombinations = new DevPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(1, ""track4""), is(nullValue()));
	}
",non-flaky,5
43025,fabiomaffioletti_jsondoc,Spring3JSONDocObjectScannerTest.findsDeeplyNestedObjects,"    @Test
    public void findsDeeplyNestedObjects() throws Exception {
        JSONDocScanner jsondocScanner = new Spring3JSONDocScanner();
        JSONDoc jsondoc = jsondocScanner.getJSONDoc(version, basePath, Lists.newArrayList(""org.jsondoc.springmvc.controller""), true, MethodDisplay.URI);

        Map<String, Set<ApiObjectDoc>> objects = jsondoc.getObjects();
        for (Set<ApiObjectDoc> values : objects.values()) {
            assertContainsDoc(values, ""NestedObject2"");
            assertContainsDoc(values, ""NestedObject3"");
        }
    }
",non-flaky,5
70804,apache_kafka,PluginUtilsTest.testOrderOfPluginUrlsWithJars,"    @Test
    public void testOrderOfPluginUrlsWithJars() throws Exception {
        createBasicDirectoryLayout();
        // Here this method is just used to create the files. The result is not used.
        createBasicExpectedUrls();

        List<Path> actual = PluginUtils.pluginUrls(pluginPath);
        // 'simple-transform.jar' is created first. In many cases, without sorting within the
        // PluginUtils, this jar will be placed before 'another-transform.jar'. However this is
        // not guaranteed because a DirectoryStream does not maintain a certain order in its
        // results. Besides this test case, sorted order in every call to assertUrls below.
        int i = Arrays.toString(actual.toArray()).indexOf(""another-transform.jar"");
        int j = Arrays.toString(actual.toArray()).indexOf(""simple-transform.jar"");
        assertTrue(i < j);
    }
",non-flaky,5
30915,camunda-cloud_zeebe,TestConfigurationFactoryTest.shouldOverlayEnvironmentSettingsOverConfigurationReadFromFile,"  @Test
  public void shouldOverlayEnvironmentSettingsOverConfigurationReadFromFile()
      throws InvocationTargetException, NoSuchMethodException, InstantiationException,
",non-flaky,5
152,apache_dubbo,737f7a7ea67832d7f17517326fb2491d0a086dd7.testListAllPort,"@Test
public void testListAllPort() throws RemotingException {
    String result = port.telnet(null, """");
    assertEquals(""20887"", result);
}",test order dependency,4
98030,vert-x3_vertx-mongo-client,MongoClientUpdateResultTest.testToJsonMongoClientUpdateResult,"  @Test
  public void testToJsonMongoClientUpdateResult() {
    JsonObject mongoClientUpdateResultJson = randomMongoClientUpdateResultJson();
    MongoClientUpdateResult mongoClientUpdateResult = new MongoClientUpdateResult(mongoClientUpdateResultJson);

    assertEquals(mongoClientUpdateResultJson, mongoClientUpdateResult.toJson());
  }
",non-flaky,5
33704,alibaba_fastjson,JSONScannerTest.checkTime10,"  @Test
  public void checkTime10() throws Throwable {

    // Arrange
    JSONScanner objectUnderTest = ((JSONScanner)Reflector.getInstance(""com.alibaba.fastjson.parser.JSONScanner""));
    objectUnderTest.hasSpecial = false;
    objectUnderTest.token = 0;
    objectUnderTest.locale = null;
    objectUnderTest.np = 0;
    objectUnderTest.features = 0;
    Reflector.setField(objectUnderTest, ""text"", """");
    objectUnderTest.calendar = null;
    objectUnderTest.matchStat = 0;
    objectUnderTest.bp = 0;
    Reflector.setField(objectUnderTest, ""len"", 0);
    objectUnderTest.stringDefaultValue = """";
    objectUnderTest.pos = 0;
    objectUnderTest.sp = 0;
    objectUnderTest.sbuf = null;
    objectUnderTest.ch = '\u0000';
    objectUnderTest.timeZone = null;
    objectUnderTest.eofPos = 0;
    char h0 = '1';
    char h1 = '9';
    char m0 = '4';
    char m1 = '3';
    char s0 = '1';
    char s1 = '\u0000';

    // Act
    Class<?> c = Reflector.forName(""com.alibaba.fastjson.parser.JSONScanner"");
    Method m = c.getDeclaredMethod(""checkTime"", Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""));
    m.setAccessible(true);
    boolean retval = (Boolean)m.invoke(objectUnderTest, h0, h1, m0, m1, s0, s1);

    // Assert result
    Assert.assertEquals(false, retval);

  }
",non-flaky,5
159689,liquibase_liquibase,RenameColumnExecuteTest.noSchema,"    @Test
    public void noSchema() throws Exception {
        this.statementUnderTest = new RenameColumnStatement(null, null, TABLE_NAME, COLUMN_NAME, ""new_name"", ""int"");

        assertCorrect(""rename column table_name.column_name to new_name"", DerbyDatabase.class, InformixDatabase.class);
        assertCorrect(""alter table table_name alter column column_name rename to new_name"", H2Database.class, HsqlDatabase.class);
        assertCorrect(""alter table table_name alter column column_name to new_name"", FirebirdDatabase.class);
        assertCorrect(""alter table table_name change column_name new_name int"", MySQLDatabase.class, MariaDBDatabase.class);
        assertCorrect(""exec sp_rename '[table_name].[column_name]', 'new_name'"", MSSQLDatabase.class);
        assertCorrect(""exec sp_rename 'table_name.column_name', 'new_name'"", SybaseDatabase.class);
        assertCorrect(""alter table [table_name] rename column_name to new_name"",SybaseASADatabase.class);
        assertCorrectOnRest(""alter table [table_name] rename column [column_name] to [new_name]"");
    }
",non-flaky,5
77117,networknt_json-schema-validator,Issue366FailFastTest.neitherValid,"  @Test
  public void neitherValid() throws Exception {
    String dataPath = ""/data/issue366.json"";

    assertThrows(JsonSchemaException.class, () -> {
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
        List<JsonNode> testNodes = node.findValues(""tests"");
        JsonNode testNode = testNodes.get(0).get(3);
        JsonNode dataNode = testNode.get(""data"");
        jsonSchema.validate(dataNode);
    });
  }
",non-flaky,5
135718,Netflix_Hystrix,CommonHystrixCommandTests.call,"    @Test
    public void testExecutionHookSemaphoreSuccess() {
        assertHooksOnSuccess(
                new Func0<C>() {
                    @Override
                    public C call() {
                        return getCommand(ExecutionIsolationStrategy.SEMAPHORE, ExecutionResult.SUCCESS, FallbackResult.SUCCESS);
                    }
",non-flaky,5
104098,spring-cloud_spring-cloud-config,ConfigClientAutoConfigurationTests.withParent,"	@Test
	public void withParent() {
		ConfigurableApplicationContext context = new SpringApplicationBuilder(
				ConfigClientAutoConfiguration.class).child(Object.class)
						.web(WebApplicationType.NONE).run();
		assertThat(BeanFactoryUtils.beanNamesForTypeIncludingAncestors(context,
				ConfigClientProperties.class).length).isEqualTo(1);
		context.close();
	}
",non-flaky,5
30919,camunda-cloud_zeebe,MsgPackWriterMiscTest.testEncodedArayHeaderLength,"  @Test
  public void testEncodedArayHeaderLength() {
    assertThat(MsgPackWriter.getEncodedArrayHeaderLenght(0x0f)).isEqualTo(1);
    assertThat(MsgPackWriter.getEncodedArrayHeaderLenght(0xffff)).isEqualTo(3);
    assertThat(MsgPackWriter.getEncodedArrayHeaderLenght(0x7fff_ffff)).isEqualTo(5);
  }
",non-flaky,5
38233,palantir_atlasdb,TextUtilsTest.testEscapeHtmlTwoByteUnicode,"    @Test
    public void testEscapeHtmlTwoByteUnicode() {
        assertTrue(""&#192;"".equals(TextUtils.escapeHtml(u00C0)));
        assertTrue(""&#256;"".equals(TextUtils.escapeHtml(u0100)));
        assertTrue(""&#288;"".equals(TextUtils.escapeHtml(u0120)));
    }
",non-flaky,5
26156,Ericsson_ecchronos,TestRepairManagementRESTImpl.testKeyspaceStatusMultipleEntries,"    @Test
    public void testKeyspaceStatusMultipleEntries()
    {
        RepairJobView job1 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(1234L)
                .withRepairInterval(11)
                .build();
        RepairJobView job2 = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withLastRepairedAt(2345L)
                .withRepairInterval(45)
                .build();
        RepairJobView job3 = new TestUtils.OnDemandRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb2"")
                .withCompletedAt(3456L)
                .build();
        List<RepairJobView> repairJobViews = Arrays.asList(
                job1,
                job2,
                job3
        );
        List<ScheduledRepairJob> expectedResponse = repairJobViews.stream()
                .map(ScheduledRepairJob::new)
                .collect(Collectors.toList());

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(repairJobViews);

        List<ScheduledRepairJob> response = GSON.fromJson(repairManagementREST.keyspaceStatus(""ks""), scheduledRepairJobListType);

        assertThat(response).isEqualTo(expectedResponse);
    }
",non-flaky,5
59647,looly_hutool,TemplateUtilTest.rythmEngineTest,"	@Test
	public void rythmEngineTest() {
		// å­ç¬¦ä¸²æ¨¡æ¿
		TemplateEngine engine = TemplateUtil.createEngine(
				new TemplateConfig(""templates"").setCustomEngine(RythmEngine.class));
		Template template = engine.getTemplate(""hello,@name"");
		String result = template.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result);

		// classpathä¸­è·åæ¨¡æ¿
		Template template2 = engine.getTemplate(""rythm_test.tmpl"");
		String result2 = template2.render(Dict.create().set(""name"", ""hutool""));
		Assert.assertEquals(""hello,hutool"", result2);
	}
",non-flaky,5
31004,camunda-cloud_zeebe,ArrayValueTest.shouldRemoveValueInBetween,"  @Test
  public void shouldRemoveValueInBetween() {
    // given
    addIntValues(array, 1, 2, 3);

    // when
    final Iterator<IntegerValue> iterator = array.iterator();
    iterator.next();
    iterator.next();
    iterator.remove();

    // then
    encodeAndDecode(array);
    assertIntValues(array, 1, 3);
  }
",non-flaky,5
91414,strapdata_elassandra,WatchBackwardsCompatibilityIT.waitForSecuritySetup,"@TestLogging(""org.elasticsearch.client:TRACE"")
    public void waitForSecuritySetup() throws Exception {

        String masterNode = null;
        String catNodesResponse = EntityUtils.toString(
                client().performRequest(""GET"", ""/_cat/nodes?h=id,master"").getEntity(),
                StandardCharsets.UTF_8
        );
        for (String line : catNodesResponse.split(""\n"")) {
            int indexOfStar = line.indexOf('*'); // * in the node's output denotes it is master
            if (indexOfStar != -1) {
                masterNode = line.substring(0, indexOfStar).trim();
                break;
            }
        }
        assertNotNull(masterNode);
        final String masterNodeId = masterNode;

        assertBusy(() -> {
            try {
                Response nodeDetailsResponse = client().performRequest(""GET"", ""/_nodes"");
                ObjectPath path = ObjectPath.createFromResponse(nodeDetailsResponse);
                Map<String, Object> nodes = path.evaluate(""nodes"");
                assertThat(nodes.size(), greaterThanOrEqualTo(2));
                String masterVersion = null;
                for (String key : nodes.keySet()) {
                    // get the ES version number master is on
                    if (key.startsWith(masterNodeId)) {
                        masterVersion = path.evaluate(""nodes."" + key + "".version"");
                        break;
                    }
                }
                assertNotNull(masterVersion);
                final String masterTemplateVersion = masterVersion;

                Response response = client().performRequest(""GET"", ""/_cluster/state/metadata"");
                ObjectPath objectPath = ObjectPath.createFromResponse(response);
                final String mappingsPath = ""metadata.templates.security-index-template.mappings"";
                Map<String, Object> mappings = objectPath.evaluate(mappingsPath);
                assertNotNull(mappings);
                assertThat(mappings.size(), greaterThanOrEqualTo(1));
                for (String key : mappings.keySet()) {
                    String templateVersion = objectPath.evaluate(mappingsPath + ""."" + key + """" +
                            ""._meta.security-version"");
                    final Version mVersion = Version.fromString(masterTemplateVersion);
                    final Version tVersion = Version.fromString(templateVersion);
                    assertEquals(mVersion, tVersion);
                }
            } catch (Exception e) {
                throw new AssertionError(""failed to get cluster state"", e);
            }
        });

        nodes = buildNodeAndVersions();
        logger.info(""Nodes in cluster before test: bwc [{}], new [{}], master [{}]"", nodes.getBWCNodes(), nodes.getNewNodes(),
                nodes.getMaster());

        Map<String, String> params = Collections.singletonMap(""error_trace"", ""true"");
        executeAgainstMasterNode(client -> {
            // create a watch before each test, most of the time this is just overwriting...
            assertOK(client.performRequest(""PUT"", ""/_xpack/watcher/watch/my-watch"", params, entity));
            // just a check to see if we can execute a watch, purely optional
            if (randomBoolean()) {
                assertOK(client.performRequest(""POST"", ""/_xpack/watcher/watch/my-watch/_execute"", params,
                        new StringEntity(""{ \""record_execution\"" : true }"", ContentType.APPLICATION_JSON)));
            }
            if (randomBoolean()) {
                Map<String, String> ignore404Params = MapBuilder.newMapBuilder(params).put(""ignore"", ""404"").immutableMap();
                Response indexExistsResponse = client.performRequest(""HEAD"", ""/.triggered_watches"", ignore404Params);
                if (indexExistsResponse.getStatusLine().getStatusCode() == 404) {
                    logger.info(""Created triggered watches index to ensure it gets upgraded"");
                    client.performRequest(""PUT"", ""/.triggered_watches"");
                }
            }
        });

        // helping debugging output
        executeAgainstMasterNode(client -> {
            Map<String, String> filterPathParams = MapBuilder.newMapBuilder(params)
                    .put(""filter_path"", ""*.template,*.index_patterns"").immutableMap();
            Response r = client.performRequest(""GET"", ""_template/*watch*"", filterPathParams);
            logger.info(""existing watcher templates response [{}]"", EntityUtils.toString(r.getEntity(), StandardCharsets.UTF_8));
        });

        // set logging to debug
//        executeAgainstMasterNode(client -> {
//            StringEntity entity = new StringEntity(""{ \""transient\"" : { \""logger.org.elasticsearch.xpack.watcher\"" : \""TRACE\"" } }"",
//                    ContentType.APPLICATION_JSON);
//            Response response = client.performRequest(""PUT"", ""_cluster/settings"", params, entity);
//            logger.info(""cluster update settings response [{}]"", EntityUtils.toString(response.getEntity(), StandardCharsets.UTF_8));
//        });
    }
",non-flaky,5
113979,apache_struts,ParameterTest.shouldConvertRequestValuesToStringArrays,"    @Test(dataProvider = ""paramValues"")
    public void shouldConvertRequestValuesToStringArrays(Object input, String[] expected) {
        Parameter.Request request = new Parameter.Request(PARAM_NAME, input);

        String[] result = request.getMultipleValues();

        assertEquals(result, expected);
        assertNotSame(result, input);
    }
",non-flaky,5
38217,palantir_atlasdb,TextUtilsTest.testProperCaseWords,"    @Test
    public void testProperCaseWords() throws Exception {
        String[] words = new String[] { ""AA102"", ""nw"", ""dog"", ""daVID CHiu"", ""yu-gi-oh rules"",
                ""b.j. penn the great,shawn sherk""};
        String[] results = new String[] { ""AA102"", ""Nw"", ""Dog"", ""David Chiu"", ""Yu-Gi-Oh Rules"",
                ""B.J. Penn The Great,Shawn Sherk""};
        for (int i=0; i < words.length; i++) {
            String result = TextUtils.properCaseWords(words[i]);
            assertEquals(results[i], result);
        }
    }
",non-flaky,5
33729,alibaba_fastjson,FastJsonJsonViewTest.test2,"	@Test
	public void test2() throws Exception {
		
		String jsonStr = ""[{\""name\"":\""p1\"",\""sonList\"":[{\""name\"":\""s1\""}]},{\""name\"":\""p2\"",\""sonList\"":[{\""name\"":\""s2\""},{\""name\"":\""s3\""}]}]"";
		
		mockMvc.perform(
				(post(""/fastjson/test2"").characterEncoding(""UTF-8"").content(jsonStr).contentType(MediaType.APPLICATION_JSON)
						))
//		.andExpect(status().isOk())
				.andDo(print());
	}
",non-flaky,5
26185,Ericsson_ecchronos,TestScheduledJobQueue.testRemoveJobInQueueIsPossible,"    @Test
    public void testRemoveJobInQueueIsPossible()
    {
        DummyJob job = new DummyJob(Priority.HIGH);
        DummyJob job2 = new DummyJob(Priority.LOW);

        queue.add(job);
        queue.add(job2);

        Iterator<ScheduledJob> iterator = queue.iterator();

        queue.remove(job2);

        assertThat(iterator).toIterable().containsExactly(job, job2);
        assertThat(queue.iterator()).toIterable().containsExactly(job);
    }
",non-flaky,5
122551,vespa-engine_vespa,SystemCtlTesterTest.return_expectations,"    @Test
    public void return_expectations() {
        assertSystemCtlMethod(sct -> sct.expectEnable(unit), sc -> sc.enable(unit).converge(context));
        assertSystemCtlMethod(sct -> sct.expectDisable(unit), sc -> sc.disable(unit).converge(context));
        assertSystemCtlMethod(sct -> sct.expectStart(unit), sc -> sc.start(unit).converge(context));
        assertSystemCtlMethod(sct -> sct.expectStop(unit), sc -> sc.stop(unit).converge(context));
        assertSystemCtlMethod(sct -> sct.expectServiceExists(unit), sc -> sc.serviceExists(context, unit));
        assertSystemCtlMethod(sct -> sct.expectIsActive(unit), sc -> sc.isActive(context, unit));
    }
",non-flaky,5
170458,eclipse_jetty.project,ObjectMBeanTest.testMetaDataCaching,"    @Test
    public void testMetaDataCaching()
    {
        Derived derived = new Derived();
        ObjectMBean derivedMBean = (ObjectMBean)container.mbeanFor(derived);
        ObjectMBean derivedMBean2 = (ObjectMBean)container.mbeanFor(derived);
        assertNotSame(derivedMBean, derivedMBean2);
        assertSame(derivedMBean.metaData(), derivedMBean2.metaData());
    }
",non-flaky,5
104097,spring-cloud_spring-cloud-config,ConfigClientAutoConfigurationTests.sunnyDay,"	@Test
	public void sunnyDay() {
		AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(
				ConfigClientAutoConfiguration.class);
		assertThat(BeanFactoryUtils.beanNamesForTypeIncludingAncestors(context,
				ConfigClientProperties.class).length).isEqualTo(1);
		context.close();
	}
",non-flaky,5
98225,apache_jackrabbit,CreateRepositoryTest.createRepositories,"    @Test
    public void createRepositories() throws Exception {
        doCreateRepositories(""jackrabbit-2.2"");
    }
",non-flaky,5
76998,Tencent_Firestorm,PartitionBalanceCoordinatorGrpcTest.getShuffleAssignmentsTest,"  @Test
  public void getShuffleAssignmentsTest() throws Exception {
    CoordinatorTestUtils.waitForRegister(coordinatorClient, 3);
    RssGetShuffleAssignmentsRequest request = new RssGetShuffleAssignmentsRequest(
        ""app1"",
        1,
        1,
        1,
        1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    RssGetShuffleAssignmentsResponse response = coordinatorClient.getShuffleAssignments(request);
    assertEquals(1, response.getPartitionToServers().size());
    for (Map.Entry<Integer, List<ShuffleServerInfo>> entry : response.getPartitionToServers().entrySet()) {
      assertEquals(1, entry.getValue().size());
      assertEquals(SHUFFLE_SERVER_PORT + 1, entry.getValue().get(0).getPort());
    }
    request = new RssGetShuffleAssignmentsRequest(
        ""app1"",
        2,
        1,
        1,
        1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    response = coordinatorClient.getShuffleAssignments(request);
    assertEquals(1, response.getPartitionToServers().size());
    for (Map.Entry<Integer, List<ShuffleServerInfo>> entry : response.getPartitionToServers().entrySet()) {
      assertEquals(1, entry.getValue().size());
      assertEquals(SHUFFLE_SERVER_PORT + 1, entry.getValue().get(0).getPort());
    }
    request = new RssGetShuffleAssignmentsRequest(
        ""app1"",
        2,
        1,
        1,
        1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    response = coordinatorClient.getShuffleAssignments(request);
    assertEquals(1, response.getPartitionToServers().size());
    for (Map.Entry<Integer, List<ShuffleServerInfo>> entry : response.getPartitionToServers().entrySet()) {
      assertEquals(1, entry.getValue().size());
      assertEquals(SHUFFLE_SERVER_PORT, entry.getValue().get(0).getPort());
    }
  }
",non-flaky,5
179459,abel533_Mapper,FieldHelperTest.run,"    @Test
    public void test2() throws IntrospectionException {
        Thread t1 = new Thread(new Runnable() {
            @Override
            public void run() {
                FieldHelper.getFields(Country.class);
            }
",non-flaky,5
26247,Ericsson_ecchronos,TestTableRepairJob.testStatusError,"    @Test
    public void testStatusError()
    {
        long repairedAt = System.currentTimeMillis() - TimeUnit.DAYS.toMillis(10);
        VnodeRepairState vnodeRepairState = TestUtils.createVnodeRepairState(1, 2, ImmutableSet.of(), repairedAt);
        VnodeRepairStatesImpl vnodeRepairStates = VnodeRepairStatesImpl.newBuilder(Arrays.asList(vnodeRepairState)).build();
        when(myRepairStateSnapshot.getVnodeRepairStates()).thenReturn(vnodeRepairStates);
        doReturn(repairedAt).when(myRepairStateSnapshot).lastCompletedAt();

        assertThat(myRepairJob.getView().getStatus()).isEqualTo(RepairJobView.Status.ERROR);
    }
",non-flaky,5
135016,undertow-io_undertow,AjpClientTestCase.completed,"    @Test
    public void testPostRequest() throws Exception {
        //
        final UndertowClient client = createClient();
        final String postMessage = ""This is a post request"";

        final List<String> responses = new CopyOnWriteArrayList<>();
        final CountDownLatch latch = new CountDownLatch(10);
        final ClientConnection connection = client.connect(ADDRESS, worker, DefaultServer.getBufferPool(), OptionMap.EMPTY).get();
        try {
            connection.getIoThread().execute(new Runnable() {
                @Override
                public void run() {
                    for (int i = 0; i < 10; i++) {
                        final ClientRequest request = new ClientRequest().setMethod(Methods.POST).setPath(POST);
                        request.getRequestHeaders().put(Headers.HOST, DefaultServer.getHostAddress());
                        request.getRequestHeaders().put(Headers.TRANSFER_ENCODING, ""chunked"");
                        connection.sendRequest(request, new ClientCallback<ClientExchange>() {
                            @Override
                            public void completed(ClientExchange result) {
                                new StringWriteChannelListener(postMessage).setup(result.getRequestChannel());
                                result.setResponseListener(new ClientCallback<ClientExchange>() {
                                    @Override
                                    public void completed(ClientExchange result) {
                                        new StringReadChannelListener(DefaultServer.getBufferPool()) {

                                            @Override
                                            protected void stringDone(String string) {
                                                responses.add(string);
                                                latch.countDown();
                                            }

                                            @Override
                                            protected void error(IOException e) {
                                                e.printStackTrace();
                                                latch.countDown();
                                            }
                                        }.setup(result.getResponseChannel());
                                    }
",non-flaky,5
92627,apache_dubbo,ApplicationConfigTest.testVersion,"    @Test
    public void testVersion() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setVersion(""1.0.0"");
        assertThat(application.getVersion(), equalTo(""1.0.0""));
        Map<String, String> parameters = new HashMap<String, String>();
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(""application.version"", ""1.0.0""));
    }
",non-flaky,5
96033,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher10,"  @Test
  public void testTokenSequenceMatcher10() throws IOException {
    CoreMap doc = createDocument(""the number is five or 5 or 5.0 or but not 5x or -5 or 5L."");

    // Test simplified pattern with number
    TokenSequencePattern p = TokenSequencePattern.compile( ""(five|5|5x|5.0|-5|5L)"");

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""five"", m.group(1));

    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""5"", m.group(1));

    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""5.0"", m.group(1));

    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""5x"", m.group(1));

    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""-5"", m.group(1));

    match = m.find();
    assertTrue(match);
    assertEquals(1, m.groupCount());
    assertEquals(""5L"", m.group(1));

    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
150186,apache_hive,TestHplsqlLocal.testSub,"  @Test
  public void testSub() throws Exception {
    run(""sub"");
  }
",non-flaky,5
92692,apache_dubbo,ProviderConfigTest.testPrompt,"    @Test
    public void testPrompt() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setPrompt(""#"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.getPrompt(), equalTo(""#""));
        assertThat(parameters, hasEntry(""prompt"", ""%23""));
    }
",non-flaky,5
88864,apache_ignite,DatasetAffinityFunctionWrapperTest.testPartition,"    @Test
    public void testPartition() {
        doReturn(0).when(affinityFunction).partition(eq(42));

        int part = wrapper.partition(42);

        assertEquals(42, part);
        verify(affinityFunction, times(0)).partition(any());
    }
",non-flaky,5
84608,apache_zookeeper,ExportJvmInfoTest.exportInfo,"    @Test
    public void exportInfo() throws Exception {
        runTest(true);
    }
",non-flaky,5
162389,testcontainers_testcontainers-java,MountableFileTest.forHostFilePathWithPermission,"    @Test
    public void forHostFilePathWithPermission() throws Exception {
        final Path file = createTempFile(""somepath"");
        final MountableFile mountableFile = MountableFile.forHostPath(file.toString(), TEST_FILE_MODE);
        performChecks(mountableFile);
        assertEquals(""Valid file mode."", BASE_FILE_MODE | TEST_FILE_MODE, mountableFile.getFileMode());
    }
",non-flaky,5
335,epimorphics_appbase,TestMonitor.testMonitor,"@Test
public void testMonitor() throws IOException, InterruptedException {
    monitor.setScanInterval(5);
    assertTrue(monitor.getEntries().isEmpty());
    File fooFile = touchFile(""foo"", ""foo1"");
    Thread.sleep(MONITOR_CHECK_DELAY);
    Collection<TestInstance> entries = monitor.getEntries();
    assertEquals(1, entries.size());
    TestInstance[] entryArray = new TestInstance[1];
    entryArray = entries.toArray(entryArray);
    TestInstance fooInst = entryArray[0];
    assertEquals(""foo1"", fooInst.getMessage());
    touchFile(""bar"", ""bar1"");
    Thread.sleep(MONITOR_CHECK_DELAY);
    entries = monitor.getEntries();
    assertEquals(2, entries.size());
    TestInstance fooCheck = monitor.get(""foo"");
    TestUtil.testArray(entryNames(entries), new String[]{ ""foo1"", ""bar1"" });
    assertEquals(fooCheck, fooInst);
    touchFile(""foo"", ""foo2"");
    Thread.sleep(MONITOR_CHECK_DELAY);
    entries = monitor.getEntries();
    assertEquals(2, entries.size());
    TestUtil.testArray(entryNames(entries), new String[]{ ""foo2"", ""bar1"" });
    fooCheck = monitor.get(""foo"");
    assertNotSame(fooInst, fooCheck);
    assertEquals(""foo2"", fooCheck.getMessage());
    fooFile.delete();
    Thread.sleep(MONITOR_CHECK_DELAY);
    entries = monitor.getEntries();
    assertEquals(1, entries.size());
    TestUtil.testArray(entryNames(entries), new String[]{ ""bar1"" });
}",async wait,0
70794,apache_kafka,DelegatingClassLoaderTest.testLoadingPluginClass,"    @Test
    public void testLoadingPluginClass() throws ClassNotFoundException {
        TestPlugins.assertAvailable();
        DelegatingClassLoader classLoader = new DelegatingClassLoader(TestPlugins.pluginPath());
        classLoader.initLoaders();
        for (String pluginClassName : TestPlugins.pluginClasses()) {
            assertNotNull(classLoader.loadClass(pluginClassName));
            assertNotNull(classLoader.pluginClassLoader(pluginClassName));
        }
    }
",non-flaky,5
118709,netty_netty,SmtpResponseDecoderTest.testDecodeInvalidSeparator,"    @Test(expected = DecoderException.class)
    public void testDecodeInvalidSeparator() {
        EmbeddedChannel channel = newChannel();
        assertTrue(channel.writeInbound(newBuffer(""200:Ok\r\n"")));
    }
",non-flaky,5
114083,aws_aws-sdk-java-v2,KeyTest.getKeyMap,"    @Test
    public void getKeyMap() {
        Map<String, AttributeValue> expectedResult = new HashMap<>();
        expectedResult.put(""gsi_id"", AttributeValue.builder().s(""id123"").build());
        expectedResult.put(""gsi_sort"", AttributeValue.builder().s(""id456"").build());
        assertThat(key.keyMap(FakeItemWithIndices.getTableSchema(), ""gsi_1""), is(expectedResult));
    }
",non-flaky,5
26162,Ericsson_ecchronos,TestRepairManagementRESTImpl.testIdEntryEmpty,"    @Test
    public void testIdEntryEmpty()
    {
        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.emptyList());

        String response = repairManagementREST.jobStatus(UUID.randomUUID().toString());

        assertThat(response).isEqualTo(""{}"");
    }
",non-flaky,5
89303,apache_samza,TestMonitorService.testShouldFailWhenTheMonitorFactoryClassIsInvalid,"  @Test(expected = SamzaException.class)
  public void testShouldFailWhenTheMonitorFactoryClassIsInvalid() {
    // Test that when MonitorFactoryClass is defined in the config and is invalid,
    // monitor service should fail. Should throw back SamzaException.
    Map<String, String> configMap = ImmutableMap.of(String.format(""monitor.name.%s"", CONFIG_MONITOR_FACTORY_CLASS),
                                                    ""RandomClassName"");
    SamzaRestConfig config = new SamzaRestConfig(new MapConfig(configMap));
    SamzaMonitorService monitorService = new SamzaMonitorService(config,
                                                                 METRICS_REGISTRY);
    monitorService.start();
  }
",non-flaky,5
26213,Ericsson_ecchronos,TestRepairSchedulerImpl.testRemoveTableConfiguration,"    @Test
    public void testRemoveTableConfiguration()
    {
        RepairSchedulerImpl repairSchedulerImpl = defaultRepairSchedulerImplBuilder().build();

        repairSchedulerImpl.putConfiguration(TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        verify(scheduleManager, timeout(1000)).schedule(any(ScheduledJob.class));
        verify(scheduleManager, never()).deschedule(any(ScheduledJob.class));
        verify(myRepairStateFactory).create(eq(TABLE_REFERENCE), eq(RepairConfiguration.DEFAULT), any());
        verify(myRepairState, atLeastOnce()).update();
        assertOneTableViewExist(repairSchedulerImpl, TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        repairSchedulerImpl.removeConfiguration(TABLE_REFERENCE);
        verify(scheduleManager, timeout(1000)).deschedule(any(ScheduledJob.class));
        assertThat(repairSchedulerImpl.getCurrentRepairJobs()).isEmpty();

        repairSchedulerImpl.close();
        verifyNoMoreInteractions(ignoreStubs(myTableRepairMetrics));
        verifyNoMoreInteractions(myRepairStateFactory);
        verifyNoMoreInteractions(scheduleManager);
    }
",non-flaky,5
170462,eclipse_jetty.project,MBeanContainerLifeCycleTest.prepare,"    @BeforeEach
    public void prepare() throws Exception
    {
        container = new ContainerLifeCycle();
        mbeanServer = ManagementFactory.getPlatformMBeanServer();
        MBeanContainer mbeanContainer = new MBeanContainer(mbeanServer);
        container.addBean(mbeanContainer);
        container.start();
    }
",non-flaky,5
113860,spring-projects_spring-data-couchbase,FluxTest.cbse,"	@Test
	public void cbse() {
		LinkedList<LinkedList<Airport>> listOfLists = new LinkedList<>();
		Airport a = new Airport(UUID.randomUUID().toString(), ""iata"", ""lowp"");
		String last = null;
		for (int i = 0; i < 5; i++) {
			LinkedList<Airport> list = new LinkedList<>();
			for (int j = 0; j < 10; j++) {
				list.add(a.withId(UUID.randomUUID().toString()));
				last = a.getId();
			}
			listOfLists.add(list);
		}
		Flux<Object> af = Flux.fromIterable(listOfLists).concatMap(catalogToStore -> Flux.fromIterable(catalogToStore)
				.parallel(4).runOn(Schedulers.parallel()).concatMap((entity) -> airportRepository.save(entity)));
		List<Object> saved = af.collectList().block();
		System.out.println(""results.size() : "" + saved.size());

		String statement = ""select * from `"" + /*config().bucketname()*/ ""_default"" + ""` where META().id >= '"" + last + ""'"";
		System.out.println(""statement: "" + statement);
		try {
			QueryResult qr = couchbaseTemplate.getCouchbaseClientFactory().getScope().query(statement,
					QueryOptions.queryOptions().profile(QueryProfile.PHASES));
			List<RemoveResult> rr = couchbaseTemplate.removeByQuery(Airport.class)
					.withOptions(QueryOptions.queryOptions().scanConsistency(QueryScanConsistency.REQUEST_PLUS)).all();
			System.out.println(qr.metaData().profile().get());
		} catch (Exception e) {
			e.printStackTrace();
			throw e;
		}
		List<Airport> airports = airportRepository.findAll().collectList().block();
		assertEquals(0, airports.size(), ""should have been all deleted"");
	}
",non-flaky,5
118710,netty_netty,SmtpResponseDecoderTest.testDecodeInvalidCode,"    @Test(expected = DecoderException.class)
    public void testDecodeInvalidCode() {
        EmbeddedChannel channel = newChannel();
        assertTrue(channel.writeInbound(newBuffer(""xyz Ok\r\n"")));
    }
",non-flaky,5
98241,apache_jackrabbit,PerformanceTest.testPerformance,"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""1.2"");
    }
",non-flaky,5
98429,ONSdigital_rm-collection-exercise-service,CollectionExerciseServiceTest.testPatchCollectionExerciseName,"  @Test
  public void testPatchCollectionExerciseName() throws Exception {
    CollectionExercise existing = setupCollectionExercise();
    CollectionExerciseDTO collex = new CollectionExerciseDTO();
    String name = ""Not BRES"";
    SurveyDTO survey = FixtureHelper.loadClassFixtures(SurveyDTO[].class).get(0);
    when(surveyService.findSurvey(any())).thenReturn(survey);
    this.collectionExerciseService.patchCollectionExercise(existing.getId(), collex);

    ArgumentCaptor<CollectionExercise> captor = ArgumentCaptor.forClass(CollectionExercise.class);
    verify(this.collexRepo).saveAndFlush(captor.capture());

    CollectionExercise ce = captor.getValue();
    assertNotNull(ce.getUpdated());
  }
",non-flaky,5
159660,liquibase_liquibase,AbstractIntegrationTest.testInvalidIncludeDoesntBreakLiquibase,"    @Test
    public void testInvalidIncludeDoesntBreakLiquibase() throws Exception {
        assumeNotNull(this.getDatabase());
        Liquibase liquibase = createLiquibase(invalidReferenceChangeLog);
        try {
            liquibase.update(new Contexts());
            fail(""Did not fail with invalid include"");
        } catch (ChangeLogParseException ignored) {
            //expected
        }

        LockService lockService = LockServiceFactory.getInstance().getLockService(database);
        assertFalse(lockService.hasChangeLogLock());
    }
",non-flaky,5
134987,undertow-io_undertow,JsrWebsocketExtensionTestCase.testExtensionsHeaders,"    @Test
    public void testExtensionsHeaders() throws Exception {


        final String SEC_WEBSOCKET_EXTENSIONS = ""permessage-deflate; client_no_context_takeover; client_max_window_bits"";
        final String SEC_WEBSOCKET_EXTENSIONS_EXPECTED = ""[permessage-deflate; client_no_context_takeover]"";  // List format
        List<WebSocketExtension> extensions = WebSocketExtension.parse(SEC_WEBSOCKET_EXTENSIONS);

        final WebSocketClientNegotiation negotiation = new WebSocketClientNegotiation(null, extensions);

        Set<ExtensionHandshake> extensionHandshakes = new HashSet<>();
        extensionHandshakes.add(new PerMessageDeflateHandshake(true));

        final WebSocketChannel clientChannel = WebSocketClient.connect(DefaultServer.getWorker(), null, DefaultServer.getBufferPool(), OptionMap.EMPTY, new URI(DefaultServer.getDefaultServerURL()), WebSocketVersion.V13, negotiation, extensionHandshakes).get();

        final CountDownLatch latch = new CountDownLatch(1);
        final AtomicReference<String> result = new AtomicReference<>();

        clientChannel.getReceiveSetter().set(new AbstractReceiveListener() {
            @Override
            protected void onFullTextMessage(WebSocketChannel channel, BufferedTextMessage message) throws IOException {
                String data = message.getData();
                WebSocketLogger.ROOT_LOGGER.info(""onFullTextMessage - Client - Received: "" + data.getBytes().length + "" bytes . Data: "" + data);
                result.set(data);
                latch.countDown();
            }

            @Override
            protected void onFullCloseMessage(WebSocketChannel channel, BufferedBinaryMessage message) throws IOException {
                message.getData().close();
                WebSocketLogger.ROOT_LOGGER.info(""onFullCloseMessage"");
            }

            @Override
            protected void onError(WebSocketChannel channel, Throwable error) {
                WebSocketLogger.ROOT_LOGGER.info(""onError"");
                super.onError(channel, error);
                error.printStackTrace();
                latch.countDown();
            }

        });
        clientChannel.resumeReceives();

        StreamSinkFrameChannel sendChannel = clientChannel.send(WebSocketFrameType.TEXT);
        new StringWriteChannelListener(""Hello, World!"").setup(sendChannel);

        latch.await(10, TimeUnit.SECONDS);
        Assert.assertEquals(""Hello, World!"", result.get());
        clientChannel.sendClose();

        Assert.assertEquals(SEC_WEBSOCKET_EXTENSIONS_EXPECTED, debug.getResponseExtensions().toString());
    }
",non-flaky,5
135744,Netflix_Hystrix,HystrixPropertyTest.testNested5,"    @Test
    public void testNested5() {
        HystrixProperty<String> nullValue = Factory.nullProperty();
        HystrixProperty<String> a = Factory.asProperty(nullValue, null);

        @SuppressWarnings(""unchecked"")
        HystrixProperty<String> withDefault = Factory.asProperty(a, Factory.asProperty(""b""));
        assertEquals(""b"", withDefault.get());
    }
",non-flaky,5
57200,apache_ozone,TestReconOmMetadataManagerImpl.testStart,"  @Test
  public void testStart() throws Exception {

    OMMetadataManager omMetadataManager = getOMMetadataManager();

    //Take checkpoint of the above OM DB.
    DBCheckpoint checkpoint = omMetadataManager.getStore()
        .getCheckpoint(true);
    File snapshotFile = new File(
        checkpoint.getCheckpointLocation().getParent() + ""/"" +
            ""om.snapshot.db_"" + System.currentTimeMillis());
    checkpoint.getCheckpointLocation().toFile().renameTo(snapshotFile);

    //Create new Recon OM Metadata manager instance.
    File reconOmDbDir = temporaryFolder.newFolder();
    OzoneConfiguration configuration = new OzoneConfiguration();
    configuration.set(OZONE_RECON_OM_SNAPSHOT_DB_DIR, reconOmDbDir
        .getAbsolutePath());
    FileUtils.copyDirectory(snapshotFile.getParentFile(), reconOmDbDir);

    ReconOMMetadataManager reconOMMetadataManager =
        new ReconOmMetadataManagerImpl(configuration, new ReconUtils());
    reconOMMetadataManager.start(configuration);

    Assert.assertNotNull(reconOMMetadataManager.getBucketTable());
    Assert.assertNotNull(reconOMMetadataManager.getVolumeTable()
        .get(""/sampleVol""));
    Assert.assertNotNull(reconOMMetadataManager.getBucketTable()
        .get(""/sampleVol/bucketOne""));
    Assert.assertNotNull(reconOMMetadataManager.getKeyTable(getBucketLayout())
        .get(""/sampleVol/bucketOne/key_one""));
    Assert.assertNotNull(reconOMMetadataManager.getKeyTable(getBucketLayout())
        .get(""/sampleVol/bucketOne/key_two""));
  }
",non-flaky,5
35668,cdapio_cdap,IntegrationTestBaseTest.testSQLQuery,"  @Test
  public void testSQLQuery() throws Exception {
    getTestManager().deployDatasetModule(NamespaceId.DEFAULT.datasetModule(""my-kv""), AppUsingCustomModule.Module.class);

    DatasetAdmin dsAdmin = getTestManager().addDatasetInstance(""myKeyValueTable"",
                                                               NamespaceId.DEFAULT.dataset(""myTable""));
    Assert.assertTrue(dsAdmin.exists());

    ApplicationManager appManager = deployApplication(NamespaceId.DEFAULT, AppUsingCustomModule.class);
    ServiceManager serviceManager = appManager.getServiceManager(""MyService"").start();
    serviceManager.waitForRun(ProgramRunStatus.RUNNING, 10, TimeUnit.SECONDS);

    put(serviceManager, ""a"", ""1"");
    put(serviceManager, ""b"", ""2"");
    put(serviceManager, ""c"", ""1"");

    try (
      Connection connection = getTestManager().getQueryClient(NamespaceId.DEFAULT);
      // the value (character) ""1"" corresponds to the decimal 49. In hex, that is 31.
      ResultSet results = connection.prepareStatement(""select key from dataset_mytable where hex(value) = '31'"")
        .executeQuery()
    ) {
      // run a query over the dataset
      Assert.assertTrue(results.next());
      Assert.assertEquals(""a"", results.getString(1));
      Assert.assertTrue(results.next());
      Assert.assertEquals(""c"", results.getString(1));
      Assert.assertFalse(results.next());
    }

    dsAdmin.drop();
    Assert.assertFalse(dsAdmin.exists());
  }
",non-flaky,5
33702,alibaba_fastjson,JSONScannerTest.checkTime8,"  @Test
  public void checkTime8() throws Throwable {

    // Arrange
    JSONScanner objectUnderTest = ((JSONScanner)Reflector.getInstance(""com.alibaba.fastjson.parser.JSONScanner""));
    objectUnderTest.hasSpecial = false;
    objectUnderTest.token = 0;
    objectUnderTest.locale = null;
    objectUnderTest.np = 0;
    objectUnderTest.features = 0;
    Reflector.setField(objectUnderTest, ""text"", """");
    objectUnderTest.calendar = null;
    objectUnderTest.matchStat = 0;
    objectUnderTest.bp = 0;
    Reflector.setField(objectUnderTest, ""len"", 0);
    objectUnderTest.stringDefaultValue = """";
    objectUnderTest.pos = 0;
    objectUnderTest.sp = 0;
    objectUnderTest.sbuf = null;
    objectUnderTest.ch = '\u0000';
    objectUnderTest.timeZone = null;
    objectUnderTest.eofPos = 0;
    char h0 = '1';
    char h1 = '9';
    char m0 = '1';
    char m1 = '\u0000';
    char s0 = '\u0000';
    char s1 = '\u0000';

    // Act
    Class<?> c = Reflector.forName(""com.alibaba.fastjson.parser.JSONScanner"");
    Method m = c.getDeclaredMethod(""checkTime"", Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""));
    m.setAccessible(true);
    boolean retval = (Boolean)m.invoke(objectUnderTest, h0, h1, m0, m1, s0, s1);

    // Assert result
    Assert.assertEquals(false, retval);

  }
",non-flaky,5
26771,MundaneImmortal_pair-distribution-app,DayPairsTest.testHasPair,"	@Test
	public void testHasPair() {
		DayPairs pairs = new DayPairs();
		Pair pair = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		Pair differentPair = new Pair();
		pairs.addPair(""track"", pair);
		
		assertThat(pairs.hasPair(pair), is(true));
		assertThat(pairs.hasPair(differentPair), is(false));
	}
",non-flaky,5
150205,apache_hive,TestBytesColumnVector.testSmallBufferReuse,"  @Test
  public void testSmallBufferReuse() {
    BytesColumnVector col = new BytesColumnVector();
    int smallWriteSize = 1024;
    int largeWriteSize = 1024 * 1024 * 2;

    int rowIdx = 0;
    int bytesWrittenToBytes1 = 0;
    col.reset();

    // Initial write (small value)
    byte[] bytes1 = writeToBytesColumnVector(rowIdx, col, smallWriteSize, (byte) 1);
    bytesWrittenToBytes1 += smallWriteSize;

    // Write a large value. This should use a different byte buffer
    rowIdx++;
    byte[] bytes2 = writeToBytesColumnVector(rowIdx, col, largeWriteSize, (byte) 2);
    assertFalse(bytes1 == bytes2);

    // Another small write. smallBuffer should be re-used for this write
    rowIdx++;
    byte[] bytes3 = writeToBytesColumnVector(rowIdx, col, smallWriteSize, (byte) 1);
    bytesWrittenToBytes1 += smallWriteSize;
    assertTrue(bytes1 == bytes3);

    // Write another large value. This should use a different byte buffer
    rowIdx++;
    byte[] bytes4 = writeToBytesColumnVector(rowIdx, col, largeWriteSize, (byte) 3);
    assertFalse(bytes1 == bytes4);
    assertFalse(bytes2 == bytes4);

    // Eventually enough small writes should result in another buffer getting created
    boolean gotNewBuffer = false;
    // Test is dependent on getting a new buffer within 1MB.
    // This may need to change as the implementation changes.
    for (int i = 0; i < 1024; ++i) {
      rowIdx++;
      byte[] currBytes = writeToBytesColumnVector(rowIdx, col, smallWriteSize, (byte) 1);
      if (currBytes == bytes1) {
        bytesWrittenToBytes1 += smallWriteSize;
      } else {
        gotNewBuffer = true;
        break;
      }
    }

    assertTrue(gotNewBuffer);

    // All small writes to the first buffer should be in contiguous memory
    for (int i = 0; i < bytesWrittenToBytes1; ++i) {
      assertEquals((byte) 1, bytes1[i]);
    }
  }
",non-flaky,5
78238,apache_beam,SimplePushbackSideInputDoFnRunnerTest.testOnTimerCalled,"  @Test
  public void testOnTimerCalled() {
    PushbackSideInputDoFnRunner<Integer, Integer> runner = createRunner(ImmutableList.of());

    String timerId = ""fooTimer"";
    IntervalWindow window = new IntervalWindow(new Instant(4), new Instant(16));
    Instant timestamp = new Instant(72);

    // Mocking is not easily compatible with annotation analysis, so we manually record
    // the method call.
    runner.onTimer(timerId, window, new Instant(timestamp), TimeDomain.EVENT_TIME);

    assertThat(
        underlying.firedTimers,
        contains(
            TimerData.of(
                timerId,
                StateNamespaces.window(IntervalWindow.getCoder(), window),
                timestamp,
                TimeDomain.EVENT_TIME)));
  }
",non-flaky,5
43089,trinodb_trino,AbstractTestIntegrationSmokeTest.testIsNullPredicate,"    @Test
    public void testIsNullPredicate()
    {
        assertQueryReturnsEmptyResult(""SELECT * FROM orders WHERE orderkey IS NULL"");
        assertQueryReturnsEmptyResult(""SELECT * FROM orders WHERE orderkey = 10 OR orderkey IS NULL"");

        // filtered column is selected
        assertQuery(""SELECT custkey, orderkey FROM orders WHERE orderkey = 32 OR orderkey IS NULL"", ""VALUES (1301, 32)"");

        // filtered column is not selected
        assertQuery(""SELECT custkey FROM orders WHERE orderkey = 32 OR orderkey IS NULL"", ""VALUES (1301)"");
    }
",non-flaky,5
179506,abel533_Mapper,StyleTest.testCamelhump,"    @Test
    public void testCamelhump() {
        for (String field : fields) {
            System.out.println(field + "" - "" + StringUtil.convertByStyle(field, Style.camelhump));
        }
    }
",non-flaky,5
38239,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRowsWithSelectedColumns,"    @Test
    public void testGetRowsWithSelectedColumns() {
        putTestDataForSingleTimestamp();
        ColumnSelection columns1and2 = ColumnSelection.create(Arrays.asList(column1, column2));
        Map<Cell, Value> values = keyValueService.getRows(TEST_TABLE,
                                                          Arrays.asList(row1, row2),
                                                          columns1and2,
                                                          TEST_TIMESTAMP + 1);
        assertEquals(3, values.size());
        assertEquals(null, values.get(Cell.create(row1, column0)));
        assertArrayEquals(value12, values.get(Cell.create(row1, column2)).getContents());
        assertArrayEquals(value21, values.get(Cell.create(row2, column1)).getContents());
        assertArrayEquals(value22, values.get(Cell.create(row2, column2)).getContents());
    }
",non-flaky,5
122628,vespa-engine_vespa,YumTesterTest.expect_query_installed,"    @Test
    public void expect_query_installed() {
        Stream.of(minimalPackage, fullPackage, null).forEach(pkg -> {
            yum.expectQueryInstalled(packages[0]).andReturn(pkg);
            assertEquals(Optional.ofNullable(pkg), yum.queryInstalled(context, packages[0]));
            terminal.verifyAllCommandsExecuted();
        });
    }
",non-flaky,5
78279,apache_beam,StateTagTest.testMapEquality,"  @Test
  public void testMapEquality() {
    StateTag<?> fooStringVarInt1 = StateTags.map(""foo"", StringUtf8Coder.of(), VarIntCoder.of());
    StateTag<?> fooStringVarInt2 = StateTags.map(""foo"", StringUtf8Coder.of(), VarIntCoder.of());
    StateTag<?> fooStringBigEndian =
        StateTags.map(""foo"", StringUtf8Coder.of(), BigEndianIntegerCoder.of());
    StateTag<?> fooVarIntBigEndian =
        StateTags.map(""foo"", VarIntCoder.of(), BigEndianIntegerCoder.of());
    StateTag<?> barStringVarInt = StateTags.map(""bar"", StringUtf8Coder.of(), VarIntCoder.of());

    assertEquals(fooStringVarInt1, fooStringVarInt2);
    assertNotEquals(fooStringVarInt1, fooStringBigEndian);
    assertNotEquals(fooStringBigEndian, fooVarIntBigEndian);
    assertNotEquals(fooStringVarInt1, fooVarIntBigEndian);
    assertNotEquals(fooStringVarInt1, barStringVarInt);
  }
",non-flaky,5
33747,alibaba_fastjson,FastJsonpHttpMessageConverter4Case2Test.test1,"    @Test
    public void test1() throws Exception {

        JSONObject json = new JSONObject();

        json.put(""id"", 123);

        json.put(""name"", ""ååå"");

        mockMvc.perform(
                (post(""/fastjson/test1"").characterEncoding(""UTF-8"").content(json.toJSONString())
                        .contentType(MediaType.APPLICATION_JSON))).andExpect(status().isOk()).andDo(print());
    }
",non-flaky,5
89279,apache_samza,TestJobsResource.testPutJobs,"  @Test
  public void testPutJobs()
      throws IOException {
    Response resp = target(""v1/jobs"").request().put(Entity.text(""""));
    assertEquals(405, resp.getStatus());
    resp.close();
  }
",non-flaky,5
76731,quarkusio_quarkus,JarRunnerIT.testThatMutableFastJarWorksProvidersDirOutsideOutputDir,"    @Test
    public void testThatMutableFastJarWorksProvidersDirOutsideOutputDir() throws Exception {
        assertThatMutableFastJarWorks(""outsidedir"", "".."" + File.separator + ""providers"");
    }
",non-flaky,5
170535,eclipse_jetty.project,TestAnnotationInheritance.testParseClassNames,"    @Test
    public void testParseClassNames() throws Exception
    {
        classNames.add(ClassA.class.getName());
        classNames.add(ClassB.class.getName());

        SampleHandler handler = new SampleHandler();
        AnnotationParser parser = new AnnotationParser();
        parser.parse(Collections.singleton(handler), classNames);

        //check we got  2 class annotations
        assertEquals(2, handler.annotatedClassNames.size());

        //check we got all annotated methods on each class
        assertEquals(7, handler.annotatedMethods.size());
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.a""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.b""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.c""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.d""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassA.l""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassB.a""));
        assertTrue(handler.annotatedMethods.contains(""org.eclipse.jetty.annotations.ClassB.c""));

        //check we got all annotated fields on each class
        assertEquals(1, handler.annotatedFields.size());
        assertEquals(""org.eclipse.jetty.annotations.ClassA.m"", handler.annotatedFields.get(0));
    }
",non-flaky,5
104677,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testGeneratedQueriesWithMultiValues,"  @Test(enabled = false)
  public void testGeneratedQueriesWithMultiValues() {
  }
",non-flaky,5
26729,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testIsRotationTimeForEmptyHistory,"	@Test
	public void testIsRotationTimeForEmptyHistory() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(new ArrayList<>());
		Company company = new Company(""myCompany"");
		company.setDevOpsRotationStrategy(""weekly"");
		devPairCombinations.setCompany(company);

		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1""), getStandardDevs(), false), is(false));
	}
",non-flaky,5
156116,soot-oss_soot,AbstractLambdaMetaFactoryCGTest.lambdaWithCaptures,"  @Test
  public void lambdaWithCaptures() {
    String testClass = ""soot.lambdaMetaFactory.LambdaWithCaptures"";

    final SootMethod target
        = prepareTarget(methodSigFromComponents(testClass, TEST_METHOD_RET, TEST_METHOD_NAME), testClass);

    final CallGraph cg = Scene.v().getCallGraph();

    final String metaFactoryClass = getMetaFactoryNameLambda(testClass, TEST_METHOD_NAME);

    final SootMethod bootstrap = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.util.function.Supplier"",
        ""bootstrap$"", testClass, ""java.lang.String""));
    final SootMethod metaFactoryConstructor
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""void"", ""<init>"", testClass, ""java.lang.String""));
    final SootMethod get = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.lang.Object"", ""get""));
    final SootMethod lambdaBody
        = Scene.v().getMethod(methodSigFromComponents(testClass, ""java.lang.String"", ""lambda$main$0"", ""java.lang.String""));
    final SootMethod getString = Scene.v().getMethod(methodSigFromComponents(testClass, ""java.lang.String"", ""getString""));

    final List<Edge> edgesFromTarget = newArrayList(cg.edgesOutOf(target));

    assertTrue(""There should be an edge from main to the bootstrap method of the synthetic LambdaMetaFactory"",
        edgesFromTarget.stream().anyMatch(e -> e.tgt().equals(bootstrap) && e.isStatic()));
    assertTrue(""There should be an edge to the constructor of the LambdaMetaFactory in the bootstrap method"",
        newArrayList(cg.edgesOutOf(bootstrap)).stream()
            .anyMatch(e -> e.tgt().equals(metaFactoryConstructor) && e.isSpecial()));
    assertTrue(
        ""There should be an interface invocation on the synthetic LambdaMetaFactory's implementation of the functional interface in the main method"",
        edgesFromTarget.stream().anyMatch(e -> e.getTgt().equals(get) && e.kind() == Kind.INTERFACE));
    assertTrue(
        ""There should be a virtual call to the lambda body implementation in the generated functional interface implementation of the synthetic LambdaMetaFactory"",
        newArrayList(cg.edgesOutOf(get)).stream().anyMatch(e -> e.getTgt().equals(lambdaBody) && e.isVirtual()));

    assertTrue(""There should be a special call to the getString method in actual lambda body implementation"",
        newArrayList(cg.edgesOutOf(lambdaBody)).stream().anyMatch(e -> e.getTgt().equals(getString) && e.isSpecial()));

    validateAllBodies(target.getDeclaringClass(), bootstrap.getDeclaringClass());
  }
",non-flaky,5
88807,apache_ignite,IgniteBinaryTest.testBinaryObjectApi,"    @Test
    public void testBinaryObjectApi() throws Exception {
        try (Ignite srv = Ignition.start(Config.getServerConfiguration())) {
            try (IgniteClient client = Ignition.startClient(new ClientConfiguration().setAddresses(Config.SERVER))) {
                // Use ""server-side"" IgniteBinary as a reference to test the thin client IgniteBinary against
                IgniteBinary refBinary = srv.binary();

                IgniteBinary binary = client.binary();

                Person obj = new Person(1, ""Joe"");

                int refTypeId = refBinary.typeId(Person.class.getName());
                int typeId = binary.typeId(Person.class.getName());

                assertEquals(refTypeId, typeId);

                BinaryObject refBinObj = refBinary.toBinary(obj);
                BinaryObject binObj = binary.toBinary(obj);

                assertBinaryObjectsEqual(refBinObj, binObj);

                assertBinaryTypesEqual(refBinary.type(typeId), binary.type(typeId));

                assertBinaryTypesEqual(refBinary.type(Person.class), binary.type(Person.class));

                assertBinaryTypesEqual(refBinary.type(Person.class.getName()), binary.type(Person.class.getName()));

                Collection<BinaryType> refTypes = refBinary.types();
                Collection<BinaryType> types = binary.types();

                assertEquals(refTypes.size(), types.size());

                BinaryObject refEnm = refBinary.buildEnum(Enum.class.getName(), Enum.DEFAULT.ordinal());
                BinaryObject enm = binary.buildEnum(Enum.class.getName(), Enum.DEFAULT.ordinal());

                assertBinaryObjectsEqual(refEnm, enm);

                Map<String, Integer> enumMap = Arrays.stream(Enum.values())
                    .collect(Collectors.toMap(java.lang.Enum::name, java.lang.Enum::ordinal));

                BinaryType refEnumType = refBinary.registerEnum(Enum.class.getName(), enumMap);
                BinaryType enumType = binary.registerEnum(Enum.class.getName(), enumMap);

                assertBinaryTypesEqual(refEnumType, enumType);

                refEnm = refBinary.buildEnum(Enum.class.getName(), Enum.DEFAULT.name());
                enm = binary.buildEnum(Enum.class.getName(), Enum.DEFAULT.name());

                assertBinaryObjectsEqual(refEnm, enm);
            }
        }
    }
",non-flaky,5
84647,apache_zookeeper,ZooKeeperTest.testDeleteRecursiveFail,"    @Test
    public void testDeleteRecursiveFail() throws IOException, InterruptedException, KeeperException {
        final ZooKeeper zk = createClient();
        setupDataTree(zk);

        ACL deleteProtection = new ACL(ZooDefs.Perms.DELETE, new Id(""digest"", ""user:tl+z3z0vO6PfPfEENfLF96E6pM0=""/* password is test */));
        List<ACL> acls = Arrays.asList(new ACL(ZooDefs.Perms.READ, Ids.ANYONE_ID_UNSAFE), deleteProtection);

        // poison the well
        zk.create(""/a/c/0/surprise"", """".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        assertEquals(1, zk.getACL(""/a/c/0"", new Stat()).size());
        zk.setACL(""/a/c/0"", acls, -1);
        assertEquals(2, zk.getACL(""/a/c/0"", new Stat()).size());

        assertFalse(ZKUtil.deleteRecursive(zk, ""/a/c"", 1000));
        List<String> children = zk.getChildren(""/a"", false);
        assertEquals(2, children.size(), ""2 children - c should fail to be deleted "");
        assertTrue(children.contains(""b""));

        assertTrue(ZKUtil.deleteRecursive(zk, ""/a/b"", 1000));
        children = zk.getChildren(""/a"", false);
        assertEquals(1, children.size(), ""1 children - b should be deleted "");

        // acquire immunity to poison
        zk.addAuthInfo(deleteProtection.getId().getScheme(), ""user:test"".getBytes());

        assertTrue(ZKUtil.deleteRecursive(zk, ""/a"", 1000));
        assertNull(zk.exists(""/a"", null));
    }
",non-flaky,5
91398,OpenLCB_OpenLCB_Java,NodeIdTextFieldTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        NodeIdTextField t = new NodeIdTextField();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
38639,apache_pulsar,TestEnvVarResolverProperties.resolveEnvVar,"    @Test
    public void resolveEnvVar() {
        environmentVariables.set(""VARNAME"", ""varvalue"");
        String resolved = EnvVarResolverProperties.resolveEnvVars(""padding ${VARNAME} padding"");
        Assert.assertEquals(""padding varvalue padding"", resolved);
    }
",non-flaky,5
89366,apache_samza,TestKafkaCheckpointManager.testCreateResourcesSkipValidation,"  @Test
  public void testCreateResourcesSkipValidation() {
    setupSystemFactory(config());
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(false, config());
    kafkaCheckpointManager.createResources();

    verify(this.createResourcesSystemAdmin).start();
    verify(this.createResourcesSystemAdmin).createStream(CHECKPOINT_SPEC);
    verify(this.createResourcesSystemAdmin, never()).validateStream(CHECKPOINT_SPEC);
    verify(this.createResourcesSystemAdmin).stop();
  }
",non-flaky,5
96945,apache_avro,TestHadoopCodecFactory.testHadoopCodecFactorySnappy,"  @Test
  public void testHadoopCodecFactorySnappy(){
    CodecFactory hadoopSnappyCodec = HadoopCodecFactory.fromHadoopString(""org.apache.hadoop.io.compress.SnappyCodec"");
    CodecFactory avroSnappyCodec = CodecFactory.fromString(""snappy"");
    assertTrue(hadoopSnappyCodec.getClass().equals(avroSnappyCodec.getClass()));
  }
",non-flaky,5
99801,apache_cassandra,OutboundConnectionSettingsTest.build_TcpConnectTimeoutLessThanZero,"    @Test (expected = IllegalArgumentException.class)
    public void build_TcpConnectTimeoutLessThanZero()
    {
        test(settings -> settings.withTcpConnectTimeoutInMS(-1));
    }
",non-flaky,5
96877,apache_avro,TestSpecificCompiler.testLogicalTypesWithMultipleFields,"  @Test
  public void testLogicalTypesWithMultipleFields() throws Exception {
    Schema logicalTypesWithMultipleFields = new Schema.Parser().parse(
        new File(""src/test/resources/logical_types_with_multiple_fields.avsc""));
    assertCompilesWithJavaCompiler(new File(OUTPUT_DIR.getRoot(), name.getMethodName()),
        new SpecificCompiler(logicalTypesWithMultipleFields).compile());
  }
",non-flaky,5
178050,aosp-mirror_platform_frameworks_support,PlaybackControlSupportGlueTest.testFastForwardToMaxThenReset,"    @Test
    public void testFastForwardToMaxThenReset() {
        PlaybackControlsRow row = new PlaybackControlsRow();
        glue.setControlsRow(row);
        SparseArrayObjectAdapter adapter = (SparseArrayObjectAdapter)
                row.getPrimaryActionsAdapter();
        PlaybackControlsRow.MultiAction playPause = (PlaybackControlsRow.MultiAction) adapter
                .lookup(PlaybackControlSupportGlue.ACTION_PLAY_PAUSE);
        PlaybackControlsRow.MultiAction fastForward = (PlaybackControlsRow.MultiAction) adapter
                .lookup(PlaybackControlSupportGlue.ACTION_FAST_FORWARD);
        PlaybackControlsRow.MultiAction rewind = (PlaybackControlsRow.MultiAction) adapter
                .lookup(PlaybackControlSupportGlue.ACTION_REWIND);

        assertFalse(glue.isMediaPlaying());
        glue.onActionClicked(playPause);
        assertTrue(glue.isMediaPlaying());
        assertEquals(PlaybackControlSupportGlue.PLAYBACK_SPEED_NORMAL, glue.getCurrentSpeedId());
        assertEquals(0, fastForward.getIndex());
        assertEquals(0, rewind.getIndex());

        // click multiple times to reach PLAYBACK_SPEED_FAST_L2
        glue.onActionClicked(fastForward);
        assertEquals(PlaybackControlSupportGlue.PLAYBACK_SPEED_FAST_L0, glue.getCurrentSpeedId());
        assertEquals(1, fastForward.getIndex());
        assertEquals(0, rewind.getIndex());
        glue.onActionClicked(fastForward);
        assertEquals(PlaybackControlSupportGlue.PLAYBACK_SPEED_FAST_L1, glue.getCurrentSpeedId());
        assertEquals(2, fastForward.getIndex());
        assertEquals(0, rewind.getIndex());
        glue.onActionClicked(fastForward);
        assertEquals(PlaybackControlSupportGlue.PLAYBACK_SPEED_FAST_L2, glue.getCurrentSpeedId());
        assertEquals(3, fastForward.getIndex());
        assertEquals(0, rewind.getIndex());
        glue.onActionClicked(fastForward);
        assertEquals(PlaybackControlSupportGlue.PLAYBACK_SPEED_FAST_L2, glue.getCurrentSpeedId());
        assertEquals(3, fastForward.getIndex());
        assertEquals(0, rewind.getIndex());

        // press playPause again put it back to play
        glue.onActionClicked(playPause);
        assertEquals(PlaybackControlSupportGlue.PLAYBACK_SPEED_NORMAL, glue.getCurrentSpeedId());
        assertEquals(0, fastForward.getIndex());
        assertEquals(0, rewind.getIndex());
    }
",non-flaky,5
170483,eclipse_jetty.project,ObjectMBeanUtilTest.testToAttributeName,"    @Test
    public void testToAttributeName()
    {
        assertEquals(""fullName"", MetaData.toAttributeName(""isfullName""));
    }
",non-flaky,5
156171,soot-oss_soot,EntryPointsTest.testClinitOf,"	@Test
	public void testClinitOf() {
		Path cp = Paths.get(""src"", ""test"", ""resources"", ""Clinit"", ""bin"");
		G.reset();
		Options.v().set_prepend_classpath(true);
		Options.v().set_process_dir(Collections.singletonList(cp.toFile().getAbsolutePath()));
		Options.v().set_src_prec(Options.src_prec_class);
		Options.v().set_allow_phantom_refs(true);
		Options.v().set_ignore_resolving_levels(true);
		Options.v().setPhaseOption(""cg.spark"", ""on"");
		Options.v().setPhaseOption(""cg.spark"", ""string-constants:true"");
		Options.v().set_whole_program(true);
		Scene.v().loadNecessaryClasses();
		SootMethod mainMethod = Scene.v().getMainMethod();
		Scene.v().setEntryPoints(Collections.singletonList(mainMethod));
		PackManager.v().getPack(""cg"").apply();
		CallGraph cg = Scene.v().getCallGraph();
		boolean found = false;
		for (Edge edge : cg) {
			if (edge.getSrc().method().getSignature().equals(""<soot.Main: void main(java.lang.String[])>"")) {
				if (edge.getTgt().method().getSignature().equals(""<soot.A: void <clinit>()>"")) { // A1 is used in main
					found = true;
					break;
				}
			}
		}
		assertTrue(found);
		SootClass a1 = Scene.v().getSootClassUnsafe(""soot.A1"");
		SootClass a = Scene.v().getSootClassUnsafe(""soot.A"");
		assertTrue(a1 != null);
		List<String> clinits1 = new ArrayList<>();
		EntryPoints.v().clinitsOf(a1).forEach(e -> {
			clinits1.add(e.toString());
		});
		List<String> clinits = new ArrayList<>();
		EntryPoints.v().clinitsOf(a).forEach(e -> {
			clinits.add(e.toString());
		});
		assertEquals(clinits1, clinits);
	}
",non-flaky,5
26709,MundaneImmortal_pair-distribution-app,PairTest.testEqual,"	@Test
	public void testEqual()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev1"")));
		
		assertThat(subject.equals(subject2), is(true));
	}
",non-flaky,5
98107,vert-x3_vertx-mongo-client,CredentialListParserTest.testSimpleAuth,"  @Test
  public void testSimpleAuth() {
    JsonObject config = new JsonObject().put(""db_name"", ""my-datasource"");
    String username = TestUtils.randomAlphaString(8);
    String password = TestUtils.randomAlphaString(20);
    config.put(""username"", username);
    config.put(""password"", password);


    List<MongoCredential> credentials = new CredentialListParser(null, config).credentials();
    assertEquals(1, credentials.size());
    MongoCredential credential = credentials.get(0);
    assertEquals(username, credential.getUserName());
    assertArrayEquals(password.toCharArray(), credential.getPassword());
    // default source should be the database name - see https://github.com/vert-x3/vertx-mongo-client/issues/46.
    assertEquals(""my-datasource"", credential.getSource());
  }
",non-flaky,5
30983,camunda-cloud_zeebe,ObjectMappingDefaultValuesTest.shouldReturnDefaultValueAfterReset,"  @Test
  public void shouldReturnDefaultValueAfterReset() {
    // given
    final MutableDirectBuffer msgPackBuffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(2);
              w.writeString(wrapString(""noDefaultValueProp""));
              w.writeInteger(123123L);
              w.writeString(wrapString(""defaultValueProp""));
              w.writeInteger(987L);
            });

    final long defaultValue = -1L;
    final DefaultValuesPOJO pojo = new DefaultValuesPOJO(defaultValue);
    pojo.wrap(msgPackBuffer);

    // when
    pojo.reset();

    // then
    assertThat(pojo.getDefaultValueProperty()).isEqualTo(defaultValue);
  }
",non-flaky,5
112156,apache_shardingsphere-elasticjob,TimeServiceTest.assertGetCurrentMillis,"    @Test
    public void assertGetCurrentMillis() throws Exception {
        assertTrue(timeService.getCurrentMillis() <= System.currentTimeMillis());
    }
",non-flaky,5
70771,apache_kafka,ConnectWorkerIntegrationTest.testBrokerCoordinator,"    @Test
    public void testBrokerCoordinator() throws Exception {
        workerProps.put(DistributedConfig.SCHEDULED_REBALANCE_MAX_DELAY_MS_CONFIG, String.valueOf(5000));
        connect = connectBuilder.workerProps(workerProps).build();
        // start the clusters
        connect.start();
        int numTasks = 4;
        // create test topic
        connect.kafka().createTopic(""test-topic"", NUM_TOPIC_PARTITIONS);

        // setup up props for the sink connector
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(numTasks));
        props.put(""topic"", ""test-topic"");
        props.put(""throughput"", String.valueOf(1));
        props.put(""messages.per.poll"", String.valueOf(10));
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());

        waitForCondition(() -> assertWorkersUp(NUM_WORKERS).orElse(false),
                WORKER_SETUP_DURATION_MS, ""Initial group of workers did not start in time."");

        // start a source connector
        connect.configureConnector(CONNECTOR_NAME, props);

        waitForCondition(() -> assertConnectorAndTasksRunning(CONNECTOR_NAME, numTasks).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");

        connect.kafka().stopOnlyKafka();

        waitForCondition(() -> assertWorkersUp(NUM_WORKERS).orElse(false),
                WORKER_SETUP_DURATION_MS, ""Group of workers did not remain the same after broker shutdown"");

        // Allow for the workers to discover that the coordinator is unavailable, wait is
        // heartbeat timeout * 2 + 4sec
        Thread.sleep(TimeUnit.SECONDS.toMillis(10));

        connect.kafka().startOnlyKafkaOnSamePorts();

        // Allow for the kafka brokers to come back online
        Thread.sleep(TimeUnit.SECONDS.toMillis(10));

        waitForCondition(() -> assertWorkersUp(NUM_WORKERS).orElse(false),
                WORKER_SETUP_DURATION_MS, ""Group of workers did not remain the same within the ""
                        + ""designated time."");

        // Allow for the workers to rebalance and reach a steady state
        Thread.sleep(TimeUnit.SECONDS.toMillis(10));

        waitForCondition(() -> assertConnectorAndTasksRunning(CONNECTOR_NAME, numTasks).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");
    }
",non-flaky,5
170512,eclipse_jetty.project,TestAnnotationParser.handle,"    @Test
    public void testMultiAnnotation() throws Exception
    {
        String[] classNames = new String[]{""org.eclipse.jetty.annotations.ClassB""};
        AnnotationParser parser = new AnnotationParser();

        class MultiAnnotationHandler extends AnnotationParser.AbstractHandler
        {
            @Override
            public void handle(ClassInfo info, String annotation)
            {
                if (annotation == null || !""org.eclipse.jetty.annotations.Multi"".equals(annotation))
                    return;
                assertTrue(""org.eclipse.jetty.annotations.ClassB"".equals(info.getClassName()));
            }
",non-flaky,5
177227,line_armeria,FileWatcherRegistryTest.runnableWithExceptionContinuesRun,"    @Test
    public void runnableWithExceptionContinuesRun() throws Exception {

        final File file = folder.newFile(""temp-file.properties"");
        final FileWatcherRegistry fileWatcherRegistry = new FileWatcherRegistry();

        final AtomicInteger val = new AtomicInteger(0);
        final FileWatchRegisterKey key = fileWatcherRegistry.register(file.toPath(), () -> {
            try {
                final BufferedReader bufferedReader = new BufferedReader(new FileReader(file));
                val.set(Integer.valueOf(bufferedReader.readLine()));
            } catch (IOException e) {
                // do nothing
            }
            throw new RuntimeException();
        });

        PrintWriter printWriter = new PrintWriter(file);
        printWriter.print(1);
        printWriter.close();

        await().untilAsserted(() -> assertThat(val.get()).isEqualTo(1));

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        printWriter = new PrintWriter(file);
        printWriter.print(2);
        printWriter.close();

        await().untilAsserted(() -> assertThat(val.get()).isEqualTo(2));

        assertThat(fileWatcherRegistry.isRunning()).isTrue();

        fileWatcherRegistry.unregister(key);

        assertThat(fileWatcherRegistry.isRunning()).isFalse();

        fileWatcherRegistry.close();
    }
",non-flaky,5
89288,apache_samza,TestJobsResource.testPutMissingStatus,"  @Test
  public void testPutMissingStatus()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID)).request()
        .put(Entity.form(new Form()));
    assertEquals(400, resp.getStatus());

    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message"").contains(""status""));
    resp.close();
  }
",non-flaky,5
110169,Wikidata_wikidata-toolkit,DirectoryManagerTest.getCompressionInputStreamBz2,"	@Test
	public void getCompressionInputStreamBz2() throws IOException {
		ByteArrayOutputStream out = new ByteArrayOutputStream();
		OutputStreamWriter ow = new OutputStreamWriter(
				new BZip2CompressorOutputStream(out), StandardCharsets.UTF_8);
		ow.write(""Test data"");
		ow.close();

		ByteArrayInputStream in = new ByteArrayInputStream(out.toByteArray());
		InputStream cin = dm.getCompressorInputStream(in, CompressionType.BZ2);

		assertEquals(""Test data"",
				new BufferedReader(new InputStreamReader(cin)).readLine());
	}
",non-flaky,5
91458,strapdata_elassandra,RelocationIT.indexShardStateChanged,"    @TestLogging(""org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.search:TRACE"")
    public void testRelocationWhileRefreshing() throws Exception {
        int numberOfRelocations = scaledRandomIntBetween(1, rarely() ? 10 : 4);
        int numberOfReplicas = randomBoolean() ? 0 : 1;
        int numberOfNodes = numberOfReplicas == 0 ? 2 : 3;

        logger.info(""testRelocationWhileIndexingRandom(numRelocations={}, numberOfReplicas={}, numberOfNodes={})"", numberOfRelocations, numberOfReplicas, numberOfNodes);

        String[] nodes = new String[numberOfNodes];
        logger.info(""--> starting [node_0] ..."");
        nodes[0] = internalCluster().startNode();

        logger.info(""--> creating test index ..."");
        prepareCreate(
                ""test"",
                Settings.builder()
                        .put(""index.number_of_shards"", 1)
                        .put(""index.number_of_replicas"", numberOfReplicas)
                        .put(""index.refresh_interval"", -1) // we want to control refreshes
                        .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms""))
                .get();

        for (int i = 1; i < numberOfNodes; i++) {
            logger.info(""--> starting [node_{}] ..."", i);
            nodes[i] = internalCluster().startNode();
            if (i != numberOfNodes - 1) {
                ClusterHealthResponse healthResponse = client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID)
                        .setWaitForNodes(Integer.toString(i + 1)).setWaitForGreenStatus().execute().actionGet();
                assertThat(healthResponse.isTimedOut(), equalTo(false));
            }
        }

        final Semaphore postRecoveryShards = new Semaphore(0);
        final IndexEventListener listener = new IndexEventListener() {
            @Override
            public void indexShardStateChanged(IndexShard indexShard, @Nullable IndexShardState previousState, IndexShardState currentState, @Nullable String reason) {
                if (currentState == IndexShardState.POST_RECOVERY) {
                    postRecoveryShards.release();
                }
            }
",non-flaky,5
114050,aws_aws-sdk-java-v2,AsyncDeleteItemWithResponseIntegrationTest.deleteItem_returnConsumedCapacity_set_consumedCapacityNotNull,"    @Test
    public void deleteItem_returnConsumedCapacity_set_consumedCapacityNotNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response =
            mappedTable.deleteItemWithResponse(r -> r.key(key).returnConsumedCapacity(ReturnConsumedCapacity.TOTAL)).join();

        assertThat(response.consumedCapacity()).isNotNull();
    }
",non-flaky,5
38704,apache_pulsar,KafkaConnectSourceErrTest.testOpenAndRead,"    @Test
    public void testOpenAndRead() throws Exception {
        kafkaConnectSource = new KafkaConnectSource();
        kafkaConnectSource.open(config, context);

        // use FileStreamSourceConnector, each line is a record, need ""\n"" and end of each record.
        OutputStream os = Files.newOutputStream(tempFile.toPath());

        String line1 = ""This is the first line\n"";
        os.write(line1.getBytes());
        os.flush();
        log.info(""write 2 lines."");

        String line2 = ""This is the second line\n"";
        os.write(line2.getBytes());
        os.flush();

        log.info(""finish write, will read 2 lines"");

        // Note: FileStreamSourceTask read the whole line as Value, and set Key as null.
        Record<KeyValue<byte[], byte[]>> record = kafkaConnectSource.read();
        String readBack1 = new String(record.getValue().getValue());
        assertTrue(line1.contains(readBack1));
        assertNull(record.getValue().getKey());
        log.info(""read line1: {}"", readBack1);
        record.ack();

        record = kafkaConnectSource.read();
        String readBack2 = new String(record.getValue().getValue());
        assertTrue(line2.contains(readBack2));
        assertNull(record.getValue().getKey());
        assertTrue(record.getPartitionId().isPresent());
        assertFalse(record.getPartitionIndex().isPresent());
        log.info(""read line2: {}"", readBack2);
        record.ack();

        String line3 = ""This is the 3rd line\n"";
        os.write(line3.getBytes());
        os.flush();

        try {
            kafkaConnectSource.read();
            fail(""expected exception"");
        } catch (Exception e) {
            log.info(""got exception"", e);
            assertTrue(e.getCause().getCause() instanceof org.apache.kafka.connect.errors.ConnectException);
        }
    }
",non-flaky,5
176781,ctco_cukes,BaseContextHandlerTest.shouldExtractNoGroupsInPattern,"    @Test
    public void shouldExtractNoGroupsInPattern() throws Exception {
        List<String> groups = capturer.extractGroups(""(hello)"");
        assertThat(groups, is(empty()));
    }
",non-flaky,5
91445,strapdata_elassandra,SuiteScopeClusterIT.testReproducible,"    @Test
    public void testReproducible() throws IOException {
        if (ITER++ == 0) {
            CLUSTER_SEED = cluster().seed();
            for (int i = 0; i < SEQUENCE.length; i++) {
                SEQUENCE[i] = randomLong();
            }
        } else {
            assertEquals(CLUSTER_SEED, Long.valueOf(cluster().seed()));
            for (int i = 0; i < SEQUENCE.length; i++) {
                assertThat(SEQUENCE[i], equalTo(randomLong()));
            }
        }
    }
",non-flaky,5
179444,abel533_Mapper,AggregationMapperTest.testMax,"    @Test
    public void testMax() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper mapper = sqlSession.getMapper(UserMapper.class);
            AggregateCondition aggregateCondition = AggregateCondition.builder().
                    aggregateBy(""id"").aliasName(""aggregation"").aggregateType(AggregateType.MAX).groupBy(""role"");
            Example example = new Example(User.class);
            example.setOrderByClause(""role desc"");
            List<User> m = mapper.selectAggregationByExample(example, aggregateCondition);
            Assert.assertEquals(2, m.size());
            Assert.assertEquals(new Long(6), m.get(0).getAggregation());
            Assert.assertEquals(new Long(3), m.get(1).getAggregation());
        } finally {
            sqlSession.close();
        }
    }
",non-flaky,5
91412,strapdata_elassandra,PreBuiltXPackTransportClientTests.testPluginInstalled,"    @Test
    public void testPluginInstalled() {
        try (TransportClient client = new PreBuiltXPackTransportClient(Settings.EMPTY)) {
            Settings settings = client.settings();
            assertEquals(SecurityField.NAME4, NetworkModule.TRANSPORT_TYPE_SETTING.get(settings));
        }
    }
",non-flaky,5
179478,abel533_Mapper,SafeUpdateByFieldTest.testSafeUpdateNull2,"    @Test(expected = PersistenceException.class)
    public void testSafeUpdateNull2() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.updateByExample(null, null);
        } finally {
            sqlSession.close();
        }
    }
",non-flaky,5
88787,apache_ignite,LongRunningProcessClearTaskTest.testCallProcessIsDoneWithException,"    @Test
    public void testCallProcessIsDoneWithException() throws ExecutionException, InterruptedException {
        UUID procId = UUID.randomUUID();

        Future<?> fut = mock(Future.class);
        doReturn(true).when(fut).isDone();
        doThrow(RuntimeException.class).when(fut).get();
        metadataStorage.put(procId, fut);

        LongRunningProcessClearTask clearTask = createTask(procId);

        List<LongRunningProcessStatus> statuses = clearTask.call();

        assertEquals(1, statuses.size());

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.DONE, status.getState());
        assertNotNull(status.getException());
        assertTrue(status.getException() instanceof RuntimeException);

        assertEquals(0, metadataStorage.size());
    }
",non-flaky,5
20945,NationalSecurityAgency_timely,TimeSeriesGroupingIteratorTest.testAdditionalTimeSeries,"    @Test
    public void testAdditionalTimeSeries() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        List<Tag> tags1 = new ArrayList<>();
        tags1.add(new Tag(""host"", ""r01n01""));
        List<Tag> tags2 = new ArrayList<>();
        tags2.add(new Tag(""host"", ""r01n02""));
        for (int i = 0; i < 100; i++) {
            ts += 1000;
            Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags1);
            byte[] row = MetricAdapter.encodeRowKey(m);
            Key k = new Key(row, tags1.get(0).join().getBytes(StandardCharsets.UTF_8),
                    MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
            table.put(k, v);
            if (i > 50) {
                // only populate this series 50 times
                Metric m2 = new Metric(""sys.cpu.user"", ts, i * 2.0D, tags2);
                byte[] row2 = MetricAdapter.encodeRowKey(m2);
                Key k2 = new Key(row2, tags2.get(0).join().getBytes(StandardCharsets.UTF_8),
                        MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v2 = new Value(MetricAdapter.encodeValue(m2.getValue().getMeasure()));
                table.put(k2, v2);
            }
        }
        SortedMapIterator source = new SortedMapIterator(table);
        TimeSeriesGroupingIterator iter = new TimeSeriesGroupingIterator();
        IteratorSetting settings = new IteratorSetting(100, TimeSeriesGroupingIterator.class);
        settings.addOption(TimeSeriesGroupingIterator.FILTER, ""0.20,0.20,0.20,0.20,0.20"");
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);

        // this section changed when the key structure changed so that identical
        // colFam values sorted consecutively within an given time period
        for (int i = 4; i < 100; i++) {
            checkNextResult(iter, new double[] { i - 4, i - 3, i - 2, i - 1, i });
        }
        for (int i = 55; i < 100; i++) {
            checkNextResult(iter, new double[] { (i - 4) * 2, (i - 3) * 2, (i - 2) * 2, (i - 1) * 2, i * 2 });
        }

        assertFalse(iter.hasTop());

    }
",non-flaky,5
98371,ONSdigital_rm-collection-exercise-service,MultipleMandatoryEventsValidatorTest.testValidReturnByEventCreation,"  @Test
  public void testValidReturnByEventCreation() throws CTPException {
    List<Event> events = getExistingEvents();
    Instant timestamp = Instant.now().plus(6, ChronoUnit.DAYS);
    Event newReturnByEvent = new Event();
    newReturnByEvent.setTag((EventService.Tag.return_by.toString()));
    newReturnByEvent.setTimestamp(Timestamp.from(timestamp));
    validator.validate(
        events, newReturnByEvent, CollectionExerciseDTO.CollectionExerciseState.CREATED);
  }
",non-flaky,5
84616,apache_zookeeper,GetEphemeralsTest.testGetEphemeralsByPath,"    @Test
    public void testGetEphemeralsByPath() throws IOException, KeeperException, InterruptedException {

        final CountDownLatch doneProcessing = new CountDownLatch(1);
        final String checkPath = BASE + ""0"";
        final List<String> unexpectedBehavior = new ArrayList<String>();
        zk.getEphemerals(checkPath, (rc, ctx, paths) -> {
            if (paths == null) {
                unexpectedBehavior.add(String.format(""Expected ephemeral count for %s to be %d but was null"", checkPath, expected.length));
            } else if (paths.size() != EPHEMERAL_CNT) {
                unexpectedBehavior.add(String.format(""Expected ephemeral count for %s to be %d but was %d"", checkPath, EPHEMERAL_CNT, paths.size()));
            }
            for (int i = 0; i < EPHEMERAL_CNT; i++) {
                String path = expected[i];
                if (!paths.contains(path)) {
                    unexpectedBehavior.add(String.format(""Expected path=%s didn't exist ""
                                                                 + ""in getEphemerals list."", path));
                }
            }
            doneProcessing.countDown();
        }, null);
        long waitForCallbackSecs = 2L;
        if (!doneProcessing.await(waitForCallbackSecs, TimeUnit.SECONDS)) {
            fail(String.format(""getEphemerals(%s) didn't callback within %d seconds"", checkPath, waitForCallbackSecs));
        }
        checkForUnexpectedBehavior(unexpectedBehavior);
    }
",non-flaky,5
135065,undertow-io_undertow,URLUtilsTestCase.testIsAbsoluteUrlRecognizingAppUrls,"    @Test
    public void testIsAbsoluteUrlRecognizingAppUrls() {
        assertTrue(URLUtils.isAbsoluteUrl(""com.example.app:/oauth2redirect/example-provider""));
        assertTrue(URLUtils.isAbsoluteUrl(""com.example.app:/oauth2redirect/example-provider?query=val""));
    }
",non-flaky,5
114064,aws_aws-sdk-java-v2,EnhancedTypeTest.navigableSetOf_ReturnsRawClassOfNavigableSet_WhenSpecifyingClass,"    @Test
    public void navigableSetOf_ReturnsRawClassOfNavigableSet_WhenSpecifyingClass() {
        EnhancedType<NavigableSet<String>> type = EnhancedType.navigableSetOf(String.class);

        assertThat(type.rawClass()).isEqualTo(NavigableSet.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
114124,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterMaxTest,"    @Test
    public void localDateTimeAttributeConverterMaxTest() {
        verifyTransform(LocalDateTime.MAX, ""+999999999-12-31T23:59:59.999999999"");
    }
",non-flaky,5
76736,quarkusio_quarkus,CreateExtensionMojoIT.testCreateCoreExtensionFromExtensionsDir,"    @Test
    public void testCreateCoreExtensionFromExtensionsDir(TestInfo testInfo) throws Throwable {
        testDir = initProject(""projects/create-extension-quarkus-core"", ""output/create-extension-quarkus-core-extensions-dir"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir.toPath().resolve(""extensions/"").toFile());

        Properties properties = new Properties();
        properties.put(""extensionId"", ""quarkus-my-ext"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        final Path testDirPath = testDir.toPath();
        assertThatDirectoryTreeMatchSnapshots(testInfo, testDirPath)
                .contains(
                        ""extensions/my-ext/pom.xml"",
                        ""extensions/my-ext/deployment/src/main/java/org/acme/my/ext/deployment/MyExtProcessor.java"",
                        ""integration-tests/my-ext/pom.xml"",
                        ""integration-tests/my-ext/src/test/java/org/acme/my/ext/it/MyExtResourceTest.java"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""extensions/my-ext/pom.xml"");
        assertThatMatchSnapshot(testInfo, testDirPath,
                ""extensions/my-ext/runtime/src/main/resources/META-INF/quarkus-extension.yaml"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""bom/application/pom.xml"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""integration-tests/pom.xml"");
        assertThatMatchSnapshot(testInfo, testDirPath, ""extensions/pom.xml"");
    }
",non-flaky,5
30942,camunda-cloud_zeebe,ElasticsearchExporterTest.shouldFlushOnClose,"  @Test
  public void shouldFlushOnClose() {
    // given
    createAndOpenExporter();

    // when
    testHarness.close();

    // then
    verify(esClient).flush();
  }
",non-flaky,5
178022,aosp-mirror_platform_frameworks_support,ListRowDataAdapterTest.itemRangeChangedTest,"    @Test
    public void itemRangeChangedTest() {
        int itemCount = 4;
        ArrayObjectAdapter adapter = new ArrayObjectAdapter(presenterSelector);
        adapter.add(new SectionRow(""section 1""));
        for (int i = 0; i < itemCount; i++) {
            HeaderItem headerItem = new HeaderItem(i, ""header ""+i);
            adapter.add(new ListRow(headerItem, createListRowAdapter()));
        }

        ListRowDataAdapter listRowDataAdapter = new ListRowDataAdapter(adapter);
        listRowDataAdapter.registerObserver(dataObserver);
        SectionRow sectionRow = new SectionRow(""section 11"");
        adapter.replace(0, sectionRow);

        verify(dataObserver, times(1)).onItemRangeChanged(0, 1);
        assertEquals(5, listRowDataAdapter.size());
    }
",non-flaky,5
78261,apache_beam,SplittableParDoProcessFnTest.testUpdatesWatermark,"  @Test
  public void testUpdatesWatermark() throws Exception {
    DoFn<Instant, String> fn = new WatermarkUpdateFn();
    Instant base = Instant.now();

    ProcessFnTester<Instant, String, OffsetRange, Long, OffsetRangeTracker> tester =
        new ProcessFnTester<>(
            base,
            fn,
            InstantCoder.of(),
            SerializableCoder.of(OffsetRange.class),
            3,
            MAX_BUNDLE_DURATION);

    tester.startElement(base, new OffsetRange(0, 8));
    assertThat(tester.takeOutputElements(), hasItems(""0"", ""1"", ""2""));
    assertEquals(base.plus(Duration.standardSeconds(2)), tester.getWatermarkHold());

    assertTrue(tester.advanceProcessingTimeBy(Duration.standardSeconds(1)));
    assertThat(tester.takeOutputElements(), hasItems(""3"", ""4"", ""5""));
    assertEquals(base.plus(Duration.standardSeconds(5)), tester.getWatermarkHold());

    assertTrue(tester.advanceProcessingTimeBy(Duration.standardSeconds(1)));
    assertThat(tester.takeOutputElements(), hasItems(""6"", ""7""));
    assertEquals(null, tester.getWatermarkHold());
  }
",non-flaky,5
170545,eclipse_jetty.project,TestServletAnnotations.testWebServletAnnotationNoMappings,"    @Test
    public void testWebServletAnnotationNoMappings() throws Exception
    {
        //an existing servlet OF THE SAME NAME has no mappings, therefore all mappings in the annotation
        //should be accepted
        WebAppContext wac = new WebAppContext();
        ServletHolder servlet = new ServletHolder();
        servlet.setName(""foo"");
        wac.getServletHandler().addServlet(servlet);

        WebServletAnnotation annotation = new WebServletAnnotation(wac, ""org.eclipse.jetty.annotations.ServletD"", null);
        annotation.apply();

        ServletMapping[] resultMappings = wac.getServletHandler().getServletMappings();
        assertEquals(1, resultMappings.length);
        assertEquals(2, resultMappings[0].getPathSpecs().length);
        for (String s : resultMappings[0].getPathSpecs())
        {
            assertThat(s, anyOf(is(""/""), is(""/bah/*"")));
        }
    }
",non-flaky,5
159650,liquibase_liquibase,AbstractIntegrationTest.testRerunDiffChangeLog,"    @Test
    public void testRerunDiffChangeLog() throws Exception {
        assumeNotNull(this.getDatabase());

        for (int run=0; run < 2; run++) { //run once outputting data as insert, once as csv
            boolean outputCsv = run == 1;
            runCompleteChangeLog();

            SnapshotControl snapshotControl = new SnapshotControl(database);

            DatabaseSnapshot originalSnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, snapshotControl);

            CompareControl compareControl = new CompareControl();
            compareControl.addSuppressedField(Column.class, ""defaultValue"");  //database returns different data even if the same
            compareControl.addSuppressedField(Column.class, ""autoIncrementInformation""); //database returns different data even if the same
            if (database instanceof OracleDatabase) {
                compareControl.addSuppressedField(Column.class, ""type""); //database returns different nvarchar2 info even though they are the same
                compareControl.addSuppressedField(Column.class, ""nullable""); // database returns different nullable on views, e.g. v_person.id
            }
            if (database instanceof PostgresDatabase) {
                compareControl.addSuppressedField(Column.class, ""type""); //database returns different nvarchar2 info even though they are the same
            }

            DiffOutputControl diffOutputControl = new DiffOutputControl();
            File tempFile = tempDirectory.getRoot().createTempFile(""liquibase-test"", "".xml"");

            if (outputCsv) {
                diffOutputControl.setDataDir(new File(tempFile.getParentFile(), ""liquibase-data"").getCanonicalPath().replaceFirst(""\\w:"",""""));
            }

            DiffResult diffResult = DiffGeneratorFactory.getInstance().compare(database, null, compareControl);


            FileOutputStream output = new FileOutputStream(tempFile);
            try {
                new DiffToChangeLog(diffResult, new DiffOutputControl()).print(new PrintStream(output));
                output.flush();
            } finally {
                output.close();
            }

            Liquibase liquibase = createLiquibase(tempFile.getName());
            clearDatabase();

            DatabaseSnapshot emptySnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));

            //run again to test changelog testing logic
            liquibase = createLiquibase(tempFile.getName());
            try {
                liquibase.update(this.contexts);
            } catch (ValidationFailedException e) {
                e.printDescriptiveError(System.out);
                throw e;
            }

            DatabaseSnapshot migratedSnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));

            DiffResult finalDiffResult = DiffGeneratorFactory.getInstance().compare(originalSnapshot, migratedSnapshot, compareControl);
            try {
                assertTrue(""recreating the database from the generated change log should cause both 'before' and "" +
                                ""'after' snapshots to be equal."",
                        finalDiffResult.areEqual());
            } catch (AssertionError e) {
                new DiffToReport(finalDiffResult, System.err).print();
                throw e;
            }

            //diff to empty and drop all
            DiffResult emptyDiffResult = DiffGeneratorFactory.getInstance().compare(emptySnapshot, migratedSnapshot, compareControl);
            output = new FileOutputStream(tempFile);
            try {
                new DiffToChangeLog(emptyDiffResult, new DiffOutputControl(true, true, true, null)).print(new PrintStream(output));
                output.flush();
            } finally {
                output.close();
            }

            liquibase = createLiquibase(tempFile.getName());
            Scope.getCurrentScope().getLog(getClass()).info(LogType.LOG, ""updating from ""+tempFile.getCanonicalPath());
            try {
                liquibase.update(this.contexts);
            } catch (LiquibaseException e) {
                throw e;
            }

            DatabaseSnapshot emptyAgainSnapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(database.getDefaultSchema(), database, new SnapshotControl(database));
            assertEquals(""a database that was 'updated' to an empty snapshot should only have 2 tables left: "" +
                            ""the database change log table and the lock table."",
                    2, emptyAgainSnapshot.get(Table.class).size());
            assertEquals(""a database that was 'updated' to an empty snapshot should not contain any views."",
                    0, emptyAgainSnapshot.get(View.class).size());
        }
    }
",non-flaky,5
77452,opensearch-project_OpenSearch,NastyInnerClasses.annotatedTestMethod,"        @Test
        public void annotatedTestMethod() {

        }
",non-flaky,5
339,testcontainers_testcontainers-java,appliesOuterTimeout,"@Test
public void appliesOuterTimeout() {
    final WaitStrategy underTest = new WaitAllStrategy()
    .withStrategy(strategy1)
    .withStartupTimeout(Duration.ofMillis(10));
    doAnswer(invocation -> {
        Uninterruptibles.sleepUninterruptibly(20, TimeUnit.MILLISECONDS);
        return null;
    }).when(strategy1).waitUntilReady(eq(container));
    assertThrows(""The outer strategy timeout applies"", TimeoutException.class, () -> {
        underTest.waitUntilReady(container);
    });
}",async wait,0
60915,apache_druid,LongMaxAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new LongMaxAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(LongMaxAverager.class));
  }
",non-flaky,5
239,Netflix_Hystrix,HealthCountsStreamTest.testShortCircuited,"@Test
public void testShortCircuited() {
    HystrixCommandKey key = Factory.asKey(""CMD-Health-G"");
    stream = HealthCountsStream.getInstance(key, 10, 100);
    final CountDownLatch latch = new CountDownLatch(1);
    stream.observe().take(10).subscribe(getSubscriber(latch));
    CommandStreamTest.Command failure1 = Command.from(groupKey, key, FAILURE, 20);
    CommandStreamTest.Command failure2 = Command.from(groupKey, key, FAILURE, 20);
    CommandStreamTest.Command failure3 = Command.from(groupKey, key, FAILURE, 20);
    CommandStreamTest.Command shortCircuit1 = Command.from(groupKey, key, SUCCESS);
    CommandStreamTest.Command shortCircuit2 = Command.from(groupKey, key, SUCCESS);
    failure1.observe();
    failure2.observe();
    failure3.observe();
    try {
        Thread.sleep(100);
    } catch (InterruptedException ie) {
        fail(ie.getMessage());
    }
    shortCircuit1.observe();
    shortCircuit2.observe();
    try {
        assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
    } catch (InterruptedException ex) {
        fail(""Interrupted ex"");
    }
    assertTrue(shortCircuit1.isResponseShortCircuited());
    assertTrue(shortCircuit2.isResponseShortCircuited());
    System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
    assertEquals(3L, stream.getLatest().getErrorCount());
    assertEquals(3L, stream.getLatest().getTotalRequests());
}",async wait,0
70,OpenLCB_OpenLCB_Java,MemoryConfigurationServiceInterfaceTest.testReadWithTimeoutInterleaved,"@Test
public void testReadWithTimeoutInterleaved() {
    int space = 0xfd;
    long address = 0x12345678;
    int length = 4;
    MemoryConfigurationService.McsReadHandler hnd = mock(McsReadHandler.class);
    MemoryConfigurationService.McsReadHandler hnd2 = mock(McsReadHandler.class);
    iface.getDatagramMeteringBuffer().setTimeout(30);
    iface.getMemoryConfigurationService().setTimeoutMillis(30);
    {
        iface.getMemoryConfigurationService().requestRead(farID, space, address, length, hnd);
        expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x78, 4 }));
        System.err.println(""Expect 'Never received reply' here -->"");
        delay(50);
        System.err.println(""<--"");
        verify(hnd).handleFailure(0x100);
        verifyNoMoreInteractions(hnd);
        iface.getMemoryConfigurationService().requestRead(farID, space, address + 1, length, hnd2);
        expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 }));
        sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80));
        consumeMessages();
        sendMessage(new DatagramRejectedMessage(farID, hereID, 0x2020));
        consumeMessages();
        System.err.println(""Expect 'unexpected response datagram' here -->"");
        sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x78, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID));
        System.err.println(""<--"");
        expectNoMessages();
        delay(50);
        expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 }));
        sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80));
        consumeMessages();
        sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80));
        consumeMessages();
        sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x79, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID));
        verify(hnd2).handleReadData(farID, space, address + 1, new byte[]{ ((byte) (0xaa)) });
        verifyNoMoreInteractions(hnd2);
    }
    System.err.println(""Sending another request..."");
    sendAnother(space, address + 5);
}",async wait,0
70775,apache_kafka,RebalanceSourceConnectorsIntegrationTest.testAddingWorker,"    @Test
    public void testAddingWorker() throws Exception {
        // create test topic
        connect.kafka().createTopic(TOPIC_NAME, NUM_TOPIC_PARTITIONS);

        // setup up props for the source connector
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));
        props.put(""throughput"", String.valueOf(1));
        props.put(""messages.per.poll"", String.valueOf(10));
        props.put(TOPIC_CONFIG, TOPIC_NAME);
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());

        waitForCondition(() -> this.assertWorkersUp(3),
                WORKER_SETUP_DURATION_MS, ""Connect workers did not start in time."");

        // start a source connector
        IntStream.range(0, 4).forEachOrdered(
            i -> {
                try {
                    connect.configureConnector(CONNECTOR_NAME + i, props);
                } catch (IOException e) {
                    throw new ConnectException(e);
                }
            });

        waitForCondition(() -> this.assertConnectorAndTasksRunning(CONNECTOR_NAME + 3, NUM_TASKS).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");

        connect.addWorker();

        waitForCondition(() -> this.assertWorkersUp(4),
                WORKER_SETUP_DURATION_MS, ""Connect workers did not start in time."");

        waitForCondition(() -> this.assertConnectorAndTasksRunning(CONNECTOR_NAME + 3, NUM_TASKS).orElse(false),
                CONNECTOR_SETUP_DURATION_MS, ""Connector tasks did not start in time."");

        waitForCondition(this::assertConnectorAndTasksAreUnique,
                WORKER_SETUP_DURATION_MS, ""Connect and tasks are imbalanced between the workers."");
    }
",non-flaky,5
26192,Ericsson_ecchronos,TestScheduleManager.testRunningJobWithThrowingRunPolicy,"    @Test
    public void testRunningJobWithThrowingRunPolicy()
    {
        DummyJob job = new DummyJob(ScheduledJob.Priority.LOW);
        myScheduler.schedule(job);

        when(myRunPolicy.validate(any(ScheduledJob.class))).thenThrow(new IllegalStateException());

        myScheduler.run();

        assertThat(job.hasRun()).isFalse();
        assertThat(myScheduler.getQueueSize()).isEqualTo(1);
    }
",non-flaky,5
156086,soot-oss_soot,MultiCallGraphVirtualEdgesTest.TestAsyncTaskBasicCG,"    @Test
    public void TestAsyncTaskBasicCG() {
        prepareTarget(methodSigFromComponents(TARGET_CLASS, TARGET_METHOD), TARGET_CLASS);
        boolean found = false;
        for (Edge edge : Scene.v().getCallGraph()) {
            //String sig = edge.getTgt().method().toString();
            System.out.println(edge);
            String sig = edge.getTgt().method().toString();

            if (edge.toString().contains(""AHelper"") && edge.toString().contains(""handle""))
                found = true;
        }

        //Assert.assertTrue(found);
    }
",non-flaky,5
76914,spring-projects_spring-data-envers,RepositoryIntegrationTests.testLifeCycle,"	@Test
	public void testLifeCycle() {

		License license = new License();
		license.name = ""Schnitzel"";

		licenseRepository.save(license);

		Country de = new Country();
		de.code = ""de"";
		de.name = ""Deutschland"";

		countryRepository.save(de);

		Country se = new Country();
		se.code = ""se"";
		se.name = ""Schweden"";

		countryRepository.save(se);

		license.laender = new HashSet<Country>();
		license.laender.addAll(Arrays.asList(de, se));

		licenseRepository.save(license);

		de.name = ""Daenemark"";

		countryRepository.save(de);

		Optional<Revision<Integer, License>> revision = licenseRepository.findLastChangeRevision(license.id);

		assertThat(revision).hasValueSatisfying(it -> {

			Page<Revision<Integer, License>> page = licenseRepository.findRevisions(license.id, PageRequest.of(0, 10));
			Revisions<Integer, License> revisions = Revisions.of(page.getContent());
			assertThat(revisions.getLatestRevision()).isEqualTo(it);
		});
	}
",non-flaky,5
89322,apache_samza,TestKafkaSystemConsumer.testFetchThresholdBytes,"  @Test
  public void testFetchThresholdBytes() {

    SystemStreamPartition ssp0 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(0));
    SystemStreamPartition ssp1 = new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(1));
    int partitionsNum = 2;
    int ime0Size = Integer.valueOf(FETCH_THRESHOLD_MSGS) / partitionsNum; // fake size
    int ime1Size = Integer.valueOf(FETCH_THRESHOLD_MSGS) / partitionsNum - 1; // fake size
    int ime11Size = 20;
    ByteArraySerializer bytesSerde = new ByteArraySerializer();
    IncomingMessageEnvelope ime0 = new IncomingMessageEnvelope(ssp0, ""0"", bytesSerde.serialize("""", ""key0"".getBytes()),
        bytesSerde.serialize("""", ""value0"".getBytes()), ime0Size);
    IncomingMessageEnvelope ime1 = new IncomingMessageEnvelope(ssp1, ""0"", bytesSerde.serialize("""", ""key1"".getBytes()),
        bytesSerde.serialize("""", ""value1"".getBytes()), ime1Size);
    IncomingMessageEnvelope ime11 = new IncomingMessageEnvelope(ssp1, ""0"", bytesSerde.serialize("""", ""key11"".getBytes()),
        bytesSerde.serialize("""", ""value11"".getBytes()), ime11Size);
    KafkaSystemConsumer consumer = createConsumer(FETCH_THRESHOLD_MSGS, FETCH_THRESHOLD_BYTES);

    consumer.register(ssp0, ""0"");
    consumer.register(ssp1, ""0"");
    consumer.start();
    consumer.messageSink.addMessage(ssp0, ime0);
    // queue for ssp0 should be full now, because we added message of size FETCH_THRESHOLD_MSGS/partitionsNum
    Assert.assertFalse(consumer.messageSink.needsMoreMessages(ssp0));
    consumer.messageSink.addMessage(ssp1, ime1);
    // queue for ssp1 should be less then full now, because we added message of size (FETCH_THRESHOLD_MSGS/partitionsNum - 1)
    Assert.assertTrue(consumer.messageSink.needsMoreMessages(ssp1));
    consumer.messageSink.addMessage(ssp1, ime11);
    // queue for ssp1 should full now, because we added message of size 20 on top
    Assert.assertFalse(consumer.messageSink.needsMoreMessages(ssp1));

    Assert.assertEquals(1, consumer.getNumMessagesInQueue(ssp0));
    Assert.assertEquals(2, consumer.getNumMessagesInQueue(ssp1));
    Assert.assertEquals(ime0Size, consumer.getMessagesSizeInQueue(ssp0));
    Assert.assertEquals(ime1Size + ime11Size, consumer.getMessagesSizeInQueue(ssp1));

    consumer.stop();
  }
",non-flaky,5
77019,Tencent_Firestorm,ShuffleStorageUtilsTest.getStorageIndexTest,"  @Test
  public void getStorageIndexTest() {
    int index = ShuffleStorageUtils.getStorageIndex(3, ""abcde"", 3, 1);
    assertEquals(2, index);
    index = ShuffleStorageUtils.getStorageIndex(3, ""abcde"", 3, 4);
    assertEquals(1, index);
  }
",non-flaky,5
26221,Ericsson_ecchronos,TestOnDemandRepairJob.testJobUnsuccessful,"    @Test
    public void testJobUnsuccessful()
    {
        OnDemandRepairJob repairJob = createOnDemandRepairJob();
        Iterator<ScheduledTask> it = repairJob.iterator();
        repairJob.postExecute(true, it.next());
        assertThat(repairJob.getState()).isEqualTo(ScheduledJob.State.RUNNABLE);
        repairJob.postExecute(false, it.next());
        assertThat(repairJob.getState()).isEqualTo(ScheduledJob.State.FAILED);
    }
",non-flaky,5
60934,apache_druid,BaseAveragerTest.testGetResult,"  @Test
  public void testGetResult()
  {
    BaseAverager<Integer, Integer> avg = new TestAverager(Integer.class, 3, ""test"", ""field"", 1);

    Assert.assertNull(avg.getResult());

    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());
    Assert.assertEquals(Integer.valueOf(1), avg.getResult());
  }
",non-flaky,5
84582,apache_zookeeper,WriteLockTest.testRun,"    @Test
    public void testRun() throws Exception {
        runTest(3);
    }
",non-flaky,5
57215,apache_ozone,TestOMDBUpdatesHandler.testPut,"  @Test
  public void testPut() throws Exception {
    OzoneConfiguration configuration = createNewTestPath();
    OmMetadataManagerImpl metaMgr = new OmMetadataManagerImpl(configuration);

    // Create 1 volume, 2 keys and write to source OM DB.
    String volumeKey = metaMgr.getVolumeKey(""sampleVol"");
    OmVolumeArgs args =
        OmVolumeArgs.newBuilder()
            .setVolume(""sampleVol"")
            .setAdminName(""bilbo"")
            .setOwnerName(""bilbo"")
            .build();
    metaMgr.getVolumeTable().put(volumeKey, args);

    OmKeyInfo firstKey = getOmKeyInfo(""sampleVol"", ""bucketOne"", ""key_one"");
    metaMgr.getKeyTable(getBucketLayout())
        .put(""/sampleVol/bucketOne/key_one"", firstKey);

    OmKeyInfo secondKey = getOmKeyInfo(""sampleVol"", ""bucketOne"", ""key_two"");
    metaMgr.getKeyTable(getBucketLayout())
        .put(""/sampleVol/bucketOne/key_two"", secondKey);

    // Write the secondKey to the target OM DB.
    OzoneConfiguration conf2 = createNewTestPath();
    OmMetadataManagerImpl reconOmmetaMgr = new OmMetadataManagerImpl(conf2);
    reconOmmetaMgr.getKeyTable(getBucketLayout())
        .put(""/sampleVol/bucketOne/key_two"", secondKey);

    RDBStore rdbStore = (RDBStore) metaMgr.getStore();
    RocksDB rocksDB = rdbStore.getDb();
    // Get all updates from source DB. (3 PUTs)
    TransactionLogIterator transactionLogIterator =
        rocksDB.getUpdatesSince(0);
    List<byte[]> writeBatches = new ArrayList<>();

    while(transactionLogIterator.isValid()) {
      TransactionLogIterator.BatchResult result =
          transactionLogIterator.getBatch();
      result.writeBatch().markWalTerminationPoint();
      WriteBatch writeBatch = result.writeBatch();
      writeBatches.add(writeBatch.data());
      transactionLogIterator.next();
    }

    // OMDBUpdatesHandler has access to target DB. Hence it has only the
    // ""secondKey"".
    OMDBUpdatesHandler omdbUpdatesHandler =
        new OMDBUpdatesHandler(reconOmmetaMgr);
    for (byte[] data : writeBatches) {
      WriteBatch writeBatch = new WriteBatch(data);
      // Capture the 3 PUT events from source DB.
      writeBatch.iterate(omdbUpdatesHandler);
    }

    List<OMDBUpdateEvent> events = omdbUpdatesHandler.getEvents();
    assertEquals(3, events.size());

    OMDBUpdateEvent volEvent = events.get(0);
    assertEquals(PUT, volEvent.getAction());
    assertEquals(volumeKey, volEvent.getKey());
    assertEquals(args.getVolume(), ((OmVolumeArgs)volEvent.getValue())
        .getVolume());

    OMDBUpdateEvent keyEvent = events.get(1);
    assertEquals(PUT, keyEvent.getAction());
    assertEquals(""/sampleVol/bucketOne/key_one"", keyEvent.getKey());
    assertNull(keyEvent.getOldValue());

    OMDBUpdateEvent updateEvent = events.get(2);
    assertEquals(UPDATE, updateEvent.getAction());
    assertEquals(""/sampleVol/bucketOne/key_two"", updateEvent.getKey());
    assertNotNull(updateEvent.getOldValue());
    assertEquals(secondKey.getKeyName(),
        ((OmKeyInfo)updateEvent.getOldValue()).getKeyName());
  }
",non-flaky,5
159617,liquibase_liquibase,MySQLIntegrationTest.snapshot,"    @Test
    public void snapshot() throws Exception {
        if (getDatabase() == null) {
            return;
        }


        runCompleteChangeLog();
        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(getDatabase().getDefaultSchema(), getDatabase(), new SnapshotControl(getDatabase()));
        System.out.println(snapshot);
    }
",non-flaky,5
38238,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetWhenMultipleVersions,"    @Test
    public void testGetWhenMultipleVersions() {
        putTestDataForMultipleTimestamps();
        Cell cell = Cell.create(row0, column0);
        Value val0 = Value.create(value0_t0, TEST_TIMESTAMP);
        Value val1 = Value.create(value0_t1, TEST_TIMESTAMP + 1);

        assertTrue(keyValueService.get(TEST_TABLE, ImmutableMap.of(cell, TEST_TIMESTAMP)).isEmpty());

        Map<Cell, Value> result = keyValueService.get(
                TEST_TABLE,
                ImmutableMap.of(cell, TEST_TIMESTAMP + 1));
        assertTrue(result.containsKey(cell));
        assertEquals(1, result.size());
        assertTrue(result.containsValue(val0));

        result = keyValueService.get(TEST_TABLE, ImmutableMap.of(cell, TEST_TIMESTAMP + 2));

        assertEquals(1, result.size());
        assertTrue(result.containsKey(cell));
        assertTrue(result.containsValue(val1));

        result = keyValueService.get(TEST_TABLE, ImmutableMap.of(cell, TEST_TIMESTAMP + 3));

        assertEquals(1, result.size());
        assertTrue(result.containsKey(cell));
        assertTrue(result.containsValue(val1));
    }
",non-flaky,5
26179,Ericsson_ecchronos,TestLockCollection.testCloseAllLocks,"    @Test
    public void testCloseAllLocks()
    {
        List<DummyLock> locks = new ArrayList<>();
        for (int i = 0; i < 10; i++)
        {
            locks.add(new DummyLock());
        }

        new LockCollection(locks).close();

        for (DummyLock lock : locks)
        {
            assertThat(lock.closed).isTrue();
        }
    }
",non-flaky,5
179469,abel533_Mapper,DateTimeTest.testInsert2,"    @Test
    public void testInsert2() {
        SqlSession sqlSession = getSqlSession();
        try {
            TimeModel2Mapper mapper = sqlSession.getMapper(TimeModel2Mapper.class);
            TimeModel2 timeModel = new TimeModel2();
            timeModel.setId(3);
            Date now = new Date();
            Timestamp now2 = new Timestamp(now.getTime());
            timeModel.setTestDate(now);
            timeModel.setTestTime(now);
            timeModel.setTestDatetime(now2);
            Assert.assertEquals(1, mapper.insert(timeModel));

            timeModel = mapper.selectByPrimaryKey(3);

            //ä¿å­åæ°æ®åºä¸­ä¸å­å¨æ¶é´é¨å
            Assert.assertEquals(toDate(now), toDate(timeModel.getTestDate()));
            Assert.assertEquals(toDate(now) + "" 00:00:00"", toDatetime(timeModel.getTestDate()));

            //æ¥æåæ¶é´é½æ
            Assert.assertEquals(toTime(now), toTime(timeModel.getTestTime()));
            Assert.assertEquals(toDatetime(now), toDatetime(timeModel.getTestTime()));

            Assert.assertEquals(toDatetime(now), toDatetime(timeModel.getTestDatetime()));
        } finally {
            sqlSession.close();
        }
    }
",non-flaky,5
59657,looly_hutool,ScriptUtilTest.compileTest,"	@Test
	public void compileTest() {
		CompiledScript script = ScriptUtil.compile(""print('Script test!');"");
		try {
			script.eval();
		} catch (ScriptException e) {
			throw new ScriptRuntimeException(e);
		}
	}
",non-flaky,5
20963,NationalSecurityAgency_timely,TagMatchingTest.testRegex3,"    @Test
    public void testRegex3() throws Exception {
        String tags = ""tag1=value1,tag2=value2,tag3=value3"";
        StringBuffer pattern = new StringBuffer();
        pattern.append(""(^|.*,)"");
        pattern.append(""tag2"");
        pattern.append(""="");
        pattern.append(""(value2|value3)"");
        pattern.append(""(,.*|$)"");
        Pattern p = Pattern.compile(pattern.toString());
        assertTrue(p.matcher(tags).matches());
    }
",non-flaky,5
175800,GoogleCloudPlatform_google-cloud-eclipse,ProjectSelectorSelectionChangedListenerTest.testSelectionChanged_emptySelection,"  @Test
  public void testSelectionChanged_emptySelection() {
    when(event.getSelection()).thenReturn(new StructuredSelection());
    listener.selectionChanged(event);
    verify(projectSelector).clearStatusLink();
  }
",non-flaky,5
91490,strapdata_elassandra,RareClusterStateIT.execute,"@TestLogging(""_root:DEBUG"")
    public void testAssignmentWithJustAddedNodes() throws Exception {
        internalCluster().startNode();
        final String index = ""index"";
        prepareCreate(index).setSettings(Settings.builder().put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)
            .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0)).get();
        ensureGreen(index);

        // close to have some unassigned started shards shards..
        client().admin().indices().prepareClose(index).get();


        final String masterName = internalCluster().getMasterName();
        final ClusterService clusterService = internalCluster().clusterService(masterName);
        final AllocationService allocationService = internalCluster().getInstance(AllocationService.class, masterName);
        clusterService.submitStateUpdateTask(""test-inject-node-and-reroute"", new ClusterStateUpdateTask() {
            @Override
            public ClusterState execute(ClusterState currentState) throws Exception {
                // inject a node
                ClusterState.Builder builder = ClusterState.builder(currentState);
                builder.nodes(DiscoveryNodes.builder(currentState.nodes()).add(new DiscoveryNode(""_non_existent"",
                        buildNewFakeTransportAddress(), emptyMap(), emptySet(), Version.CURRENT)));

                // open index
                final IndexMetaData indexMetaData = IndexMetaData.builder(currentState.metaData().index(index)).state(IndexMetaData.State.OPEN).build();

                builder.metaData(MetaData.builder(currentState.metaData()).put(indexMetaData, true));
                builder.blocks(ClusterBlocks.builder().blocks(currentState.blocks()).removeIndexBlocks(index));
                ClusterState updatedState = builder.build();

                RoutingTable.Builder routingTable = RoutingTable.builder(updatedState.routingTable());
                routingTable.addAsRecovery(updatedState.metaData().index(index));
                updatedState = ClusterState.builder(updatedState).routingTable(routingTable.build()).build();

                return allocationService.reroute(updatedState, ""reroute"");

            }
",non-flaky,5
133996,CorfuDB_CorfuDB,HandOfGodIT.handOfGodTest,"    @Test(timeout = 300000)
    public void handOfGodTest() {
        workflow(wf -> {
            wf.deploy();

            ClientParams clientFixture = ClientParams.builder().build();
            CorfuCluster corfuCluster = wf.getUniverse()
                    .getGroup(wf.getFixture().data().getGroupParamByIndex(0).getName());

            CorfuClient corfuClient = corfuCluster.getLocalCorfuClient();

            CorfuTable<String, String> table = corfuClient.createDefaultCorfuTable(DEFAULT_STREAM_NAME);
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                table.put(String.valueOf(i), String.valueOf(i));
            }

            //Should force remove two nodes from cluster
            CorfuServer server0 = corfuCluster.getServerByIndex(0);
            CorfuServer server1 = corfuCluster.getServerByIndex(1);
            CorfuServer server2 = corfuCluster.getServerByIndex(2);

            // Sequentially kill two nodes
            server1.kill();
            server2.kill();

            // Force remove the dead nodes
            corfuClient.getManagementView().forceRemoveNode(
                    server1.getEndpoint(),
                    clientFixture.getNumRetry(),
                    clientFixture.getTimeout(),
                    clientFixture.getPollPeriod()
            );

            corfuClient.getManagementView().forceRemoveNode(
                    server2.getEndpoint(),
                    clientFixture.getNumRetry(),
                    clientFixture.getTimeout(),
                    clientFixture.getPollPeriod()
            );

            // Verify layout contains only the node that is up
            corfuClient.invalidateLayout();
            Layout layout = corfuClient.getLayout();
            assertThat(layout.getAllActiveServers()).containsExactly(server0.getEndpoint());

            // Verify cluster status is STABLE
            ClusterStatusReport clusterStatusReport = corfuClient.getManagementView().getClusterStatus();
            assertThat(clusterStatusReport.getClusterStatus()).isEqualTo(ClusterStatus.STABLE);

            ScenarioUtils.waitUninterruptibly(Duration.ofSeconds(30));

            // Verify data path working
            for (int i = 0; i < DEFAULT_TABLE_ITER; i++) {
                assertThat(table.get(String.valueOf(i))).isEqualTo(String.valueOf(i));
            }

            corfuClient.shutdown();
        });
    }
",non-flaky,5
20973,NationalSecurityAgency_timely,WebSocketRequestDeserializationTest.testCreateDeserialization,"    @Test
    public void testCreateDeserialization() throws Exception {
        // @formatter:off
		String json = ""{ ""
				       + ""\""operation\"" : \""create\"",""
				       + "" \""sessionId\"": \""1234\""""
				    + ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(CreateSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((CreateSubscription) request).getSessionId());
    }
",non-flaky,5
92662,apache_dubbo,ConsumerConfigTest.testDefault,"    @Test
    public void testDefault() throws Exception {
        ConsumerConfig consumer = new ConsumerConfig();
        consumer.setDefault(true);
        assertThat(consumer.isDefault(), is(true));
    }
",non-flaky,5
122547,vespa-engine_vespa,SystemCtlTest.stop,"    @Test
    public void stop() {
        terminal.expectCommand(
                        ""systemctl show docker 2>&1"",
                        0,
                        ""a=b\n"" +
                                ""ActiveState=active\n"" +
                                ""bar=zoo\n"")
                .expectCommand(""systemctl stop docker 2>&1"", 0, """");

        assertTrue(new SystemCtl(terminal).stop(""docker"").converge(taskContext));
    }
",non-flaky,5
77472,opensearch-project_OpenSearch,ClusterApplierServiceTests.onSuccess,"    @TestLogging(value = ""org.opensearch.cluster.service:TRACE"", reason = ""to ensure that we log cluster state events on TRACE level"")
    public void testClusterStateUpdateLogging() throws Exception {
        MockLogAppender mockAppender = new MockLogAppender();
        mockAppender.start();
        mockAppender.addExpectation(
                new MockLogAppender.SeenEventExpectation(
                        ""test1"",
                        ClusterApplierService.class.getCanonicalName(),
                        Level.DEBUG,
                        ""*processing [test1]: took [1s] no change in cluster state""));
        mockAppender.addExpectation(
                new MockLogAppender.SeenEventExpectation(
                        ""test2"",
                        ClusterApplierService.class.getCanonicalName(),
                        Level.TRACE,
                        ""*failed to execute cluster state applier in [2s]*""));
        mockAppender.addExpectation(
            new MockLogAppender.SeenEventExpectation(
                ""test3"",
                ClusterApplierService.class.getCanonicalName(),
                Level.DEBUG,
                ""*processing [test3]: took [0s] no change in cluster state*""));

        Logger clusterLogger = LogManager.getLogger(ClusterApplierService.class);
        Loggers.addAppender(clusterLogger, mockAppender);
        try {
            clusterApplierService.currentTimeOverride = threadPool.relativeTimeInMillis();
            clusterApplierService.runOnApplierThread(""test1"",
                currentState -> clusterApplierService.currentTimeOverride += TimeValue.timeValueSeconds(1).millis(),
                new ClusterApplyListener() {
                    @Override
                    public void onSuccess(String source) { }

",non-flaky,5
13882,neo4j_neo4j,StoreMigratorFrom21IT.mustMendDuplicatePropertiesWhenUpgradingFromVersion21,"    @Test
    public void mustMendDuplicatePropertiesWhenUpgradingFromVersion21() throws Exception
    {
        // The rules:
        // If an index is present, all duplicates should be removed and the property set to the value in the index
        // If an index is not present, the property should be set to the value of the last duplicate in the property
        // chain, all duplicates except the first should be removed
        // If an index is not present, the first property in the duplicate chain should be kept for the users
        // benefit, moved to a special property value, `__DUPLICATE_<propkey>`
        //
        // This is the broken store that we are upgrading:
        //
        //   (#0:Label { keyA: ""actual"", keyA: ""phony!"", keyA: ""phony!"" })
        //   (#1 { keyA: ""actual"", keyA: ""actual"", keyA: ""actual"" })
        //   (#2:Label { keyA: ""real1"", keyA: ""phony"", keyA: ""phony"", keyD: ""real2"", keyD: ""phony"", keyD: ""phony"" })
        //   (#3 { keyA: ""real1"", keyA: ""phony"", keyA: ""phony"", keyD: ""real2"", keyD: ""phony"", keyD: ""phony"" })
        //   (#4 { keyA: ""actual"", keyB: ""actual"", keyC: ""actual"" })
        //   (#0)-[#0:REL { keyA: ""actual"", keyA: ""actual"", keyA: ""actual"" }]->(#1)
        //   (#0)-[#1:REL { keyA: ""real1"", keyA: ""phony"", keyA: ""phony"",
        //                  keyD: ""real2"", keyE: ""phony"", keyF: ""phony"" }]->(#1)
        //   (#2)-[#2:REL { keyA: ""actual"", keyB: ""actual"", keyC: ""actual"" }]->(#0)
        //
        // And this is what we want to end up with, after upgrading:
        //
        //   (#0:Label { keyA: ""actual"" })
        //   (#1 { keyA: ""actual"", __DUPLICATE_keyA: ""actual"" })
        //   (#2:Label { keyA: ""real1"", keyD: ""real2"" })
        //   (#3 { keyA: ""real1"", __DUPLICATE_keyA_1: ""real1"", __DUPLICATE_keyA_2: ""real1"",
        //         keyD: ""real2"", __DUPLICATE_keyD_1: ""real2"", __DUPLICATE_keyD_2: ""real2"" })
        //   (#4 { keyA: ""actual"", keyB: ""actual"", keyC: ""actual"" })
        //   (#0)-[#0:REL { keyA: ""actual"", __DUPLICATE_keyA: ""actual"" }]->(#1)
        //   (#0)-[#1:REL { keyA: ""real1"", __DUPLICATE_keyA_1: ""real1"", __DUPLICATE_keyA_2: ""real1"",
        //                  keyD: ""real2"", __DUPLICATE_keyD_1: ""real2"", __DUPLICATE_keyD_2: ""real2"" }]->(#1)
        //   (#2)-[#2:REL { keyA: ""actual"", keyB: ""actual"", keyC: ""actual"" }]->(#0)

        File dir = MigrationTestUtils.find21FormatStoreDirectoryWithDuplicateProperties( storeDir.directory() );

        GraphDatabaseBuilder builder =
                new GraphDatabaseFactory().newEmbeddedDatabaseBuilder( dir.getAbsolutePath() ).setConfig(
                        GraphDatabaseSettings.allow_store_upgrade, ""true"" );
        GraphDatabaseService database = builder.newGraphDatabase();
        database.shutdown();
        ConsistencyCheckService service = new ConsistencyCheckService();

        ConsistencyCheckService.Result result = service.runFullConsistencyCheck(
                dir.getAbsolutePath(), new Config(), ProgressMonitorFactory.NONE, StringLogger.SYSTEM );
        assertTrue( result.isSuccessful() );

        database = builder.newGraphDatabase();
        // Upgrade is now completed. Verify the contents:
        DependencyResolver dependencyResolver = ((GraphDatabaseAPI) database).getDependencyResolver();
        NeoStoreProvider provider = dependencyResolver.resolveDependency( NeoStoreProvider.class );
        NeoStore store = provider.evaluate();
        NodeStore nodeStore = store.getNodeStore();
        RelationshipStore relStore = store.getRelationshipStore();
        PropertyStore propertyStore = store.getPropertyStore();

        // Verify that the properties appear correct to the outside world:
        try ( Transaction ignore = database.beginTx() )
        {
            verifyPropertiesEqual( database.getNodeById( 0 ),
                    Pair.of( ""keyA"", ""actual"" ) );
            verifyPropertiesEqual( database.getNodeById( 1 ),
                    Pair.of( ""keyA"", ""actual"" ),
                    Pair.of( ""__DUPLICATE_keyA_1"", ""actual"" ),
                    Pair.of( ""__DUPLICATE_keyA_2"", ""actual"" ));
            verifyPropertiesEqual( database.getNodeById( 2 ),
                    Pair.of( ""keyA"", ""real1"" ),
                    Pair.of( ""keyD"", ""real2"" ) );
            verifyPropertiesEqual( database.getNodeById( 3 ),
                    Pair.of( ""keyA"", ""real1"" ),
                    Pair.of( ""__DUPLICATE_keyA_1"", ""real1"" ),
                    Pair.of( ""__DUPLICATE_keyA_2"", ""real1"" ),
                    Pair.of( ""keyD"", ""real2"" ),
                    Pair.of( ""__DUPLICATE_keyD_1"", ""real2"" ),
                    Pair.of( ""__DUPLICATE_keyD_2"", ""real2"" ) );
            verifyPropertiesEqual( database.getNodeById( 4 ),
                    Pair.of( ""keyA"", ""actual"" ),
                    Pair.of( ""keyB"", ""actual"" ),
                    Pair.of( ""keyC"", ""actual"" ) );
            verifyPropertiesEqual( database.getRelationshipById( 0 ),
                    Pair.of( ""keyA"", ""actual"" ),
                    Pair.of( ""__DUPLICATE_keyA_1"", ""actual"" ),
                    Pair.of( ""__DUPLICATE_keyA_2"", ""actual"" ));
            verifyPropertiesEqual( database.getRelationshipById( 1 ),
                    Pair.of( ""keyA"", ""real1"" ),
                    Pair.of( ""__DUPLICATE_keyA_1"", ""real1"" ),
                    Pair.of( ""__DUPLICATE_keyA_2"", ""real1"" ),
                    Pair.of( ""keyD"", ""real2"" ),
                    Pair.of( ""__DUPLICATE_keyD_1"", ""real2"" ),
                    Pair.of( ""__DUPLICATE_keyD_2"", ""real2"" ) );
            verifyPropertiesEqual( database.getRelationshipById( 2 ),
                    Pair.of( ""keyA"", ""actual"" ),
                    Pair.of( ""keyB"", ""actual"" ),
                    Pair.of( ""keyC"", ""actual"" ) );
        }

        // Verify that there are no two properties on the entities, that have the same key:
        // (This is important because the verification above cannot tell if we have two keys with the same value)
        verifyNoDuplicatePropertyKeys( propertyStore, nodeStore.getRecord( 0 ).getNextProp() );
        verifyNoDuplicatePropertyKeys( propertyStore, nodeStore.getRecord( 1 ).getNextProp() );
        verifyNoDuplicatePropertyKeys( propertyStore, nodeStore.getRecord( 2 ).getNextProp() );
        verifyNoDuplicatePropertyKeys( propertyStore, relStore.getRecord( 0 ).getNextProp() );
        verifyNoDuplicatePropertyKeys( propertyStore, relStore.getRecord( 1 ).getNextProp() );

        database.shutdown();
    }
",non-flaky,5
30922,camunda-cloud_zeebe,MsgPackWriterMiscTest.testEncodedLongValueLength,"  @Test
  public void testEncodedLongValueLength() {
    assertThat(MsgPackWriter.getEncodedLongValueLength(0x7f)).isEqualTo(1);
    assertThat(MsgPackWriter.getEncodedLongValueLength(0xff)).isEqualTo(2);
    assertThat(MsgPackWriter.getEncodedLongValueLength(0xffff)).isEqualTo(3);
    assertThat(MsgPackWriter.getEncodedLongValueLength(0xffff_ffffL)).isEqualTo(5);
    assertThat(MsgPackWriter.getEncodedLongValueLength(0x7fff_ffff_ffff_ffffL)).isEqualTo(9);
    assertThat(MsgPackWriter.getEncodedLongValueLength(-0x20)).isEqualTo(1);
    assertThat(MsgPackWriter.getEncodedLongValueLength(Byte.MIN_VALUE)).isEqualTo(2);
    assertThat(MsgPackWriter.getEncodedLongValueLength(Short.MIN_VALUE)).isEqualTo(3);
    assertThat(MsgPackWriter.getEncodedLongValueLength(Integer.MIN_VALUE)).isEqualTo(5);
    assertThat(MsgPackWriter.getEncodedLongValueLength(Long.MIN_VALUE)).isEqualTo(9);
  }
",non-flaky,5
178014,aosp-mirror_platform_frameworks_support,PlaybackControlGlueTest.testMediaPauseButtonOnPause,"    @Test
    public void testMediaPauseButtonOnPause() {
        PlaybackControlsRow row = new PlaybackControlsRow();
        glue.setControlsRow(row);
        SparseArrayObjectAdapter adapter = (SparseArrayObjectAdapter)
                row.getPrimaryActionsAdapter();
        PlaybackControlsRow.MultiAction playPause = (PlaybackControlsRow.MultiAction) adapter
                .lookup(PlaybackControlGlue.ACTION_PLAY_PAUSE);

        glue.onActionClicked(playPause);
        glue.onActionClicked(playPause);
        assertEquals(PlaybackControlGlue.PLAYBACK_SPEED_PAUSED, glue.getCurrentSpeedId());
        glue.onKey(null, KeyEvent.KEYCODE_MEDIA_PAUSE, new KeyEvent(KeyEvent.ACTION_DOWN,
                KeyEvent.KEYCODE_MEDIA_PAUSE));
        assertEquals(PlaybackControlGlue.PLAYBACK_SPEED_PAUSED, glue.getCurrentSpeedId());
    }
",non-flaky,5
99703,apache_cassandra,DistributionSequenceTest.negValueSequence,"    @Test
    public void negValueSequence() throws Exception
    {
        Distribution dist = OptionDistribution.get(""seq(-1000..-10)"").get();
        assertTrue(dist instanceof DistributionSequence);

        assertEquals(-1000, dist.minValue());
        assertEquals( -10, dist.maxValue());
        assertEquals(-504, dist.average());

        assertEquals(-1000, dist.inverseCumProb(0d));
        assertEquals(-10, dist.inverseCumProb(1d));

        long min = dist.next();
        assertEquals(-1000, min);

        long last = min;
        long next = dist.next();
        while (last<next)
        {
            assertEquals(next, last+1); //increase by one each step
            last = next;
            next = dist.next();
        }

        assertEquals(-10, last); // wrapping
        assertEquals(-1000, next); // wrapping
    }
",non-flaky,5
78292,apache_beam,SideInputHandlerTest.testIsReady,"  @Test
  public void testIsReady() {
    SideInputHandler sideInputHandler =
        new SideInputHandler(
            ImmutableList.of(view1, view2), InMemoryStateInternals.<Void>forKey(null));

    IntervalWindow firstWindow = new IntervalWindow(new Instant(0), new Instant(WINDOW_MSECS_1));

    IntervalWindow secondWindow = new IntervalWindow(new Instant(0), new Instant(WINDOW_MSECS_2));

    // side input should not yet be ready
    assertFalse(sideInputHandler.isReady(view1, firstWindow));

    // add a value for view1
    sideInputHandler.addSideInputValue(
        view1,
        valuesInWindow(
            materializeValuesFor(View.asIterable(), ""Hello""), new Instant(0), firstWindow));

    // now side input should be ready
    assertTrue(sideInputHandler.isReady(view1, firstWindow));

    // second window input should still not be ready
    assertFalse(sideInputHandler.isReady(view1, secondWindow));
  }
",non-flaky,5
98017,vert-x3_vertx-mongo-client,MongoClientWithObjectIdTest.testSavePreexistingObjectID,"  @Test
  public void testSavePreexistingObjectID() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject doc = createDoc();
      //Changed to hex string as a random string will not be valid for useObjectId = true
      doc.put(""_id"", new ObjectId().toHexString());
      mongoClient.saveWithOptions(collection, doc, ACKNOWLEDGED, onSuccess(id -> {
        assertNull(id);
        testComplete();
      }));
    }));
    await();
  }
",non-flaky,5
136505,doanduyhai_Achilles,FrozenNestedTypeStrategyTest.should_fail_for_non_frozen_list_udtValue,"    @Test
    public void should_fail_for_non_frozen_list_udtValue() throws Exception {
        setExec(aptUtils -> {
            final NestedTypeValidator2_1 strategy = new NestedTypeValidator2_1();
            final String className = TestEntityWithNestedTypes.class.getCanonicalName();
            final TypeName rawClass = ClassName.get(TestEntityWithNestedTypes.class);
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            // private List<UDTValue> listUdtValue;
            VariableElement elm = findFieldInType(typeElement, ""listUdtValue"");
            final AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils, globalParsingContext, elm);
            strategy.validate(aptUtils, annotationTree, ""listUdtValue"", rawClass);
        });
        failTestWithMessage(""collections/array type/UDT "" +
                ""'com.datastax.driver.core.UDTValue' "" +
                ""in 'listUdtValue' "" +
                ""of class 'info.archinnov.achilles.internals.sample_classes.parser.strategy.TestEntityWithNestedTypes' "" +
                ""should be annotated with @Frozen"", TestEntityWithNestedTypes.class);
    }
",non-flaky,5
176823,ctco_cukes,EntityFacadeTest.intArrayValueIsCheckedAsString,"    @Test
    public void intArrayValueIsCheckedAsString() throws Exception {
        BasicAttributes entity = new BasicAttributes(true);
        entity.put(""userPassword"", new int[]{1, 2, 3});

        Whitebox.setInternalState(entityFacade, ""entity"", entity);

        entityFacade.entityHasAttributeWithValue(""userpassword"", ""{1,2,3}"");
    }
",non-flaky,5
112101,apache_shardingsphere-elasticjob,DistributeOnceElasticJobListenerTest.assertBeforeJobExecutedWhenIsNotAllStartedAndNotTimeout,"    @Test
    public void assertBeforeJobExecutedWhenIsNotAllStartedAndNotTimeout() {
        when(guaranteeService.isAllStarted()).thenReturn(false);
        when(timeService.getCurrentMillis()).thenReturn(0L);
        distributeOnceElasticJobListener.beforeJobExecuted(shardingContexts);
        verify(guaranteeService).registerStart(Sets.newHashSet(0, 1));
        verify(guaranteeService, times(0)).clearAllStartedInfo();
    }
",non-flaky,5
89310,apache_samza,TestKafkaSystemAdminWithMock.testGetSSPMetadata,"  @Test
  public void testGetSSPMetadata() {
    SystemStreamPartition ssp = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    SystemStreamPartition otherSSP = new SystemStreamPartition(TEST_SYSTEM, ""otherTopic"", new Partition(1));
    TopicPartition topicPartition = new TopicPartition(VALID_TOPIC, 0);
    TopicPartition otherTopicPartition = new TopicPartition(""otherTopic"", 1);
    when(mockKafkaConsumer.beginningOffsets(ImmutableList.of(topicPartition, otherTopicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 1L, otherTopicPartition, 2L));
    when(mockKafkaConsumer.endOffsets(ImmutableList.of(topicPartition, otherTopicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 11L, otherTopicPartition, 12L));
    Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> expected =
        ImmutableMap.of(ssp, new SystemStreamMetadata.SystemStreamPartitionMetadata(""1"", ""10"", ""11""), otherSSP,
            new SystemStreamMetadata.SystemStreamPartitionMetadata(""2"", ""11"", ""12""));
    assertEquals(kafkaSystemAdmin.getSSPMetadata(ImmutableSet.of(ssp, otherSSP)), expected);
  }
",non-flaky,5
96948,apache_avro,TestHadoopCodecFactory.testHadoopCodecFactoryFail,"  @Test
  public void testHadoopCodecFactoryFail(){
    CodecFactory hadoopSnappyCodec = HadoopCodecFactory.fromHadoopString(""org.apache.hadoop.io.compress.FooCodec"");
    assertTrue(hadoopSnappyCodec == null);
  }
",non-flaky,5
88827,apache_ignite,IgniteThrottlingUnitTest.tooMuchPagesMarkedDirty,"    @Test
    public void tooMuchPagesMarkedDirty() {
        PagesWriteSpeedBasedThrottle throttle = new PagesWriteSpeedBasedThrottle(pageMemory2g, null, stateChecker, log);

       // 363308	350004	348976	10604
        long time = throttle.getParkTime(0.75,
            ((350004 + 348976) / 2),
            350004-10604,
            4,
            279,
            23933);

        System.err.println(time);

        assertTrue(time == 0);
    }
",non-flaky,5
170488,eclipse_jetty.project,ConnectorServerTest.testAnyRegistryHostBindsToAny,"    @Test
    public void testAnyRegistryHostBindsToAny() throws Exception
    {
        ServerSocket serverSocket = new ServerSocket(0);
        int registryPort = serverSocket.getLocalPort();
        serverSocket.close();
        connectorServer = new ConnectorServer(new JMXServiceURL(""service:jmx:rmi:///jndi/rmi://0.0.0.0:"" + registryPort + ""/jmxrmi""), objectName);
        connectorServer.start();

        // Verify that I can connect to the RMI registry using a non-loopback address.
        new Socket(InetAddress.getLocalHost(), registryPort).close();
        // Verify that I can connect to the RMI registry using the loopback address.
        new Socket(InetAddress.getLoopbackAddress(), registryPort).close();
    }
",non-flaky,5
26214,Ericsson_ecchronos,TestRepairSchedulerImpl.testUpdateTableConfiguration,"    @Test
    public void testUpdateTableConfiguration()
    {
        RepairSchedulerImpl repairSchedulerImpl = defaultRepairSchedulerImplBuilder().build();

        long expectedUpdatedRepairInterval = TimeUnit.DAYS.toMillis(1);

        RepairConfiguration updatedRepairConfiguration = RepairConfiguration.newBuilder()
                .withRepairInterval(expectedUpdatedRepairInterval, TimeUnit.MILLISECONDS)
                .build();

        repairSchedulerImpl.putConfiguration(TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        verify(scheduleManager, timeout(1000)).schedule(any(ScheduledJob.class));
        verify(scheduleManager, never()).deschedule(any(ScheduledJob.class));
        verify(myRepairStateFactory).create(eq(TABLE_REFERENCE), eq(RepairConfiguration.DEFAULT), any());
        verify(myRepairState, atLeastOnce()).update();
        assertOneTableViewExist(repairSchedulerImpl, TABLE_REFERENCE, RepairConfiguration.DEFAULT);

        repairSchedulerImpl.putConfiguration(TABLE_REFERENCE, updatedRepairConfiguration);

        verify(scheduleManager, timeout(1000).times(2)).schedule(any(ScheduledJob.class));
        verify(scheduleManager, timeout(1000)).deschedule(any(ScheduledJob.class));
        verify(myRepairStateFactory).create(eq(TABLE_REFERENCE), eq(updatedRepairConfiguration), any());
        verify(myRepairState, atLeastOnce()).update();
        assertOneTableViewExist(repairSchedulerImpl, TABLE_REFERENCE, updatedRepairConfiguration);

        repairSchedulerImpl.close();
        verify(scheduleManager, times(2)).deschedule(any(ScheduledJob.class));
        assertThat(repairSchedulerImpl.getCurrentRepairJobs()).isEmpty();

        verifyNoMoreInteractions(ignoreStubs(myTableRepairMetrics));
        verifyNoMoreInteractions(myRepairStateFactory);
        verifyNoMoreInteractions(scheduleManager);
    }
",non-flaky,5
91505,apache_kylin,KylinClientTest.retrieveMetaData,"    @Test
    public void retrieveMetaData() throws IOException {
        HttpResponse response = TestUtil.mockHttpResponseWithFile(200, ""OK"", ""tables_and_columns.json"");
        when(httpClient.execute(any(HttpUriRequest.class))).thenReturn(response);

        KylinMeta.KMetaProject metaData = client.retrieveMetaData(connInfo.getProject());

        assertEquals(connInfo.getProject(), metaData.projectName);
        assertTrue(!metaData.catalogs.isEmpty());
        KylinMeta.KMetaCatalog catalog = metaData.catalogs.get(0);
        assertEquals(""defaultCatalog"", catalog.getName());
        assertEquals(1, catalog.schemas.size());
        KylinMeta.KMetaSchema schema = catalog.schemas.get(0);
        assertEquals(""DEFAULT"", schema.getName());
        assertEquals(5, schema.tables.size());
    }
",non-flaky,5
77545,dropwizard_dropwizard,ResourceTestRuleTest.testDefaultJsonProcessingMapper,"    @Test
    public void testDefaultJsonProcessingMapper() {
        assertThat(resourceTestRule.target(""/person/blah/runtime-exception"")
                .request()
                .post(Entity.json(""{ \""he: \""ho\""}""))
                .readEntity(String.class))
                .isEqualTo(""{\""code\"":400,\""message\"":\""Unable to process JSON\""}"");
    }
",non-flaky,5
135077,undertow-io_undertow,CookiesTestCase.testEqualsInValueAllowedInQuotedValue,"    @Test
    public void testEqualsInValueAllowedInQuotedValue() {
        Map<String, Cookie> cookies = Cookies.parseRequestCookies(2, true, Arrays.asList(""CUSTOMER=\""WILE_E_COYOTE=THE_COYOTE\""; SHIPPING=FEDEX"" ));
        Assert.assertEquals(2, cookies.size());
        Cookie cookie = cookies.get(""CUSTOMER"");
        Assert.assertNotNull(cookie);
        Assert.assertEquals(""WILE_E_COYOTE=THE_COYOTE"", cookie.getValue());
        cookie = cookies.get(""SHIPPING"");
        Assert.assertNotNull(cookie);
        Assert.assertEquals(""FEDEX"", cookie.getValue());
    }
",non-flaky,5
362,line_armeria,ServiceRequestCancellationTest.shouldCompleteLogWhenCancelledByClient,"@Test
void shouldCompleteLogWhenCancelledByClient(SessionProtocol protocol) {
    final ClientFactory factory = ClientFactory.builder().build();
    final WebClient client = WebClient.builder(server.uri(protocol)).factory(factory).build();
    final CompletableFuture<AggregatedHttpResponse> responseFuture = client.get(""/reset"").aggregate();
    await().untilAtomic(ctxRef, Matchers.notNullValue());
    factory.close();
    final RequestLog log = ctxRef.get().log().whenComplete().join();
    if (protocol.isMultiplex()) {
        assertThat(log.responseCause()).isInstanceOf(ClosedStreamException.class).hasMessageContaining(""received a RST_STREAM frame: CANCEL"");
        assertThatThrownBy(responseFuture::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedStreamException.class);
    } else {
        assertThat(log.responseCause()).isInstanceOf(ClosedSessionException.class);
        assertThatThrownBy(responseFuture::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedSessionException.class);
    }
}",test order dependency,4
159665,liquibase_liquibase,MssqlIntegrationTest.defaultValuesTests,"    @Test
    public void defaultValuesTests() throws Exception {
        clearDatabase();

        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(""changelogs/mssql/issues/default.values.xml"");
        liquibase.update((String) null);

        DatabaseSnapshot snapshot = SnapshotGeneratorFactory.getInstance().createSnapshot(CatalogAndSchema.DEFAULT, this.getDatabase(), new SnapshotControl(getDatabase()));

        for (Table table : snapshot.get(Table.class)) {
            for (Column column : table.getColumns()) {
                if (column.getName().toLowerCase().endsWith(""_default"")) {
                    Object defaultValue = column.getDefaultValue();
                    assertNotNull(""Null default value for "" + table.getName() + ""."" + column.getName(), defaultValue);
                    if (column.getName().toLowerCase().contains(""date"") || column.getName().toLowerCase().contains(""time"")) {
                        if (defaultValue instanceof String) {
                            assertTrue(defaultValue.equals(""2017-12-09 23:52:39.1234567 +01:00""));
                        } else if (defaultValue instanceof DatabaseFunction) {
                            ((DatabaseFunction) defaultValue).getValue().contains(""type datetimeoffset"");
                        } else if (defaultValue instanceof Time) {
                            Calendar calendar = Calendar.getInstance();
                            calendar.setTime(((Date) defaultValue));
                            assertEquals(23, calendar.get(Calendar.HOUR_OF_DAY));
                            assertEquals(52, calendar.get(Calendar.MINUTE));
                            assertEquals(39, calendar.get(Calendar.SECOND));
                        } else {
                            assertTrue(""Unexpected default type ""+defaultValue.getClass().getName()+"" for "" + table.getName() + ""."" + column.getName(), defaultValue instanceof Date);
                            Calendar calendar = Calendar.getInstance();
                            calendar.setTime(((Date) defaultValue));
                            assertEquals(9, calendar.get(Calendar.DAY_OF_MONTH));
                            assertEquals(11, calendar.get(Calendar.MONTH));
                            assertEquals(2017, calendar.get(Calendar.YEAR));
                        }
                    } else if (column.getName().toLowerCase().contains(""char_"")) {
                        assertTrue(""Unexpected default type ""+defaultValue.getClass().getName()+"" for "" + table.getName() + ""."" + column.getName(), defaultValue instanceof String);
                    } else if (column.getName().toLowerCase().contains(""binary_"")) {
                        assertTrue(""Unexpected default type ""+defaultValue.getClass().getName()+"" for "" + table.getName() + ""."" + column.getName(), defaultValue instanceof DatabaseFunction);
                    } else {
                        assertTrue(""Unexpected default type ""+defaultValue.getClass().getName()+"" for "" + table.getName() + ""."" + column.getName(), defaultValue instanceof Number);
                        assertEquals(1, ((Number) defaultValue).intValue());
                    }
                }
            }
        }
    }
",non-flaky,5
112109,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertAddTaskResultStatistics,"    @Test
    public void assertAddTaskResultStatistics() {
        for (StatisticInterval each : StatisticInterval.values()) {
            assertTrue(repository.add(new TaskResultStatistics(100, 0, each, new Date())));
        }
    }
",non-flaky,5
60901,apache_druid,MovingAverageIterableTest.testAveraging,"  @Test
  public void testAveraging()
  {

    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();
    Map<String, Object> event3 = new HashMap<>();
    Map<String, Object> event4 = new HashMap<>();

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    Row row1 = new MapBasedRow(JAN_1, event1);

    event2.put(""gender"", ""m"");
    event2.put(""pageViews"", 20L);
    Row row2 = new MapBasedRow(JAN_2, event2);

    event3.put(""gender"", ""m"");
    event3.put(""pageViews"", 30L);
    Row row3 = new MapBasedRow(JAN_3, event3);

    event4.put(""gender"", ""f"");
    event4.put(""pageViews"", 40L);
    Row row4 = new MapBasedRow(JAN_3, event4);

    float retval = 14.5f;

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.singletonList(row1)),
        new RowBucket(JAN_2, Collections.singletonList(row2)),
        new RowBucket(JAN_3, Arrays.asList(row3, row4))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Arrays.asList(
            new ConstantAveragerFactory(""costPageViews"", 7, retval),
            new LongMeanAveragerFactory(""movingAvgPageViews"", 7, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row caResult = iter.next();

    Assert.assertEquals(JAN_1, caResult.getTimestamp());
    Assert.assertEquals(""m"", (caResult.getDimension(""gender"")).get(0));
    Assert.assertEquals(retval, caResult.getMetric(""costPageViews"").floatValue(), 0.0f);
    Assert.assertEquals(1.4285715f, caResult.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    caResult = iter.next();
    Assert.assertEquals(""m"", (caResult.getDimension(""gender"")).get(0));
    Assert.assertEquals(4.285714f, caResult.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    caResult = iter.next();
    Assert.assertEquals(""m"", (caResult.getDimension(""gender"")).get(0));
    Assert.assertEquals(8.571428f, caResult.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    caResult = iter.next();
    Assert.assertEquals(""f"", (caResult.getDimension(""gender"")).get(0));
    Assert.assertEquals(5.714285850f, caResult.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertFalse(iter.hasNext());

  }
",non-flaky,5
175797,GoogleCloudPlatform_google-cloud-eclipse,RelativeFileFieldSetterTest.testSetField_userSuppliesPathOutsideBase,"  @Test
  public void testSetField_userSuppliesPathOutsideBase() {
    when(field.getText()).thenReturn("""");
    when(dialog.open()).thenReturn(""/path/outside/base/app.yaml"");

    new RelativeFileFieldSetter(field, new Path(""/base/path""), dialog).widgetSelected(event);
    verify(field).setText(""../../path/outside/base/app.yaml"");
  }
",non-flaky,5
76672,quarkusio_quarkus,ConfiguredBean.loadConfig,"@TestAnnotation
    public void loadConfig(TestBuildAndRunTimeConfig buildTimeConfig, TestRunTimeConfig runTimeConfig,
            FooRuntimeConfig fooRuntimeConfig) {
        System.out.printf(""loadConfig, buildTimeConfig=%s, runTimeConfig=%s, fooRuntimeConfig=%s%n"", buildTimeConfig,
                runTimeConfig, fooRuntimeConfig);
        this.buildTimeConfig = buildTimeConfig;
        this.runTimeConfig = runTimeConfig;
        this.fooRuntimeConfig = fooRuntimeConfig;
    }
",non-flaky,5
99771,apache_cassandra,RateBasedBackPressureTest.testBackPressureRateLimiterIsIncreasedAfterGoingAgainAboveHighRatio,"    @Test
    public void testBackPressureRateLimiterIsIncreasedAfterGoingAgainAboveHighRatio() throws Exception
    {
        long windowSize = 6000;
        TestTimeSource timeSource = new TestTimeSource();
        RateBasedBackPressure strategy = new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""10"", FLOW, ""FAST""), timeSource, windowSize);
        RateBasedBackPressureState state = strategy.newState(InetAddressAndPort.getLoopbackAddress());

        // Update incoming and outgoing rate so that the ratio is 0.5:
        state.incomingRate.update(50);
        state.outgoingRate.update(100);

        // Move time ahead:
        timeSource.sleep(windowSize, TimeUnit.MILLISECONDS);

        // Verify the rate decreased:
        strategy.apply(Sets.newHashSet(state), 1, TimeUnit.SECONDS);
        assertEquals(7.4, state.rateLimiter.getRate(), 0.1);

        // Update incoming and outgoing rate back above high rate:
        state.incomingRate.update(50);
        state.outgoingRate.update(50);

        // Move time ahead:
        timeSource.sleep(windowSize, TimeUnit.MILLISECONDS);

        // Verify rate limiter is increased by factor:
        strategy.apply(Sets.newHashSet(state), 1, TimeUnit.SECONDS);
        assertEquals(8.25, state.rateLimiter.getRate(), 0.1);

        // Update incoming and outgoing rate to keep it below the limiter rate:
        state.incomingRate.update(1);
        state.outgoingRate.update(1);

        // Move time ahead:
        timeSource.sleep(windowSize, TimeUnit.MILLISECONDS);

        // Verify rate limiter is not increased as already higher than the actual rate:
        strategy.apply(Sets.newHashSet(state), 1, TimeUnit.SECONDS);
        assertEquals(8.25, state.rateLimiter.getRate(), 0.1);
    }
",non-flaky,5
175754,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testRefreshProjectsForSelectedCredential_switchAccounts,"  @Test
  public void testRefreshProjectsForSelectedCredential_switchAccounts()
      throws ProjectRepositoryException, InterruptedException {
    when(loginService.getAccounts()).thenReturn(twoAccountSet);
    initializeProjectRepository();

    deployPanel = createPanel(false /* requireValues */);
    Table projectTable = getProjectSelector().getViewer().getTable();
    assertNull(deployPanel.latestGcpProjectQueryJob);
    assertThat(projectTable.getItemCount(), is(0));

    selectAccount(account1);
    Job jobForAccount1 = deployPanel.latestGcpProjectQueryJob;
    jobForAccount1.join();
    assertThat(projectTable.getItemCount(), is(2));

    selectAccount(account2);
    assertNotEquals(jobForAccount1, deployPanel.latestGcpProjectQueryJob);
    deployPanel.latestGcpProjectQueryJob.join();
    assertThat(projectTable.getItemCount(), is(1));
    assertThat(((GcpProject) projectTable.getItem(0).getData()).getId(), is(""projectId2""));
  }
",non-flaky,5
33663,alibaba_fastjson,SerializeWriterTest.test_large,"    @Test
    public void test_large() throws Exception {
        SerializeWriter writer = new SerializeWriter();

        for (int i = 0; i < 1024 * 1024; ++i) {
            writer.write(i);
        }

        writer.close();
    }
",non-flaky,5
92633,apache_dubbo,ApplicationConfigTest.testRegistry,"    @Test
    public void testRegistry() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        RegistryConfig registry = new RegistryConfig();
        application.setRegistry(registry);
        assertThat(application.getRegistry(), sameInstance(registry));
        application.setRegistries(Collections.singletonList(registry));
        assertThat(application.getRegistries(), contains(registry));
        assertThat(application.getRegistries(), hasSize(1));
    }
",non-flaky,5
43023,fabiomaffioletti_jsondoc,Spring3JSONDocObjectScannerTest.getJSONDoc,"    @Test
    public void getJSONDoc() throws IOException {
        JSONDocScanner jsondocScanner = new Spring3JSONDocScanner();
        JSONDoc jsondoc = jsondocScanner.getJSONDoc(version, basePath, Lists.newArrayList(""org.jsondoc.springmvc.controller""), true, MethodDisplay.URI);

        Map<String, Set<ApiObjectDoc>> objects = jsondoc.getObjects();
        for (Set<ApiObjectDoc> values : objects.values()) {
            for (ApiObjectDoc apiObjectDoc : values) {
                System.out.println(apiObjectDoc.getName());
            }
        }

    }
",non-flaky,5
15,MundaneImmortal_pair-distribution-app,testGenerateNewDayPairs,"@Test
public void testGenerateNewDayPairs() {
    PairCombinations pairs = getPairsList();
    List<Developer> devs = getStandardDevs();
    List<String> tracks = Arrays.asList(""track1"", ""track2"", ""track3"");
    Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs);
    subject.buildDevelopersPairingDays(pairs, devs);
    DayPairs dayPairs = subject.generateNewDayPairs(tracks, devs, pairs, pairsWeight, getStandardCompanies());
    assertThat(dayPairs.getTracks().size(), is(2));
    assertThat(dayPairs.getTracks(), contains(""track1"", ""track2""));
    assertThat(dayPairs.getPairByTrack(""track1""),
    is(not(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2""))))));
    assertThat(dayPairs.getPairByTrack(""track2""),
    is(not(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4""))))));
    boolean trackOneHasContext = dayPairs.getPairByTrack(""track1"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track1"").getSecondDev().hasContext();
    boolean trackTwoHasContext = dayPairs.getPairByTrack(""track2"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track2"").getSecondDev().hasContext();
    assertThat(trackOneHasContext, is(true));
    assertThat(trackTwoHasContext, is(true));
}",unordered collections,3
135770,Netflix_Hystrix,HystrixPluginsTest.testMetricsPublisherDefaultImpl,"    /*@Test
    public void testMetricsPublisherDefaultImpl() {
        HystrixMetricsPublisher impl = HystrixPlugins.getInstance().getMetricsPublisher();
        assertTrue(impl instanceof HystrixMetricsPublisherDefault);
    }
",non-flaky,5
57278,apache_ozone,TestContainerEndpoint.testGetKeysForContainerWithPrevKey,"  @Test
  public void testGetKeysForContainerWithPrevKey() {
    // test if prev-key param works as expected
    Response response = containerEndpoint.getKeysForContainer(
        1L, -1, ""/sampleVol/bucketOne/key_one"");

    KeysResponse data =
        (KeysResponse) response.getEntity();

    assertEquals(3, data.getTotalCount());

    Collection<KeyMetadata> keyMetadataList = data.getKeys();
    assertEquals(1, keyMetadataList.size());

    Iterator<KeyMetadata> iterator = keyMetadataList.iterator();
    KeyMetadata keyMetadata = iterator.next();

    assertEquals(""key_two"", keyMetadata.getKey());
    assertEquals(2, keyMetadata.getVersions().size());
    assertEquals(2, keyMetadata.getBlockIds().size());

    response = containerEndpoint.getKeysForContainer(
        1L, -1, StringUtils.EMPTY);
    data = (KeysResponse) response.getEntity();
    keyMetadataList = data.getKeys();

    assertEquals(3, data.getTotalCount());
    assertEquals(2, keyMetadataList.size());
    iterator = keyMetadataList.iterator();
    keyMetadata = iterator.next();
    assertEquals(""key_one"", keyMetadata.getKey());

    // test for negative cases
    response = containerEndpoint.getKeysForContainer(
        1L, -1, ""/sampleVol/bucketOne/invalid_key"");
    data = (KeysResponse) response.getEntity();
    keyMetadataList = data.getKeys();
    assertEquals(3, data.getTotalCount());
    assertEquals(0, keyMetadataList.size());

    response = containerEndpoint.getKeysForContainer(
        5L, -1, """");
    data = (KeysResponse) response.getEntity();
    keyMetadataList = data.getKeys();
    assertEquals(0, keyMetadataList.size());
    assertEquals(0, data.getTotalCount());
  }
",non-flaky,5
162757,OpenAPITools_openapi-generator,AdditionalPropertiesIntegerTest.testAdditionalPropertiesInteger,"    @Test
    public void testAdditionalPropertiesInteger() {
        // TODO: test AdditionalPropertiesInteger
    }
",non-flaky,5
114013,apache_struts,StrutsTilesAnnotationProcessorTest.buildDefiniton,"    @Test
    public void buildDefiniton() {
        StrutsTilesAnnotationProcessor annotationProcessor = new StrutsTilesAnnotationProcessor();
        TilesDefinition tilesDefinition = annotationProcessor.findAnnotation(new TilesTestActionSingleAnnotation(), null);

        Definition definition = annotationProcessor.buildTilesDefinition(""tileName"", tilesDefinition);

        Assert.assertNotNull(definition);
        Assert.assertEquals(""tileName"", definition.getName());
        Assert.assertEquals(""preparer"", definition.getPreparer());
        Assert.assertEquals(""base-definition"", definition.getExtends());
        Attribute templateAttribute = definition.getTemplateAttribute();
        Assert.assertEquals(""template"", templateAttribute.getValue());
        Assert.assertEquals(""type"", templateAttribute.getRenderer());
        Assert.assertEquals(""role"", templateAttribute.getRole());
        Expression definitionExpressionObject = templateAttribute.getExpressionObject();
        Assert.assertEquals(""templ*"", definitionExpressionObject.getExpression());
        Assert.assertNull(definitionExpressionObject.getLanguage());

        Attribute putAttribute = definition.getAttribute(""put-attr"");
        Assert.assertNotNull(putAttribute);
        Assert.assertEquals(""attr-val"", putAttribute.getValue());
        Assert.assertEquals(""attr-type"", putAttribute.getRenderer());
        Assert.assertEquals(""attr-role"", putAttribute.getRole());
        Expression putAttrExpressionObject = putAttribute.getExpressionObject();
        Assert.assertEquals(""expr"", putAttrExpressionObject.getExpression());
        Assert.assertEquals(""lang"", putAttrExpressionObject.getLanguage());

        Attribute listAttribute = definition.getAttribute(""list-name"");
        Assert.assertEquals(""list-role"", listAttribute.getRole());
        List<Attribute> listValue = getListValue(listAttribute);
        Assert.assertEquals(2, listValue.size());

        Attribute addAttribute = listValue.get(0);
        Assert.assertEquals(""list-attr-role"", addAttribute.getRole());
        Assert.assertEquals(""list-attr-val"", addAttribute.getValue());
        Assert.assertEquals(""list-attr-type"", addAttribute.getRenderer());
        Expression addAttrExpressionObject = addAttribute.getExpressionObject();
        Assert.assertEquals(""list-attr-expr"", addAttrExpressionObject.getExpression());

        Attribute addListAttribute = listValue.get(1);
        Assert.assertEquals(""list-list-attr-role"", addListAttribute.getRole());
        List<Attribute> addListValue = getListValue(addListAttribute);
        Assert.assertEquals(1, addListValue.size());
        Assert.assertEquals(""list-list-add-attr"", addListValue.get(0).getValue());

        Set<String> cascadedAttributeNames = definition.getCascadedAttributeNames();
        Assert.assertEquals(2, cascadedAttributeNames.size());
        Assert.assertTrue(cascadedAttributeNames.contains(""put-attr""));
        Assert.assertTrue(cascadedAttributeNames.contains(""list-name""));
    }
",non-flaky,5
156071,jReddit_jReddit,RedditOAuthAgentTest.testTokenAppOnly,"    @Test
    public void testTokenAppOnly() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        
        // Captor for the request that is executed
        ArgumentCaptor<OAuthClientRequest> clientCaptor = ArgumentCaptor.forClass(OAuthClientRequest.class);
        
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenReturn(jsonTokenNonRefreshable);
        
        // Run subject
        RedditToken token = subject.tokenAppOnly(false);
        
        // Verify and capture
        verify(mockOAuthClient).accessToken(clientCaptor.capture());
        
        OAuthClientRequest request = clientCaptor.getValue();
        
        assertNotNull(request.getHeader(""Authorization"")); // This is Base64 encoded
        assertEquals(request.getHeader(""User-Agent""), userAgent);
        
        assertEquals(accessToken, token.getAccessToken());
        assertNull(token.getRefreshToken());
        assertEquals(tokenType, token.getTokenType());
        assertEquals(expiresIn, token.getExpirationSpan());
        assertTrue(token.hasScope(RedditScope.EDIT));
        assertTrue(token.hasScope(RedditScope.FLAIR));
        assertFalse(token.hasScope(RedditScope.PRIVATEMESSAGE));

    }
",non-flaky,5
70854,apache_kafka,TransformationConfigTest.testEmbeddedConfigHoistField,"    @Test
    public void testEmbeddedConfigHoistField() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", HoistField.Value.class.getName());
        connProps.put(""transforms.example.field"", ""field"");

        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
104129,spring-cloud_spring-cloud-config,ConfigServicePropertySourceLocatorTests.shouldThrowExceptionWhenPasswordAndAuthorizationBothSet,"	@Test
	public void shouldThrowExceptionWhenPasswordAndAuthorizationBothSet() {
		HttpHeaders headers = new HttpHeaders();
		ConfigClientProperties defaults = new ConfigClientProperties(this.environment);
		defaults.getHeaders().put(AUTHORIZATION, ""Basic dXNlcm5hbWU6cGFzc3dvcmQNCg=="");
		this.locator = new ConfigServicePropertySourceLocator(defaults);
		String username = ""user"";
		String password = ""pass"";
		this.expected.expect(IllegalStateException.class);
		this.expected.expectMessage(""You must set either 'password' or 'authorization'"");
		ReflectionTestUtils.invokeMethod(this.locator, ""addAuthorizationToken"", defaults,
				headers, username, password);
	}
",non-flaky,5
362,apache_hadoop,TestPermissionSymlinks.testReadWhenTargetNotReadable,"  @Test(timeout = 5000)
  public void testReadWhenTargetNotReadable() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0000));
    doReadTargetNotReadable();
  }
",non-flaky,5
33837,apache_camel,FileCopyExample.testCopyFileOverIronMQ,"    @Test
    public void testCopyFileOverIronMQ() throws Exception {
        getMockEndpoint(""mock:result"").expectedMessageCount(1);
        assertMockEndpointsSatisfied();
        assertFileExists(""target/out/test.txt"");
    }
",non-flaky,5
110111,Wikidata_wikidata-toolkit,JsonSerializationActionTest.testJsonGzipOutput,"	@Test
	public void testJsonGzipOutput() throws IOException {
		String[] args = new String[] { ""-a"", ""json"", ""-o"",
				""/path/to/output.json"", ""-z"", ""gz"" };

		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);

		ClientConfiguration config = new ClientConfiguration(args);
		JsonSerializationAction jsa = (JsonSerializationAction) config
				.getActions().get(0);

		ItemIdValue subject1 = Datamodel.makeWikidataItemIdValue(""Q42"");
		MonolingualTextValue mtv1 = Datamodel.makeMonolingualTextValue(""Test1"",
				""en"");
		MonolingualTextValue mtv2 = Datamodel.makeMonolingualTextValue(""Test2"",
				""fr"");

		ItemDocument id1 = Datamodel.makeItemDocument(subject1,
				Arrays.asList(mtv1, mtv2), Arrays.asList(mtv1),
				Collections.<MonolingualTextValue> emptyList(),
				Collections.<StatementGroup> emptyList(),
				Collections.<String, SiteLink> emptyMap());

		jsa.open();
		jsa.processItemDocument(id1);
		jsa.close();

		MockDirectoryManager mdm = new MockDirectoryManager(
				Paths.get(""/path/to/""), false);

		ObjectMapper mapper = new DatamodelMapper(Datamodel.SITE_WIKIDATA);
		ObjectReader documentReader = mapper.readerFor(EntityDocumentImpl.class);
		MappingIterator<EntityDocument> documentIterator = documentReader
				.readValues(mdm.getInputStreamForFile(""output.json.gz"",
						CompressionType.GZIP));

		List<EntityDocument> results = new ArrayList<>();
		while (documentIterator.hasNextValue()) {
			EntityDocument document = documentIterator.nextValue();
			results.add(document);
		}
		documentIterator.close();

		assertEquals(1, results.size());
		assertEquals(id1, results.get(0));
	}
",non-flaky,5
98460,ONSdigital_rm-collection-exercise-service,EventServiceTest.testTagShouldHaveMpsAsIsActionable,"  @Test
  public void testTagShouldHaveMpsAsIsActionable() {
    assertThat(Tag.mps.isActionable(), Matchers.is(true));
  }
",non-flaky,5
176802,ctco_cukes,TemplatingEngineTest.testBody,"    @Test
    public void testBody() {
        String body = ""{\n"" +
            "" \""business\"": {\n"" +
            "" \""businessDirection\"": 1006415,\n"" +
            "" \""transactionType\"": 101759,\n"" +
            "" \""businessSegment\"": 1022645\n"" +
            "" },\n"" +
            "" \""contractName\"": \""@contractName\"",\n"" +
            "" \""underwritingYear\"": 2015,\n"" +
            "" \""businessAndParticipationType\"": 1001011,\n"" +
            "" \""agreementType\"": \""@agreementType\"",\n"" +
            "" \""fasClassification\"": \""@fasClassification\"",\n"" +
            "" \""accountingBasis\"": 100003,\n"" +
            "" \""underwritingObjectStatus\"": 1003797,\n"" +
            "" \""inceptionDate\"": \""2015-01-01T00:00:00.000+0000\"",\n"" +
            "" \""expirationDate\"": \""2015-12-31T00:00:00.000+0000\"",\n"" +
            "" \""contractCurrency\"": \""EUR\"",\n"" +
            "" \""profitCentre\"": @profitCentre,\n"" +
            "" \""involvedParties\"": [\n"" +
            "" {\n"" +
            "" \""partnerId\"": \""@partnerId_1\"",\n"" +
            "" \""partnerRole\"": @partnerRole\n"" +
            "" },\n"" +
            "" {\n"" +
            "" \""partnerId\"": @partnerId_2,\n"" +
            "" \""partnerRole\"": 2173\n"" +
            "" }\n"" +
            "" ]\n"" +
            ""}"";

        String processBody = TemplatingEngine.processBody(body);

        assertTrue(processBody.contains(""\""contractName\"": \""test1\""""));
        assertTrue(processBody.contains(""\""profitCentre\"": 24342""));
    }
",non-flaky,5
104641,apache_pinot,OfflineClusterIntegrationTest.testDefaultColumns,"  @Test(dependsOnMethods = ""testAggregateMetadataAPI"")
  public void testDefaultColumns()
      throws Exception {
    long numTotalDocs = getCountStarResult();

    reloadWithExtraColumns();
    JsonNode queryResponse = postQuery(SELECT_STAR_QUERY);
    assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(queryResponse.get(""selectionResults"").get(""columns"").size(), 91);

    testNewAddedColumns();

    reloadWithMissingColumns();
    queryResponse = postQuery(SELECT_STAR_QUERY);
    assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(queryResponse.get(""selectionResults"").get(""columns"").size(), 75);

    reloadWithRegularColumns();
    queryResponse = postQuery(SELECT_STAR_QUERY);
    assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
    assertEquals(queryResponse.get(""selectionResults"").get(""columns"").size(), 79);

    _tableSizeAfterRemovingIndex = getTableSize(getTableName());
  }
",non-flaky,5
112662,tbsalling_aismessages,LongRangeBroadcastMessageTest.canDecode1,"    @Test
    public void canDecode1() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,KC5E2b@U19PFdLbMuc5=ROv62<7m,0*16""));

        System.out.println(aisMessage.toString());

        assertEquals(AISMessageType.LongRangeBroadcastMessage, aisMessage.getMessageType());
        assertEquals((Integer) 1, aisMessage.getRepeatIndicator());
        assertEquals(MMSI.valueOf(206914217), aisMessage.getSourceMmsi());

        LongRangeBroadcastMessage message = (LongRangeBroadcastMessage) aisMessage;
        assertFalse(message.getPositionAccuracy());
        assertFalse(message.getRaim());
        assertEquals(NavigationStatus.NotUnderCommand, message.getNavigationalStatus());
        assertEquals(Float.valueOf(137.02333f), message.getLongitude());
        assertEquals(Float.valueOf(4.84f), message.getLatitude());
        assertEquals(Float.valueOf(57f), message.getSpeedOverGround(), 1e-5);
        assertEquals((Integer)57, message.getRawSpeedOverGround());
        assertEquals(Float.valueOf(167f), message.getCourseOverGround(), 1e-5);
        assertEquals((Integer)167, message.getRawCourseOverGround());
    }
",non-flaky,5
110839,pushtorefresh_storio,GetObjectObserveChangesTest.repeatsOperationWithRawQueryByChangeOfTag,"    @Test
    public void repeatsOperationWithRawQueryByChangeOfTag() {
        User user = putUserBlocking();

        PreparedGetObject<User> operation = storIOSQLite
                .get()
                .object(User.class)
                .withQuery(query)
                .prepare();

        verifyChangesReceived(operation, tagChanges, user);
    }
",non-flaky,5
170504,eclipse_jetty.project,MBeanContainerTest.testBeanRemoved,"    @Test
    public void testBeanRemoved()
    {
        setUpBeanRemoved();

        mbeanContainer.beanRemoved(null, managed);

        assertNull(mbeanContainer.findMBean(managed), ""Bean shouldn't be registered with container as we removed the bean"");
    }
",non-flaky,5
134027,CorfuDB_CorfuDB,OrchestratorTest.testAddNodeRequestWithExisting,"    @Test
    public void testAddNodeRequestWithExisting() {
        sendAndValidateWorkflowDispatch(getAddNodeRequestMsg(ENDPOINT_1), WORKFLOW_ID_1);

        // Verify that no new workflow is run.
        verify(orchestrator, never()).run(any(IWorkflow.class), anyInt());
    }
",non-flaky,5
346,apache_hadoop,TestNetworkTopology.testNumOfChildren,"  @Test
  public void testNumOfChildren() throws Exception {
    assertEquals(cluster.getNumOfLeaves(), dataNodes.length);
  }
",non-flaky,5
356,cdapio_cdap,MetricsQueryTestRun.testingUserServiceGaugeMetrics,"@Test
public void testingUserServiceGaugeMetrics() throws Exception {
    MetricsCollector collector =
    collectionService.getCollector(getUserServiceContext(Constants.DEFAULT_NAMESPACE, ""WordCount"", ""CounterService"",
    ""CountRunnable""));
    collector.increment(""gmetric"", 1);
    collector.gauge(""gmetric"", 10);
    collector.increment(""gmetric"", 1);
    TimeUnit.SECONDS.sleep(1);
    collector.gauge(""gmetric"", 10);
    TimeUnit.SECONDS.sleep(2);
    String runnableRequest =
    ""/system/apps/WordCount/services/CounterService/runnables/CountRunnable/gmetric?aggregate=true"";
    String serviceRequest =
    ""/system/apps/WordCount/services/CounterService/gmetric?aggregate=true"";
    testSingleMetric(runnableRequest, 10);
    testSingleMetric(serviceRequest, 10);
}",async wait,0
98627,nutzam_nutz,El2Test.test_issue_1475_1476,"    @Test
    public void test_issue_1475_1476() {
        
        Context context = Lang.context();
        context.set(""Math"", Math.class);
        
        
        //Queue<Object> rpn = new ShuntingYard().parseToRPN(""Math.max(10, 0-11)"");
        //System.out.println(rpn);
        
//        Queue<Object> rpn = new ShuntingYard().parseToRPN(""Math.max(0,-10)"");
//        System.out.println(rpn);
        Object max = El.eval(context, ""Math.max(0,-11)"");
        assertEquals(0, max);
        
        
        assertEquals(0, El.eval(context, ""Math.max(-1,0)""));
        assertEquals(0, El.eval(context, ""Math.max(0,-1)""));
        assertEquals(0, El.eval(context, ""Math.max(-0,-1)""));
        

        assertEquals(0, El.eval(context, ""Math.max(-1,Math.max(-1,Math.max(-1,Math.max(-1,0))))""));
        assertEquals(0, El.eval(context, ""Math.max(Math.max(Math.max(Math.max(0,-1),-1),-1),-1)""));
        assertEquals(0, El.eval(context, ""Math.max(-Math.max(-Math.max(-Math.max(-0,-1),-1),-1),-1)""));
    }
",non-flaky,5
59591,looly_hutool,QrCodeUtilTest.decodeTest,"	@Test
	public void decodeTest() {
		String decode = QrCodeUtil.decode(FileUtil.file(""e:/pic/qr.png""));
		Console.log(decode);
	}
",non-flaky,5
118718,netty_netty,SocketTest.testSoLinger,"    @Test
    public void testSoLinger() throws Exception {
        assertEquals(-1, socket.getSoLinger());
        socket.setSoLinger(10);
        assertEquals(10, socket.getSoLinger());
    }
",non-flaky,5
60946,apache_druid,RowBucketIterableTest.testMissingDaysAtBegining,"  @Test
  public void testMissingDaysAtBegining()
  {
    List<Row> expectedDay1 = Collections.emptyList();
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_2);

    rows = new ArrayList<>();
    rows.add(JAN_2_M_10);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(JAN_1, actual.getDateTime());
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_2, actual.getDateTime());
    Assert.assertEquals(expectedDay2, actual.getRows());
  }
",non-flaky,5
96918,apache_avro,TestAvroOutputFormat.testSnappyCodecUsingAvroCodec,"  @Test
  public void testSnappyCodecUsingAvroCodec() {
    CodecFactory avroSnappyCodec = CodecFactory.fromString(""snappy"");

    JobConf job = new JobConf();
    job.set(""mapred.output.compress"", ""true"");
    job.set(AvroJob.OUTPUT_CODEC, ""snappy"");
    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
    assertNotNull(factory);
    assertEquals(factory.getClass(), avroSnappyCodec.getClass());
  }
",non-flaky,5
134029,CorfuDB_CorfuDB,OrchestratorTest.testRemoveNodeRequestWithExisting,"    @Test
    public void testRemoveNodeRequestWithExisting() {
        sendAndValidateWorkflowDispatch(getRemoveNodeRequestMsg(ENDPOINT_1), WORKFLOW_ID_1);

        // Verify that no new workflow is run.
        verify(orchestrator, never()).run(any(IWorkflow.class), anyInt());
    }
",non-flaky,5
99725,apache_cassandra,FQLReplayTest.testStoringResults,"    @Test
    public void testStoringResults() throws Throwable
    {
        File tmpDir = Files.createTempDirectory(""results"").toFile();
        File queryDir = Files.createTempDirectory(""queries"").toFile();

        ResultHandler.ComparableResultSet res = createResultSet(10, 10, true);
        ResultStore rs = new ResultStore(Collections.singletonList(tmpDir), queryDir);
        FQLQuery query = new FQLQuery.Single(""abc"", QueryOptions.DEFAULT.getProtocolVersion().asInt(), QueryOptions.DEFAULT, 12345, 11111, 22, ""select * from abc"", Collections.emptyList());
        try
        {
            rs.storeColumnDefinitions(query, Collections.singletonList(res.getColumnDefinitions()));
            Iterator<ResultHandler.ComparableRow> it = res.iterator();
            while (it.hasNext())
            {
                List<ResultHandler.ComparableRow> row = Collections.singletonList(it.next());
                rs.storeRows(row);
            }
            // this marks the end of the result set:
            rs.storeRows(Collections.singletonList(null));
        }
        finally
        {
            rs.close();
        }

        compareResults(Collections.singletonList(Pair.create(query, res)),
                       readResultFile(tmpDir, queryDir));

    }
",non-flaky,5
176885,OryxProject_oryx,ConfigUtilsTest.testOptionalString,"  @Test
  public void testOptionalString() {
    assertNull(ConfigUtils.getOptionalString(ConfigUtils.getDefault(), ""nonexistent""));
  }
",non-flaky,5
176858,OryxProject_oryx,LoggingTest.doCall,"  @Test(expected = IllegalStateException.class)
  public void testLoggingVoidCallableException() {
    new LoggingVoidCallable() {
      @Override
      public void doCall() throws IOException {
        throw buildIOE();
      }
",non-flaky,5
20982,NationalSecurityAgency_timely,MetricsResponseTest.testGenerateHtml,"    @Test
    public void testGenerateHtml() throws Exception {
        Configuration cfg = TestConfiguration.createMinimalConfigurationForTest();
        MetaCache cache = MetaCacheFactory.getCache(cfg);
        cache.add(new Meta(""sys.cpu.user"", ""host"", ""localhost""));
        cache.add(new Meta(""sys.cpu.user"", ""instance"", ""0""));
        cache.add(new Meta(""sys.cpu.idle"", ""host"", ""localhost""));
        cache.add(new Meta(""sys.cpu.idle"", ""instance"", ""0""));
        TestMetricsResponse r = new TestMetricsResponse(cfg);
        String html = r.generateHtml().toString();
        Assert.assertTrue(html.contains(""<td>sys.cpu.idle</td>""));
        Assert.assertTrue(html.contains(""<td>host=localhost instance=0 </td>""));
        Assert.assertTrue(html.contains(""<td>sys.cpu.user</td>""));
        Assert.assertTrue(html.contains(""<td>host=localhost instance=0 </td>""));
    }
",non-flaky,5
30967,camunda-cloud_zeebe,POJOArrayTest.shouldDeserializePOJOWithDefaultValues,"  @Test
  public void shouldDeserializePOJOWithDefaultValues() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    // when
    pojo.wrap(buffer);

    // then
    final Iterator<MinimalPOJO> iterator1 = pojo.simpleArray().iterator();
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(123L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(456L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(789L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(555L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(777L);
    assertThat(iterator1.hasNext()).isFalse();
  }
",non-flaky,5
114044,aws_aws-sdk-java-v2,AsyncUpdateItemWithResponseIntegrationTest.updateItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull,"    @Test
    public void updateItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull() {
        Record record = new Record().setId(1).setId2(10);
        UpdateItemEnhancedRequest<Record> request = UpdateItemEnhancedRequest.builder(Record.class)
                                                                          .item(record)
                                                                          .build();

        UpdateItemEnhancedResponse<Record> response = mappedTable.updateItemWithResponse(request).join();

        assertThat(response.itemCollectionMetrics()).isNull();
    }
",non-flaky,5
38684,apache_pulsar,RandomExponentialRetryTests.callWithSomeRetries,"    @Test
    public void callWithSomeRetries() throws Exception {
        int N = 10;
        MockTime mockTime = new MockTime();
        RandomExponentialRetry backoffRetry = new RandomExponentialRetry();
        assertEquals(N, (int)backoffRetry.retry( () -> testFunction(N), N+1, 100, ""SomeRetries"", mockTime));
        assertEquals(N, mockTime.sleeps.size());
        for(int i = 0; i < N; i++) {
            assertTrue(mockTime.sleeps.get(i) <=  backoffRetry.waitInMs(i, 100));
        }
        System.out.println(""sleeps=""+mockTime.sleeps);
    }
",non-flaky,5
160380,ConsenSys_teku,SignedBlockTest.shouldDeserialize,"  @Test
  public void shouldDeserialize() throws JsonProcessingException {
    final SignedBlock signedBlock = jsonProvider.jsonToObject(jsonData, SignedBlock.class);
    assertThat(signedBlock.slot).isEqualTo(slot);
    assertThat(signedBlock.signingRoot).isEqualTo(signingRoot);
  }
",non-flaky,5
156077,jReddit_jReddit,RedditScopeBuilderTest.testAddRemoveMultiple,"    @Test
    public void testAddRemoveMultiple() {
        builder.addScopes(RedditScope.EDIT, RedditScope.MODPOSTS);
        builder.removeScopes(RedditScope.EDIT, RedditScope.MODPOSTS, RedditScope.MODCONFIG);
        assertEquals("""", builder.build());
    }
",non-flaky,5
110852,pushtorefresh_storio,QueryTest.queryLimitOffset,"    @Test
    public void queryLimitOffset() {
        final List<User> users = putUsersBlocking(10);

        final int offset = 5;
        final int limit = 3;
        final List<User> usersFromQuery = storIOSQLite
                .get()
                .listOfObjects(User.class)
                .withQuery(Query.builder()
                        .table(UserTableMeta.TABLE)
                        .orderBy(UserTableMeta.COLUMN_EMAIL)
                        .limit(offset + "", "" + limit)
                        .build())
                .prepare()
                .executeAsBlocking();

        assertThat(usersFromQuery).isNotNull();
        assertThat(usersFromQuery).hasSize(Math.min(limit, users.size() - offset));

        Collections.sort(users);

        int position = 0;
        for (int i = offset; i < offset + limit; i++) {
            assertThat(usersFromQuery.get(position++)).isEqualTo(users.get(i));
        }
    }
",non-flaky,5
110136,Wikidata_wikidata-toolkit,ClientConfigurationTest.testOfflineModeArgumentsLong,"	@Test
	public void testOfflineModeArgumentsLong() {
		String[] args = new String[] { ""--offline"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertTrue(config.getOfflineMode());
	}
",non-flaky,5
35712,cdapio_cdap,TestDistributedLogReader.testDistributedLogPrevBoth,"  @Test
  public void testDistributedLogPrevBoth() throws Exception {
    ReadRange readRange = new ReadRange(0, Long.MAX_VALUE, LogOffset.INVALID_KAFKA_OFFSET);
    testDistributedLogPrev(readRange, LOGGING_CONTEXT_BOTH, 16, 4, ""TestDistributedLogReader Log message1 "", 60);

    readRange = new ReadRange(System.currentTimeMillis() - TimeUnit.DAYS.toMillis(1),
                                        System.currentTimeMillis(), LogOffset.INVALID_KAFKA_OFFSET);
    testDistributedLogPrev(readRange, LOGGING_CONTEXT_BOTH, 16, 4, ""TestDistributedLogReader Log message1 "", 60);

    testDistributedLogPrev(ReadRange.LATEST, LOGGING_CONTEXT_BOTH, 9, 8, ""TestDistributedLogReader Log message1 "", 60);
  }
",non-flaky,5
98214,apache_jackrabbit,ConnectionOptionsTest.testBuilder,"    @Test
    public void testBuilder() {
        ConnectionOptions.Builder builder = ConnectionOptions.builder();
        builder.allowSelfSignedCertificates(true);
        builder.disableHostnameVerification(false);
        builder.maxConnections(10);
        builder.connectionTimeoutMs(100);
        builder.requestTimeoutMs(200);
        builder.socketTimeoutMs(300);
        builder.proxyHost(""proxyHost"");
        builder.proxyPort(1234);
        builder.proxyUsername(""proxyUser"");
        builder.proxyPassword(""proxyPassword"");
        builder.proxyProtocol(""https:"");
        ConnectionOptions options = builder.build();
        Assert.assertEquals(true, options.isAllowSelfSignedCertificates());
        Assert.assertEquals(false, options.isDisableHostnameVerification());
        Assert.assertEquals(10, options.getMaxConnections());
        Assert.assertEquals(100, options.getConnectionTimeoutMs());
        Assert.assertEquals(200, options.getRequestTimeoutMs());
        Assert.assertEquals(300, options.getSocketTimeoutMs());
        Assert.assertEquals(""proxyHost"", options.getProxyHost());
        Assert.assertEquals(1234, options.getProxyPort());
        Assert.assertEquals(""proxyUser"", options.getProxyUsername());
        Assert.assertEquals(""proxyPassword"", options.getProxyPassword());
        Assert.assertEquals(""https:"", options.getProxyProtocol());
    }
",non-flaky,5
159644,liquibase_liquibase,AbstractIntegrationTest.testUpdateClearUpdate,"    @Test
    public void testUpdateClearUpdate() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(completeChangeLog);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);
        clearDatabase();

        liquibase = createLiquibase(completeChangeLog);
        liquibase.setChangeLogParameter( ""loginuser"", getUsername());
        liquibase.update(this.contexts);
    }
",non-flaky,5
133931,CorfuDB_CorfuDB,LayoutHandlerTest.testMalformedGetLayout,"    @Test
    public void testMalformedGetLayout() throws IOException {
        Layout defaultLayout = getDefaultLayout();
        defaultLayout.setLayoutServers(new LinkedList<>());

        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getLayoutResponseMsg(defaultLayout)
        );

        layoutHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the request was completed exceptionally with the expected exception type.
        verify(mockClientRouter).completeExceptionally(anyLong(), any(SerializerException.class));
    }
",non-flaky,5
97951,ReactiveX_RxJava,CovarianceTest.testCovarianceOfFrom,"    @Test
    public void testCovarianceOfFrom() {
        Observable.<Movie> from(new HorrorMovie());
        Observable.<Movie> from(new ArrayList<HorrorMovie>());
        // Observable.<HorrorMovie>from(new Movie()); // may not compile
    }
",non-flaky,5
77106,networknt_json-schema-validator,Issue406Test.testPreloadingNotHappening,"    @Test
    public void testPreloadingNotHappening() {
        final JsonSchemaFactory factory = JsonSchemaFactory.getInstance(SpecVersion.VersionFlag.V7);
        final JsonSchema schema = factory.getSchema(INVALID_$REF_SCHEMA);
        // not breaking - pass
        Assertions.assertNotNull(schema);
    }
",non-flaky,5
99727,apache_cassandra,FQLReplayTest.testCompareEqualRows,"    @Test
    public void testCompareEqualRows()
    {
        ResultComparator rc = new ResultComparator();

        ResultHandler.ComparableResultSet res = createResultSet(10, 10, false);
        ResultHandler.ComparableResultSet res2 = createResultSet(10, 10, false);
        List<ResultHandler.ComparableResultSet> toCompare = Lists.newArrayList(res, res2);
        List<Iterator<ResultHandler.ComparableRow>> iters = toCompare.stream().map(Iterable::iterator).collect(Collectors.toList());

        while (true)
        {
            List<ResultHandler.ComparableRow> rows = ResultHandler.rows(iters);
            assertTrue(rc.compareRows(Lists.newArrayList(""eq1"", ""eq2""), null, rows));
            if (rows.stream().allMatch(Objects::isNull))
                break;
        }
    }
",non-flaky,5
136479,doanduyhai_Achilles,TestEntityWithDSESearch.should_search_date_gt_and_lte,"    @Test
    public void should_search_date_gt_and_lte() throws Exception {
        //Given
        final Date searchedDate1 = toDate(""2016-09-25 13:00:00.000Z"");
        final Date searchedDate2 = toDate(""2016-09-26 09:00:00.000Z"");

        //When
        final List<EntityWithDSESearch> actual = manager
                .indexed()
                .select()
                .allColumns_FromBaseTable()
                .where()
                .date().Gt_And_Lte(searchedDate1, searchedDate2)
                .getList();

        //Then
        assertThat(actual).hasSize(2);
        assertThat(actual.stream()
                .map(EntityWithDSESearch::getDate)
                .map(this::toString)
                .collect(toList()))
                .contains(""2016-09-26 08:00:00.000Z"", ""2016-09-26 09:00:00.000Z"");
    }
",non-flaky,5
89353,apache_samza,TestKafkaCheckpointLogKeySerde.testBinaryCompatibility,"  @Test
  public void testBinaryCompatibility() {
    KafkaCheckpointLogKey logKey1 = new KafkaCheckpointLogKey(KafkaCheckpointLogKey.CHECKPOINT_V1_KEY_TYPE,
        new TaskName(""Partition 0""), GroupByPartitionFactory.class.getCanonicalName());
    KafkaCheckpointLogKeySerde checkpointSerde = new KafkaCheckpointLogKeySerde();

    byte[] bytes = (""{\""systemstreampartition-grouper-factory\"""" +
        "":\""org.apache.samza.container.grouper.stream.GroupByPartitionFactory\"",\""taskName\"":\""Partition 0\"","" +
        ""\""type\"":\""checkpoint\""}"").getBytes();

    // test that the checkpoints returned by the Serde are byte-wise identical to an actual checkpoint in Kafka
    Assert.assertEquals(true, Arrays.equals(bytes, checkpointSerde.toBytes(logKey1)));
  }
",non-flaky,5
170492,eclipse_jetty.project,ConnectorServerTest.testLocalhostRMIBindsToLoopback,"    @Test
    public void testLocalhostRMIBindsToLoopback() throws Exception
    {
        connectorServer = new ConnectorServer(new JMXServiceURL(""service:jmx:rmi://localhost/jndi/rmi://localhost:1099/jmxrmi""), objectName);
        connectorServer.start();
        JMXServiceURL address = connectorServer.getAddress();

        InetAddress localHost = InetAddress.getLocalHost();
        if (!localHost.isLoopbackAddress())
        {
            assertThrows(ConnectException.class, () ->
            {
                // Verify that I cannot connect to the RMIRegistry using a non-loopback address.
                new Socket(localHost, address.getPort());
            });
        }

        InetAddress loopback = InetAddress.getLoopbackAddress();
        new Socket(loopback, address.getPort()).close();
    }
",non-flaky,5
20950,NationalSecurityAgency_timely,RateIteratorTest.testCounterRateWithMax,"    @Test
    public void testCounterRateWithMax() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        for (int j = 0; j < 10; j++) {
            for (int i = 0; i < 10; i++) {
                ts += 1000;
                Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags);
                byte[] row = MetricAdapter.encodeRowKey(m);
                Key k = new Key(row, tags.get(0).join().getBytes(StandardCharsets.UTF_8),
                        MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
                table.put(k, v);
            }
        }

        SortedMapIterator source = new SortedMapIterator(table);
        RateIterator iter = new RateIterator();
        IteratorSetting settings = new IteratorSetting(100, RateIterator.class);

        QueryRequest.RateOption option = new QueryRequest.RateOption();
        option.setCounter(true);
        option.setCounterMax(10);
        RateIterator.setRateOptions(settings, option);

        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);
        for (int i = 0; i < 99; i++) {
            assertTrue(iter.hasTop());
            assertEquals(0.001D, MetricAdapter.decodeValue(iter.getTopValue().get()), 0.0D);
            iter.next();
        }
        assertFalse(iter.hasTop());
    }
",non-flaky,5
88774,apache_ignite,JavaIgniteDataFrameSelfTest.testDataFrameWriteExample,"    @Test
    public void testDataFrameWriteExample() throws Exception {
        JavaIgniteDataFrameWriteExample.main(EMPTY_ARGS);
    }
",non-flaky,5
92702,apache_dubbo,MethodConfigTest.testArguments,"    @Test
    public void testArguments() throws Exception {
        MethodConfig method = new MethodConfig();
        ArgumentConfig argument = new ArgumentConfig();
        method.setArguments(Collections.singletonList(argument));
        assertThat(method.getArguments(), contains(argument));
        assertThat(method.getArguments(), Matchers.<org.apache.dubbo.config.ArgumentConfig>hasSize(1));
    }
",non-flaky,5
92710,apache_dubbo,MethodConfigTest.testReturn,"    @Test
    public void testReturn() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setReturn(true);
        assertThat(method.isReturn(), is(true));
    }
",non-flaky,5
33693,alibaba_fastjson,JSONScannerTest.checkDate16,"  @Test
  public void checkDate16() throws Throwable {

    // Arrange
    char y0 = '2';
    char y1 = '1';
    char y2 = '0';
    char y3 = '\u0830';
    char M0 = '1';
    char M1 = '\u0000';
    int d0 = 0;
    int d1 = 0;

    // Act
    Class<?> c = Reflector.forName(""com.alibaba.fastjson.parser.JSONScanner"");
    Method m = c.getDeclaredMethod(""checkDate"", Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""int""), Reflector.forName(""int""));
    m.setAccessible(true);
    boolean retval = (Boolean)m.invoke(null, y0, y1, y2, y3, M0, M1, d0, d1);

    // Assert result
    Assert.assertEquals(false, retval);

  }
",non-flaky,5
43101,trinodb_trino,AbstractTestIntegrationSmokeTest.testExplainAnalyze,"    @Test
    public void testExplainAnalyze()
    {
        assertExplainAnalyze(""EXPLAIN ANALYZE SELECT * FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SELECT count(*), clerk FROM orders GROUP BY clerk"");
        assertExplainAnalyze(
                ""EXPLAIN ANALYZE SELECT x + y FROM ("" +
                        ""   SELECT orderdate, COUNT(*) x FROM orders GROUP BY orderdate) a JOIN ("" +
                        ""   SELECT orderdate, COUNT(*) y FROM orders GROUP BY orderdate) b ON a.orderdate = b.orderdate"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SELECT count(*), clerk FROM orders GROUP BY clerk UNION ALL SELECT sum(orderkey), clerk FROM orders GROUP BY clerk"");

        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW COLUMNS FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE EXPLAIN SELECT count(*) FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE EXPLAIN ANALYZE SELECT count(*) FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW FUNCTIONS"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW TABLES"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW SCHEMAS"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW CATALOGS"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW SESSION"");
    }
",non-flaky,5
78276,apache_beam,StateTagTest.testValueEquality,"  @Test
  public void testValueEquality() {
    StateTag<?> fooVarInt1 = StateTags.value(""foo"", VarIntCoder.of());
    StateTag<?> fooVarInt2 = StateTags.value(""foo"", VarIntCoder.of());
    StateTag<?> fooBigEndian = StateTags.value(""foo"", BigEndianIntegerCoder.of());
    StateTag<?> barVarInt = StateTags.value(""bar"", VarIntCoder.of());

    assertEquals(fooVarInt1, fooVarInt2);
    assertNotEquals(fooVarInt1, fooBigEndian);
    assertNotEquals(fooVarInt1, barVarInt);
  }
",non-flaky,5
89334,apache_samza,TestKafkaSystemAdminJava.testValidateStreamDoesNotExist,"  @Test(expected = StreamValidationException.class)
  public void testValidateStreamDoesNotExist() {

    StreamSpec spec = new StreamSpec(""testId"", ""testStreamNameExist"", ""testSystem"", 8);

    systemAdmin().validateStream(spec);
  }
",non-flaky,5
104155,spring-cloud_spring-cloud-config,EncryptionControllerTests.formDataInWithPrefix,"	@Test
	public void formDataInWithPrefix() {
		this.controller = new EncryptionController(
				new SingleTextEncryptorLocator(new RsaSecretEncryptor()));
		// Add space to input
		String cipher = this.controller.encrypt(""{key:test}foo bar="",
				MediaType.APPLICATION_FORM_URLENCODED);
		String decrypt = this.controller.decrypt(cipher + ""="",
				MediaType.APPLICATION_FORM_URLENCODED);
		assertThat(decrypt).as(""Wrong decrypted plaintext: "" + decrypt)
				.isEqualTo(""foo bar"");
	}
",non-flaky,5
170528,eclipse_jetty.project,TestSecurityAnnotationConversions.testDenyAllOnClass,"    @Test
    public void testDenyAllOnClass() throws Exception
    {

        WebAppContext wac = makeWebAppContext(DenyServlet.class.getCanonicalName(), ""denyServlet"", new String[]{
            ""/foo/*"", ""*.foo""
        });

        //Assume we found 1 servlet with a @HttpConstraint with value=EmptyRoleSemantic.DENY security annotation
        ServletSecurityAnnotationHandler annotationHandler = new ServletSecurityAnnotationHandler(wac);
        AnnotationIntrospector introspector = new AnnotationIntrospector(wac);
        introspector.registerHandler(annotationHandler);

        //set up the expected outcomes:
        //1 ConstraintMapping per ServletMapping pathSpec
        Constraint expectedConstraint = new Constraint();
        expectedConstraint.setAuthenticate(true);
        expectedConstraint.setDataConstraint(Constraint.DC_NONE);

        ConstraintMapping[] expectedMappings = new ConstraintMapping[2];

        expectedMappings[0] = new ConstraintMapping();
        expectedMappings[0].setConstraint(expectedConstraint);
        expectedMappings[0].setPathSpec(""/foo/*"");

        expectedMappings[1] = new ConstraintMapping();
        expectedMappings[1].setConstraint(expectedConstraint);
        expectedMappings[1].setPathSpec(""*.foo"");

        introspector.introspect(new DenyServlet(), null);

        compareResults(expectedMappings, ((ConstraintAware)wac.getSecurityHandler()).getConstraintMappings());
    }
",non-flaky,5
26172,Ericsson_ecchronos,TestRepairManagementRESTImpl.testTableConfigNonExisting,"    @Test
    public void testTableConfigNonExisting()
    {
        RepairConfiguration repairConfig = TestUtils.createRepairConfiguration(11, 2.2, 33, 44);
        RepairJobView repairJobView = new ScheduledRepairJobView(UUID.randomUUID(), myTableReferenceFactory.forTable(""ks"", ""tbl""), repairConfig, null, Status.IN_QUEUE, 0);

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.singletonList(repairJobView));

        Map<Object, Object> response = GSON.fromJson(repairManagementREST.tableConfig(""nonexisting"", ""tbl""), new TypeToken<Map<Object, Object>>(){}.getType());

        assertThat(response).isEmpty();
    }
",non-flaky,5
160369,ConsenSys_teku,SignedAttestationTest.shouldCreate,"  @Test
  public void shouldCreate() {
    final SignedAttestation signedAttestation = new SignedAttestation(source, target, signingRoot);
    assertThat(signedAttestation.sourceEpoch).isEqualTo(source);
    assertThat(signedAttestation.targetEpoch).isEqualTo(target);
    assertThat(signedAttestation.signingRoot).isEqualTo(signingRoot);
  }
",non-flaky,5
38212,palantir_atlasdb,RocksDbKeyValueServiceTest.testDoubleWriteToTransactionTable,"    @Test
    public void testDoubleWriteToTransactionTable() {
        db.createTable(TRANSACTION_TABLE, AtlasDbConstants.EMPTY_TABLE_METADATA);
        final Cell cell = Cell.create(""r1"".getBytes(), COMMIT_TS_COLUMN);
        db.putUnlessExists(TRANSACTION_TABLE, ImmutableMap.of(cell, ""v1"".getBytes()));
        try {
            db.putUnlessExists(TRANSACTION_TABLE, ImmutableMap.of(cell, ""v2"".getBytes()));
            fail();
        } catch (KeyAlreadyExistsException e) {
            // expected
        }
        final Map<Cell, Value> res = db.get(TRANSACTION_TABLE, ImmutableMap.of(cell, 1L));
        final Value value = res.get(cell);
        assertEquals(0L, value.getTimestamp());
        assertEquals(""v1"", new String(value.getContents()));
    }
",non-flaky,5
99708,apache_cassandra,MultiResultLoggerTest.delegatesToInitialPrintStream,"    @Test
    public void delegatesToInitialPrintStream() throws Exception
    {
        ByteArrayOutputStream output = new ByteArrayOutputStream();
        PrintStream printStream = new PrintStream(output, true);
        MultiResultLogger underTest = new MultiResultLogger(printStream);

        underTest.println(""Very important result"");

        assertEquals(""Very important result\n"", output.toString());
    }
",non-flaky,5
21165,swankjesse_dex,OldClassTest.getLocalClass,"    @TestAnnotation(""libcore.java.lang.OldClassTest$PublicTestClass"")
        public Object getLocalClass() {
            class LocalClass {}
            Object returnedObject = new LocalClass();
            return returnedObject;
        }
",non-flaky,5
177216,line_armeria,AbstractStreamDecoderTest.notEmpty,"    @Test
    public void notEmpty() {
        final StreamDecoder decoder = newDecoder();
        final ByteBuf buf = ByteBufAllocator.DEFAULT.buffer();
        buf.writeBytes(PAYLOAD);
        final HttpData data = decoder.decode(HttpData.wrap(buf));
        assertThat(buf.refCnt()).isZero();
        assertThat(data.byteBuf().refCnt()).isOne();
        data.close();
    }
",non-flaky,5
110929,pushtorefresh_storio,InsertQueryTest.createdThroughToBuilderQueryShouldBeEqual,"    @Test
    public void createdThroughToBuilderQueryShouldBeEqual() {
        final String table = ""test_table"";
        final String nullColumnHack = ""test_null_column_hack"";
        final String tag = ""test_tag"";

        final InsertQuery firstQuery = InsertQuery.builder()
                .table(table)
                .nullColumnHack(nullColumnHack)
                .affectsTags(tag)
                .build();

        final InsertQuery secondQuery = firstQuery.toBuilder().build();

        assertThat(secondQuery).isEqualTo(firstQuery);
    }
",non-flaky,5
136557,doanduyhai_Achilles,UDTMetaCodeGenTest.should_generate_udt_property_class,"    @Test
    public void should_generate_udt_property_class() throws Exception {
        setExec(aptUtils -> {
            final String className = TestUDT.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final UDTMetaCodeGen builder = new UDTMetaCodeGen(aptUtils);

            final GlobalParsingContext globalContext = GlobalParsingContext.defaultContext();
            final EntityParsingContext context = new EntityParsingContext(typeElement,
                    ClassName.get(TestUDT.class), new LowerCaseNaming(), globalContext);
            final List<FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, globalContext);

            final TypeSpec typeSpec = builder.buildUDTClassProperty(typeElement, context, parsingResults, Collections.emptyList());

            assertThat(typeSpec.toString().trim()).isEqualTo(
                    readCodeBlockFromFile(""expected_code/udt_meta_builder/should_generate_udt_property_class.txt""));

        });
        launchTest(TestUDT.class);
    }
",non-flaky,5
98413,ONSdigital_rm-collection-exercise-service,NudgeEmailValidatorTest.testCantUpdateNudgeThatHasPastAndCollectionExerciseInLockedState,"  @Test
  public void testCantUpdateNudgeThatHasPastAndCollectionExerciseInLockedState() {
    final Event nudge = new Event();
    nudge.setTag((EventService.Tag.nudge_email_0.toString()));
    nudge.setTimestamp(Timestamp.from(Instant.now().minus(2, ChronoUnit.DAYS)));

    final Event newNudge = new Event();
    newNudge.setTag((EventService.Tag.nudge_email_0.toString()));
    newNudge.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));

    final List<Event> events = Collections.singletonList(nudge);
    CTPException actualException = null;
    try {
      nudgeEmailValidator.validate(
          events, newNudge, CollectionExerciseDTO.CollectionExerciseState.LIVE);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(""Nudge email cannot be set in the past"", actualException.getMessage());
  }
",non-flaky,5
113904,spring-projects_spring-data-couchbase,CouchbaseTemplateQueryCollectionIntegrationTests.findByAnalytics,"	@Test
	public void findByAnalytics() { // 2
		AnalyticsOptions options = AnalyticsOptions.analyticsOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.one(vie);
		try {
			List<Airport> found = couchbaseTemplate.findByAnalytics(Airport.class).inScope(scopeName)
					.inCollection(collectionName).withOptions(options).all();
			assertEquals(saved, found);
		} finally {
			couchbaseTemplate.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId());
		}
	}
",non-flaky,5
13919,neo4j_neo4j,QuorumWritesIT.testInstanceCanBeReplacedToReestablishQuorum,"    @Test
    public void testInstanceCanBeReplacedToReestablishQuorum() throws Throwable
    {
        File root = TargetDirectory.forTest( getClass() ).cleanDirectory(
                ""testInstanceCanBeReplacedToReestablishQuorum""
        );
        ClusterManager clusterManager = new ClusterManager( clusterOfSize( 3 ), root,
                MapUtil.stringMap( HaSettings.tx_push_factor.name(), ""2"", HaSettings.state_switch_timeout.name(), ""5s"" ) );
        clusterManager.start();
        ClusterManager.ManagedCluster cluster = clusterManager.getDefaultCluster();

        HighlyAvailableGraphDatabase master = cluster.getMaster();

        cluster.await( ClusterManager.masterSeesAllSlavesAsAvailable() );

        doTx( master );

        final CountDownLatch latch1 = new CountDownLatch( 1 );
        waitOnHeartbeatFail( master, latch1 );

        HighlyAvailableGraphDatabase slave1 = cluster.getAnySlave();
        cluster.fail( slave1 );

        latch1.await();
        slave1.shutdown();

        doTx( master );

        final CountDownLatch latch2 = new CountDownLatch( 1 );
        waitOnHeartbeatFail( master, latch2 );

        HighlyAvailableGraphDatabase slave2 = cluster.getAnySlave( slave1 );
        cluster.fail( slave2 );

        latch2.await();

        // The master should stop saying that it's master
        assertFalse( master.isMaster() );

        try
        {
            doTx( master );
            fail( ""After both slaves fail txs should not go through"" );
        }
        catch ( TransactionFailureException e )
        {
            assertEquals( ""Timeout waiting for cluster to elect master"", e.getMessage() );
        }

        // This is not a hack, this simulates a period of inactivity in the cluster.
        Thread.sleep( 120000 ); // TODO Define ""inactivity"" and await that condition instead of 120 seconds.

        final CountDownLatch latch3 = new CountDownLatch( 1 );
        final CountDownLatch latch4 = new CountDownLatch( 1 );
        final CountDownLatch latch5 = new CountDownLatch( 1 );
        waitOnHeartbeatAlive( master, latch3 );
        waitOnRoleIsAvailable( master, latch4, HighAvailabilityModeSwitcher.MASTER );
        waitOnRoleIsAvailable( master, latch5, HighAvailabilityModeSwitcher.SLAVE );

        HighlyAvailableGraphDatabase replacement =
                (HighlyAvailableGraphDatabase) new TestHighlyAvailableGraphDatabaseFactory().
                newHighlyAvailableDatabaseBuilder( new File( root, ""replacement"" ).getAbsolutePath() ).
                setConfig( ClusterSettings.cluster_server, "":5010"" ).
                setConfig( HaSettings.ha_server, "":6010"" ).
                setConfig( ClusterSettings.server_id, ""3"" ).
                setConfig( ClusterSettings.initial_hosts, cluster.getInitialHostsConfigString() ).
                setConfig( HaSettings.tx_push_factor, ""0"" ).
                newGraphDatabase();

        latch3.await();
        latch4.await();
        latch5.await();

        assertTrue( master.isMaster() );
        assertFalse( replacement.isMaster() );

        Node finalNode = doTx( master );

        Transaction transaction = replacement.beginTx();
        try
        {
            replacement.getNodeById( finalNode.getId() );
        }
        finally
        {
            transaction.finish();
        }

        clusterManager.stop();
        replacement.shutdown();
    }
",non-flaky,5
112084,apache_shardingsphere-elasticjob,JobShardingStrategyFactoryTest.assertGetStrategyFailureWhenNotStrategyClass,"    @Test(expected = JobConfigurationException.class)
    public void assertGetStrategyFailureWhenNotStrategyClass() {
        JobShardingStrategyFactory.getStrategy(Object.class.getName());
    }
",non-flaky,5
98663,nutzam_nutz,BaseTest.test_param,"    @Test
    public void test_param() {
        get(""/common/param?id="" + Long.MAX_VALUE);
        assertEquals("""" + Long.MAX_VALUE, resp.getContent());
    }
",non-flaky,5
33745,alibaba_fastjson,FastJsonHttpMessageConverterTest.test6,"    @Test
    public void test6() throws Exception {

        mockMvc.perform(
                (post(""/fastjson/test6"").characterEncoding(""UTF-8"")
                        .param(""userId"", ""1234"")
                        .param(""flag"", ""0"")
                        .contentType(MediaType.APPLICATION_FORM_URLENCODED)))
                .andDo(print());
    }
",non-flaky,5
60927,apache_druid,LongMeanAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new LongMeanAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(LongMeanAverager.class));
  }
",non-flaky,5
98073,vert-x3_vertx-mongo-client,WriteConcernParserTest.testNoWriteConcern,"  @Test
  public void testNoWriteConcern() {
    WriteConcern wc = new WriteConcernParser(null, new JsonObject()).writeConcern();
    assertNull(wc);
  }
",non-flaky,5
177219,line_armeria,FileWatcherRunnableTest.testPropertyFileWatcherRunnableExitsOnInterrupt,"    @Test
    public void testPropertyFileWatcherRunnableExitsOnInterrupt() throws InterruptedException {
        final WatchService watchService = mock(WatchService.class);
        final FileWatcherRunnable fileWatcherRunnable = new FileWatcherRunnable(watchService, mock(
                FileSystemWatchContext.class));
        when(watchService.take()).then(invocation -> {
            while (!Thread.currentThread().isInterrupted()) {
                Thread.yield();
            }
            return null;
        });
        final Thread thread = new Thread(fileWatcherRunnable);
        thread.start();
        thread.interrupt();
        await().untilAsserted(() -> assertThat(thread.isAlive()).isFalse());
    }
",non-flaky,5
98601,nutzam_nutz,El2Test.lssue_486,"    @Test
    public void lssue_486() {
        assertEquals(2 + (-3), El.eval(""2+(-3)""));
        assertEquals(2 + -3, El.eval(""2+-3""));
        assertEquals(2 * -3, El.eval(""2*-3""));
        assertEquals(-2 * -3, El.eval(""-2*-3""));
        assertEquals(2 / -3, El.eval(""2/-3""));
        assertEquals(2 % -3, El.eval(""2%-3""));
    }
",non-flaky,5
99,stanfordnlp_CoreNLP,DirectedMultiGraphTest.testConnectedComponents,"@Test
public void testConnectedComponents() {
    System.out.println(""graph is "" + graph.toString());
    List<Set<Integer>> ccs = graph.getConnectedComponents();
    for (Set<Integer> cc : ccs) {
        System.out.println(""Connected component: "" + cc);
    }
    assertEquals(ccs.size(), 4);
    assertEquals(CollectionUtils.sorted(ccs.get(0)), Arrays.asList(1, 2, 3, 4));
}",unordered collections,3
135737,Netflix_Hystrix,HystrixCommandTestWithCustomConcurrencyStrategy.testCommandDoesNotRequireContextConcurrencyStrategyProvidesItContextLeftUninitialized,"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyProvidesItContextLeftUninitialized() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(true);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is not set up
        HystrixRequestContext.setContextOnCurrentThread(null);
        HystrixCommand<Boolean> cmd = new TestCommand(false, false);
        assertTrue(cmd.execute()); //command execution not affected by missing context
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
    }
",non-flaky,5
59652,looly_hutool,TemplateUtilTest.renderToFileTest,"	@Test
	public void renderToFileTest() {
		TemplateEngine engine = new BeetlEngine(new TemplateConfig(""templates"", ResourceMode.CLASSPATH));
		Template template = engine.getTemplate(""freemarker_test.ftl"");

		final Map<String, Object> bindingMap = new HashMap<>();
		bindingMap.put(""name"", ""aa"");
		File outputFile = new File(""e:/test.txt"");
		template.render(bindingMap, outputFile);
	}
",non-flaky,5
89331,apache_samza,TestKafkaSystemAdminJava.testCreateChangelogStreamHelp,"  @Test
  public void testCreateChangelogStreamHelp() {
    testCreateChangelogStreamHelp(""testChangeLogStream"");
  }
",non-flaky,5
98102,vert-x3_vertx-mongo-client,SocketSettingsParserTest.testSocketSettings,"  @Test
  public void testSocketSettings() {
    int connectTimeoutMS = Math.abs(TestUtils.randomInt());
    int socketTimeoutMS = Math.abs(TestUtils.randomInt());
    int receiveBufferSize = Math.abs(TestUtils.randomInt());
    int sendBufferSize = Math.abs(TestUtils.randomInt());

    JsonObject config = new JsonObject();
    config.put(""connectTimeoutMS"", connectTimeoutMS);
    config.put(""socketTimeoutMS"", socketTimeoutMS);
    config.put(""receiveBufferSize"", receiveBufferSize);
    config.put(""sendBufferSize"", sendBufferSize);

    SocketSettings settings = new SocketSettingsParser(null, config).settings();
    assertEquals(connectTimeoutMS, settings.getConnectTimeout(TimeUnit.MILLISECONDS));
    assertEquals(socketTimeoutMS, settings.getReadTimeout(TimeUnit.MILLISECONDS));
    assertEquals(receiveBufferSize, settings.getReceiveBufferSize());
    assertEquals(sendBufferSize, settings.getSendBufferSize());
  }
",non-flaky,5
92694,apache_dubbo,ProviderConfigTest.testNetworker,"    @Test
    public void testNetworker() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setNetworker(""networker"");
        assertThat(provider.getNetworker(), equalTo(""networker""));
    }
",non-flaky,5
59578,looly_hutool,CronTest.cronTest,"	@Test
	public void cronTest() {
		// æ¯æç§çº§å«å®æ¶ä»»å¡
		CronUtil.setMatchSecond(true);
		CronUtil.getScheduler().setDaemon(false);
		CronUtil.start();

		ThreadUtil.waitForDie();
		CronUtil.stop();
	}
",non-flaky,5
89341,apache_samza,TestKafkaSystemAdminJava.testStartpointTimestampVisitorShouldResolveToCorrectOffsetWhenTimestampDoesNotExist,"  @Test
  public void testStartpointTimestampVisitorShouldResolveToCorrectOffsetWhenTimestampDoesNotExist() {
    final KafkaConsumer consumer = Mockito.mock(KafkaConsumer.class);
    final KafkaStartpointToOffsetResolver kafkaStartpointToOffsetResolver = new KafkaStartpointToOffsetResolver(consumer);

    final StartpointTimestamp startpointTimestamp = new StartpointTimestamp(0L);
    final Map<TopicPartition, OffsetAndTimestamp> offsetForTimesResult = new HashMap<>();
    offsetForTimesResult.put(TEST_TOPIC_PARTITION, null);

    // Mock the consumer interactions.
    Mockito.when(consumer.offsetsForTimes(ImmutableMap.of(TEST_TOPIC_PARTITION, 0L))).thenReturn(offsetForTimesResult);
    Mockito.when(consumer.endOffsets(ImmutableSet.of(TEST_TOPIC_PARTITION))).thenReturn(ImmutableMap.of(TEST_TOPIC_PARTITION, 10L));

    String resolvedOffset = kafkaStartpointToOffsetResolver.visit(TEST_SYSTEM_STREAM_PARTITION, startpointTimestamp);
    Assert.assertEquals(TEST_OFFSET, resolvedOffset);

    // Mock verifications.
    Mockito.verify(consumer).offsetsForTimes(ImmutableMap.of(TEST_TOPIC_PARTITION, 0L));
  }
",non-flaky,5
42972,fabiomaffioletti_jsondoc,ApiDocTest.testApiErrorsDoc,"	@Test
	public void testApiErrorsDoc() throws Exception {

		final ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>>newHashSet(Test3Controller.class),
				MethodDisplay.URI).iterator().next();

		final Set<ApiMethodDoc> methods = apiDoc.getMethods();
		final ApiMethodDoc apiMethodDoc = methods.iterator().next();
		final List<ApiErrorDoc> apiErrors = apiMethodDoc.getApierrors();

		Assert.assertEquals(1, methods.size());
		Assert.assertEquals(3, apiErrors.size());
		Assert.assertEquals(""1000"", apiErrors.get(0).getCode());
		Assert.assertEquals(""method-level annotation should be applied"",
				""A test error #1"", apiErrors.get(0).getDescription());
		Assert.assertEquals(""2000"", apiErrors.get(1).getCode());
		Assert.assertEquals(""400"", apiErrors.get(2).getCode());

	}
",non-flaky,5
91591,apache_kylin,SourceConfigurationUtilTest.testSqoopConf,"    @Test
    public void testSqoopConf() {
        Map<String, String> configMap = SourceConfigurationUtil.loadSqoopConfiguration();
        assertFalse(configMap.isEmpty());
        assertEquals(""1"", configMap.get(""dfs.replication""));
    }
",non-flaky,5
113909,spring-projects_spring-data-couchbase,CouchbaseTemplateQueryCollectionIntegrationTests.removeById,"	@Test
	public void removeById() { // 7
		RemoveOptions options = RemoveOptions.removeOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.one(vie);
		RemoveResult removeResult = couchbaseTemplate.removeById().inScope(scopeName).inCollection(collectionName)
				.withOptions(options).one(saved.getId());
		assertEquals(saved.getId(), removeResult.getId());
	}
",non-flaky,5
113977,apache_struts,NamedVariablePatternMatcherTest.testMatch,"    @Test
    public void testMatch() {
        NamedVariablePatternMatcher matcher = new NamedVariablePatternMatcher();

        Map<String, String> vars = new HashMap<>();
        CompiledPattern pattern = new CompiledPattern(Pattern.compile(""foo([^/]+)""), Arrays.asList(""bar""));

        assertTrue(matcher.match(vars, ""foobaz"", pattern));
        assertEquals(""baz"", vars.get(""bar""));
    }
",non-flaky,5
57196,apache_ozone,TestReconUtils.testCreateTarFile,"  @Test
  public void testCreateTarFile() throws Exception {

    File tempSnapshotDir = null;
    FileInputStream fis = null;
    FileOutputStream fos = null;
    File tarFile = null;

    try {
      String testDirName = System.getProperty(""java.io.tmpdir"");
      if (!testDirName.endsWith(""/"")) {
        testDirName += ""/"";
      }
      testDirName += ""TestCreateTarFile_Dir"" + System.currentTimeMillis();
      tempSnapshotDir = new File(testDirName);
      tempSnapshotDir.mkdirs();

      File file = new File(testDirName + ""/temp1.txt"");
      OutputStreamWriter writer = new OutputStreamWriter(
          new FileOutputStream(file), UTF_8);
      writer.write(""Test data 1"");
      writer.close();

      file = new File(testDirName + ""/temp2.txt"");
      writer = new OutputStreamWriter(
          new FileOutputStream(file), UTF_8);
      writer.write(""Test data 2"");
      writer.close();

      tarFile = createTarFile(Paths.get(testDirName));
      Assert.assertNotNull(tarFile);

    } finally {
      org.apache.hadoop.io.IOUtils.closeStream(fis);
      org.apache.hadoop.io.IOUtils.closeStream(fos);
      FileUtils.deleteDirectory(tempSnapshotDir);
      FileUtils.deleteQuietly(tarFile);
    }
  }
",non-flaky,5
78255,apache_beam,StateInternalsTest.testWatermarkEndOfWindowState,"  @Test
  public void testWatermarkEndOfWindowState() throws Exception {
    WatermarkHoldState value = underTest.state(NAMESPACE_1, WATERMARK_EOW_ADDR);

    // State instances are cached, but depend on the namespace.
    assertEquals(value, underTest.state(NAMESPACE_1, WATERMARK_EOW_ADDR));
    assertFalse(value.equals(underTest.state(NAMESPACE_2, WATERMARK_EOW_ADDR)));

    assertThat(value.read(), Matchers.nullValue());
    value.add(new Instant(2000));
    assertThat(value.read(), equalTo(new Instant(2000)));

    value.clear();
    assertThat(value.read(), equalTo(null));
    assertThat(underTest.state(NAMESPACE_1, WATERMARK_EOW_ADDR), equalTo(value));
  }
",non-flaky,5
33894,apache_camel,FhirReadIT.testResourceByLongIdAndStringResource,"    @Test
    public void testResourceByLongIdAndStringResource() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.resource"", Patient.class);
        // parameter type is Long
        headers.put(""CamelFhir.longId"", Long.valueOf(patient.getIdElement().getIdPart()));

        Patient result = requestBodyAndHeaders(""direct://RESOURCE_BY_LONG_ID_AND_STRING_RESOURCE"", null, headers);

        assertValidResponse(result);
    }
",non-flaky,5
112670,tbsalling_aismessages,NMEAMessageInputStreamReaderTest.catchesInvalidMessageExceptions,"    @Test
    public void catchesInvalidMessageExceptions() throws IOException {
        String nmeaStream =
            ""!AIVDM,1,1,,B,402=481uaUcf;OQ55JS9ITi025Jp,0*2B\n"" +
            ""!AIVDM,1,1,,B,58LAM242B9POUKWWW<0a>0<4E<58,0*6E\n"" +  // invalid
            ""!AIVDM,1,1,,A,33nr7t001f13KNTOahh2@QpF00vh,0*58\n"";

        InputStream inputStream = new ByteArrayInputStream(nmeaStream.getBytes(StandardCharsets.UTF_8));

        new NMEAMessageInputStreamReader(inputStream, nmeaMessageHandler).run();
    }
",non-flaky,5
150157,apache_hive,TestHplsqlLocal.testDeclare3,"  @Test
  public void testDeclare3() throws Exception {
    run(""declare3"");
  }
",non-flaky,5
38194,palantir_atlasdb,SchemasTest.testCreateTable,"    @Test
    public void testCreateTable() {
        mockery.checking(new Expectations(){{
            oneOf(kvs).createTables(with(tableMapContainsEntry(TABLE_REF, getSimpleTableDefinitionAsBytes(TABLE_REF))));
        }});
        Schemas.createTable(kvs, TABLE_REF, getSimpleTableDefinition(TABLE_REF));
    }
",non-flaky,5
134992,undertow-io_undertow,AnnotatedEndpointTest.testIdleTimeout,"    @Test
    public void testIdleTimeout() throws Exception {
        AnnotatedClientEndpoint.reset();
        Session session = deployment.connectToServer(AnnotatedClientEndpoint.class, new URI(""ws://"" + DefaultServer.getHostAddress(""default"") + "":"" + DefaultServer.getHostPort(""default"") + ""/ws/chat/Bob""));

        Assert.assertEquals(""hi Bob (protocol=foo)"", AnnotatedClientEndpoint.message());

        session.close();
        Assert.assertEquals(""CLOSED"", AnnotatedClientEndpoint.message());
    }
",non-flaky,5
13859,neo4j_neo4j,TestCommunication.throwingServerSideExceptionBackToClient,"    @Test
    public void throwingServerSideExceptionBackToClient() throws Throwable
    {
        MadeUpServer server = builder.server();
        MadeUpClient client = builder.client();
        addToLifeAndStart( server, client );

        String exceptionMessage = ""The message"";
        try
        {
            client.throwException( exceptionMessage );
            fail( ""Should have thrown "" + MadeUpException.class.getSimpleName() );
        }
        catch ( MadeUpException e )
        {   // Good
            assertEquals( exceptionMessage, e.getMessage() );
        }
    }
",non-flaky,5
88813,apache_ignite,FunctionalTest.testRemoveReplace,"    @Test
    public void testRemoveReplace() throws Exception {
        try (Ignite ignored = Ignition.start(Config.getServerConfiguration());
             IgniteClient client = Ignition.startClient(getClientConfiguration())
        ) {
            ClientCache<Integer, String> cache = client.createCache(""testRemoveReplace"");

            Map<Integer, String> data = IntStream.rangeClosed(1, 100).boxed()
                .collect(Collectors.toMap(i -> i, Object::toString));

            cache.putAll(data);

            assertFalse(cache.replace(1, ""2"", ""3""));
            assertEquals(""1"", cache.get(1));
            assertTrue(cache.replace(1, ""1"", ""3""));
            assertEquals(""3"", cache.get(1));

            assertFalse(cache.replace(101, ""101""));
            assertNull(cache.get(101));
            assertTrue(cache.replace(100, ""101""));
            assertEquals(""101"", cache.get(100));

            assertFalse(cache.remove(101));
            assertTrue(cache.remove(100));
            assertNull(cache.get(100));

            assertFalse(cache.remove(99, ""100""));
            assertEquals(""99"", cache.get(99));
            assertTrue(cache.remove(99, ""99""));
            assertNull(cache.get(99));

            cache.put(101, ""101"");

            cache.removeAll(data.keySet());
            assertEquals(1, cache.size());
            assertEquals(""101"", cache.get(101));

            cache.removeAll();
            assertEquals(0, cache.size());
        }
    }
",non-flaky,5
91387,OpenLCB_OpenLCB_Java,OlcbInterfaceTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
177232,line_armeria,PropertiesEndpointGroupTest.resourceWithoutDefaultPort,"    @Test
    public void resourceWithoutDefaultPort() {
        final PropertiesEndpointGroup endpointGroup = PropertiesEndpointGroup.of(
                getClass().getClassLoader(), ""server-list.properties"", ""serverA.hosts"");

        assertThat(endpointGroup.endpoints()).containsExactlyInAnyOrder(Endpoint.parse(""127.0.0.1:8080""),
                                                                        Endpoint.parse(""127.0.0.1:8081""),
                                                                        Endpoint.parse(""127.0.0.1""));
    }
",non-flaky,5
38675,apache_pulsar,InfluxDBSinkConfigTest.testBatchConfig,"    @Test(expectedExceptions = IllegalArgumentException.class,
    public void testBatchConfig() throws Exception {
        Map<String, Object> map = buildValidConfigMap();
        map.put(""batchSize"", -1);
        InfluxDBSinkConfig config = InfluxDBSinkConfig.load(map);
        config.validate();
    }
",non-flaky,5
26744,MundaneImmortal_pair-distribution-app,DeveloperTest.testEqualsOfDifferentInstances,"	@Test
	public void testEqualsOfDifferentInstances() {
		Developer developer = new Developer(""developerId"");
		Developer differentDeveloper = new Developer(""developerId2"");
		
		assertThat(developer.equals(differentDeveloper), is(false));
		assertThat(differentDeveloper.equals(developer), is(false));
	}
",non-flaky,5
98086,vert-x3_vertx-mongo-client,WriteConcernParserTest.testConnStringSimpleAndAdvancedWriteConcern,"  @Test
  public void testConnStringSimpleAndAdvancedWriteConcern() {
    final ConnectionString connString = new ConnectionString(""mongodb://localhost:27017/mydb?replicaSet=myapp"" +
      ""&w=majority&wtimeoutms=20&journal=false"");
    WriteConcern expected = new WriteConcern(""majority"").withWTimeout(20, TimeUnit.MILLISECONDS).withJournal(false);
    WriteConcern wc = new WriteConcernParser(connString, new JsonObject()).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
",non-flaky,5
76947,Tencent_Firestorm,ShuffleReadClientImplTest.readTest8,"  @Test
  public void readTest8() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest8"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 30, 0, expectedData, blockIdBitmap);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());
    // crc32 is incorrect
    try (MockedStatic<ChecksumUtils> checksumUtilsMock = Mockito.mockStatic(ChecksumUtils.class)) {
      checksumUtilsMock.when(() -> ChecksumUtils.getCrc32((ByteBuffer) any())).thenReturn(-1L);
      try {
        ByteBuffer bb = readClient.readShuffleBlockData().getByteBuffer();
        while (bb != null) {
          bb = readClient.readShuffleBlockData().getByteBuffer();
        }
        fail(EXPECTED_EXCEPTION_MESSAGE);
      } catch (Exception e) {
        assertTrue(e.getMessage().startsWith(""Unexpected crc value""));
      }
    }
    readClient.close();
  }
",non-flaky,5
104678,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testGeneratedQueriesWithoutMultiValues,"  @Test(enabled = false)
  public void testGeneratedQueriesWithoutMultiValues() {
  }
",non-flaky,5
38274,palantir_atlasdb,AbstractTransactionTest.testKeyValueRows,"    @Test
    public void testKeyValueRows() {
        putDirect(""row1"", ""col1"", ""v1"", 0);
        Pair<String, Long> pair = getDirect(""row1"", ""col1"", 1);
        assertEquals(0L, (long)pair.getRhSide());
        assertEquals(""v1"", pair.getLhSide());

        putDirect(""row1"", ""col1"", ""v2"", 2);
        pair = getDirect(""row1"", ""col1"", 2);
        assertEquals(0L, (long)pair.getRhSide());
        assertEquals(""v1"", pair.getLhSide());

        pair = getDirect(""row1"", ""col1"", 3);
        assertEquals(2L, (long)pair.getRhSide());
        assertEquals(""v2"", pair.getLhSide());
    }
",non-flaky,5
33857,apache_camel,FhirPatchIT.testPatchById,"    @Test
    public void testPatchById() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.patchBody"", PATCH);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.id"", this.patient.getIdElement());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", null);

        MethodOutcome result = requestBodyAndHeaders(""direct://PATCH_BY_ID"", null, headers);
        assertNotNull(result, ""patchById result"");
        assertActive(result);
    }
",non-flaky,5
176920,OryxProject_oryx,RDFCategoricalHyperParamTuningIT.testRDF,"  @Test
  public void testRDF() throws Exception {
    Path tempDir = getTempDir();
    Path dataDir = tempDir.resolve(""data"");
    Path modelDir = tempDir.resolve(""model"");

    Map<String,Object> overlayConfig = new HashMap<>();
    overlayConfig.put(""oryx.batch.update-class"", RDFUpdate.class.getName());
    ConfigUtils.set(overlayConfig, ""oryx.batch.storage.data-dir"", dataDir);
    ConfigUtils.set(overlayConfig, ""oryx.batch.storage.model-dir"", modelDir);
    overlayConfig.put(""oryx.batch.streaming.generation-interval-sec"", GEN_INTERVAL_SEC);
    overlayConfig.put(""oryx.batch.streaming.block-interval-sec"", BLOCK_INTERVAL_SEC);
    overlayConfig.put(""oryx.rdf.num-trees"", 10);
    overlayConfig.put(""oryx.rdf.hyperparams.max-depth"", MAX_DEPTH);
    // Low values like 1 are deliberately bad, won't work
    overlayConfig.put(""oryx.rdf.hyperparams.max-depth"", ""[1,"" + MAX_DEPTH + ""]"");
    overlayConfig.put(""oryx.rdf.hyperparams.max-split-candidates"", MAX_SPLIT_CANDIDATES);
    overlayConfig.put(""oryx.input-schema.num-features"", 5);
    overlayConfig.put(""oryx.input-schema.categorical-features"", ""[\""4\""]"");
    overlayConfig.put(""oryx.input-schema.id-features"", ""[\""0\""]"");
    overlayConfig.put(""oryx.input-schema.target-feature"", ""\""4\"""");
    overlayConfig.put(""oryx.ml.eval.candidates"", 3);
    overlayConfig.put(""oryx.ml.eval.parallelism"", 2);
    Config config = ConfigUtils.overlayOn(overlayConfig, getConfig());

    startMessaging();

    startServerProduceConsumeTopics(
        config,
        new RandomCategoricalRDFDataGenerator(3),
        DATA_TO_WRITE,
        WRITE_INTERVAL_MSEC);

    List<Path> modelInstanceDirs = IOUtils.listFiles(modelDir, ""*"");

    checkIntervals(modelInstanceDirs.size(), DATA_TO_WRITE, WRITE_INTERVAL_MSEC, GEN_INTERVAL_SEC);

    Path latestModelDir = modelInstanceDirs.get(modelInstanceDirs.size() - 1);
    Path modelFile = latestModelDir.resolve(MLUpdate.MODEL_FILE_NAME);
    assertTrue(""No such model file: "" + modelFile, Files.exists(modelFile));

    PMML pmml = PMMLUtils.read(modelFile);

    assertEquals(3, pmml.getExtensions().size());
    Map<String,Object> expected = new HashMap<>();
    expected.put(""maxSplitCandidates"", MAX_SPLIT_CANDIDATES);
    expected.put(""maxDepth"", MAX_DEPTH);
    expected.put(""impurity"", IMPURITY);
    checkExtensions(pmml, expected);

    Pair<DecisionForest,CategoricalValueEncodings> forestEncoding = RDFPMMLUtils.read(pmml);
    DecisionForest forest = forestEncoding.getFirst();
    CategoricalValueEncodings encoding = forestEncoding.getSecond();
    Map<String,Integer> targetEncoding = encoding.getValueEncodingMap(4);

    int[] zeroOne = { 0, 1 };
    for (int f1 : zeroOne) {
      for (int f2 : zeroOne) {
        for (int f3 : zeroOne) {
          CategoricalPrediction prediction =
              (CategoricalPrediction) forest.predict(new Example(null,
                                                                 null,
                                                                 NumericFeature.forValue(f1),
                                                                 NumericFeature.forValue(f2),
                                                                 NumericFeature.forValue(f3)));
          boolean expectedPositive = f1 == 1 && f2 == 1 && f3 == 1;
          assertEquals(targetEncoding.get(Boolean.toString(expectedPositive)).intValue(),
                       prediction.getMostProbableCategoryEncoding());
        }
      }
    }

  }
",non-flaky,5
30950,camunda-cloud_zeebe,ElasticsearchClientIT.shouldFlushOnMemoryLimit,"  @Test
  public void shouldFlushOnMemoryLimit() {
    // given
    final var bulkMemoryLimit = 1024;
    final var recordSize = 2;

    configuration.bulk.memoryLimit = bulkMemoryLimit;
    configuration.bulk.size = Integer.MAX_VALUE;
    configuration.bulk.delay = Integer.MAX_VALUE;

    final var variableValue1 = ""x"".repeat(bulkMemoryLimit / recordSize);
    final var variableValue2 = ""y"".repeat(bulkMemoryLimit / recordSize);
    final Function<String, String> jsonRecord =
        (String value) -> String.format(""{\""value\"":\""%s\""}"", value);

    final VariableRecordValue recordValue = mock(VariableRecordValue.class);
    when(recordValue.getValue()).thenReturn(variableValue1);

    final Record<VariableRecordValue> recordMock = mock(Record.class);
    when(recordMock.getKey()).thenReturn(1L);
    when(recordMock.getPartitionId()).thenReturn(1);
    when(recordMock.getValueType()).thenReturn(ValueType.VARIABLE);
    when(recordMock.getValue()).thenReturn(recordValue);
    when(recordMock.toJson()).thenReturn(jsonRecord.apply(variableValue1));

    // when
    client.index(recordMock);

    assertThat(client.shouldFlush()).isFalse();

    when(recordMock.getKey()).thenReturn(2L);
    when(recordMock.toJson()).thenReturn(jsonRecord.apply(variableValue2));

    client.index(recordMock);

    // then
    assertThat(client.shouldFlush()).isTrue();
  }
",non-flaky,5
150121,apache_hive,TestHplsqlOffline.testCreateTableTd,"  @Test
  public void testCreateTableTd() throws Exception {
    run(""create_table_td"");
  }
",non-flaky,5
77505,dropwizard_dropwizard,OptionalAuthFilterOrderingTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();
    }
",non-flaky,5
150125,apache_hive,TestHplsqlOffline.testSelectDb2,"  @Test
  public void testSelectDb2() throws Exception {
    run(""select_db2"");
  }
",non-flaky,5
156092,soot-oss_soot,AsmMethodSourceTest.testSilsDisabled,"  @Test
  public void testSilsDisabled() {
    final String className = ""soot.asm.LocalNaming"";
    final String[] params = {};
    SootMethod target = prepareTarget(methodSigFromComponents(className, ""void"", ""test"", params), className);
    Body body = target.retrieveActiveBody();
    Set<String> localNames = body.getLocals().stream().map(Local::getName).collect(Collectors.toSet());
    // test if all expected Local names are present
    Assert.assertTrue(localNames.contains(""d""));
    Assert.assertTrue(localNames.contains(""f""));
    Assert.assertTrue(localNames.contains(""arr""));
  }
",non-flaky,5
112120,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindTaskRunningStatisticsWithDifferentFromDate,"    @Test
    public void assertFindTaskRunningStatisticsWithDifferentFromDate() {
        Date now = new Date();
        Date yesterday = getYesterday();
        assertTrue(repository.add(new TaskRunningStatistics(100, yesterday)));
        assertTrue(repository.add(new TaskRunningStatistics(100, now)));
        assertThat(repository.findTaskRunningStatistics(yesterday).size(), is(2));
        assertThat(repository.findTaskRunningStatistics(now).size(), is(1));
    }
",non-flaky,5
118758,netty_netty,ByteBufUtilTest.testWriteUtf8InvalidOnlyLeadingSurrogate,"    @Test
    public void testWriteUtf8InvalidOnlyLeadingSurrogate() {
        String surrogateString = new StringBuilder(2)
                                .append('a')
                                .append('\uD800')
                                .append('b')
                                .toString();
        ByteBuf buf = Unpooled.buffer(16);
        buf.writeBytes(surrogateString.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = Unpooled.buffer(16);
        ByteBufUtil.writeUtf8(buf2, surrogateString);

        assertEquals(buf, buf2);
        assertEquals(buf.readableBytes(), ByteBufUtil.utf8Bytes(surrogateString));

        buf.release();
        buf2.release();
    }
",non-flaky,5
256,apache_hadoop,TestDelegationTokenForProxyUser.testWebHdfsDoAs,"@Test
public void testWebHdfsDoAs() throws Exception {
    LOG.info(""START: testWebHdfsDoAs()"");
    ((Log4JLogger) (LOG)).getLogger().setLevel(ALL);
    ((Log4JLogger) (LOG)).getLogger().setLevel(ALL);
    final UserGroupInformation ugi = UserGroupInformation.createRemoteUser(REAL_USER);
    LOG.info(""ugi.getShortUserName()="" + ugi.getShortUserName());
    final WebHdfsFileSystem webhdfs = WebHdfsTestUtil.getWebHdfsFileSystemAs(ugi, config);
    final Path root = new Path(""/"");
    cluster.getFileSystem().setPermission(root, new FsPermission(((short) (0777))));
    {
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, GETHOMEDIRECTORY, root, new DoAsParam(PROXY_USER));
        final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK);
        conn.disconnect();
        final Object responsePath = m.get(Path.class.getSimpleName());
        LOG.info(""responsePath="" + responsePath);
        Assert.assertEquals(""/user/"" + PROXY_USER, responsePath);
    }
    {
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, GETHOMEDIRECTORY, root, new DoAsParam(PROXY_USER) {
            @Override
            public String getName() {
                return ""DOas"";
            }
        });
        final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK);
        conn.disconnect();
        final Object responsePath = m.get(Path.class.getSimpleName());
        LOG.info(""responsePath="" + responsePath);
        Assert.assertEquals(""/user/"" + PROXY_USER, responsePath);
    }
    final Path f = new Path(""/testWebHdfsDoAs/a.txt"");
    {
        final PutOpParam.Op op = Op.CREATE;
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, op, f, new DoAsParam(PROXY_USER));
        HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        conn = WebHdfsTestUtil.twoStepWrite(webhdfs, op, conn);
        final FSDataOutputStream out = WebHdfsTestUtil.write(webhdfs, op, conn, 4096);
        out.write(""Hello, webhdfs user!"".getBytes());
        out.close();
        final FileStatus status = webhdfs.getFileStatus(f);
        LOG.info(""status.getOwner()="" + status.getOwner());
        Assert.assertEquals(PROXY_USER, status.getOwner());
    }
    {
        final PostOpParam.Op op = Op.APPEND;
        final URL url = WebHdfsTestUtil.toUrl(webhdfs, op, f, new DoAsParam(PROXY_USER));
        HttpURLConnection conn = ((HttpURLConnection) (url.openConnection()));
        conn = WebHdfsTestUtil.twoStepWrite(webhdfs, op, conn);
        final FSDataOutputStream out = WebHdfsTestUtil.write(webhdfs, op, conn, 4096);
        out.write(""\nHello again!"".getBytes());
        out.close();
        final FileStatus status = webhdfs.getFileStatus(f);
        LOG.info(""status.getOwner()="" + status.getOwner());
        LOG.info(""status.getLen()  ="" + status.getLen());
        Assert.assertEquals(PROXY_USER, status.getOwner());
    }
}",test order dependency,4
30927,camunda-cloud_zeebe,MsgPackReadTokenTest.shouldReadToken,"  @Test
  public void shouldReadToken() {
    // given
    final MsgPackReader reader = new MsgPackReader();
    final ByteArrayBuilder builder = new ByteArrayBuilder();
    given.accept(builder);
    final DirectBuffer buf = new UnsafeBuffer(builder.value);
    reader.wrap(buf, 0, buf.capacity());

    // when
    final MsgPackToken msgPackToken = reader.readToken();

    // then
    assertThat(reader.getOffset()).isEqualTo(buf.capacity());
    assertThat(msgPackToken.getType()).isEqualTo(expectedType);
    assertion.accept(msgPackToken);
  }
",non-flaky,5
135026,undertow-io_undertow,HttpStringTestCase.testOrderShorterFirst,"    @Test
    public void testOrderShorterFirst() {
        HttpString a =  new HttpString(""a"");
        HttpString aa =  new HttpString(""aa"");
        Assert.assertEquals(-1, a.compareTo(aa));
    }
",non-flaky,5
70788,apache_kafka,ExampleConnectIntegrationTest.testSinkConnector,"    @Test
    public void testSinkConnector() throws Exception {
        // create test topic
        connect.kafka().createTopic(""test-topic"", NUM_TOPIC_PARTITIONS);

        // setup up props for the sink connector
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSinkConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));
        props.put(TOPICS_CONFIG, ""test-topic"");
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());

        // expect all records to be consumed by the connector
        connectorHandle.expectedRecords(NUM_RECORDS_PRODUCED);

        // expect all records to be consumed by the connector
        connectorHandle.expectedCommits(NUM_RECORDS_PRODUCED);

        // start a sink connector
        connect.configureConnector(CONNECTOR_NAME, props);

        waitForCondition(this::checkForPartitionAssignment,
                CONNECTOR_SETUP_DURATION_MS,
                ""Connector tasks were not assigned a partition each."");

        // produce some messages into source topic partitions
        for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {
            connect.kafka().produce(""test-topic"", i % NUM_TOPIC_PARTITIONS, ""key"", ""simple-message-value-"" + i);
        }

        // consume all records from the source topic or fail, to ensure that they were correctly produced.
        assertEquals(""Unexpected number of records consumed"", NUM_RECORDS_PRODUCED,
                connect.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, ""test-topic"").count());

        // wait for the connector tasks to consume all records.
        connectorHandle.awaitRecords(RECORD_TRANSFER_DURATION_MS);

        // wait for the connector tasks to commit all records.
        connectorHandle.awaitCommits(RECORD_TRANSFER_DURATION_MS);

        // delete connector
        connect.deleteConnector(CONNECTOR_NAME);
    }
",non-flaky,5
110899,pushtorefresh_storio,UpdateTest.updateNullFieldToNotNull,"    @Test
    public void updateNullFieldToNotNull() {
        final User userForInsert = User.newInstance(null, ""user@email.com"", null); // phone is null

        putUserBlocking(userForInsert);

        final User userForUpdate = User.newInstance(
                userForInsert.id(),
                userForInsert.email(),
                ""1-999-547867""  // phone not null
        );

        updateUserBlocking(userForUpdate);
        checkOnlyOneItemInStorage(userForUpdate);
    }
",non-flaky,5
84577,apache_zookeeper,LeaderElectionSupportTest.testNodes20,"    @Test
    public void testNodes20() throws Exception {
        int testIterations = 20;
        final CountDownLatch latch = new CountDownLatch(testIterations);
        final AtomicInteger failureCounter = new AtomicInteger();

        for (int i = 0; i < testIterations; i++) {
            runElectionSupportThread(latch, failureCounter);
        }

        assertEquals(0, failureCounter.get());

        if (!latch.await(10, TimeUnit.SECONDS)) {
            LOGGER.info(""Waited for all threads to start, but timed out. We had {} failures."", failureCounter);
        }
    }
",non-flaky,5
78331,apache_beam,ReduceFnRunnerTest.testWatermarkHoldAndLateData,"  @Test
  public void testWatermarkHoldAndLateData() throws Exception {
    MetricsContainerImpl container = new MetricsContainerImpl(""any"");
    MetricsEnvironment.setCurrentContainer(container);
    // Test handling of late data. Specifically, ensure the watermark hold is correct.
    Duration allowedLateness = Duration.millis(10);
    ReduceFnTester<Integer, Iterable<Integer>, IntervalWindow> tester =
        ReduceFnTester.nonCombining(
            FixedWindows.of(Duration.millis(10)),
            mockTriggerStateMachine,
            AccumulationMode.ACCUMULATING_FIRED_PANES,
            allowedLateness,
            ClosingBehavior.FIRE_IF_NON_EMPTY);

    // Input watermark -> null
    assertEquals(null, tester.getWatermarkHold());
    assertEquals(null, tester.getOutputWatermark());

    // All on time data, verify watermark hold.
    IntervalWindow expectedWindow = new IntervalWindow(new Instant(0), new Instant(10));
    injectElement(tester, 1);
    injectElement(tester, 3);
    assertEquals(new Instant(1), tester.getWatermarkHold());
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    injectElement(tester, 2);
    List<WindowedValue<Iterable<Integer>>> output = tester.extractOutput();
    assertThat(
        output,
        contains(
            isSingleWindowedValue(
                containsInAnyOrder(1, 2, 3),
                equalTo(new Instant(1)),
                equalTo((BoundedWindow) expectedWindow))));
    assertThat(
        output.get(0).getPane(), equalTo(PaneInfo.createPane(true, false, Timing.EARLY, 0, -1)));

    // There is no end-of-window hold, but the timer set by the trigger holds the watermark
    assertThat(tester.getWatermarkHold(), nullValue());

    // Nothing dropped.
    long droppedElements =
        container
            .getCounter(
                MetricName.named(ReduceFnRunner.class, ReduceFnRunner.DROPPED_DUE_TO_CLOSED_WINDOW))
            .getCumulative();
    assertEquals(0, droppedElements);

    // Input watermark -> 4, output watermark should advance that far as well
    tester.advanceInputWatermark(new Instant(4));
    assertEquals(new Instant(4), tester.getOutputWatermark());

    // Some late, some on time. Verify that we only hold to the minimum of on-time.
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(false);
    tester.advanceInputWatermark(new Instant(4));
    injectElement(tester, 2);
    injectElement(tester, 3);

    // Late data has arrived behind the _output_ watermark. The ReduceFnRunner sets a GC hold
    // since this data is not permitted to hold up the output watermark.
    assertThat(
        tester.getWatermarkHold(), equalTo(expectedWindow.maxTimestamp().plus(allowedLateness)));

    // Now data just ahead of the output watermark arrives and sets an earlier ""element"" hold
    injectElement(tester, 5);
    assertEquals(new Instant(5), tester.getWatermarkHold());

    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    injectElement(tester, 4);
    output = tester.extractOutput();
    assertThat(
        output,
        contains(
            isSingleWindowedValue(
                containsInAnyOrder(
                    1, 2, 3, // earlier firing
                    2, 3, 4, 5), // new elements
                4, // timestamp
                0, // window start
                10))); // window end
    assertThat(
        output.get(0).getPane(), equalTo(PaneInfo.createPane(false, false, Timing.EARLY, 1, -1)));

    // Since the element hold is cleared, there is no hold remaining
    assertThat(tester.getWatermarkHold(), nullValue());

    // All behind the output watermark -- hold is at GC time (if we imagine the
    // trigger sets a timer for ON_TIME firing, that is actually when they'll be emitted)
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(false);
    tester.advanceInputWatermark(new Instant(8));
    injectElement(tester, 6);
    injectElement(tester, 5);
    assertThat(
        tester.getWatermarkHold(), equalTo(expectedWindow.maxTimestamp().plus(allowedLateness)));

    injectElement(tester, 4);

    // Fire the ON_TIME pane
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);

    // To get an ON_TIME pane, we need the output watermark to be held back a little; this would
    // be done by way of the timers set by the trigger, which are mocked here
    tester.setAutoAdvanceOutputWatermark(false);

    tester.advanceInputWatermark(expectedWindow.maxTimestamp().plus(1));
    tester.fireTimer(expectedWindow, expectedWindow.maxTimestamp(), TimeDomain.EVENT_TIME);

    // Output time is end of the window, because all the new data was late, but the pane
    // is the ON_TIME pane.
    output = tester.extractOutput();
    assertThat(
        output,
        contains(
            isSingleWindowedValue(
                containsInAnyOrder(
                    1, 2, 3, // earlier firing
                    2, 3, 4, 5, // earlier firing
                    4, 5, 6), // new elements
                9, // timestamp
                0, // window start
                10))); // window end
    assertThat(
        output.get(0).getPane(), equalTo(PaneInfo.createPane(false, false, Timing.ON_TIME, 2, 0)));

    tester.setAutoAdvanceOutputWatermark(true);

    // This is ""pending"" at the time the watermark makes it way-late.
    // Because we're about to expire the window, we output it.
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(false);
    injectElement(tester, 8);
    droppedElements =
        container
            .getCounter(
                MetricName.named(ReduceFnRunner.class, ReduceFnRunner.DROPPED_DUE_TO_CLOSED_WINDOW))
            .getCumulative();
    assertEquals(0, droppedElements);

    // Exceed the GC limit, triggering the last pane to be fired
    tester.advanceInputWatermark(new Instant(50));
    output = tester.extractOutput();
    // Output time is still end of the window, because the new data (8) was behind
    // the output watermark.
    assertThat(
        output,
        contains(
            isSingleWindowedValue(
                containsInAnyOrder(
                    1, 2, 3, // earlier firing
                    2, 3, 4, 5, // earlier firing
                    4, 5, 6, // earlier firing
                    8), // new element prior to window becoming expired
                9, // timestamp
                0, // window start
                10))); // window end
    assertThat(
        output.get(0).getPane(), equalTo(PaneInfo.createPane(false, true, Timing.LATE, 3, 1)));
    assertEquals(new Instant(50), tester.getOutputWatermark());
    assertEquals(null, tester.getWatermarkHold());

    // Late timers are ignored
    tester.fireTimer(
        new IntervalWindow(new Instant(0), new Instant(10)),
        new Instant(12),
        TimeDomain.EVENT_TIME);

    // And because we're past the end of window + allowed lateness, everything should be cleaned up.
    assertFalse(tester.isMarkedFinished(firstWindow));
    tester.assertHasOnlyGlobalAndFinishedSetsFor();
  }
",non-flaky,5
30970,camunda-cloud_zeebe,POJOArrayTest.shouldFailOnRemovingWhenEntryHasBeenAddedBefore,"  @Test
  public void shouldFailOnRemovingWhenEntryHasBeenAddedBefore() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    pojo.wrap(buffer);
    final Iterator<MinimalPOJO> iterator = pojo.simpleArray().iterator();
    iterator.next();
    pojo.simpleArray().add().setLongProp(999L);

    // then
    exception.expect(IllegalStateException.class);

    // when
    iterator.remove();
  }
",non-flaky,5
59626,looly_hutool,JschUtilTest.getSessionTest,"	@Test
	public void getSessionTest(){
		JschUtil.getSession(""192.168.1.134"", 22, ""root"", ""aaa"", null);
	}
",non-flaky,5
38277,palantir_atlasdb,AbstractTransactionTest.testKeyValueRange,"    @Test
    public void testKeyValueRange() {
        putDirect(""row1"", ""col1"", ""v1"", 0);
        putDirect(""row1"", ""col2"", ""v2"", 2);
        putDirect(""row1"", ""col4"", ""v5"", 3);
        putDirect(""row1a"", ""col4"", ""v5"", 100);
        putDirect(""row2"", ""col2"", ""v3"", 1);
        putDirect(""row2"", ""col4"", ""v4"", 6);

        ImmutableList<RowResult<Value>> list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, RangeRequest.builder().build(), 1));
        assertEquals(1, list.size());
        RowResult<Value> row = list.iterator().next();
        assertEquals(1, row.getColumns().size());

        list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, RangeRequest.builder().build(), 2));
        assertEquals(2, list.size());
        row = list.iterator().next();
        assertEquals(1, row.getColumns().size());

        list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, RangeRequest.builder().build(), 3));
        assertEquals(2, list.size());
        row = list.iterator().next();
        assertEquals(2, row.getColumns().size());

        list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, RangeRequest.builder().endRowExclusive(PtBytes.toBytes(""row2"")).build(), 3));
        assertEquals(1, list.size());
        row = list.iterator().next();
        assertEquals(2, row.getColumns().size());

        list = ImmutableList.copyOf(keyValueService.getRange(TEST_TABLE, RangeRequest.builder().startRowInclusive(PtBytes.toBytes(""row1a"")).build(), 3));
        assertEquals(1, list.size());
        row = list.iterator().next();
        assertEquals(1, row.getColumns().size());
    }
",non-flaky,5
110850,pushtorefresh_storio,QueryTest.queryOrderedDesc,"    @Test
    public void queryOrderedDesc() {
        final List<User> users = TestFactory.newUsers(3);

        // Sorting by email before inserting, for the purity of the experiment.
        Collections.sort(users);

        putUsersBlocking(users);

        final List<User> usersFromQueryOrdered = storIOSQLite
                .get()
                .listOfObjects(User.class)
                .withQuery(Query.builder()
                        .table(UserTableMeta.TABLE)
                        .orderBy(UserTableMeta.COLUMN_EMAIL + "" DESC"")
                        .build())
                .prepare()
                .executeAsBlocking();

        assertThat(usersFromQueryOrdered).isNotNull();
        assertThat(usersFromQueryOrdered).hasSize(users.size());

        // Reverse sorting by email for check ordering.
        Collections.reverse(users);

        for (int i = 0; i < users.size(); i++) {
            assertThat(usersFromQueryOrdered.get(i)).isEqualTo(users.get(i));
        }
    }
",non-flaky,5
84560,apache_zookeeper,DistributedQueueTest.testOffer1,"    @Test
    public void testOffer1() throws Exception {
        String dir = ""/testOffer1"";
        String testString = ""Hello World"";
        final int numClients = 1;
        ZooKeeper[] clients = new ZooKeeper[numClients];
        DistributedQueue[] queueHandles = new DistributedQueue[numClients];
        for (int i = 0; i < clients.length; i++) {
            clients[i] = createClient();
            queueHandles[i] = new DistributedQueue(clients[i], dir, null);
        }

        queueHandles[0].offer(testString.getBytes());

        byte[] dequeuedBytes = queueHandles[0].remove();
        assertEquals(new String(dequeuedBytes), testString);
    }
",non-flaky,5
92665,apache_dubbo,ModuleConfigTest.testName2,"    @Test
    public void testName2() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setName(""module-name"");
        assertThat(module.getName(), equalTo(""module-name""));
        assertThat(module.getId(), equalTo(""module-name""));
        Map<String, String> parameters = new HashMap<String, String>();
        ModuleConfig.appendParameters(parameters, module);
        assertThat(parameters, hasEntry(""module"", ""module-name""));
    }
",non-flaky,5
110875,pushtorefresh_storio,RxQueryTest.queryListOfObjectsAsSingle,"    @Test
    public void queryListOfObjectsAsSingle() {
        final List<User> users = putUsersBlocking(10);

        final Single<List<User>> usersSingle = storIOSQLite
                .get()
                .listOfObjects(User.class)
                .withQuery(UserTableMeta.QUERY_ALL)
                .prepare()
                .asRxSingle();

        TestSubscriber<List<User>> testSubscriber = new TestSubscriber<List<User>>();
        usersSingle.subscribe(testSubscriber);

        testSubscriber.awaitTerminalEvent(5, SECONDS);
        testSubscriber.assertNoErrors();
        testSubscriber.assertValue(users);
        testSubscriber.assertCompleted();
    }
",non-flaky,5
38612,apache_pulsar,PerformanceProducerTest.testCreatePartitions,"    @Test(timeOut = 20000)
    public void testCreatePartitions() throws Exception {
        String argString = ""%s -r 10 -u %s -au %s -m 5 -np 10"";
        String topic = testTopic + UUID.randomUUID().toString();
        String args = String.format(argString, topic, pulsar.getBrokerServiceUrl(), pulsar.getWebServiceAddress());
        Thread thread = new Thread(() -> {
            try {
                PerformanceProducer.main(args.split("" ""));
            } catch (Exception e) {
                e.printStackTrace();
            }
        });
        thread.start();
        thread.join();
        Assert.assertEquals(10, pulsar.getAdminClient().topics().getPartitionedTopicMetadata(topic).partitions);
    }
",non-flaky,5
91500,apache_kylin,DriverTest.testWithCubeData,"    @Test
    public void testWithCubeData() throws Exception {
        Driver driver = new Driver();
        Properties info = new Properties();
        info.put(""user"", ""ADMIN"");
        info.put(""password"", ""KYLIN"");
        Connection conn = driver.connect(""jdbc:kylin://localhost:7070/default"", info);

        ResultSet catalogs = conn.getMetaData().getCatalogs();
        System.out.println(""CATALOGS"");
        printResultSetMetaData(catalogs);
        printResultSet(catalogs);

        ResultSet schemas = conn.getMetaData().getSchemas();
        System.out.println(""SCHEMAS"");
        printResultSetMetaData(schemas);
        printResultSet(schemas);

        ResultSet tables = conn.getMetaData().getTables(null, null, null, null);
        System.out.println(""TABLES"");
        printResultSetMetaData(tables);
        printResultSet(tables);

        for (int j = 0; j < 3; j++) {
            Statement state = conn.createStatement();
            ResultSet resultSet = state.executeQuery(""select * from test_kylin_fact"");

            printResultSetMetaData(resultSet);
            printResultSet(resultSet);

            resultSet.close();
        }

        catalogs.close();
        schemas.close();
        tables.close();
        conn.close();
    }
",non-flaky,5
170520,eclipse_jetty.project,TestAnnotationConfiguration.setup,"    @BeforeEach
    public void setup() throws Exception
    {
        web25 = MavenTestingUtils.getTestResourceFile(""web25.xml"");
        web31false = MavenTestingUtils.getTestResourceFile(""web31false.xml"");
        web31true = MavenTestingUtils.getTestResourceFile(""web31true.xml"");

        // prepare an sci that will be on the webapp's classpath
        jarDir = new File(MavenTestingUtils.getTestResourcesDir().getParentFile(), ""jar"");
        testSciJar = new File(jarDir, ""test-sci.jar"");
        assertTrue(testSciJar.exists());

        testContainerSciJar = new File(jarDir, ""test-sci-for-container-path.jar"");
        testWebInfClassesJar = new File(jarDir, ""test-sci-for-webinf.jar"");

        // unpack some classes to pretend that are in WEB-INF/classes
        unpacked = new File(MavenTestingUtils.getTargetTestingDir(), ""test-sci-for-webinf"");
        unpacked.mkdirs();
        FS.cleanDirectory(unpacked);
        JAR.unpack(testWebInfClassesJar, unpacked);
        webInfClasses = Resource.newResource(unpacked);

        containerLoader = new URLClassLoader(new URL[]{
            testContainerSciJar.toURI().toURL()
        }, Thread.currentThread().getContextClassLoader());

        targetClasses = Resource.newResource(MavenTestingUtils.getTargetDir().toURI()).addPath(""/test-classes"");

        classes = Arrays.asList(new Resource[]{webInfClasses, targetClasses});

        webAppLoader = new URLClassLoader(new URL[]{
            testSciJar.toURI().toURL(), targetClasses.getURI().toURL(), webInfClasses.getURI().toURL()
        },
            containerLoader);
    }
",non-flaky,5
38677,apache_pulsar,RabbitMQSinkTest.TestOpenAndWriteSink,"    @Test
    public void TestOpenAndWriteSink() throws Exception {
        Map<String, Object> configs = new HashMap<>();
        configs.put(""host"", ""localhost"");
        configs.put(""port"", ""5673"");
        configs.put(""virtualHost"", ""default"");
        configs.put(""username"", ""guest"");
        configs.put(""password"", ""guest"");
        configs.put(""connectionName"", ""test-connection"");
        configs.put(""requestedChannelMax"", ""0"");
        configs.put(""requestedFrameMax"", ""0"");
        configs.put(""connectionTimeout"", ""60000"");
        configs.put(""handshakeTimeout"", ""10000"");
        configs.put(""requestedHeartbeat"", ""60"");
        configs.put(""exchangeName"", ""test-exchange"");
        configs.put(""exchangeType"", ""fanout"");

        RabbitMQSink sink = new RabbitMQSink();

        // open should success
        // rabbitmq service may need time to initialize
        Awaitility.await().ignoreExceptions().untilAsserted(() -> sink.open(configs, null));

        // write should success
        Record<byte[]> record = build(""test-topic"", ""fakeKey"", ""fakeValue"", ""fakeRoutingKey"");
        sink.write(record);

        sink.close();
    }
",non-flaky,5
20987,NationalSecurityAgency_timely,AggregatorsResponseTest.testAggregatorsResponse,"    @Test
    public void testAggregatorsResponse() throws Exception {
        AggregatorsResponse response = new AggregatorsResponse();
        response.addAggregator(""min"");
        response.addAggregator(""max"");
        String r = JsonUtil.getObjectMapper().writeValueAsString(response);
        Assert.assertEquals(""[\""min\"",\""max\""]"", r);
    }
",non-flaky,5
134982,undertow-io_undertow,WebsocketBasicAuthTestCase.testWrappedRequest,"    @Test
    public void testWrappedRequest() throws Exception {
        ProgramaticClientEndpoint endpoint = new ProgramaticClientEndpoint();
        ClientEndpointConfig clientEndpointConfig = ClientEndpointConfig.Builder.create().build();
        ContainerProvider.getWebSocketContainer().connectToServer(endpoint, clientEndpointConfig, new URI(""ws://"" + DefaultServer.getHostAddress(""default"") + "":"" + DefaultServer.getHostPort(""default"") + ""/servletContext/wrapper""));
        Assert.assertEquals(""wrapped"", endpoint.getResponses().poll(15, TimeUnit.SECONDS));
        endpoint.session.close();
        endpoint.closeLatch.await(10, TimeUnit.SECONDS);
    }
",non-flaky,5
33689,alibaba_fastjson,JSONScannerTest.checkDate12,"  @Test
  public void checkDate12() throws Throwable {

    // Arrange
    char y0 = '2';
    char y1 = '1';
    char y2 = '\u8030';
    char y3 = '\u0830';
    char M0 = '1';
    char M1 = '\u0000';
    int d0 = 0;
    int d1 = 0;

    // Act
    Class<?> c = Reflector.forName(""com.alibaba.fastjson.parser.JSONScanner"");
    Method m = c.getDeclaredMethod(""checkDate"", Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""int""), Reflector.forName(""int""));
    m.setAccessible(true);
    boolean retval = (Boolean)m.invoke(null, y0, y1, y2, y3, M0, M1, d0, d1);

    // Assert result
    Assert.assertEquals(false, retval);

  }
",non-flaky,5
136508,doanduyhai_Achilles,FrozenNestedTypeStrategyTest.should_not_fail_for_non_frozen_map_tuple,"    @Test
    public void should_not_fail_for_non_frozen_map_tuple() throws Exception {
        setExec(aptUtils -> {
            final NestedTypeValidator2_1 strategy = new NestedTypeValidator2_1();
            final String className = TestEntityWithNestedTypes.class.getCanonicalName();
            final TypeName rawClass = ClassName.get(TestEntityWithNestedTypes.class);
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            // private Map<Integer, Tuple2<Integer, String>> mapTuple;
            VariableElement elm = findFieldInType(typeElement, ""mapTuple"");
            final AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils, globalParsingContext, elm);
            strategy.validate(aptUtils, annotationTree, ""mapTuple"", rawClass);
        });
        launchTest(TestEntityWithNestedTypes.class);
    }
",non-flaky,5
160388,ConsenSys_teku,ChainDataProviderTest.getBeaconState_shouldFindHeadState,"  @Test
  public void getBeaconState_shouldFindHeadState() throws ExecutionException, InterruptedException {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    SafeFuture<Optional<BeaconState>> future = provider.getBeaconState(""head"");
    final Optional<BeaconState> maybeState = future.get();
    assertThat(maybeState.get().asInternalBeaconState(spec).hashTreeRoot())
        .isEqualTo(beaconStateInternal.hashTreeRoot());
  }
",non-flaky,5
91425,strapdata_elassandra,MlDistributedFailureIT.testLoseDedicatedMasterNode,"    @TestLogging(""org.elasticsearch.xpack.ml.action:DEBUG,org.elasticsearch.xpack.persistent:TRACE,"" +
    public void testLoseDedicatedMasterNode() throws Exception {
        internalCluster().ensureAtMostNumDataNodes(0);
        logger.info(""Starting dedicated master node..."");
        internalCluster().startNode(Settings.builder()
                .put(""node.master"", true)
                .put(""node.data"", false)
                .put(""node.ml"", false)
                .build());
        logger.info(""Starting ml and data node..."");
        String mlAndDataNode = internalCluster().startNode(Settings.builder()
                .put(""node.master"", false)
                .build());
        ensureStableClusterOnAllNodes(2);
        run(""lose-dedicated-master-node-job"", () -> {
            logger.info(""Stopping dedicated master node"");
            internalCluster().stopRandomNode(settings -> settings.getAsBoolean(""node.master"", false));
            assertBusy(() -> {
                ClusterState state = client(mlAndDataNode).admin().cluster().prepareState()
                        .setLocal(true).get().getState();
                assertNull(state.nodes().getMasterNodeId());
            });
            logger.info(""Restarting dedicated master node"");
            internalCluster().startNode(Settings.builder()
                    .put(""node.master"", true)
                    .put(""node.data"", false)
                    .put(""node.ml"", false)
                    .build());
            ensureStableClusterOnAllNodes(2);
        });
    }
",non-flaky,5
113992,apache_struts,URLDecoderUtilTest.testURLDecodeStringValidUtf8Start,"    @Test
    public void testURLDecodeStringValidUtf8Start() {
        String result = URLDecoderUtil.decode(""%c3%aaxxxx"", ""UTF-8"");
        assertEquals(""\u00eaxxxx"", result);
    }
",non-flaky,5
92689,apache_dubbo,ProviderConfigTest.testBuffer,"    @Test
    public void testBuffer() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setBuffer(10);
        assertThat(provider.getBuffer(), is(10));
    }
",non-flaky,5
35672,cdapio_cdap,LogBufferRecoveryServiceTest.testLogBufferRecoveryService,"  @Test
  public void testLogBufferRecoveryService() throws Exception {
    String absolutePath = TMP_FOLDER.newFolder().getAbsolutePath();

    // create and start pipeline
    LoggerContext loggerContext = LogPipelineTestUtil.createLoggerContext(""WARN"",
                                                                          ImmutableMap.of(""test.logger"", ""INFO""),
                                                                          MockAppender.class.getName());
    final MockAppender appender = LogPipelineTestUtil.getAppender(loggerContext.getLogger(Logger.ROOT_LOGGER_NAME),
                                                                  ""Test"", MockAppender.class);
    MockCheckpointManager checkpointManager = new MockCheckpointManager();
    LogBufferPipelineConfig config = new LogBufferPipelineConfig(1024L, 300L, 500L, 4);
    loggerContext.start();
    LogBufferProcessorPipeline pipeline = new LogBufferProcessorPipeline(
      new LogProcessorPipelineContext(CConfiguration.create(), ""test"", loggerContext, NO_OP_METRICS_CONTEXT, 0),
      config, checkpointManager, 0);

    // start the pipeline
    pipeline.startAndWait();

    // write directly to log buffer
    LogBufferWriter writer = new LogBufferWriter(absolutePath, 250, () -> { });
    ImmutableList<byte[]> events = getLoggingEvents();
    writer.write(events.iterator()).iterator();
    writer.close();

    // start log buffer reader to read log events from files. keep the batch size as 2 so that there are more than 1
    // iterations
    LogBufferRecoveryService service = new LogBufferRecoveryService(ImmutableList.of(pipeline),
                                                                    ImmutableList.of(checkpointManager),
                                                                    absolutePath, 2, new AtomicBoolean(true));
    service.startAndWait();

    Tasks.waitFor(5, () -> appender.getEvents().size(), 120, TimeUnit.SECONDS, 100, TimeUnit.MILLISECONDS);

    service.stopAndWait();
    pipeline.stopAndWait();
    loggerContext.stop();
  }
",non-flaky,5
112095,apache_shardingsphere-elasticjob,RotateServerByNameJobShardingStrategyTest.assertSharding3,"    @Test
    public void assertSharding3() {
        Map<JobInstance, List<Integer>> expected = new HashMap<>();
        expected.put(new JobInstance(""host0@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host1@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host2@-@0""), Collections.<Integer>emptyList());
        assertThat(rotateServerByNameJobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""3"", 2), is(expected));
    }
",non-flaky,5
91399,OpenLCB_OpenLCB_Java,ProducerPaneTest.put,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        EventID eventID = new EventID(new byte[]{1,0,0,0,0,0,1,0});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection sender) {
            }
",non-flaky,5
349,GoogleCloudPlatform_google-cloud-eclipse,CreateAppEngineStandardWtpProjectTest.testNoTestClassesInDeploymentAssembly,"@Test
public void testNoTestClassesInDeploymentAssembly()
throws InvocationTargetException, CoreException {
    CreateAppEngineWtpProject creator = new CreateAppEngineStandardWtpProject(config, adaptable);
    creator.execute(monitor);
    ProjectUtils.waitForProjects(project);
    assertNoTestClassesInDeploymentAssembly();
}
private void assertNoTestClassesInDeploymentAssembly() throws CoreException {
    StructureEdit core = StructureEdit.getStructureEditForRead(project);
    WorkbenchComponent component = core.getComponent();
    assertNotNull(component);
    boolean seenMainSourcePath = false;
    List<ComponentResource> resources = component.getResources();
    for (ComponentResource resource : resources) {
        assertFalse(containsSegment(resource.getSourcePath(), ""test""));
        if (resource.getSourcePath().equals(new Path(""/src/main/java""))
        && resource.getRuntimePath().equals(new Path(""/WEB-INF/classes""))) {
            seenMainSourcePath = true;
        }
    }
    assertTrue(seenMainSourcePath);
}",async wait,0
135716,Netflix_Hystrix,HystrixThreadPoolMetricsTest.shouldYieldNoExecutedTasksOnStartup,"	@Test
	public void shouldYieldNoExecutedTasksOnStartup() throws Exception {
		//given
		final Collection<HystrixThreadPoolMetrics> instances = HystrixThreadPoolMetrics.getInstances();

		//then
		assertEquals(0, instances.size());

	}
",non-flaky,5
243,alibaba_fastjson,test_date,"@Test
public void test_date() throws Exception {
    Date date1 = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12\""}"", VO.class).getGmtCreate();
    assertNotNull(date1);
    Date date2 = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19+00:00\""}"", VO.class).getGmtCreate();
    Date date3 = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate();
    Date date4 = JSON.parseObject(""{\""gmtCreate\"":\""20180912T151019Z\""}"", VO.class).getGmtCreate();
    Date date5 = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate();
    Date date6 = JSON.parseObject(""{\""gmtCreate\"":\""20180912\""}"", VO.class).getGmtCreate();
    long delta_2_1 = date2.getTime() - date1.getTime();
    assertEquals(83419000, delta_2_1);
    long delta_3_1 = date3.getTime() - date1.getTime();
    assertEquals(83419000, delta_3_1);
    long delta_4_3 = date4.getTime() - date3.getTime();
    assertEquals(0, delta_4_3);
    long delta_5_4 = date5.getTime() - date4.getTime();
    assertEquals(0, delta_5_4);
    long delta_6_1 = date6.getTime() - date1.getTime();
    assertEquals(0, delta_6_1);
}",time,2
60868,apache_druid,RedisCacheConfigTest.testInvalidClusterNodePort0,"  @Test
  public void testInvalidClusterNodePort0() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(
        ""{\""expiration\"": 1000,""
        + ""\""cluster\"": {""
        + ""\""nodes\"": \""127.0.0.1:0\"""" //<===Invalid Port
        + ""}""
        + ""}"",
        RedisCacheConfig.class
    );

    expectedException.expect(new ExceptionMatcher(
        IAE.class,
        new ContainsMatcher(""Invalid port"")
    ));
    RedisCacheFactory.create(fromJson);
  }
",non-flaky,5
118742,netty_netty,ByteBufUtilTest.notEqualsBufferSubsections,"    @Test
    public void notEqualsBufferSubsections() {
        byte[] b1 = new byte[50];
        byte[] b2 = new byte[256];
        Random rand = new Random();
        rand.nextBytes(b1);
        rand.nextBytes(b2);
        final int iB1 = b1.length / 2;
        final int iB2 = iB1 + b1.length;
        final int length = b1.length - iB1;
        System.arraycopy(b1, iB1, b2, iB2, length);
        // Randomly pick an index in the range that will be compared and make the value at that index differ between
        // the 2 arrays.
        int diffIndex = random(rand, iB1, iB1 + length - 1);
        ++b1[diffIndex];
        assertFalse(ByteBufUtil.equals(Unpooled.wrappedBuffer(b1), iB1, Unpooled.wrappedBuffer(b2), iB2, length));
    }
",non-flaky,5
179504,abel533_Mapper,StyleTest.testUppercase,"    @Test
    public void testUppercase() {
        for (String field : fields) {
            Assert.assertEquals(field.toUpperCase(), StringUtil.convertByStyle(field, Style.uppercase));
        }
    }
",non-flaky,5
76708,quarkusio_quarkus,CharacterSetSupportITCase.testFieldAndGetterReflectionOnEntityFromServlet,"    @Test
    public void testFieldAndGetterReflectionOnEntityFromServlet() throws Exception {
        RestAssured.when().get(""/core/charsetsupport"").then()
                .body(is(""OK""));
    }
",non-flaky,5
156065,jReddit_jReddit,RedditOAuthAgentTest.testTokenOAuthProblemException,"    @Test(expected=RedditOAuthException.class)
    public void testTokenOAuthProblemException() throws OAuthSystemException, OAuthProblemException, RedditOAuthException {
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenThrow(OAuthProblemException.error(""Error""));
        subject.token(code);
    }
",non-flaky,5
98049,vert-x3_vertx-mongo-client,GridFsTest.testBigFileUpload,"  @Test
  public void testBigFileUpload() {
    String originalFileName = createTempFileWithContent((1024 * 50) + 16);
    long originalLength = new File(originalFileName).length();
    String copiedFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(originalFileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<Long> downloadPromise = Promise.promise();
      gridFsClient.get().downloadFileAs(originalFileName, copiedFileName, downloadPromise);
      return downloadPromise.future();
    }).compose(length -> {
      assertEquals(originalLength, length.longValue());
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      } else {
        testComplete();
      }
    });
    await();
  }
",non-flaky,5
33,apache_kafka,shouldTogglePrepareForBulkLoadDuringRestoreCalls,"@Test
public void shouldTogglePrepareForBulkLoadDuringRestoreCalls() throws Exception {
    final List<KeyValue<byte[], byte[]>> entries = new ArrayList<>();
    entries.add(new KeyValue<>(""1"".getBytes(""UTF-8""), ""a"".getBytes(""UTF-8"")));
    entries.add(new KeyValue<>(""2"".getBytes(""UTF-8""), ""b"".getBytes(""UTF-8"")));
    entries.add(new KeyValue<>(""3"".getBytes(""UTF-8""), ""c"".getBytes(""UTF-8"")));
    final AtomicReference<Exception> conditionNotMet = new AtomicReference<>();
    final AtomicInteger conditionCheckCount = new AtomicInteger();
    Thread conditionCheckThread = new Thread(new Runnable() {
        @Override
        public void run() {
            assertRocksDBTurnsOnBulkLoading(conditionCheckCount, conditionNotMet);
            assertRockDBTurnsOffBulkLoad(conditionCheckCount, conditionNotMet);
        }
    });
    subject.init(context, subject);
    conditionCheckThread.start();
    context.restore(subject.name(), entries);
    conditionCheckThread.join(2000);
    assertTrue(conditionNotMet.get() == null);
    assertTrue(conditionCheckCount.get() == 2);
}",concurrency,1
96104,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testCanWriteReadWriteReadLargeFile,"  @Test
  public void testCanWriteReadWriteReadLargeFile() {
    try {
      AnnotationSerializer serializer = new ProtobufAnnotationSerializer();
      // Write
      StanfordCoreNLP pipe = new StanfordCoreNLP(new Properties());
      Annotation doc = pipe.process(prideAndPrejudiceChapters1to5);

      ByteArrayOutputStream ks = new ByteArrayOutputStream();
      serializer.write(doc, ks).close();

      // Read
      InputStream kis = new ByteArrayInputStream(ks.toByteArray());
      Pair<Annotation, InputStream> pair1 = serializer.read(kis);
      pair1.second.close();
      Annotation readDoc = pair1.first;
      kis.close();

      for (int i = 0 ; i < doc.get(CoreAnnotations.MentionsAnnotation.class).size() ; i++) {
        CoreMap cm1 = doc.get(CoreAnnotations.MentionsAnnotation.class).get(i);
        CoreMap cm2 = readDoc.get(CoreAnnotations.MentionsAnnotation.class).get(i);
        diffCoreMaps(i,cm1,cm2);
      }

      sameAsRead(doc, readDoc);

      // Write 2
      ByteArrayOutputStream ks2 = new ByteArrayOutputStream();
      serializer.write(readDoc, ks2).close();

      // Read 2
      InputStream kis2 = new ByteArrayInputStream(ks2.toByteArray());
      Pair<Annotation, InputStream> pair = serializer.read(kis2);
      pair.second.close();
      Annotation readDoc2 = pair.first;
      kis2.close();

      sameAsRead(readDoc, readDoc2);
      sameAsRead(doc, readDoc2);
    } catch (Exception e) {
      throw new RuntimeException(e);
    }
  }
",non-flaky,5
170525,eclipse_jetty.project,TestAnnotationConfiguration.testRelativeOrderingWithSCIs,"    @Test
    public void testRelativeOrderingWithSCIs() throws Exception
    {
        // test a 3.1 webapp with RELATIVE ORDERING loads sci from
        // equivalent of WEB-INF/classes first as well as container path

        ClassLoader old = Thread.currentThread().getContextClassLoader();

        File orderedFragmentJar = new File(jarDir, ""test-sci-with-ordering.jar"");
        assertTrue(orderedFragmentJar.exists());
        URLClassLoader orderedLoader = new URLClassLoader(new URL[]{
            orderedFragmentJar.toURI().toURL(), testSciJar.toURI().toURL(),
            targetClasses.getURI().toURL(), webInfClasses.getURI().toURL()
        },
            containerLoader);
        Thread.currentThread().setContextClassLoader(orderedLoader);

        try
        {
            AnnotationConfiguration config = new AnnotationConfiguration();
            WebAppContext context = new WebAppContext();
            List<ServletContainerInitializer> scis;
            context.setClassLoader(orderedLoader);
            context.getMetaData().setWebDescriptor(new WebDescriptor(Resource.newResource(web31true)));
            RelativeOrdering ordering = new RelativeOrdering(context.getMetaData());
            context.getMetaData().setOrdering(ordering);
            context.getMetaData().addWebInfResource(Resource.newResource(orderedFragmentJar.toURI().toURL()));
            context.getMetaData().addWebInfResource(Resource.newResource(testSciJar.toURI().toURL()));
            context.getMetaData().setWebInfClassesResources(classes);
            context.getMetaData().orderFragments();
            context.getServletContext().setEffectiveMajorVersion(3);
            context.getServletContext().setEffectiveMinorVersion(1);
            scis = config.getNonExcludedInitializers(context);
            assertNotNull(scis);
            assertEquals(4, scis.size());
            assertEquals(""com.acme.ServerServletContainerInitializer"", scis.get(0).getClass().getName()); //container path
            assertEquals(""com.acme.webinf.WebInfClassServletContainerInitializer"", scis.get(1).getClass().getName()); // web-inf
            assertEquals(""com.acme.ordering.AcmeServletContainerInitializer"", scis.get(2).getClass().getName()); // first
            assertEquals(""com.acme.initializer.FooInitializer"", scis.get(3).getClass().getName()); //other in ordering
        }
        finally
        {
            Thread.currentThread().setContextClassLoader(old);
        }
    }
",non-flaky,5
38224,palantir_atlasdb,TextUtilsTest.testMaximalPrefix,"    @Test
    public void testMaximalPrefix() throws Exception{
        ArrayList<String> list1 = new ArrayList<String>(7);
        list1.add(""abcdef"");
        list1.add(""abcdefg"");
        list1.add(""abcdefgh"");
        list1.add(""abcd"");
        list1.add(""abcdefl58a"");
        list1.add(""abcdeeeeee"");
        list1.add(""abcde888"");
        assertEquals(""Wrong maximal prefix"",""abcd"",TextUtils.findMaximalPrefix(list1));

        list1.clear();
        assertEquals(""Should be empty string"","""",TextUtils.findMaximalPrefix(list1));
        assertEquals(""Should be empty string"","""",TextUtils.findMaximalPrefix(null));

        list1.add(""abcd"");
        assertEquals(""Should be abcd"",""abcd"",TextUtils.findMaximalPrefix(list1));
        list1.add(""efgh"");
        list1.add(""ifht"");

        assertEquals(""Should be empty string"","""",TextUtils.findMaximalPrefix(list1));
    }
",non-flaky,5
110891,pushtorefresh_storio,InterceptorTest.putContentValues,"    @Test
    public void putContentValues() {
        storIOSQLite.put()
                .contentValues(createContentValues())
                .withPutResolver(createCVPutResolver())
                .prepare()
                .executeAsBlocking();
        checkInterceptorsCalls();
    }
",non-flaky,5
96956,apache_avro,TestAvroSerialization.testGetSerializerForValue,"  @Test
  public void testGetSerializerForValue() throws IOException {
    // Set the writer schema in the job configuration.
    Schema writerSchema = Schema.create(Schema.Type.STRING);
    Job job = new Job();
    AvroJob.setMapOutputValueSchema(job, writerSchema);

    // Get a serializer from the configuration.
    AvroSerialization serialization
        = ReflectionUtils.newInstance(AvroSerialization.class, job.getConfiguration());
    @SuppressWarnings(""unchecked"")
    Serializer<AvroWrapper> serializer = serialization.getSerializer(AvroValue.class);
    assertTrue(serializer instanceof AvroSerializer);
    AvroSerializer avroSerializer = (AvroSerializer) serializer;

    // Check that the writer schema is set correctly on the serializer.
    assertEquals(writerSchema, avroSerializer.getWriterSchema());
  }
",non-flaky,5
113939,spring-projects_spring-data-couchbase,StringN1qlQueryCreatorMockedTests.beforeEach,"	@BeforeEach
	public void beforeEach() {
		context = new CouchbaseMappingContext();
		converter = new MappingCouchbaseConverter(context);
		ApplicationContext ac = new AnnotationConfigApplicationContext(Config.class);
		couchbaseTemplate = (CouchbaseTemplate) ac.getBean(COUCHBASE_TEMPLATE);
	}
",non-flaky,5
98339,Kong_unirest-java,AssertTest.expectAnyPath,"    @Test
    public void expectAnyPath(){
        client.expect(HttpMethod.GET)
                .thenReturn(""woh"");

        Unirest.get(path).asEmpty();

        client.verifyAll();
    }
",non-flaky,5
175834,GoogleCloudPlatform_google-cloud-eclipse,BucketNameValidatorTest.testValidation_validNameWithDot,"  @Test
  public void testValidation_validNameWithDot() {
    assertThat(validator.validate(LENGTH_64_WITH_DOT).getSeverity(), is(IStatus.OK));
  }
",non-flaky,5
177250,line_armeria,DnsAddressEndpointGroupTest.noPort,"    @Test
    public void noPort() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                new DefaultDnsQuestion(""no-port.com."", A),
                new DefaultDnsResponse(0).addRecord(ANSWER, newAddressRecord(""no-port.com"", ""1.1.1.1""))
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""no-port.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_ONLY)
                                                .build()) {

                assertThat(group.whenReady().get()).containsExactly(
                        Endpoint.of(""no-port.com"").withIpAddr(""1.1.1.1""));
            }
        }
    }
",non-flaky,5
150185,apache_hive,TestHplsqlLocal.testSetError,"  @Test
  public void testSetError() throws Exception {
    run(""seterror"");
  }
",non-flaky,5
179445,abel533_Mapper,AggregationMapperTest.testMin,"    @Test
    public void testMin() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper mapper = sqlSession.getMapper(UserMapper.class);
            AggregateCondition aggregateCondition = AggregateCondition.builder().
                    aggregateBy(""id"").aliasName(""aggregation"").aggregateType(AggregateType.MIN);
            Example example = new Example(User.class);
            List<User> m = mapper.selectAggregationByExample(example, aggregateCondition);
            Assert.assertEquals(1, m.size());
            Assert.assertEquals(new Long(1), m.get(0).getAggregation());
        } finally {
            sqlSession.close();
        }
    }
",non-flaky,5
110153,Wikidata_wikidata-toolkit,NestedIteratorTest.iterateBeyondInnerList,"	@Test(expected = NoSuchElementException.class)
	public void iterateBeyondInnerList() {
		NestedIterator<String> nestedIterator = new NestedIterator<>(
				Collections.singletonList(Collections.<String> emptyList()));
		nestedIterator.next();
	}
",non-flaky,5
159639,liquibase_liquibase,AbstractIntegrationTest.testDatabaseIsReachableIfRequired,"    @Test
    public void testDatabaseIsReachableIfRequired() {
        if (isDatabaseProvidedByTravisCI()) {
            assertNotNull(
                    ""This integration test is expected to pass on Travis CI.\n"" +
                            ""If you are running on a dev machine and do not have the required\n"" +
                            ""database installed, you may choose to ignore this failed test.\n"" +
                            ""To run this test on a dev machine, you will need to install the corresponding\n"" +
                            ""database and configure liquibase.integrationtest.local.properties"",
                    getDatabase());
        } else {
            assumeNotNull(this.getDatabase());
        }
    }
",non-flaky,5
30925,camunda-cloud_zeebe,MsgPackWriterTest.testWriteMessage,"  @Test
  public void testWriteMessage() throws Exception {
    // given
    final MsgPackWriter writer = new MsgPackWriter();
    writer.wrap(actualValueBuffer, WRITE_OFFSET);

    final ByteArrayBuilder builder = new ByteArrayBuilder();
    expectedValueWriter.accept(builder);
    final byte[] expectedValue = builder.value;

    // when
    actualValueWriter.accept(writer);

    // then
    assertThat(writer.getOffset()).isEqualTo(WRITE_OFFSET + expectedValue.length);
    assertThatBuffer(actualValueBuffer).hasBytes(expectedValue, WRITE_OFFSET);
  }
",non-flaky,5
57205,apache_ozone,TestNSSummaryTask.testProcess,"  @Test
  public void testProcess() throws Exception {
    NSSummary nonExistentSummary =
            reconNamespaceSummaryManager.getNSSummary(BUCKET_ONE_OBJECT_ID);
    Assert.assertNull(nonExistentSummary);

    populateOMDB();

    // Events for keyTable change:
    // put file5 under bucket 2
    String omPutKey = BUCKET_TWO_OBJECT_ID + OM_KEY_PREFIX + FILE_FIVE;
    OmKeyInfo omPutKeyInfo = buildOmKeyInfo(VOL, BUCKET_TWO, KEY_FIVE,
            FILE_FIVE, KEY_FIVE_OBJECT_ID, BUCKET_TWO_OBJECT_ID, KEY_FIVE_SIZE);
    OMDBUpdateEvent keyEvent1 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmKeyInfo>()
            .setKey(omPutKey)
            .setValue(omPutKeyInfo)
            .setTable(omMetadataManager.getKeyTable(getBucketLayout())
            .getName())
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.PUT)
            .build();

    // delete file 1 under bucket 1
    String omDeleteKey = BUCKET_ONE_OBJECT_ID + OM_KEY_PREFIX + FILE_ONE;
    OmKeyInfo omDeleteInfo = buildOmKeyInfo(VOL, BUCKET_ONE, KEY_ONE, FILE_ONE,
            KEY_ONE_OBJECT_ID, BUCKET_ONE_OBJECT_ID);
    OMDBUpdateEvent keyEvent2 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmKeyInfo>()
            .setKey(omDeleteKey)
            .setValue(omDeleteInfo)
            .setTable(omMetadataManager.getKeyTable(getBucketLayout())
            .getName())
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.DELETE)
            .build();

    // update file 2's size under bucket 2
    String omUpdateKey = BUCKET_TWO_OBJECT_ID + OM_KEY_PREFIX + FILE_TWO;
    OmKeyInfo omOldInfo = buildOmKeyInfo(VOL, BUCKET_TWO, KEY_TWO, FILE_TWO,
            KEY_TWO_OBJECT_ID, BUCKET_TWO_OBJECT_ID, KEY_TWO_OLD_SIZE);
    OmKeyInfo omUpdateInfo = buildOmKeyInfo(VOL, BUCKET_TWO, KEY_TWO, FILE_TWO,
            KEY_TWO_OBJECT_ID, BUCKET_TWO_OBJECT_ID, KEY_TWO_UPDATE_SIZE);
    OMDBUpdateEvent keyEvent3 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmKeyInfo>()
            .setKey(omUpdateKey)
            .setValue(omUpdateInfo)
            .setOldValue(omOldInfo)
            .setTable(omMetadataManager.getKeyTable(getBucketLayout())
            .getName())
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.UPDATE)
            .build();

    // Events for DirectoryTable change:
    // add dir 4 under bucket 1
    String omDirPutKey1 = BUCKET_ONE_OBJECT_ID + OM_KEY_PREFIX + DIR_FOUR;
    OmDirectoryInfo omDirPutValue1 = buildOmDirInfo(DIR_FOUR,
            DIR_FOUR_OBJECT_ID, BUCKET_ONE_OBJECT_ID);
    OMDBUpdateEvent keyEvent4 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmDirectoryInfo>()
            .setKey(omDirPutKey1)
            .setValue(omDirPutValue1)
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.PUT)
            .setTable(omMetadataManager.getDirectoryTable().getName())
            .build();

    // add dir 5 under bucket 2
    String omDirPutKey2 = BUCKET_TWO_OBJECT_ID + OM_KEY_PREFIX + DIR_FIVE;
    OmDirectoryInfo omDirPutValue2 = buildOmDirInfo(DIR_FIVE,
            DIR_FIVE_OBJECT_ID, BUCKET_TWO_OBJECT_ID);
    OMDBUpdateEvent keyEvent5 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmDirectoryInfo>()
            .setKey(omDirPutKey2)
            .setValue(omDirPutValue2)
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.PUT)
            .setTable(omMetadataManager.getDirectoryTable().getName())
            .build();

    // delete dir 3 under dir 1
    String omDirDeleteKey = DIR_ONE_OBJECT_ID + OM_KEY_PREFIX + DIR_THREE;
    OmDirectoryInfo omDirDeleteValue = buildOmDirInfo(DIR_FIVE,
            DIR_THREE_OBJECT_ID, DIR_ONE_OBJECT_ID);
    OMDBUpdateEvent keyEvent6 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmDirectoryInfo>()
            .setKey(omDirDeleteKey)
            .setValue(omDirDeleteValue)
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.DELETE)
            .setTable(omMetadataManager.getDirectoryTable().getName())
            .build();

    // rename dir1
    String omDirUpdateKey = BUCKET_ONE_OBJECT_ID + OM_KEY_PREFIX + DIR_ONE;
    OmDirectoryInfo omDirOldValue = buildOmDirInfo(DIR_ONE,
            DIR_ONE_OBJECT_ID, BUCKET_ONE_OBJECT_ID);
    OmDirectoryInfo omDirUpdateValue = buildOmDirInfo(DIR_ONE_RENAME,
            DIR_ONE_OBJECT_ID, BUCKET_ONE_OBJECT_ID);
    OMDBUpdateEvent keyEvent7 = new OMDBUpdateEvent.
            OMUpdateEventBuilder<String, OmDirectoryInfo>()
            .setKey(omDirUpdateKey)
            .setValue(omDirUpdateValue)
            .setOldValue(omDirOldValue)
            .setAction(OMDBUpdateEvent.OMDBUpdateAction.UPDATE)
            .setTable(omMetadataManager.getDirectoryTable().getName())
            .build();

    OMUpdateEventBatch omUpdateEventBatch = new OMUpdateEventBatch(
            new ArrayList<OMDBUpdateEvent>() {{
              add(keyEvent1);
              add(keyEvent2);
              add(keyEvent3);
              add(keyEvent4);
              add(keyEvent5);
              add(keyEvent6);
              add(keyEvent7);
          }});

    NSSummaryTask nsSummaryTask = new NSSummaryTask(
            reconNamespaceSummaryManager);
    nsSummaryTask.reprocess(reconOMMetadataManager);
    nsSummaryTask.process(omUpdateEventBatch);

    // file 5 is added under bucket 2, so bucket 2 has 3 keys now
    // file 1 is gone, so bucket 1 is empty now
    // file 2 is updated with new datasize,
    // so file size dist for bucket 2 should be updated
    NSSummary nsSummaryForBucket1 =
            reconNamespaceSummaryManager.getNSSummary(BUCKET_ONE_OBJECT_ID);
    Assert.assertNotNull(nsSummaryForBucket1);
    Assert.assertEquals(0, nsSummaryForBucket1.getNumOfFiles());

    Set<Long> childDirBucket1 = nsSummaryForBucket1.getChildDir();
    // after put dir4, bucket1 now has two child dirs: dir1 and dir4
    Assert.assertEquals(2, childDirBucket1.size());
    bucketOneAns.clear();
    bucketOneAns.add(DIR_ONE_OBJECT_ID);
    bucketOneAns.add(DIR_FOUR_OBJECT_ID);
    Assert.assertEquals(bucketOneAns, childDirBucket1);

    NSSummary nsSummaryForBucket2 =
            reconNamespaceSummaryManager.getNSSummary(BUCKET_TWO_OBJECT_ID);
    Assert.assertNotNull(nsSummaryForBucket2);
    Assert.assertEquals(3, nsSummaryForBucket2.getNumOfFiles());
    // key 4 + key 5 + updated key 2
    Assert.assertEquals(KEY_FOUR_SIZE + KEY_FIVE_SIZE + KEY_TWO_UPDATE_SIZE,
            nsSummaryForBucket2.getSizeOfFiles());

    int[] fileSizeDist = nsSummaryForBucket2.getFileSizeBucket();
    Assert.assertEquals(ReconConstants.NUM_OF_BINS, fileSizeDist.length);
    // 1023L and 100L
    Assert.assertEquals(2, fileSizeDist[0]);
    // 2050L
    Assert.assertEquals(1, fileSizeDist[2]);
    for (int i = 0; i < ReconConstants.NUM_OF_BINS; ++i) {
      if (i == 0 || i == 2) {
        continue;
      }
      Assert.assertEquals(0, fileSizeDist[i]);
    }

    // after put dir5, bucket 2 now has one dir
    Set<Long> childDirBucket2 = nsSummaryForBucket2.getChildDir();
    Assert.assertEquals(1, childDirBucket2.size());
    bucketTwoAns.add(DIR_FIVE_OBJECT_ID);
    Assert.assertEquals(bucketTwoAns, childDirBucket2);

    // after delete dir 3, dir 1 now has only one dir: dir2
    NSSummary nsSummaryForDir1 = reconNamespaceSummaryManager
            .getNSSummary(DIR_ONE_OBJECT_ID);
    Assert.assertNotNull(nsSummaryForDir1);
    Set<Long> childDirForDir1 = nsSummaryForDir1.getChildDir();
    Assert.assertEquals(1, childDirForDir1.size());
    dirOneAns.clear();
    dirOneAns.add(DIR_TWO_OBJECT_ID);
    Assert.assertEquals(dirOneAns, childDirForDir1);

    // after renaming dir1, check its new name
    Assert.assertEquals(DIR_ONE_RENAME, nsSummaryForDir1.getDirName());
  }
",non-flaky,5
77431,opensearch-project_OpenSearch,BwcVersionsTests.testExceptionOnTooManyMajors,"    @Test(expected = IllegalStateException.class)
    public void testExceptionOnTooManyMajors() {
        new BwcVersions(
            asList(formatVersionToLine(""5.6.12""), formatVersionToLine(""6.5.0""), formatVersionToLine(""7.0.0"")),
            Version.fromString(""6.5.0"")
        );
    }
",non-flaky,5
57213,apache_ozone,TestReconTaskControllerImpl.testBadBehavedTaskIsIgnored,"  @Test
  public void testBadBehavedTaskIsIgnored() throws Exception {
    String taskName = ""Dummy_"" + System.currentTimeMillis();
    DummyReconDBTask dummyReconDBTask =
        new DummyReconDBTask(taskName, DummyReconDBTask.TaskType.ALWAYS_FAIL);
    reconTaskController.registerTask(dummyReconDBTask);

    OMUpdateEventBatch omUpdateEventBatchMock = mock(OMUpdateEventBatch.class);
    when(omUpdateEventBatchMock.isEmpty()).thenReturn(false);
    when(omUpdateEventBatchMock.getLastSequenceNumber()).thenReturn(100L);

    OMMetadataManager omMetadataManagerMock = mock(OMMetadataManager.class);
    for (int i = 0; i < 2; i++) {
      reconTaskController.consumeOMEvents(omUpdateEventBatchMock,
          omMetadataManagerMock);

      assertFalse(reconTaskController.getRegisteredTasks().isEmpty());
      assertEquals(dummyReconDBTask, reconTaskController.getRegisteredTasks()
          .get(dummyReconDBTask.getTaskName()));
    }

    //Should be ignored now.
    reconTaskController.consumeOMEvents(omUpdateEventBatchMock,
        omMetadataManagerMock);
    assertTrue(reconTaskController.getRegisteredTasks().isEmpty());

    reconTaskStatusDao = getDao(ReconTaskStatusDao.class);
    ReconTaskStatus dbRecord = reconTaskStatusDao.findById(taskName);

    Assert.assertEquals(taskName, dbRecord.getTaskName());
    Assert.assertEquals(Long.valueOf(0L), dbRecord.getLastUpdatedTimestamp());
    Assert.assertEquals(Long.valueOf(0L), dbRecord.getLastUpdatedSeqNumber());
  }
",non-flaky,5
77157,networknt_json-schema-validator,V4JsonSchemaTest.testMinLengthValidator,"    @Test
    public void testMinLengthValidator() throws Exception {
        runTestFile(""draft4/minLength.json"");
    }
",non-flaky,5
197,apache_pulsar,PrometheusMetricsTest.testPerTopicStats,"@Test
public void testPerTopicStats() throws Exception {
    String randSeed = randomName(16);
    System.out.println(""The randSeed of testPerTopicStats() is: "" + randSeed);
    Producer<byte[]> p1 = pulsarClient.newProducer().topic(""persistent://my-property/use/"" + randSeed + ""/my-topic1"").create();
    Producer<byte[]> p2 = pulsarClient.newProducer().topic(""persistent://my-property/use/"" + randSeed + ""/my-topic2"").create();
    for (int i = 0; i < 10; i++) {
        String message = ""my-message-"" + i;
        p1.send(message.getBytes());
        p2.send(message.getBytes());
    }
    ByteArrayOutputStream statsOut = new ByteArrayOutputStream();
    PrometheusMetricsGenerator.generate(pulsar, true, false, statsOut);
    String metricsStr = new String(statsOut.toByteArray());
    Multimap<String, Metric> metrics = parseMetrics(metricsStr);
    metrics.entries().forEach(e -> {
        System.out.println(e.getKey() + "": "" + e.getValue());
    });
    List<Metric> cm = (List<Metric>) metrics.get(""pulsar_storage_write_latency_le_1"");
    List<Metric> matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList());
    int positionOfTopic1;
    int positionOfTopic2;
    if(cm.get(0).tags.get(""topic"").equals(""persistent://my-property/use/"" + randSeed + ""/my-topic1"")) {
        positionOfTopic1 = 0;
        positionOfTopic2 = 1;
    } else {
        positionOfTopic2 = 0;
        positionOfTopic1 = 1;
    }
    matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList());
    if(matchingMetrics.size() > 2){
        System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). First check. Debug entries: "");
        matchingMetrics.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":""  + kv.getValue())));
    }
    assertEquals(matchingMetrics.size(), 2);
    assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic2"");
    assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""namespace""), ""my-property/use/"" + randSeed);
    assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic1"");
    assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""namespace""), ""my-property/use/"" + randSeed);
    cm = (List<Metric>) metrics.get(""pulsar_producers_count"");
    if(cm.get(1).tags.get(""topic"").equals(""persistent://my-property/use/"" + randSeed + ""/my-topic1"")) {
        positionOfTopic1 = 1;
        positionOfTopic2 = 2;
    } else {
        positionOfTopic2 = 1;
        positionOfTopic1 = 2;
    }
    matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList());
    if(matchingMetrics.size() > 2){
        System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Second check. Debug entries: "");
        matchingMetrics.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":""  + kv.getValue())));
    }
    assertEquals(matchingMetrics.size(), 2);
    assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic2"");
    assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""namespace""), ""my-property/use/"" + randSeed);
    assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic1"");
    assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""namespace""), ""my-property/use/"" + randSeed);
    cm = (List<Metric>) metrics.get(""topic_load_times_count"");
    if(cm.size() > 1){
        System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Third check. Debug entries: "");
        cm.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":""  + kv.getValue())));
    }
    assertEquals(cm.size(), 1);
    assertEquals(cm.get(0).tags.get(""cluster""), ""test"");
    cm = (List<Metric>) metrics.get(""pulsar_in_bytes_total"");
    if(cm.get(0).tags.get(""topic"").equals(""persistent://my-property/use/"" + randSeed + ""/my-topic1"")) {
        positionOfTopic1 = 0;
        positionOfTopic2 = 1;
    } else {
        positionOfTopic2 = 0;
        positionOfTopic1 = 1;
    }
    matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList());
    if(matchingMetrics.size() > 2){
        System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Fourth check. Debug entries: "");
        matchingMetrics.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":""  + kv.getValue())));
    }
    assertEquals(matchingMetrics.size(), 2);
    assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic2"");
    assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""namespace""), ""my-property/use/"" + randSeed);
    assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic1"");
    assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""namespace""), ""my-property/use/"" + randSeed);
    cm = (List<Metric>) metrics.get(""pulsar_in_messages_total"");
    if(cm.get(0).tags.get(""topic"").equals(""persistent://my-property/use/"" + randSeed + ""/my-topic1"")) {
        positionOfTopic1 = 0;
        positionOfTopic2 = 1;
    } else {
        positionOfTopic2 = 0;
        positionOfTopic1 = 1;
    }
    matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList());
    if(matchingMetrics.size() > 2){
        System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Fifth check. Debug entries: "");
        matchingMetrics.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":""  + kv.getValue())));
    }
    assertEquals(matchingMetrics.size(), 2);
    assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic2"");
    assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""namespace""), ""my-property/use/"" + randSeed);
    assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic1"");
    assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""namespace""), ""my-property/use/"" + randSeed);
    p1.close();
    p2.close();
}",concurrency,1
135030,undertow-io_undertow,DateUtilsTestCase.testParseFirefoxDate,"    @Test
    public void testParseFirefoxDate() {

        String firefoxHeader = ""Mon, 31 Mar 2014 09:24:49 GMT"";
        Date firefoxDate = DateUtils.parseDate(firefoxHeader);

        Assert.assertNotNull(firefoxDate);

        Calendar calendar = Calendar.getInstance(TimeZone.getTimeZone(""GMT""));
        calendar.set(2014, Calendar.MARCH, 31, 9, 24, 49);
        calendar.set(Calendar.MILLISECOND, 0);

        Assert.assertEquals(calendar.getTime(), firefoxDate);


    }
",non-flaky,5
110851,pushtorefresh_storio,QueryTest.querySingleLimit,"    @Test
    public void querySingleLimit() {
        putUsersBlocking(10);

        final int limit = 8;
        final List<User> usersFromQuery = storIOSQLite
                .get()
                .listOfObjects(User.class)
                .withQuery(Query.builder()
                        .table(UserTableMeta.TABLE)
                        .limit(String.valueOf(limit))
                        .build())
                .prepare()
                .executeAsBlocking();

        assertThat(usersFromQuery).isNotNull();
        assertThat(usersFromQuery).hasSize(limit);
    }
",non-flaky,5
122570,vespa-engine_vespa,DiskSizeTest.bytes_to_display_count_test,"    @Test
    public void bytes_to_display_count_test() {
        assertEquals(""-1 bytes"", DiskSize.of(-1).asString());
        assertEquals(""123 bytes"", DiskSize.of(123).asString());
        assertEquals(""1 kB"", DiskSize.of(1_000).asString());
        assertEquals(""15 MB"", DiskSize.of(15_000_000).asString());
        assertEquals(""123 GB"", DiskSize.of(123_456_789_012L).asString());
        assertEquals(""988 TB"", DiskSize.of(987_654_321_098_765L).asString());
        assertEquals(""987.7 TB"", DiskSize.of(987_654_321_098_765L).asString(1));
        assertEquals(""987.65 TB"", DiskSize.of(987_654_321_098_765L).asString(2));
        assertEquals(""2 PB"", DiskSize.of(2_000_000_000_000_000L).asString());
        assertEquals(""9 EB"", DiskSize.of(Long.MAX_VALUE).asString());
    }
",non-flaky,5
114067,aws_aws-sdk-java-v2,EnhancedTypeTest.collectionOf_ReturnsRawClassOfCollection_WhenSpecifyingEnhancedType,"    @Test
    public void collectionOf_ReturnsRawClassOfCollection_WhenSpecifyingEnhancedType() {
        EnhancedType<Collection<String>> type = EnhancedType.collectionOf(EnhancedType.of(String.class));

        assertThat(type.rawClass()).isEqualTo(Collection.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
43125,trinodb_trino,BaseConnectorSmokeTest.testCreateSchema,"    @Test
    public void testCreateSchema()
    {
        String schemaName = ""test_schema_create_"" + randomTableSuffix();
        if (!hasBehavior(SUPPORTS_CREATE_SCHEMA)) {
            assertQueryFails(""CREATE SCHEMA "" + schemaName, ""This connector does not support creating schemas"");
            return;
        }

        assertUpdate(""CREATE SCHEMA "" + schemaName);
        assertThat(query(""SHOW SCHEMAS""))
                .skippingTypesCheck()
                .containsAll(format(""VALUES '%s', '%s'"", getSession().getSchema().orElseThrow(), schemaName));
        assertUpdate(""DROP SCHEMA "" + schemaName);
    }
",non-flaky,5
301,apache_hadoop,TestFairScheduler.testContinuousScheduling,"@Test
public void testContinuousScheduling() throws Exception {
    FairScheduler fs = new FairScheduler();
    Configuration conf = createConfiguration();
    conf.setBoolean(CONTINUOUS_SCHEDULING_ENABLED, true);
    fs.reinitialize(conf, resourceManager.getRMContext());
    Assert.assertTrue(""Continuous scheduling should be enabled."", fs.isContinuousSchedulingEnabled());
    RMNode node1 = MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1, ""127.0.0.1"");
    NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
    fs.handle(nodeEvent1);
    Assert.assertEquals(fs.getClusterCapacity().getMemory(), 8 * 1024);
    Assert.assertEquals(fs.getClusterCapacity().getVirtualCores(), 8);
    ApplicationAttemptId appAttemptId = createAppAttemptId(this.APP_ID++, this.ATTEMPT_ID++);
    fs.addApplication(appAttemptId, ""queue11"", ""user11"");
    List<ResourceRequest> ask = new ArrayList<ResourceRequest>();
    ResourceRequest request = createResourceRequest(1024, 1, ANY, 1, 1, true);
    ask.add(request);
    fs.allocate(appAttemptId, ask, new ArrayList<ContainerId>(), null, null);
    Thread.sleep(fs.getConf().getContinuousSchedulingSleepMs() + 500);
    Resource consumption = fs.applications.get(appAttemptId).getCurrentConsumption();
    Assert.assertEquals(1024, consumption.getMemory());
    Assert.assertEquals(1, consumption.getVirtualCores());
}",async wait,0
35707,cdapio_cdap,TestFileLogging.testGetLog,"  @Test
  public void testGetLog() throws Exception {
    // LogReader.getLog is tested in LogSaverTest for distributed mode
    LoggingContext loggingContext = new WorkerLoggingContext(""TFL_NS_1"", ""APP_1"", ""WORKER_1"", ""RUN1"", ""INSTANCE1"");
    FileLogReader logTail = injector.getInstance(FileLogReader.class);
    LoggingTester.LogCallback logCallback1 = new LoggingTester.LogCallback();
    logTail.getLogPrev(loggingContext, ReadRange.LATEST, 60, Filter.EMPTY_FILTER,
                       logCallback1);
    List<LogEvent> allEvents = logCallback1.getEvents();
    Assert.assertEquals(60, allEvents.size());

    List<LogEvent> events =
      Lists.newArrayList(logTail.getLog(loggingContext, allEvents.get(10).getLoggingEvent().getTimeStamp(),
                                        allEvents.get(15).getLoggingEvent().getTimeStamp(), Filter.EMPTY_FILTER));

    Assert.assertEquals(5, events.size());
    Assert.assertEquals(allEvents.get(10).getLoggingEvent().getFormattedMessage(),
                        events.get(0).getLoggingEvent().getFormattedMessage());
    Assert.assertEquals(allEvents.get(14).getLoggingEvent().getFormattedMessage(),
                        events.get(4).getLoggingEvent().getFormattedMessage());


    events =
      Lists.newArrayList(logTail.getLog(loggingContext, allEvents.get(0).getLoggingEvent().getTimeStamp(),
                                        allEvents.get(59).getLoggingEvent().getTimeStamp(), Filter.EMPTY_FILTER));
    Assert.assertEquals(59, events.size());
    Assert.assertEquals(allEvents.get(0).getLoggingEvent().getFormattedMessage(),
                        events.get(0).getLoggingEvent().getFormattedMessage());
    Assert.assertEquals(allEvents.get(58).getLoggingEvent().getFormattedMessage(),
                        events.get(58).getLoggingEvent().getFormattedMessage());

    events =
      Lists.newArrayList(logTail.getLog(loggingContext, allEvents.get(12).getLoggingEvent().getTimeStamp(),
                                        allEvents.get(41).getLoggingEvent().getTimeStamp(), Filter.EMPTY_FILTER));
    Assert.assertEquals(29, events.size());
    Assert.assertEquals(allEvents.get(12).getLoggingEvent().getFormattedMessage(),
                        events.get(0).getLoggingEvent().getFormattedMessage());
    Assert.assertEquals(allEvents.get(40).getLoggingEvent().getFormattedMessage(),
                        events.get(28).getLoggingEvent().getFormattedMessage());

    events =
      Lists.newArrayList(logTail.getLog(loggingContext, allEvents.get(22).getLoggingEvent().getTimeStamp(),
                                        allEvents.get(38).getLoggingEvent().getTimeStamp(), Filter.EMPTY_FILTER));
    Assert.assertEquals(16, events.size());
    Assert.assertEquals(allEvents.get(22).getLoggingEvent().getFormattedMessage(),
                        events.get(0).getLoggingEvent().getFormattedMessage());
    Assert.assertEquals(allEvents.get(37).getLoggingEvent().getFormattedMessage(),
                        events.get(15).getLoggingEvent().getFormattedMessage());

    events =
      Lists.newArrayList(logTail.getLog(loggingContext, allEvents.get(41).getLoggingEvent().getTimeStamp(),
                                        allEvents.get(59).getLoggingEvent().getTimeStamp(), Filter.EMPTY_FILTER));
    Assert.assertEquals(18, events.size());
    Assert.assertEquals(allEvents.get(41).getLoggingEvent().getFormattedMessage(),
                        events.get(0).getLoggingEvent().getFormattedMessage());
    Assert.assertEquals(allEvents.get(58).getLoggingEvent().getFormattedMessage(),
                        events.get(17).getLoggingEvent().getFormattedMessage());

    // Try with null run id, should get all logs for WORKER_1
    LoggingContext loggingContext1 = new WorkerLoggingContext(""TFL_NS_1"", ""APP_1"", ""WORKER_1"", null, ""INSTANCE1"");
    events =
      Lists.newArrayList(logTail.getLog(loggingContext1, 0, Long.MAX_VALUE, Filter.EMPTY_FILTER));
    Assert.assertEquals(120, events.size());
  }
",non-flaky,5
110148,Wikidata_wikidata-toolkit,ClientConfigurationTest.testPropertyFilterArgumentsEmpty,"	@Test
	public void testPropertyFilterArgumentsEmpty() {
		String[] args = new String[] { ""--fProp"", ""-"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<PropertyIdValue> propFilters = new HashSet<>();

		assertEquals(propFilters, config.getFilterProperties());
	}
",non-flaky,5
92705,apache_dubbo,MethodConfigTest.testOnreturnMethod,"    @Test
    public void testOnreturnMethod() throws Exception {
        MethodConfig method = new MethodConfig();
        method.setOnreturnMethod(""on-return-method"");
        assertThat(method.getOnreturnMethod(), equalTo(""on-return-method""));
        Map<Object, Object> attribute = new HashMap<Object, Object>();
        MethodConfig.appendAttributes(attribute, method);
        assertThat(attribute, hasEntry((Object) Constants.ON_RETURN_METHOD_KEY, (Object) ""on-return-method""));
        Map<String, String> parameters = new HashMap<String, String>();
        MethodConfig.appendParameters(parameters, method);
        assertThat(parameters.size(), is(0));
    }
",non-flaky,5
92641,apache_dubbo,ApplicationConfigTest.testParameters,"    @Test
    public void testParameters() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setQosAcceptForeignIp(true);
        Map<String, String> parameters = new HashMap<String, String>();
        parameters.put(""k1"", ""v1"");
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(""k1"", ""v1""));
        assertThat(parameters, hasEntry(Constants.ACCEPT_FOREIGN_IP, ""true""));
    }
",non-flaky,5
13922,neo4j_neo4j,ForeignStoreIdIT.nonEmptyForeignDbShouldNotBeAbleToJoin,"    @Test
    public void nonEmptyForeignDbShouldNotBeAbleToJoin() throws Exception
    {
        // GIVEN
        // -- one instance running
        firstInstance = new TestHighlyAvailableGraphDatabaseFactory()
                .newHighlyAvailableDatabaseBuilder( DIR.cleanDirectory( ""1"" ).getAbsolutePath() )
                .setConfig( server_id, ""1"" )
                .setConfig( initial_hosts, ""127.0.0.1:5001"" )
                .setConfig( cluster_server, ""127.0.0.1:5001"" )
                .setConfig( ha_server, ""127.0.0.1:6041"" )
                .newGraphDatabase();
        createNodes( firstInstance, 3, ""first"" );
        // -- another instance preparing to join with a store with a different store ID
        String foreignDbStoreDir = createAnotherStore( DIR.cleanDirectory( ""2"" ), 1 );

        // WHEN
        // -- the other joins
        foreignInstance = new TestHighlyAvailableGraphDatabaseFactory()
                .newHighlyAvailableDatabaseBuilder( foreignDbStoreDir )
                .setConfig( server_id, ""2"" )
                .setConfig( initial_hosts, ""127.0.0.1:5001"" )
                .setConfig( cluster_server, ""127.0.0.1:5002"" )
                .setConfig( ha_server, ""127.0.0.1:6042"" )
                .setConfig( state_switch_timeout, ""5s"" )
                .newGraphDatabase();

        try
        {
            // THEN
            // -- that node should arrive at the master
            createNode( foreignInstance, ""foreigner"" );
            fail( ""Shouldn't be able to create a node, since it shouldn't have joined"" );
        }
        catch ( Exception e )
        {
            // Good
        }
    }
",non-flaky,5
77501,dropwizard_dropwizard,NoAuthPrincipalEntityTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception {
        super.tearDown();
    }
",non-flaky,5
114080,aws_aws-sdk-java-v2,ExpressionTest.joinNames_conflictingKey,"    @Test
    public void joinNames_conflictingKey() {
        Map<String, String> names1 = new HashMap<>();
        names1.put(""one"", ""1"");
        names1.put(""two"", ""2"");
        Map<String, String> names2 = new HashMap<>();
        names2.put(""three"", ""3"");
        names2.put(""two"", ""4"");

        exception.expect(IllegalArgumentException.class);
        exception.expectMessage(""two"");
        Expression.joinNames(names1, names2);
    }
",non-flaky,5
150124,apache_hive,TestHplsqlOffline.testSelect,"  @Test
  public void testSelect() throws Exception {
    run(""select"");
  }
",non-flaky,5
160325,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldReturnEmptyWhenKeyIsAbsent,"    @Test
    public void shouldReturnEmptyWhenKeyIsAbsent() {
      assertThat(propertyReader.readProperty(ABSENT_PROPERTY_KEY), is(emptyString()));
    }
",non-flaky,5
26151,Ericsson_ecchronos,TestRepairManagementRESTImpl.testStatusEntry,"    @Test
    public void testStatusEntry()
    {
        long repairInterval = TimeUnit.DAYS.toMillis(7);
        long lastRepairedAt = System.currentTimeMillis();

        RepairJobView repairJobView = new TestUtils.ScheduledRepairJobBuilder()
                .withKeyspace(""ks"")
                .withTable(""tb"")
                .withLastRepairedAt(lastRepairedAt)
                .withRepairInterval(repairInterval)
                .build();
        ScheduledRepairJob expectedResponse = new ScheduledRepairJob(repairJobView);

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.singletonList(repairJobView));

        List<ScheduledRepairJob> response = GSON.fromJson(repairManagementREST.status(), scheduledRepairJobListType);

        assertThat(response).containsExactly(expectedResponse);
    }
",non-flaky,5
162669,OpenAPITools_openapi-generator,StoreApiTest.getOrderByIdTest,"    @Test
    public void getOrderByIdTest() {
        Long orderId = null;
        //Order response = api.getOrderById(orderId);
        //assertNotNull(response);
        // TODO: test validations
        
        
    }
",non-flaky,5
70778,apache_kafka,ErrorHandlingIntegrationTest.testSkipRetryAndDLQWithHeaders,"    @Test
    public void testSkipRetryAndDLQWithHeaders() throws Exception {
        // create test topic
        connect.kafka().createTopic(""test-topic"");

        // setup connector config
        Map<String, String> props = new HashMap<>();
        props.put(CONNECTOR_CLASS_CONFIG, MonitorableSinkConnector.class.getSimpleName());
        props.put(TASKS_MAX_CONFIG, String.valueOf(NUM_TASKS));
        props.put(TOPICS_CONFIG, ""test-topic"");
        props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());
        props.put(TRANSFORMS_CONFIG, ""failing_transform"");
        props.put(""transforms.failing_transform.type"", FaultyPassthrough.class.getName());

        // log all errors, along with message metadata
        props.put(ERRORS_LOG_ENABLE_CONFIG, ""true"");
        props.put(ERRORS_LOG_INCLUDE_MESSAGES_CONFIG, ""true"");

        // produce bad messages into dead letter queue
        props.put(DLQ_TOPIC_NAME_CONFIG, DLQ_TOPIC);
        props.put(DLQ_CONTEXT_HEADERS_ENABLE_CONFIG, ""true"");
        props.put(DLQ_TOPIC_REPLICATION_FACTOR_CONFIG, ""1"");

        // tolerate all erros
        props.put(ERRORS_TOLERANCE_CONFIG, ""all"");

        // retry for up to one second
        props.put(ERRORS_RETRY_TIMEOUT_CONFIG, ""1000"");

        // set expected records to successfully reach the task
        connectorHandle.taskHandle(TASK_ID).expectedRecords(EXPECTED_CORRECT_RECORDS);

        connect.configureConnector(CONNECTOR_NAME, props);

        waitForCondition(this::checkForPartitionAssignment,
                CONNECTOR_SETUP_DURATION_MS,
                ""Connector task was not assigned a partition."");

        // produce some strings into test topic
        for (int i = 0; i < NUM_RECORDS_PRODUCED; i++) {
            connect.kafka().produce(""test-topic"", ""key-"" + i, ""value-"" + i);
        }

        // consume all records from test topic
        log.info(""Consuming records from test topic"");
        int i = 0;
        for (ConsumerRecord<byte[], byte[]> rec : connect.kafka().consume(NUM_RECORDS_PRODUCED, CONSUME_MAX_DURATION_MS, ""test-topic"")) {
            String k = new String(rec.key());
            String v = new String(rec.value());
            log.debug(""Consumed record (key='{}', value='{}') from topic {}"", k, v, rec.topic());
            assertEquals(""Unexpected key"", k, ""key-"" + i);
            assertEquals(""Unexpected value"", v, ""value-"" + i);
            i++;
        }

        // wait for records to reach the task
        connectorHandle.taskHandle(TASK_ID).awaitRecords(CONSUME_MAX_DURATION_MS);

        // consume failed records from dead letter queue topic
        log.info(""Consuming records from test topic"");
        ConsumerRecords<byte[], byte[]> messages = connect.kafka().consume(EXPECTED_INCORRECT_RECORDS, CONSUME_MAX_DURATION_MS, DLQ_TOPIC);
        for (ConsumerRecord<byte[], byte[]> recs : messages) {
            log.debug(""Consumed record (key={}, value={}) from dead letter queue topic {}"",
                    new String(recs.key()), new String(recs.value()), DLQ_TOPIC);
            assertTrue(recs.headers().toArray().length > 0);
            assertValue(""test-topic"", recs.headers(), ERROR_HEADER_ORIG_TOPIC);
            assertValue(RetriableException.class.getName(), recs.headers(), ERROR_HEADER_EXCEPTION);
            assertValue(""Error when value='value-7'"", recs.headers(), ERROR_HEADER_EXCEPTION_MESSAGE);
        }

        connect.deleteConnector(CONNECTOR_NAME);
    }
",non-flaky,5
43056,trinodb_trino,BaseConnectorTest.testJoinWithEmptySides,"    @Test(timeOut = 300_000, dataProvider = ""joinDistributionTypes"")
    public void testJoinWithEmptySides(JoinDistributionType joinDistributionType)
    {
        Session session = noJoinReordering(joinDistributionType);
        // empty build side
        assertQuery(session, ""SELECT count(*) FROM nation JOIN region ON nation.regionkey = region.regionkey AND region.name = ''"", ""VALUES 0"");
        assertQuery(session, ""SELECT count(*) FROM nation JOIN region ON nation.regionkey = region.regionkey AND region.regionkey < 0"", ""VALUES 0"");
        // empty probe side
        assertQuery(session, ""SELECT count(*) FROM region JOIN nation ON nation.regionkey = region.regionkey AND region.name = ''"", ""VALUES 0"");
        assertQuery(session, ""SELECT count(*) FROM nation JOIN region ON nation.regionkey = region.regionkey AND region.regionkey < 0"", ""VALUES 0"");
    }
",non-flaky,5
175748,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testUncheckStopPreviousVersionButtonWhenDisabled,"  @Test
  public void testUncheckStopPreviousVersionButtonWhenDisabled() {
    deployPanel = createPanel(true /* requireValues */);

    Button promoteButton = getButtonWithText(""Promote the deployed version to receive all traffic"");
    Button stopButton = getButtonWithText(""Stop previous version"");
    SWTBotCheckBox promote = new SWTBotCheckBox(promoteButton);
    SWTBotCheckBox stop = new SWTBotCheckBox(stopButton);

    // Initially, everything is checked and enabled.
    assertTrue(promoteButton.getSelection());
    assertTrue(stopButton.getSelection());
    assertTrue(stopButton.getEnabled());

    promote.click();
    assertFalse(promoteButton.getSelection());
    assertFalse(stopButton.getSelection());
    assertFalse(stopButton.getEnabled());

    promote.click();
    assertTrue(promoteButton.getSelection());
    assertTrue(stopButton.getSelection());
    assertTrue(stopButton.getEnabled());

    stop.click();
    assertTrue(promoteButton.getSelection());
    assertFalse(stopButton.getSelection());
    assertTrue(stopButton.getEnabled());

    promote.click();
    assertFalse(promoteButton.getSelection());
    assertFalse(stopButton.getSelection());
    assertFalse(stopButton.getEnabled());

    promote.click();
    assertTrue(promoteButton.getSelection());
    assertFalse(stopButton.getSelection());
    assertTrue(stopButton.getEnabled());
  }
",non-flaky,5
159678,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_noSchema,"    //    @Test
//    public void execute_noSchema() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddUniqueConstraintStatement(null, TABLE_NAME, COLUMN_NAME, ""uq_adduqtest"")) {
//
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertFalse(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        //todo: enable snapshot and assertion when snapshot can check for unique constraints
//                        //snapshot = new DatabaseSnapshotGenerator(snapshot);
//                    	assertTrue(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//                });
//    }
",non-flaky,5
110894,pushtorefresh_storio,InsertTest.insertOne,"    @Test
    public void insertOne() {
        final User user = putUserBlocking();

        // why we created StorIOSQLite: nobody loves nulls
        final Cursor cursor = db.query(UserTableMeta.TABLE, null, null, null, null, null, null);

        // asserting that values was really inserted to db
        assertThat(cursor.getCount()).isEqualTo(1);
        assertThat(cursor.moveToFirst()).isTrue();

        final User insertedUser = UserTableMeta.GET_RESOLVER.mapFromCursor(storIOSQLite, cursor);

        assertThat(insertedUser.id()).isNotNull();
        assertThat(user.equalsExceptId(insertedUser)).isTrue();

        cursor.close();
    }
",non-flaky,5
96915,apache_avro,TestAvroOutputFormat.testDeflateCodecUsingHadoopClass,"  @Test
  public void testDeflateCodecUsingHadoopClass() {
    CodecFactory avroDeflateCodec = CodecFactory.fromString(""deflate"");

    JobConf job = new JobConf();
    job.set(""mapred.output.compress"", ""true"");
    job.set(""mapred.output.compression.codec"", ""org.apache.hadoop.io.compress.DeflateCodec"");
    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
    assertNotNull(factory);
    assertEquals(factory.getClass(), avroDeflateCodec.getClass());
  }
",non-flaky,5
175778,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidate_relativePathWithAppYaml,"  @Test
  public void testValidate_relativePathWithAppYaml() throws IOException {
    createAppYamlFile(basePath + ""/some/directory"", ""runtime: java"");

    when(appYamlPath.getValue()).thenReturn(""some/directory/app.yaml"");
    IStatus result = pathValidator.validate();
    assertTrue(result.isOK());
  }
",non-flaky,5
175779,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidate_absolutePathWithAppYaml,"  @Test
  public void testValidate_absolutePathWithAppYaml() throws IOException {
    File absolutePath = tempFolder.newFolder(""another"", ""folder"");
    File appYaml = createAppYamlFile(absolutePath.toString(), ""runtime: java"");

    when(appYamlPath.getValue()).thenReturn(appYaml.toString());
    IStatus result = pathValidator.validate();
    assertTrue(result.isOK());
  }
",non-flaky,5
98208,apache_jackrabbit,RepositoryServiceImplIT.testGetAgainstTrustedCertServer,"    @Test
    public void testGetAgainstTrustedCertServer() throws RepositoryException, ClientProtocolException, IOException {
        assumeTrue(""Cannot connect to http://www.apache.org"", canConnectTo(""http://www.apache.org""));
        RepositoryServiceImpl repositoryServiceImpl = RepositoryServiceImplTest.getRepositoryService(""https://jackrabbit.apache.org/jcr"", ConnectionOptions.builder().build());
        HttpClient client = repositoryServiceImpl.getClient(null);
        HttpGet get = new HttpGet(""https://jackrabbit.apache.org/jcr/index.html"");
        String content = client.execute(get, new BasicResponseHandler());
        assertFalse(content.isEmpty());
    }
",non-flaky,5
89290,apache_samza,TestTasksResource.testGetTasksWithInvalidJobName,"  @Test
  public void testGetTasksWithInvalidJobName() throws IOException {
    String requestUrl = String.format(""v1/jobs/%s/%s/tasks"", ""BadJobName"", MockJobProxy.JOB_INSTANCE_4_ID);
    Response resp = target(requestUrl).request().get();
    assertEquals(400, resp.getStatus());
    final Map<String, String> errorMessage = objectMapper.readValue(resp.readEntity(String.class), new TypeReference<Map<String, String>>() { });
    assertTrue(errorMessage.get(""message""), errorMessage.get(""message"").contains(""Invalid arguments for getTasks. ""));
    resp.close();
  }
",non-flaky,5
170526,eclipse_jetty.project,TestAnnotationConfiguration.testDiscoveredFalseWithSCIs,"    @Test
    public void testDiscoveredFalseWithSCIs() throws Exception
    {
        ClassLoader old = Thread.currentThread().getContextClassLoader();
        Thread.currentThread().setContextClassLoader(webAppLoader);
        try
        {
            //test 2.5 webapp with configurationDiscovered=false loads only server scis
            AnnotationConfiguration config = new AnnotationConfiguration();
            WebAppContext context = new WebAppContext();
            List<ServletContainerInitializer> scis;
            context.setConfigurationDiscovered(false);
            context.setClassLoader(webAppLoader);
            context.getMetaData().setWebDescriptor(new WebDescriptor(Resource.newResource(web25)));
            context.getMetaData().setWebInfClassesResources(classes);
            context.getMetaData().addWebInfResource(Resource.newResource(testSciJar.toURI().toURL()));
            context.getServletContext().setEffectiveMajorVersion(2);
            context.getServletContext().setEffectiveMinorVersion(5);
            scis = config.getNonExcludedInitializers(context);
            assertNotNull(scis);
            for (ServletContainerInitializer s : scis)
            {
                //should not have any of the web-inf lib scis in here
                assertFalse(s.getClass().getName().equals(""com.acme.ordering.AcmeServletContainerInitializer""));
                assertFalse(s.getClass().getName().equals(""com.acme.initializer.FooInitializer""));
                //NOTE: should also not have the web-inf classes scis in here either, but due to the
                //way the test is set up, the sci we're pretending is in web-inf classes will actually
                //NOT be loaded by the webapp's classloader, but rather by the junit classloader, so
                //it looks as if it is a container class.
            }
        }
        finally
        {
            Thread.currentThread().setContextClassLoader(old);
        }
    }
",non-flaky,5
179497,abel533_Mapper,TypeHandlerTest2.testUpdate,"    @Test
    public void testUpdate(){
        SqlSession sqlSession = getSqlSession();
        try {
            User2Mapper userMapper = sqlSession.getMapper(User2Mapper.class);
            User2 user = userMapper.selectByPrimaryKey(1);
            Assert.assertEquals(""abel533"", user.getName());
            Assert.assertEquals(""Hebei"", user.getAddress().getProvince());
            Assert.assertEquals(""Shijiazhuang"", user.getAddress().getCity());
            Assert.assertEquals(StateEnum.enabled, user.getState());

            user.setState(StateEnum.disabled);
            user.getAddress().setCity(""Handan"");
            Assert.assertEquals(1, userMapper.updateByPrimaryKey(user));

            user = userMapper.selectByPrimaryKey(1);
            Assert.assertEquals(""abel533"", user.getName());
            Assert.assertEquals(""Hebei"", user.getAddress().getProvince());
            Assert.assertEquals(""Handan"", user.getAddress().getCity());
            Assert.assertEquals(StateEnum.disabled, user.getState());
        } finally {
            sqlSession.close();
        }
    }
",non-flaky,5
162675,OpenAPITools_openapi-generator,PetApiTest.getPetByIdTest,"    @Test
    public void getPetByIdTest() {
        Long petId = null;
        //Pet response = api.getPetById(petId);
        //assertNotNull(response);
        // TODO: test validations
        
        
    }
",non-flaky,5
177983,aosp-mirror_platform_frameworks_support,BidiFormatterTest.testUnicodeWrap,"    @Test
    public void testUnicodeWrap() {
        // Make sure an input of null doesn't crash anything.
        assertNull(LTR_FMT.unicodeWrap(null));

        // Uniform directionality in opposite context.
        assertEquals(""uniform dir opposite to LTR context"",
                RLE + ""."" + HE + ""."" + PDF + LRM,
                LTR_FMT_EXIT_RESET.unicodeWrap(""."" + HE + "".""));
        assertEquals(""uniform dir opposite to LTR context, stereo reset"",
                LRM + RLE + ""."" + HE + ""."" + PDF + LRM,
                LTR_FMT.unicodeWrap(""."" + HE + "".""));
        assertEquals(""uniform dir opposite to LTR context, stereo reset, no isolation"",
                RLE + ""."" + HE + ""."" + PDF,
                LTR_FMT.unicodeWrap(""."" + HE + ""."", false));
        assertEquals(""neutral treated as opposite to LTR context"",
                RLE + ""."" + PDF + LRM,
                LTR_FMT_EXIT_RESET.unicodeWrap(""."", TextDirectionHeuristicsCompat.RTL));
        assertEquals(""uniform dir opposite to RTL context"",
                LRE + ""."" + EN + ""."" + PDF + RLM,
                RTL_FMT_EXIT_RESET.unicodeWrap(""."" + EN + "".""));
        assertEquals(""uniform dir opposite to RTL context, stereo reset"",
                RLM + LRE + ""."" + EN + ""."" + PDF + RLM,
                RTL_FMT.unicodeWrap(""."" + EN + "".""));
        assertEquals(""uniform dir opposite to RTL context, stereo reset, no isolation"",
                LRE + ""."" + EN + ""."" + PDF,
                RTL_FMT.unicodeWrap(""."" + EN + ""."", false));
        assertEquals(""neutral treated as opposite to RTL context"",
                LRE + ""."" + PDF + RLM,
                RTL_FMT_EXIT_RESET.unicodeWrap(""."", TextDirectionHeuristicsCompat.LTR));

        // We test mixed-directionality cases only with an explicit overall directionality parameter
        // because the estimation logic is outside the sphere of BidiFormatter, and different
        // estimators will treat them differently.

        // Overall directionality matching context, but with opposite exit directionality.
        assertEquals(""exit dir opposite to LTR context"",
                EN + HE + LRM,
                LTR_FMT_EXIT_RESET.unicodeWrap(EN + HE, TextDirectionHeuristicsCompat.LTR));
        assertEquals(""exit dir opposite to LTR context, stereo reset"",
                EN + HE + LRM,
                LTR_FMT.unicodeWrap(EN + HE, TextDirectionHeuristicsCompat.LTR));
        assertEquals(""exit dir opposite to LTR context, stereo reset, no isolation"",
                EN + HE,
                LTR_FMT.unicodeWrap(EN + HE, TextDirectionHeuristicsCompat.LTR, false));

        assertEquals(""exit dir opposite to RTL context"",
                HE + EN + RLM,
                RTL_FMT_EXIT_RESET.unicodeWrap(HE + EN, TextDirectionHeuristicsCompat.RTL));
        assertEquals(""exit dir opposite to RTL context, stereo reset"",
                HE + EN + RLM,
                RTL_FMT.unicodeWrap(HE + EN, TextDirectionHeuristicsCompat.RTL));
        assertEquals(""exit dir opposite to RTL context, stereo reset, no isolation"",
                HE + EN,
                RTL_FMT.unicodeWrap(HE + EN, TextDirectionHeuristicsCompat.RTL, false));

        // Overall directionality matching context, but with opposite entry directionality.
        assertEquals(""entry dir opposite to LTR context"",
                HE + EN,
                LTR_FMT_EXIT_RESET.unicodeWrap(HE + EN, TextDirectionHeuristicsCompat.LTR));
        assertEquals(""entry dir opposite to LTR context, stereo reset"",
                LRM + HE + EN,
                LTR_FMT.unicodeWrap(HE + EN, TextDirectionHeuristicsCompat.LTR));
        assertEquals(""entry dir opposite to LTR context, stereo reset, no isolation"",
                HE + EN,
                LTR_FMT.unicodeWrap(HE + EN, TextDirectionHeuristicsCompat.LTR, false));

        assertEquals(""entry dir opposite to RTL context"",
                EN + HE,
                RTL_FMT_EXIT_RESET.unicodeWrap(EN + HE, TextDirectionHeuristicsCompat.RTL));
        assertEquals(""entry dir opposite to RTL context, stereo reset"",
                RLM + EN + HE,
                RTL_FMT.unicodeWrap(EN + HE, TextDirectionHeuristicsCompat.RTL));
        assertEquals(""entry dir opposite to RTL context, stereo reset, no isolation"",
                EN + HE,
                RTL_FMT.unicodeWrap(EN + HE, TextDirectionHeuristicsCompat.RTL, false));

        // Overall directionality matching context, but with opposite entry and exit directionality.
        assertEquals(""entry and exit dir opposite to LTR context"",
                HE + EN + HE + LRM,
                LTR_FMT_EXIT_RESET.unicodeWrap(HE + EN + HE, TextDirectionHeuristicsCompat.LTR));
        assertEquals(""entry and exit dir opposite to LTR context, stereo reset"",
                LRM + HE + EN + HE + LRM,
                LTR_FMT.unicodeWrap(HE + EN + HE, TextDirectionHeuristicsCompat.LTR));
        assertEquals(""entry and exit dir opposite to LTR context, no isolation"",
                HE + EN + HE,
                LTR_FMT_EXIT_RESET.unicodeWrap(HE + EN + HE, TextDirectionHeuristicsCompat.LTR,
                        false));

        assertEquals(""entry and exit dir opposite to RTL context"",
                EN + HE + EN + RLM,
                RTL_FMT_EXIT_RESET.unicodeWrap(EN + HE + EN, TextDirectionHeuristicsCompat.RTL));
        assertEquals(""entry and exit dir opposite to RTL context, no isolation"",
                EN + HE + EN,
                RTL_FMT_EXIT_RESET.unicodeWrap(EN + HE + EN, TextDirectionHeuristicsCompat.RTL,
                        false));

        // Entry and exit directionality matching context, but with opposite overall directionality.
        assertEquals(""overall dir (but not entry or exit dir) opposite to LTR context"",
                RLE + EN + HE + EN + PDF + LRM,
                LTR_FMT_EXIT_RESET.unicodeWrap(EN + HE + EN, TextDirectionHeuristicsCompat.RTL));
        assertEquals(""overall dir (but not entry or exit dir) opposite to LTR context, stereo reset"",
                LRM + RLE + EN + HE + EN + PDF + LRM,
                LTR_FMT.unicodeWrap(EN + HE + EN, TextDirectionHeuristicsCompat.RTL));
        assertEquals(""overall dir (but not entry or exit dir) opposite to LTR context, no isolation"",
                RLE + EN + HE + EN + PDF,
                LTR_FMT_EXIT_RESET.unicodeWrap(EN + HE + EN, TextDirectionHeuristicsCompat.RTL,
                        false));

        assertEquals(""overall dir (but not entry or exit dir) opposite to RTL context"",
                LRE + HE + EN + HE + PDF + RLM,
                RTL_FMT_EXIT_RESET.unicodeWrap(HE + EN + HE, TextDirectionHeuristicsCompat.LTR));
        assertEquals(""overall dir (but not entry or exit dir) opposite to RTL context, stereo reset"",
                RLM + LRE + HE + EN + HE + PDF + RLM,
                RTL_FMT.unicodeWrap(HE + EN + HE, TextDirectionHeuristicsCompat.LTR));
        assertEquals(""overall dir (but not entry or exit dir) opposite to RTL context, no isolation"",
                LRE + HE + EN + HE + PDF,
                RTL_FMT_EXIT_RESET.unicodeWrap(HE + EN + HE, TextDirectionHeuristicsCompat.LTR,
                        false));
    }
",non-flaky,5
84605,apache_zookeeper,PrometheusMetricsProviderTest.testGauge,"    @Test
    public void testGauge() throws Exception {
        int[] values = {78, -89};
        int[] callCounts = {0, 0};
        Gauge gauge0 = () -> {
            callCounts[0]++;
            return values[0];
        };
        Gauge gauge1 = () -> {
            callCounts[1]++;
            return values[1];
        };
        provider.getRootContext().registerGauge(""gg"", gauge0);

        int[] count = {0};
        provider.dump((k, v) -> {
            assertEquals(""gg"", k);
            assertEquals(values[0], ((Number) v).intValue());
            count[0]++;
        }
        );
        assertEquals(1, callCounts[0]);
        assertEquals(0, callCounts[1]);
        assertEquals(1, count[0]);
        count[0] = 0;
        String res2 = callServlet();
        assertThat(res2, CoreMatchers.containsString(""# TYPE gg gauge""));
        assertThat(res2, CoreMatchers.containsString(""gg 78.0""));

        provider.getRootContext().unregisterGauge(""gg"");
        provider.dump((k, v) -> {
            count[0]++;
        }
        );
        assertEquals(2, callCounts[0]);
        assertEquals(0, callCounts[1]);
        assertEquals(0, count[0]);
        String res3 = callServlet();
        assertTrue(res3.isEmpty());

        provider.getRootContext().registerGauge(""gg"", gauge1);

        provider.dump((k, v) -> {
            assertEquals(""gg"", k);
            assertEquals(values[1], ((Number) v).intValue());
            count[0]++;
        }
        );
        assertEquals(2, callCounts[0]);
        assertEquals(1, callCounts[1]);
        assertEquals(1, count[0]);
        count[0] = 0;

        String res4 = callServlet();
        assertThat(res4, CoreMatchers.containsString(""# TYPE gg gauge""));
        assertThat(res4, CoreMatchers.containsString(""gg -89.0""));
        assertEquals(2, callCounts[0]);
        // the servlet must sample the value again (from gauge1)
        assertEquals(2, callCounts[1]);

        // override gauge, without unregister
        provider.getRootContext().registerGauge(""gg"", gauge0);

        provider.dump((k, v) -> {
            count[0]++;
        }
        );
        assertEquals(1, count[0]);
        assertEquals(3, callCounts[0]);
        assertEquals(2, callCounts[1]);
    }
",non-flaky,5
13860,neo4j_neo4j,TestCommunication.applicationProtocolVersionsMustMatch,"    @Test
    public void applicationProtocolVersionsMustMatch() throws Throwable
    {
        MadeUpServer server = builder.applicationProtocolVersion( (byte) (APPLICATION_PROTOCOL_VERSION + 1) ).server();
        MadeUpClient client = builder.client();
        addToLifeAndStart( server, client );

        try
        {
            client.multiply( 10, 20 );
            fail( ""Shouldn't be able to communicate with different application protocol versions"" );
        }
        catch ( IllegalProtocolVersionException e )
        { /* Good */ }
    }
",non-flaky,5
76679,quarkusio_quarkus,CustomAuthEmbeddedBase.testJaxrsGetRoleFailure,"    @Test
    public void testJaxrsGetRoleFailure() {
        RestAssured.given().auth().preemptive().basic(""jdoe"", ""p4ssw0rd"")
                .when().get(""/jaxrs-secured/rolesClass"").then()
                .statusCode(403);
    }
",non-flaky,5
89356,apache_samza,TestKafkaCheckpointLogKeySerde.testForwardsCompatibility,"  @Test
  public void testForwardsCompatibility() {
    // Set the key to another value, this is for the future if we want to support multiple checkpoint keys
    // we do not want to throw in the Serdes layer, but must be validated in the CheckpointManager
    KafkaCheckpointLogKey key = new KafkaCheckpointLogKey(""checkpoint-v2"",
        new TaskName(""Partition 0""), GroupByPartitionFactory.class.getCanonicalName());
    KafkaCheckpointLogKeySerde checkpointSerde = new KafkaCheckpointLogKeySerde();

    // test that deserialize(serialize(k)) == k
    Assert.assertEquals(key, checkpointSerde.fromBytes(checkpointSerde.toBytes(key)));
  }
",non-flaky,5
135023,undertow-io_undertow,ResponseParserResumeTestCase.testOneCharacterAtATime,"    @Test
    public void testOneCharacterAtATime() throws BadRequestException {
        byte[] in = DATA.getBytes();
        final ResponseParseState context = new ResponseParseState();
        HttpResponseBuilder result = new HttpResponseBuilder();
        ByteBuffer buffer = ByteBuffer.wrap(in);
        buffer.limit(1);
        while (context.state != ResponseParseState.PARSE_COMPLETE) {
            HttpResponseParser.INSTANCE.handle(buffer, context, result);
            buffer.limit(buffer.limit() + 1);
        }
        runAssertions(result, context);
    }
",non-flaky,5
13850,neo4j_neo4j,ResourcePoolTest.shouldMaintainPoolAtHighWatermarkWhenConcurrentUsagePassesMinSize,"    @Test
    public void shouldMaintainPoolAtHighWatermarkWhenConcurrentUsagePassesMinSize() throws Exception
    {
        // given
        final int MIN_SIZE = 50;
        final int MAX_SIZE = 200;
        final int MID_SIZE = 90;

        StatefulMonitor stateMonitor = new StatefulMonitor();
        FakeClock clock = new FakeClock();
        final ResourcePool<Something> pool = getResourcePool( stateMonitor, clock, MIN_SIZE );
        List<ResourceHolder> holders = new LinkedList<ResourceHolder>();

        buildAPeakOfAcquiredResourcesAndTriggerAlarmWithSideEffects( MAX_SIZE, clock, pool, holders );

        // when
        // After the peak, stay at MID_SIZE concurrent usage, using up all already present resources in the process
        // but also keeping the high watermark above the MIN_SIZE
        clock.forward( 110, TimeUnit.MILLISECONDS );
        // Requires some rounds to happen, since there is constant racing between releasing and acquiring which does
        // not always result in reaping of resources, as there is reuse
        for ( int i = 0; i < 10; i++ )
        {
            // The latch is necessary to reduce races between batches
            CountDownLatch release = new CountDownLatch( MID_SIZE );
            for ( ResourceHolder holder : acquireFromPool( pool, MID_SIZE ) )
            {
                holder.release( release );
            }
            release.await();
            clock.forward( 110, TimeUnit.MILLISECONDS );
        }

        // then
        // currentPeakSize should be at MID_SIZE
        assertEquals( MID_SIZE, stateMonitor.currentPeakSize.get() );
        // target size too
        assertEquals( MID_SIZE, stateMonitor.targetSize.get() );
        // only the excess from the MAX_SIZE down to mid size must have been disposed
        // +1 for the alarm from buildAPeakOfAcquiredResourcesAndTriggerAlarmWithSideEffects
        assertEquals( MAX_SIZE - MID_SIZE + 1, stateMonitor.disposed.get() );
    }
",non-flaky,5
35749,cdapio_cdap,AuthServerAnnounceTest.testAnnounceURLsConfig,"  @Test
  public void testAnnounceURLsConfig() throws Exception {
    HttpRouterService routerService = new AuthServerAnnounceTest.HttpRouterService(HOSTNAME, DISCOVERY_SERVICE);
    routerService.cConf.set(Constants.Security.AUTH_SERVER_ANNOUNCE_URLS, ANNOUNCE_URLS);
    routerService.startUp();
    try {
      List<String> expected = Stream.of(ANNOUNCE_URLS.split("",""))
        .map(url -> String.format(""%s/%s"", url, GrantAccessToken.Paths.GET_TOKEN))
        .collect(Collectors.toList());
      Assert.assertEquals(expected, getAuthURI(routerService));
    } finally {
      routerService.shutDown();
    }
  }
",non-flaky,5
98063,vert-x3_vertx-mongo-client,MongoClientAggregateUpdateTest.testAggregateUpdateCollectionWithOptions,"  @Test
  public void testAggregateUpdateCollectionWithOptions() {
    String collection = randomCollection();
    mongoClient.insert(collection, new JsonObject().put(""price"", 10).put(""quantity"", 1), onSuccess(id -> {
      mongoClient.insert(collection, new JsonObject().put(""price"", 20).put(""quantity"", 2), onSuccess(id2 -> {
        mongoClient.insert(collection, new JsonObject().put(""price"", 30).put(""quantity"", 10), onSuccess(id3 -> {
          mongoClient.updateCollectionWithOptions(collection,
            // reduce price of low quantity items
            new JsonObject().put(""quantity"", new JsonObject().put(""$lte"", 2)),
            new JsonArray().add(new JsonObject().put(""$set"", new JsonObject().put(""price"", new JsonObject().put(""$subtract"", new JsonArray().add(""$price"").add(2))))),
            new UpdateOptions(),onSuccess(res -> {
              assertEquals(2, res.getDocModified());
              assertEquals(2, res.getDocMatched());
              testComplete();
            }));
        }));
      }));
    }));
    await();
  }
",non-flaky,5
135808,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testFallbackMissing,"    @Test
    public void testFallbackMissing() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-K"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.FAILURE, 20, HystrixEventType.FALLBACK_MISSING);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.FAILURE.ordinal()] = 1;
        expected[HystrixEventType.FALLBACK_MISSING.ordinal()] = 1;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
176813,ctco_cukes,EndsWithRegexpTest.matchesNotEndWith,"    @Test
    public void matchesNotEndWith() throws Exception {
        assertThat(""hello world"", Matchers.not(EndsWithRegexp.endsWithRegexp(""hello"")));
    }
",non-flaky,5
178044,aosp-mirror_platform_frameworks_support,GuidedStepAttributesTest.run,"    @Test
    public void testToggleEnabledFlags() throws Throwable {

        Intent intent = new Intent();
        Resources res = mContext.getResources();

        final int NUM_SEARCH_ACTIONS = 10;
        final List<Integer> DISABLED_ACTIONS = new ArrayList<>(
                Arrays.asList(1, 3, 5, 7));
        final int ACTION_ID_REVERT_BUTTON = 0;
        final int ACTION_ID_SEARCH_BEGIN = ACTION_ID_REVERT_BUTTON + 1;
        int ACTION_ID_SEARCH_END = ACTION_ID_SEARCH_BEGIN;

        // sequence of clicked actions simulated in the test
        List<Integer> CLICK_SEQUENCE = new ArrayList<>();

        // Expected Clicked sequence can be different from focused ones since some of the actions
        // are disabled hence not clickable
        List<Integer> EXPECTED_FOCUSED_SEQUENCE = new ArrayList<>();
        List<Integer> EXPECTED_CLICKED_SEQUENCE = new ArrayList<>();
        // Expected actions state according to list of DISABLED_ACTIONS: false for disabled actions
        List<Boolean> EXPECTED_ACTIONS_STATE = new ArrayList<>(
                Arrays.asList(new Boolean[NUM_SEARCH_ACTIONS])
        );
        Collections.fill(EXPECTED_ACTIONS_STATE, Boolean.FALSE);

        for(int i = 0; i < NUM_SEARCH_ACTIONS; i++) {
            CLICK_SEQUENCE.add(i + 1);
        }
        for(int clickedActionId : CLICK_SEQUENCE) {
            EXPECTED_FOCUSED_SEQUENCE.add(clickedActionId);
            if (DISABLED_ACTIONS.contains(clickedActionId - 1))
                EXPECTED_CLICKED_SEQUENCE.add(clickedActionId);
            else
                EXPECTED_CLICKED_SEQUENCE.add(-1);
        }

        String title = ""Guided Actions Enabled Test"";
        String breadcrumb = ""Toggle Enabled Flag Test Demo"";
        String description = """";
        GuidanceStylist.Guidance guidance = new GuidanceStylist.Guidance(title, description,
                breadcrumb, null);

        List<GuidedAction> actionList = new ArrayList<>();
        actionList.add(new GuidedAction.Builder(mContext)
                .id(ACTION_ID_REVERT_BUTTON)
                .title(res.getString(R.string.invert_title))
                .description(res.getString(R.string.revert_description))
                .build()
        );

        for (int i = 0; i < NUM_SEARCH_ACTIONS; i++ ) {
            actionList.add(new GuidedAction.Builder(mContext)
                    .id(ACTION_ID_SEARCH_END++)
                    .title(res.getString(R.string.search) + """" + i)
                    .description(res.getString(R.string.search_description) + i)
                    .build()
            );
        }
        for(int action_id : DISABLED_ACTIONS ) {
            if ( action_id >= 0 && action_id < NUM_SEARCH_ACTIONS ) {
                actionList.get(action_id + 1).setEnabled(false);
                EXPECTED_ACTIONS_STATE.set(action_id, Boolean.TRUE);
            }
        }

        GuidedStepAttributesTestFragment.clear();
        GuidedStepAttributesTestFragment.GUIDANCE = guidance;
        GuidedStepAttributesTestFragment.ACTION_LIST = actionList;
        GuidedStepAttributesTestFragment.setActionClickCallback(ACTION_ID_REVERT_BUTTON,
                sRevertCallback);

        initActivity(intent);

        final GuidedStepFragment mFragment = (GuidedStepFragment)
                mActivity.getGuidedStepTestFragment();

        mActivity.runOnUiThread(new Runnable() {
            @Override
            public void run() {
                mFragment.setSelectedActionPosition(0);
            }
",non-flaky,5
98231,apache_jackrabbit,PerformanceTest.testPerformance,"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""1.0"");
    }
",non-flaky,5
150163,apache_hive,TestHplsqlLocal.testExceptionDivideByZero,"  @Test
  public void testExceptionDivideByZero() throws Exception {
    run(""exception_divide_by_zero"");
  }
",non-flaky,5
110133,Wikidata_wikidata-toolkit,ClientConfigurationTest.testDumpLocationArgumentsShort,"	@Test
	public void testDumpLocationArgumentsShort() {
		String[] args = new String[] { ""-d"", ""dumps/wikidata/"" };
		ClientConfiguration config = new ClientConfiguration(args);
		assertEquals(""dumps/wikidata/"", config.getDumpDirectoryLocation());
	}
",non-flaky,5
91459,strapdata_elassandra,RelocationIT.testIndexAndRelocateConcurrently,"    @TestLogging(
    public void testIndexAndRelocateConcurrently() throws ExecutionException, InterruptedException {
        int halfNodes = randomIntBetween(1, 3);
        Settings[] nodeSettings = Stream.concat(
            Stream.generate(() -> Settings.builder().put(""node.attr.color"", ""blue"").build()).limit(halfNodes),
            Stream.generate(() -> Settings.builder().put(""node.attr.color"", ""red"").build()).limit(halfNodes)
            ).toArray(Settings[]::new);
        List<String> nodes = internalCluster().startNodes(nodeSettings);
        String[] blueNodes = nodes.subList(0, halfNodes).stream().toArray(String[]::new);
        String[] redNodes = nodes.subList(halfNodes, nodes.size()).stream().toArray(String[]::new);
        logger.info(""blue nodes: {}"", (Object)blueNodes);
        logger.info(""red nodes: {}"", (Object)redNodes);
        ensureStableCluster(halfNodes * 2);

        final Settings.Builder settings = Settings.builder()
                .put(""index.routing.allocation.exclude.color"", ""blue"")
                .put(indexSettings())
                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(halfNodes - 1))
                .put(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), ""100ms"");
        assertAcked(prepareCreate(""test"", settings));
        assertAllShardsOnNodes(""test"", redNodes);
        int numDocs = randomIntBetween(100, 150);
        ArrayList<String> ids = new ArrayList<>();
        logger.info("" --> indexing [{}] docs"", numDocs);
        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
        for (int i = 0; i < numDocs; i++) {
            String id = randomRealisticUnicodeOfLength(10) + String.valueOf(i);
            ids.add(id);
            docs[i] = client().prepareIndex(""test"", ""type1"", id).setSource(""field1"", English.intToEnglish(i));
        }
        indexRandom(true, docs);
        SearchResponse countResponse = client().prepareSearch(""test"").get();
        assertHitCount(countResponse, numDocs);

        logger.info("" --> moving index to new nodes"");
        Settings build = Settings.builder().put(""index.routing.allocation.exclude.color"", ""red"")
            .put(""index.routing.allocation.include.color"", ""blue"").build();
        client().admin().indices().prepareUpdateSettings(""test"").setSettings(build).execute().actionGet();

        // index while relocating
        logger.info("" --> indexing [{}] more docs"", numDocs);
        for (int i = 0; i < numDocs; i++) {
            String id = randomRealisticUnicodeOfLength(10) + String.valueOf(numDocs + i);
            ids.add(id);
            docs[i] = client().prepareIndex(""test"", ""type1"", id).setSource(""field1"", English.intToEnglish(numDocs + i));
        }
        indexRandom(true, docs);
        numDocs *= 2;

        logger.info("" --> waiting for relocation to complete"");
        ensureGreen(""test""); // move all shards to the new nodes (it waits on relocation)

        final int numIters = randomIntBetween(10, 20);
        for (int i = 0; i < numIters; i++) {
            logger.info("" --> checking iteration {}"", i);
            SearchResponse afterRelocation = client().prepareSearch().setSize(ids.size()).get();
            assertNoFailures(afterRelocation);
            assertSearchHits(afterRelocation, ids.toArray(new String[ids.size()]));
        }

    }
",non-flaky,5
98587,nutzam_nutz,El2Test.sikpSpace,"    @Test
    public void sikpSpace() {
        // ç©ºæ ¼æ£æµ
        assertEquals(3, El.eval(""    1 + 2    ""));
    }
",non-flaky,5
92629,apache_dubbo,ApplicationConfigTest.testOrganization,"    @Test
    public void testOrganization() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setOrganization(""org"");
        assertThat(application.getOrganization(), equalTo(""org""));
    }
",non-flaky,5
156096,soot-oss_soot,AsmInnerClassTest.InnerStaticInner,"  @Test
  public void InnerStaticInner() {
    SootMethod target3 =
        prepareTarget(
            methodSigFromComponents(TEST_TARGET_CLASS + ""$Inner$InnerInner"", ""void"", ""method""),
            TEST_TARGET_CLASS + ""$Inner$InnerInner"");
    // one dummy
    assertEquals(2, Scene.v().getApplicationClasses().size());
    assertTrue(target3.getDeclaringClass().hasOuterClass());
    assertTrue(target3.getDeclaringClass().isInnerClass());
    InnerClassTag innerClassTag = null;
    for (Tag tag : target3.getDeclaringClass().getTags()) {
      // FIXME: we have multiple innerclasstags? for a parent it makes sense but for a child class?
      if (tag instanceof InnerClassTag) {
        boolean inner =
            ((InnerClassTag) tag)
                .getInnerClass()
                .equals(""soot/asm/ScopeFinderTarget$Inner$InnerInner"");
        if (inner) {
          innerClassTag = (InnerClassTag) tag;
          break;
        }
      }
    }
    assertNotNull(innerClassTag);
    assertEquals(""soot/asm/ScopeFinderTarget$Inner$InnerInner"", innerClassTag.getInnerClass());
    assertEquals(""soot/asm/ScopeFinderTarget$Inner"", innerClassTag.getOuterClass());
    assertFalse(Modifier.isStatic(innerClassTag.getAccessFlags()));
  }
",non-flaky,5
104647,apache_pinot,OfflineClusterIntegrationTest.testCaseStatementInSelection,"  @Test
  public void testCaseStatementInSelection()
      throws Exception {
    List<String> origins = Arrays
        .asList(""ATL"", ""ORD"", ""DFW"", ""DEN"", ""LAX"", ""IAH"", ""SFO"", ""PHX"", ""LAS"", ""EWR"", ""MCO"", ""BOS"", ""SLC"", ""SEA"", ""MSP"",
            ""CLT"", ""LGA"", ""DTW"", ""JFK"", ""BWI"");
    StringBuilder caseStatementBuilder = new StringBuilder(""CASE "");
    for (int i = 0; i < origins.size(); i++) {
      // WHEN origin = 'ATL' THEN 1
      // WHEN origin = 'ORD' THEN 2
      // WHEN origin = 'DFW' THEN 3
      // ....
      caseStatementBuilder.append(String.format(""WHEN origin = '%s' THEN %d "", origins.get(i), i + 1));
    }
    caseStatementBuilder.append(""ELSE 0 END"");
    String sqlQuery = ""SELECT origin, "" + caseStatementBuilder + "" AS origin_code FROM mytable LIMIT 1000"";
    JsonNode response = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    JsonNode rows = response.get(""resultTable"").get(""rows"");
    assertEquals(response.get(""exceptions"").size(), 0);
    for (int i = 0; i < rows.size(); i++) {
      String origin = rows.get(i).get(0).asText();
      int originCode = rows.get(i).get(1).asInt();
      if (originCode > 0) {
        assertEquals(origin, origins.get(originCode - 1));
      } else {
        assertFalse(origins.contains(origin));
      }
    }
  }
",non-flaky,5
178018,aosp-mirror_platform_frameworks_support,PlaybackControlGlueTest.testMediaPlayPauseButtonOnFF,"    @Test
    public void testMediaPlayPauseButtonOnFF() {
        PlaybackControlsRow row = new PlaybackControlsRow();
        glue.setControlsRow(row);
        SparseArrayObjectAdapter adapter = (SparseArrayObjectAdapter)
                row.getPrimaryActionsAdapter();
        PlaybackControlsRow.MultiAction playPause = (PlaybackControlsRow.MultiAction) adapter
                .lookup(PlaybackControlGlue.ACTION_PLAY_PAUSE);
        PlaybackControlsRow.MultiAction fastForward = (PlaybackControlsRow.MultiAction) adapter
                .lookup(PlaybackControlGlue.ACTION_FAST_FORWARD);

        glue.onActionClicked(playPause);
        glue.onActionClicked(fastForward);
        assertEquals(PlaybackControlGlue.PLAYBACK_SPEED_FAST_L0, glue.getCurrentSpeedId());
        glue.onKey(null, KeyEvent.KEYCODE_MEDIA_PLAY_PAUSE, new KeyEvent(KeyEvent.ACTION_DOWN,
                KeyEvent.KEYCODE_MEDIA_PLAY_PAUSE));
        assertEquals(PlaybackControlGlue.PLAYBACK_SPEED_NORMAL, glue.getCurrentSpeedId());
    }
",non-flaky,5
76675,quarkusio_quarkus,CustomAuthEmbeddedBase.testSecureAccessFailure,"    @Test()
    public void testSecureAccessFailure() {
        RestAssured.when().get(""/secure-test"").then()
                .statusCode(401);
    }
",non-flaky,5
112118,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindLatestTaskResultStatistics,"    @Test
    public void assertFindLatestTaskResultStatistics() {
        for (StatisticInterval each : StatisticInterval.values()) {
            repository.add(new TaskResultStatistics(100, 2, each, new Date()));
            repository.add(new TaskResultStatistics(200, 5, each, new Date()));
            Optional<TaskResultStatistics> po = repository.findLatestTaskResultStatistics(each);
            assertThat(po.get().getSuccessCount(), is(200));
            assertThat(po.get().getFailedCount(), is(5));
        }
    }
",non-flaky,5
91466,strapdata_elassandra,MasterDisruptionIT.execute,"    @TestLogging(""_root:DEBUG,org.elasticsearch.cluster.service:TRACE,org.elasticsearch.test.disruption:TRACE"")
    public void testStaleMasterNotHijackingMajority() throws Exception {
        // 3 node cluster with unicast discovery and minimum_master_nodes set to 2:
        final List<String> nodes = startCluster(3, 2);

        // Save the current master node as old master node, because that node will get frozen
        final String oldMasterNode = internalCluster().getMasterName();
        for (String node : nodes) {
            ensureStableCluster(3, node);
        }
        assertMaster(oldMasterNode, nodes);

        // Simulating a painful gc by suspending all threads for a long time on the current elected master node.
        SingleNodeDisruption masterNodeDisruption = new LongGCDisruption(random(), oldMasterNode);

        // Save the majority side
        final List<String> majoritySide = new ArrayList<>(nodes);
        majoritySide.remove(oldMasterNode);

        // Keeps track of the previous and current master when a master node transition took place on each node on the majority side:
        final Map<String, List<Tuple<String, String>>> masters = Collections.synchronizedMap(new HashMap<String, List<Tuple<String,
                        String>>>());
        for (final String node : majoritySide) {
            masters.put(node, new ArrayList<Tuple<String, String>>());
            internalCluster().getInstance(ClusterService.class, node).addListener(event -> {
                DiscoveryNode previousMaster = event.previousState().nodes().getMasterNode();
                DiscoveryNode currentMaster = event.state().nodes().getMasterNode();
                if (!Objects.equals(previousMaster, currentMaster)) {
                    logger.info(""node {} received new cluster state: {} \n and had previous cluster state: {}"", node, event.state(),
                            event.previousState());
                    String previousMasterNodeName = previousMaster != null ? previousMaster.getName() : null;
                    String currentMasterNodeName = currentMaster != null ? currentMaster.getName() : null;
                    masters.get(node).add(new Tuple<>(previousMasterNodeName, currentMasterNodeName));
                }
            });
        }

        final CountDownLatch oldMasterNodeSteppedDown = new CountDownLatch(1);
        internalCluster().getInstance(ClusterService.class, oldMasterNode).addListener(event -> {
            if (event.state().nodes().getMasterNodeId() == null) {
                oldMasterNodeSteppedDown.countDown();
            }
        });

        internalCluster().setDisruptionScheme(masterNodeDisruption);
        logger.info(""freezing node [{}]"", oldMasterNode);
        masterNodeDisruption.startDisrupting();

        // Wait for the majority side to get stable
        assertDifferentMaster(majoritySide.get(0), oldMasterNode);
        assertDifferentMaster(majoritySide.get(1), oldMasterNode);

        // the test is periodically tripping on the following assertion. To find out which threads are blocking the nodes from making
        // progress we print a stack dump
        boolean failed = true;
        try {
            assertDiscoveryCompleted(majoritySide);
            failed = false;
        } finally {
            if (failed) {
                logger.error(""discovery failed to complete, probably caused by a blocked thread: {}"",
                        new HotThreads().busiestThreads(Integer.MAX_VALUE).ignoreIdleThreads(false).detect());
            }
        }

        // The old master node is frozen, but here we submit a cluster state update task that doesn't get executed,
        // but will be queued and once the old master node un-freezes it gets executed.
        // The old master node will send this update + the cluster state where he is flagged as master to the other
        // nodes that follow the new master. These nodes should ignore this update.
        internalCluster().getInstance(ClusterService.class, oldMasterNode).submitStateUpdateTask(""sneaky-update"", new
                ClusterStateUpdateTask(Priority.IMMEDIATE) {
                    @Override
                    public ClusterState execute(ClusterState currentState) throws Exception {
                        return ClusterState.builder(currentState).build();
                    }
",non-flaky,5
156129,soot-oss_soot,LambdaMetaFactoryAdaptTest.parameterWidening,"  @Test
  public void parameterWidening() {
    String testClass = ""soot.lambdaMetaFactory.Adapt"";

    final SootMethod target = prepareTarget(methodSigFromComponents(testClass, ""void"", ""parameterWidening""), testClass);

    // TODO more fine-grained testing

    validateAllBodies(target.getDeclaringClass());
  }
",non-flaky,5
98044,vert-x3_vertx-mongo-client,RefCountTest.testNonShared,"  @Test
  public void testNonShared() {
    LocalMap<String, Object> map = getLocalMap();
    JsonObject config = getConfig();
    MongoClient client1 = MongoClient.create(vertx, config);
    assertEquals(1, map.size());
    MongoClient client2 = MongoClient.create(vertx, config);
    assertEquals(2, map.size());
    MongoClient client3 = MongoClient.create(vertx, config);
    assertEquals(3, map.size());
    client1.close();
    assertEquals(2, map.size());
    client2.close();
    assertEquals(1, map.size());
    client3.close();
    assertWaitUntil(() -> map.size() == 0);
    assertWaitUntil(() -> getLocalMap().size() == 0);
    assertWaitUntil(() -> map != getLocalMap()); // Map has been closed
  }
",non-flaky,5
42980,fabiomaffioletti_jsondoc,ApiObjectDocTest.testNoNameApiObjectDoc,"	@Test
	public void testNoNameApiObjectDoc() {
		Set<Class<?>> classes = new HashSet<Class<?>>();
		classes.add(NoNameApiObject.class);
		ApiObjectDoc apiObjectDoc = jsondocScanner.getApiObjectDocs(classes).iterator().next();
		Assert.assertEquals(""nonameapiobject"", apiObjectDoc.getName());
		Assert.assertEquals(""id"", apiObjectDoc.getFields().iterator().next().getName());
		Assert.assertEquals(1, apiObjectDoc.getJsondochints().size());
	}
",non-flaky,5
113898,spring-projects_spring-data-couchbase,ReactiveCouchbaseTemplateQueryCollectionIntegrationTests.replaceByIdOptions,"	@Test
	public void replaceByIdOptions() { // 9 - options
		ReplaceOptions options = ReplaceOptions.replaceOptions().timeout(Duration.ofNanos(10));
		assertThrows(AmbiguousTimeoutException.class, () -> template.replaceById(Airport.class).inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie.withIcao(""newIcao"")).block());
	}
",non-flaky,5
96017,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherBeginEnd,"  @Test
  public void testTokenSequenceMatcherBeginEnd() throws IOException {
    CoreMap doc = createDocument(testText);

    // Test simple sequence with begin sequence matching
    TokenSequencePattern p = TokenSequencePattern.compile(""^ [] []"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));

    boolean match = m.find();
    assertTrue(match);
    assertEquals(""the number"", m.group());

    match = m.find();
    assertFalse(match);

    // Test simple sequence with end sequence matching
    p = TokenSequencePattern.compile(""[] [] $"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));

    match = m.find();
    assertTrue(match);
    assertEquals(""fifty."", m.group());

    match = m.find();
    assertFalse(match);

    // Test simple sequence with begin and end sequence matching
    p = TokenSequencePattern.compile(""^ [] [] $"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));

    match = m.find();
    assertFalse(match);

    // Test simple sequence with ^$ in a string regular expression
    p = TokenSequencePattern.compile(""/^number$/"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));

    match = m.find();
    assertTrue(match);
    assertEquals(""number"", m.group());

    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
91421,strapdata_elassandra,RemoteIndexAuditTrailStartingTests.transportSSLEnabled,"@TestLogging(""org.elasticsearch.xpack.security.audit.index:TRACE"")
    public boolean transportSSLEnabled() {
        return sslEnabled;
    }
",non-flaky,5
60881,apache_druid,MaterializedViewSupervisorTest.testCheckSegments,"  @Test
  public void testCheckSegments() throws IOException
  {
    Set<DataSegment> baseSegments = Sets.newHashSet(
        new DataSegment(
            ""base"",
            Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""),
            ""2015-01-02"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        ),
        new DataSegment(
            ""base"",
            Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
            ""2015-01-03"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        ),
        new DataSegment(
            ""base"",
            Intervals.of(""2015-01-03T00Z/2015-01-04T00Z""),
            ""2015-01-04"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        )
    );
    Set<DataSegment> derivativeSegments = Sets.newHashSet(
        new DataSegment(
            derivativeDatasourceName,
            Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""),
            ""2015-01-02"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        ),
        new DataSegment(
            derivativeDatasourceName,
            Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
            ""3015-01-01"",
            ImmutableMap.of(),
            ImmutableList.of(""dim1"", ""dim2""),
            ImmutableList.of(""m1""),
            new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
            9,
            1024
        )
    );
    indexerMetadataStorageCoordinator.announceHistoricalSegments(baseSegments);
    indexerMetadataStorageCoordinator.announceHistoricalSegments(derivativeSegments);
    EasyMock.expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes();
    EasyMock.expect(taskMaster.getTaskRunner()).andReturn(Optional.absent()).anyTimes();
    EasyMock.expect(taskStorage.getActiveTasks()).andReturn(ImmutableList.of()).anyTimes();
    Pair<SortedMap<Interval, String>, Map<Interval, List<DataSegment>>> toBuildInterval = supervisor.checkSegments();
    Set<Interval> expectedToBuildInterval = Sets.newHashSet(Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""));
    Map<Interval, List<DataSegment>> expectedSegments = new HashMap<>();
    expectedSegments.put(
        Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""),
        Collections.singletonList(
            new DataSegment(
                ""base"",
                Intervals.of(""2015-01-01T00Z/2015-01-02T00Z""),
                ""2015-01-02"",
                ImmutableMap.of(),
                ImmutableList.of(""dim1"", ""dim2""),
                ImmutableList.of(""m1""),
                new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
                9,
                1024
            )
        )
    );
    expectedSegments.put(
        Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
        Collections.singletonList(
            new DataSegment(
                ""base"",
                Intervals.of(""2015-01-02T00Z/2015-01-03T00Z""),
                ""2015-01-03"",
                ImmutableMap.of(),
                ImmutableList.of(""dim1"", ""dim2""),
                ImmutableList.of(""m1""),
                new HashBasedNumberedShardSpec(0, 1, 0, 1, null, null, null),
                9,
                1024
            )
        )
    );
    Assert.assertEquals(expectedToBuildInterval, toBuildInterval.lhs.keySet());
    Assert.assertEquals(expectedSegments, toBuildInterval.rhs);
  }
",non-flaky,5
26198,Ericsson_ecchronos,TestScheduleManager.run,"    @Test (timeout = 2000L)
    public void testRemoveLongRunningJob() throws InterruptedException
    {
        LongRunningJob job = new LongRunningJob(ScheduledJob.Priority.HIGH);
        myScheduler.schedule(job);

        final CountDownLatch cdl = new CountDownLatch(1);

        new Thread()
        {
            @Override
            public void run()
            {
                myScheduler.run();
                cdl.countDown();
            }
",non-flaky,5
150142,apache_hive,TestHplsqlLocal.testCreateFunction4,"  @Test
  public void testCreateFunction4() throws Exception {
    run(""create_function4"");
  }
",non-flaky,5
177199,line_armeria,SpringTomcatApplicationItTest.contextLoads,"    @Test
    public void contextLoads() {
        assertThat(greetingController).isNotNull();
    }
",non-flaky,5
156141,soot-oss_soot,AbnormalTest.testMethodWithNoInstruction,"    @Test
    public void testMethodWithNoInstruction() {
        setup();
        Options.v().set_output_format(Options.output_format_jimple);
        runTest();
        setup();
        Options.v().set_output_format(Options.output_format_grimp);
        runTest();
        setup();
        Options.v().set_output_format(Options.output_format_baf);
        runTest();
        setup();
        Options.v().set_output_format(Options.output_format_dava);
        runTest();
        setup();
        Options.v().set_output_format(Options.output_format_shimp);
        runTest();
        setup();
        Options.v().set_output_format(Options.output_format_class);
        runTest();
    }
",non-flaky,5
177204,line_armeria,SpringTomcatApplicationItTest.greetingShouldReturn404,"    @Test
    public void greetingShouldReturn404() throws Exception {
        assertThat(restTemplate.getForEntity(""http://localhost:"" +
                                             httpPort +
                                             ""/tomcat/api/rest/v1/greet"",
                                             Void.class)
                               .getStatusCode()).isEqualByComparingTo(HttpStatus.NOT_FOUND);
    }
",non-flaky,5
156161,soot-oss_soot,TypingMinimizeTest.testMostCommonTypingPairs_2,"  @Test
  public void testMostCommonTypingPairs_2() {

    logger.debug(""Starting Object Random Minimize"");

    List<Typing> typingList = new ArrayList<>();

    Type Type1 = serializableType;
    Type Type2 = comparableType;
    Type Type3 = numberType;
    Local x1 = new JimpleLocal(""$x1"", null);

    Typing typing1 = new Typing(Arrays.asList(x1));
    typing1.set(x1, Type1);
    typingList.add(typing1);

    Typing typing2 = new Typing(Arrays.asList(x1));
    typing2.set(x1, Type2);
    typingList.add(typing2);

    Typing typing3 = new Typing(Arrays.asList(x1));
    typing3.set(x1, Type3);
    typingList.add(typing3);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(2, typingList.size());
    assertThat(typingList, containsInAnyOrder(typing2, typing3));
  }
",non-flaky,5
156139,soot-oss_soot,LoadingTest.testLoadingJava11ClassFromCI,"  @Test
  public void testLoadingJava11ClassFromCI() {
    G.reset();
    Main.main(new String[] { ""-soot-modulepath"", ""VIRTUAL_FS_FOR_JDK"", ""-pp"", ""-src-prec"", ""only-class"",
        ""java.lang.invoke.ConstantBootstraps"" });

    SootClass klass = Scene.v().getSootClass(""java.lang.invoke.ConstantBootstraps"");
    assertTrue(klass.getName().equals(""java.lang.invoke.ConstantBootstraps""));
    assertTrue(klass.moduleName.equals(""java.base""));

  }
",non-flaky,5
97950,ReactiveX_RxJava,ZipTests.testCovarianceOfZip,"    @Test
    public void testCovarianceOfZip() {
        Observable<HorrorMovie> horrors = Observable.from(new HorrorMovie());
        Observable<CoolRating> ratings = Observable.from(new CoolRating());

        Observable.<Movie, CoolRating, Result> zip(horrors, ratings, combine).toBlockingObservable().forEach(action);
        Observable.<Movie, CoolRating, Result> zip(horrors, ratings, combine).toBlockingObservable().forEach(action);
        Observable.<Media, Rating, ExtendedResult> zip(horrors, ratings, combine).toBlockingObservable().forEach(extendedAction);
        Observable.<Media, Rating, Result> zip(horrors, ratings, combine).toBlockingObservable().forEach(action);
        Observable.<Media, Rating, ExtendedResult> zip(horrors, ratings, combine).toBlockingObservable().forEach(action);

        Observable.<Movie, CoolRating, Result> zip(horrors, ratings, combine);
    }
",non-flaky,5
104638,apache_pinot,OfflineClusterIntegrationTest.testBloomFilterTriggering,"  @Test(dependsOnMethods = ""testDefaultColumns"")
  public void testBloomFilterTriggering()
      throws Exception {
    long numTotalDocs = getCountStarResult();
    assertEquals(postQuery(TEST_UPDATED_BLOOM_FILTER_QUERY).get(""numSegmentsProcessed"").asLong(), NUM_SEGMENTS);

    // Update table config and trigger reload
    TableConfig tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setBloomFilterColumns(UPDATED_BLOOM_FILTER_COLUMNS);
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_BLOOM_FILTER_QUERY);
        // Total docs should not change during reload
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numSegmentsProcessed"").asLong() == 0L;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to generate bloom filter"");

    // Update table config to remove the new bloom filter, and
    // reload table to clean the new bloom filter physically.
    tableConfig = getOfflineTableConfig();
    tableConfig.getIndexingConfig().setBloomFilterColumns(getBloomFilterColumns());
    updateTableConfig(tableConfig);
    reloadOfflineTable(getTableName());
    TestUtils.waitForCondition(aVoid -> {
      try {
        JsonNode queryResponse = postQuery(TEST_UPDATED_BLOOM_FILTER_QUERY);
        // Total docs should not change during reload, but num entries scanned
        // gets back to total number of documents as bloom filter is removed.
        assertEquals(queryResponse.get(""totalDocs"").asLong(), numTotalDocs);
        return queryResponse.get(""numSegmentsProcessed"").asLong() == NUM_SEGMENTS;
      } catch (Exception e) {
        throw new RuntimeException(e);
      }
    }, 600_000L, ""Failed to cleanup obsolete index"");
    assertEquals(getTableSize(getTableName()), _tableSizeAfterRemovingIndex);
  }
",non-flaky,5
110103,Wikidata_wikidata-toolkit,DumpProcessingOutputActionTest.testDefaults,"	@Test
	public void testDefaults() {
		String[] args = new String[] { ""-a"", ""json"" };
		DumpProcessingOutputAction action = getActionFromArgs(args);

		assertEquals(action.compressionType,
				DumpProcessingOutputAction.COMPRESS_NONE);
		assertFalse(action.useStdOut);
	}
",non-flaky,5
38215,palantir_atlasdb,RocksDbKeyValueServiceTest.testLockFile,"    @Test
    public void testLockFile() {
        try {
            RocksDbKeyValueService db2 = RocksDbKeyValueService.create(""testdb""); // tempted to make IBM DB2 joke
            assertTrue(""RocksDBKVS should protect against concurrent instances with a lock"", false);
        } catch (RuntimeException e) {
            assertTrue(""Unknown exception type thrown; expected IOException when two RocksDBs are pointed at same directory"", e.getCause() instanceof IOException);
        }
    }
",non-flaky,5
92693,apache_dubbo,ProviderConfigTest.testDispatcher,"    @Test
    public void testDispatcher() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setDispatcher(""mockdispatcher"");
        assertThat(provider.getDispatcher(), equalTo(""mockdispatcher""));
    }
",non-flaky,5
110150,Wikidata_wikidata-toolkit,ClientConfigurationTest.testLocalDumpFileShort,"	@Test
	public void testLocalDumpFileShort() {
		DirectoryManagerFactory
				.setDirectoryManagerClass(MockDirectoryManager.class);
		String[] args = new String[] { ""-i"", ""dumptest.json"" };
		ClientConfiguration config = new ClientConfiguration(args);

		MwDumpFile df = config.getLocalDumpFile();

		assertEquals(""dumptest.json"", config.getInputDumpLocation());
		assertTrue(df instanceof MwLocalDumpFile);
		MwLocalDumpFile ldf = (MwLocalDumpFile) df;

		assertEquals(Paths.get(""dumptest.json"").toAbsolutePath(), ldf.getPath());
	}
",non-flaky,5
179419,abel533_Mapper,NameStyleTest.testCamelhump,"    @Test
    public void testCamelhump(){
        EntityHelper.initEntityNameMap(UserCamelhump.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserCamelhump.class);
        Assert.assertNotNull(entityTable);
        Assert.assertEquals(""user_camelhump"", entityTable.getName());

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertEquals(""user_name"", column.getColumn());
            Assert.assertEquals(""userName"", column.getProperty());

            Assert.assertEquals(""user_name = #{userName}"", column.getColumnEqualsHolder());
            Assert.assertEquals(""user_name = #{record.userName}"", column.getColumnEqualsHolder(""record""));
            Assert.assertEquals(""#{userName}"", column.getColumnHolder());
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record""));
            Assert.assertEquals(""#{record.userName}"", column.getColumnHolder(""record"", ""suffix""));
            Assert.assertEquals(""#{record.userNamesuffix},"", column.getColumnHolder(""record"", ""suffix"", "",""));
            Assert.assertNull(column.getTypeHandler());
        }

        ResultMap resultMap = entityTable.getResultMap(configuration);
        Assert.assertEquals(""[USER_NAME]"", resultMap.getMappedColumns().toString());

        Assert.assertEquals(1, resultMap.getResultMappings().size());

        ResultMapping resultMapping = resultMap.getResultMappings().get(0);
        Assert.assertEquals(""user_name"", resultMapping.getColumn());
        Assert.assertEquals(""userName"", resultMapping.getProperty());
        Assert.assertNull(resultMapping.getJdbcType());
        Assert.assertEquals(StringTypeHandler.class, resultMapping.getTypeHandler().getClass());
    }
",non-flaky,5
122639,vespa-engine_vespa,YumTest.testAlreadyUpgraded,"    @Test
    public void testAlreadyUpgraded() {
        terminal.expectCommand(
                ""yum upgrade --assumeyes --setopt skip_missing_names_on_update=False package-1 package-2 2>&1"",
                0,
                ""foobar\nNo packages marked for update\n"");

        assertFalse(yum
                .upgrade(""package-1"", ""package-2"")
                .converge(taskContext));
    }
",non-flaky,5
38650,apache_pulsar,KinesisSinkTest.testCredentialProviderPlugin,"    @Test
    public void testCredentialProviderPlugin() throws Exception {
        KinesisSink sink = new KinesisSink();

        AWSCredentialsProvider credentialProvider = sink
                .createCredentialProviderWithPlugin(AwsCredentialProviderPluginImpl.class.getName(), ""{}"")
                .getCredentialProvider();
        Assert.assertNotNull(credentialProvider);
        Assert.assertEquals(credentialProvider.getCredentials().getAWSAccessKeyId(),
                AwsCredentialProviderPluginImpl.accessKey);
        Assert.assertEquals(credentialProvider.getCredentials().getAWSSecretKey(),
                AwsCredentialProviderPluginImpl.secretKey);
        Assert.assertEquals(((BasicSessionCredentials) credentialProvider.getCredentials()).getSessionToken(),
                AwsCredentialProviderPluginImpl.sessionToken);

        sink.close();
    }
",non-flaky,5
156056,jReddit_jReddit,RedditTokenTest.testGetters,"    @Test
    public void testGetters() {
        
        RedditToken subject = new RedditToken(jsonToken);
        RedditToken subjectUserProvided = new RedditToken(accessToken, tokenType, expiresIn, scope);
        assertEquals(accessToken, subject.getAccessToken());
        assertEquals(refreshToken, subject.getRefreshToken());
        assertEquals(tokenType, subject.getTokenType());
        assertEquals(expiresIn, subject.getExpirationSpan());
        assertTrue(subject.hasScope(RedditScope.EDIT));
        assertTrue(subject.hasScope(RedditScope.FLAIR));
        assertFalse(subject.hasScope(RedditScope.PRIVATEMESSAGE));
        assertTrue(subject.isRefreshable());
        assertFalse(subjectUserProvided.isRefreshable());
        
    }
",non-flaky,5
288,apache_pulsar,MessageIdTest.producerSendAsync,"@Test
@Test(timeOut = 10000)
public void producerSendAsync() throws PulsarClientException {
    String key = ""producerSendAsync"";
    final String topicName = ""persistent://prop/cluster/namespace/topic-"" + key;
    final String subscriptionName = ""my-subscription-"" + key;
    final String messagePredicate = ""my-message-"" + key + ""-"";
    final int numberOfMessages = 30;
    Producer<byte[]> producer = pulsarClient.newProducer().topic(topicName)
    .enableBatching(false)
    .messageRoutingMode(MessageRoutingMode.SinglePartition)
    .create();
    Consumer<byte[]> consumer = pulsarClient.newConsumer().topic(topicName).subscriptionName(subscriptionName)
    .subscribe();
    Set<MessageId> messageIds = new HashSet<>();
    List<Future<MessageId>> futures = new ArrayList<>();
    for (int i = 0; i < numberOfMessages; i++) {
        String message = messagePredicate + i;
        futures.add(producer.sendAsync(message.getBytes()));
    }
    MessageIdImpl previousMessageId = null;
    for (Future<MessageId> f : futures) {
        try {
            MessageIdImpl currentMessageId = (MessageIdImpl) f.get();
            if (previousMessageId != null) {
                Assert.assertTrue(currentMessageId.compareTo(previousMessageId) > 0,
                ""Message Ids should be in ascending order"");
            }
            messageIds.add(currentMessageId);
            previousMessageId = currentMessageId;
        } catch (Exception e) {
            Assert.fail(""Failed to publish message, Exception: "" + e.getMessage());
        }
    }
    log.info(""Message IDs = "" + messageIds);
    Assert.assertEquals(messageIds.size(), numberOfMessages, ""Not all messages published successfully"");
    for (int i = 0; i < numberOfMessages; i++) {
        Message<byte[]> message = consumer.receive();
        Assert.assertEquals(new String(message.getData()), messagePredicate + i);
        MessageId messageId = message.getMessageId();
        Assert.assertTrue(messageIds.remove(messageId), ""Failed to receive message"");
    }
    log.info(""Message IDs = "" + messageIds);
    Assert.assertEquals(messageIds.size(), 0, ""Not all messages received successfully"");
    consumer.unsubscribe();
}",async wait,0
178019,aosp-mirror_platform_frameworks_support,PlaybackControlGlueTest.testMediaPlayPauseButtonOnPlay,"    @Test
    public void testMediaPlayPauseButtonOnPlay() {
        PlaybackControlsRow row = new PlaybackControlsRow();
        glue.setControlsRow(row);
        SparseArrayObjectAdapter adapter = (SparseArrayObjectAdapter)
                row.getPrimaryActionsAdapter();
        PlaybackControlsRow.MultiAction playPause = (PlaybackControlsRow.MultiAction) adapter
                .lookup(PlaybackControlGlue.ACTION_PLAY_PAUSE);

        glue.onActionClicked(playPause);
        assertEquals(PlaybackControlGlue.PLAYBACK_SPEED_NORMAL, glue.getCurrentSpeedId());
        glue.onKey(null, KeyEvent.KEYCODE_MEDIA_PLAY_PAUSE, new KeyEvent(KeyEvent.ACTION_DOWN,
                KeyEvent.KEYCODE_MEDIA_PLAY_PAUSE));
        assertEquals(PlaybackControlGlue.PLAYBACK_SPEED_PAUSED, glue.getCurrentSpeedId());
    }
",non-flaky,5
77114,networknt_json-schema-validator,Issue366FailFastTest.firstOneValid,"  @Test
  public void firstOneValid() throws Exception {
    String dataPath = ""/data/issue366.json"";

    InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
    JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
    List<JsonNode> testNodes = node.findValues(""tests"");
    JsonNode testNode = testNodes.get(0).get(0);
    JsonNode dataNode = testNode.get(""data"");
    Set<ValidationMessage> errors = jsonSchema.validate(dataNode);
    assertTrue(errors.isEmpty());
  }
",non-flaky,5
110166,Wikidata_wikidata-toolkit,DirectoryManagerTest.NoCreateFileAtomicInputStreamReadOnly,"	@Test(expected = IOException.class)
	public void NoCreateFileAtomicInputStreamReadOnly() throws IOException {
		ByteArrayInputStream in = new ByteArrayInputStream(
				""new contents"".getBytes(StandardCharsets.UTF_8));
		dm.createFileAtomic(""new-test-file.txt"", in);
	}
",non-flaky,5
110195,Wikidata_wikidata-toolkit,RdfConverterTest.testWriteBasicDeclarations,"	@Test
	public void testWriteBasicDeclarations() throws RDFHandlerException,
			RDFParseException, IOException {
		this.rdfConverter.writeBasicDeclarations();
		this.rdfWriter.finish();
		Model model = RdfTestHelpers.parseRdf(this.out.toString());
		assertEquals(RdfTestHelpers.parseRdf(RdfTestHelpers
				.getResourceFromFile(""BasicDeclarations.rdf"")), model);
	}
",non-flaky,5
26238,Ericsson_ecchronos,TestTableRepairJob.testPostExecuteRepaired,"    @Test
    public void testPostExecuteRepaired()
    {
        // mock
        long repairedAt = System.currentTimeMillis();
        doReturn(repairedAt).when(myRepairStateSnapshot).lastCompletedAt();
        doReturn(false).when(myRepairStateSnapshot).canRepair();

        myRepairJob.postExecute(true, null);

        assertThat(myRepairJob.getLastSuccessfulRun()).isEqualTo(repairedAt);
        verify(myRepairState, times(1)).update();
    }
",non-flaky,5
349,apache_hadoop,TestNetworkTopology.testGetDistance,"  @Test
  public void testGetDistance() throws Exception {
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[0]), 0);
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[1]), 2);
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[3]), 4);
    assertEquals(cluster.getDistance(dataNodes[0], dataNodes[6]), 6);
    // verify the distance is zero as long as two nodes have the same path.
    // They don't need to refer to the same object.
    NodeBase node1 = new NodeBase(dataNodes[0].getHostName(),
        dataNodes[0].getNetworkLocation());
    NodeBase node2 = new NodeBase(dataNodes[0].getHostName(),
        dataNodes[0].getNetworkLocation());
    assertEquals(0, cluster.getDistance(node1, node2));
    // verify the distance can be computed by path.
    // They don't need to refer to the same object or parents.
    NodeBase node3 = new NodeBase(dataNodes[3].getHostName(),
        dataNodes[3].getNetworkLocation());
    NodeBase node4 = new NodeBase(dataNodes[6].getHostName(),
        dataNodes[6].getNetworkLocation());
    assertEquals(0, NetworkTopology.getDistanceByPath(node1, node2));
    assertEquals(4, NetworkTopology.getDistanceByPath(node2, node3));
    assertEquals(6, NetworkTopology.getDistanceByPath(node2, node4));
  }
",non-flaky,5
43002,fabiomaffioletti_jsondoc,PlainSpringJSONDocScannerTest.testMergeApiDoc,"	@Test
	public void testMergeApiDoc() {
		Set<Class<?>> controllers = new LinkedHashSet<Class<?>>();
		controllers.add(SpringController.class);
		Set<ApiDoc> apiDocs = jsondocScanner.getApiDocs(controllers, MethodDisplay.URI);

		ApiDoc apiDoc = apiDocs.iterator().next();
		Assert.assertEquals(""SpringController"", apiDoc.getDescription());
		Assert.assertEquals(""SpringController"", apiDoc.getName());
		Assert.assertNotNull(apiDoc.getGroup());

		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			Assert.assertEquals(MethodDisplay.URI, apiMethodDoc.getDisplayMethodAs());
			Assert.assertNull(apiMethodDoc.getAuth());
			Assert.assertNull(apiMethodDoc.getSupportedversions());
			Assert.assertTrue(apiMethodDoc.getApierrors().isEmpty());
			Assert.assertNull(apiMethodDoc.getId());
			Assert.assertEquals("""", apiMethodDoc.getSummary());
			Assert.assertEquals("""", apiMethodDoc.getDescription());
			
			if (apiMethodDoc.getPath().contains(""/api/string/{name}"")) {
				Assert.assertEquals(2, apiMethodDoc.getHeaders().size());
				Set<ApiHeaderDoc> headers = apiMethodDoc.getHeaders();
				Iterator<ApiHeaderDoc> headersIterator = headers.iterator();
				ApiHeaderDoc headerTest = headersIterator.next();
				Assert.assertEquals(""header"", headerTest.getName());
				Assert.assertEquals(""test"", headerTest.getAllowedvalues()[0]);
				ApiHeaderDoc headerTwo = headersIterator.next();
				Assert.assertEquals(""header-two"", headerTwo.getName());
				Assert.assertEquals(""header-test"", headerTwo.getAllowedvalues()[0]);

				Assert.assertEquals(""string"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				Assert.assertEquals(""string"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""POST"", apiMethodDoc.getVerb().iterator().next().name());
				Assert.assertEquals(""application/json"", apiMethodDoc.getProduces().iterator().next());
				Assert.assertEquals(""application/json"", apiMethodDoc.getConsumes().iterator().next());
				Assert.assertEquals(""201 - Created"", apiMethodDoc.getResponsestatuscode());

				Set<ApiParamDoc> queryparameters = apiMethodDoc.getQueryparameters();
				Assert.assertEquals(4, queryparameters.size());
				Iterator<ApiParamDoc> qpIterator = queryparameters.iterator();
				ApiParamDoc apiParamDoc = qpIterator.next();
				Assert.assertEquals(""delete"", apiParamDoc.getName());
				Assert.assertEquals(""true"", apiParamDoc.getRequired());
				Assert.assertEquals(null, apiParamDoc.getDefaultvalue());
				Assert.assertEquals(0, apiParamDoc.getAllowedvalues().length);
				apiParamDoc = qpIterator.next();
				Assert.assertEquals(""id"", apiParamDoc.getName());
				Assert.assertEquals(""true"", apiParamDoc.getRequired());
				Assert.assertTrue(apiParamDoc.getDefaultvalue().isEmpty());
				apiParamDoc = qpIterator.next();
				Assert.assertEquals("""", apiParamDoc.getName());
				Assert.assertEquals(""true"", apiParamDoc.getRequired());
				Assert.assertEquals("""", apiParamDoc.getDefaultvalue());

				apiParamDoc = qpIterator.next();
				Assert.assertEquals(""user"", apiParamDoc.getName());
				Assert.assertEquals(""false"", apiParamDoc.getRequired());
				Assert.assertEquals(""admin"", apiParamDoc.getDefaultvalue());

				Set<ApiParamDoc> pathparameters = apiMethodDoc.getPathparameters();
				Iterator<ApiParamDoc> ppIterator = pathparameters.iterator();
				apiParamDoc = ppIterator.next();
				apiParamDoc = apiMethodDoc.getPathparameters().iterator().next();
				Assert.assertEquals(""test"", apiParamDoc.getName());
			}
		}

	}
",non-flaky,5
150177,apache_hive,TestHplsqlLocal.testLen,"  @Test
  public void testLen() throws Exception {
    run(""len"");
  }
",non-flaky,5
89298,apache_samza,TestLocalStoreMonitor.shouldContinueLocalStoreCleanUpAfterFailureToCleanUpStoreOfAJob,"  @Test
  public void shouldContinueLocalStoreCleanUpAfterFailureToCleanUpStoreOfAJob() throws Exception {
    File testFailingJobDir = new File(localStoreDir, ""test-jobName-jobId-1"");

    File testFailingTaskStoreDir = new File(new File(testFailingJobDir, ""test-store""), ""test-task"");

    FileUtils.forceMkdir(testFailingTaskStoreDir);

    // For job: test-jobName-jobId-1, throw up in getTasks call and
    // expect the cleanup to succeed for other job: test-jobName-jobId.
    Mockito.doThrow(new RuntimeException(""Dummy exception message.""))
        .when(jobsClientMock)
        .getTasks(new JobInstance(""test-jobName"", ""jobId-1""));

    Task task = new Task(""notLocalHost"", ""test-task"", ""0"", new ArrayList<>(), ImmutableList.of(""test-store""));

    Mockito.when(jobsClientMock.getTasks(new JobInstance(""test-jobName"", ""jobId""))).thenReturn(ImmutableList.of(task));

    Map<String, String> configMap = new HashMap<>(config);
    configMap.put(LocalStoreMonitorConfig.CONFIG_IGNORE_FAILURES, ""true"");

    LocalStoreMonitor localStoreMonitor =
        new LocalStoreMonitor(new LocalStoreMonitorConfig(new MapConfig(configMap)), localStoreMonitorMetrics,
            jobsClientMock);

    localStoreMonitor.monitor();

    // Non failing job directory should be cleaned up.
    assertTrue(""Task store directory should not exist."", !taskStoreDir.exists());
    FileUtils.deleteDirectory(testFailingJobDir);
  }
",non-flaky,5
60937,apache_druid,LongMeanAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new LongMeanAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(0.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(1.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3L), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 3), new HashMap<>());
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2L), new HashMap<>());
    Assert.assertEquals(2.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(4.0 / 3, avg.computeResult(), 0.0);
  }
",non-flaky,5
122616,vespa-engine_vespa,FileAttributesCacheTest.exists,"    @Test
    public void exists() {
        UnixPath unixPath = mock(UnixPath.class);
        FileAttributesCache cache = new FileAttributesCache(unixPath);

        when(unixPath.getAttributesIfExists()).thenReturn(Optional.empty());
        assertFalse(cache.get().isPresent());
        verify(unixPath, times(1)).getAttributesIfExists();
        verifyNoMoreInteractions(unixPath);

        FileAttributes attributes = mock(FileAttributes.class);
        when(unixPath.getAttributesIfExists()).thenReturn(Optional.of(attributes));
        assertTrue(cache.get().isPresent());
        verify(unixPath, times(1 + 1)).getAttributesIfExists();
        verifyNoMoreInteractions(unixPath);

        assertEquals(attributes, cache.getOrThrow());
        verifyNoMoreInteractions(unixPath);
    }
",non-flaky,5
371,apache_hadoop,TestPermissionSymlinks.testAclRenameTargetNotWritableFS,"  @Test
  public void testAclRenameTargetNotWritableFS() throws Exception {
    fs.setAcl(target, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    fs.setAcl(targetParent, Arrays.asList(
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, user.getUserName(), READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ALL),
      aclEntry(ACCESS, OTHER, ALL)));
    doRenameLinkTargetNotWritableFS();
  }
",non-flaky,5
96046,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testMultiPatternMatcher,"  @Test
  public void testMultiPatternMatcher() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test simple sequence
    TokenSequencePattern p1 = TokenSequencePattern.compile(""/Archbishop/ /of/ /Canterbury/"");
    p1.setPriority(1);
    TokenSequencePattern p2 = TokenSequencePattern.compile(""/[a-zA-Z]+/{1,2}  /of/ /[a-zA-Z]+/+"");
    MultiPatternMatcher<CoreMap> m = new MultiPatternMatcher<CoreMap>(p2,p1);
    List<SequenceMatchResult<CoreMap>> matched = m.findNonOverlapping(doc.get(CoreAnnotations.TokensAnnotation.class));
    assertEquals(4, matched.size());
    assertEquals(""first Bishop of London"", matched.get(0).group());
    assertEquals(""Archbishop of Canterbury"", matched.get(1).group());
    assertEquals(""a member of the Gregorian mission sent to England to convert the"", matched.get(2).group());
    assertEquals(""as Bishop of London in"", matched.get(3).group());
  }
",non-flaky,5
89358,apache_samza,TestKafkaCheckpointManager.testCreateResourcesTopicValidationError,"  @Test(expected = StreamValidationException.class)
  public void testCreateResourcesTopicValidationError() {
    setupSystemFactory(config());
    // throw an exception during validateStream
    doThrow(new StreamValidationException(""invalid stream"")).when(this.createResourcesSystemAdmin)
        .validateStream(CHECKPOINT_SPEC);
    KafkaCheckpointManager checkpointManager = buildKafkaCheckpointManager(true, config());
    // expect an exception during startup
    checkpointManager.createResources();
  }
",non-flaky,5
122600,vespa-engine_vespa,FileWriterTest.testAtomicWrite,"    @Test
    public void testAtomicWrite() {
        FileWriter writer = new FileWriter(fileSystem.getPath(""/foo/bar""))
                .atomicWrite(true);

        assertTrue(writer.converge(context, ""content""));

        verify(context).recordSystemModification(any(), eq(""Creating file /foo/bar""));
        assertEquals(""content"", new UnixPath(writer.path()).readUtf8File());
    }
",non-flaky,5
91487,strapdata_elassandra,IndexPrimaryRelocationIT.run,"    @TestLogging(""_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.index.shard:TRACE,org.elasticsearch.cluster.service:TRACE"")
    public void testPrimaryRelocationWhileIndexing() throws Exception {
        internalCluster().ensureAtLeastNumDataNodes(randomIntBetween(2, 3));
        client().admin().indices().prepareCreate(""test"")
            .setSettings(Settings.builder().put(""index.number_of_shards"", 1).put(""index.number_of_replicas"", 0))
            .addMapping(""type"", ""field"", ""type=text"")
            .get();
        ensureGreen(""test"");
        AtomicInteger numAutoGenDocs = new AtomicInteger();
        final AtomicBoolean finished = new AtomicBoolean(false);
        Thread indexingThread = new Thread() {
            @Override
            public void run() {
                while (finished.get() == false) {
                    IndexResponse indexResponse = client().prepareIndex(""test"", ""type"", ""id"").setSource(""field"", ""value"").get();
                    assertEquals(DocWriteResponse.Result.CREATED, indexResponse.getResult());
                    DeleteResponse deleteResponse = client().prepareDelete(""test"", ""type"", ""id"").get();
                    assertEquals(DocWriteResponse.Result.DELETED, deleteResponse.getResult());
                    client().prepareIndex(""test"", ""type"").setSource(""auto"", true).get();
                    numAutoGenDocs.incrementAndGet();
                }
            }
",non-flaky,5
97994,ReactiveX_RxJava,MergeTests.testMergeCovariance,"    @Test
    public void testMergeCovariance() {
        Observable<Media> o1 = Observable.<Media> from(new HorrorMovie(), new Movie());
        Observable<Media> o2 = Observable.from(new Media(), new HorrorMovie());

        Observable<Observable<Media>> os = Observable.from(o1, o2);

        List<Media> values = Observable.merge(os).toList().toBlockingObservable().single();
    }
",non-flaky,5
35721,cdapio_cdap,LocalLogAppenderResilientTest.addStatusEvent,"  @Test
  public void testResilientLogging() throws Exception {
    Configuration hConf = new Configuration();
    CConfiguration cConf = CConfiguration.create();

    File datasetDir = new File(tmpFolder.newFolder(), ""datasetUser"");
    //noinspection ResultOfMethodCallIgnored
    datasetDir.mkdirs();

    cConf.set(Constants.Dataset.Manager.OUTPUT_DIR, datasetDir.getAbsolutePath());
    cConf.set(Constants.Service.MASTER_SERVICES_BIND_ADDRESS, ""localhost"");

    cConf.set(Constants.Dataset.Executor.ADDRESS, ""localhost"");
    cConf.setInt(Constants.Dataset.Executor.PORT, Networks.getRandomPort());

    cConf.set(Constants.CFG_LOCAL_DATA_DIR, tmpFolder.newFolder().getAbsolutePath());

    Injector injector = Guice.createInjector(
      new ConfigModule(cConf, hConf),
      new IOModule(),
      new ZKClientModule(),
      new KafkaClientModule(),
      new InMemoryDiscoveryModule(),
      new NonCustomLocationUnitTestModule(),
      new DataFabricModules().getInMemoryModules(),
      new DataSetsModules().getStandaloneModules(),
      new DataSetServiceModules().getInMemoryModules(),
      new TransactionMetricsModule(),
      new ExploreClientModule(),
      new LocalLogAppenderModule(),
      new NamespaceAdminTestModule(),
      new AuthorizationTestModule(),
      new AuthorizationEnforcementModule().getInMemoryModules(),
      new AuthenticationContextModules().getMasterModule(),
      new AbstractModule() {
        @Override
        protected void configure() {
          bind(UGIProvider.class).to(UnsupportedUGIProvider.class);
          bind(OwnerAdmin.class).to(NoOpOwnerAdmin.class);
          bind(MetadataServiceClient.class).to(NoOpMetadataServiceClient.class);
        }
      });

    TransactionManager txManager = injector.getInstance(TransactionManager.class);
    txManager.startAndWait();
    StructuredTableRegistry structuredTableRegistry = injector.getInstance(StructuredTableRegistry.class);
    structuredTableRegistry.initialize();
    StoreDefinition.createAllTables(injector.getInstance(StructuredTableAdmin.class), structuredTableRegistry);

    DatasetOpExecutorService opExecutorService = injector.getInstance(DatasetOpExecutorService.class);
    opExecutorService.startAndWait();

    // Start the logging before starting the service.
    LoggingContextAccessor.setLoggingContext(new WorkerLoggingContext(""TRL_ACCT_1"", ""APP_1"", ""WORKER_1"",
                                                                      ""RUN"", ""INSTANCE""));
    String logBaseDir = ""trl-log/log_files_"" + new Random(System.currentTimeMillis()).nextLong();

    cConf.set(LoggingConfiguration.LOG_BASE_DIR, logBaseDir);
    cConf.setInt(LoggingConfiguration.LOG_MAX_FILE_SIZE_BYTES, 20 * 1024);
    final LogAppender appender = injector.getInstance(LocalLogAppender.class);
    new LogAppenderInitializer(appender).initialize(""TestResilientLogging"");

    int failureMsgCount = 3;
    final CountDownLatch failureLatch = new CountDownLatch(failureMsgCount);
    LoggerContext loggerContext = (LoggerContext) LoggerFactory.getILoggerFactory();
    loggerContext.getStatusManager().add(new StatusListener() {
      @Override
      public void addStatusEvent(Status status) {
        if (status.getLevel() != Status.ERROR || status.getOrigin() != appender) {
          return;
        }
        Throwable cause = status.getThrowable();
        if (cause != null) {
          Throwable rootCause = Throwables.getRootCause(cause);
          if (rootCause instanceof ServiceUnavailableException) {
            String serviceName = ((ServiceUnavailableException) rootCause).getServiceName();
            if (Constants.Service.DATASET_MANAGER.equals(serviceName)) {
              failureLatch.countDown();
            }
          }
        }
      }
",non-flaky,5
162347,epimorphics_appbase,TestSource.testWrapper,"    @Test
    public void testWrapper() {
        // Labels
        assertEquals(""Pref label"", getNode(""test:i1"").getLabel());
        assertEquals(""Alt label"",  getNode(""test:i2"").getLabel());
        assertEquals(""rdfs label"", getNode(""test:i3"").getLabel());
        assertEquals(""name"",       getNode(""test:i4"").getLabel());
        
        WNode node = getNode(""test:i5"");
        assertEquals(""en label"", node.getLabel(""en""));
        assertEquals(""plain label"", node.getLabel(""cy""));
        
        assertTrue(node.isResource());
        assertTrue(node.isURIResource());
        assertFalse(node.isLiteral());
        assertEquals(""http://www.epimorphics.com/vocabs/test/i5"", node.getURI());
        
        DatasetGraph dsg = source.constructViews(""?uri skos:altLabel ?rdfs_label"", TEST_NS + ""i1"", TEST_NS + ""i2"");
        checkLabel(dsg, ""i1"", ""Alt label"");
        checkLabel(dsg, ""i2"", ""Alt label"");
        
        // General accessors
        WNode test = getNode(""test:test"");
        WNode v = test.getPropertyValue(""test:num"");
        assertNotNull(v);
        assertTrue(v.isLiteral());
        assertTrue(v.isNumber());
        assertEquals(42, v.asInt());
        
        v = test.getPropertyValue(""test:float"");
        assertNotNull(v);
        assertTrue(v.isLiteral());
        assertTrue(v.isNumber());
        assertEquals(3.14, v.asFloat(), 0.001);
        
        v = test.getPropertyValue(""test:string"");
        assertNotNull(v);
        assertEquals(""a string"", v.getLabel());
        
        List<WNode> values = test.listPropertyValues(""test:resource"");
        assertEquals(2, values.size());
        TestUtil.testArray(values, new WNode[]{ getNode(""test:i1""), getNode(""test:i2"")});
        
        // Lists
        WNode list = test.getPropertyValue(""test:list"");
        assertNotNull(list);
        assertTrue(list.isList());
        List<WNode> elts = list.asList();
        assertEquals(3,  elts.size());
        assertEquals(1, elts.get(0).asInt());
        assertEquals(3, elts.get(1).asInt());
        assertEquals(5, elts.get(2).asInt());
        
        // Connections
        checkConnections( getNode(""test:c"").listInLinks(""test:p""), new String[]{""test:a"", ""test:b""} );
        checkConnections( getNode(""test:d"").listInLinks(""test:p""), new String[]{""test:c""} );
        checkConnections( getNode(""test:c"").listInLinks(""test:q""), new String[]{""test:f""} );

        checkConnections( getNode(""test:c"").connectedNodes(""test:p / test:p""), new String[]{""test:e""} );
        
        List<PropertyValue> connections = getNode(""test:c"").listInLinks();
        assertEquals(2, connections.size());
        assertEquals(getNode(""test:p""), connections.get(0).getProp());
        checkConnections( connections.get(0).getValues(), new String[]{""test:a"", ""test:b""});
        assertEquals(getNode(""test:q""), connections.get(1).getProp());
        checkConnections( connections.get(1).getValues(), new String[]{""test:f""});
        
        // Text search
        List<WNode> matches = source.search(""aa"");
        assertEquals(1, matches.size());
        checkConnections(matches, new String[]{""test:a""});

        matches = source.search(""label"");
        assertEquals(4, matches.size());
        checkConnections(matches, new String[]{""test:i1"", ""test:i2"", ""test:i3"", ""test:i5""});
        
        matches = source.search(""label"", 2);
        assertEquals(2, matches.size());
        
        matches = source.search(""pref"");
        assertEquals(1, matches.size());
        checkConnections(matches, new String[]{""test:i1""});
    }
",non-flaky,5
89367,apache_samza,TestKafkaCheckpointManager.testReadEmpty,"  @Test
  public void testReadEmpty() throws InterruptedException {
    setupSystemFactory(config());
    setupConsumer(ImmutableList.of());
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config());
    kafkaCheckpointManager.register(TASK0);
    assertNull(kafkaCheckpointManager.readLastCheckpoint(TASK0));
  }
",non-flaky,5
114043,aws_aws-sdk-java-v2,PutItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Record record = new Record().setId(1).setId2(10);
        PutItemEnhancedRequest<Record> request = PutItemEnhancedRequest.builder(Record.class)
                                                                       .item(record)
                                                                       .returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE)
                                                                       .build();

        PutItemEnhancedResponse<Record> response = mappedTable.putItemWithResponse(request);

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
96889,apache_avro,TestSchemas.testVisit2,"  @Test
  public void testVisit2() {
    String s2 = ""{\""type\"": \""record\"", \""name\"": \""c1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": \""int\""}"" +
        ""]}"";
    Assert.assertEquals(""c1.\""int\""!"", Schemas.visit(new Schema.Parser().parse(s2), new TestVisitor()));

  }
",non-flaky,5
156115,soot-oss_soot,AbstractLambdaMetaFactoryCGTest.lambdaNoCaptures,"  @Test
  public void lambdaNoCaptures() {
    String testClass = ""soot.lambdaMetaFactory.LambdaNoCaptures"";

    final SootMethod target = prepareTarget(methodSigFromComponents(testClass, TEST_METHOD_RET, TEST_METHOD_NAME), testClass,
        ""java.util.function.Function"");

    final CallGraph cg = Scene.v().getCallGraph();

    final String metaFactoryClass = getMetaFactoryNameLambda(testClass, TEST_METHOD_NAME);

    final SootMethod bootstrap
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.util.function.Function"", ""bootstrap$""));
    final SootMethod metaFactoryConstructor
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""void"", ""<init>""));
    final SootMethod apply
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.lang.Object"", ""apply"", ""java.lang.Object""));
    final SootMethod lambdaBody
        = Scene.v().getMethod(methodSigFromComponents(testClass, ""java.lang.String"", ""lambda$main$0"", ""java.lang.Integer""));
    final SootMethod staticCallee
        = Scene.v().getMethod(methodSigFromComponents(testClass, ""void"", ""staticCallee"", ""java.lang.Integer""));

    final List<Edge> edgesFromTarget = newArrayList(cg.edgesOutOf(target));

    assertTrue(""There should be an edge from main to the bootstrap method of the synthetic LambdaMetaFactory"",
        edgesFromTarget.stream().anyMatch(e -> e.tgt().equals(bootstrap) && e.isStatic()));
    assertTrue(""There should be an edge to the constructor of the LambdaMetaFactory in the bootstrap method"",
        newArrayList(cg.edgesOutOf(bootstrap)).stream()
            .anyMatch(e -> e.tgt().equals(metaFactoryConstructor) && e.isSpecial()));
    assertTrue(
        ""There should be an instance invocation on the synthetic LambdaMetaFactory's implementation of the functional interface in the main method"",
        edgesFromTarget.stream().anyMatch(e -> e.getTgt().equals(apply) && e.kind() == Kind.INTERFACE));
    assertTrue(
        ""There should be a static call to the lambda body implementation in the generated functional interface implementation of the synthetic LambdaMetaFactory"",
        newArrayList(cg.edgesOutOf(apply)).stream().anyMatch(e -> e.getTgt().equals(lambdaBody) && e.isStatic()));

    assertTrue(""There should be a static call to the staticCallee method in actual lambda body implementation"",
        newArrayList(cg.edgesOutOf(lambdaBody)).stream().anyMatch(e -> e.getTgt().equals(staticCallee) && e.isStatic()));

    validateAllBodies(target.getDeclaringClass(), bootstrap.getDeclaringClass());
  }
",non-flaky,5
38654,apache_pulsar,SourceTest.testSinkContext,"    @Test
    public void testSinkContext() throws Exception {
        SourceContext sourceContext = mock(SourceContext.class);

        Source testSource = spy(TestSource.class);
        testSource.open(new HashMap<>(), sourceContext);

        verify(sourceContext, times(1)).recordMetric(""foo"", 1);
    }
",non-flaky,5
98029,vert-x3_vertx-mongo-client,MongoClientUpdateResultTest.testJsonMongoClientUpdateResult,"  @Test
  public void testJsonMongoClientUpdateResult() {
    properJson();

    jsonWithoutRequiredFields();
  }
",non-flaky,5
88806,apache_ignite,IgniteBinaryTest.testBinaryObjectPutGet,"    @Test
    public void testBinaryObjectPutGet() throws Exception {
        int key = 1;

        try (Ignite ignored = Ignition.start(Config.getServerConfiguration())) {
            try (IgniteClient client =
                     Ignition.startClient(new ClientConfiguration().setAddresses(Config.SERVER))
            ) {
                IgniteBinary binary = client.binary();

                BinaryObject val = binary.builder(""Person"")
                    .setField(""id"", 1, int.class)
                    .setField(""name"", ""Joe"", String.class)
                    .build();

                ClientCache<Integer, BinaryObject> cache = client.cache(Config.DEFAULT_CACHE_NAME).withKeepBinary();

                cache.put(key, val);

                BinaryObject cachedVal =
                    client.cache(Config.DEFAULT_CACHE_NAME).<Integer, BinaryObject>withKeepBinary().get(key);

                assertBinaryObjectsEqual(val, cachedVal);
            }
        }
    }
",non-flaky,5
38700,apache_pulsar,ElasticSearchExtractTests.getSchemaType,"    @Test
    public void testKeyValueGenericRecord() throws Exception {
        RecordSchemaBuilder keySchemaBuilder = org.apache.pulsar.client.api.schema.SchemaBuilder.record(""key"");
        keySchemaBuilder.field(""a"").type(SchemaType.STRING).optional().defaultValue(null);
        keySchemaBuilder.field(""b"").type(SchemaType.INT32).optional().defaultValue(null);
        GenericSchema<GenericRecord> keySchema = Schema.generic(keySchemaBuilder.build(schemaType));
        GenericRecord keyGenericRecord = keySchema.newRecordBuilder()
                .set(""a"", ""1"")
                .set(""b"", 1)
                .build();

        RecordSchemaBuilder valueSchemaBuilder = org.apache.pulsar.client.api.schema.SchemaBuilder.record(""value"");
        valueSchemaBuilder.field(""c"").type(SchemaType.STRING).optional().defaultValue(null);
        valueSchemaBuilder.field(""d"").type(SchemaType.INT32).optional().defaultValue(null);
        RecordSchemaBuilder udtSchemaBuilder = SchemaBuilder.record(""type1"");
        udtSchemaBuilder.field(""a"").type(SchemaType.STRING).optional().defaultValue(null);
        udtSchemaBuilder.field(""b"").type(SchemaType.BOOLEAN).optional().defaultValue(null);
        udtSchemaBuilder.field(""d"").type(SchemaType.DOUBLE).optional().defaultValue(null);
        udtSchemaBuilder.field(""f"").type(SchemaType.FLOAT).optional().defaultValue(null);
        udtSchemaBuilder.field(""i"").type(SchemaType.INT32).optional().defaultValue(null);
        udtSchemaBuilder.field(""l"").type(SchemaType.INT64).optional().defaultValue(null);
        GenericSchema<GenericRecord> udtGenericSchema = Schema.generic(udtSchemaBuilder.build(schemaType));
        valueSchemaBuilder.field(""e"", udtGenericSchema).type(schemaType).optional().defaultValue(null);
        GenericSchema<GenericRecord> valueSchema = Schema.generic(valueSchemaBuilder.build(schemaType));

        GenericRecord valueGenericRecord = valueSchema.newRecordBuilder()
                .set(""c"", ""1"")
                .set(""d"", 1)
                .set(""e"", udtGenericSchema.newRecordBuilder()
                        .set(""a"", ""a"")
                        .set(""b"", true)
                        .set(""d"", 1.0)
                        .set(""f"", 1.0f)
                        .set(""i"", 1)
                        .set(""l"", 10L)
                        .build())
                .build();

        Schema<KeyValue<GenericRecord, GenericRecord>> keyValueSchema = Schema.KeyValue(keySchema, valueSchema, KeyValueEncodingType.INLINE);
        KeyValue<GenericRecord, GenericRecord> keyValue = new KeyValue<>(keyGenericRecord, valueGenericRecord);
        GenericObject genericObject = new GenericObject() {
            @Override
            public SchemaType getSchemaType() {
                return SchemaType.KEY_VALUE;
            }
",non-flaky,5
84562,apache_zookeeper,DistributedQueueTest.testTake1,"    @Test
    public void testTake1() throws Exception {
        String dir = ""/testTake1"";
        String testString = ""Hello World"";
        final int numClients = 1;
        ZooKeeper[] clients = new ZooKeeper[numClients];
        DistributedQueue[] queueHandles = new DistributedQueue[numClients];
        for (int i = 0; i < clients.length; i++) {
            clients[i] = createClient();
            queueHandles[i] = new DistributedQueue(clients[i], dir, null);
        }

        queueHandles[0].offer(testString.getBytes());

        byte[] dequeuedBytes = queueHandles[0].take();
        assertEquals(new String(dequeuedBytes), testString);
    }
",non-flaky,5
70816,apache_kafka,PluginsTest.shouldShareStaticValuesBetweenSamePlugin,"    @Test
    public void shouldShareStaticValuesBetweenSamePlugin() {
        // Plugins are not isolated from other instances of their own class.
        TestPlugins.assertAvailable();
        Converter firstPlugin = plugins.newPlugin(
            TestPlugins.ALIASED_STATIC_FIELD,
            new AbstractConfig(new ConfigDef(), Collections.emptyMap()),
            Converter.class
        );

        assertInstanceOf(SamplingTestPlugin.class, firstPlugin, ""Cannot collect samples"");

        Converter secondPlugin = plugins.newPlugin(
            TestPlugins.ALIASED_STATIC_FIELD,
            new AbstractConfig(new ConfigDef(), Collections.emptyMap()),
            Converter.class
        );

        assertInstanceOf(SamplingTestPlugin.class, secondPlugin, ""Cannot collect samples"");
        assertSame(
            ((SamplingTestPlugin) firstPlugin).otherSamples(),
            ((SamplingTestPlugin) secondPlugin).otherSamples()
        );
    }
",non-flaky,5
31011,camunda-cloud_zeebe,ArrayValueTest.shouldIncreaseInternalBufferWhenAddingToBeginning,"  @Test
  public void shouldIncreaseInternalBufferWhenAddingToBeginning() {
    // given
    final int valueCount = 10_000;
    final List<Integer> generatedList =
        IntStream.iterate(0, (i) -> ++i).limit(valueCount).boxed().collect(Collectors.toList());
    final List<Integer> reverseList = new ArrayList<>(generatedList);
    Collections.reverse(generatedList);

    final Integer[] values = generatedList.toArray(new Integer[valueCount]);

    // when
    for (final Integer value : values) {
      // reset cursor to first position
      array.iterator();
      array.add().setValue(value);
    }

    // then
    encodeAndDecode(array);

    final Integer[] resultValues = reverseList.toArray(new Integer[valueCount]);
    assertIntValues(array, resultValues);
  }
",non-flaky,5
91423,strapdata_elassandra,LicensingTests.nodeSettings,"@TestLogging(""org.elasticsearch.cluster.service:TRACE,org.elasticsearch.discovery.zen:TRACE,org.elasticsearch.action.search:TRACE,"" +
    public Settings nodeSettings(int nodeOrdinal) {
        return Settings.builder().put(super.nodeSettings(nodeOrdinal))
                .put(NetworkModule.HTTP_ENABLED.getKey(), true)
            .put(TestZenDiscovery.USE_MOCK_PINGS.getKey(), false)
                .build();
    }
",non-flaky,5
133899,cdancy_jenkins-rest,PluginManagerApiLiveTest.testGetPlugins,"    @Test
    public void testGetPlugins() {
        final Plugins plugins = api().plugins(3, null);
        assertNotNull(plugins);
        assertTrue(plugins.errors().isEmpty());
        assertFalse(plugins.plugins().isEmpty());
        assertNotNull(plugins.plugins().get(0).shortName());
    }
",non-flaky,5
38225,palantir_atlasdb,TextUtilsTest.testHexConverter,"    @Test
    public void testHexConverter(){
        byte[] bytes = new byte[]{(byte)255, (byte)255, 0, 0};
        System.out.println(Arrays.toString(bytes) +"" -> 0x"" + TextUtils.byteArrayToHexString(bytes));
        assertEquals(""ffff0000"", TextUtils.byteArrayToHexString(bytes));
    }
",non-flaky,5
88853,apache_ignite,DatasetWrapperTest.testCompute,"    @Test
    public void testCompute() {
        doReturn(42).when(dataset).compute(any(IgniteBiFunction.class), any(), any());

        Integer res = (Integer) wrapper.compute(mock(IgniteBiFunction.class), mock(IgniteBinaryOperator.class),
            null);

        assertEquals(42, res.intValue());

        verify(dataset, times(1)).compute(any(IgniteBiFunction.class), any(), any());
    }
",non-flaky,5
91519,apache_kylin,KafkaInputRecordReaderTest.testGetCurrentValue,"    @Test
    public void testGetCurrentValue()  throws Throwable  {
        KafkaInputRecordReader kafkaInputRecordReader = new KafkaInputRecordReader();
        kafkaInputRecordReader.nextKeyValue();
        assertEquals(0, kafkaInputRecordReader.getCurrentValue().getBytes().length);
    }
",non-flaky,5
114036,aws_aws-sdk-java-v2,AppTest.handleRequest_shouldReturnConstantValue,"    @Test
    public void handleRequest_shouldReturnConstantValue() {
        App function = new App();
        Object result = function.handleRequest(""echo"", null);
        assertEquals(""echo"", result);
    }
",non-flaky,5
156134,soot-oss_soot,DexByteCodeInstrutionsTest.InvokeCustom1,"  @Test
  public void InvokeCustom1() {
    final SootMethod testTarget
        = prepareTarget(methodSigFromComponents(TARGET_CLASS, ""void invokeCustomTarget()""), TARGET_CLASS);

    // We model invokeCustom as invokeDynamic
    final List<InvokeExpr> invokes = invokesFromMethod(testTarget);
    Assert.assertEquals(1, invokes.size());
    final InvokeExpr invokeCustom = invokes.get(0);
    Assert.assertTrue(invokeCustom instanceof DynamicInvokeExpr);
    final SootMethodRef targetMethodRef = invokeCustom.getMethodRef();
    Assert.assertEquals(methodSigFromComponents(SootClass.INVOKEDYNAMIC_DUMMY_CLASS_NAME, SUPPLIER_GET_SUBSIG),
        targetMethodRef.getSignature());
    final String callToLambdaMethaFactory
        = ""dynamicinvoke \""get\"" <java.util.function.Supplier ()>() <java.lang.invoke.LambdaMetafactory: java.lang.invoke.CallSite metafactory(java.lang.invoke.MethodHandles$Lookup,java.lang.String,java.lang.invoke.MethodType,java.lang.invoke.MethodType,java.lang.invoke.MethodHandle,java.lang.invoke.MethodType)>(methodtype: java.lang.Object __METHODTYPE__(), methodhandle: \""REF_INVOKE_STATIC\"" <soot.dexpler.instructions.DexBytecodeTarget: java.lang.String lambda$invokeCustomTarget$0()>, methodtype: java.lang.String __METHODTYPE__())"";
    Assert.assertEquals(callToLambdaMethaFactory, invokeCustom.toString());
  }
",non-flaky,5
91592,apache_kylin,HiveCmdBuilderTest.testHiveCLI,"    @Test
    public void testHiveCLI() {
        System.setProperty(""kylin.source.hive.client"", ""cli"");

        Map<String, String> hiveProps = new HashMap<>();
        hiveProps.put(""hive.execution.engine"", ""mr"");
        Map<String, String> hivePropsOverwrite = new HashMap<>();
        hivePropsOverwrite.put(""hive.execution.engine"", ""tez"");
        HiveCmdBuilder hiveCmdBuilder = new HiveCmdBuilder(""test HiveCLI"");
        hiveCmdBuilder.addStatement(""USE default;"");
        hiveCmdBuilder.addStatement(""DROP TABLE `test`;"");
        hiveCmdBuilder.addStatement(""SHOW\n TABLES;"");
        hiveCmdBuilder.setHiveConfProps(hiveProps);
        hiveCmdBuilder.overwriteHiveProps(hivePropsOverwrite);
        assertEquals(
                ""hive -e \""set mapred.job.name='test HiveCLI';\nUSE default;\nDROP TABLE \\`test\\`;\nSHOW\n TABLES;\n\"" --hiveconf hive.execution.engine=tez"",
                hiveCmdBuilder.build());
    }
",non-flaky,5
170509,eclipse_jetty.project,MBeanContainerTest.testNonManagedLifecycleNotUnregistered,"    @Test
    public void testNonManagedLifecycleNotUnregistered() throws Exception
    {
        testNonManagedObjectNotUnregistered(new ContainerLifeCycle());
    }
",non-flaky,5
118777,netty_netty,ByteBufUtilTest.run,"    @Test
    public void testIsTextMultiThreaded() throws Throwable {
        final ByteBuf buffer = Unpooled.copiedBuffer(""Hello, World!"", CharsetUtil.ISO_8859_1);

        try {
            final AtomicInteger counter = new AtomicInteger(60000);
            final AtomicReference<Throwable> errorRef = new AtomicReference<Throwable>();
            List<Thread> threads = new ArrayList<Thread>();
            for (int i = 0; i < 10; i++) {
                Thread thread = new Thread(new Runnable() {
                    @Override
                    public void run() {
                        try {
                            while (errorRef.get() == null && counter.decrementAndGet() > 0) {
                                assertTrue(ByteBufUtil.isText(buffer, CharsetUtil.ISO_8859_1));
                            }
                        } catch (Throwable cause) {
                            errorRef.compareAndSet(null, cause);
                        }
                    }
",non-flaky,5
175741,GoogleCloudPlatform_google-cloud-eclipse,MultipleConnectionsTest.testUnlimitedConnectionsBehaviour,"	@Test
	public void testUnlimitedConnectionsBehaviour() throws CoreException, InterruptedException {
		connector = new SocketListenMultiConnector();
		Map<String, String> arguments = new HashMap<>();
		arguments.put(""port"", Integer.toString(port));
		arguments.put(""connectionLimit"", ""0"");
		connector.connect(arguments, new NullProgressMonitor(), launch);
		Thread.sleep(200);

		for (int i = 0; i < 10; i++) {
			assertTrue(""connection "" + i + "" should succeed"", connect());
		}
	}
",non-flaky,5
177181,line_armeria,BraveClientIntegrationTest.clientTimestampAndDurationEnclosedByParent,"    @Test
    public void clientTimestampAndDurationEnclosedByParent() {
    }
",non-flaky,5
59605,looly_hutool,ExtractorTest.sevenZTest,"	@Test
	public void sevenZTest(){
		Extractor extractor = CompressUtil.createExtractor(
				CharsetUtil.defaultCharset(),
				FileUtil.file(""d:/test/compress/test.7z""));

		extractor.extract(FileUtil.file(""d:/test/compress/test2/""));
	}
",non-flaky,5
26195,Ericsson_ecchronos,TestScheduleManager.testTwoJobsRejected,"    @Test
    public void testTwoJobsRejected()
    {
        DummyJob job = new DummyJob(ScheduledJob.Priority.LOW);
        DummyJob job2 = new DummyJob(ScheduledJob.Priority.LOW);
        myScheduler.schedule(job);
        myScheduler.schedule(job2);

        when(myRunPolicy.validate(any(ScheduledJob.class))).thenReturn(1L);

        myScheduler.run();

        assertThat(job.hasRun()).isFalse();
        assertThat(myScheduler.getQueueSize()).isEqualTo(2);
        verify(myRunPolicy, times(2)).validate(any(ScheduledJob.class));
    }
",non-flaky,5
118732,netty_netty,EmptyByteBufTest.testIsReadable,"    @Test
    public void testIsReadable() {
        EmptyByteBuf empty = new EmptyByteBuf(UnpooledByteBufAllocator.DEFAULT);
        assertFalse(empty.isReadable());
        assertFalse(empty.isReadable(1));
    }
",non-flaky,5
97980,ReactiveX_RxJava,ObservableTests.onSubscribe,"    @Test
    public void testCustomObservableWithErrorInObservableSynchronous() {
        final AtomicInteger count = new AtomicInteger();
        final AtomicReference<Throwable> error = new AtomicReference<Throwable>();
        Observable.create(new OnSubscribeFunc<String>() {

            @Override
            public Subscription onSubscribe(Observer<? super String> observer) {
                observer.onNext(""1"");
                observer.onNext(""2"");
                throw new NumberFormatException();
            }
",non-flaky,5
33872,apache_camel,FhirUpdateIT.testResourceStringId,"    @Test
    public void testResourceStringId() throws Exception {
        Date date = new SimpleDateFormat(""yyyy-MM-dd"").parse(""1998-04-29"");
        assertNotEquals(date, patient.getBirthDate());
        this.patient.setBirthDate(date);
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is org.hl7.fhir.instance.model.api.IBaseResource
        headers.put(""CamelFhir.resource"", this.patient);
        // parameter type is org.hl7.fhir.instance.model.api.IIdType
        headers.put(""CamelFhir.stringId"", this.patient.getIdElement().getIdPart());
        // parameter type is ca.uhn.fhir.rest.api.PreferReturnEnum
        headers.put(""CamelFhir.preferReturn"", PreferReturnEnum.REPRESENTATION);

        MethodOutcome result = requestBodyAndHeaders(""direct://RESOURCE_WITH_STRING_ID"", null, headers);

        assertNotNull(result, ""resource result"");
        LOG.debug(""resource: "" + result);
        assertEquals(date, ((Patient) result.getResource()).getBirthDate(), ""Birth date not updated!"");
    }
",non-flaky,5
35667,cdapio_cdap,IntegrationTestBaseTest.testDeployApplicationInNamespace,"  @Test
  public void testDeployApplicationInNamespace() throws Exception {
    NamespaceId namespace = new NamespaceId(""Test1"");
    NamespaceMeta namespaceMeta = new NamespaceMeta.Builder().setName(namespace).build();
    getNamespaceClient().create(namespaceMeta);
    ClientConfig clientConfig = new ClientConfig.Builder(getClientConfig()).build();
    deployApplication(namespace, AllProgramsApp.class);

    // Check the default namespaces applications to see whether the application wasn't made in the default namespace
    ClientConfig defaultClientConfig = new ClientConfig.Builder(getClientConfig()).build();
    Assert.assertTrue(new ApplicationClient(defaultClientConfig).list(NamespaceId.DEFAULT).isEmpty());

    ApplicationClient applicationClient = new ApplicationClient(clientConfig);
    Assert.assertEquals(AllProgramsApp.NAME, applicationClient.list(namespace).get(0).getName());
    applicationClient.delete(namespace.app(AllProgramsApp.NAME));
    Assert.assertTrue(new ApplicationClient(clientConfig).list(namespace).isEmpty());

  }
",non-flaky,5
104124,spring-cloud_spring-cloud-config,ConfigServicePropertySourceLocatorTests.failFastWhenNotFound,"	@Test
	public void failFastWhenNotFound() throws Exception {
		ClientHttpRequestFactory requestFactory = Mockito
				.mock(ClientHttpRequestFactory.class);
		ClientHttpRequest request = Mockito.mock(ClientHttpRequest.class);
		ClientHttpResponse response = Mockito.mock(ClientHttpResponse.class);
		Mockito.when(requestFactory.createRequest(Mockito.any(URI.class),
				Mockito.any(HttpMethod.class))).thenReturn(request);
		RestTemplate restTemplate = new RestTemplate(requestFactory);
		ConfigClientProperties defaults = new ConfigClientProperties(this.environment);
		defaults.setFailFast(true);
		this.locator = new ConfigServicePropertySourceLocator(defaults);
		Mockito.when(request.getHeaders()).thenReturn(new HttpHeaders());
		Mockito.when(request.execute()).thenReturn(response);
		HttpHeaders headers = new HttpHeaders();
		headers.setContentType(MediaType.APPLICATION_JSON);
		Mockito.when(response.getHeaders()).thenReturn(headers);
		Mockito.when(response.getStatusCode()).thenReturn(HttpStatus.NOT_FOUND);
		Mockito.when(response.getBody())
				.thenReturn(new ByteArrayInputStream("""".getBytes()));
		this.locator.setRestTemplate(restTemplate);
		this.expected
				.expectCause(IsInstanceOf.instanceOf(IllegalArgumentException.class));
		this.expected.expectMessage(""fail fast property is set"");
		this.locator.locate(this.environment);
	}
",non-flaky,5
91396,OpenLCB_OpenLCB_Java,NodeTreeRepTest.put,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        MimicNodeStore store = null;
        NodeID nid1 = new NodeID(new byte[]{1,3,3,4,5,6});
        NodeID nid2 = new NodeID(new byte[]{2,3,3,4,5,6});
    
        ProducerIdentifiedMessage pim1 = new ProducerIdentifiedMessage(nid1, 
                                         new EventID(new byte[]{1,0,0,0,0,0,1,0}), EventState.Unknown);
        Connection connection = new AbstractConnection() {
            public void put(Message msg, Connection sender) {
            }
",non-flaky,5
122566,vespa-engine_vespa,ChildProcess2ImplTest.testSuccess,"    @Test
    public void testSuccess() throws Exception {
        when(commandLine.getTimeout()).thenReturn(Duration.ofHours(1));
        when(commandLine.getMaxOutputBytes()).thenReturn(10L);
        when(commandLine.getOutputEncoding()).thenReturn(StandardCharsets.UTF_8);
        when(commandLine.getSigTermGracePeriod()).thenReturn(Duration.ofMinutes(2));
        when(commandLine.getSigKillGracePeriod()).thenReturn(Duration.ofMinutes(3));
        when(commandLine.toString()).thenReturn(""program arg"");

        when(timer.currentTime()).thenReturn(
                Instant.ofEpochMilli(1),
                Instant.ofEpochMilli(2));

        when(processApi.waitFor(anyLong(), any())).thenReturn(true);

        try (ChildProcess2Impl child =
                     new ChildProcess2Impl(commandLine, processApi, temporaryFile, timer)) {
            child.waitForTermination();
        }
    }
",non-flaky,5
176931,OryxProject_oryx,ServingLayerTest.testServingLayerSecure,"  @Test
  public void testServingLayerSecure() throws Exception {
    Path keystoreFile = SecureAPIConfigIT.buildKeystoreFile();
    Map<String,Object> overlay = buildOverlay();
    overlay.put(""oryx.serving.api.keystore-file"", ""\"""" + keystoreFile + ""\"""");
    overlay.put(""oryx.serving.api.keystore-password"", ""oryxpass"");
    Config config = ConfigUtils.overlayOn(overlay, ConfigUtils.getDefault());
    try {
      doTestServingLayer(config);
    } finally {
      Files.delete(Paths.get(config.getString(""oryx.serving.api.keystore-file"")));
    }
  }
",non-flaky,5
77171,networknt_json-schema-validator,V4JsonSchemaTest.testUnionTypeValidator,"    @Test
    public void testUnionTypeValidator() throws Exception {
        runTestFile(""draft4/union_type.json"");
    }
",non-flaky,5
159669,liquibase_liquibase,AbstractMssqlIntegrationTest.smartDataLoad,"    @Test
    public void smartDataLoad() throws Exception {
        assumeNotNull(this.getDatabase());
        Liquibase liquibase = createLiquibase(""changelogs/common/smartDataLoad.changelog.xml"");
        clearDatabase();
        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
        try {
            liquibase.rollback(new Date(0), this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
    }
",non-flaky,5
76752,quarkusio_quarkus,CreateProjectMojoIT.testProjectGenerationFromScratchWithResource,"    @Test
    public void testProjectGenerationFromScratchWithResource() throws Exception {
        testDir = initEmptyProject(""projects/project-generation-with-resource"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""org.acme"");
        properties.put(""projectArtifactId"", ""acme"");
        properties.put(""className"", ""org.acme.MyResource.java"");
        properties.put(""extensions"", ""resteasy"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        // As the directory is not empty (log) navigate to the artifactID directory
        testDir = new File(testDir, ""acme"");

        assertThat(new File(testDir, ""pom.xml"")).isFile();
        assertThat(new File(testDir, ""src/main/java"")).isDirectory();

        check(new File(testDir, ""src/main/java/org/acme/MyResource.java""), ""package org.acme;"");
    }
",non-flaky,5
150194,apache_hive,TestHplsqlLocal.testTwoPipes,"  @Test
  public void testTwoPipes() throws Exception {
    run(""twopipes"");
  }
",non-flaky,5
104141,spring-cloud_spring-cloud-config,ConfigClientPropertiesTests.changeNameInOverride,"	@Test
	public void changeNameInOverride() {
		this.locator.setName(""one"");
		ConfigurableEnvironment environment = new StandardEnvironment();
		TestPropertyValues.of(""spring.application.name:two"").applyTo(environment);
		ConfigClientProperties override = this.locator.override(environment);
		assertThat(override.getName()).isEqualTo(""two"");
	}
",non-flaky,5
104181,spring-cloud_spring-cloud-config,EnvironmentPropertySourceTest.testEscapedPlaceholdersRemoved,"	@Test
	public void testEscapedPlaceholdersRemoved() {
		assertThat(resolvePlaceholders(this.env, ""\\${abc}"")).isEqualTo(""${abc}"");
		// JSON generated from jackson will be double escaped
		assertThat(resolvePlaceholders(this.env, ""\\\\${abc}"")).isEqualTo(""${abc}"");
	}
",non-flaky,5
97981,ReactiveX_RxJava,ObservableTests.run,"    @Test
    public void testPublish() throws InterruptedException {
        final AtomicInteger counter = new AtomicInteger();
        ConnectableObservable<String> o = Observable.create(new OnSubscribeFunc<String>() {

            @Override
            public Subscription onSubscribe(final Observer<? super String> observer) {
                final BooleanSubscription subscription = new BooleanSubscription();
                new Thread(new Runnable() {

                    @Override
                    public void run() {
                        counter.incrementAndGet();
                        observer.onNext(""one"");
                        observer.onCompleted();
                    }
",non-flaky,5
30960,camunda-cloud_zeebe,POJOArrayTest.shouldSerializePOJOAfterReset,"  @Test
  public void shouldSerializePOJOAfterReset() {
    // given
    final POJOArray pojo = new POJOArray();
    pojo.simpleArray().add().setLongProp(124);
    pojo.reset();

    final int writeLength = pojo.getLength();

    // when
    final UnsafeBuffer resultBuffer = new UnsafeBuffer(new byte[writeLength]);
    pojo.write(resultBuffer, 0);

    // then
    final Map<String, Object> msgPackMap =
        MsgPackUtil.asMap(resultBuffer, 0, resultBuffer.capacity());
    assertThat(msgPackMap).containsOnly(entry(""simpleArray"", ""[]""));
  }
",non-flaky,5
113865,spring-projects_spring-data-couchbase,CouchbaseTemplateQueryIntegrationTests.beforeEach,"	@BeforeEach
	public void beforeEach() {
		super.beforeEach();
		// already setup by JavaIntegrationTests.beforeAll()
		// ApplicationContext ac = new AnnotationConfigApplicationContext(Config.class);
		// couchbaseTemplate = (CouchbaseTemplate) ac.getBean(COUCHBASE_TEMPLATE);
		// reactiveCouchbaseTemplate = (ReactiveCouchbaseTemplate) ac.getBean(REACTIVE_COUCHBASE_TEMPLATE);
		// ensure each test starts with clean state

		couchbaseTemplate.removeByQuery(User.class).all();
		couchbaseTemplate.findByQuery(User.class).withConsistency(QueryScanConsistency.REQUEST_PLUS).all();
	}
",non-flaky,5
114099,aws_aws-sdk-java-v2,TableSchemaTest.fromClass_constructsBeanTableSchema,"    @Test
    public void fromClass_constructsBeanTableSchema() {
        TableSchema<SimpleBean> tableSchema = TableSchema.fromClass(SimpleBean.class);
        assertThat(tableSchema).isInstanceOf(BeanTableSchema.class);
    }
",non-flaky,5
104688,apache_pinot,MapTypeClusterIntegrationTest.testQueries,"  @Test
  public void testQueries()
      throws Exception {
    // Selection only
    String query = ""SELECT mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES) FROM "" + getTableName();
    JsonNode pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), i);
    }
    query = ""SELECT mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), i);
    }

    // Selection order-by
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k2', stringKeyMap__VALUES) FROM "" + getTableName()
        + "" ORDER BY mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES)"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), NUM_DOCS + i);
    }
    query = ""SELECT mapValue(intKeyMap__KEYS, 717, intKeyMap__VALUES) FROM "" + getTableName()
        + "" ORDER BY mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES)"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      assertEquals(Integer.parseInt(selectionResults.get(i).get(0).textValue()), NUM_DOCS + i);
    }

    // Aggregation only
    query = ""SELECT MAX(mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES)) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode aggregationResult = pinotResponse.get(""aggregationResults"").get(0).get(""value"");
    assertEquals((int) Double.parseDouble(aggregationResult.textValue()), NUM_DOCS - 1);
    query = ""SELECT MAX(mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES)) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    aggregationResult = pinotResponse.get(""aggregationResults"").get(0).get(""value"");
    assertEquals((int) Double.parseDouble(aggregationResult.textValue()), NUM_DOCS - 1);

    // Aggregation group-by
    query = ""SELECT MIN(mapValue(stringKeyMap__KEYS, 'k2', stringKeyMap__VALUES)) FROM "" + getTableName()
        + "" GROUP BY mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES)"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    JsonNode groupByResults = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    assertEquals(groupByResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      JsonNode groupByResult = groupByResults.get(i);
      assertEquals(Integer.parseInt(groupByResult.get(""group"").get(0).asText()), i);
      assertEquals((int) Double.parseDouble(groupByResult.get(""value"").asText()), NUM_DOCS + i);
    }
    query = ""SELECT MIN(mapValue(intKeyMap__KEYS, 717, intKeyMap__VALUES)) FROM "" + getTableName()
        + "" GROUP BY mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES)"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    groupByResults = pinotResponse.get(""aggregationResults"").get(0).get(""groupByResult"");
    assertEquals(groupByResults.size(), 10);
    for (int i = 0; i < 10; i++) {
      JsonNode groupByResult = groupByResults.get(i);
      assertEquals(Integer.parseInt(groupByResult.get(""group"").get(0).asText()), i);
      assertEquals((int) Double.parseDouble(groupByResult.get(""value"").asText()), NUM_DOCS + i);
    }

    // Filter
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k2', stringKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE mapValue(stringKeyMap__KEYS, 'k1', stringKeyMap__VALUES) = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 1);
    assertEquals(Integer.parseInt(selectionResults.get(0).get(0).textValue()), NUM_DOCS + 25);
    query = ""SELECT mapValue(intKeyMap__KEYS, 717, intKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE mapValue(intKeyMap__KEYS, 95, intKeyMap__VALUES) = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 1);
    assertEquals(Integer.parseInt(selectionResults.get(0).get(0).textValue()), NUM_DOCS + 25);

    // Filter on non-existing key
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k2', stringKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE mapValue(stringKeyMap__KEYS, 'k3', stringKeyMap__VALUES) = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
    query = ""SELECT mapValue(intKeyMap__KEYS, 717, intKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE mapValue(intKeyMap__KEYS, 123, intKeyMap__VALUES) = 25"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);

    // Select non-existing key (illegal query)
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k3', stringKeyMap__VALUES) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertNotEquals(pinotResponse.get(""exceptions"").size(), 0);
    query = ""SELECT mapValue(stringKeyMap__KEYS, 123, stringKeyMap__VALUES) FROM "" + getTableName();
    pinotResponse = postQuery(query);
    assertNotEquals(pinotResponse.get(""exceptions"").size(), 0);

    // Select non-existing key with proper filter
    query = ""SELECT mapValue(stringKeyMap__KEYS, 'k3', stringKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE stringKeyMap__KEYS = 'k3'"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
    query = ""SELECT mapValue(intKeyMap__KEYS, 123, intKeyMap__VALUES) FROM "" + getTableName()
        + "" WHERE stringKeyMap__KEYS = 123"";
    pinotResponse = postQuery(query);
    assertEquals(pinotResponse.get(""exceptions"").size(), 0);
    selectionResults = pinotResponse.get(""selectionResults"").get(""results"");
    assertEquals(selectionResults.size(), 0);
  }
",non-flaky,5
98051,vert-x3_vertx-mongo-client,GridFsTest.testFindWithMetadata,"  @Test
  public void testFindWithMetadata() {
    String fileName = createTempFileWithContent((1024 * 3) + 70);

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    JsonObject meta = new JsonObject();
    meta.put(""nick_name"", ""Puhi the eel"");

    GridFsUploadOptions options = new GridFsUploadOptions();
    options.setMetadata(meta);

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFileWithOptions(fileName, options, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<List<String>> findPromise = Promise.promise();
      JsonObject query = new JsonObject().put(""metadata.nick_name"", ""Puhi the eel"");
      gridFsClient.get().findIds(query, findPromise);
      return findPromise.future();
    }).compose(list -> {
      assertTrue(list.size() > 0);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
",non-flaky,5
110882,pushtorefresh_storio,InterceptorTest.getCursorWithRawQuery,"    @Test
    public void getCursorWithRawQuery() {
        storIOSQLite.get()
                .cursor()
                .withQuery(RawQuery.builder()
                        .query(""select * from "" + TweetTableMeta.TABLE)
                        .build()
                )
                .prepare()
                .executeAsBlocking();
        checkInterceptorsCalls();
    }
",non-flaky,5
84611,apache_zookeeper,GetEphemeralsTest.setUp,"    @BeforeEach
    public void setUp() throws Exception {
        super.setUp();

        zk = createClient();
        expected = generatePaths(PERSISTENT_CNT, EPHEMERAL_CNT);
    }
",non-flaky,5
98028,vert-x3_vertx-mongo-client,MongoClientUpdateResultTest.testCopyMongoClientUpdateResult,"  @Test
  public void testCopyMongoClientUpdateResult() {
    MongoClientUpdateResult mongoClientUpdateResultOrigin = new MongoClientUpdateResult(TestUtils.randomLong(),
      randomUpsertId(), TestUtils.randomLong());
    MongoClientUpdateResult mongoClientUpdateResultCopy = new MongoClientUpdateResult(mongoClientUpdateResultOrigin);

    assertEquals(mongoClientUpdateResultOrigin.getDocMatched(), mongoClientUpdateResultCopy.getDocMatched());
    assertEquals(mongoClientUpdateResultOrigin.getDocUpsertedId(), mongoClientUpdateResultCopy.getDocUpsertedId());
    assertEquals(mongoClientUpdateResultOrigin.getDocModified(), mongoClientUpdateResultCopy.getDocModified());
  }
",non-flaky,5
98090,vert-x3_vertx-mongo-client,ParsingSSLOptionsTest.one_should_be_able_to_allow_invalid_host_names_via_connection_string,"  @Test
  public void one_should_be_able_to_allow_invalid_host_names_via_connection_string() {
    // given
    final JsonObject withSSLAndInvalidHostnameEnabled = new JsonObject().put(
      ""connection_string"", ""mongodb://localhost:27017/mydb?replicaSet=myRs&ssl=true&sslInvalidHostNameAllowed=true""
    );

    // when
    final SslSettings sslSettings = new MongoClientOptionsParser(vertx, withSSLAndInvalidHostnameEnabled)
      .settings()
      .getSslSettings();

    // then
    assertTrue(sslSettings.isInvalidHostNameAllowed());
  }
",non-flaky,5
30953,camunda-cloud_zeebe,SubscriptionUtilTest.shouldGetPartitionIdForCorrelationKey,"  @Test
  public void shouldGetPartitionIdForCorrelationKey() {
    assertThat(getSubscriptionPartitionId(wrapString(""a""), 10)).isEqualTo(7 + START_PARTITION_ID);
    assertThat(getSubscriptionPartitionId(wrapString(""b""), 3)).isEqualTo(2 + START_PARTITION_ID);
    assertThat(getSubscriptionPartitionId(wrapString(""c""), 11)).isEqualTo(0 + START_PARTITION_ID);
    assertThat(getSubscriptionPartitionId(wrapString(""foobar""), 100))
        .isEqualTo(63 + START_PARTITION_ID);
  }
",non-flaky,5
156137,soot-oss_soot,LoadingTest.testLoadingJava9to11Class,"  @Test
  public void testLoadingJava9to11Class() {
    G.reset();
    Options.v().set_soot_modulepath(""VIRTUAL_FS_FOR_JDK"");
    Scene.v().loadBasicClasses();

    SootClass klass1
        = SootModuleResolver.v().resolveClass(""java.lang.invoke.VarHandle"", SootClass.BODIES, Optional.of(""java.base""));

    assertTrue(klass1.getName().equals(""java.lang.invoke.VarHandle""));
    assertTrue(klass1.moduleName.equals(""java.base""));

    SootClass klass2 = SootModuleResolver.v().resolveClass(""java.lang.invoke.ConstantBootstraps"", SootClass.BODIES,
        Optional.of(""java.base""));

    assertTrue(klass2.getName().equals(""java.lang.invoke.ConstantBootstraps""));
    assertTrue(klass2.moduleName.equals(""java.base""));

    Scene.v().loadNecessaryClasses();
  }
",non-flaky,5
104681,apache_pinot,RealtimeToOfflineSegmentsMinionClusterIntegrationTest.testInstanceShutdown,"  @Test(enabled = false)
  public void testInstanceShutdown() {
  }
",non-flaky,5
98412,ONSdigital_rm-collection-exercise-service,NudgeEmailValidatorTest.testCanUpdateNudgeWhenLive,"  @Test
  public void testCanUpdateNudgeWhenLive() throws CTPException {
    final Event nudgeEvent = new Event();
    nudgeEvent.setTag(EventService.Tag.nudge_email_0.toString());
    nudgeEvent.setTimestamp(Timestamp.from(Instant.now()));

    final List<Event> events = new ArrayList<>();

    nudgeEmailValidator.validate(
        events, nudgeEvent, CollectionExerciseDTO.CollectionExerciseState.LIVE);
  }
",non-flaky,5
170530,eclipse_jetty.project,TestSecurityAnnotationConversions.testRolesAllowedWithTransportGuarantee,"    @Test
    public void testRolesAllowedWithTransportGuarantee() throws Exception
    {
        //Assume we found 1 servlet with annotation with roles defined and
        //and a TransportGuarantee

        WebAppContext wac = makeWebAppContext(RolesServlet.class.getCanonicalName(), ""rolesServlet"", new String[]{
            ""/foo/*"", ""*.foo""
        });

        ServletSecurityAnnotationHandler annotationHandler = new ServletSecurityAnnotationHandler(wac);
        AnnotationIntrospector introspector = new AnnotationIntrospector(wac);
        introspector.registerHandler(annotationHandler);

        //set up the expected outcomes:compareResults
        //1 ConstraintMapping per ServletMapping
        Constraint expectedConstraint = new Constraint();
        expectedConstraint.setAuthenticate(true);
        expectedConstraint.setRoles(new String[]{""tom"", ""dick"", ""harry""});
        expectedConstraint.setDataConstraint(Constraint.DC_CONFIDENTIAL);

        ConstraintMapping[] expectedMappings = new ConstraintMapping[2];
        expectedMappings[0] = new ConstraintMapping();
        expectedMappings[0].setConstraint(expectedConstraint);
        expectedMappings[0].setPathSpec(""/foo/*"");

        expectedMappings[1] = new ConstraintMapping();
        expectedMappings[1].setConstraint(expectedConstraint);
        expectedMappings[1].setPathSpec(""*.foo"");
        introspector.introspect(new RolesServlet(), null);
        compareResults(expectedMappings, ((ConstraintAware)wac.getSecurityHandler()).getConstraintMappings());
    }
",non-flaky,5
104610,apache_pinot,AggregateMetricsClusterIntegrationTest.testQueries,"  @Test
  public void testQueries()
      throws Exception {
    String sql = ""SELECT SUM(AirTime), SUM(ArrDelay) FROM mytable"";
    testSqlQuery(sql, Collections.singletonList(sql));
    sql = ""SELECT SUM(AirTime), DaysSinceEpoch FROM mytable GROUP BY DaysSinceEpoch ORDER BY SUM(AirTime) DESC"";
    testSqlQuery(sql, Collections.singletonList(sql));
    sql = ""SELECT Origin, SUM(ArrDelay) FROM mytable WHERE Carrier = 'AA' GROUP BY Origin ORDER BY Origin"";
    testSqlQuery(sql, Collections.singletonList(sql));
  }
",non-flaky,5
76707,quarkusio_quarkus,ResourcesITCase.excludedNative,"    @Test
    public void excludedNative() {
        RestAssured.when()
                .get(""/resources/test-resources/file.adoc"")
                .then()
                .statusCode(404);

        RestAssured.when()
                .get(""/resources/test-resources/excluded/unwanted.txt"")
                .then()
                .statusCode(404);

        RestAssured.when()
                .get(""/resources/META-INF/quarkus-native-resources.txt"")
                .then()
                .statusCode(404);
    }
",non-flaky,5
344,apache_hadoop,TestMountd.testStart,"  @Test
  public void testStart() throws IOException {
    // Start minicluster
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(config).numDataNodes(1)
        .build();
    cluster.waitActive();
    
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);
    
    int newTimeoutMillis = 1000; // 1s
    // Set the new portmap rpc timeout values and check
    config.setInt(NfsConfigKeys.NFS_UDP_CLIENT_PORTMAP_TIMEOUT_MILLIS_KEY,
                  newTimeoutMillis);
    assertTrue(config.getInt(
                      NfsConfigKeys.NFS_UDP_CLIENT_PORTMAP_TIMEOUT_MILLIS_KEY,
          0) == newTimeoutMillis);

    // Start nfs
    Nfs3 nfs3 = new Nfs3(config);
    nfs3.startServiceInternal(false);

    RpcProgramMountd mountd = (RpcProgramMountd) nfs3.getMountd()
        .getRpcProgram();
    mountd.nullOp(new XDR(), 1234, InetAddress.getByName(""localhost""));
    assertTrue(mountd.getPortmapUdpTimeoutMillis() == newTimeoutMillis);
    RpcProgramNfs3 nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();
    nfsd.nullProcedure();
    assertTrue(nfsd.getPortmapUdpTimeoutMillis() == newTimeoutMillis);
    
    cluster.shutdown();
  }
",non-flaky,5
35678,cdapio_cdap,LogBufferProcessorPipelineTest.testSingleAppender,"  @Test
  public void testSingleAppender() throws Exception {
    LoggerContext loggerContext = LogPipelineTestUtil.createLoggerContext(""WARN"",
                                                                          ImmutableMap.of(""test.logger"", ""INFO""),
                                                                          MockAppender.class.getName());
    final MockAppender appender = LogPipelineTestUtil.getAppender(loggerContext.getLogger(Logger.ROOT_LOGGER_NAME),
                                                                  ""Test"", MockAppender.class);
    MockCheckpointManager checkpointManager = new MockCheckpointManager();
    LogBufferPipelineConfig config = new LogBufferPipelineConfig(1024L, 300L, 500L, 4);
    loggerContext.start();
    LogBufferProcessorPipeline pipeline = new LogBufferProcessorPipeline(
      new LogProcessorPipelineContext(CConfiguration.create(), ""test"", loggerContext, NO_OP_METRICS_CONTEXT, 0),
      config, checkpointManager, 0);
    // start the pipeline
    pipeline.startAndWait();

    // start thread to write to incomingEventQueue
    List<ILoggingEvent> events = getLoggingEvents();
    AtomicInteger i = new AtomicInteger(0);
    List<LogBufferEvent> bufferEvents = events.stream().map(event -> {
      LogBufferEvent lbe = new LogBufferEvent(event, serializer.toBytes(event).length,
                                              new LogBufferFileOffset(0, i.get()));
      i.incrementAndGet();
      return lbe;
    }).collect(Collectors.toList());

    // start a thread to send log buffer events to pipeline
    ExecutorService executorService = Executors.newSingleThreadExecutor();
    executorService.execute(() -> {
      for (int count = 0; count < 40; count++) {
        pipeline.processLogEvents(bufferEvents.iterator());
        try {
          Thread.sleep(100);
        } catch (InterruptedException e) {
          // should not happen
        }
      }
    });

    // wait for pipeline to append all the logs to appender. The DEBUG message should get filtered out.
    Tasks.waitFor(200, () -> appender.getEvents().size(), 60, TimeUnit.SECONDS, 100, TimeUnit.MILLISECONDS);
    executorService.shutdown();
    pipeline.stopAndWait();
    loggerContext.stop();
  }
",non-flaky,5
104130,spring-cloud_spring-cloud-config,ConfigServicePropertySourceLocatorTests.shouldThrowExceptionWhenNegativeReadTimeoutSet,"	@Test
	public void shouldThrowExceptionWhenNegativeReadTimeoutSet() {
		ConfigClientProperties defaults = new ConfigClientProperties(this.environment);
		defaults.setRequestReadTimeout(-1);
		this.locator = new ConfigServicePropertySourceLocator(defaults);
		this.expected.expect(IllegalStateException.class);
		this.expected.expectMessage(""Invalid Value for Read Timeout set."");
		ReflectionTestUtils.invokeMethod(this.locator, ""getSecureRestTemplate"", defaults);
	}
",non-flaky,5
26155,Ericsson_ecchronos,TestRepairManagementRESTImpl.testKeyspaceStatusEntry,"    @Test
    public void testKeyspaceStatusEntry()
    {
        long expectedLastRepairedAt = 234;
        long repairInterval = 123;

        RepairJobView repairJobView = new TestUtils.ScheduledRepairJobBuilder()
            .withKeyspace(""ks"")
            .withTable(""tb"")
            .withLastRepairedAt(expectedLastRepairedAt)
            .withRepairInterval(repairInterval)
            .build();
        ScheduledRepairJob expectedResponse = new ScheduledRepairJob(repairJobView);

        when(myRepairScheduler.getCurrentRepairJobs()).thenReturn(Collections.singletonList(repairJobView));

        List<ScheduledRepairJob> response = GSON.fromJson(repairManagementREST.keyspaceStatus(""ks""), scheduledRepairJobListType);

        assertThat(response).containsExactly(expectedResponse);
    }
",non-flaky,5
176842,OryxProject_oryx,VectorMathTest.testParseVector,"  @Test
  public void testParseVector() {
    assertArrayEquals(
        new double[] {-1.0, 2.01, 3.5},
        VectorMath.parseVector(new String[] {""-1.0"", ""2.01"", ""3.5""}));
  }
",non-flaky,5
98025,vert-x3_vertx-mongo-client,UpdateOptionsTest.testToJson,"  @Test
  public void testToJson() {
    UpdateOptions options = new UpdateOptions();
    WriteOption writeOption = MAJORITY;
    boolean multi = TestUtils.randomBoolean();
    boolean upsert = TestUtils.randomBoolean();
    JsonArray arrayFilters = new JsonArray().add(new JsonObject().put(TestUtils.randomAlphaString(5), TestUtils.randomAlphaString(5)));

    options.setWriteOption(writeOption);
    options.setMulti(multi);
    options.setUpsert(upsert);
    options.setArrayFilters(arrayFilters);

    assertEquals(options, new UpdateOptions(options.toJson()));
  }
",non-flaky,5
112661,tbsalling_aismessages,AidToNavigationReportTest.testDataFields,"    @Test
    public void testDataFields() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDO,1,1,,A,E>lt;MIas0h3V:@;4a::h0b7W005Jh4nq:3l800003v010,4*08""));
        Map<String, Object> dataFields = aisMessage.dataFields();

        assertNotNull(dataFields);
        assertEquals(22, dataFields.size());

        assertEquals(""AidToNavigationReport"", dataFields.get(""messageType""));
        assertEquals(0, dataFields.get(""repeatIndicator""));
        assertEquals(995036021, dataFields.get(""sourceMmsi.MMSI""));
        assertEquals(""BeaconSpecialMark"", dataFields.get(""aidType""));
        assertEquals(""S6A GLT VIRTU ATON"", dataFields.get(""name""));
        assertEquals(false, dataFields.get(""positionAccurate""));
        assertEquals(151.49791f, dataFields.get(""longitude""));
        assertEquals(-23.917385f, dataFields.get(""latitude""));
        assertEquals(0, dataFields.get(""toStern""));
        assertEquals(0, dataFields.get(""toBow""));
        assertEquals(0, dataFields.get(""toPort""));
        assertEquals(0, dataFields.get(""toStarboard""));
        assertEquals(""Surveyed"", dataFields.get(""positionFixingDevice""));
        assertEquals(60, dataFields.get(""second""));
        assertEquals(false, dataFields.get(""offPosition""));
        assertEquals(""00000000"", dataFields.get(""atoNStatus""));
        assertEquals(false, dataFields.get(""raimFlag""));
        assertEquals(true, dataFields.get(""virtualAid""));
        assertEquals(false, dataFields.get(""assignedMode""));
        assertEquals(0, dataFields.get(""spare1""));
        assertEquals(0, dataFields.get(""spare2""));

        assertFalse(dataFields.containsKey(""nameExtension""));
        assertFalse(dataFields.containsKey(""class""));
    }
",non-flaky,5
135790,Netflix_Hystrix,HystrixCommandTimeoutConcurrencyTesting.testTimeoutRace,"    @Test
    public void testTimeoutRace() throws InterruptedException {
        final int NUM_TRIALS = 10;

        for (int i = 0; i < NUM_TRIALS; i++) {
            List<Observable<String>> observables = new ArrayList<Observable<String>>();
            HystrixRequestContext context = null;

            try {
                context = HystrixRequestContext.initializeContext();
                for (int j = 0; j < NUM_CONCURRENT_COMMANDS; j++) {
                    observables.add(new TestCommand().observe());
                }

                Observable<String> overall = Observable.merge(observables);

                List<String> results = overall.toList().toBlocking().first(); //wait for all commands to complete

                for (String s : results) {
                    if (s == null) {
                        System.err.println(""Received NULL!"");
                        throw new RuntimeException(""Received NULL"");
                    }
                }

                for (HystrixInvokableInfo<?> hi : HystrixRequestLog.getCurrentRequest().getAllExecutedCommands()) {
                    if (!hi.isResponseTimedOut()) {
                        System.err.println(""Timeout not found in executed command"");
                        throw new RuntimeException(""Timeout not found in executed command"");
                    }
                    if (hi.isResponseTimedOut() && hi.getExecutionEvents().size() == 1) {
                        System.err.println(""Missing fallback status!"");
                        throw new RuntimeException(""Missing fallback status on timeout."");
                    }
                }

            } catch (Exception e) {
                System.err.println(""Error: "" + e.getMessage());
                e.printStackTrace();
                throw new RuntimeException(e);
            } finally {
                System.out.println(HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
                if (context != null) {
                    context.shutdown();
                }
            }

            System.out.println(""*************** TRIAL "" + i + "" ******************"");
            System.out.println();
            Thread.sleep(50);
        }

        Hystrix.reset();
    }
",non-flaky,5
296,apache_hadoop,TestWrites.testOverlappingWrites,"  @Test
  public void testOverlappingWrites() throws IOException, InterruptedException {
    NfsConfiguration config = new NfsConfiguration();
    MiniDFSCluster cluster = null;
    RpcProgramNfs3 nfsd;
    final int bufSize = 32;
    SecurityHandler securityHandler = Mockito.mock(SecurityHandler.class);
    Mockito.when(securityHandler.getUser()).thenReturn(
        System.getProperty(""user.name""));
    String currentUser = System.getProperty(""user.name"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserGroupConfKey(currentUser),
        ""*"");
    config.set(
        DefaultImpersonationProvider.getTestProvider().
            getProxySuperuserIpConfKey(currentUser),
        ""*"");
    ProxyUsers.refreshSuperUserGroupsConfiguration(config);
    // Use emphral port in case tests are running in parallel
    config.setInt(""nfs3.mountd.port"", 0);
    config.setInt(""nfs3.server.port"", 0);

    try {
      cluster = new MiniDFSCluster.Builder(config).numDataNodes(1).build();
      cluster.waitActive();

      Nfs3 nfs3 = new Nfs3(config);
      nfs3.startServiceInternal(false);
      nfsd = (RpcProgramNfs3) nfs3.getRpcProgram();

      DFSClient dfsClient = new DFSClient(DFSUtilClient.getNNAddress(config),
          config);
      int namenodeId = Nfs3Utils.getNamenodeId(config);
      HdfsFileStatus status = dfsClient.getFileInfo(""/"");
      FileHandle rootHandle = new FileHandle(status.getFileId(), namenodeId);

      CREATE3Request createReq = new CREATE3Request(rootHandle,
          ""overlapping-writes"" + System.currentTimeMillis(),
          Nfs3Constant.CREATE_UNCHECKED, new SetAttr3(), 0);
      XDR createXdr = new XDR();
      createReq.serialize(createXdr);
      CREATE3Response createRsp = nfsd.create(createXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", 1234));
      FileHandle handle = createRsp.getObjHandle();
      byte[] buffer = new byte[bufSize];
      for (int i = 0; i < bufSize; i++) {
        buffer[i] = (byte) i;
      }
      int[][] ranges = new int[][] {
          {0, 10},
          {5, 7},
          {5, 5},
          {10, 6},
          {18, 6},
          {20, 6},
          {28, 4},
          {16, 2},
          {25, 4}
      };
      for (int i = 0; i < ranges.length; i++) {
        int x[] = ranges[i];
        byte[] tbuffer = new byte[x[1]];
        for (int j = 0; j < x[1]; j++) {
          tbuffer[j] = buffer[x[0] + j];
        }
        WRITE3Request writeReq = new WRITE3Request(handle, (long)x[0], x[1],
            WriteStableHow.UNSTABLE, ByteBuffer.wrap(tbuffer));
        XDR writeXdr = new XDR();
        writeReq.serialize(writeXdr);
        nfsd.write(writeXdr.asReadOnlyWrap(), null, 1, securityHandler,
            new InetSocketAddress(""localhost"", 1234));
      }

      waitWrite(nfsd, handle, 60000);
      READ3Request readReq = new READ3Request(handle, 0, bufSize);
      XDR readXdr = new XDR();
      readReq.serialize(readXdr);
      READ3Response readRsp = nfsd.read(readXdr.asReadOnlyWrap(),
          securityHandler, new InetSocketAddress(""localhost"", config.getInt(
              NfsConfigKeys.DFS_NFS_SERVER_PORT_KEY,
              NfsConfigKeys.DFS_NFS_SERVER_PORT_DEFAULT)));

      assertTrue(Arrays.equals(buffer, readRsp.getData().array()));
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
114062,aws_aws-sdk-java-v2,EnhancedTypeTest.sortedSetOf_ReturnsRawClassOfDeque_WhenSpecifyingClass,"    @Test
    public void sortedSetOf_ReturnsRawClassOfDeque_WhenSpecifyingClass() {
        EnhancedType<SortedSet<String>> type = EnhancedType.sortedSetOf(String.class);

        assertThat(type.rawClass()).isEqualTo(SortedSet.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
159634,liquibase_liquibase,OracleIntegrationTest.indexCreatedOnCorrectSchema,"    @Test
    public void indexCreatedOnCorrectSchema() throws Exception {
        assumeNotNull(this.getDatabase());

        Liquibase liquibase = createLiquibase(this.indexOnSchemaChangeLog);
        clearDatabase();

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }

        Statement queryIndex = ((JdbcConnection) this.getDatabase().getConnection()).getUnderlyingConnection().createStatement();

        ResultSet indexOwner = queryIndex.executeQuery(""SELECT owner FROM ALL_INDEXES WHERE index_name = 'IDX_BOOK_ID'"");

        assertTrue(indexOwner.next());

        String owner = indexOwner.getString(""owner"");

        assertEquals(""LBCAT2"", owner);

        // check that the automatically rollback now works too
        try {
            liquibase.rollback( new Date(0),this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }




    }
",non-flaky,5
60923,apache_druid,BaseAveragerFactoryTest.testGetDependentFields,"  @Test
  public void testGetDependentFields()
  {
    List<String> dependentFields = fac.getDependentFields();
    Assert.assertEquals(1, dependentFields.size());
    Assert.assertEquals(""field"", dependentFields.get(0));
  }
",non-flaky,5
60863,apache_druid,DistinctCountTimeseriesQueryTest.testTimeseriesWithDistinctCountAgg,"  @Test
  public void testTimeseriesWithDistinctCountAgg() throws Exception
  {
    TimeseriesQueryEngine engine = new TimeseriesQueryEngine();

    IncrementalIndex index = new OnheapIncrementalIndex.Builder()
        .setIndexSchema(
            new IncrementalIndexSchema.Builder()
                .withQueryGranularity(Granularities.SECOND)
                .withMetrics(new CountAggregatorFactory(""cnt""))
                .build()
        )
        .setMaxRowCount(1000)
        .build();

    String visitor_id = ""visitor_id"";
    String client_type = ""client_type"";
    DateTime time = DateTimes.of(""2016-03-04T00:00:00.000Z"");
    long timestamp = time.getMillis();
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""0"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""1"", client_type, ""iphone"")
        )
    );
    index.add(
        new MapBasedInputRow(
            timestamp,
            Lists.newArrayList(visitor_id, client_type),
            ImmutableMap.of(visitor_id, ""2"", client_type, ""android"")
        )
    );

    TimeseriesQuery query = Druids.newTimeseriesQueryBuilder()
                                  .dataSource(QueryRunnerTestHelper.DATA_SOURCE)
                                  .granularity(QueryRunnerTestHelper.ALL_GRAN)
                                  .intervals(QueryRunnerTestHelper.FULL_ON_INTERVAL_SPEC)
                                  .aggregators(
                                      Lists.newArrayList(
                                          QueryRunnerTestHelper.ROWS_COUNT,
                                          new DistinctCountAggregatorFactory(""UV"", visitor_id, null)
                                      )
                                  )
                                  .build();

    final Iterable<Result<TimeseriesResultValue>> results =
        engine.process(query, new IncrementalIndexStorageAdapter(index)).toList();

    List<Result<TimeseriesResultValue>> expectedResults = Collections.singletonList(
        new Result<>(
            time,
            new TimeseriesResultValue(
                ImmutableMap.of(""UV"", 3, ""rows"", 3L)
            )
        )
    );
    TestHelper.assertExpectedResults(expectedResults, results);
  }
",non-flaky,5
96018,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher1,"  @Test
  public void testTokenSequenceMatcher1() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test simple sequence
    TokenSequencePattern p = TokenSequencePattern.compile(getSequencePatternExpr(""Archbishop"", ""of"", ""Canterbury""));
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(""Archbishop of Canterbury"", m.group());
    match = m.find();
    assertFalse(match);

    m.reset();
    match = m.find();
    assertTrue(match);
    assertEquals(""Archbishop of Canterbury"", m.group());

    m.reset();
    match = m.matches();
    assertFalse(match);

    // Test sequence with or
    p = TokenSequencePattern.compile(
            new SequencePattern.OrPatternExpr(
                    getSequencePatternExpr(""Archbishop"", ""of"", ""Canterbury""),
                    getSequencePatternExpr(""Bishop"", ""of"", ""London"")
            ));
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Bishop of London"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Archbishop of Canterbury"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Bishop of London"", m.group());
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile(
              new SequencePattern.SequencePatternExpr(
                    SequencePattern.SEQ_BEGIN_PATTERN_EXPR,
                    getSequencePatternExpr(""Archbishop"", ""of"", ""Canterbury"")
            ));
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile(
            new SequencePattern.SequencePatternExpr(
                    SequencePattern.SEQ_BEGIN_PATTERN_EXPR,
                    getSequencePatternExpr(""Mellitus"", ""was"", ""the"")
            ));
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Mellitus was the"", m.group());
    match = m.find();
    assertFalse(match);


    p = TokenSequencePattern.compile(
            new SequencePattern.SequencePatternExpr(
                    getSequencePatternExpr(""Archbishop"", ""of"", ""Canterbury""),
                    SequencePattern.SEQ_END_PATTERN_EXPR
                    ));
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile(
            new SequencePattern.SequencePatternExpr(
                    getSequencePatternExpr(""London"", ""in"", ""604"", "".""),
                    SequencePattern.SEQ_END_PATTERN_EXPR
                    ));
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""London in 604."", m.group());
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
98614,nutzam_nutz,El2Test.testIssue307,"    @Test
    public void testIssue307(){
        Context context = Lang.context();
        List<String> list = new ArrayList<String>();
        list.add(""jk"");
        context.set(""list"", list);
        context.set(""System"", System.class);
        
        El.eval(context, ""list.add(list.get(0))"");
        assertEquals(2, list.size());
    }
",non-flaky,5
78321,apache_beam,ReduceFnRunnerTest.testFixedWindowsEowAndGcTogetherFireIfNonEmpty,"  @Test
  public void testFixedWindowsEowAndGcTogetherFireIfNonEmpty() throws Exception {
    ReduceFnTester<Integer, Iterable<Integer>, IntervalWindow> tester =
        ReduceFnTester.nonCombining(
            FixedWindows.of(Duration.millis(10)),
            DefaultTriggerStateMachine.of(),
            AccumulationMode.ACCUMULATING_FIRED_PANES,
            Duration.millis(50),
            ClosingBehavior.FIRE_IF_NON_EMPTY);

    tester.setAutoAdvanceOutputWatermark(true);

    tester.advanceInputWatermark(new Instant(0));
    injectElement(tester, 1);
    tester.advanceInputWatermark(new Instant(100));

    List<WindowedValue<Iterable<Integer>>> output = tester.extractOutput();
    assertThat(
        output,
        contains(
            isSingleWindowedValue(
                contains(1), 1, 0, 10, PaneInfo.createPane(true, true, Timing.ON_TIME))));
  }
",non-flaky,5
20915,NationalSecurityAgency_timely,MetricHistogramTest.testCount,"    @Test
    public void testCount() throws Exception {
        Assert.assertEquals(100.0D, m.count(), 0.0D);
    }
",non-flaky,5
267,alibaba_fastjson,SortFieldTest.test_1,"@Test
public void test_1() throws Exception {
    V1 entity = new V1();
    String text = JSON.toJSONString(entity, SortField);
    System.out.println(text);
    Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", text);
    JSONObject object = JSON.parseObject(text);
    text = JSON.toJSONString(object, SortField);
    Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", text);
}",unordered collections,3
162713,OpenAPITools_openapi-generator,XmlItemTest.nameBooleanTest,"    @Test
    public void nameBooleanTest() {
        // TODO: test nameBoolean
    }
",non-flaky,5
170463,eclipse_jetty.project,MBeanContainerLifeCycleTest.dispose,"    @AfterEach
    public void dispose() throws Exception
    {
        container.stop();
    }
",non-flaky,5
104651,apache_pinot,OfflineClusterIntegrationTest.testFilterWithInvertedIndexUDF,"  @Test
  public void testFilterWithInvertedIndexUDF()
      throws Exception {
    int daysSinceEpoch = 16138;
    long secondsSinceEpoch = 16138 * 24 * 60 * 60;

    String[] origins = new String[]{
        ""ATL"", ""ORD"", ""DFW"", ""DEN"", ""LAX"", ""IAH"", ""SFO"", ""PHX"", ""LAS"", ""EWR"", ""MCO"", ""BOS"", ""SLC"", ""SEA"", ""MSP"", ""CLT"",
        ""LGA"", ""DTW"", ""JFK"", ""BWI""
    };
    String pqlQuery;
    for (String origin : origins) {
      pqlQuery =
          ""SELECT count(*) FROM mytable WHERE Origin = \"""" + origin + ""\"" AND DaysSinceEpoch = "" + daysSinceEpoch;
      JsonNode response1 = postQuery(pqlQuery);
      pqlQuery = ""SELECT count(*) FROM mytable WHERE Origin = \"""" + origin
          + ""\"" AND timeConvert(DaysSinceEpoch,'DAYS','SECONDS') = "" + secondsSinceEpoch;
      JsonNode response2 = postQuery(pqlQuery);
      double val1 = response1.get(""aggregationResults"").get(0).get(""value"").asDouble();
      double val2 = response2.get(""aggregationResults"").get(0).get(""value"").asDouble();
      assertEquals(val1, val2);
    }
  }
",non-flaky,5
60907,apache_druid,MovingAverageIterableTest.testMissingDaysInMiddle,"  @Test
  public void testMissingDaysInMiddle()
  {
    System.setProperty(""druid.generic.useDefaultValueForNull"", ""true"");
    NullHandling.initializeForTests();
    Map<String, Object> event1 = new HashMap<>();
    Map<String, Object> event2 = new HashMap<>();

    List<DimensionSpec> ds = new ArrayList<>();
    ds.add(new DefaultDimensionSpec(""gender"", ""gender""));

    event1.put(""gender"", ""m"");
    event1.put(""pageViews"", 10L);
    Row row1 = new MapBasedRow(JAN_1, event1);

    event2.put(""gender"", ""m"");
    event2.put(""pageViews"", 20L);
    Row row2 = new MapBasedRow(JAN_4, event2);

    Sequence<RowBucket> seq = Sequences.simple(Arrays.asList(
        new RowBucket(JAN_1, Collections.singletonList(row1)),
        new RowBucket(JAN_2, Collections.emptyList()),
        new RowBucket(JAN_3, Collections.emptyList()),
        new RowBucket(JAN_4, Collections.singletonList(row2))
    ));

    Iterator<Row> iter = new MovingAverageIterable(
        seq,
        ds,
        Collections.singletonList(
            new LongMeanAveragerFactory(""movingAvgPageViews"", 4, 1, ""pageViews"")
        ),
        Collections.emptyList(),
        Collections.singletonList(new LongSumAggregatorFactory(""pageViews"", ""pageViews""))
    ).iterator();

    Assert.assertTrue(iter.hasNext());
    Row result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(2.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertTrue(iter.hasNext());
    result = iter.next();
    Assert.assertEquals(""m"", (result.getDimension(""gender"")).get(0));
    Assert.assertEquals(7.5f, result.getMetric(""movingAvgPageViews"").floatValue(), 0.0f);

    Assert.assertFalse(iter.hasNext());
  }
",non-flaky,5
159690,liquibase_liquibase,AddAutoIncrementExecuteTest.noSchema,"    @Test
    public void noSchema() throws Exception {
        this.statementUnderTest = new AddAutoIncrementStatement(null, null, TABLE_NAME, COLUMN_NAME, ""int"", null, null, null, null);

        assertCorrect(""alter table [table_name] modify column_name serial"", PostgresDatabase.class);
        assertCorrect(""alter table table_name modify column_name int auto_increment"", MySQLDatabase.class);
        assertCorrect(""ALTER TABLE [table_name] ALTER COLUMN [column_name] SET GENERATED BY DEFAULT AS IDENTITY"", DB2Database.class);
        assertCorrect(""alter table table_name alter column column_name int generated by default as identity"", HsqlDatabase.class);
        assertCorrect(""alter table table_name alter column column_name int auto_increment"", H2Database.class);

        assertCorrect(""ALTER TABLE [table_name] MODIFY [column_name] serial"", InformixDatabase.class);
        assertCorrect(""ALTER TABLE [table_name] ALTER [column_name] SET DEFAULT AUTOINCREMENT"", SybaseASADatabase.class);
        assertCorrect(""ALTER TABLE [table_name] MODIFY [column_name] int identity"", SybaseDatabase.class);
        assertCorrect(""ALTER TABLE [table_name] ALTER column [column_name] SET GENERATED BY DEFAULT AS IDENTITY"", Db2zDatabase.class);

        assertCorrectOnRest(""ALTER TABLE [table_name] MODIFY [column_name] int AUTO_INCREMENT"");
    }
",non-flaky,5
70817,apache_kafka,PluginsTest.newPluginShouldServiceLoadWithPluginClassLoader,"    @Test
    public void newPluginShouldServiceLoadWithPluginClassLoader() {
        TestPlugins.assertAvailable();
        Converter plugin = plugins.newPlugin(
            TestPlugins.SERVICE_LOADER,
            new AbstractConfig(new ConfigDef(), Collections.emptyMap()),
            Converter.class
        );

        assertInstanceOf(SamplingTestPlugin.class, plugin, ""Cannot collect samples"");
        Map<String, SamplingTestPlugin> samples = ((SamplingTestPlugin) plugin).flatten();
        // Assert that the service loaded subclass is found in both environments
        assertTrue(samples.containsKey(""ServiceLoadedSubclass.static""));
        assertTrue(samples.containsKey(""ServiceLoadedSubclass.dynamic""));
        assertPluginClassLoaderAlwaysActive(samples);
    }
",non-flaky,5
104700,apache_pinot,SegmentWriterUploaderIntegrationTest.testFileBasedSegmentWriterAndDefaultUploader,"  @Test
  public void testFileBasedSegmentWriterAndDefaultUploader()
      throws Exception {

    TableConfig offlineTableConfig = createOfflineTableConfig();
    addTableConfig(offlineTableConfig);

    SegmentWriter segmentWriter = new FileBasedSegmentWriter();
    segmentWriter.init(offlineTableConfig, _schema);
    SegmentUploader segmentUploader = new SegmentUploaderDefault();
    segmentUploader.init(offlineTableConfig);

    GenericRow reuse = new GenericRow();
    long totalDocs = 0;
    for (int i = 0; i < 3; i++) {
      AvroRecordReader avroRecordReader = new AvroRecordReader();
      avroRecordReader.init(_avroFiles.get(i), null, null);

      long numDocsInSegment = 0;
      while (avroRecordReader.hasNext()) {
        avroRecordReader.next(reuse);
        segmentWriter.collect(reuse);
        numDocsInSegment++;
        totalDocs++;
      }
      // flush to segment
      URI segmentTarURI = segmentWriter.flush();
      // upload
      segmentUploader.uploadSegment(segmentTarURI, null);

      // check num segments
      Assert.assertEquals(getNumSegments(), i + 1);
      // check numDocs in latest segment
      Assert.assertEquals(getNumDocsInLatestSegment(), numDocsInSegment);
      // check totalDocs in query
      checkTotalDocsInQuery(totalDocs);
    }
    segmentWriter.close();

    dropAllSegments(_tableNameWithType, TableType.OFFLINE);
    checkNumSegments(0);

    // upload all together using dir
    segmentUploader.uploadSegmentsFromDir(_tarDir.toURI(), null);
    // check num segments
    Assert.assertEquals(getNumSegments(), 3);
    // check totalDocs in query
    checkTotalDocsInQuery(totalDocs);

    dropOfflineTable(_tableNameWithType);
  }
",non-flaky,5
98619,nutzam_nutz,El2Test.test_base64,"    @Test
    public void test_base64(){
        Context ctx = Lang.context();
        
        El el = new El(""base64('ä¸­æ,è±æabc,ç«ææ((%&(*')"");
        assertEquals(Base64.encodeToString(""ä¸­æ,è±æabc,ç«ææ((%&(*"".getBytes(Encoding.CHARSET_UTF8), false), el.eval(ctx));
        
        String str = Base64.encodeToString(""EEEä¸­æ"".getBytes(Encoding.CHARSET_UTF8), false);
        el = new El(""base64('decode', \'"" + str + ""\')"");
        assertEquals(""EEEä¸­æ"", el.eval(ctx));
    }
",non-flaky,5
91485,strapdata_elassandra,IndicesShardStoreRequestIT.testEmpty,"@TestLogging(""_root:DEBUG,org.elasticsearch.action.admin.indices.shards:TRACE,org.elasticsearch.cluster.service:TRACE"")
    public void testEmpty() {
        ensureGreen();
        IndicesShardStoresResponse rsp = client().admin().indices().prepareShardStores().get();
        assertThat(rsp.getStoreStatuses().size(), equalTo(0));
    }
",non-flaky,5
35718,cdapio_cdap,TestKafkaLogging.testGetNext,"  @Test
  public void testGetNext() throws Exception {
    // Check with null runId and null instanceId
    LoggingContext loggingContext = new WorkerLoggingContext(""TKL_NS_1"", ""APP_1"", ""FLOW_1"", ""RUN1"", ""INSTANCE1"");
    KafkaLogReader logReader = KAFKA_TESTER.getInjector().getInstance(KafkaLogReader.class);
    LoggingTester tester = new LoggingTester();
    tester.testGetNext(logReader, loggingContext);
  }
",non-flaky,5
133898,julianghionoiu_dpnt-coverage,LanguageTest.should_throw_exception_if_language_not_recognised,"    @Test
    public void should_throw_exception_if_language_not_recognised() throws IllegalLanguageException {
        thrown.expect(IllegalLanguageException.class);
        Language.of(""none"");
    }
",non-flaky,5
99751,apache_cassandra,AsyncStreamingInputPlusTest.available_closed,"    @Test
    public void available_closed()
    {
        inputPlus = new AsyncStreamingInputPlus(channel);
        inputPlus.requestClosure();
        inputPlus.unsafeAvailable();
    }
",non-flaky,5
91400,OpenLCB_OpenLCB_Java,GridConnectOutputTest.run,"    @Test
    public void testCTor() {
        GridConnectOutput t = new GridConnectOutput(new java.io.ByteArrayOutputStream(), new Runnable(){
    public void run(){
    }
",non-flaky,5
113892,spring-projects_spring-data-couchbase,ReactiveCouchbaseTemplateQueryCollectionIntegrationTests.findByIdOptions,"	@Test
	public void findByIdOptions() { // 3
		GetOptions options = GetOptions.getOptions().timeout(Duration.ofNanos(10));
		assertThrows(UnambiguousTimeoutException.class, () -> template.findById(Airport.class).inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie.getId()).block());
	}
",non-flaky,5
43000,fabiomaffioletti_jsondoc,Issue151Test.testIssue151,"	@Test
	public void testIssue151() {
		JSONDoc jsonDoc = jsondocScanner.getJSONDoc(""version"", ""basePath"", Lists.newArrayList(""org.jsondoc.springmvc.issues.issue151""), true, MethodDisplay.URI);
		Assert.assertEquals(2, jsonDoc.getObjects().keySet().size());
		Assert.assertEquals(1, jsonDoc.getObjects().get(""bargroup"").size());
		Assert.assertEquals(1, jsonDoc.getObjects().get(""foogroup"").size());
	}
",non-flaky,5
70858,apache_kafka,TransformationConfigTest.testEmbeddedConfigReplaceField,"    @Test
    public void testEmbeddedConfigReplaceField() {
        // Validate that we can construct a Connector config containing the extended config for the transform
        HashMap<String, String> connProps = new HashMap<>();
        connProps.put(""name"", ""foo"");
        connProps.put(""connector.class"", MockConnector.class.getName());
        connProps.put(""transforms"", ""example"");
        connProps.put(""transforms.example.type"", ReplaceField.Value.class.getName());

        Plugins plugins = null; // Safe when we're only constructing the config
        new ConnectorConfig(plugins, connProps);
    }
",non-flaky,5
88850,apache_ignite,DatasetWrapperTest.testComputeWithCtx,"    @Test
    public void testComputeWithCtx() {
        doReturn(42).when(dataset).computeWithCtx(any(IgniteTriFunction.class), any(), any());

        Integer res = (Integer) wrapper.computeWithCtx(mock(IgniteTriFunction.class), mock(IgniteBinaryOperator.class),
            null);

        assertEquals(42, res.intValue());

        verify(dataset, times(1)).computeWithCtx(any(IgniteTriFunction.class), any(), any());
    }
",non-flaky,5
133946,CorfuDB_CorfuDB,BaseHandlerTest.testHandleRestart,"    @Test
    public void testHandleRestart() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getRestartResponseMsg()
        );

        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
110931,pushtorefresh_storio,InsertQueryTest.affectsTagsVarargShouldRewrite,"    @Test
    public void affectsTagsVarargShouldRewrite() {
        InsertQuery insertQuery = InsertQuery.builder()
                .table(""table"")
                .affectsTags(""first_call_vararg"")
                .affectsTags(""second_call_vararg"")
                .build();

        assertThat(insertQuery.affectsTags()).isEqualTo(singleton(""second_call_vararg""));
    }
",non-flaky,5
162700,OpenAPITools_openapi-generator,CatTest.testCat,"    @Test
    public void testCat() {
        // TODO: test Cat
    }
",non-flaky,5
104666,apache_pinot,RealtimeKinesisIntegrationTest.testRecords,"  @Test
  public void testRecords()
      throws Exception {
    Assert.assertNotEquals(_totalRecordsPushedInStream, 0);

    ResultSet pinotResultSet = getPinotConnection()
        .execute(new Request(""sql"", ""SELECT * FROM "" + getTableName() + "" ORDER BY Origin LIMIT 10000""))
        .getResultSet(0);

    Assert.assertNotEquals(pinotResultSet.getRowCount(), 0);

    Statement h2statement =
        _h2Connection.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY, java.sql.ResultSet.CONCUR_READ_ONLY);
    h2statement.execute(""SELECT * FROM "" + getTableName() + "" ORDER BY Origin"");
    java.sql.ResultSet h2ResultSet = h2statement.getResultSet();

    Assert.assertFalse(h2ResultSet.isLast());

    h2ResultSet.beforeFirst();
    int row = 0;
    Map<String, Integer> columnToIndex = new HashMap<>();
    for (int i = 0; i < _h2FieldNameAndTypes.size(); i++) {
      columnToIndex.put(pinotResultSet.getColumnName(i), i);
    }

    while (h2ResultSet.next()) {

      for (String fieldNameAndDatatype : _h2FieldNameAndTypes) {
        String[] fieldNameAndDatatypeList = fieldNameAndDatatype.split("" "");
        String fieldName = fieldNameAndDatatypeList[0];
        String h2DataType = fieldNameAndDatatypeList[1];
        switch (h2DataType) {
          case ""int"": {
            int expectedValue = h2ResultSet.getInt(fieldName);
            int actualValue = pinotResultSet.getInt(row, columnToIndex.get(fieldName));
            Assert.assertEquals(expectedValue, actualValue);
            break;
          }
          case ""varchar(128)"": {
            String expectedValue = h2ResultSet.getString(fieldName);
            String actualValue = pinotResultSet.getString(row, columnToIndex.get(fieldName));
            Assert.assertEquals(expectedValue, actualValue);
            break;
          }
          default:
            break;
        }
      }

      row++;

      if (row >= pinotResultSet.getRowCount()) {
        int cnt = 0;
        while (h2ResultSet.next()) {
          cnt++;
        }
        Assert.assertEquals(cnt, 0);
        break;
      }
    }
  }
",non-flaky,5
26202,Ericsson_ecchronos,TestLockCache.testGetOtherLockAfterThrowingOnAnotherResource,"    @Test
    public void testGetOtherLockAfterThrowingOnAnotherResource() throws LockException
    {
        String otherResource = ""RepairResource-b2e33e60-7af6-11e9-8f9e-2a86e4085a59-1"";

        LockException expectedException = doThrowOnGetLock(RESOURCE);
        DistributedLock expectedOtherLock = doReturnLockOnGetLock(otherResource);

        assertGetLockThrowsException(RESOURCE, expectedException);
        assertGetLockRetrievesExpectedLock(otherResource, expectedOtherLock);
    }
",non-flaky,5
104176,spring-cloud_spring-cloud-config,EncryptionControllerMultiTextEncryptorTests.shouldNotEncryptUsingNoOp,"	@Test(expected = EncryptionTooWeakException.class)
	public void shouldNotEncryptUsingNoOp() {
		// given
		String application = ""unknown"";

		// when
		this.controller.encrypt(application, this.profiles, this.data, TEXT_PLAIN);

		// then exception is thrown
	}
",non-flaky,5
91520,apache_kylin,TimedJsonStreamParserTest.testNormalValue,"    @Test
    public void testNormalValue() throws Exception {
        userNeedColNames = new String[] { ""createdAt"", ""id"", ""isTruncated"", ""text"" };
        List<TblColRef> allCol = mockupTblColRefList();
        TimedJsonStreamParser parser = new TimedJsonStreamParser(allCol, null);
        Object msg = mapper.readValue(new File(jsonFilePath), mapType);
        ByteBuffer buffer = getJsonByteBuffer(msg);
        List<StreamingMessageRow> msgList = parser.parse(buffer);
        List<String> result = msgList.get(0).getData();
        assertEquals(""Jul 20, 2016 9:59:17 AM"", result.get(0));
        assertEquals(""755703618762862600"", result.get(1));
        assertEquals(""false"", result.get(2));
        assertEquals(""dejamos"", result.get(3));
    }
",non-flaky,5
112114,apache_shardingsphere-elasticjob,StatisticRdbRepositoryTest.assertFindTaskResultStatisticsWithDifferentFromDate,"    @Test
    public void assertFindTaskResultStatisticsWithDifferentFromDate() {
        Date now = new Date();
        Date yesterday = getYesterday();
        for (StatisticInterval each : StatisticInterval.values()) {
            assertTrue(repository.add(new TaskResultStatistics(100, 0, each, yesterday)));
            assertTrue(repository.add(new TaskResultStatistics(100, 0, each, now)));
            assertThat(repository.findTaskResultStatistics(yesterday, each).size(), is(2));
            assertThat(repository.findTaskResultStatistics(now, each).size(), is(1));
        }
    }
",non-flaky,5
110159,Wikidata_wikidata-toolkit,WebResourceFetcherTest.testSetUserAgent,"	@Test
	public void testSetUserAgent() {
		WebResourceFetcherImpl.setUserAgent(""My user agent"");
		assertEquals(""My user agent"", WebResourceFetcherImpl.getUserAgent());
	}
",non-flaky,5
91502,apache_kylin,DriverTest.testSSLFromURL,"    @Test
    public void testSSLFromURL() throws SQLException {
        Driver driver = new DummyDriver();
        Connection conn = driver.connect(""jdbc:kylin:ssl=True;//test_url/test_db"", null);
        assertEquals(""test_url"", ((KylinConnection) conn).getBaseUrl());
        assertEquals(""test_db"", ((KylinConnection) conn).getProject());
        assertTrue(Boolean.parseBoolean((String) ((KylinConnection) conn).getConnectionProperties().get(""ssl"")));
        conn.close();
    }
",non-flaky,5
76681,quarkusio_quarkus,CustomAuthEmbeddedBase.testJaxrsPathAdminRoleSuccess,"    @Test
    public void testJaxrsPathAdminRoleSuccess() {
        RestAssured.given().auth().preemptive().basic(""scott"", ""jb0ss"")
                .when().get(""/jaxrs-secured/parameterized-paths/my/banking/admin"").then()
                .statusCode(200);
    }
",non-flaky,5
98578,nutzam_nutz,SimpleSpeedTest.run,"    @Test
    public void test_speed() throws SecurityException, NoSuchMethodException {
        final SimpleSpeedTest z = new SimpleSpeedTest();
        final String elstr = ""num + (i - 1 + 2 - 3 + 4 - 5 + 6 - 7)-z.abc(i)"";
        final Context context = Lang.context(""{num:0}"");
        context.set(""z"", z);

        System.out.println(""\n"" + Strings.dup('=', 100));

        Stopwatch sw = Stopwatch.run(new Atom() {
            public void run() {
                int num = 0;
                for (int i = 0; i < max; i++)
                    num = num + (i - 1 + 2 - 3 + 4 - 5 + 6 - 7) - z.abc(i);
                //System.out.println(""Num: "" + num);
            }
",non-flaky,5
70835,apache_kafka,WorkerSourceTaskTest.answer,"    @Test
    public void testFailureInPoll() throws Exception {
        createWorkerTask();

        sourceTask.initialize(EasyMock.anyObject(SourceTaskContext.class));
        EasyMock.expectLastCall();
        sourceTask.start(TASK_PROPS);
        EasyMock.expectLastCall();
        statusListener.onStartup(taskId);
        EasyMock.expectLastCall();

        final CountDownLatch pollLatch = new CountDownLatch(1);
        final RuntimeException exception = new RuntimeException();
        EasyMock.expect(sourceTask.poll()).andAnswer(new IAnswer<List<SourceRecord>>() {
            @Override
            public List<SourceRecord> answer() throws Throwable {
                pollLatch.countDown();
                throw exception;
            }
",non-flaky,5
38252,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testAddGCSentinelValues,"    @Test
    public void testAddGCSentinelValues() {
        putTestDataForMultipleTimestamps();
        Cell cell = Cell.create(row0, column0);

        Multimap<Cell, Long> timestampsBefore = keyValueService.getAllTimestamps(TEST_TABLE, ImmutableSet.of(cell), Long.MAX_VALUE);
        assertEquals(2, timestampsBefore.size());
        assertTrue(!timestampsBefore.containsEntry(cell, Value.INVALID_VALUE_TIMESTAMP));

        keyValueService.addGarbageCollectionSentinelValues(TEST_TABLE, ImmutableSet.of(cell));

        Multimap<Cell, Long> timestampsAfter1 = keyValueService.getAllTimestamps(TEST_TABLE, ImmutableSet.of(cell), Long.MAX_VALUE);
        assertEquals(3, timestampsAfter1.size());
        assertTrue(timestampsAfter1.containsEntry(cell, Value.INVALID_VALUE_TIMESTAMP));

        keyValueService.addGarbageCollectionSentinelValues(TEST_TABLE, ImmutableSet.of(cell));

        Multimap<Cell, Long> timestampsAfter2 = keyValueService.getAllTimestamps(TEST_TABLE, ImmutableSet.of(cell), Long.MAX_VALUE);
        assertEquals(3, timestampsAfter2.size());
        assertTrue(timestampsAfter2.containsEntry(cell, Value.INVALID_VALUE_TIMESTAMP));
    }
",non-flaky,5
33716,alibaba_fastjson,JSONPathTest.eq1,"  @Test
  public void eq1() throws Throwable {
    // Arrange
    Object a = -1;
    Object b = null;
    // Act
    Class<?> c = Reflector.forName(""com.alibaba.fastjson.JSONPath"");
    Method m = c.getDeclaredMethod(""eq"", Reflector.forName(""java.lang.Object""), Reflector.forName(""java.lang.Object""));
    m.setAccessible(true);
    boolean retval = (Boolean)m.invoke(null, a, b);
    // Assert result
    Assert.assertEquals(false, retval);
  }
",non-flaky,5
301,apache_hadoop,TestRpcProgramNfs3.testLookup,"  @Test(timeout = 60000)
  public void testLookup() throws Exception {
    HdfsFileStatus status = nn.getRpcServer().getFileInfo(testdir);
    long dirId = status.getFileId();
    int namenodeId = Nfs3Utils.getNamenodeId(config);
    FileHandle handle = new FileHandle(dirId, namenodeId);
    LOOKUP3Request lookupReq = new LOOKUP3Request(handle, ""bar"");
    XDR xdr_req = new XDR();
    lookupReq.serialize(xdr_req);

    // Attempt by an unpriviledged user should fail.
    LOOKUP3Response response1 = nfsd.lookup(xdr_req.asReadOnlyWrap(),
        securityHandlerUnpriviledged,
        new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3ERR_ACCES,
        response1.getStatus());

    // Attempt by a priviledged user should pass.
    LOOKUP3Response response2 = nfsd.lookup(xdr_req.asReadOnlyWrap(),
        securityHandler, new InetSocketAddress(""localhost"", 1234));
    assertEquals(""Incorrect return code"", Nfs3Status.NFS3_OK,
        response2.getStatus());
  }
",non-flaky,5
122560,vespa-engine_vespa,CommandLineTest.waitingForTerminationExceptionStillClosesChild,"    @Test
    public void waitingForTerminationExceptionStillClosesChild() {
        TestChildProcess2 child = new TestChildProcess2(0, """");
        child.throwInWaitForTermination(new NegativeArraySizeException());
        terminal.interceptCommand(commandLine.toString(), command -> child);
        assertFalse(child.closeCalled());
        try {
            commandLine.add(""foo"").execute();
            fail();
        } catch (NegativeArraySizeException e) {
            // OK
        }

        assertTrue(child.closeCalled());
    }
",non-flaky,5
135806,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testThreadPoolRejected,"    @Test
    public void testThreadPoolRejected() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-I"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //10 commands will saturate threadpools when called concurrently.
        //submit 2 more requests and they should be THREADPOOL_REJECTED
        //should see 10 SUCCESSes, 2 THREADPOOL_REJECTED and 2 FALLBACK_SUCCESSes

        List<Command> saturators = new ArrayList<Command>();

        for (int i = 0; i < 10; i++) {
            saturators.add(Command.from(groupKey, key, HystrixEventType.SUCCESS, 500));
        }

        Command rejected1 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0);
        Command rejected2 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0);

        for (final Command saturator : saturators) {
            saturator.observe();
        }

        try {
            Thread.sleep(100);
        } catch (InterruptedException ie) {
            fail(ie.getMessage());
        }

        rejected1.observe();
        rejected2.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }

        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertTrue(rejected1.isResponseThreadPoolRejected());
        assertTrue(rejected2.isResponseThreadPoolRejected());
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.SUCCESS.ordinal()] = 10;
        expected[HystrixEventType.THREAD_POOL_REJECTED.ordinal()] = 2;
        expected[HystrixEventType.FALLBACK_SUCCESS.ordinal()] = 2;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
70815,apache_kafka,PluginsTest.shouldThrowIfPluginThrows,"    @Test(expected = ConnectException.class)
    public void shouldThrowIfPluginThrows() {
        TestPlugins.assertAvailable();

        plugins.newPlugin(
            TestPlugins.ALWAYS_THROW_EXCEPTION,
            new AbstractConfig(new ConfigDef(), Collections.emptyMap()),
            Converter.class
        );
    }
",non-flaky,5
88812,apache_ignite,FunctionalTest.testAtomicPutGet,"    @Test
    public void testAtomicPutGet() throws Exception {
        try (Ignite ignored = Ignition.start(Config.getServerConfiguration());
             IgniteClient client = Ignition.startClient(getClientConfiguration())
        ) {
            ClientCache<Integer, String> cache = client.createCache(""testRemoveReplace"");

            assertNull(cache.getAndPut(1, ""1""));
            assertEquals(""1"", cache.getAndPut(1, ""1.1""));

            assertEquals(""1.1"", cache.getAndRemove(1));
            assertNull(cache.getAndRemove(1));

            assertTrue(cache.putIfAbsent(1, ""1""));
            assertFalse(cache.putIfAbsent(1, ""1.1""));

            assertEquals(""1"", cache.getAndReplace(1, ""1.1""));
            assertEquals(""1.1"", cache.getAndReplace(1, ""1""));
            assertNull(cache.getAndReplace(2, ""2""));
        }
    }
",non-flaky,5
77549,dropwizard_dropwizard,GzipDefaultVaryBehaviourTest.testDefaultVaryHeader,"    @Test
    public void testDefaultVaryHeader() {
        final Response clientResponse = RULE.client().target(
            ""http://localhost:"" + RULE.getLocalPort() + ""/test"").request().header(ACCEPT_ENCODING, ""gzip"").get();

        assertThat(clientResponse.getHeaders().get(VARY)).isEqualTo(Collections.singletonList((Object) ACCEPT_ENCODING));
        assertThat(clientResponse.getHeaders().get(CONTENT_ENCODING)).isEqualTo(Collections.singletonList((Object) ""gzip""));
    }
",non-flaky,5
91534,apache_kylin,DefaultJdbcMetadataTest.testListColumns,"    @Test
    public void testListColumns() throws SQLException {
        String schema = ""testSchema"";
        String table = ""testTable"";
        ResultSet rs = mock(ResultSet.class);
        when(dbmd.getColumns(null, schema, table, null)).thenReturn(rs);

        ResultSet result = jdbcMetadata.listColumns(dbmd, schema, table);

        verify(dbmd, times(1)).getColumns(null, schema, table, null);
        Assert.assertEquals(rs, result);
    }
",non-flaky,5
38672,apache_pulsar,InfluxDBSinkTest.testOpenWriteCloseAvro,"    @Test
    public void testOpenWriteCloseAvro() throws Exception {
        AvroSchema<Cpu> avroSchema = AvroSchema.of(Cpu.class);
        openWriteClose(avroSchema);
    }
",non-flaky,5
110127,Wikidata_wikidata-toolkit,ClientTest.testNonExistingLocalDump,"	@Test
	public void testNonExistingLocalDump() {
		String[] args = { ""-f"", ""./asfjl.json"" };
		Client client = new Client(mockDpc, args);
		client.performActions();

		Mockito.verify(mockDpc, Mockito.never()).processDump(
				Mockito.<MwDumpFile> any());
	}
",non-flaky,5
59607,looly_hutool,ExpressionUtilTest.jexlTest,"	@Test
	public void jexlTest(){
		ExpressionEngine engine = new JexlEngine();

		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = engine.eval(""a-(b-c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
",non-flaky,5
179462,abel533_Mapper,KeySqlTest.testUserAutoIncrement,"    @Test
    public void testUserAutoIncrement() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserAutoIncrementMapper mapper = sqlSession.getMapper(UserAutoIncrementMapper.class);

            UserAutoIncrement user = new UserAutoIncrement();
            user.setName(""liuzh"");
            Assert.assertEquals(1, mapper.insert(user));
            Assert.assertNotNull(user.getId());

            user = mapper.selectByPrimaryKey(user.getId());
            Assert.assertEquals(""liuzh"", user.getName());
        } finally {
            sqlSession.close();
        }
    }
",non-flaky,5
104621,apache_pinot,RealtimeClusterIntegrationTest.testDictionaryBasedQueries,"  @Test
  public void testDictionaryBasedQueries()
      throws Exception {

    // Dictionary columns
    // int
    testDictionaryBasedFunctions(""NASDelay"");

    // long
    testDictionaryBasedFunctions(""AirlineID"");

    // double
    testDictionaryBasedFunctions(""ArrDelayMinutes"");

    // float
    testDictionaryBasedFunctions(""DepDelayMinutes"");

    // Non Dictionary columns
    // int
    testDictionaryBasedFunctions(""ActualElapsedTime"");

    // double
    testDictionaryBasedFunctions(""DepDelay"");

    // float
    testDictionaryBasedFunctions(""ArrDelay"");
  }
",non-flaky,5
118728,netty_netty,BigEndianHeapByteBufTest.shouldNotAllowNullInConstructor1,"    @Test(expected = NullPointerException.class)
    public void shouldNotAllowNullInConstructor1() {
        new UnpooledHeapByteBuf(null, new byte[1], 0);
    }
",non-flaky,5
43036,trinodb_trino,BaseDynamicPartitionPruningTest.testSemiJoinWithNonSelectiveBuildSide,"    @Test(timeOut = 30_000)
    public void testSemiJoinWithNonSelectiveBuildSide()
    {
        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem WHERE suppkey IN (SELECT suppkey FROM supplier)"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        // Probe-side is fully scanned
        assertEquals(probeStats.getInputPositions(), LINEITEM_COUNT);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);

        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertThat(domainStats.getSimplifiedDomain())
                .isEqualTo(getSimplifiedDomainString(1L, 100L, 100, BIGINT));
    }
",non-flaky,5
38613,apache_pulsar,PerformanceProducerTest.testNotExistIMessageFormatter,"    @Test
    public void testNotExistIMessageFormatter() {
        IMessageFormatter msgFormatter = PerformanceProducer.getMessageFormatter(""org.apache.pulsar.testclient.NonExistentFormatter"");
        Assert.assertNull(msgFormatter);
    }
",non-flaky,5
110201,Wikidata_wikidata-toolkit,MwLocalDumpFileTest.missingDumpFileDirectory,"	@Test
	public void missingDumpFileDirectory() throws IOException {
		MwLocalDumpFile df = new MwLocalDumpFile(
				""/nonexisting-directory/non-existing-file.json.gz"");
		assertFalse(df.isAvailable());
	}
",non-flaky,5
60886,apache_druid,DerivativeDataSourceMetadataTest.testNullBaseDataSource,"  @Test
  public void testNullBaseDataSource()
  {
    expectedException.expect(CoreMatchers.instanceOf(IllegalArgumentException.class));
    expectedException.expectMessage(
        ""baseDataSource cannot be null or empty. Please provide a baseDataSource.""
    );
    String baseDataSource = null;
    Set<String> dims = Sets.newHashSet(""dim1"", ""dim2"", ""dim3"");
    Set<String> metrics = Sets.newHashSet(""cost"");
    DerivativeDataSourceMetadata metadata = new DerivativeDataSourceMetadata(baseDataSource, dims, metrics);
  }
",non-flaky,5
26233,Ericsson_ecchronos,TestTableRepairJob.testPrevalidateNotRepairable,"    @Test
    public void testPrevalidateNotRepairable()
    {
        // mock
        doReturn(false).when(myRepairStateSnapshot).canRepair();

        assertThat(myRepairJob.runnable()).isFalse();

        verify(myRepairState, times(1)).update();
        verify(myRepairStateSnapshot, times(1)).canRepair();
    }
",non-flaky,5
33887,apache_camel,FhirMetaIT.testGetFromType,"    @Test
    public void testGetFromType() throws Exception {
        final Map<String, Object> headers = new HashMap<>();
        // parameter type is Class
        headers.put(""CamelFhir.metaType"", Meta.class);
        // parameter type is String
        headers.put(""CamelFhir.resourceType"", ""Patient"");

        IBaseMetaType result = requestBodyAndHeaders(""direct://GET_FROM_TYPE"", null, headers);

        LOG.debug(""getFromType: "" + result);
        assertNotNull(result, ""getFromType result"");
    }
",non-flaky,5
98639,nutzam_nutz,SimpleAdaptorTest.test_inputstream_as_string,"    @Test
    public void test_inputstream_as_string() {
        resp = post(""/adaptor/ins"", ""I am abc"");
        if (resp.getStatus() != 200) {
            fail();
        }
        assertEquals(""I am abc"", resp.getContent());
    }
",non-flaky,5
98344,Kong_unirest-java,CacheManagerTest.getClient,"    @Test
        public Object getClient() {
            return null;
        }
",non-flaky,5
30993,camunda-cloud_zeebe,ObjectMappingTest.shouldFailDeserializationWithUndersizedIntegerValue,"  @Test
  public void shouldFailDeserializationWithUndersizedIntegerValue() {
    // given
    final POJO pojo = new POJO();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(6);

              w.writeString(wrapString(""enumProp""));
              w.writeString(wrapString(POJOEnum.BAR.toString()));

              w.writeString(wrapString(""binaryProp""));
              w.writeBinary(BUF1);

              w.writeString(wrapString(""stringProp""));
              w.writeString(BUF2);

              w.writeString(wrapString(""packedProp""));
              w.writeRaw(MSGPACK_BUF1);

              w.writeString(wrapString(""longProp""));
              w.writeInteger(88888L);

              w.writeString(wrapString(""intProp""));
              w.writeInteger(Integer.MIN_VALUE - 1L);
            });

    // then
    exception.expect(RuntimeException.class);
    exception.expectMessage(""Could not deserialize object"");

    // when
    pojo.wrap(buffer);
  }
",non-flaky,5
96021,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherConj,"  @Test
  public void testTokenSequenceMatcherConj() throws IOException {
    CoreMap doc = createDocument(testText1);
    TokenSequencePattern p = TokenSequencePattern.compile(
                  new SequencePattern.AndPatternExpr(
                    new SequencePattern.SequencePatternExpr(
                      new SequencePattern.GroupPatternExpr(
                            new SequencePattern.RepeatPatternExpr(
                                    getNodePatternExpr(""[A-Za-z]+""), 2, 2)),
                      getNodePatternExpr(""of""),
                      new SequencePattern.GroupPatternExpr(
                            new SequencePattern.RepeatPatternExpr(
                                    getNodePatternExpr(""[A-Za-z]+""), 1, 3, false))),
                    new SequencePattern.SequencePatternExpr(
                      new SequencePattern.GroupPatternExpr(
                        new SequencePattern.RepeatPatternExpr(
                            getNodePatternExpr("".*""), 0, -1)),
                      getNodePatternExpr(""Bishop""),
                      new SequencePattern.RepeatPatternExpr(
                            getNodePatternExpr("".*""), 0, -1)
                    )));

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals(""first"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    // TODO: This conjunction has both a greedy and nongreedy pattern
    //  - the greedy will try to match as much as possible
    //  - while the non greedy will try to match less
    //  - currently the greedy overrides the nongreedy so we get an additional in...
    assertEquals(""as Bishop of London in"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London in"", m.group(2));
    assertEquals(""as"", m.group(3));
    match = m.find();
    assertFalse(match);


    // Same as before, but both non-greedy now...
    p = TokenSequencePattern.compile(
                  new SequencePattern.AndPatternExpr(
                    new SequencePattern.SequencePatternExpr(
                      new SequencePattern.GroupPatternExpr(
                            new SequencePattern.RepeatPatternExpr(
                                    getNodePatternExpr(""[A-Za-z]+""), 2, 2)),
                      getNodePatternExpr(""of""),
                      new SequencePattern.GroupPatternExpr(
                            new SequencePattern.RepeatPatternExpr(
                                    getNodePatternExpr(""[A-Za-z]+""), 1, 3, false))),
                    new SequencePattern.SequencePatternExpr(
                      new SequencePattern.GroupPatternExpr(
                        new SequencePattern.RepeatPatternExpr(
                            getNodePatternExpr("".*""), 0, -1)),
                      getNodePatternExpr(""Bishop""),
                      new SequencePattern.RepeatPatternExpr(
                            getNodePatternExpr("".*""), 0, -1, false)
                    )));

    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals(""first"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""as Bishop of London"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals(""as"", m.group(3));
    match = m.find();
    assertFalse(match);


    // Same as before, but compiled from string
    p = TokenSequencePattern.compile(
            ""(?: (/[A-Za-z]+/{2,2}) /of/ (/[A-Za-z]+/{1,3}?) ) & (?: (/.*/*) /Bishop/ /.*/*? )"");

    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals(""first"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""as Bishop of London"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    assertEquals(""as"", m.group(3));
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
97996,ReactiveX_RxJava,MergeTests.testMergeCovariance3,"    @Test
    public void testMergeCovariance3() {
        Observable<Movie> o1 = Observable.from(new HorrorMovie(), new Movie());
        Observable<Media> o2 = Observable.from(new Media(), new HorrorMovie());

        List<Media> values = Observable.merge(o1, o2).toList().toBlockingObservable().single();
        
        assertTrue(values.get(0) instanceof HorrorMovie);
        assertTrue(values.get(1) instanceof Movie);
        assertTrue(values.get(2) instanceof Media);
        assertTrue(values.get(3) instanceof HorrorMovie);
    }
",non-flaky,5
13843,neo4j_neo4j,ResourcePoolTest.shouldNotReuseBrokenInstances,"    @Test
    public void shouldNotReuseBrokenInstances() throws Exception
    {
        ResourcePool<Something> pool = new ResourcePool<Something>( 5 )
        {
            @Override
            protected Something create()
            {
                return new Something();
            }

            @Override
            protected boolean isAlive( Something resource )
            {
                return !resource.closed;
            }
        };

        Something somethingFirst = pool.acquire();
        somethingFirst.doStuff();
        pool.release();

        Something something = pool.acquire();
        assertEquals( somethingFirst, something );
        something.doStuff();
        something.close();
        pool.release();

        Something somethingElse = pool.acquire();
        assertFalse( something == somethingElse );
        somethingElse.doStuff();
    }
",non-flaky,5
30972,camunda-cloud_zeebe,POJOArrayTest.shouldIterateOverModifiedArray,"  @Test
  public void shouldIterateOverModifiedArray() {
    // given
    final POJOArray pojo = new POJOArray();
    final ValueArray<MinimalPOJO> array = pojo.simpleArray();

    // when
    array.add().setLongProp(123L);

    // then
    final Iterator<MinimalPOJO> iterator = array.iterator();
    assertThat(iterator.hasNext()).isTrue();
    assertThat(iterator.next().getLongProp()).isEqualTo(123L);
    assertThat(iterator.hasNext()).isFalse();
  }
",non-flaky,5
76769,quarkusio_quarkus,PackageIT.testLegacyJarHasValidCRC,"    @Test
    public void testLegacyJarHasValidCRC() throws Exception {
        testDir = initProject(""projects/uberjar-check"", ""projects/project-legacyjar-crc"");

        running = new RunningInvoker(testDir, false);
        final MavenProcessInvocationResult result = running.execute(Collections.singletonList(""package""),
                Collections.singletonMap(""QUARKUS_PACKAGE_TYPE"", ""legacy-jar""));

        assertThat(result.getProcess().waitFor()).isEqualTo(0);

        final File targetDir = getTargetDir();
        assertThat(getNumberOfFilesEndingWith(targetDir, "".jar"")).isEqualTo(2);

        final Path runnerJar = targetDir.toPath().resolve(""acme-1.0-SNAPSHOT-runner.jar"");
        Assertions.assertTrue(Files.exists(runnerJar), ""Runner jar "" + runnerJar + "" is missing"");
        assertZipEntriesCanBeOpenedAndClosed(runnerJar);
    }
",non-flaky,5
98054,vert-x3_vertx-mongo-client,GridFsTest.testDownloadStream,"  @Test
  public void testDownloadStream() {
    long fileLength = (1024 * 3) + 70;
    String fileName = createTempFileWithContent(fileLength);
    String downloadFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createDefaultGridFsBucketService(gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      Promise<AsyncFile> openPromise = Promise.promise();
      vertx.fileSystem().open(downloadFileName, new OpenOptions().setWrite(true), openPromise);
      return openPromise.future();
    }).compose(asyncFile -> {
      Promise<Long> downloadedPromise = Promise.promise();
      gridFsClient.get().downloadByFileName(asyncFile, fileName, downloadedPromise);
      return downloadedPromise.future();
    }).compose(length -> {
      assertTrue(fileLength == length);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();

  }
",non-flaky,5
20930,NationalSecurityAgency_timely,MetricTest.testJson,"    @Test
    public void testJson() throws IOException {
        ObjectMapper mapper = new ObjectMapper();

        String expectedJson = ""{\""name\"":\""m1\"",\""timestamp\"":1,\""measure\"":1.0,\""tags\"":[{\""k1\"":\""v1\""}]}"";

        Metric m1 = Metric.newBuilder().name(""m1"").tag(""k1"", ""v1"").value(1, 1.0).build();

        Metric expectedMetric = mapper.readValue(expectedJson, Metric.class);

        assertTrue(m1.equals(expectedMetric));

        expectedJson = ""{\""name\"":\""m1\"",\""tags\"":[{\""k1\"":\""v1\""}],\""timestamp\"":5,\""measure\"":5.0}"";
        expectedMetric = mapper.readValue(expectedJson, Metric.class);

        assertEquals((long) expectedMetric.getValue().getTimestamp(), 5L);
        assertEquals(expectedMetric.getValue().getMeasure(), 5.0D, 0.0);

    }
",non-flaky,5
91536,apache_kylin,SQLServerJdbcMetadataTest.testListDatabasesWithoutSpecificDB,"    @Test(expected = IllegalArgumentException.class)
    public void testListDatabasesWithoutSpecificDB() throws SQLException {
        when(connection.getCatalog()).thenReturn("""");
        jdbcMetadata.listDatabases();
    }
",non-flaky,5
96081,stanfordnlp_CoreNLP,CustomAnnotationSerializerITest.testSimple,"  @Test
  public void testSimple() throws IOException {
    Annotation annotation = new Annotation(""This is a test"");
    fullPipeline.annotate(annotation);
    runTest(annotation);
  }
",non-flaky,5
77536,dropwizard_dropwizard,ResourceTestRuleWithGrizzlyTest.testClientSupportsPatchMethod,"    @Test
    public void testClientSupportsPatchMethod() {
        final String resp = resourceTestRule.target(""test"")
            .request()
            .method(""PATCH"", Entity.text(""Patch is working""), String.class);
        assertThat(resp).isEqualTo(""Patch is working"");
    }
",non-flaky,5
136551,doanduyhai_Achilles,EntityMetaCodeGenTest.should_fail_building_class_with_wrong_clustering_column_order,"    @Test
    public void should_fail_building_class_with_wrong_clustering_column_order() throws Exception {
        setExec(aptUtils -> {
            final String className = TestEntityWithWrongClusteringColumns.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final List<FieldParser.FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, context);
            builder.buildEntityMeta(EntityType.TABLE, typeElement, context, parsingResults, emptyList());
        });
        failTestWithMessage(
                ""The @ClusteringColumn ordering is wrong in class 'info.archinnov.achilles.internals.sample_classes.parser.entity.TestEntityWithWrongClusteringColumns'"",
                TestEntityWithWrongClusteringColumns.class);
    }
",non-flaky,5
135069,undertow-io_undertow,CookiesTestCase.testParsingSetCookieHeaderV0,"    @Test
    public void testParsingSetCookieHeaderV0() {

        Cookie cookie = Cookies.parseSetCookieHeader(""CUSTOMER=WILE_E_COYOTE; path=/; expires=Wednesday, 09-Nov-99 23:12:40 GMT"");
        Assert.assertEquals(""CUSTOMER"", cookie.getName());
        Assert.assertEquals(""WILE_E_COYOTE"", cookie.getValue());
        Assert.assertEquals(""/"", cookie.getPath());
        Assert.assertEquals(date(1999, 11, 9, 23, 12, 40), cookie.getExpires());


        cookie = Cookies.parseSetCookieHeader(""SHIPPING=FEDEX; path=/foo; secure"");
        Assert.assertEquals(""SHIPPING"", cookie.getName());
        Assert.assertEquals(""FEDEX"", cookie.getValue());
        Assert.assertEquals(""/foo"", cookie.getPath());
        Assert.assertTrue(cookie.isSecure());

        cookie = Cookies.parseSetCookieHeader(""SHIPPING=FEDEX"");
        Assert.assertEquals(""SHIPPING"", cookie.getName());
        Assert.assertEquals(""FEDEX"", cookie.getValue());
    }
",non-flaky,5
30968,camunda-cloud_zeebe,POJOArrayTest.shouldFailOnInitialRemove,"  @Test
  public void shouldFailOnInitialRemove() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    pojo.wrap(buffer);
    final Iterator<MinimalPOJO> iterator = pojo.simpleArray().iterator();

    // then
    exception.expect(IllegalStateException.class);

    // when
    iterator.remove();
  }
",non-flaky,5
13883,neo4j_neo4j,StoreMigratorFrom19IT.shouldMigrate,"    @Test
    public void shouldMigrate() throws IOException, ConsistencyCheckIncompleteException
    {
        // GIVEN
        File legacyStoreDir = find19FormatHugeStoreDirectory( storeDir.directory() );

        // WHEN
        newStoreUpgrader().migrateIfNeeded( legacyStoreDir, schemaIndexProvider, pageCache );

        // THEN
        assertEquals( 100, monitor.eventSize() );
        assertTrue( monitor.isStarted() );
        assertTrue( monitor.isFinished() );

        GraphDatabaseService database = new GraphDatabaseFactory().newEmbeddedDatabase( storeDir.absolutePath() );

        try
        {
            verifyDatabaseContents( database );
        }
        finally
        {
            // CLEANUP
            database.shutdown();
        }

        try ( NeoStore neoStore = storeFactory.newNeoStore( true ) )
        {
            verifyNeoStore( neoStore );
        }

        assertConsistentStore( storeDir.directory() );
    }
",non-flaky,5
98240,apache_jackrabbit,PerformanceTest.testPerformance,"    @Test
    public void testPerformance() throws Exception {
        testPerformance(""2.6"");

        System.setProperty(QueryEngine.NATIVE_SORT_SYSTEM_PROPERTY, ""true"");
        testPerformance(""2.6-expSort"", getDefaultConfig());
        System.setProperty(QueryEngine.NATIVE_SORT_SYSTEM_PROPERTY, ""false"");
    }
",non-flaky,5
262,cdapio_cdap,WorkflowHttpHandlerTest.testWorkflowTokenPut,"@Test
public void testWorkflowTokenPut() throws Exception {
    Assert.assertEquals(200, deploy(WorkflowTokenTestPutApp.class).getStatusLine().getStatusCode());
    Id.Application appId = Id.Application.from(Id.Namespace.DEFAULT, WorkflowTokenTestPutApp.NAME);
    Id.Workflow workflowId = Id.Workflow.from(appId, WorkflowTokenTestPutApp.WorkflowTokenTestPut.NAME);
    Id.Program mapReduceId = Id.Program.from(appId, ProgramType.MAPREDUCE, WorkflowTokenTestPutApp.RecordCounter.NAME);
    Id.Program sparkId = Id.Program.from(appId, ProgramType.SPARK, WorkflowTokenTestPutApp.SparkTestApp.NAME);
    String outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
    startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""firstInput""),
    ""outputPath"", outputPath, ""put.in.mapper.initialize"", ""true""));
    waitState(workflowId, ProgramRunStatus.RUNNING.name());
    waitState(workflowId, ""STOPPED"");
    List<RunRecord> workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name());
    Assert.assertEquals(1, workflowProgramRuns.size());
    List<RunRecord> mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.FAILED.name());
    Assert.assertEquals(1, mapReduceProgramRuns.size());
    outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
    startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""secondInput""),
    ""outputPath"", outputPath, ""put.in.map"", ""true""));
    waitState(workflowId, ProgramRunStatus.RUNNING.name());
    waitState(workflowId, ""STOPPED"");
    workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name());
    Assert.assertEquals(2, workflowProgramRuns.size());
    mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.FAILED.name());
    Assert.assertEquals(2, mapReduceProgramRuns.size());
    outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
    startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""thirdInput""),
    ""outputPath"", outputPath, ""put.in.reducer.initialize"", ""true""));
    waitState(workflowId, ProgramRunStatus.RUNNING.name());
    waitState(workflowId, ""STOPPED"");
    workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name());
    Assert.assertEquals(3, workflowProgramRuns.size());
    mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.FAILED.name());
    Assert.assertEquals(3, mapReduceProgramRuns.size());
    outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
    startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""fourthInput""),
    ""outputPath"", outputPath, ""put.in.reduce"", ""true""));
    waitState(workflowId, ProgramRunStatus.RUNNING.name());
    waitState(workflowId, ""STOPPED"");
    workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name());
    Assert.assertEquals(4, workflowProgramRuns.size());
    mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.FAILED.name());
    Assert.assertEquals(4, mapReduceProgramRuns.size());
    outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
    startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""fifthInput""),
    ""outputPath"", outputPath, ""closurePutToken"", ""true""));
    waitState(workflowId, ProgramRunStatus.RUNNING.name());
    waitState(workflowId, ""STOPPED"");
    workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name());
    Assert.assertEquals(5, workflowProgramRuns.size());
    mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.COMPLETED.name());
    Assert.assertEquals(1, mapReduceProgramRuns.size());
    List<RunRecord> sparkProgramRuns = getProgramRuns(sparkId, ProgramRunStatus.FAILED.name());
    Assert.assertEquals(1, sparkProgramRuns.size());
    outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
    startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""sixthInput""),
    ""outputPath"", outputPath));
    waitState(workflowId, ProgramRunStatus.RUNNING.name());
    waitState(workflowId, ""STOPPED"");
    workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.COMPLETED.name());
    Assert.assertEquals(1, workflowProgramRuns.size());
    workflowProgramRuns = getProgramRuns(sparkId, ProgramRunStatus.COMPLETED.name());
    Assert.assertEquals(1, workflowProgramRuns.size());
}",async wait,0
13926,neo4j_neo4j,TestProver.aClusterSnapshotShouldEqualItsOrigin,"    @Test
    public void aClusterSnapshotShouldEqualItsOrigin() throws Exception
    {
        // Given
        Logging logging = new TestLogging();
        ClusterConfiguration config = new ClusterConfiguration( ""default"",
                logging.getMessagesLog( ClusterConfiguration.class ),
                ""cluster://localhost:5001"",
                ""cluster://localhost:5002"",
                ""cluster://localhost:5003"" );

        ClusterState state = new ClusterState(
                asList(
                        newClusterInstance( new InstanceId( 1 ), new URI( ""cluster://localhost:5001"" ),
                                new Monitors(), config, logging ),
                        newClusterInstance( new InstanceId( 2 ), new URI( ""cluster://localhost:5002"" ),
                                new Monitors(), config, logging ),
                        newClusterInstance( new InstanceId( 3 ), new URI( ""cluster://localhost:5003"" ),
                                new Monitors(), config, logging ) ),
                emptySetOf( ClusterAction.class )
        );

        // When
        ClusterState snapshot = state.snapshot();

        // Then
        assertEquals( state, snapshot );
        assertEquals( state.hashCode(), snapshot.hashCode() );
    }
",non-flaky,5
91378,OpenLCB_OpenLCB_Java,TractionThrottleTest.put,"    @Test
    public void testCTor() {
        NodeID nodeID = new NodeID(new byte[]{1,2,3,4,5,6});
        Connection testConnection = new AbstractConnection(){
            public void put(Message msg, Connection node) {
            }
",non-flaky,5
60866,apache_druid,RedisCacheConfigTest.testClusterInvalidNode,"  @Test
  public void testClusterInvalidNode() throws IOException
  {
    ObjectMapper mapper = new ObjectMapper();
    RedisCacheConfig fromJson = mapper.readValue(
        ""{\""expiration\"": 1000,""
        + ""\""cluster\"": {""
        + ""\""nodes\"": \""127.0.0.1\"""" //<===Invalid Node
        + ""}""
        + ""}"",
        RedisCacheConfig.class
    );

    expectedException.expect(new ExceptionMatcher(
        IAE.class,
        new StartWithMatcher(""Invalid redis cluster"")
    ));
    RedisCacheFactory.create(fromJson);
  }
",non-flaky,5
26240,Ericsson_ecchronos,TestTableRepairJob.testPostExecuteNotRepaired,"    @Test
    public void testPostExecuteNotRepaired()
    {
        // mock
        doReturn(true).when(myRepairStateSnapshot).canRepair();

        long lastRun = myRepairJob.getLastSuccessfulRun();

        myRepairJob.postExecute(true, null);

        assertThat(myRepairJob.getLastSuccessfulRun()).isEqualTo(lastRun);
        verify(myRepairState, times(1)).update();
    }
",non-flaky,5
159709,liquibase_liquibase,CDILiquibaseTest.shouldntRunWhenConfigShouldRunIsFalse,"    @Test
    public void shouldntRunWhenConfigShouldRunIsFalse() {
        System.setProperty(""liquibase.config.shouldRun"", ""false"");
        validateRunningState(false);
    }
",non-flaky,5
114073,aws_aws-sdk-java-v2,EnhancedTypeTest.navigableMapOf_ReturnsRawClassOfNavigableMap_WhenSpecifyingEnhancedType,"    @Test
    public void navigableMapOf_ReturnsRawClassOfNavigableMap_WhenSpecifyingEnhancedType() {
        EnhancedType<NavigableMap<String, Integer>> type =
            EnhancedType.navigableMapOf(EnhancedType.of(String.class), EnhancedType.of(Integer.class));

        assertThat(type.rawClass()).isEqualTo(NavigableMap.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class), EnhancedType.of(Integer.class));
    }
",non-flaky,5
176798,ctco_cukes,ContextCapturerTest.shouldCaptureValuesFromMinimalPattern,"    @Test
    public void shouldCaptureValuesFromMinimalPattern() throws Exception {
        capturer.captureValuesFromPattern(""(.*)"", Lists.newArrayList(""hello""), ""world"");
        verify(world).put(""hello"", ""world"");
    }
",non-flaky,5
42988,fabiomaffioletti_jsondoc,JSONDocApiMethodPathBuilderTest.apply,"	@Test
	public void testPathWithMethodDisplayURI() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(Controller.class), MethodDisplay.URI).iterator().next();

		boolean allRight = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
			@Override
			public boolean apply(ApiMethodDoc input) {
				return 
						input.getPath().contains(""/path1"") && 
						input.getPath().contains(""/path2"") && 
						input.getDisplayedMethodString().contains(""/path1"") &&
						input.getDisplayedMethodString().contains(""/path2"");
			}
",non-flaky,5
135066,undertow-io_undertow,URLUtilsTestCase.testIsAbsoluteUrlRecognizingRelativeUrls,"    @Test
    public void testIsAbsoluteUrlRecognizingRelativeUrls() {
        assertFalse(URLUtils.isAbsoluteUrl(""relative""));
        assertFalse(URLUtils.isAbsoluteUrl(""relative/path""));
        assertFalse(URLUtils.isAbsoluteUrl(""relative/path?query=val""));
        assertFalse(URLUtils.isAbsoluteUrl(""/root/relative/path""));
    }
",non-flaky,5
78317,apache_beam,ReduceFnRunnerTest.testOnElementBufferingDiscarding,"  @Test
  public void testOnElementBufferingDiscarding() throws Exception {
    // Test basic execution of a trigger using a non-combining window set and discarding mode.
    MetricsContainerImpl container = new MetricsContainerImpl(""any"");
    MetricsEnvironment.setCurrentContainer(container);
    ReduceFnTester<Integer, Iterable<Integer>, IntervalWindow> tester =
        ReduceFnTester.nonCombining(
            FixedWindows.of(Duration.millis(10)),
            mockTriggerStateMachine,
            AccumulationMode.DISCARDING_FIRED_PANES,
            Duration.millis(100),
            ClosingBehavior.FIRE_IF_NON_EMPTY);

    // Pane of {1, 2}
    injectElement(tester, 1);
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    injectElement(tester, 2);
    assertThat(
        tester.extractOutput(),
        contains(isSingleWindowedValue(containsInAnyOrder(1, 2), 1, 0, 10)));

    // Pane of just 3, and finish
    when(mockTriggerStateMachine.shouldFire(anyTriggerContext())).thenReturn(true);
    triggerShouldFinish(mockTriggerStateMachine);
    injectElement(tester, 3);
    assertThat(
        tester.extractOutput(), contains(isSingleWindowedValue(containsInAnyOrder(3), 3, 0, 10)));
    assertTrue(tester.isMarkedFinished(firstWindow));
    tester.assertHasOnlyGlobalAndFinishedSetsFor(firstWindow);

    // This element shouldn't be seen, because the trigger has finished
    injectElement(tester, 4);

    long droppedElements =
        container
            .getCounter(
                MetricName.named(ReduceFnRunner.class, ReduceFnRunner.DROPPED_DUE_TO_CLOSED_WINDOW))
            .getCumulative();
    assertEquals(1, droppedElements);
  }
",non-flaky,5
179465,abel533_Mapper,KeySqlTest.testUserSqlBefore,"    @Test
    public void testUserSqlBefore() {
        SqlSession sqlSession = getSqlSession();
        try {
            UserSqlBeforeMapper mapper = sqlSession.getMapper(UserSqlBeforeMapper.class);

            UserSqlBefore user = new UserSqlBefore();
            user.setName(""liuzh"");
            Assert.assertEquals(1, mapper.insert(user));
            Assert.assertEquals(new Integer(12345), user.getId());

            user = mapper.selectByPrimaryKey(12345);
            Assert.assertEquals(""liuzh"", user.getName());
        } finally {
            sqlSession.close();
        }
    }
",non-flaky,5
88865,apache_ignite,DatasetAffinityFunctionWrapperTest.testAssignPartitions,"    @Test
    public void testAssignPartitions() {
        List<List<ClusterNode>> nodes = Collections.singletonList(Collections.singletonList(mock(ClusterNode.class)));

        doReturn(nodes).when(affinityFunction).assignPartitions(any());

        List<List<ClusterNode>> resNodes = wrapper.assignPartitions(mock(AffinityFunctionContext.class));

        assertEquals(nodes, resNodes);
        verify(affinityFunction, times(1)).assignPartitions(any());
    }
",non-flaky,5
26234,Ericsson_ecchronos,TestTableRepairJob.testPrevalidateNeedRepair,"    @Test
    public void testPrevalidateNeedRepair()
    {
        // mock
        doReturn(true).when(myRepairStateSnapshot).canRepair();

        assertThat(myRepairJob.runnable()).isTrue();

        verify(myRepairState, times(1)).update();
        verify(myRepairStateSnapshot, times(1)).canRepair();
    }
",non-flaky,5
113890,spring-projects_spring-data-couchbase,ReactiveCouchbaseTemplateQueryCollectionIntegrationTests.existsByIdOptions,"	@Test
	public void existsByIdOptions() { // 1 - Options
		ExistsOptions options = ExistsOptions.existsOptions().timeout(Duration.ofNanos(10));
		assertThrows(UnambiguousTimeoutException.class, () -> template.existsById().inScope(otherScope)
				.inCollection(otherCollection).withOptions(options).one(vie.getId()).block());
	}
",non-flaky,5
78239,apache_beam,StateInternalsTest.testValue,"  @Test
  public void testValue() throws Exception {
    ValueState<String> value = underTest.state(NAMESPACE_1, STRING_VALUE_ADDR);

    // State instances are cached, but depend on the namespace.
    assertThat(underTest.state(NAMESPACE_1, STRING_VALUE_ADDR), equalTo(value));
    assertThat(underTest.state(NAMESPACE_2, STRING_VALUE_ADDR), not(equalTo(value)));

    assertThat(value.read(), Matchers.nullValue());
    value.write(""hello"");
    assertThat(value.read(), equalTo(""hello""));
    value.write(""world"");
    assertThat(value.read(), equalTo(""world""));

    value.clear();
    assertThat(value.read(), Matchers.nullValue());
    assertThat(underTest.state(NAMESPACE_1, STRING_VALUE_ADDR), equalTo(value));
  }
",non-flaky,5
159659,liquibase_liquibase,AbstractIntegrationTest.testDiffExternalForeignKeys,"   @Test
   public void testDiffExternalForeignKeys() throws Exception {
       assumeNotNull(this.getDatabase());
       clearDatabase();
       Liquibase liquibase = createLiquibase(externalfkInitChangeLog);
       liquibase.update(contexts);

       DiffResult diffResult = liquibase.diff(database, null, new CompareControl());
       DiffResultAssert.assertThat(diffResult).containsMissingForeignKeyWithName(""fk_person_country"");
   }
",non-flaky,5
104692,apache_pinot,ConvertToRawIndexMinionClusterIntegrationTest.testPinotHelixResourceManagerAPIs,"  @Test
  public void testPinotHelixResourceManagerAPIs() {
    // Instance APIs
    Assert.assertEquals(_helixResourceManager.getAllInstances().size(), 5);
    Assert.assertEquals(_helixResourceManager.getOnlineInstanceList().size(), 5);
    Assert.assertEquals(_helixResourceManager.getOnlineUnTaggedBrokerInstanceList().size(), 0);
    Assert.assertEquals(_helixResourceManager.getOnlineUnTaggedServerInstanceList().size(), 0);

    // Table APIs
    String rawTableName = getTableName();
    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(rawTableName);
    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(rawTableName);
    List<String> tableNames = _helixResourceManager.getAllTables();
    Assert.assertEquals(tableNames.size(), 2);
    Assert.assertTrue(tableNames.contains(offlineTableName));
    Assert.assertTrue(tableNames.contains(realtimeTableName));
    Assert.assertEquals(_helixResourceManager.getAllRawTables(), Collections.singletonList(rawTableName));
    Assert.assertEquals(_helixResourceManager.getAllRealtimeTables(), Collections.singletonList(realtimeTableName));

    // Tenant APIs
    Assert.assertEquals(_helixResourceManager.getAllBrokerTenantNames(), Collections.singleton(""TestTenant""));
    Assert.assertEquals(_helixResourceManager.getAllServerTenantNames(), Collections.singleton(""TestTenant""));
  }
",non-flaky,5
98061,vert-x3_vertx-mongo-client,GridFsTest.testFileDownloadById,"  @Test
  public void testFileDownloadById() {
    String fileName = createTempFileWithContent(1024);
    String asFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createGridFsBucketService(""fs"", gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      Promise<Long> downloadPromise = Promise.promise();
      gridFsClient.get().downloadFileByID(id, asFileName, downloadPromise);
      return downloadPromise.future();
    }).compose(length -> {
      assertEquals(1024L, length.longValue());
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
",non-flaky,5
20999,NationalSecurityAgency_timely,AggregationIteratorTest.simpleAggregatedSample,"    @Test
    public void simpleAggregatedSample() throws Exception {
        AggregationIterator iter = new AggregationIterator();
        Map<Set<Tag>, Aggregation> samples = runQuery(iter, testData2, 100);
        assertEquals(1, samples.size());
        for (Entry<Set<Tag>, Aggregation> entry : samples.entrySet()) {
            Set<Tag> tags = entry.getKey();
            assertEquals(1, tags.size());
            assertEquals(Collections.singleton(new Tag(""host"", "".*"")), tags);
            long ts = 0;
            int count = 0;
            for (Sample sample : entry.getValue()) {
                assertEquals(ts, sample.timestamp);
                ts += 100;
                assertEquals(count == 0 ? 0.2 : (count == 10 ? 0.5 : 0.35), sample.value, 0.0001);
                count++;
            }
            assertEquals(11, count);
        }
    }
",non-flaky,5
156163,soot-oss_soot,TypingMinimizeTest.testMostCommonTypingPairs_4,"  @Test
  public void testMostCommonTypingPairs_4() {

    List<Typing> typingList = new ArrayList<>();

    Type Type1 = cloneableType;
    Type Type2 = serializableType;
    Type Type3 = abstractMapType;

    Local x1 = new JimpleLocal(""$x1"", null);

    Typing typing1 = new Typing(Arrays.asList(x1));
    typing1.set(x1, Type1);
    typingList.add(typing1);

    Typing typing2 = new Typing(Arrays.asList(x1));
    typing2.set(x1, Type2);
    typingList.add(typing2);

    Typing typing3 = new Typing(Arrays.asList(x1));
    typing3.set(x1, Type3);
    typingList.add(typing3);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(3, typingList.size());

  }
",non-flaky,5
110842,pushtorefresh_storio,GetListOfObjectsObserveChangesTest.repeatsOperationWithQueryByChangeOfTag,"    @Test
    public void repeatsOperationWithQueryByChangeOfTag() {
        User user = putUserBlocking();

        PreparedGetListOfObjects<User> operation = storIOSQLite
                .get()
                .listOfObjects(User.class)
                .withQuery(query)
                .prepare();

        verifyChangesReceived(operation, tagChanges, singletonList(user));
    }
",non-flaky,5
96075,stanfordnlp_CoreNLP,RequirementsCorrectSlowITest.testTrueCasePipeline,"   @Test
   public void testTrueCasePipeline() {
     testAnnotatorSequence(Arrays.asList(""tokenize"",""ssplit"",""pos"",""lemma"",""truecase""));
   }
",non-flaky,5
135738,Netflix_Hystrix,HystrixCommandTestWithCustomConcurrencyStrategy.testCommandDoesNotRequireContextConcurrencyStrategyDoesNotProvideItContextSetUpCorrectly,"    @Test
    public void testCommandDoesNotRequireContextConcurrencyStrategyDoesNotProvideItContextSetUpCorrectly() {
        HystrixConcurrencyStrategy strategy = new CustomConcurrencyStrategy(false);
        HystrixPlugins.getInstance().registerConcurrencyStrategy(strategy);

        //context is set up properly
        HystrixRequestContext context = HystrixRequestContext.initializeContext();
        HystrixCommand<Boolean> cmd = new TestCommand(true, true);
        assertTrue(cmd.execute());
        printRequestLog();
        assertNull(HystrixRequestLog.getCurrentRequest());
        assertNull(HystrixRequestLog.getCurrentRequest(strategy));
        assertNull(cmd.currentRequestLog);
        context.shutdown();
    }
",non-flaky,5
356,apache_hadoop,TestNetworkTopology.testInvalidNetworkTopologiesNotCachedInHdfs,"  @Test(timeout=180000)
  public void testInvalidNetworkTopologiesNotCachedInHdfs() throws Exception {
    // start a cluster
    Configuration conf = new HdfsConfiguration();
    MiniDFSCluster cluster = null;
    try {
      // bad rack topology
      String racks[] = { ""/a/b"", ""/c"" };
      String hosts[] = { ""foo1.example.com"", ""foo2.example.com"" };
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).
          racks(racks).hosts(hosts).build();
      cluster.waitActive();
      
      NamenodeProtocols nn = cluster.getNameNodeRpc();
      Assert.assertNotNull(nn);
      
      // Wait for one DataNode to register.
      // The other DataNode will not be able to register up because of the rack mismatch.
      DatanodeInfo[] info;
      while (true) {
        info = nn.getDatanodeReport(DatanodeReportType.LIVE);
        Assert.assertFalse(info.length == 2);
        if (info.length == 1) {
          break;
        }
        Thread.sleep(1000);
      }
      // Set the network topology of the other node to the match the network
      // topology of the node that came up.
      int validIdx = info[0].getHostName().equals(hosts[0]) ? 0 : 1;
      int invalidIdx = validIdx == 1 ? 0 : 1;
      StaticMapping.addNodeToRack(hosts[invalidIdx], racks[validIdx]);
      LOG.info(""datanode "" + validIdx + "" came up with network location "" + 
        info[0].getNetworkLocation());

      // Restart the DN with the invalid topology and wait for it to register.
      cluster.restartDataNode(invalidIdx);
      Thread.sleep(5000);
      while (true) {
        info = nn.getDatanodeReport(DatanodeReportType.LIVE);
        if (info.length == 2) {
          break;
        }
        if (info.length == 0) {
          LOG.info(""got no valid DNs"");
        } else if (info.length == 1) {
          LOG.info(""got one valid DN: "" + info[0].getHostName() +
              "" (at "" + info[0].getNetworkLocation() + "")"");
        }
        Thread.sleep(1000);
      }
      Assert.assertEquals(info[0].getNetworkLocation(),
                          info[1].getNetworkLocation());
    } finally {
      if (cluster != null) {
        cluster.shutdown();
      }
    }
  }
",non-flaky,5
13832,neo4j_neo4j,LoggingResourcePoolMonitorTest.testUpdatedCurrentPeakSizeLogsOnlyOnChange,"    @Test
    public void testUpdatedCurrentPeakSizeLogsOnlyOnChange() throws Exception
    {
        StringLogger logger = mock( StringLogger.class );
        LoggingResourcePoolMonitor monitor = new LoggingResourcePoolMonitor( logger );

        monitor.updatedCurrentPeakSize( 10 );
        verify( logger, times( 1 ) ).debug( anyString() );

        monitor.updatedCurrentPeakSize( 10 );
        verify( logger, times( 1 ) ).debug( anyString() );

        monitor.updatedCurrentPeakSize( 11 );
        verify( logger, times( 2 ) ).debug( anyString() );
    }
",non-flaky,5
13837,neo4j_neo4j,TransactionCommittingResponseUnpackerTest.testStopShouldAllowTransactionsToCompleteCommitAndApply,"    @Test
    public void testStopShouldAllowTransactionsToCompleteCommitAndApply() throws Throwable
    {
        // Given

        // Handcrafted deep mocks, otherwise the dependency resolution throws ClassCastExceptions
        DependencyResolver dependencyResolver = mock( DependencyResolver.class );
        TransactionIdStore txIdStore = mock( TransactionIdStore.class );

        when( dependencyResolver.resolveDependency( TransactionIdStore.class ) ).thenReturn( txIdStore );

        TransactionAppender appender = mockedTransactionAppender();
        LogicalTransactionStore logicalTransactionStore = mock( LogicalTransactionStore.class );
        when( logicalTransactionStore.getAppender() ).thenReturn( appender );
        when( dependencyResolver.resolveDependency( LogicalTransactionStore.class ) )
                .thenReturn( logicalTransactionStore );

        when( dependencyResolver.resolveDependency( TransactionRepresentationStoreApplier.class ) )
                .thenReturn( mock( TransactionRepresentationStoreApplier.class ) );
        LogFile logFile = mock( LogFile.class );
        when( dependencyResolver.resolveDependency( LogFile.class ) ).thenReturn( logFile );
        LogRotation logRotation = mock(LogRotation.class);
        when( dependencyResolver.resolveDependency( LogRotation.class ) ).thenReturn( logRotation );

        setUpIndexUpdatesValidatorMocking( dependencyResolver );

          /*
           * The tx handler is called on every transaction applied after setting its id to committing
           * but before setting it to applied. We use this to stop the unpacker in the middle of the
           * process.
           */
        StoppingTxHandler stoppingTxHandler = new StoppingTxHandler();

        int maxBatchSize = 10;
        TransactionCommittingResponseUnpacker unpacker = new TransactionCommittingResponseUnpacker(
                dependencyResolver, maxBatchSize );
        stoppingTxHandler.setUnpacker( unpacker );

        // When
        unpacker.start();
        long committingTransactionId = BASE_TX_ID + 1;
        DummyTransactionResponse response = new DummyTransactionResponse( committingTransactionId, 1, appender, maxBatchSize );
        unpacker.unpackResponse( response, stoppingTxHandler );

        // Then
        // we can't verify transactionCommitted since that's part of the TransactionAppender, which we have mocked
        verify( txIdStore, times( 1 ) ).transactionClosed( committingTransactionId );
        verify( appender, times( 1 ) ).append( any( TransactionRepresentation.class ), anyLong() );
        verify( appender, times( 1 ) ).force();
        verify( logRotation, times( 1 ) ).rotateLogIfNeeded( logAppendEvent );

        // Then
          // The txhandler has stopped the unpacker. It should not allow any more transactions to go through
        try
        {
            unpacker.unpackResponse( mock( Response.class ), stoppingTxHandler );
            fail( ""A stopped transaction unpacker should not allow transactions to be applied"" );
        }
        catch( IllegalStateException e)
        {
            // good
        }
        verifyNoMoreInteractions( txIdStore );
        verifyNoMoreInteractions( appender );
    }
",non-flaky,5
113922,spring-projects_spring-data-couchbase,CouchbaseTemplateQueryCollectionIntegrationTests.upsertByIdOther,"	@Test
	public void upsertByIdOther() { // 10
		UpsertOptions options = UpsertOptions.upsertOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));

		Airport saved = couchbaseTemplate.upsertById(Airport.class).inScope(otherScope).inCollection(otherCollection)
				.withOptions(options).one(vie);
		try {
			Airport found = couchbaseTemplate.findById(Airport.class).inScope(otherScope).inCollection(otherCollection)
					.withOptions(getOptions).one(saved.getId());
			assertEquals(saved, found);
		} finally {
			couchbaseTemplate.removeById().inScope(otherScope).inCollection(otherCollection).one(saved.getId());
		}
	}
",non-flaky,5
76765,quarkusio_quarkus,PackageIT.testDependencyOnPomMutableJar,"    @Test
    public void testDependencyOnPomMutableJar()
            throws MavenInvocationException, IOException, InterruptedException {
        testDir = initProject(""projects/dependency-on-pom"");

        running = new RunningInvoker(testDir, false);
        // we do want to run the tests too
        final MavenProcessInvocationResult result = running.execute(Collections.singletonList(""package""),
                Collections.emptyMap());

        assertThat(result.getProcess().waitFor()).isEqualTo(0);

        File targetDir = getTargetDir();
        List<File> jars = getFilesEndingWith(targetDir, "".jar"");
        assertThat(jars).hasSize(1);
    }
",non-flaky,5
38259,palantir_atlasdb,AbstractSerializableTransactionTest.call,"    @Test(expected=TransactionFailedRetriableException.class)
    public void testConcurrentWriteSkew() throws InterruptedException, BrokenBarrierException {
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", ""100"");
        put(t0, ""row2"", ""col1"", ""100"");
        t0.commit();

        final CyclicBarrier barrier = new CyclicBarrier(2);

        final Transaction t1 = startTransaction();
        ExecutorService exec = PTExecutors.newCachedThreadPool();
        Future<?> f = exec.submit( new Callable<Void>() {
            @Override
            public Void call() throws Exception {
                withdrawMoney(t1, true, false);
                barrier.await();
                t1.commit();
                return null;
            }
",non-flaky,5
160332,triplea-game_triplea,AbstractPropertyReaderTestCase.shouldReturnDefaultValueWhenKeyIsAbsent,"    @Test
    public void shouldReturnDefaultValueWhenKeyIsAbsent() throws Exception {
      final int defaultValue = 777;
      final PropertyReader propertyReader = newEmptyPropertyReader();

      assertThat(
          propertyReader.readIntegerPropertyOrDefault(ABSENT_PROPERTY_KEY, defaultValue),
          is(defaultValue));
    }
",non-flaky,5
110164,Wikidata_wikidata-toolkit,DirectoryManagerTest.NoCreateFileStringReadOnly,"	@Test(expected = IOException.class)
	public void NoCreateFileStringReadOnly() throws IOException {
		dm.createFile(""new-test-file.txt"", ""new contents"");
	}
",non-flaky,5
35662,cdapio_cdap,Spark2Test.testScalaSparkWithObjectStore,"  @Test
  public void testScalaSparkWithObjectStore() throws Exception {
    ApplicationManager applicationManager = deploy(NamespaceId.DEFAULT, SparkAppUsingObjectStore.class);

    DataSetManager<ObjectStore<String>> keysManager = getDataset(""keys"");
    prepareInputData(keysManager);

    SparkManager sparkManager = applicationManager.getSparkManager(ScalaCharCountProgram.class.getSimpleName()).start();
    sparkManager.waitForRun(ProgramRunStatus.RUNNING, 10, TimeUnit.SECONDS);
    sparkManager.waitForStopped(60, TimeUnit.SECONDS);

    DataSetManager<KeyValueTable> countManager = getDataset(""count"");
    checkOutputData(countManager);
  }
",non-flaky,5
91451,strapdata_elassandra,RecoveryDuringReplicationTests.testResyncAfterPrimaryPromotion,"    @TestLogging(""org.elasticsearch.index.shard:TRACE,org.elasticsearch.action.resync:TRACE"")
    public void testResyncAfterPrimaryPromotion() throws Exception {
        // TODO: check translog trimming functionality once rollback is implemented in Lucene (ES trimming is done)
        Map<String, String> mappings =
            Collections.singletonMap(""type"", ""{ \""type\"": { \""properties\"": { \""f\"": { \""type\"": \""keyword\""} }}}"");
        try (ReplicationGroup shards = new ReplicationGroup(buildIndexMetaData(2, mappings))) {
            shards.startAll();
            int initialDocs = randomInt(10);

            for (int i = 0; i < initialDocs; i++) {
                final IndexRequest indexRequest = new IndexRequest(index.getName(), ""type"", ""initial_doc_"" + i)
                    .source(""{ \""f\"": \""normal\""}"", XContentType.JSON);
                shards.index(indexRequest);
            }

            boolean syncedGlobalCheckPoint = randomBoolean();
            if (syncedGlobalCheckPoint) {
                shards.syncGlobalCheckpoint();
            }

            final IndexShard oldPrimary = shards.getPrimary();
            final IndexShard newPrimary = shards.getReplicas().get(0);
            final IndexShard justReplica = shards.getReplicas().get(1);

            // simulate docs that were inflight when primary failed
            final int extraDocs = randomInt(5);
            logger.info(""--> indexing {} extra docs"", extraDocs);
            for (int i = 0; i < extraDocs; i++) {
                final IndexRequest indexRequest = new IndexRequest(index.getName(), ""type"", ""extra_doc_"" + i)
                    .source(""{ \""f\"": \""normal\""}"", XContentType.JSON);
                final BulkShardRequest bulkShardRequest = indexOnPrimary(indexRequest, oldPrimary);
                indexOnReplica(bulkShardRequest, shards, newPrimary);
            }

            final int extraDocsToBeTrimmed = randomIntBetween(0, 10);
            logger.info(""--> indexing {} extra docs to be trimmed"", extraDocsToBeTrimmed);
            for (int i = 0; i < extraDocsToBeTrimmed; i++) {
                final IndexRequest indexRequest = new IndexRequest(index.getName(), ""type"", ""extra_trimmed_"" + i)
                    .source(""{ \""f\"": \""trimmed\""}"", XContentType.JSON);
                final BulkShardRequest bulkShardRequest = indexOnPrimary(indexRequest, oldPrimary);
                // have to replicate to another replica != newPrimary one - the subject to trim
                indexOnReplica(bulkShardRequest, shards, justReplica);
            }

            logger.info(""--> resyncing replicas seqno_stats primary {} replica {}"", oldPrimary.seqNoStats(), newPrimary.seqNoStats());
            PrimaryReplicaSyncer.ResyncTask task = shards.promoteReplicaToPrimary(newPrimary).get();
            if (syncedGlobalCheckPoint) {
                assertEquals(extraDocs, task.getResyncedOperations());
            } else {
                assertThat(task.getResyncedOperations(), greaterThanOrEqualTo(extraDocs));
            }
            shards.assertAllEqual(initialDocs + extraDocs);
            for (IndexShard replica : shards.getReplicas()) {
                assertThat(replica.getMaxSeqNoOfUpdatesOrDeletes(),
                    greaterThanOrEqualTo(shards.getPrimary().getMaxSeqNoOfUpdatesOrDeletes()));
            }

            // check translog on replica is trimmed
            int translogOperations = 0;
            try(Translog.Snapshot snapshot = getTranslog(justReplica).newSnapshot()) {
                Translog.Operation next;
                while ((next = snapshot.next()) != null) {
                    translogOperations++;
                    assertThat(""unexpected op: "" + next, (int)next.seqNo(), lessThan(initialDocs + extraDocs));
                    assertThat(""unexpected primaryTerm: "" + next.primaryTerm(), next.primaryTerm(),
                        is(oldPrimary.getPendingPrimaryTerm()));
                    final Translog.Source source = next.getSource();
                    assertThat(source.source.utf8ToString(), is(""{ \""f\"": \""normal\""}""));
                }
            }
            assertThat(translogOperations, is(initialDocs + extraDocs));
        }
    }
",non-flaky,5
98015,vert-x3_vertx-mongo-client,MongoClientWithObjectIdTest.testInsertPreexistingID,"  @Test
  public void testInsertPreexistingID() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject doc = createDoc();
      //Changed to hex string as a random string will not be valid for useObjectId = true
      doc.put(""_id"", new ObjectId().toHexString());
      mongoClient.insert(collection, doc, onSuccess(id -> {
        assertNull(id);
        testComplete();
      }));
    }));
    await();
  }
",non-flaky,5
136528,doanduyhai_Achilles,EntityMetaCodeGenTest.should_build_entity_with_simple_partition_key,"    @Test
    public void should_build_entity_with_simple_partition_key() throws Exception {
        setExec(aptUtils -> {
            final String className = TestEntityWithSimplePartitionKey.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final List<FieldParser.FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, context);
            final TypeSpec typeSpec = builder.buildEntityMeta(EntityType.TABLE, typeElement, context, parsingResults, emptyList()).sourceCode;

            assertThat(buildSource(typeSpec)).isEqualTo(
                    readCodeBlockFromFile(""expected_code/entity_meta_builder/should_build_entity_with_simple_partition_key.txt""));
        });
        launchTest(TestEntityWithSimplePartitionKey.class);
    }
",non-flaky,5
99707,apache_cassandra,DistributionGaussianTest.negValueGaussian,"    @Test
    public void negValueGaussian()
    {
        Distribution dist = OptionDistribution.get(""gaussian(-1000..-10)"").get();
        assertTrue(dist instanceof DistributionBoundApache);

        assertEquals(-1000, dist.minValue());
        assertEquals( -10, dist.maxValue());
        assertEquals(-504, dist.average());

        assertEquals(-1000, dist.inverseCumProb(0d));
        assertEquals(-10, dist.inverseCumProb(1d));
    }
",non-flaky,5
160372,ConsenSys_teku,MinimalSigningHistoryTest.shouldReadMetadataFromMinimalJson,"  @Test
  public void shouldReadMetadataFromMinimalJson() throws IOException {
    final String minimalJson =
        Resources.toString(Resources.getResource(""format2_minimal.json""), StandardCharsets.UTF_8);

    JsonNode jsonNode = mapper.readTree(minimalJson);
    JsonNode metadataJson = jsonNode.get(""metadata"");
    Metadata metadata = mapper.treeToValue(metadataJson, Metadata.class);
    assertThat(metadata).isEqualTo(new Metadata(INTERCHANGE_VERSION, GENESIS_ROOT));

    List<SigningHistory> minimalSigningHistoryList =
        Arrays.asList(mapper.readValue(jsonNode.get(""data"").toString(), SigningHistory[].class));

    SigningHistory element =
        new SigningHistory(
            blsPubKey,
            new ValidatorSigningRecord(
                GENESIS_ROOT, UInt64.valueOf(81952), UInt64.valueOf(2290), UInt64.valueOf(3007)));
    assertThat(minimalSigningHistoryList).containsExactly(element);
  }
",non-flaky,5
177987,aosp-mirror_platform_frameworks_support,CustomTabsIntentTest.testToolbarColorIsNotAResource,"    @Test
    public void testToolbarColorIsNotAResource() {
        @ColorRes int colorId = android.R.color.background_dark;
        int color = InstrumentationRegistry.getContext().getResources().getColor(colorId);
        Intent intent = new CustomTabsIntent.Builder().setToolbarColor(colorId).build().intent;
        assertFalse(""The color should not be a resource ID"",
                color == intent.getIntExtra(CustomTabsIntent.EXTRA_TOOLBAR_COLOR, 0));
        intent = new CustomTabsIntent.Builder().setToolbarColor(color).build().intent;
        assertEquals(color, intent.getIntExtra(CustomTabsIntent.EXTRA_TOOLBAR_COLOR, 0));
    }
",non-flaky,5
98014,vert-x3_vertx-mongo-client,MongoClientWithObjectIdTest.testInsertPreexistingObjectID,"  @Test
  public void testInsertPreexistingObjectID() throws Exception {
    String collection = randomCollection();
    mongoClient.createCollection(collection, onSuccess(res -> {
      JsonObject doc = createDoc();
      //Changed to hex string as a random string will not be valid for useObjectId = true
      doc.put(""_id"", new ObjectId().toHexString());
      mongoClient.insertWithOptions(collection, doc, ACKNOWLEDGED, onSuccess(id -> {
        assertNull(id);
        testComplete();
      }));
    }));
    await();
  }
",non-flaky,5
38223,palantir_atlasdb,TextUtilsTest.testPropertiesToXML,"    @Test
    public void testPropertiesToXML()
    {
        // simple string kv pair
        Properties p = new Properties();
        p.setProperty(""MY_CONFIG_KEY"", ""MY_CONFIG_VALUE"");
        String propertiesAsXML = TextUtils.storePropertiesToXMLString(p);
        assertNotNull(propertiesAsXML);
        p = TextUtils.loadPropertiesFromXMLString(propertiesAsXML);
        assertNotNull(p.getProperty(""MY_CONFIG_KEY""));
        assertEquals(""MY_CONFIG_VALUE"", p.getProperty(""MY_CONFIG_KEY""));

        // embedded config
        Properties pComplex = new Properties();
        pComplex.setProperty(""MY_SUB_CONFIG"", TextUtils.storePropertiesToXMLString(p));
        propertiesAsXML = TextUtils.storePropertiesToXMLString(pComplex);
        assertNotNull(propertiesAsXML);
        pComplex = TextUtils.loadPropertiesFromXMLString(propertiesAsXML);
        p = TextUtils.loadPropertiesFromXMLString(pComplex.getProperty(""MY_SUB_CONFIG""));
        assertNotNull(p.getProperty(""MY_CONFIG_KEY""));
        assertEquals(""MY_CONFIG_VALUE"", p.getProperty(""MY_CONFIG_KEY""));
    }
",non-flaky,5
99753,apache_cassandra,AsyncStreamingInputPlusTest.available_ClosedButWithBytes,"    @Test
    public void available_ClosedButWithBytes()
    {
        inputPlus = new AsyncStreamingInputPlus(channel);
        int size = 4;
        buf = channel.alloc().heapBuffer(size);
        buf.writerIndex(size);
        inputPlus.append(buf);
        inputPlus.requestClosure();
        Assert.assertEquals(size, inputPlus.unsafeAvailable());
    }
",non-flaky,5
177215,line_armeria,HttpDecodedResponseTest.onSubscribe,"    @Test
            public void onSubscribe(Subscription s) {
                s.request(Long.MAX_VALUE);
            }
",non-flaky,5
99733,apache_cassandra,FQLReplayTest.testResultHandlerMultipleResultSets,"    @Test
    public void testResultHandlerMultipleResultSets() throws IOException
    {
        List<String> targetHosts = Lists.newArrayList(""hosta"", ""hostb"", ""hostc"");
        File tmpDir = Files.createTempDirectory(""testresulthandler"").toFile();
        File queryDir = Files.createTempDirectory(""queries"").toFile();
        List<File> resultPaths = new ArrayList<>();
        targetHosts.forEach(host -> { File f = new File(tmpDir, host); f.mkdir(); resultPaths.add(f);});
        List<Pair<FQLQuery, List<ResultHandler.ComparableResultSet>>> resultSets = new ArrayList<>();
        Random random = new Random();
        for (int i = 0; i < 10; i++)
        {
            List<ResultHandler.ComparableResultSet> results = new ArrayList<>();
            List<ByteBuffer> values = Collections.singletonList(ByteBufferUtil.bytes(i * 50));
            for (int jj = 0; jj < targetHosts.size(); jj++)
            {
                results.add(createResultSet(5, 1 + random.nextInt(10), true));
            }
            FQLQuery q = i % 2 == 0
                         ? new FQLQuery.Single(""abc""+i,
                                             3,
                                             QueryOptions.forInternalCalls(values),
                                             i * 1000,
                                             12345,
                                             54321,
                                             ""select * from xyz where id = ""+i,
                                             values)
                         : new FQLQuery.Batch(""abc""+i,
                                              3,
                                              QueryOptions.forInternalCalls(values),
                                              i * 1000,
                                              i * 54321,
                                              i * 12345,
                                              com.datastax.driver.core.BatchStatement.Type.UNLOGGED,
                                              Lists.newArrayList(""select * from aaaa""),
                                              Collections.singletonList(values));

            resultSets.add(Pair.create(q, results));
        }
        try (ResultHandler rh = new ResultHandler(targetHosts, resultPaths, queryDir))
        {
            for (int i = 0; i < resultSets.size(); i++)
                rh.handleResults(resultSets.get(i).left, resultSets.get(i).right);
        }

        for (int i = 0; i < targetHosts.size(); i++)
            compareWithFile(resultPaths, queryDir, resultSets, i);
    }
",non-flaky,5
170455,eclipse_jetty.project,ObjectMBeanTest.testMBeanForString,"    @Test
    public void testMBeanForString()
    {
        String obj = ""foo"";
        Object mbean = container.mbeanFor(obj);
        assertNotNull(mbean);
        container.beanAdded(null, obj);
        ObjectName objectName = container.findMBean(obj);
        assertNotNull(objectName);
    }
",non-flaky,5
13879,neo4j_neo4j,ProtocolTest.shouldSerializeAndDeserializeTransactionRepresentation,"    @Test
    public void shouldSerializeAndDeserializeTransactionRepresentation() throws Exception
    {
        // GIVEN
        PhysicalTransactionRepresentation transaction = new PhysicalTransactionRepresentation( justOneNode() );
        byte[] additionalHeader = ""extra"".getBytes();
        int masterId = 1, authorId = 2;
        long timeStarted = 12345, lastTxWhenStarted = 12, timeCommitted = timeStarted+10;
        transaction.setHeader( additionalHeader, masterId, authorId, timeStarted, lastTxWhenStarted, timeCommitted, -1 );
        Protocol.TransactionSerializer serializer = new Protocol.TransactionSerializer( transaction );
        ChannelBuffer buffer = new ChannelBufferWrapper( new InMemoryLogChannel() );

        // WHEN serializing the transaction
        serializer.write( buffer );

        // THEN deserializing the same transaction should yield the same data.
        // ... remember that this deserializer doesn't read the data source name string. Read it manually here
        assertEquals( NeoStoreDataSource.DEFAULT_DATA_SOURCE_NAME, Protocol.readString( buffer ) );
        TransactionRepresentation readTransaction = Protocol.TRANSACTION_REPRESENTATION_DESERIALIZER.read(
                buffer, ByteBuffer.allocate( 1000 ) );
        assertArrayEquals( additionalHeader, readTransaction.additionalHeader() );
        assertEquals( masterId, readTransaction.getMasterId() );
        assertEquals( authorId, readTransaction.getAuthorId() );
        assertEquals( timeStarted, readTransaction.getTimeStarted() );
        assertEquals( lastTxWhenStarted, readTransaction.getLatestCommittedTxWhenStarted() );
        assertEquals( timeCommitted, readTransaction.getTimeCommitted() );
    }
",non-flaky,5
150196,apache_hive,TestHplsqlLocal.testValuesInto,"  @Test
  public void testValuesInto() throws Exception {
    run(""values_into"");
  }
",non-flaky,5
96954,apache_avro,TestAvroSerialization.testAccept,"  @Test
  public void testAccept() {
    AvroSerialization<CharSequence> serialization = new AvroSerialization<>();

    assertTrue(serialization.accept(AvroKey.class));
    assertTrue(serialization.accept(AvroValue.class));
    assertFalse(serialization.accept(AvroWrapper.class));
    assertFalse(serialization.accept(String.class));
  }
",non-flaky,5
237,undertow-io_undertow,d0efffad5d2034bb07525cac9b299dac72c3045d.testCloseReason,"@Test
public void testCloseReason() throws Exception {
    MessageEndpoint.reset();
    Session session = deployment.connectToServer(AnnotatedClientEndpoint.class, new URI(""ws://"" + DefaultServer.getHostAddress(""default"") + "":"" + DefaultServer.getHostPort(""default"") + ""/ws/chat/Bob""));
    Assert.assertEquals(""hi Bob (protocol=foo)"", AnnotatedClientEndpoint.message());
    session.close(new CloseReason(CloseReason.CloseCodes.VIOLATED_POLICY, ""Foo!""));
    Assert.assertEquals(""CLOSED"", AnnotatedClientEndpoint.message());
    CloseReason cr = MessageEndpoint.getReason();
    Assert.assertEquals(CloseReason.CloseCodes.VIOLATED_POLICY.getCode(), cr.getCloseCode().getCode());
    Assert.assertEquals(""Foo!"", cr.getReasonPhrase());
}",test order dependency,4
96888,apache_avro,TestSchemas.testVisit1,"  @Test
  public void testVisit1() {
    String s1 = ""{\""type\"": \""record\"", \""name\"": \""t1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": \""int\""}"" +
        ""]}"";
    Assert.assertEquals(""t1."", Schemas.visit(new Schema.Parser().parse(s1), new TestVisitor()));
  }
",non-flaky,5
136496,doanduyhai_Achilles,LowerCaseNamingTest.should_return_blank_name_on_null,"    @Test
    public void should_return_blank_name_on_null() throws Exception {
        //Given
        String name = null;

        //When
        final String actual = strategy.apply(name);

        //Then
        assertThat(actual).isEmpty();
    }
",non-flaky,5
96860,apache_avro,TestSpecificCompiler.testCanReadTemplateFilesOnTheFilesystem,"  @Test
  public void testCanReadTemplateFilesOnTheFilesystem() throws IOException {
    SpecificCompiler compiler = createCompiler();
    compiler.compileToDestination(this.src, OUTPUT_DIR.getRoot());
    assertTrue(new File(OUTPUT_DIR.getRoot(),""SimpleRecord.java"").exists());
  }
",non-flaky,5
160413,ConsenSys_teku,ChainDataProviderTest.getStateSyncCommittees_shouldRejectFarFutureEpoch,"  @Test
  public void getStateSyncCommittees_shouldRejectFarFutureEpoch() {
    final ChainDataProvider provider = setupAltairState();
    final SafeFuture<Optional<StateSyncCommittees>> future =
        provider.getStateSyncCommittees(""head"", Optional.of(UInt64.valueOf(""1024000"")));
    SafeFutureAssert.assertThatSafeFuture(future)
        .isCompletedExceptionallyWith(IllegalArgumentException.class);
  }
",non-flaky,5
76721,quarkusio_quarkus,QuarkusCodestartBuildIT.testRunAloneCodestartsKotlin,"    @ParameterizedTest
    public void testRunAloneCodestartsKotlin(String codestart) throws Exception {
        generateProjectRunTests(""maven"", ""kotlin"", singletonList(codestart));
    }
",non-flaky,5
159612,liquibase_liquibase,MavenIntegrationTest.nothing,"    @Test
    public void nothing() {
        //tests fail when not running a maven based build. need to figure out how to determine that
    }
",non-flaky,5
104184,spring-cloud_spring-cloud-config,GitSkipSslValidationCredentialsProviderTest.testIsInteractiveWithDelegate,"	@Test
	public void testIsInteractiveWithDelegate() {
		this.skipSslValidationCredentialsProvider = new GitSkipSslValidationCredentialsProvider(
				this.mockDelegateCredentialsProvider);

		when(this.mockDelegateCredentialsProvider.isInteractive()).thenReturn(true);

		assertThat(this.skipSslValidationCredentialsProvider.isInteractive()).as(
				""With a delegate provider, isInteractive value depends on the delegate"")
				.isTrue();
	}
",non-flaky,5
20934,NationalSecurityAgency_timely,SerializationTest.testAddSubscription,"    @Test
    public void testAddSubscription() throws Exception {
        AddSubscription add = new AddSubscription();
        add.setSubscriptionId(""1234"");
        add.setMetric(""sys.cpu.user"");
        testSerialization(add);
    }
",non-flaky,5
135049,undertow-io_undertow,NetworkUtilsAddressParsingTestCase.testIpV6AddressToSmall,"    @Test(expected = IOException.class)
    public void testIpV6AddressToSmall() throws IOException {
        NetworkUtils.parseIpv6Address(""2001:1db8:3:6:ff00:42:8329"");
    }
",non-flaky,5
57221,apache_ozone,TestUtilizationSchemaDefinition.testReconSchemaCreated,"  @Test
  public void testReconSchemaCreated() throws Exception {
    Connection connection = getConnection();
    // Verify table definition
    DatabaseMetaData metaData = connection.getMetaData();
    ResultSet resultSet = metaData.getColumns(null, null,
        CLUSTER_GROWTH_DAILY_TABLE_NAME, null);

    List<Pair<String, Integer>> expectedPairs = new ArrayList<>();

    expectedPairs.add(new ImmutablePair<>(""timestamp"", Types.TIMESTAMP));
    expectedPairs.add(new ImmutablePair<>(""datanode_id"", Types.INTEGER));
    expectedPairs.add(new ImmutablePair<>(""datanode_host"", Types.VARCHAR));
    expectedPairs.add(new ImmutablePair<>(""rack_id"", Types.VARCHAR));
    expectedPairs.add(new ImmutablePair<>(""available_size"", Types.BIGINT));
    expectedPairs.add(new ImmutablePair<>(""used_size"", Types.BIGINT));
    expectedPairs.add(new ImmutablePair<>(""container_count"", Types.INTEGER));
    expectedPairs.add(new ImmutablePair<>(""block_count"", Types.INTEGER));

    List<Pair<String, Integer>> actualPairs = new ArrayList<>();

    while (resultSet.next()) {
      actualPairs.add(new ImmutablePair<>(resultSet.getString(""COLUMN_NAME""),
          resultSet.getInt(""DATA_TYPE"")));
    }

    Assert.assertEquals(8, actualPairs.size());
    Assert.assertEquals(expectedPairs, actualPairs);

    ResultSet resultSetFileCount = metaData.getColumns(null, null,
        FILE_COUNT_BY_SIZE_TABLE_NAME, null);

    List<Pair<String, Integer>> expectedPairsFileCount = new ArrayList<>();
    expectedPairsFileCount.add(
        new ImmutablePair<>(""volume"", Types.VARCHAR));
    expectedPairsFileCount.add(
        new ImmutablePair<>(""bucket"", Types.VARCHAR));
    expectedPairsFileCount.add(
        new ImmutablePair<>(""file_size"", Types.BIGINT));
    expectedPairsFileCount.add(
        new ImmutablePair<>(""count"", Types.BIGINT));

    List<Pair<String, Integer>> actualPairsFileCount = new ArrayList<>();
    while(resultSetFileCount.next()) {
      actualPairsFileCount.add(new ImmutablePair<>(resultSetFileCount.getString(
          ""COLUMN_NAME""), resultSetFileCount.getInt(
              ""DATA_TYPE"")));
    }
    assertEquals(""Unexpected number of columns"",
        4, actualPairsFileCount.size());
    assertEquals(""Columns Do not Match "",
        expectedPairsFileCount, actualPairsFileCount);
  }
",non-flaky,5
118731,netty_netty,EmptyByteBufTest.testWriteEmptyByteBuf,"    @Test
    public void testWriteEmptyByteBuf() {
        EmptyByteBuf empty = new EmptyByteBuf(UnpooledByteBufAllocator.DEFAULT);
        empty.writeBytes(Unpooled.EMPTY_BUFFER); // Ok
        ByteBuf nonEmpty = UnpooledByteBufAllocator.DEFAULT.buffer().writeBoolean(false);
        try {
            empty.writeBytes(nonEmpty);
            fail();
        } catch (IndexOutOfBoundsException ignored) {
            // Ignore.
        } finally {
            nonEmpty.release();
        }
    }
",non-flaky,5
159671,liquibase_liquibase,AddColumnExecutorTest.generateSql_autoIncrement,"    @Test
    public void generateSql_autoIncrement() throws Exception {
        this.statementUnderTest = new AddColumnStatement(null, ""table_name"", ""column_name"", ""int"", null, new AutoIncrementConstraint(""column_name""));

        assertCorrect(""alter table table_name add column_name serial"", InformixDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int default autoincrement null"", SybaseASADatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] serial"", PostgresDatabase.class);
        assertCorrect(""alter table [dbo].[table_name] add [column_name] int identity"", MSSQLDatabase.class);
        assertCorrect(""alter table [table_name] add [column_name] int identity null"", SybaseDatabase.class);
        assertCorrect(""not supported. fixme!!"", SQLiteDatabase.class);
        assertCorrect(""alter table table_name add column_name int auto_increment_clause"");
    }
",non-flaky,5
43033,trinodb_trino,BaseDynamicPartitionPruningTest.testJoinWithImplicitCoercion,"    @Test(timeOut = 30_000)
    public void testJoinWithImplicitCoercion()
    {
        // setup partitioned fact table with integer suppkey
        createLineitemTable(""partitioned_lineitem_int"", ImmutableList.of(""orderkey"", ""CAST(suppkey as int) suppkey_int""), ImmutableList.of(""suppkey_int""));
        assertQuery(
                ""SELECT count(*) FROM partitioned_lineitem_int"",
                ""VALUES "" + LINEITEM_COUNT);

        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem_int l JOIN supplier s ON l.suppkey_int = s.suppkey AND s.name = 'Supplier#000000001'"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(""partitioned_lineitem_int""));
        // Probe-side is partially scanned
        assertEquals(probeStats.getInputPositions(), 615L);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);
        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertEquals(domainStats.getSimplifiedDomain(), singleValue(BIGINT, 1L).toString(getSession().toConnectorSession()));
    }
",non-flaky,5
33735,alibaba_fastjson,FastJsonViewTest.test2,"    @Test
    public void test2() throws Exception {
        mockMvc.perform(
                (post(""/fastjsonview/test2"").characterEncoding(""UTF-8"")
                        .contentType(MediaType.APPLICATION_JSON))).andExpect(status
                ().isOk()).andDo(print()
        ).andExpect(content().string(""{\""description\"":\""fastjsonviewæ³¨è§£æµè¯\"",\""stock\"":\""haha\""}""));
    }
",non-flaky,5
113970,apache_struts,DefaultActionProxyTest.testThorwExceptionOnNotAllowedMethod,"    @Test
    public void testThorwExceptionOnNotAllowedMethod() throws Exception {
        final String filename = ""com/opensymphony/xwork2/config/providers/xwork-test-allowed-methods.xml"";
        loadConfigurationProviders(new XmlConfigurationProvider(filename));
        DefaultActionProxy dap = new DefaultActionProxy(new MockActionInvocation(), ""strict"", ""Default"", ""notAllowed"", true, true);
        container.inject(dap);

        try {
            dap.prepare();
            fail(""Must throw exception!"");
        } catch (Exception e) {
            assertEquals(e.getMessage(), ""Method notAllowed for action Default is not allowed!"");
        }
    }
",non-flaky,5
96062,stanfordnlp_CoreNLP,ChineseSerializationITest.testChineseSerialization,"  @Test
  public void testChineseSerialization() {

    try {
      AnnotationSerializer serializer = new ProtobufAnnotationSerializer();
      // write Chinese doc
      String sampleChineseDocument = ""å·´æåÂ·å¥¥å·´é©¬æ¯ç¾å½æ»ç»ãä»å¨2008å¹´å½é"";
      Properties chineseProperties = StringUtils.argsToProperties(""-props"",
              ""StanfordCoreNLP-chinese.properties"");
      Annotation doc = new StanfordCoreNLP(chineseProperties).process(sampleChineseDocument);

      // fake having a section in the annotation so the test passes.
      // todo [2017] clean up the status of sections.
      doc.set(CoreAnnotations.SectionsAnnotation.class, new ArrayList<CoreMap>());

      ByteArrayOutputStream ks = new ByteArrayOutputStream();
      serializer.write(doc, ks).close();
      // read
      InputStream kis = new ByteArrayInputStream(ks.toByteArray());
      Pair<Annotation, InputStream> pair = serializer.read(kis);
      pair.second.close();
      Annotation readDoc = pair.first;
      kis.close();
      // check characters are equal
      List<CoreLabel> docChars = doc.get(SegmenterCoreAnnotations.CharactersAnnotation.class);
      List<CoreLabel> readDocChars = doc.get(SegmenterCoreAnnotations.CharactersAnnotation.class);
      assertEquals(docChars.size(),readDocChars.size());
      int numChars = docChars.size();
      int currChar = 0;
      while (currChar < numChars) {
        assertEquals(docChars.get(currChar),readDocChars.get(currChar));
        currChar++;
      }
      // check that sentences are equal
      /*int sentenceCount = 0;
      while (sentenceCount < doc.get(CoreAnnotations.SentencesAnnotation.class).size()) {
        assertEquals(doc.get(CoreAnnotations.SentencesAnnotation.class).get(sentenceCount),
                readDoc.get(CoreAnnotations.SentencesAnnotation.class).get(sentenceCount));
        sentenceCount++;
      }*/
      // check JSON output is same
      String docJSON = JSONOutputter.jsonPrint(doc);
      String readDocJSON = JSONOutputter.jsonPrint(readDoc);
      assertEquals(docJSON,readDocJSON);
    } catch (Exception e) { throw new RuntimeException(e); }
  }
",non-flaky,5
175750,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testProjectNotSelectedIsAnErrorWhenRequireValuesIsTrue,"  @Test
  public void testProjectNotSelectedIsAnErrorWhenRequireValuesIsTrue() {
    deployPanel = createPanel(true /* requireValues */);
    assertThat(getProjectSelectionValidator().getSeverity(), is(IStatus.ERROR));
  }
",non-flaky,5
150136,apache_hive,TestHplsqlLocal.testChar,"  @Test
  public void testChar() throws Exception {
    run(""char"");
  }
",non-flaky,5
35677,cdapio_cdap,LogBufferReaderTest.testLogReader,"  @Test
  public void testLogReader() throws Exception {
    String absolutePath = TMP_FOLDER.newFolder().getAbsolutePath();

    LogBufferWriter writer = new LogBufferWriter(absolutePath, 250, () -> { });
    ImmutableList<byte[]> events = getLoggingEvents();
    Iterable<LogBufferEvent> writtenEvents = writer.write(events.iterator());
    writer.close();

    List<LogBufferEvent> logBufferEvents = new LinkedList<>();
    // read from start positions, tests case where no checkpoints are persisted
    LogBufferReader reader = new LogBufferReader(absolutePath, 2, 3, -1, -1);
    Iterator<LogBufferEvent> iterator = writtenEvents.iterator();
    verifyEvents(logBufferEvents, reader, iterator);
    reader.close();

    // this should skip first and second event, this is because log buffer offsets are offset for event that is
    // already stored. so in this case, skip first event and skip second event as second event is the last stored event
    reader = new LogBufferReader(absolutePath, 2, 3, 0, 145);
    iterator = writtenEvents.iterator();
    iterator.next();
    iterator.next();
    verifyEvents(logBufferEvents, reader, iterator);
    reader.close();
  }
",non-flaky,5
30933,camunda-cloud_zeebe,ElasticsearchExporterJobRecordIT.shouldExportJobBatchRecordWithOverlappingCustomHeaders,"  @Test
  public void shouldExportJobBatchRecordWithOverlappingCustomHeaders() {
    // when
    exporterBrokerRule.deployProcess(
        Bpmn.createExecutableProcess(""process"")
            .startEvent()
            .serviceTask(
                ""task"",
                t -> t.zeebeJobType(""test"").zeebeTaskHeader(""x"", ""1"").zeebeTaskHeader(""x.y"", ""2""))
            .endEvent()
            .done(),
        ""process.bpmn"");

    final var processInstanceKey = exporterBrokerRule.createProcessInstance(""process"", Map.of());

    await(""index templates need to be created"").untilAsserted(this::assertIndexSettings);
    final var jobCreated =
        RecordingExporter.jobRecords(JobIntent.CREATED)
            .withProcessInstanceKey(processInstanceKey)
            .getFirst();

    jobWorker =
        exporterBrokerRule.createJobWorker(
            ""test"", ((client, job) -> client.newCompleteCommand(job.getKey()).send()));

    // then
    final var jobBatchActivated =
        RecordingExporter.jobBatchRecords(JobBatchIntent.ACTIVATED).withType(""test"").getFirst();

    assertThat(jobBatchActivated.getValue().getJobKeys()).contains(jobCreated.getKey());
    assertRecordExported(jobBatchActivated);
  }
",non-flaky,5
162457,testcontainers_testcontainers-java,KeyValuesStatementTest.keyWithTabsTest,"    @Test
    public void keyWithTabsTest() throws Exception {
        assertStatement(new KeyValuesStatement(""TEST"", Collections.singletonMap(""key\twith\ttab"", ""1"")));
    }
",non-flaky,5
156070,jReddit_jReddit,RedditOAuthAgentTest.testTokenAppOnlyConfidential,"    @Test
    public void testTokenAppOnlyConfidential() throws RedditOAuthException, OAuthSystemException, OAuthProblemException {
        
        // Captor for the request that is executed
        ArgumentCaptor<OAuthClientRequest> clientCaptor = ArgumentCaptor.forClass(OAuthClientRequest.class);
        
        when(mockOAuthClient.accessToken(any(OAuthClientRequest.class))).thenReturn(jsonTokenNonRefreshable);
        
        // Run subject
        RedditToken token = subject.tokenAppOnly(true);
        
        // Verify and capture
        verify(mockOAuthClient).accessToken(clientCaptor.capture());
        
        OAuthClientRequest request = clientCaptor.getValue();
        
        assertNotNull(request.getHeader(""Authorization"")); // This is Base64 encoded
        assertEquals(request.getHeader(""User-Agent""), userAgent);
        
        assertEquals(accessToken, token.getAccessToken());
        assertNull(token.getRefreshToken());
        assertEquals(tokenType, token.getTokenType());
        assertEquals(expiresIn, token.getExpirationSpan());
        assertTrue(token.hasScope(RedditScope.EDIT));
        assertTrue(token.hasScope(RedditScope.FLAIR));
        assertFalse(token.hasScope(RedditScope.PRIVATEMESSAGE));

    }
",non-flaky,5
135805,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.run,"    @Test
    public void testSemaphoreRejected() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-H"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        //10 commands will saturate semaphore when called from different threads.
        //submit 2 more requests and they should be SEMAPHORE_REJECTED
        //should see 10 SUCCESSes, 2 SEMAPHORE_REJECTED and 2 FALLBACK_SUCCESSes

        List<Command> saturators = new ArrayList<Command>();

        for (int i = 0; i < 10; i++) {
            saturators.add(Command.from(groupKey, key, HystrixEventType.SUCCESS, 500, HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE));
        }

        Command rejected1 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0, HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE);
        Command rejected2 = Command.from(groupKey, key, HystrixEventType.SUCCESS, 0, HystrixCommandProperties.ExecutionIsolationStrategy.SEMAPHORE);

        for (final Command saturator : saturators) {
            new Thread(new HystrixContextRunnable(new Runnable() {
                @Override
                public void run() {
                    saturator.observe();
                }
",non-flaky,5
122557,vespa-engine_vespa,CommandLineTest.verifyDefaults,"    @Test
    public void verifyDefaults() {
        assertEquals(CommandLine.DEFAULT_TIMEOUT, commandLine.getTimeout());
        assertEquals(CommandLine.DEFAULT_MAX_OUTPUT_BYTES, commandLine.getMaxOutputBytes());
        assertEquals(CommandLine.DEFAULT_SIGTERM_GRACE_PERIOD, commandLine.getSigTermGracePeriod());
        assertEquals(CommandLine.DEFAULT_SIGKILL_GRACE_PERIOD, commandLine.getSigKillGracePeriod());
        assertEquals(0, commandLine.getArguments().size());
        assertEquals(Optional.empty(), commandLine.getOutputFile());
        assertEquals(StandardCharsets.UTF_8, commandLine.getOutputEncoding());
        assertTrue(commandLine.getRedirectStderrToStdoutInsteadOfDiscard());
        Predicate<Integer> defaultExitCodePredicate = commandLine.getSuccessfulExitCodePredicate();
        assertTrue(defaultExitCodePredicate.test(0));
        assertFalse(defaultExitCodePredicate.test(1));
    }
",non-flaky,5
59618,looly_hutool,BeanValidatorUtilTest.propertyValidatorTest,"	@Test
	public void propertyValidatorTest() {
		BeanValidationResult result = ValidationUtil.warpValidateProperty(new TestClass(), ""name"");
		Assert.assertFalse(result.isSuccess());
		Assert.assertEquals(1, result.getErrorMessages().size());
	}
",non-flaky,5
77495,dropwizard_dropwizard,SelfValidationTest.clearAllLoggers,"    @BeforeEach
    public void clearAllLoggers() {
        //this must be a clear all because the validation runs in other threads
        TestLoggerFactory.clearAll();
    }
",non-flaky,5
59581,looly_hutool,MailTest.sendWithFileTest,"	@Test
	public void sendWithFileTest() {
		MailUtil.send(""hutool@foxmail.com"", ""æµè¯"", ""<h1>é®ä»¶æ¥èªHutoolæµè¯</h1>"", true, FileUtil.file(""d:/æµè¯éä»¶ææ¬.txt""));
	}
",non-flaky,5
43070,trinodb_trino,BaseConnectorTest.testShowCreateInformationSchemaTable,"    @Test
    public void testShowCreateInformationSchemaTable()
    {
        assertQueryFails(""SHOW CREATE VIEW information_schema.schemata"", ""line 1:1: Relation '\\w+.information_schema.schemata' is a table, not a view"");
        assertQueryFails(""SHOW CREATE MATERIALIZED VIEW information_schema.schemata"", ""line 1:1: Relation '\\w+.information_schema.schemata' is a table, not a materialized view"");

        assertThat((String) computeScalar(""SHOW CREATE TABLE information_schema.schemata""))
                .isEqualTo(""CREATE TABLE "" + getSession().getCatalog().orElseThrow() + "".information_schema.schemata (\n"" +
                        ""   catalog_name varchar,\n"" +
                        ""   schema_name varchar\n"" +
                        "")"");
    }
",non-flaky,5
178004,aosp-mirror_platform_frameworks_support,BrowseSupportFragmentTest.testPressRightBeforeMainFragmentCreated,"    @Test
    public void testPressRightBeforeMainFragmentCreated() throws Throwable {
        final long dataLoadingDelay = 1000;
        Intent intent = new Intent();
        intent.putExtra(BrowseSupportFragmentTestActivity.EXTRA_LOAD_DATA_DELAY, dataLoadingDelay);
        intent.putExtra(BrowseSupportFragmentTestActivity.EXTRA_ADD_TO_BACKSTACK , false);
        mActivity = activityTestRule.launchActivity(intent);

        assertNull(mActivity.getBrowseTestSupportFragment().getMainFragment());
        sendKeys(KeyEvent.KEYCODE_DPAD_RIGHT);
    }
",non-flaky,5
84600,apache_zookeeper,BinaryInputArchiveTest.testReadStringForRecordsHavingLengthLessThanMaxAllowedSize,"  @Test
  public void testReadStringForRecordsHavingLengthLessThanMaxAllowedSize()
      throws IOException {
    int maxBufferSize = 2000;
    int extraMaxBufferSize = 1025;
    int recordSize = maxBufferSize + extraMaxBufferSize - 100;
    //Exception is not expected as record size is less than the allowed size
    BinaryInputArchive ia =
        getBinaryInputArchive(recordSize, maxBufferSize, extraMaxBufferSize);
    String s = ia.readString("""");
    assertNotNull(s);
    assertEquals(recordSize, s.getBytes().length);
  }
",non-flaky,5
70808,apache_kafka,PluginUtilsTest.testPluginUrlsWithRelativeSymlinkBackwards,"    @Test
    public void testPluginUrlsWithRelativeSymlinkBackwards() throws Exception {
        createBasicDirectoryLayout();

        Path anotherPath = rootDir.newFolder(""moreplugins"").toPath().toRealPath();
        Files.createDirectories(anotherPath.resolve(""connectorB-deps""));
        Files.createSymbolicLink(
                pluginPath.resolve(""connectorB/deps/symlink""),
                Paths.get(""../../../moreplugins/connectorB-deps"")
        );

        List<Path> expectedUrls = createBasicExpectedUrls();
        expectedUrls.add(Files.createFile(anotherPath.resolve(""connectorB-deps/converter.jar"")));

        assertUrls(expectedUrls, PluginUtils.pluginUrls(pluginPath));
    }
",non-flaky,5
99789,apache_cassandra,MessagingServiceTest.listenPlainConnectionWithBroadcastAddr,"    @Test
    public void listenPlainConnectionWithBroadcastAddr() throws InterruptedException
    {
        ServerEncryptionOptions serverEncryptionOptions = new ServerEncryptionOptions()
                                                          .withInternodeEncryption(ServerEncryptionOptions.InternodeEncryption.none);
        listen(serverEncryptionOptions, true);
    }
",non-flaky,5
35670,cdapio_cdap,LogBufferWriterTest.testFileRotation,"  @Test
  public void testFileRotation() throws Exception {
    // Make sure rotation happens after every event is written
    LogBufferWriter writer = new LogBufferWriter(TMP_FOLDER.newFolder().getAbsolutePath(), 10, () -> { });
    ImmutableList<byte[]> events = getLoggingEvents();
    Iterator<LogBufferEvent> writtenEvents = writer.write(events.iterator()).iterator();
    writer.close();

    int i = 0;
    // verify if correct offsets and file id were set with file rotation
    while (writtenEvents.hasNext()) {
      LogBufferEvent bufferEvent = writtenEvents.next();
      Assert.assertEquals(bufferEvent.getLogEvent().getMessage(), String.valueOf(i));
      // There will be 2 events in one file.
      Assert.assertEquals(i++ + "".buf"", bufferEvent.getOffset().getFileId() + "".buf"");
      Assert.assertEquals(0, bufferEvent.getOffset().getFilePos());
    }
  }
",non-flaky,5
77481,opensearch-project_OpenSearch,TransportLoggerTests.setUp,"@TestLogging(value = ""org.opensearch.transport.TransportLogger:trace"", reason = ""to ensure we log network events on TRACE level"")
    public void setUp() throws Exception {
        super.setUp();
        appender = new MockLogAppender();
        Loggers.addAppender(LogManager.getLogger(TransportLogger.class), appender);
        appender.start();
    }
",non-flaky,5
91561,apache_kylin,LocalFileResourceStoreTest.testRollback,"    @Test
    public void testRollback() throws Exception {
        ResourceStore store = ResourceStore.getStore(KylinConfig.getInstanceFromEnv());
        byte[] bytes = new byte[] { 0, 1, 2 };
        RawResource raw;
        Checkpoint cp;

        cp = store.checkpoint();
        try {
            store.putResource(""/res1"", new StringEntity(""data1""), 1000, StringEntity.serializer);
        } finally {
            cp.close();
        }
        StringEntity str = store.getResource(""/res1"", StringEntity.serializer);
        assertEquals(""data1"", str.toString());

        cp = store.checkpoint();
        try {
            ByteArrayInputStream is = new ByteArrayInputStream(bytes);
            store.putResource(""/res2"", is, 2000);
            is.close();
            
            store.putResource(""/res1"", str, 2000, StringEntity.serializer);
            store.deleteResource(""/res1"");

            assertEquals(null, store.getResource(""/res1""));
            assertEquals(2000, (raw = store.getResource(""/res2"")).lastModified());
            raw.content().close();
            
            cp.rollback();
            
            assertEquals(null, store.getResource(""/res2""));
            assertEquals(1000, (raw = store.getResource(""/res1"")).lastModified());
            raw.content().close();
        } finally {
            cp.close();
        }
    }
",non-flaky,5
176810,ctco_cukes,EndsWithRegexpTest.matchesDirectMatch,"    @Test
    public void matchesDirectMatch() throws Exception {
        assertThat(""hello"", EndsWithRegexp.endsWithRegexp(""hello""));
    }
",non-flaky,5
134014,CorfuDB_CorfuDB,LoggingMeterRegistryTest.testWriteTimer,"    @Test
    public void testWriteTimer() {
        LoggingMeterRegistryWithHistogramSupport registry = getInstance();
        Timer timer = new TestTimer();
        String line = registry.writeTimer(timer).findFirst().orElseThrow(IllegalArgumentException::new);
        assertTrue(line.contains(""metric,endpoint=localhost:9000,metric_type=timer sum=200,count=100,mean=2,upper=300""));
    }
",non-flaky,5
133981,CorfuDB_CorfuDB,ClientHandshakeHandlerTest.testResponseDroppedBeforeHandshake,"    @Test
    public void testResponseDroppedBeforeHandshake() {
        // Take out the handshake request message upon channelActive.
        Object out = embeddedChannel.readOutbound();
        assertTrue(out instanceof RequestMsg);
        assertTrue(((RequestMsg) out).getPayload().hasHandshakeRequest());
        // Get a ping ResponseMsg
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getPingResponseMsg()
        );

        embeddedChannel.writeInbound(response);

        // Verify that the response was correctly dropped and there is no inbound nor outbound messages.
        assertNull(embeddedChannel.readInbound());
        assertNull(embeddedChannel.readOutbound());
    }
",non-flaky,5
92625,apache_dubbo,GenericServiceTest.testGeneric2,"    @Test
    public void testGeneric2() {
        DemoService server = new DemoServiceImpl();
        ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();
        Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();
        URL url = URL.valueOf(""dubbo://127.0.0.1:5342/"" + DemoService.class.getName() + ""?version=1.0.0&generic=true"");
        Exporter<DemoService> exporter = protocol.export(proxyFactory.getInvoker(server, DemoService.class, url));
        Invoker<GenericService> invoker = protocol.refer(GenericService.class, url);

        GenericService client = proxyFactory.getProxy(invoker, true);
        Object result = client.$invoke(""sayHello"", new String[]{""java.lang.String""}, new Object[]{""haha""});
        Assert.assertEquals(""hello haha"", result);

        Invoker<DemoService> invoker2 = protocol.refer(DemoService.class, url);

        GenericService client2 = (GenericService) proxyFactory.getProxy(invoker2, true);
        Object result2 = client2.$invoke(""sayHello"", new String[]{""java.lang.String""}, new Object[]{""haha""});
        Assert.assertEquals(""hello haha"", result2);

        invoker.destroy();
        exporter.unexport();
    }
",non-flaky,5
35703,cdapio_cdap,FileMetadataCleanerTest.testWithBatchSizeLargerThanNumOfFiles,"  @Test
  public void testWithBatchSizeLargerThanNumOfFiles() throws Exception {
    TransactionRunner transactionRunner = injector.getInstance(TransactionRunner.class);

    FileMetaDataWriter fileMetaDataWriter = new FileMetaDataWriter(transactionRunner);
    FileMetaDataReader fileMetadataReader = injector.getInstance(FileMetaDataReader.class);
    FileMetadataCleaner fileMetadataCleaner = new FileMetadataCleaner(transactionRunner);
    try {
      LogPathIdentifier identifier = new LogPathIdentifier(NamespaceId.DEFAULT.getNamespace(),
                                                           ""testApp"", String.format(""testFlow%s"", 0));

      LocationFactory locationFactory = injector.getInstance(LocationFactory.class);
      Location location = locationFactory.create(TMP_FOLDER.newFolder().getPath()).append(""/logs"");
      long currentTime = System.currentTimeMillis();
      long newCurrentTime = currentTime + 100;

      for (int j = 0; j < 10; j++) {
        fileMetaDataWriter.writeMetaData(identifier, newCurrentTime + j, newCurrentTime + j,
                                         location.append(""testFileNew"" + Integer.toString(j)));
      }

      List<LogLocation> locations;
      locations = fileMetadataReader.listFiles(identifier, newCurrentTime, newCurrentTime + 10);
      // should include files from currentTime (0..9)
      Assert.assertEquals(10, locations.size());

      long tillTime = newCurrentTime + 4;
      List<FileMetadataCleaner.DeletedEntry> deleteEntries =
        fileMetadataCleaner.scanAndGetFilesToDelete(tillTime, 1000);
      Assert.assertEquals(5, deleteEntries.size());
    } finally {
      // cleanup meta
      deleteAllMetaEntries(transactionRunner);
    }
  }
",non-flaky,5
20992,NationalSecurityAgency_timely,MetaKeySetTest.testToMutations,"    @Test
    public void testToMutations() {
        Meta one = new Meta(""sys.cpu.user"", ""tag1"", ""value1"");
        Meta two = new Meta(""sys.cpu.user"", ""tag2"", ""value2"");
        Meta three = new Meta(""sys.cpu.user"", ""tag3"", ""value3"");
        MetaKeySet mks = new MetaKeySet();
        mks.addAll(one.toKeys());
        mks.addAll(two.toKeys());
        mks.addAll(three.toKeys());
        List<Mutation> muts = mks.toMutations();
        Mutation e1 = new Mutation(""m:sys.cpu.user"");
        e1.put("""", """", MetaKeySet.NULL_VALUE);
        Mutation e2 = new Mutation(""t:sys.cpu.user"");
        e2.put(""tag1"", """", MetaKeySet.NULL_VALUE);
        e2.put(""tag2"", """", MetaKeySet.NULL_VALUE);
        e2.put(""tag3"", """", MetaKeySet.NULL_VALUE);
        Mutation e3 = new Mutation(""v:sys.cpu.user"");
        e3.put(""tag1"", ""value1"", MetaKeySet.NULL_VALUE);
        e3.put(""tag2"", ""value2"", MetaKeySet.NULL_VALUE);
        e3.put(""tag3"", ""value3"", MetaKeySet.NULL_VALUE);
        Assert.assertEquals(3, muts.size());
        Assert.assertTrue(muts.contains(e1));
        Assert.assertTrue(muts.contains(e2));
        Assert.assertTrue(muts.contains(e3));
    }
",non-flaky,5
70842,apache_kafka,WorkerSourceTaskTest.testSendRecordsNoTimestamp,"    @Test
    public void testSendRecordsNoTimestamp() throws Exception {
        final Long timestamp = -1L;
        createWorkerTask();

        List<SourceRecord> records = Collections.singletonList(
                new SourceRecord(PARTITION, OFFSET, ""topic"", null, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD, timestamp)
        );

        Capture<ProducerRecord<byte[], byte[]>> sent = expectSendRecordAnyTimes();

        PowerMock.replayAll();

        Whitebox.setInternalState(workerTask, ""toSend"", records);
        Whitebox.invokeMethod(workerTask, ""sendRecords"");
        assertEquals(null, sent.getValue().timestamp());

        PowerMock.verifyAll();
    }
",non-flaky,5
179474,abel533_Mapper,DefaultEnumTypeHandlerTest.testUpdate,"    @Test
    public void testUpdate(){
        SqlSession sqlSession = getSqlSession();
        try {
            UserMapper userMapper = sqlSession.getMapper(UserMapper.class);
            User user = userMapper.selectByPrimaryKey(1);
            Assert.assertEquals(""abel533"", user.getName());
            Assert.assertEquals(LockDictEnum.unlocked, user.getLock());
            Assert.assertEquals(StateDictEnum.enabled, user.getState());

            user.setLock(LockDictEnum.locked);
            user.setState(StateDictEnum.disabled);
            Assert.assertEquals(1, userMapper.updateByPrimaryKey(user));

            user = userMapper.selectByPrimaryKey(1);
            Assert.assertEquals(""abel533"", user.getName());
            Assert.assertEquals(LockDictEnum.locked, user.getLock());
            Assert.assertEquals(StateDictEnum.disabled, user.getState());
        } finally {
            sqlSession.close();
        }
    }
",non-flaky,5
43086,trinodb_trino,AbstractTestIntegrationSmokeTest.testAggregation,"    @Test
    public void testAggregation()
    {
        assertQuery(""SELECT sum(orderkey) FROM orders"");
        assertQuery(""SELECT sum(totalprice) FROM orders"");
        assertQuery(""SELECT max(comment) FROM nation"");

        assertQuery(""SELECT count(*) FROM orders"");
        assertQuery(""SELECT count(*) FROM orders WHERE orderkey > 10"");
        assertQuery(""SELECT count(*) FROM (SELECT * FROM orders LIMIT 10)"");
        assertQuery(""SELECT count(*) FROM (SELECT * FROM orders WHERE orderkey > 10 LIMIT 10)"");

        assertQuery(""SELECT DISTINCT regionkey FROM nation"");
        assertQuery(""SELECT regionkey FROM nation GROUP BY regionkey"");

        // TODO support aggregation pushdown with GROUPING SETS
        assertQuery(
                ""SELECT regionkey, nationkey FROM nation GROUP BY GROUPING SETS ((regionkey), (nationkey))"",
                ""SELECT NULL, nationkey FROM nation "" +
                        ""UNION ALL SELECT DISTINCT regionkey, NULL FROM nation"");
        assertQuery(
                ""SELECT regionkey, nationkey, count(*) FROM nation GROUP BY GROUPING SETS ((), (regionkey), (nationkey), (regionkey, nationkey))"",
                ""SELECT NULL, NULL, count(*) FROM nation "" +
                        ""UNION ALL SELECT NULL, nationkey, 1 FROM nation "" +
                        ""UNION ALL SELECT regionkey, NULL, count(*) FROM nation GROUP BY regionkey "" +
                        ""UNION ALL SELECT regionkey, nationkey, 1 FROM nation"");

        assertQuery(""SELECT count(regionkey) FROM nation"");
        assertQuery(""SELECT count(DISTINCT regionkey) FROM nation"");
        assertQuery(""SELECT regionkey, count(*) FROM nation GROUP BY regionkey"");

        assertQuery(""SELECT min(regionkey), max(regionkey) FROM nation"");
        assertQuery(""SELECT min(DISTINCT regionkey), max(DISTINCT regionkey) FROM nation"");
        assertQuery(""SELECT regionkey, min(regionkey), min(name), max(regionkey), max(name) FROM nation GROUP BY regionkey"");

        assertQuery(""SELECT sum(regionkey) FROM nation"");
        assertQuery(""SELECT sum(DISTINCT regionkey) FROM nation"");
        assertQuery(""SELECT regionkey, sum(regionkey) FROM nation GROUP BY regionkey"");

        assertQuery(
                ""SELECT avg(nationkey) FROM nation"",
                ""SELECT avg(CAST(nationkey AS double)) FROM nation"");
        assertQuery(
                ""SELECT avg(DISTINCT nationkey) FROM nation"",
                ""SELECT avg(DISTINCT CAST(nationkey AS double)) FROM nation"");
        assertQuery(
                ""SELECT regionkey, avg(nationkey) FROM nation GROUP BY regionkey"",
                ""SELECT regionkey, avg(CAST(nationkey AS double)) FROM nation GROUP BY regionkey"");
    }
",non-flaky,5
76762,quarkusio_quarkus,NativeImageIT.testJavaLibraryPathAtRuntime,"    @Test
    public void testJavaLibraryPathAtRuntime() throws Exception {
        final File testDir = initProject(""projects/native-image-app"", ""projects/native-image-app-output"");
        final RunningInvoker running = new RunningInvoker(testDir, false);

        // trigger mvn package -Pnative -Dquarkus.ssl.native=true
        final String[] mvnArgs = new String[] { ""package"", ""-DskipTests"", ""-Pnative"", ""-Dquarkus.ssl.native=true"" };
        final MavenProcessInvocationResult result = running.execute(Arrays.asList(mvnArgs), Collections.emptyMap());
        await().atMost(10, TimeUnit.MINUTES).until(() -> result.getProcess() != null && !result.getProcess().isAlive());
        final String processLog = running.log();
        try {
            assertThat(processLog).containsIgnoringCase(""BUILD SUCCESS"");
        } catch (AssertionError ae) {
            // skip this test (instead of failing), if the native-image command wasn't available.
            // Bit brittle to rely on the log message, but it's OK in the context of this test
            Assumptions.assumeFalse(processLog.contains(""Cannot find the `native-image""),
                    ""Skipping test since native-image tool isn't available"");
            // native-image command was available but the build failed for some reason, throw the original error
            throw ae;
        } finally {
            running.stop();
        }

        // now that the native image is built, run it
        final Path nativeImageRunner = testDir.toPath().toAbsolutePath().resolve(Paths.get(""target/acme-1.0-SNAPSHOT-runner""));
        final Path tmpDir = Files.createTempDirectory(""native-image-test"");
        tmpDir.toFile().deleteOnExit();
        final Process nativeImageRunWithAdditionalLibPath = runNativeImage(nativeImageRunner,
                new String[] { ""-Djava.library.path="" + tmpDir.toString() });
        try {
            final String response = DevModeTestUtils.getHttpResponse(""/hello/javaLibraryPath"");
            Assertions.assertTrue(response.contains(tmpDir.toString()),
                    ""Response "" + response + "" for java.library.path was expected to contain the "" + tmpDir + "", but didn't"");
        } finally {
            nativeImageRunWithAdditionalLibPath.destroy();
        }

    }
",non-flaky,5
114018,apache_struts,JSONReaderTest.testExponentialNumber2,"    @Test
    public void testExponentialNumber2() throws Exception {
        Object ret = reader.read(""123.4e10"");
        assertNotNull(ret);
        assertEquals(Double.class, ret.getClass());
        assertEquals(123.4e10, ret);
    }
",non-flaky,5
33725,alibaba_fastjson,Bug89.testBug89,"    @Test
    public void testBug89() {
        try {
            String s = ""{\""a\"":Ð·ãâ )_,\""}"";
            JSON.parseObject(s);
            fail(""Expect JSONException"");
        } catch (JSONException e) {
            // good
        }
    }
",non-flaky,5
78308,apache_beam,SimpleDoFnRunnerTest.testOnTimerExceptionsWrappedAsUserCodeException,"  @Test
  public void testOnTimerExceptionsWrappedAsUserCodeException() {
    ThrowingDoFn fn = new ThrowingDoFn();
    DoFnRunner<String, String> runner =
        new SimpleDoFnRunner<>(
            null,
            fn,
            NullSideInputReader.empty(),
            null,
            null,
            Collections.emptyList(),
            mockStepContext,
            null,
            Collections.emptyMap(),
            WindowingStrategy.of(new GlobalWindows()));

    thrown.expect(UserCodeException.class);
    thrown.expectCause(is(fn.exceptionToThrow));

    runner.onTimer(
        ThrowingDoFn.TIMER_ID, GlobalWindow.INSTANCE, new Instant(0), TimeDomain.EVENT_TIME);
  }
",non-flaky,5
150174,apache_hive,TestHplsqlLocal.testLang,"  @Test
  public void testLang() throws Exception {
    run(""lang"");
  }
",non-flaky,5
177208,line_armeria,ClientAuthIntegrationTest.normal,"    @Test
    public void normal() {
        try (ClientFactory clientFactory =
                     ClientFactory.builder()
                                  .tlsCustomizer(ctx -> ctx.keyManager(clientCert.certificateFile(),
                                                                       clientCert.privateKeyFile()))
                                  .tlsNoVerify()
                                  .build()) {
            final WebClient client = WebClient.builder(rule.httpsUri())
                                              .factory(clientFactory)
                                              .decorator(LoggingClient.builder().newDecorator())
                                              .build();
            assertThat(client.get(""/"").aggregate().join().status()).isEqualTo(HttpStatus.OK);
        }
    }
",non-flaky,5
33675,alibaba_fastjson,JSONScannerTest.charArrayCompare1,"  @Test
  public void charArrayCompare1() throws Throwable {

    // Arrange
    String src = """";
    int offset = 7;
    char[] dest = { '\u0000' };

    // Act
    Class<?> c = Reflector.forName(""com.alibaba.fastjson.parser.JSONScanner"");
    Method m = c.getDeclaredMethod(""charArrayCompare"", Reflector.forName(""java.lang.String""), Reflector.forName(""int""), Reflector.forName(""char []""));
    m.setAccessible(true);
    boolean retval = (Boolean)m.invoke(null, src, offset, dest);

    // Assert result
    Assert.assertEquals(false, retval);

  }
",non-flaky,5
35734,cdapio_cdap,AggregatedMetricsCollectionServiceTest.testPublish,"  @Test
  public void testPublish() throws InterruptedException {
    final BlockingQueue<MetricValues> published = new LinkedBlockingQueue<>();

    AggregatedMetricsCollectionService service = new AggregatedMetricsCollectionService(1000L) {
      @Override
      protected void publish(Iterator<MetricValues> metrics) {
        Iterators.addAll(published, metrics);
      }
    };

    service.startAndWait();

    // non-empty tags.
    final Map<String, String> baseTags = ImmutableMap.of(Constants.Metrics.Tag.NAMESPACE, NAMESPACE,
                                                         Constants.Metrics.Tag.APP, APP,
                                                         Constants.Metrics.Tag.SERVICE, SERVICE,
                                                         Constants.Metrics.Tag.RUN_ID, RUNID);

    try {
      // The first section tests with empty tags.
      // Publish couple metrics with empty tags, they should be aggregated.
      service.getContext(EMPTY_TAGS).increment(METRIC, Integer.MAX_VALUE);
      service.getContext(EMPTY_TAGS).increment(METRIC, 2);
      service.getContext(EMPTY_TAGS).increment(METRIC, 3);
      service.getContext(EMPTY_TAGS).increment(METRIC, 4);

      verifyCounterMetricsValue(published, ImmutableMap.of(0, ImmutableMap.of(METRIC, 9L + Integer.MAX_VALUE)));

      // No publishing for 0 value metrics
      Assert.assertNull(published.poll(3, TimeUnit.SECONDS));

      //update the metrics multiple times with gauge.
      service.getContext(EMPTY_TAGS).gauge(GAUGE_METRIC, 1);
      service.getContext(EMPTY_TAGS).gauge(GAUGE_METRIC, 2);
      service.getContext(EMPTY_TAGS).gauge(GAUGE_METRIC, 3);

      // gauge just updates the value, so polling should return the most recent value written
      verifyGaugeMetricsValue(published, ImmutableMap.of(0, 3L));

      // define collectors for non-empty tags
      MetricsContext baseCollector = service.getContext(baseTags);
      MetricsContext metricsContext = baseCollector.childContext(Constants.Metrics.Tag.HANDLER, HANDLER)
        .childContext(Constants.Metrics.Tag.INSTANCE_ID, INSTANCE);

      // increment metrics for various collectors
      baseCollector.increment(METRIC, Integer.MAX_VALUE);
      metricsContext.increment(METRIC, 5);
      baseCollector.increment(METRIC, 10);
      baseCollector.increment(METRIC, 3);
      metricsContext.increment(METRIC, 2);
      metricsContext.increment(METRIC, 4);
      metricsContext.increment(METRIC, 3);
      metricsContext.increment(METRIC, 1);

      // there are two collectors, verify their metrics values
      verifyCounterMetricsValue(published, ImmutableMap.of(4, ImmutableMap.of(METRIC, 13L + Integer.MAX_VALUE),
                                                           6, ImmutableMap.of(METRIC, 15L)));

      // No publishing for 0 value metrics
      Assert.assertNull(published.poll(3, TimeUnit.SECONDS));

      // gauge metrics for various collectors
      baseCollector.gauge(GAUGE_METRIC, Integer.MAX_VALUE);
      baseCollector.gauge(GAUGE_METRIC, 3);
      metricsContext.gauge(GAUGE_METRIC, 6);
      metricsContext.gauge(GAUGE_METRIC, 2);
      baseCollector.gauge(GAUGE_METRIC, 1);
      metricsContext.gauge(GAUGE_METRIC, Integer.MAX_VALUE);

      // gauge just updates the value, so polling should return the most recent value written
      verifyGaugeMetricsValue(published, ImmutableMap.of(4, 1L, 6, (long) Integer.MAX_VALUE));

      metricsContext.gauge(GAUGE_METRIC, 0);
      verifyCounterMetricsValue(published, ImmutableMap.of(6, ImmutableMap.of(GAUGE_METRIC, 0L)));
    } finally {
      service.stopAndWait();
    }
  }
",non-flaky,5
77480,opensearch-project_OpenSearch,TcpTransportTests.testExceptionHandling,"    @TestLogging(reason = ""testing logging"", value = ""org.opensearch.transport.TcpTransport:DEBUG"")
    public void testExceptionHandling() throws IllegalAccessException {
        testExceptionHandling(false, new OpenSearchException(""simulated""), true,
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.ERROR, ""*""),
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.WARN, ""*""),
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.INFO, ""*""),
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.DEBUG, ""*""));
        testExceptionHandling(new OpenSearchException(""simulated""),
            new MockLogAppender.SeenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"",
                Level.WARN, ""exception caught on transport layer [*], closing connection""));
        testExceptionHandling(new ClosedChannelException(),
            new MockLogAppender.SeenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"",
                Level.DEBUG, ""close connection exception caught on transport layer [*], disconnecting from relevant node""));
        testExceptionHandling(new OpenSearchException(""Connection reset""),
            new MockLogAppender.SeenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"",
                Level.DEBUG, ""close connection exception caught on transport layer [*], disconnecting from relevant node""));
        testExceptionHandling(new BindException(),
            new MockLogAppender.SeenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"",
                Level.DEBUG, ""bind exception caught on transport layer [*]""));
        testExceptionHandling(new CancelledKeyException(),
            new MockLogAppender.SeenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"",
                Level.DEBUG, ""cancelled key exception caught on transport layer [*], disconnecting from relevant node""));
        testExceptionHandling(true, new TcpTransport.HttpRequestOnTransportException(""test""), false,
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.ERROR, ""*""),
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.WARN, ""*""),
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.INFO, ""*""),
            new MockLogAppender.UnseenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"", Level.DEBUG, ""*""));
        testExceptionHandling(new StreamCorruptedException(""simulated""),
            new MockLogAppender.SeenEventExpectation(""message"", ""org.opensearch.transport.TcpTransport"",
                Level.WARN, ""simulated, [*], closing connection""));
    }
",non-flaky,5
150113,apache_hive,TestHplsqlUdf.testEvaluateWithoutRun,"  @Test
  public void testEvaluateWithoutRun() throws HiveException {
    // init udf
    Udf udf = new Udf();
    ObjectInspector[] initArguments = {queryOI, argOI};
    udf.initialize(initArguments);
    //set arguments
    DeferredObject queryObj = new DeferredJavaObject(""hello(:1)"");
      DeferredObject argObj = new DeferredJavaObject(""name"");
      DeferredObject[] argumentsObj = {queryObj, argObj};
      
      // init exec and set parameters, included
      udf.initExec(argumentsObj);
      udf.setParameters(argumentsObj);
      
      // checking var exists and its value is right
      Var var = udf.exec.findVariable("":1"");
      Assert.assertNotNull(var);
      String val = (String) var.value;
      Assert.assertEquals(val, ""name"");
  }
",non-flaky,5
78325,apache_beam,ReduceFnRunnerTest.testCombiningAccumulatingProcessingTime,"  @Test
  public void testCombiningAccumulatingProcessingTime() throws Exception {
    WindowingStrategy<?, IntervalWindow> strategy =
        WindowingStrategy.of((WindowFn<?, IntervalWindow>) FixedWindows.of(Duration.millis(100)))
            .withTimestampCombiner(TimestampCombiner.EARLIEST)
            .withMode(AccumulationMode.ACCUMULATING_FIRED_PANES)
            .withAllowedLateness(Duration.ZERO)
            .withTrigger(
                Repeatedly.forever(
                    AfterProcessingTime.pastFirstElementInPane().plusDelayOf(Duration.millis(10))));

    ReduceFnTester<Integer, Integer, IntervalWindow> tester =
        ReduceFnTester.combining(strategy, Sum.ofIntegers(), VarIntCoder.of());

    tester.advanceProcessingTime(new Instant(5000));
    injectElement(tester, 2); // processing timer @ 5000 + 10; EOW timer @ 100
    injectElement(tester, 5);

    tester.advanceInputWatermarkNoTimers(new Instant(100));
    tester.advanceProcessingTimeNoTimers(new Instant(5010));

    // Fires the GC/EOW timer at the same time as the processing time timer.
    tester.fireTimers(
        new IntervalWindow(new Instant(0), new Instant(100)),
        TimestampedValue.of(TimeDomain.EVENT_TIME, new Instant(100)),
        TimestampedValue.of(TimeDomain.PROCESSING_TIME, new Instant(5010)));

    assertThat(
        tester.extractOutput(),
        contains(
            isSingleWindowedValue(
                equalTo(7), 2, 0, 100, PaneInfo.createPane(true, true, Timing.ON_TIME, 0, 0))));
  }
",non-flaky,5
150151,apache_hive,TestHplsqlLocal.testCreateProcedureNoParams,"  @Test
  public void testCreateProcedureNoParams() throws Exception {
    run(""create_procedure_no_params"");
  }
",non-flaky,5
112096,apache_shardingsphere-elasticjob,OdevitySortByNameJobShardingStrategyTest.assertShardingByAsc,"    @Test
    public void assertShardingByAsc() {
        Map<JobInstance, List<Integer>> expected = new HashMap<>();
        expected.put(new JobInstance(""host0@-@0""), Collections.singletonList(0));
        expected.put(new JobInstance(""host1@-@0""), Collections.singletonList(1));
        expected.put(new JobInstance(""host2@-@0""), Collections.<Integer>emptyList());
        assertThat(odevitySortByNameJobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""1"", 2), is(expected));
    }
",non-flaky,5
150203,apache_hive,TestJavaDataModel.testGetModelForSystemWhenSetToUnknown,"  @Test
  public void testGetModelForSystemWhenSetToUnknown() throws Exception {
    System.setProperty(DATA_MODEL_PROPERTY, ""unknown"");
    assertSame(JavaDataModel.JAVA64, JavaDataModel.getModelForSystem());
  }
",non-flaky,5
84644,apache_zookeeper,EnforceAuthenticationTest.testEnforceAuthenticationNewBehaviourWithNetty,"    @Test
    public void testEnforceAuthenticationNewBehaviourWithNetty() throws Exception {
        Map<String, String> prop = new HashMap<>();
        prop.put(removeZooKeeper(AuthenticationHelper.ENFORCE_AUTH_ENABLED), ""true"");
        prop.put(removeZooKeeper(AuthenticationHelper.ENFORCE_AUTH_SCHEMES), ""digest"");
        prop.put(""serverCnxnFactory"", ""org.apache.zookeeper.server.NettyServerCnxnFactory"");
        startServer(prop);
        testEnforceAuthNewBehaviour(true);
    }
",non-flaky,5
134016,CorfuDB_CorfuDB,LoggingMeterRegistryTest.testTimerPercentiles,"    @Test
    public void testTimerPercentiles() {
        AggregateSink sink = new AggregateSink();

        LoggingMeterRegistryWithHistogramSupport registry = getInstance(sink);

        Timer timer = Timer.builder(""timer"")
                .publishPercentileHistogram()
                .publishPercentiles(0.99, 0.95, 0.5)
                .tags(""endpoint"", ""localhost:9000"")
                .register(registry);
        for (int i = 0; i < 3; i++) {
            timer.record(() -> {
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException ie) {

                }
            });
        }
        assertTrue(sink.substringIsPresent(""timer_percentile,endpoint=localhost:9000,phi=0.99,metric_type=gauge""));
        assertTrue(sink.substringIsPresent(""timer_percentile,endpoint=localhost:9000,phi=0.95,metric_type=gauge""));
        assertTrue(sink.substringIsPresent(""timer_percentile,endpoint=localhost:9000,phi=0.5,metric_type=gauge""));
    }
",non-flaky,5
26710,MundaneImmortal_pair-distribution-app,PairTest.testEqualWithOpsTrue,"	@Test
	public void testEqualWithOpsTrue()  {
		Pair subject = new Pair(Arrays.asList(new Developer(""dev1"")));
		subject.setOpsPair(true);
		Pair subject2 = new Pair(Arrays.asList(new Developer(""dev1"")));
		subject2.setOpsPair(true);
		
		assertThat(subject.equals(subject2), is(true));
	}
",non-flaky,5
78245,apache_beam,StateInternalsTest.testSetIsEmpty,"  @Test
  public void testSetIsEmpty() throws Exception {

    SetState<String> value = underTest.state(NAMESPACE_1, STRING_SET_ADDR);

    assertThat(value.isEmpty().read(), Matchers.is(true));
    ReadableState<Boolean> readFuture = value.isEmpty();
    value.add(""hello"");
    assertThat(readFuture.read(), Matchers.is(false));

    value.clear();
    assertThat(readFuture.read(), Matchers.is(true));
  }
",non-flaky,5
150131,apache_hive,TestHplsqlLocal.testBoolExpr,"  @Test
  public void testBoolExpr() throws Exception {
    run(""bool_expr"");
  }
",non-flaky,5
57248,apache_ozone,TestReconNodeManager.testUpdateNodeOperationalStateFromScm,"  @Test
  public void testUpdateNodeOperationalStateFromScm() throws Exception {
    ReconStorageConfig scmStorageConfig = new ReconStorageConfig(conf);
    EventQueue eventQueue = new EventQueue();
    NetworkTopology clusterMap = new NetworkTopologyImpl(conf);
    Table<UUID, DatanodeDetails> nodeTable =
        ReconSCMDBDefinition.NODES.getTable(store);
    ReconNodeManager reconNodeManager = new ReconNodeManager(conf,
        scmStorageConfig, eventQueue, clusterMap, nodeTable, versionManager);


    DatanodeDetails datanodeDetails = randomDatanodeDetails();
    HddsProtos.Node node = mock(HddsProtos.Node.class);

    LambdaTestUtils.intercept(NodeNotFoundException.class, () -> {
      reconNodeManager.updateNodeOperationalStateFromScm(node, datanodeDetails);
    });

    reconNodeManager.register(datanodeDetails, null, null);
    assertEquals(IN_SERVICE, reconNodeManager
        .getNodeByUuid(datanodeDetails.getUuidString()).getPersistedOpState());

    when(node.getNodeOperationalStates(eq(0)))
        .thenReturn(DECOMMISSIONING);
    reconNodeManager.updateNodeOperationalStateFromScm(node, datanodeDetails);
    assertEquals(DECOMMISSIONING, reconNodeManager
        .getNodeByUuid(datanodeDetails.getUuidString()).getPersistedOpState());
    List<DatanodeDetails> nodes =
        reconNodeManager.getNodes(DECOMMISSIONING, null);
    assertEquals(1, nodes.size());
    assertEquals(datanodeDetails.getUuid(), nodes.get(0).getUuid());
  }
",non-flaky,5
96886,apache_avro,TestSchemas.testHasGeneratedJavaClass,"  @Test
  public void testHasGeneratedJavaClass() {
    Assert.assertTrue(Schemas.hasGeneratedJavaClass(
        new Schema.Parser().parse(""{\""type\"": \""fixed\"", \""name\"": \""N\"", \""size\"": 10}"")));
    Assert.assertFalse(Schemas.hasGeneratedJavaClass(new Schema.Parser().parse(""{\""type\"": \""int\""}"")));
  }
",non-flaky,5
170484,eclipse_jetty.project,ConnectorServerTest.tearDown,"    @AfterEach
    public void tearDown() throws Exception
    {
        if (connectorServer != null)
            connectorServer.stop();
    }
",non-flaky,5
21000,NationalSecurityAgency_timely,DownsampleIteratorTest.simpleGetOneSample,"    @Test
    public void simpleGetOneSample() throws Exception {
        // check that data gets pulled out
        DownsampleIterator iter = new DownsampleIterator();
        Map<Set<Tag>, Downsample> samples = runQuery(iter, testData1, 100, -1);
        assertEquals(1, samples.size());
        for (Entry<Set<Tag>, Downsample> entry : samples.entrySet()) {
            Set<Tag> tags = entry.getKey();
            assertEquals(1, tags.size());
            assertEquals(Collections.singleton(new Tag(""host"", ""host1"")), tags);
            long ts = 0;
            for (Sample sample : entry.getValue()) {
                assertEquals(ts, sample.timestamp);
                ts += 100;
                assertEquals(0.2, sample.value, 0.0001);
            }
            assertEquals(1000, ts);
        }
    }
",non-flaky,5
33700,alibaba_fastjson,JSONScannerTest.checkTime6,"  @Test
  public void checkTime6() throws Throwable {

    // Arrange
    JSONScanner objectUnderTest = ((JSONScanner)Reflector.getInstance(""com.alibaba.fastjson.parser.JSONScanner""));
    objectUnderTest.hasSpecial = false;
    objectUnderTest.token = 0;
    objectUnderTest.locale = null;
    objectUnderTest.np = 0;
    objectUnderTest.features = 0;
    Reflector.setField(objectUnderTest, ""text"", """");
    objectUnderTest.calendar = null;
    objectUnderTest.matchStat = 0;
    objectUnderTest.bp = 0;
    Reflector.setField(objectUnderTest, ""len"", 0);
    objectUnderTest.stringDefaultValue = """";
    objectUnderTest.pos = 0;
    objectUnderTest.sp = 0;
    objectUnderTest.sbuf = null;
    objectUnderTest.ch = '\u0000';
    objectUnderTest.timeZone = null;
    objectUnderTest.eofPos = 0;
    char h0 = '0';
    char h1 = '9';
    char m0 = '1';
    char m1 = '\u0000';
    char s0 = '\u0000';
    char s1 = '\u0000';

    // Act
    Class<?> c = Reflector.forName(""com.alibaba.fastjson.parser.JSONScanner"");
    Method m = c.getDeclaredMethod(""checkTime"", Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""));
    m.setAccessible(true);
    boolean retval = (Boolean)m.invoke(objectUnderTest, h0, h1, m0, m1, s0, s1);

    // Assert result
    Assert.assertEquals(false, retval);

  }
",non-flaky,5
33736,alibaba_fastjson,FastJsonViewTest.test3,"    @Test
    public void test3() throws Exception {
        mockMvc.perform(
                (post(""/fastjsonview/test3"").characterEncoding(""UTF-8"")
                        .contentType(MediaType.APPLICATION_JSON))).andExpect(status
                ().isOk()).andDo(print()).andExpect(content().string(""{\""id\"":100,\""name\"":\""æµè¯\"",\""rootDepartment\"":{\""description\"":\""é¨é¨1æè¿°\""}}""));
    }
",non-flaky,5
84609,apache_zookeeper,ExportJvmInfoTest.doNotExportInfo,"    @Test
    public void doNotExportInfo() throws Exception {
        runTest(false);
    }
",non-flaky,5
110854,pushtorefresh_storio,QueryTest.queryLimitOffsetQuantity,"    @Test
    public void queryLimitOffsetQuantity() {
        final List<User> users = putUsersBlocking(10);

        final int offset = 5;
        final int quantity = 3;
        final List<User> usersFromQuery = storIOSQLite
                .get()
                .listOfObjects(User.class)
                .withQuery(Query.builder()
                        .table(UserTableMeta.TABLE)
                        .orderBy(UserTableMeta.COLUMN_EMAIL)
                        .limit(offset, quantity)
                        .build())
                .prepare()
                .executeAsBlocking();

        assertThat(usersFromQuery).isNotNull();
        assertThat(usersFromQuery).hasSize(Math.min(quantity, users.size() - offset));

        Collections.sort(users);

        int position = 0;
        for (int i = offset; i < offset + quantity; i++) {
            assertThat(usersFromQuery.get(position++)).isEqualTo(users.get(i));
        }
    }
",non-flaky,5
114111,aws_aws-sdk-java-v2,InstantAsStringAttributeConvertersTest.InstantAsStringAttributeConverterEpochPlusOneMilliTest,"    @Test
    public void InstantAsStringAttributeConverterEpochPlusOneMilliTest() {
        verifyTransform(Instant.EPOCH.plusMillis(1), ""1970-01-01T00:00:00.001Z"");
    }
",non-flaky,5
89337,apache_samza,TestKafkaSystemAdminJava.testClearStream,"  @Test
  public void testClearStream() {
    StreamSpec spec = new StreamSpec(""testId"", ""testStreamClear"", ""testSystem"", 8);

    KafkaSystemAdmin admin = systemAdmin();
    String topicName = spec.getPhysicalName();

    assertTrue(""createStream should return true if the stream does not exist and then is created."", admin.createStream(spec));
    // validate topic exists
    assertTrue(admin.clearStream(spec));

    // validate that topic was removed
    DescribeTopicsResult dtr = admin.adminClient.describeTopics(ImmutableSet.of(topicName));
    try {
      TopicDescription td = dtr.all().get().get(topicName);
      Assert.fail(""topic "" + topicName + "" should've been removed. td="" + td);
    } catch (Exception e) {
      if (!(e.getCause() instanceof org.apache.kafka.common.errors.UnknownTopicOrPartitionException)) {
        Assert.fail(""topic "" + topicName + "" should've been removed. Expected UnknownTopicOrPartitionException."");
      }
    }
  }
",non-flaky,5
97967,ReactiveX_RxJava,ObservableTests.testCountAFewItems,"    @Test
    public void testCountAFewItems() {
        Observable<String> observable = Observable.from(""a"", ""b"", ""c"", ""d"");
        observable.count().subscribe(w);
        // we should be called only once
        verify(w, times(1)).onNext(anyInt());
        verify(w).onNext(4);
        verify(w, never()).onError(any(Throwable.class));
        verify(w, times(1)).onCompleted();
    }
",non-flaky,5
177201,line_armeria,SpringTomcatApplicationItTest.verifySingleConnector,"    @Test
    public void verifySingleConnector() {
        // Relevant to Tomcat 9.0
        assertThat(applicationContext).isInstanceOf(WebServerApplicationContext.class);
        final WebServer webServer = ((WebServerApplicationContext) applicationContext).getWebServer();
        assertThat(webServer).isInstanceOf(TomcatWebServer.class);
        assertThat(((TomcatWebServer) webServer).getTomcat()
                                                .getEngine()
                                                .getService()
                                                .findConnectors()).hasSize(1);
    }
",non-flaky,5
59601,looly_hutool,ArchiverTest.tarTest,"	@Test
	public void tarTest(){
		final File file = FileUtil.file(""d:/test/compress/test.tar"");
		StreamArchiver.create(CharsetUtil.CHARSET_UTF_8, ArchiveStreamFactory.TAR, file)
				.add(FileUtil.file(""d:/Java""), (f)->{
					Console.log(""Add: {}"", f.getPath());
					return true;
				})
				.finish().close();
	}
",non-flaky,5
38234,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRowColumnSelection,"    @Test
    public void testGetRowColumnSelection() {
        Cell cell1 = Cell.create(PtBytes.toBytes(""row""), PtBytes.toBytes(""col1""));
        Cell cell2 = Cell.create(PtBytes.toBytes(""row""), PtBytes.toBytes(""col2""));
        Cell cell3 = Cell.create(PtBytes.toBytes(""row""), PtBytes.toBytes(""col3""));
        byte[] val = PtBytes.toBytes(""val"");

        keyValueService.put(TEST_TABLE, ImmutableMap.of(cell1, val, cell2, val, cell3, val), 0);

        Map<Cell, Value> rows1 = keyValueService.getRows(
                TEST_TABLE,
                ImmutableSet.of(cell1.getRowName()),
                ColumnSelection.all(),
                1);
        Assert.assertEquals(ImmutableSet.of(cell1, cell2, cell3), rows1.keySet());

        Map<Cell, Value> rows2 = keyValueService.getRows(
                TEST_TABLE,
                ImmutableSet.of(cell1.getRowName()),
                ColumnSelection.create(ImmutableList.of(cell1.getColumnName())),
                1);
        assertEquals(ImmutableSet.of(cell1), rows2.keySet());

        Map<Cell, Value> rows3 = keyValueService.getRows(
                TEST_TABLE,
                ImmutableSet.of(cell1.getRowName()),
                ColumnSelection.create(ImmutableList.of(cell1.getColumnName(), cell3.getColumnName())),
                1);
        assertEquals(ImmutableSet.of(cell1, cell3), rows3.keySet());
        Map<Cell, Value> rows4 = keyValueService.getRows(
                TEST_TABLE,
                ImmutableSet.of(cell1.getRowName()),
                ColumnSelection.create(ImmutableList.<byte[]>of()),
                1);

        // This has changed recently - now empty column set means
        // that all columns are selected.
        assertEquals(ImmutableSet.of(cell1, cell2, cell3), rows4.keySet());
    }
",non-flaky,5
26235,Ericsson_ecchronos,TestTableRepairJob.testPrevalidateNotRepairableThenRepairable,"    @Test
    public void testPrevalidateNotRepairableThenRepairable()
    {
        // mock
        doReturn(false).doReturn(true).when(myRepairStateSnapshot).canRepair();

        assertThat(myRepairJob.runnable()).isFalse();
        assertThat(myRepairJob.runnable()).isTrue();

        verify(myRepairState, times(2)).update();
        verify(myRepairStateSnapshot, times(2)).canRepair();
    }
",non-flaky,5
122573,vespa-engine_vespa,MakeDirectoryTest.okIfParentExists,"    @Test
    public void okIfParentExists() {
        String path = ""/dir"";
        MakeDirectory makeDirectory = new MakeDirectory(fileSystem.getPath(path));
        assertTrue(makeDirectory.converge(context));
        assertTrue(Files.isDirectory(fileSystem.getPath(path)));

        MakeDirectory makeDirectory2 = new MakeDirectory(fileSystem.getPath(path));
        assertFalse(makeDirectory2.converge(context));
    }
",non-flaky,5
13834,neo4j_neo4j,ResponsePackerTest.obligation,"    @Test
    public void shouldHaveFixedTargetTransactionIdEvenIfLastTransactionIdIsMoving() throws Exception
    {
        // GIVEN
        LogicalTransactionStore transactionStore = mock( LogicalTransactionStore.class );
        long lastAppliedTransactionId = 5L;
        IOCursor<CommittedTransactionRepresentation> endlessCursor = new EndlessCursor( lastAppliedTransactionId+1 );
        when( transactionStore.getTransactions( anyLong() ) ).thenReturn( endlessCursor );
        final long targetTransactionId = 8L;
        final TransactionIdStore transactionIdStore = new DeadSimpleTransactionIdStore( targetTransactionId, 0 );
        ResponsePacker packer = new ResponsePacker( transactionStore, transactionIdStore,
                singletonProvider( new StoreId() ) );

        // WHEN
        Response<Object> response = packer.packTransactionStreamResponse( requestContextStartingAt( 5L ), null );
        final AtomicLong nextExpectedVisit = new AtomicLong( lastAppliedTransactionId );
        response.accept( new Response.Handler()
        {
            @Override
            public void obligation( long txId ) throws IOException
            {
                fail( ""Should not be called"" );
            }
",non-flaky,5
113975,apache_struts,NamedVariablePatternMatcherTest.testCompile,"    @Test
    public void testCompile() {
        NamedVariablePatternMatcher matcher = new NamedVariablePatternMatcher();

        assertNull(matcher.compilePattern(null));
        assertNull(matcher.compilePattern(""""));

        CompiledPattern pattern = matcher.compilePattern(""foo"");
        assertEquals(""foo"", pattern.getPattern().pattern());

        pattern = matcher.compilePattern(""foo{jim}"");
        assertEquals(""foo([^/]+)"", pattern.getPattern().pattern());
        assertEquals(""jim"", pattern.getVariableNames().get(0));

        pattern = matcher.compilePattern(""foo{jim}/{bob}"");
        assertEquals(""foo([^/]+)/([^/]+)"", pattern.getPattern().pattern());
        assertEquals(""jim"", pattern.getVariableNames().get(0));
        assertEquals(""bob"", pattern.getVariableNames().get(1));
        assertTrue(pattern.getPattern().matcher(""foostar/jie"").matches());
        assertFalse(pattern.getPattern().matcher(""foo/star/jie"").matches());
    }
",non-flaky,5
13892,neo4j_neo4j,HaBeanIT.testAfterHardMasterSwitchClusterInfoIsCorrect,"    @Test
    public void testAfterHardMasterSwitchClusterInfoIsCorrect() throws Throwable
    {
        startCluster( 3 );
        RepairKit masterShutdown = cluster.fail( cluster.getMaster() );
        cluster.await( ClusterManager.masterAvailable() );
        cluster.await( ClusterManager.masterSeesSlavesAsAvailable( 1 ) );
        for ( HighlyAvailableGraphDatabase db : cluster.getAllMembers() )
        {
            if ( db.getInstanceState() == HighAvailabilityMemberState.PENDING )
            {
                continue;
            }
            // Instance that was hard killed will still be in the cluster
            assertEquals( 3, ha( db ).getInstancesInCluster().length );
        }
        masterShutdown.repair();
        cluster.await( ClusterManager.masterAvailable() );
        cluster.await( ClusterManager.masterSeesSlavesAsAvailable( 2 ) );
        for ( HighlyAvailableGraphDatabase db : cluster.getAllMembers() )
        {
            int mastersFound = 0;
            HighAvailability bean = ha( db );

            assertEquals( 3, bean.getInstancesInCluster().length );
            for ( ClusterMemberInfo info : bean.getInstancesInCluster() )
            {
                assertTrue( bean.getInstanceId() + "": every instance should be available: "" + info.getInstanceId(),
                        info.isAvailable() );
                for ( String role : info.getRoles() )
                {
                    if (role.equals( HighAvailabilityModeSwitcher.MASTER ))
                    {
                        mastersFound++;
                    }
                }
            }
            assertEquals( 1, mastersFound );
        }
    }
",non-flaky,5
112091,apache_shardingsphere-elasticjob,AverageAllocationJobShardingStrategyTest.shardingForServersLessThanShardingCountAliquantFor8ShardingCountAnd3Servers,"    @Test
    public void shardingForServersLessThanShardingCountAliquantFor8ShardingCountAnd3Servers() {
        Map<JobInstance, List<Integer>> expected = new LinkedHashMap<>(3, 1);
        expected.put(new JobInstance(""host0@-@0""), Arrays.asList(0, 1, 6));
        expected.put(new JobInstance(""host1@-@0""), Arrays.asList(2, 3, 7));
        expected.put(new JobInstance(""host2@-@0""), Arrays.asList(4, 5));
        assertThat(jobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""test_job"", 8), is(expected));
    }
",non-flaky,5
133952,CorfuDB_CorfuDB,BaseHandlerTest.testHandleBootstrappedError,"    @Test
    public void testHandleBootstrappedError() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getBootstrappedErrorMsg()
        );

        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed exceptionally (once)
        // with the expected exception
        verify(mockClientRouter, never()).completeRequest(anyLong(), any());
        verify(mockClientRouter).completeExceptionally(
                eq(response.getHeader().getRequestId()), any(AlreadyBootstrappedException.class));
    }
",non-flaky,5
98040,vert-x3_vertx-mongo-client,AggregateOptionsTest.testOptionsJson,"  @Test
  public void testOptionsJson() {
    JsonObject json = new JsonObject();

    long maxAwaitTime = TestUtils.randomLong();
    json.put(""maxAwaitTime"", maxAwaitTime);

    long maxTime = TestUtils.randomLong();
    json.put(""maxTime"", maxTime);

    AggregateOptions options = new AggregateOptions(json);
    assertEquals(maxTime, options.getMaxTime());
  }
",non-flaky,5
76997,Tencent_Firestorm,CoordinatorGrpcTest.rpcMetricsTest,"  @Test
  public void rpcMetricsTest() throws Exception{
    String appId = ""rpcMetricsTest"";
    double oldValue = coordinators.get(0).getGrpcMetrics().getCounterMap()
        .get(CoordinatorGrpcMetrics.HEARTBEAT_METHOD).get();
    CoordinatorTestUtils.waitForRegister(coordinatorClient,2);
    double newValue = coordinators.get(0).getGrpcMetrics().getCounterMap()
        .get(CoordinatorGrpcMetrics.HEARTBEAT_METHOD).get();
    assertTrue(newValue - oldValue > 1);
    assertEquals(0,
        coordinators.get(0).getGrpcMetrics().getGaugeMap()
            .get(CoordinatorGrpcMetrics.HEARTBEAT_METHOD).get(), 0.5);

    RssGetShuffleAssignmentsRequest request = new RssGetShuffleAssignmentsRequest(
        appId, 1, 10, 4, 1,
        Sets.newHashSet(Constants.SHUFFLE_SERVER_VERSION));
    oldValue = coordinators.get(0).getGrpcMetrics().getCounterMap()
        .get(CoordinatorGrpcMetrics.GET_SHUFFLE_ASSIGNMENTS_METHOD).get();
    coordinatorClient.getShuffleAssignments(request);
    newValue = coordinators.get(0).getGrpcMetrics().getCounterMap()
        .get(CoordinatorGrpcMetrics.GET_SHUFFLE_ASSIGNMENTS_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        coordinators.get(0).getGrpcMetrics().getGaugeMap()
            .get(CoordinatorGrpcMetrics.GET_SHUFFLE_ASSIGNMENTS_METHOD).get(), 0.5);
  }
",non-flaky,5
33724,alibaba_fastjson,TestIssue1763_2.testBug1763_2,"    @Test
    public void testBug1763_2() {
        BaseResult<PageResult<CouponResult>> data = JSON.parseObject(jsonStr, new TypeReferenceBug1763_2<BaseResult<PageResult<T>>>(clazz){}.getType());

        Assert.assertTrue(data.isSuccess());
        Assert.assertTrue(data.getContent().getList().size() == 2);
        try {
            data.getContent().getList().get(0).getId();
        } catch (Throwable ex) {
            Assert.assertEquals(ex.getCause() instanceof ClassCastException, false);
        }
    }
",non-flaky,5
26777,MundaneImmortal_pair-distribution-app,CompanyTest.testGetCompanyNameWithUpperCase,"	@Test
	public void testGetCompanyNameWithUpperCase() {
		assertThat(new Company(""COMPANY"").getName(), is(""company""));
	}
",non-flaky,5
59625,looly_hutool,JschUtilTest.reconnectIfTimeoutTest,"	@Test
	public void reconnectIfTimeoutTest() throws InterruptedException {
		Session session = JschUtil.getSession(""sunnyserver"", 22,""mysftp"",""liuyang1234"");
		Sftp sftp = JschUtil.createSftp(session);

		Console.log(""æå°pwd: "" + sftp.pwd());
		Console.log(""cd / : "" + sftp.cd(""/""));
		Console.log(""ä¼ç ä¸æ®µæ¶é´ï¼æ¥çæ¯å¦è¶æ¶"");
		Thread.sleep(30 * 1000);

		try{
			// å½è¿æ¥è¶æ¶æ¶ï¼isConnected()ä»ç¶è¿åtrueï¼pwdå½ä»¤ä¹è½æ­£å¸¸è¿åï¼å æ­¤ï¼å©ç¨åécdå½ä»¤çè¿åç»æï¼æ¥å¤æ­æ¯å¦è¿æ¥è¶æ¶
			Console.log(""isConnected "" + sftp.getClient().isConnected());
			Console.log(""æå°pwd: "" + sftp.pwd());
			Console.log(""cd / : "" + sftp.cd(""/""));
		}catch (JschRuntimeException e) {
			e.printStackTrace();
		}

		Console.log(""è°ç¨reconnectIfTimeoutæ¹æ³ï¼å¤æ­æ¯å¦è¶æ¶å¹¶éè¿"");
		sftp.reconnectIfTimeout();

		Console.log(""æå°pwd: "" + sftp.pwd());

		IoUtil.close(sftp);
	}
",non-flaky,5
162432,testcontainers_testcontainers-java,GenericContainerRuleTest.failFastWhenContainerHaltsImmediately,"    @Test @Ignore //TODO investigate intermittent failures
    public void failFastWhenContainerHaltsImmediately() throws Exception {

        long startingTimeMs = System.currentTimeMillis();
        final GenericContainer failsImmediately = new GenericContainer(""alpine:3.2"")
              .withCommand(""/bin/sh"", ""-c"", ""return false"")
              .withMinimumRunningDuration(Duration.ofMillis(100));

        try {
            assertThrows(
                  ""When we start a container that halts immediately, an exception is thrown"",
                  RetryCountExceededException.class,
                  () -> {
                      failsImmediately.start();
                      return null;
                  });

            // Check how long it took, to verify that we ARE bailing out early.
            // Want to strike a balance here; too short and this test will fail intermittently
            // on slow systems and/or due to GC variation, too long and we won't properly test
            // what we're intending to test.
            int allowedSecondsToFailure =
                GenericContainer.CONTAINER_RUNNING_TIMEOUT_SEC / 2;
            long completedTimeMs = System.currentTimeMillis();
            assertTrue(""container should not take long to start up"",
                  completedTimeMs - startingTimeMs < 1000L * allowedSecondsToFailure);
        } finally {
            failsImmediately.stop();
        }
    }
",non-flaky,5
77131,networknt_json-schema-validator,Issue342Test.propertyNameEnumShouldFailV7,"    @Test
    public void propertyNameEnumShouldFailV7() throws Exception {
        String schemaPath = ""/schema/issue342-v7.json"";
        String dataPath = ""/data/issue342.json"";
        InputStream schemaInputStream = getClass().getResourceAsStream(schemaPath);
        JsonSchema schema = getJsonSchemaFromStreamContentV7(schemaInputStream);
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);
        Set<ValidationMessage> errors = schema.validate(node);
        Assertions.assertEquals(1, errors.size());
        final ValidationMessage error = errors.iterator().next();
        Assertions.assertEquals(""$.z"", error.getPath());
        Assertions.assertEquals(""Property name $.z is not valid for validation: does not have a value in the enumeration [a, b, c]"", error.getMessage());
    }
",non-flaky,5
134981,undertow-io_undertow,WebsocketBasicAuthTestCase.beforeRequest,"    @Test
    public void testAuthenticatedWebsocket() throws Exception {
        ProgramaticClientEndpoint endpoint = new ProgramaticClientEndpoint();
        ClientEndpointConfig clientEndpointConfig = ClientEndpointConfig.Builder.create().configurator(new ClientConfigurator(){
            @Override
            public void beforeRequest(Map<String, List<String>> headers) {
                headers.put(AUTHORIZATION.toString(), Collections.singletonList(BASIC + "" "" + FlexBase64.encodeString(""user1:password1"".getBytes(), false)));
            }
",non-flaky,5
113934,spring-projects_spring-data-couchbase,CouchbaseTemplateQueryCollectionIntegrationTests.testScopeCollectionRepoWith,"	@Test
	public void testScopeCollectionRepoWith() {
		UserCol user = new UserCol(""1"", ""Dave"", ""Wilson"");
		Query query = Query.query(QueryCriteria.where(""firstname"").is(user.getFirstname()));
		try {
			UserCol saved = couchbaseTemplate.insertById(UserCol.class).inScope(scopeName).inCollection(collectionName)
					.one(user);
			List<UserCol> found = couchbaseTemplate.findByQuery(UserCol.class)
					.withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(scopeName).inCollection(collectionName)
					.matching(query).all();
			assertEquals(saved, found.get(0), ""should have found what was saved"");
			List<UserCol> notfound = couchbaseTemplate.findByQuery(UserCol.class).inScope(CollectionIdentifier.DEFAULT_SCOPE)
					.inCollection(CollectionIdentifier.DEFAULT_COLLECTION).matching(query).all();
			assertEquals(0, notfound.size(), ""should not have found what was saved"");
			couchbaseTemplate.removeByQuery(UserCol.class).inScope(scopeName).inCollection(collectionName).matching(query)
					.all();
		} finally {
			try {
				couchbaseTemplate.removeByQuery(UserCol.class).inScope(scopeName).inCollection(collectionName).matching(query)
						.all();
			} catch (DataRetrievalFailureException drfe) {}
		}
	}
",non-flaky,5
175744,GoogleCloudPlatform_google-cloud-eclipse,AppEngineDeployPreferencesPanelTest.testAutoSelectSingleAccount,"  @Test
  public void testAutoSelectSingleAccount() {
    when(loginService.getAccounts()).thenReturn(oneAccountSet);
    deployPanel = createPanel(true /* requireValues */);
    assertThat(deployPanel.getSelectedCredential(), is(credential));

    // verify not in error
    IStatus status = getAccountSelectorValidationStatus();
    assertTrue(""account selector is in error: "" + status.getMessage(), status.isOK());

    assertThat(""auto-selected value should be propagated back to model"",
        deployPanel.model.getAccountEmail(), is(account1.getEmail()));
  }
",non-flaky,5
91441,strapdata_elassandra,PackageTestCase.onlyCompatibleDistributions,"@TestCaseOrdering(TestCaseOrdering.AlphabeticOrder.class)
    public void onlyCompatibleDistributions() {
        assumeTrue(""only compatible distributions"", distribution().packaging.compatible);
    }
",non-flaky,5
99729,apache_cassandra,FQLReplayTest.testCompareRowsDifferentContent,"    @Test
    public void testCompareRowsDifferentContent()
    {
        ResultComparator rc = new ResultComparator();
        ResultHandler.ComparableResultSet res = createResultSet(10, 10, false);
        ResultHandler.ComparableResultSet res2 = createResultSet(10, 10, false);
        List<ResultHandler.ComparableResultSet> toCompare = Lists.newArrayList(res, res2, createResultSet(10, 10, true));
        List<Iterator<ResultHandler.ComparableRow>> iters = toCompare.stream().map(Iterable::iterator).collect(Collectors.toList());
        while (true)
        {
            List<ResultHandler.ComparableRow> rows = ResultHandler.rows(iters);
            if (rows.stream().allMatch(Objects::isNull))
                break;
            assertFalse(rows.toString(), rc.compareRows(Lists.newArrayList(""eq1"", ""eq2"", ""diff""), null, rows));
        }
    }
",non-flaky,5
358,OryxProject_oryx,ALSServingInputProducerIT.testALSInputProducer,"@Test
public void testALSInputProducer() throws Exception {
    Map<String, Object> overlayConfig = new HashMap<>();
    overlayConfig.put(""oryx.serving.application-resources"", ""\""com.cloudera.oryx.app.serving,com.cloudera.oryx.app.serving.als\"""");
    overlayConfig.put(""oryx.serving.model-manager-class"", ALSServingModelManager.class.getName());
    Config config = ConfigUtils.overlayOn(overlayConfig, getConfig());
    startMessaging();
    startServer(config);
    @SuppressWarnings(""unchecked"")
    TopicProducer<String, String> inputProducer = ((TopicProducer<String, String>) (getServingLayer().getContext().getServletContext().getAttribute(INPUT_PRODUCER_KEY)));
    String[] inputs = new String[]{ ""abc,123,1.5"", ""xyz,234,-0.5"", ""AB,10,0"" };
    List<Pair<String, String>> keyMessages;
    try (final CloseableIterator<Pair<String, String>> data = new ConsumeData(INPUT_TOPIC, getZKPort()).iterator()) {
        log.info(""Starting consumer thread"");
        ConsumeTopicRunnable consumeInput = new ConsumeTopicRunnable(data);
        new Thread(consumeInput).start();
        Thread.sleep(3000);
        for (String input : inputs) {
            inputProducer.send("""", input);
        }
        Thread.sleep(1000);
        keyMessages = consumeInput.getKeyMessages();
    }
    for (int i = 0; i < keyMessages.size(); i++) {
        Pair<String, String> keyMessage = keyMessages.get(i);
        assertEquals("""", keyMessage.getFirst());
        assertEquals(inputs[i], keyMessage.getSecond());
    }
    assertEquals(inputs.length, keyMessages.size());
}",async wait,0
43088,trinodb_trino,AbstractTestIntegrationSmokeTest.testInListPredicate,"    @Test
    public void testInListPredicate()
    {
        assertQueryReturnsEmptyResult(""SELECT * FROM orders WHERE orderkey IN (10, 11, 20, 21)"");

        // filtered column is selected
        assertQuery(""SELECT custkey, orderkey FROM orders WHERE orderkey IN (7, 10, 32, 33)"", ""VALUES (392, 7), (1301, 32), (670, 33)"");

        // filtered column is not selected
        assertQuery(""SELECT custkey FROM orders WHERE orderkey IN (7, 10, 32, 33)"", ""VALUES (392), (1301), (670)"");
    }
",non-flaky,5
20991,NationalSecurityAgency_timely,MetaKeySetTest.testContents,"    @Test
    public void testContents() {
        Meta one = new Meta(""sys.cpu.user"", ""tag1"", ""value1"");
        Meta two = new Meta(""sys.cpu.user"", ""tag2"", ""value2"");
        Meta three = new Meta(""sys.cpu.user"", ""tag3"", ""value3"");
        MetaKeySet mks = new MetaKeySet();
        mks.addAll(one.toKeys());
        mks.addAll(two.toKeys());
        mks.addAll(three.toKeys());
        Assert.assertEquals(7, mks.size());
        Assert.assertTrue(mks.contains(new Key(""m:sys.cpu.user"")));
        Assert.assertTrue(mks.contains(new Key(""t:sys.cpu.user"", ""tag1"")));
        Assert.assertTrue(mks.contains(new Key(""t:sys.cpu.user"", ""tag2"")));
        Assert.assertTrue(mks.contains(new Key(""t:sys.cpu.user"", ""tag3"")));
        Assert.assertTrue(mks.contains(new Key(""v:sys.cpu.user"", ""tag1"", ""value1"")));
        Assert.assertTrue(mks.contains(new Key(""v:sys.cpu.user"", ""tag2"", ""value2"")));
        Assert.assertTrue(mks.contains(new Key(""v:sys.cpu.user"", ""tag3"", ""value3"")));
    }
",non-flaky,5
122580,vespa-engine_vespa,EditorTest.testEdit,"    @Test
    public void testEdit() {
        path.writeUtf8File(joinLines(""first"", ""second"", ""third""));

        LineEditor lineEditor = mock(LineEditor.class);
        when(lineEditor.edit(any())).thenReturn(
                LineEdit.none(), // don't edit the first line
                LineEdit.remove(), // remove the second
                LineEdit.replaceWith(""replacement"")); // replace the third

        Editor editor = new Editor(path.toPath(), lineEditor);
        TaskContext context = mock(TaskContext.class);

        assertTrue(editor.converge(context));

        verify(lineEditor, times(3)).edit(any());

        // Verify the system modification message
        ArgumentCaptor<String> modificationMessage = ArgumentCaptor.forClass(String.class);
        verify(context).recordSystemModification(any(), modificationMessage.capture());
        assertEquals(
                ""Patching file /file:\n-second\n-third\n+replacement\n"",
                modificationMessage.getValue());

        // Verify the new contents of the file:
        assertEquals(joinLines(""first"", ""replacement""), path.readUtf8File());
    }
",non-flaky,5
328,spring-projects_spring-data-couchbase,MappingCouchbaseConverterTests.writesAndReadsClassContainingCustomConvertedObjects,"@Test
void writesAndReadsClassContainingCustomConvertedObjects() {
    List<Object> converters = new ArrayList<>();
    converters.add(BigDecimalToStringConverter.INSTANCE);
    converters.add(StringToBigDecimalConverter.INSTANCE);
    CustomConversions customConversions = new CouchbaseCustomConversions(converters);
    converter.setCustomConversions(customConversions);
    converter.afterPropertiesSet();
    ((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(customConversions.getSimpleTypeHolder());
    CouchbaseDocument converted = new CouchbaseDocument();
    final String weightStr = ""12.34"";
    final BigDecimal weight = new BigDecimal(weightStr);
    final CustomObject addy = new CustomObject(weight);
    List<CustomObject> listOfObjects = new ArrayList<>();
    listOfObjects.add(addy);
    Map<String, CustomObject> mapOfObjects = new HashMap<>();
    mapOfObjects.put(""obj0"", addy);
    mapOfObjects.put(""obj1"", addy);
    CustomObjectEntity entity = new CustomObjectEntity(addy, listOfObjects, mapOfObjects);
    converter.write(entity, converted);
    CouchbaseDocument source = new CouchbaseDocument();
    source.put(""_class"", CustomObjectEntity.class.getName());
    CouchbaseDocument objectDoc = new CouchbaseDocument();
    objectDoc.put(""weight"", weightStr);
    source.put(""object"", objectDoc);
    CouchbaseList listOfObjectsDoc = new CouchbaseList();
    listOfObjectsDoc.put(objectDoc);
    source.put(""listOfObjects"", listOfObjectsDoc);
    CouchbaseDocument mapOfObjectsDoc = new CouchbaseDocument();
    mapOfObjectsDoc.put(""obj0"", objectDoc);
    mapOfObjectsDoc.put(""obj1"", objectDoc);
    source.put(""mapOfObjects"", mapOfObjectsDoc);
    assertThat(converted.export().toString()).isEqualTo(source.export().toString());
    CustomObjectEntity readConverted = converter.read(CustomObjectEntity.class, source);
    assertThat(readConverted.object.weight).isEqualTo(addy.weight);
    assertThat(readConverted.listOfObjects.get(0).weight).isEqualTo(listOfObjects.get(0).weight);
    assertThat(readConverted.mapOfObjects.get(""obj0"").weight).isEqualTo(mapOfObjects.get(""obj0"").weight);
    assertThat(readConverted.mapOfObjects.get(""obj1"").weight).isEqualTo(mapOfObjects.get(""obj1"").weight);
}",unordered collections,3
77544,dropwizard_dropwizard,ResourceTestRuleTest.testDefaultConstraintViolation,"    @Test
    public void testDefaultConstraintViolation() {
        assertThat(resourceTestRule.target(""/person/blah/index"")
                .queryParam(""ind"", -1).request()
                .get().readEntity(String.class))
                .isEqualTo(""{\""errors\"":[\""query param ind must be greater than or equal to 0\""]}"");
    }
",non-flaky,5
43055,trinodb_trino,BaseConnectorTest.testSelectAll,"    @Test
    public void testSelectAll()
    {
        assertQuery(""SELECT * FROM orders"");
    }
",non-flaky,5
30966,camunda-cloud_zeebe,POJOArrayTest.shouldDeserializePOJO,"  @Test
  public void shouldDeserializePOJO() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(3);
              encodeSimpleArrayProp(w);

              w.writeString(wrapString(""emptyDefaultArray""));
              w.writeArrayHeader(1);

              w.writeMapHeader(1);
              w.writeString(wrapString(""longProp""));
              w.writeInteger(753L);

              w.writeString(wrapString(""notEmptyDefaultArray""));
              w.writeArrayHeader(0);
            });

    // when
    pojo.wrap(buffer);

    // then
    final Iterator<MinimalPOJO> iterator1 = pojo.simpleArray().iterator();
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(123L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(456L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(789L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(555L);
    assertThat(iterator1.hasNext()).isTrue();
    assertThat(iterator1.next().getLongProp()).isEqualTo(777L);
    assertThat(iterator1.hasNext()).isFalse();
  }
",non-flaky,5
136499,doanduyhai_Achilles,FrozenNestedTypeStrategyTest.should_fail_for_non_frozen_udtValue,"    @Test
    public void should_fail_for_non_frozen_udtValue() throws Exception {
        setExec(aptUtils -> {
            final NestedTypeValidator2_1 strategy = new NestedTypeValidator2_1();
            final String className = TestEntityWithNestedTypes.class.getCanonicalName();
            final TypeName rawClass = ClassName.get(TestEntityWithNestedTypes.class);
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            // private UDTValue udtValue;
            VariableElement elm = findFieldInType(typeElement, ""udtValue"");
            final AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils, globalParsingContext, elm);
            strategy.validate(aptUtils, annotationTree, ""udtValue"", rawClass);
        });
        failTestWithMessage(""UDTValue "" +
                ""in field 'udtValue' "" +
                ""of class 'info.archinnov.achilles.internals.sample_classes.parser.strategy.TestEntityWithNestedTypes' "" +
                ""should be annotated with @Frozen"", TestEntityWithNestedTypes.class);
    }
",non-flaky,5
38643,apache_pulsar,TestPropertiesFileConfigurationProvider.testPropertyRead,"    @Test
    public void testPropertyRead() {

        FlumeConfiguration configuration = provider.getFlumeConfiguration();
        assertNotNull(configuration);

    /*
     * Test the known errors in the file
     */
        List<String> expected = Lists.newArrayList();
        expected.add(""host5 CONFIG_ERROR"");
        expected.add(""host5 INVALID_PROPERTY"");
        expected.add(""host4 CONFIG_ERROR"");
        expected.add(""host4 CONFIG_ERROR"");
        expected.add(""host4 PROPERTY_VALUE_NULL"");
        expected.add(""host4 PROPERTY_VALUE_NULL"");
        expected.add(""host4 PROPERTY_VALUE_NULL"");
        expected.add(""host4 AGENT_CONFIGURATION_INVALID"");
        expected.add(""ch2 ATTRS_MISSING"");
        expected.add(""host3 CONFIG_ERROR"");
        expected.add(""host3 PROPERTY_VALUE_NULL"");
        expected.add(""host3 AGENT_CONFIGURATION_INVALID"");
        expected.add(""host2 PROPERTY_VALUE_NULL"");
        expected.add(""host2 AGENT_CONFIGURATION_INVALID"");
        List<String> actual = Lists.newArrayList();
        for (FlumeConfigurationError error : configuration.getConfigurationErrors()) {
            actual.add(error.getComponentName() + "" "" + error.getErrorType().toString());
        }
        Collections.sort(expected);
        Collections.sort(actual);
        assertEquals(actual, expected);

        AgentConfiguration agentConfiguration =
                configuration.getConfigurationFor(""host1"");
        assertNotNull(agentConfiguration);

        LOGGER.info(agentConfiguration.getPrevalidationConfig());
        LOGGER.info(agentConfiguration.getPostvalidationConfig());

        Set<String> sources = Sets.newHashSet(""source1"");
        Set<String> sinks = Sets.newHashSet(""sink1"");
        Set<String> channels = Sets.newHashSet(""channel1"");

        assertEquals(agentConfiguration.getSourceSet(), sources);
        assertEquals(agentConfiguration.getSinkSet(), sinks);
        assertEquals(agentConfiguration.getChannelSet(), channels);
    }
",non-flaky,5
60896,apache_druid,KafkaEmitterConfigTest.testJacksonModules,"  @Test
  public void testJacksonModules()
  {
    Assert.assertTrue(new KafkaEmitterModule().getJacksonModules().isEmpty());
  }
",non-flaky,5
42973,fabiomaffioletti_jsondoc,ApiDocTest.testApiDoc,"	@Test
	public void testApiDoc() {
		Set<Class<?>> classes = new HashSet<Class<?>>();
		classes.add(TestController.class);
		ApiDoc apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""test-controller"", apiDoc.getName());
		Assert.assertEquals(""a-test-controller"", apiDoc.getDescription());
		Assert.assertEquals(""1.0"", apiDoc.getSupportedversions().getSince());
		Assert.assertEquals(""2.12"", apiDoc.getSupportedversions().getUntil());
		Assert.assertEquals(ApiAuthType.NONE.name(), apiDoc.getAuth().getType());
		Assert.assertEquals(DefaultJSONDocScanner.ANONYMOUS, apiDoc.getAuth().getRoles().get(0));

		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			
			if (apiMethodDoc.getPath().contains(""/name"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""string"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""string"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				Assert.assertEquals(""200 - OK"", apiMethodDoc.getResponsestatuscode());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""name"")) {
						Assert.assertEquals(""string"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}

			if (apiMethodDoc.getPath().contains(""/age"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""204"", apiMethodDoc.getResponsestatuscode());
				Assert.assertEquals(""integer"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""integer"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""age"")) {
						Assert.assertEquals(""integer"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}

			if (apiMethodDoc.getPath().contains(""/avg"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""long"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""long"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""avg"")) {
						Assert.assertEquals(""long"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}

			if (apiMethodDoc.getPath().contains(""/map"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""map[string, integer]"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""map[string, integer]"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""map"")) {
						Assert.assertEquals(""map[string, integer]"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}

			if (apiMethodDoc.getPath().contains(""/parametrizedList"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""list of string"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""list of string"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""parametrizedList"")) {
						Assert.assertEquals(""list of string"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
				
			}

			if (apiMethodDoc.getPath().contains(""/wildcardParametrizedList"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""list of wildcard"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""list of wildcard"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""wildcardParametrizedList"")) {
						Assert.assertEquals(""list of wildcard"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}

			if (apiMethodDoc.getPath().contains(""/LongArray"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""array of long"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""array of long"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""LongArray"")) {
						Assert.assertEquals(""array of long"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}

			if (apiMethodDoc.getPath().contains(""/longArray"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""array of long"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
				Assert.assertEquals(""array of long"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
				for (ApiParamDoc apiParamDoc : apiMethodDoc.getPathparameters()) {
					if(apiParamDoc.getName().equals(""longArray"")) {
						Assert.assertEquals(""array of long"", apiParamDoc.getJsondocType().getOneLineText());
					}
				}
			}
			
			if (apiMethodDoc.getPath().contains(""/version"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""1.0"", apiMethodDoc.getSupportedversions().getSince());
				Assert.assertEquals(""2.12"", apiMethodDoc.getSupportedversions().getUntil());
			}
			
			if (apiMethodDoc.getPath().contains(""/child"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""child"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
			}
			
			if (apiMethodDoc.getPath().contains(""/pizza"")) {
				Assert.assertEquals(ApiVerb.GET, apiMethodDoc.getVerb().iterator().next());
				Assert.assertEquals(""customPizzaObject"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
			}
			
			if (apiMethodDoc.getPath().contains(""/multiple-request-methods"")) {
				Assert.assertEquals(2, apiMethodDoc.getVerb().size());
				Iterator<ApiVerb> iterator = apiMethodDoc.getVerb().iterator();
				Assert.assertEquals(ApiVerb.GET, iterator.next());
				Assert.assertEquals(ApiVerb.POST, iterator.next());
			}
			
		}

		classes.clear();
		classes.add(TestControllerWithBasicAuth.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""test-controller-with-basic-auth"", apiDoc.getName());
		Assert.assertEquals(ApiAuthType.BASIC_AUTH.name(), apiDoc.getAuth().getType());
		Assert.assertEquals(""ROLE_USER"", apiDoc.getAuth().getRoles().get(0));
		Assert.assertEquals(""ROLE_ADMIN"", apiDoc.getAuth().getRoles().get(1));
		Assert.assertTrue(apiDoc.getAuth().getTestusers().size() > 0);
		
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/basicAuth"")) {
				Assert.assertEquals(ApiAuthType.BASIC_AUTH.name(), apiMethodDoc.getAuth().getType());
				Assert.assertEquals(""ROLE_USER"", apiMethodDoc.getAuth().getRoles().get(0));
				Assert.assertTrue(apiMethodDoc.getAuth().getTestusers().size() > 0);
			}
			
			if (apiMethodDoc.getPath().contains(""/noAuth"")) {
				Assert.assertEquals(ApiAuthType.NONE.name(), apiMethodDoc.getAuth().getType());
				Assert.assertEquals(DefaultJSONDocScanner.ANONYMOUS, apiMethodDoc.getAuth().getRoles().get(0));
			}
			
			if (apiMethodDoc.getPath().contains(""/undefinedAuthWithAuthOnClass"")) {
				Assert.assertEquals(ApiAuthType.BASIC_AUTH.name(), apiMethodDoc.getAuth().getType());
				Assert.assertEquals(""ROLE_USER"", apiMethodDoc.getAuth().getRoles().get(0));
				Assert.assertEquals(""ROLE_ADMIN"", apiMethodDoc.getAuth().getRoles().get(1));
			}
			
		}
		
		classes.clear();
		classes.add(TestControllerWithNoAuthAnnotation.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""test-controller-with-no-auth-annotation"", apiDoc.getName());
		Assert.assertNull(apiDoc.getAuth());
		
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/basicAuth"")) {
				Assert.assertEquals(ApiAuthType.BASIC_AUTH.name(), apiMethodDoc.getAuth().getType());
				Assert.assertEquals(""ROLE_USER"", apiMethodDoc.getAuth().getRoles().get(0));
				Assert.assertTrue(apiMethodDoc.getAuth().getTestusers().size() > 0);
			}
			
			if (apiMethodDoc.getPath().contains(""/noAuth"")) {
				Assert.assertEquals(ApiAuthType.NONE.name(), apiMethodDoc.getAuth().getType());
				Assert.assertEquals(DefaultJSONDocScanner.ANONYMOUS, apiMethodDoc.getAuth().getRoles().get(0));
			}
			
			if (apiMethodDoc.getPath().contains(""/undefinedAuthWithoutAuthOnClass"")) {
				Assert.assertNull(apiMethodDoc.getAuth());
			}
			
		}
		
		classes.clear();
		classes.add(TestOldStyleServlets.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""test-old-style-servlets"", apiDoc.getName());
		
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/oldStyle"")) {
				Assert.assertEquals(1, apiMethodDoc.getPathparameters().size());
			}
			
			if (apiMethodDoc.getPath().contains(""/oldStyleWithList"")) {
				Assert.assertEquals(1, apiMethodDoc.getPathparameters().size());
			}
			
			if (apiMethodDoc.getPath().contains(""/oldStyleWithMap"")) {
				Assert.assertEquals(1, apiMethodDoc.getPathparameters().size());
			}
			
			if (apiMethodDoc.getPath().contains(""/oldStyleMixed"")) {
				Assert.assertEquals(3, apiMethodDoc.getPathparameters().size());
				Assert.assertEquals(1, apiMethodDoc.getQueryparameters().size());
				Assert.assertEquals(""qTest"", apiMethodDoc.getQueryparameters().iterator().next().getDefaultvalue());
			}
			
			if (apiMethodDoc.getPath().contains(""/oldStyleResponseObject"")) {
				Assert.assertEquals(""list"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
			}
			
			if (apiMethodDoc.getPath().contains(""/oldStyleBodyObject"")) {
				Assert.assertEquals(""list"", apiMethodDoc.getBodyobject().getJsondocType().getOneLineText());
			}
		}
		
		classes.clear();
		classes.add(TestErrorsAndWarningsAndHints.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""test-errors-warnings-hints"", apiDoc.getName());
		ApiMethodDoc apiMethodDoc = apiDoc.getMethods().iterator().next();
		Assert.assertEquals(1, apiMethodDoc.getJsondocerrors().size());
		Assert.assertEquals(1, apiMethodDoc.getJsondocwarnings().size());
		Assert.assertEquals(2, apiMethodDoc.getJsondochints().size());
		
		classes.clear();
		classes.add(TestErrorsAndWarningsAndHintsMethodSummary.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.SUMMARY).iterator().next();
		apiMethodDoc = apiDoc.getMethods().iterator().next();
		Assert.assertEquals(1, apiMethodDoc.getJsondocerrors().size());
		Assert.assertEquals(1, apiMethodDoc.getJsondocwarnings().size());
		Assert.assertEquals(3, apiMethodDoc.getJsondochints().size());
		
		classes.clear();
		classes.add(InterfaceController.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""interface-controller"", apiDoc.getName());
		apiMethodDoc = apiDoc.getMethods().iterator().next();
		Assert.assertNotNull(apiMethodDoc);
		Assert.assertEquals(""/interface"", apiMethodDoc.getPath().iterator().next());
		
		classes.clear();
		classes.add(TestDeclaredMethods.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""test-declared-methods"", apiDoc.getName());
		Assert.assertEquals(2, apiDoc.getMethods().size());
		
		
		classes.clear();
		classes.add(TestMultipleParamsWithSameMethod.class);
		apiDoc = jsondocScanner.getApiDocs(classes, MethodDisplay.URI).iterator().next();
		Assert.assertEquals(3, apiDoc.getMethods().size());
		
	}
",non-flaky,5
35717,cdapio_cdap,TestDistributedLogReader.testDistributedLogNextKafka,"  @Test
  public void testDistributedLogNextKafka() throws Exception {
    ReadRange readRange = new ReadRange(0, Long.MAX_VALUE, LogOffset.INVALID_KAFKA_OFFSET);
    testDistributedLogNext(readRange, LOGGING_CONTEXT_KAFKA, 10, 3, ""TestDistributedLogReader Log message3 "", 30, 0);

    readRange = new ReadRange(System.currentTimeMillis() - TimeUnit.DAYS.toMillis(1),
                              System.currentTimeMillis(), LogOffset.INVALID_KAFKA_OFFSET);
    testDistributedLogNext(readRange, LOGGING_CONTEXT_KAFKA, 10, 3, ""TestDistributedLogReader Log message3 "", 30, 0);

    testDistributedLogNext(ReadRange.LATEST, LOGGING_CONTEXT_KAFKA, 1, 8,
                           ""TestDistributedLogReader Log message3 "", 8, 22);
  }
",non-flaky,5
99736,apache_cassandra,FQLReplayTest.testFQLQuerySingleToStatement,"    @Test
    public void testFQLQuerySingleToStatement()
    {
        List<ByteBuffer> values = new ArrayList<>();
        for (int i = 0; i < 10; i++)
            values.add(ByteBufferUtil.bytes(i));
        FQLQuery.Single single = new FQLQuery.Single(""xyz"",
                                                     QueryOptions.DEFAULT.getProtocolVersion().asInt(),
                                                     QueryOptions.forInternalCalls(values),
                                                     1234,
                                                     12345,
                                                     54321,
                                                     ""select * from aaa"",
                                                     values);
        Statement stmt = single.toStatement();
        assertEquals(stmt.getDefaultTimestamp(), 12345);
        assertTrue(stmt instanceof SimpleStatement);
        SimpleStatement simpleStmt = (SimpleStatement)stmt;
        assertEquals(""select * from aaa"",simpleStmt.getQueryString(CodecRegistry.DEFAULT_INSTANCE));
        assertArrayEquals(values.toArray(), simpleStmt.getValues(com.datastax.driver.core.ProtocolVersion.fromInt(QueryOptions.DEFAULT.getProtocolVersion().asInt()), CodecRegistry.DEFAULT_INSTANCE));
    }
",non-flaky,5
112637,tbsalling_aismessages,AddressedBinaryMessageTest.canDecodeAsmNumberOfPersonsOnboard,"    @Test
    public void canDecodeAsmNumberOfPersonsOnboard() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,B,63bump80OEGr06P060,4*79""));
        System.out.println(aisMessage.toString());

        assertTrue(aisMessage instanceof AddressedBinaryMessage);
        AddressedBinaryMessage addressedBinaryMessage = (AddressedBinaryMessage) aisMessage;
        assertEquals(1, addressedBinaryMessage.getDesignatedAreaCode().intValue());
        assertEquals(40, addressedBinaryMessage.getFunctionalId().intValue());

        ApplicationSpecificMessage asm = addressedBinaryMessage.getApplicationSpecificMessage();
        assertEquals(1, asm.getDesignatedAreaCode());
        assertEquals(40, asm.getFunctionalId());

        assertTrue(asm instanceof NumberOfPersonsOnBoard);
        NumberOfPersonsOnBoard numberOfPersonsOnBoard = (NumberOfPersonsOnBoard) asm;
        assertEquals(""0000000000011000"", numberOfPersonsOnBoard.getBinaryData());
        assertEquals(Integer.valueOf(3), numberOfPersonsOnBoard.getNumberOfPersons());
   }
",non-flaky,5
20,cdapio_cdap,WorkflowHttpHandlerTest.testWorkflowForkFailure,"@Test
public void testWorkflowForkFailure() throws Exception {
    Assert.assertEquals(200, deploy(WorkflowFailureInForkApp.class).getStatusLine().getStatusCode());
    Id.Application appId = Application.from(DEFAULT, NAME);
    Id.Workflow workflowId = Workflow.from(appId, NAME);
    Id.Program firstMRId = Program.from(appId, MAPREDUCE, FIRST_MAPREDUCE_NAME);
    Id.Program secondMRId = Program.from(appId, MAPREDUCE, SECOND_MAPREDUCE_NAME);
    String outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
    File fileToSync = new File(tmpFolder.newFolder() + ""/sync.file"");
    File fileToWait = new File(tmpFolder.newFolder() + ""/wait.file"");
    startProgram(workflowId, ImmutableMap.of(""inputPath"", createInput(""testWorkflowForkFailureInput""), ""outputPath"", outputPath, ""sync.file"", fileToSync.getAbsolutePath(), ""wait.file"", fileToWait.getAbsolutePath(), (""mapreduce."" + WorkflowFailureInForkApp.SECOND_MAPREDUCE_NAME) + "".throw.exception"", ""true""));
    waitState(workflowId, RUNNING.name());
    waitState(workflowId, STOPPED.name());
    verifyProgramRuns(workflowId, ""failed"");
    List<RunRecord> mapReduceProgramRuns = getProgramRuns(firstMRId, KILLED.name());
    Assert.assertEquals(1, mapReduceProgramRuns.size());
    mapReduceProgramRuns = getProgramRuns(secondMRId, FAILED.name());
    Assert.assertEquals(1, mapReduceProgramRuns.size());
}",concurrency,1
35681,cdapio_cdap,KafkaLogProcessorPipelineTest.testMetricsAppender,"  @Test
  public void testMetricsAppender() throws Exception {
    Injector injector = KAFKA_TESTER.getInjector();
    MetricsCollectionService collectionService = injector.getInstance(MetricsCollectionService.class);
    collectionService.startAndWait();
    LoggerContext loggerContext = new LocalAppenderContext(injector.getInstance(TransactionRunner.class),
                                                           injector.getInstance(LocationFactory.class),
                                                           injector.getInstance(MetricsCollectionService.class));
    final File logDir = TEMP_FOLDER.newFolder();
    loggerContext.putProperty(""logDirectory"", logDir.getAbsolutePath());

    LogPipelineConfigurator configurator = new LogPipelineConfigurator(CConfiguration.create());
    configurator.setContext(loggerContext);
    URL configURL = getClass().getClassLoader().getResource(""pipeline-metric-appender.xml"");
    Assert.assertNotNull(configURL);
    configurator.doConfigure(configURL);

    String topic = ""metricsPipeline"";
    TestCheckpointManager checkpointManager = new TestCheckpointManager();
    KafkaPipelineConfig config = new KafkaPipelineConfig(topic, Collections.singleton(0), 1024L, 100L, 1048576, 200L);
    KAFKA_TESTER.createTopic(topic, 1);

    loggerContext.start();
    KafkaLogProcessorPipeline pipeline = new KafkaLogProcessorPipeline(
      new LogProcessorPipelineContext(CConfiguration.create(), ""testMetricAppender"",
                                      loggerContext, NO_OP_METRICS_CONTEXT, 0),
      checkpointManager,
      KAFKA_TESTER.getBrokerService(), config);

    pipeline.startAndWait();

    // Publish some log messages to Kafka
    long now = System.currentTimeMillis();
    WorkerLoggingContext loggingContext =
      new WorkerLoggingContext(""default"", ""app1"", ""worker1"", ""run1"", ""instance1"");
    publishLog(topic,
               ImmutableList.of(
                 LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""0"", now - 1000),
                 LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""2"", now - 700),
                 LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""3"", now - 500),
                 LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""1"", now - 900),
                 LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.DEBUG, ""hidden"", now - 600),
                 LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""4"", now - 100)),
               loggingContext
    );

    WorkflowProgramLoggingContext workflowProgramLoggingContext =
      new WorkflowProgramLoggingContext(""default"", ""app1"", ""wflow1"", ""run1"", ProgramType.MAPREDUCE, ""mr1"", ""mrun1"");

    publishLog(topic,
               ImmutableList.of(
                 LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.WARN, ""0"", now - 1000),
                 LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.WARN, ""2"", now - 700),
                 LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.TRACE, ""3"", now - 500)),
               workflowProgramLoggingContext
    );

    ServiceLoggingContext serviceLoggingContext =
      new ServiceLoggingContext(NamespaceId.SYSTEM.getNamespace(), Constants.Logging.COMPONENT_NAME,
                                Constants.Service.TRANSACTION);
    publishLog(topic,
               ImmutableList.of(
                 LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.ERROR, ""0"", now - 1000),
                 LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.ERROR, ""2"", now - 700),
                 LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.ERROR, ""3"", now - 500),
                 LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""1"", now - 900)),
               serviceLoggingContext
    );

    final MetricStore metricStore = injector.getInstance(MetricStore.class);
    try {
      verifyMetricsWithRetry(metricStore,
                             new MetricDataQuery(0, Integer.MAX_VALUE, Integer.MAX_VALUE,
                                                 ""system.app.log.info"",
                                                 AggregationFunction.SUM,
                                                 LoggingContextHelper.getMetricsTags(loggingContext),
                                                 new ArrayList<>()), 5L);

      verifyMetricsWithRetry(metricStore,
                             new MetricDataQuery(0, Integer.MAX_VALUE, Integer.MAX_VALUE,
                                                 ""system.app.log.debug"",
                                                 AggregationFunction.SUM,
                                                 LoggingContextHelper.getMetricsTags(loggingContext),
                                                 new ArrayList<>()), 1L);

      verifyMetricsWithRetry(metricStore,
                             new MetricDataQuery(0, Integer.MAX_VALUE, Integer.MAX_VALUE,
                                                 ""system.app.log.warn"",
                                                 AggregationFunction.SUM,
                                                 // mapreduce metrics context
                                                 ImmutableMap.of(Constants.Metrics.Tag.NAMESPACE, ""default"",
                                                                 Constants.Metrics.Tag.APP, ""app1"",
                                                                 Constants.Metrics.Tag.MAPREDUCE, ""mr1"",
                                                                 Constants.Metrics.Tag.RUN_ID, ""mrun1""),
                                                 new ArrayList<>()), 2L);
      verifyMetricsWithRetry(metricStore,
                             new MetricDataQuery(0, Integer.MAX_VALUE, Integer.MAX_VALUE,
                                                 ""system.app.log.trace"",
                                                 AggregationFunction.SUM,
                                                 // workflow metrics context
                                                 ImmutableMap.of(Constants.Metrics.Tag.NAMESPACE, ""default"",
                                                                 Constants.Metrics.Tag.APP, ""app1"",
                                                                 Constants.Metrics.Tag.WORKFLOW, ""wflow1"",
                                                                 Constants.Metrics.Tag.RUN_ID, ""run1""),
                                                 new ArrayList<>()), 1L);
      verifyMetricsWithRetry(metricStore,
                             new MetricDataQuery(0, Integer.MAX_VALUE, Integer.MAX_VALUE,
                                                 ""system.services.log.error"",
                                                 AggregationFunction.SUM,
                                                 LoggingContextHelper.getMetricsTags(serviceLoggingContext),
                                                 new ArrayList<>()), 3L);
    } finally {
      pipeline.stopAndWait();
      loggerContext.stop();
      collectionService.stopAndWait();
    }
  }
",non-flaky,5
91415,strapdata_elassandra,OpenLdapUserSearchSessionFactoryTests.init,"@TestLogging(""org.elasticsearch.xpack.core.ssl.SSLService:TRACE"")
    public void init() throws Exception {
        Path caPath = getDataPath(LDAPCACERT_PATH);
        /*
         * Prior to each test we reinitialize the socket factory with a new SSLService so that we get a new SSLContext.
         * If we re-use a SSLContext, previously connected sessions can get re-established which breaks hostname
         * verification tests since a re-established connection does not perform hostname verification.
         */
        globalSettings = Settings.builder()
            .put(""path.home"", createTempDir())
            .put(""xpack.ssl.certificate_authorities"", caPath)
            .build();
        threadPool = new TestThreadPool(""LdapUserSearchSessionFactoryTests"");
    }
",non-flaky,5
20958,NationalSecurityAgency_timely,MetricAgeOffFilterTest.testDefault,"    @Test
    public void testDefault() throws Exception {
        MetricAgeOffFilter filter = new MetricAgeOffFilter();
        HashMap<String, String> options = new HashMap<>();
        options.put(MetricAgeOffFilter.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        filter.init(null, options, null);
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0],
                new byte[0], new byte[0], TEST_TIME), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 1), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 1), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 2), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 2), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 3), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 4), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 4), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 5), new byte[0],
                new byte[0], new byte[0], TEST_TIME + 5), null));
    }
",non-flaky,5
89285,apache_samza,TestJobsResource.testStartJob,"  @Test
  public void testStartJob()
      throws IOException {
    Response resp = target(String.format(""v1/jobs/%s/%s"", MockJobProxy.JOB_INSTANCE_2_NAME, MockJobProxy.JOB_INSTANCE_2_ID))
        .queryParam(""status"", ""started"").request().put(Entity.form(new Form()));
    assertEquals(202, resp.getStatus());

    final Job job2 = objectMapper.readValue(resp.readEntity(String.class), Job.class);
    assertEquals(MockJobProxy.JOB_INSTANCE_2_NAME, job2.getJobName());
    assertEquals(MockJobProxy.JOB_INSTANCE_2_ID, job2.getJobId());
    assertStatusNotDefault(job2);
    resp.close();
  }
",non-flaky,5
88786,apache_ignite,LongRunningProcessClearTaskTest.testCallProcessIsDone,"    @Test
    public void testCallProcessIsDone() {
        UUID procId = UUID.randomUUID();

        Future<?> fut = mock(Future.class);
        doReturn(true).when(fut).isDone();
        metadataStorage.put(procId, fut);

        LongRunningProcessClearTask clearTask = createTask(procId);

        List<LongRunningProcessStatus> statuses = clearTask.call();

        assertEquals(1, statuses.size());

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.DONE, status.getState());
        assertNull(status.getException());

        assertEquals(0, metadataStorage.size());
    }
",non-flaky,5
96095,stanfordnlp_CoreNLP,ProtobufAnnotationSerializerSlowITest.testSentiment,"  @Test
  public void testSentiment() {
    testAnnotators(""tokenize,ssplit,pos,parse,sentiment"");
  }
",non-flaky,5
20947,NationalSecurityAgency_timely,RateIteratorTest.testConstantTimeRate,"    @Test
    public void testConstantTimeRate() throws Exception {
        SortedMapIterator source = new SortedMapIterator(table);
        RateIterator iter = new RateIterator();
        IteratorSetting settings = new IteratorSetting(100, RateIterator.class);
        iter.init(source, settings.getOptions(), SCAN_IE);
        iter.seek(new Range(), EMPTY_COL_FAMS, true);
        for (int i = 0; i < 99; i++) {
            assertTrue(iter.hasTop());
            assertEquals(0.001D, MetricAdapter.decodeValue(iter.getTopValue().get()), 0.0D);
            iter.next();
        }
        assertFalse(iter.hasTop());
    }
",non-flaky,5
159613,liquibase_liquibase,MavenIntegrationTest.testUpdate,"//    @Test
//    public void testUpdate() throws Exception{
//        Verifier verifier=createVerifier();
//
//        verifier.executeGoal( ""clean"" );
//        verifier.executeGoal( ""install"" );
//
//        //Verify everithing has gone well.
//        verifier.verifyErrorFreeLog();
//
//        //Reset the streams before executing the verifier
//        verifier.resetStreams();
//    }
",non-flaky,5
162447,testcontainers_testcontainers-java,HttpWaitStrategyTest.testWaitUntilReadyWithTimeoutAndWithManyStatusCodesAndLambda,"    @Test
    public void testWaitUntilReadyWithTimeoutAndWithManyStatusCodesAndLambda() {
        waitUntilReadyAndTimeout(startContainerWithCommand(createShellCommand(""401 UNAUTHORIZED"", GOOD_RESPONSE_BODY),
            createHttpWaitStrategy(ready)
                .forStatusCode(300)
                .forStatusCodeMatching(it -> it == 500)
        ));
    }
",non-flaky,5
122555,vespa-engine_vespa,CommandLineTest.testStrings,"    @Test
    public void testStrings() {
        terminal.expectCommand(
                ""/bin/bash \""with space\"" \""speci&l\"" \""\"" \""double\\\""quote\"" 2>&1"",
                0,
                """");
        commandLine.add(""/bin/bash"", ""with space"", ""speci&l"", """", ""double\""quote"").execute();
        assertEquals(""bash"", commandLine.programName());
    }
",non-flaky,5
96917,apache_avro,TestAvroOutputFormat.testSnappyCodecUsingHadoopClass,"  @Test
  public void testSnappyCodecUsingHadoopClass() {
    CodecFactory avroSnappyCodec = CodecFactory.fromString(""snappy"");

    JobConf job = new JobConf();
    job.set(""mapred.output.compress"", ""true"");
    job.set(""mapred.output.compression.codec"", ""org.apache.hadoop.io.compress.SnappyCodec"");
    CodecFactory factory = AvroOutputFormat.getCodecFactory(job);
    assertNotNull(factory);
    assertEquals(factory.getClass(), avroSnappyCodec.getClass());
  }
",non-flaky,5
89302,apache_samza,TestMonitorService.createSchedulerAndScheduleMonitor,"  @Test
  public void testShouldNotFailWhenTheMonitorFactoryClassIsNotDefined()
      throws Exception {
    // Test that when MonitorFactoryClass is not defined in the config, monitor service
    // should not fail.
    Map<String, String> configMap = ImmutableMap.of(""monitor.monitor1.config.key1"", ""configValue1"",
                                                    ""monitor.monitor1.config.key2"", ""configValue2"",
                                                    String.format(""monitor.MOCK_MONITOR.%s"", CONFIG_MONITOR_FACTORY_CLASS),
                                                    MockMonitorFactory.class.getCanonicalName());

    SamzaRestConfig config = new SamzaRestConfig(new MapConfig(configMap));

    class SamzaMonitorServiceTest extends SamzaMonitorService {
      MetricsRegistry metricsRegistry;
      public SamzaMonitorServiceTest(SamzaRestConfig config, MetricsRegistry metricsRegistry) {
        super(config, metricsRegistry);
        this.metricsRegistry = metricsRegistry;
      }

      @Override
      public void createSchedulerAndScheduleMonitor(String monitorName, MonitorConfig monitorConfig, long schedulingIntervalInMs) {
        try {
          // immediately run monitor, without scheduling
          instantiateMonitor(monitorName, monitorConfig, metricsRegistry).monitor();
        } catch (Exception e) {
          fail();
        }
      }
",non-flaky,5
176815,ctco_cukes,EndsWithRegexpTest.matchesLocationUrl,"    @Test
    public void matchesLocationUrl() throws Exception {
        assertThat(""http://company.com:80/webapp/orx/rest/index/types/CLIENT/nodes/6f1155df-644b-4228-89af"" +
                ""-7d24b8fe1a8d"", EndsWithRegexp.endsWithRegexp(""/index/types/CLIENT/nodes/.+""));
    }
",non-flaky,5
96086,stanfordnlp_CoreNLP,StanfordCoreNLPServerITest.testReady,"  @Test
  public void testReady() {
    String result = IOUtils.slurpURLNoExceptions(""http://localhost:"" + port + ""/ready"");
    Assert.assertNotNull(result);
    Assert.assertEquals(""ready"", result.trim());
  }
",non-flaky,5
88828,apache_ignite,IgniteThrottlingUnitTest.warningInCaseTooMuchThrottling,"    @Test
    public void warningInCaseTooMuchThrottling() {
        AtomicInteger warnings = new AtomicInteger(0);
        IgniteLogger log = mock(IgniteLogger.class);

        doAnswer(invocation -> {
            Object[] args = invocation.getArguments();

            System.out.println(""log.info() called with arguments: "" + Arrays.toString(args));

            warnings.incrementAndGet();

            return null;
        }).when(log).info(anyString());

        AtomicInteger written = new AtomicInteger();
        CheckpointWriteProgressSupplier cpProgress = mock(CheckpointWriteProgressSupplier.class);
        when(cpProgress.writtenPagesCounter()).thenReturn(written);

        PagesWriteSpeedBasedThrottle throttle = new PagesWriteSpeedBasedThrottle(pageMemory2g, cpProgress, stateChecker, log) {
            @Override protected void doPark(long throttleParkTimeNs) {
                //do nothing
            }
        };
        throttle.onBeginCheckpoint();
        written.set(200); //emulating some pages written

        for (int i = 0; i < 100000; i++) {
            //emulating high load on marking
            throttle.onMarkDirty(false);

            if (throttle.throttleWeight() > PagesWriteSpeedBasedThrottle.WARN_THRESHOLD)
                break;
        }

        for (int i = 0; i < 1000; i++) {
            //emulating additional page writes to be sure log message is generated

            throttle.onMarkDirty(false);

            if(warnings.get()>0)
                break;
        }

        System.out.println(throttle.throttleWeight());

        assertTrue(warnings.get() > 0);
    }
",non-flaky,5
30937,camunda-cloud_zeebe,ElasticsearchExporterTest.shouldExportEnabledValueTypes,"  @Test
  public void shouldExportEnabledValueTypes() {
    // given
    config.index.event = true;
    config.index.deployment = true;
    config.index.process = true;
    config.index.error = true;
    config.index.incident = true;
    config.index.job = true;
    config.index.jobBatch = true;
    config.index.message = true;
    config.index.messageSubscription = true;
    config.index.variable = true;
    config.index.variableDocument = true;
    config.index.processInstance = true;
    config.index.processInstanceCreation = true;
    config.index.processMessageSubscription = true;

    createAndOpenExporter();

    final ValueType[] valueTypes =
        new ValueType[] {
          ValueType.DEPLOYMENT,
          ValueType.PROCESS,
          ValueType.ERROR,
          ValueType.INCIDENT,
          ValueType.JOB,
          ValueType.JOB_BATCH,
          ValueType.MESSAGE,
          ValueType.MESSAGE_SUBSCRIPTION,
          ValueType.VARIABLE,
          ValueType.VARIABLE_DOCUMENT,
          ValueType.PROCESS_INSTANCE,
          ValueType.PROCESS_INSTANCE_CREATION,
          ValueType.PROCESS_MESSAGE_SUBSCRIPTION
        };

    // when - then
    final Context.RecordFilter filter = testHarness.getContext().getFilter();

    assertThat(Arrays.stream(valueTypes).map(filter::acceptValue)).containsOnly(true);
  }
",non-flaky,5
57267,apache_ozone,TestNSSummaryEndpoint.testDiskUsageWithReplication,"  @Test
  public void testDiskUsageWithReplication() throws Exception {
    setUpMultiBlockKey();
    Response keyResponse = nsSummaryEndpoint.getDiskUsage(MULTI_BLOCK_KEY_PATH,
            false, true);
    DUResponse replicaDUResponse = (DUResponse) keyResponse.getEntity();
    Assert.assertEquals(ResponseStatus.OK, replicaDUResponse.getStatus());
    Assert.assertEquals(MULTI_BLOCK_KEY_SIZE_WITH_REPLICA,
            replicaDUResponse.getSizeWithReplica());
  }
",non-flaky,5
21010,NationalSecurityAgency_timely,TimelyTcpIT.testPutInvalidTimestamp,"    @Test
    public void testPutInvalidTimestamp() throws Exception {
        final TestServer m = new TestServer(conf);
        m.run();
        try (Socket sock = new Socket(""127.0.0.1"", 54321);
                PrintWriter writer = new PrintWriter(sock.getOutputStream(), true);
                BufferedReader reader = new BufferedReader(new InputStreamReader(sock.getInputStream()));) {
            writer.write(""put sys.cpu.user "" + TEST_TIME + ""Z"" + "" 1.0 tag1=value1 tag2=value2\n"");
            writer.flush();
            sleepUninterruptibly(WAIT_SECONDS, TimeUnit.SECONDS);
            Assert.assertEquals(0, m.getTcpRequests().getCount());
        } finally {
            m.shutdown();
        }
    }
",non-flaky,5
178035,aosp-mirror_platform_frameworks_support,GuidedDatePickerTest.testNovemberToOctoberTransition,"    @Test
    public void testNovemberToOctoberTransition() throws Throwable {
        long startTime = System.currentTimeMillis();
        Intent intent = new Intent();

        String title = ""Date Picker Transition Test"";
        String breadcrumb = ""Month Transition Test Demo"";
        String description = ""Testing the transition from Nov to Oct"";
        GuidanceStylist.Guidance guidance = new GuidanceStylist.Guidance(title, description,
                breadcrumb, null);

        List<GuidedAction> actionList = new ArrayList<>();

        Calendar cal = Calendar.getInstance();

        cal.set(Calendar.YEAR, 2016);
        cal.set(Calendar.MONTH, Calendar.NOVEMBER);
        cal.set(Calendar.DAY_OF_MONTH, cal.getActualMaximum(Calendar.DAY_OF_MONTH));
        Date initialDate = cal.getTime();

        GuidedDatePickerAction action = new GuidedDatePickerAction.Builder(
                mContext)
                .id(0)
                .title(""Date"")
                .date(initialDate.getTime())
                .datePickerFormat(""DMY"")
                .build();

        actionList.add(action);

        GuidedStepAttributesTestFragment.clear();
        GuidedStepAttributesTestFragment.GUIDANCE = guidance;
        GuidedStepAttributesTestFragment.ACTION_LIST = actionList;

        initActivity(intent);

        DatePicker mPickerView = (DatePicker) mActivity.findViewById(
                R.id.guidedactions_activator_item);

        verticalScrollToFieldValue(Calendar.MONTH, Calendar.OCTOBER, new int[] {0, 1, 2},
                mPickerView, KeyEvent.KEYCODE_DPAD_UP);
        long executionTime = System.currentTimeMillis() - startTime;
        Log.d(TAG, ""testNovemberToOctober() Execution time: "" + executionTime);
        Thread.sleep(FINAL_WAIT);
    }
",non-flaky,5
77189,networknt_json-schema-validator,JsonWalkTest.testWalk,"    @Test
    public void testWalk() throws IOException {
        ObjectMapper objectMapper = new ObjectMapper();
        ValidationResult result = jsonSchema.walk(
                objectMapper.readTree(getClass().getClassLoader().getResourceAsStream(""data/walk-data.json"")), false);
        JsonNode collectedNode = (JsonNode) result.getCollectorContext().get(SAMPLE_WALK_COLLECTOR_TYPE);
        assertEquals(collectedNode, (objectMapper.readTree(""{"" +
                ""    \""PROPERTY1\"": \""sample1\"",""
                + ""    \""PROPERTY2\"": \""sample2\"",""
                + ""    \""property3\"": {""
                + ""        \""street_address\"":\""test-address\"",""
                + ""        \""phone_number\"": {""
                + ""            \""country-code\"": \""091\"",""
                + ""            \""number\"": \""123456789\""""
                + ""          }""
                + ""     }""
                + ""}"")));
    }
",non-flaky,5
159680,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_withTablespace,"//    @Test
//    public void execute_withTablespace() throws Exception {
//        new DatabaseTestTemplate().testOnAvailableDatabases(
//                new SqlStatementDatabaseTest(null, new AddUniqueConstraintStatement(null, TABLE_NAME, COLUMN_NAME, ""uq_adduqtest"").setTablespace(TestContext.ALT_TABLESPACE)) {
//                    protected void preExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        assertFalse(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//
//                    protected void postExecuteAssert(DatabaseSnapshotGenerator snapshot) {
//                        //todo: enable snapshot and assertion when snapshot can check for unique constraints
//                        // snapshot = new DatabaseSnapshotGenerator(database);
////                assertTrue(snapshot.getTable(TABLE_NAME).getColumn(COLUMN_NAME).isUnique());
//                    }
//                });
//    }
",non-flaky,5
60951,apache_druid,RowBucketIterableTest.testMissingDaysInMiddleOneRow,"  @Test
  public void testMissingDaysInMiddleOneRow()
  {
    List<Row> expectedDay1 = Collections.singletonList(JAN_1_M_10);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.emptyList();
    List<Row> expectedDay4 = Collections.singletonList(JAN_4_M_10);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_2_M_10);
    rows.add(JAN_4_M_10);

    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(JAN_3, actual.getDateTime());
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
99788,apache_cassandra,MessagingServiceTest.listenPlainConnection,"    @Test
    public void listenPlainConnection() throws InterruptedException
    {
        ServerEncryptionOptions serverEncryptionOptions = new ServerEncryptionOptions()
                                                          .withInternodeEncryption(ServerEncryptionOptions.InternodeEncryption.none);
        listen(serverEncryptionOptions, false);
    }
",non-flaky,5
77564,dropwizard_dropwizard,OptionalLongMessageBodyWriterTest.showWithQueryParam,"    @Test
        public OptionalLong showWithQueryParam(@QueryParam(""id"") OptionalLong id) {
            return id;
        }
",non-flaky,5
135753,Netflix_Hystrix,HystrixConcurrencyStrategyTest.call,"    @Test
    public void testRequestContextPropagatesAcrossObserveOnPool() {
        new SimpleCommand().execute();
        new SimpleCommand().observe().map(new Func1<String, String>() {

            @Override
            public String call(String s) {
                System.out.println(""Map => Commands: "" + HystrixRequestLog.getCurrentRequest().getAllExecutedCommands());
                return s;
            }
",non-flaky,5
122631,vespa-engine_vespa,YumPackageNameTest.testArchitectures,"    @Test
    public void testArchitectures() {
        assertEquals(""x86_64"", YumPackageName.fromString(""docker.x86_64"").getArchitecture().get());
        assertEquals(""i686"", YumPackageName.fromString(""docker.i686"").getArchitecture().get());
        assertEquals(""noarch"", YumPackageName.fromString(""docker.noarch"").getArchitecture().get());
    }
",non-flaky,5
92637,apache_dubbo,ApplicationConfigTest.testDumpDirectory,"    @Test
    public void testDumpDirectory() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setDumpDirectory(""/dump"");
        assertThat(application.getDumpDirectory(), equalTo(""/dump""));
        Map<String, String> parameters = new HashMap<String, String>();
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(Constants.DUMP_DIRECTORY, ""/dump""));
    }
",non-flaky,5
114102,aws_aws-sdk-java-v2,EnhancedTypeDocumentationConfigurationTest.defaultBuilder_defaultToFalse,"    @Test
    public void defaultBuilder_defaultToFalse() {
        EnhancedTypeDocumentConfiguration configuration =
            EnhancedTypeDocumentConfiguration.builder().build();
        assertThat(configuration.ignoreNulls()).isFalse();
        assertThat(configuration.preserveEmptyObject()).isFalse();
    }
",non-flaky,5
159684,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_withTablespace,"    @Test
    public void execute_withTablespace() throws Exception {
        statementUnderTest = new AddUniqueConstraintStatement(null, null, TABLE_NAME, new ColumnConfig[] { new ColumnConfig().setName(COLUMN_NAME)}, CONSTRAINT_NAME).setTablespace(TABLESPACE_NAME);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq]) on liquibase2"", MSSQLDatabase.class);
        assertCorrect(""alter table adduqtest add constraint unique (coltomakeuq) constraint uq_test"", InformixDatabase.class);
        assertCorrect(""alter table \""adduqtest\"" add constraint uq_test unique (\""coltomakeuq\"") USING INDEX TABLESPACE "" + TABLESPACE_NAME, PostgresDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", MySQLDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", MariaDBDatabase.class);
        assertCorrect(""alter table adduqtest add constraint uq_test unique (coltomakeuq)"", DerbyDatabase.class, HsqlDatabase.class, DB2Database.class, H2Database.class, FirebirdDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", Db2zDatabase.class);
        assertCorrectOnRest(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq]) USING INDEX TABLESPACE "" + TABLESPACE_NAME);
    }
",non-flaky,5
91411,OpenLCB_OpenLCB_Java,GridLayout2Test.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        GridLayout2 t = new GridLayout2();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
177160,line_armeria,TokenBucketThrottlingStrategyTest.throttle4,"    @Test
    public void throttle4() throws Exception {
        final WebClient client = WebClient.of(serverRule.httpUri());
        final AggregatedHttpResponse response1 = client.get(""/http-throttle4"").aggregate().get();
        assertThat(response1.status()).isEqualTo(HttpStatus.OK);

        assertThat(response1.headers().contains(HttpHeaderNames.RETRY_AFTER)).isFalse();
        assertThat(response1.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response1.headers().contains(""X-RateLimit-Reset"")).isFalse();

        final AggregatedHttpResponse response2 = client.get(""/http-throttle4"").aggregate().get();
        assertThat(response2.status()).isEqualTo(HttpStatus.SERVICE_UNAVAILABLE);

        assertThat(response2.headers().contains(HttpHeaderNames.RETRY_AFTER)).isTrue();
        final long retryAfter2 = Long.parseLong(response2.headers().get(HttpHeaderNames.RETRY_AFTER));
        assertThat(retryAfter2).isBetween(5L, 10L);
        assertThat(response2.headers().contains(""RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-Rate-Limit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Remaining"")).isFalse();
        assertThat(response2.headers().contains(""X-RateLimit-Reset"")).isFalse();
    }
",non-flaky,5
21009,NationalSecurityAgency_timely,TimelyTcpIT.testPutMultipleBinary,"    @Test
    public void testPutMultipleBinary() throws Exception {

        FlatBufferBuilder builder = new FlatBufferBuilder(1);

        int[] metric = new int[2];
        Map<String, String> t = new HashMap<>();
        t.put(""tag1"", ""value1"");
        t.put(""tag2"", ""value2"");
        metric[0] = createMetric(builder, ""sys.cpu.user"", TEST_TIME, 1.0D, t);
        t = new HashMap<>();
        t.put(""tag3"", ""value3"");
        t.put(""tag4"", ""value4"");
        metric[1] = createMetric(builder, ""sys.cpu.idle"", TEST_TIME + 1, 1.0D, t);

        int metricVector = timely.api.flatbuffer.Metrics.createMetricsVector(builder, metric);

        timely.api.flatbuffer.Metrics.startMetrics(builder);
        timely.api.flatbuffer.Metrics.addMetrics(builder, metricVector);
        int metrics = timely.api.flatbuffer.Metrics.endMetrics(builder);
        timely.api.flatbuffer.Metrics.finishMetricsBuffer(builder, metrics);

        ByteBuffer binary = builder.dataBuffer();
        byte[] data = new byte[binary.remaining()];
        binary.get(data, 0, binary.remaining());
        LOG.debug(""Sending {} bytes"", data.length);

        final TestServer m = new TestServer(conf);
        m.run();
        try (Socket sock = new Socket(""127.0.0.1"", 54321);) {
            sock.getOutputStream().write(data);
            sock.getOutputStream().flush();
            while (2 != m.getTcpRequests().getCount()) {
                LOG.debug(""Thread sleeping"");
                Thread.sleep(5);
            }
            Assert.assertEquals(2, m.getTcpRequests().getResponses().size());
            Assert.assertEquals(MetricRequest.class, m.getTcpRequests().getResponses().get(0).getClass());
            // @formatter:off
            MetricRequest actual = (MetricRequest) m.getTcpRequests().getResponses().get(0);
            MetricRequest expected = new MetricRequest(
                    Metric.newBuilder()
                            .name(""sys.cpu.user"")
                            .value(TEST_TIME, 1.0D)
                            .tag(new Tag(""tag1"", ""value1""))
                            .tag(new Tag(""tag2"", ""value2""))
                            .build()
            );
            Assert.assertEquals(expected, actual);

            Assert.assertEquals(MetricRequest.class, m.getTcpRequests().getResponses().get(1).getClass());
            actual = (MetricRequest) m.getTcpRequests().getResponses().get(1);
            expected = new MetricRequest(
                    Metric.newBuilder()
                            .name(""sys.cpu.idle"")
                            .value(TEST_TIME + 1, 1.0D)
                            .tag(new Tag(""tag3"", ""value3""))
                            .tag(new Tag(""tag4"", ""value4""))
                            .build()
            );
            // @formatter:on
            Assert.assertEquals(expected, actual);

        } finally {
            m.shutdown();
        }
    }
",non-flaky,5
77146,networknt_json-schema-validator,V4JsonSchemaTest.testDefaultValidator,"    @Test
    public void testDefaultValidator() throws Exception {
        runTestFile(""draft4/default.json"");
    }
",non-flaky,5
104667,apache_pinot,RealtimeKinesisIntegrationTest.testCountRecords,"  @Test
  public void testCountRecords() {
    long count =
        getPinotConnection().execute(new Request(""sql"", ""SELECT COUNT(*) FROM "" + getTableName())).getResultSet(0)
            .getLong(0);

    Assert.assertEquals(count, _totalRecordsPushedInStream);
  }
",non-flaky,5
59637,looly_hutool,TokenizerUtilTest.jiebaTest,"	@Test
	public void jiebaTest() {
		TokenizerEngine engine = new JiebaEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""è¿ ä¸¤ä¸ª æ¹æ³ ç åºå« å¨äº è¿åå¼"", resultStr);
	}
",non-flaky,5
162416,testcontainers_testcontainers-java,DockerComposeLogConsumerTest.testLogConsumer,"    @Test
    public void testLogConsumer() throws TimeoutException {
        WaitingConsumer logConsumer = new WaitingConsumer();
        DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/v2-compose-test.yml""))
            .withExposedService(""redis_1"", 6379)
            .withLogConsumer(""redis_1"", logConsumer);

        try {
            environment.starting(Description.EMPTY);
            logConsumer.waitUntil(frame -> frame.getType() == STDOUT && frame.getUtf8String().contains(""Ready to accept connections""), 5, TimeUnit.SECONDS);
        } finally {
            environment.finished(Description.EMPTY);
        }
    }
",non-flaky,5
177252,line_armeria,DnsAddressEndpointGroupTest.backoffOnEmptyResponse,"    @Test
    public void backoffOnEmptyResponse() throws Exception {
        try (TestDnsServer server = new TestDnsServer(ImmutableMap.of(
                // Respond with empty records.
                new DefaultDnsQuestion(""empty.com."", A), new DefaultDnsResponse(0),
                new DefaultDnsQuestion(""empty.com."", AAAA), new DefaultDnsResponse(0)
        ))) {
            try (DnsAddressEndpointGroup group =
                         DnsAddressEndpointGroup.builder(""empty.com"")
                                                .serverAddresses(server.addr())
                                                .resolvedAddressTypes(ResolvedAddressTypes.IPV4_PREFERRED)
                                                .backoff(Backoff.fixed(500))
                                                .build()) {

                await().untilAsserted(() -> assertThat(group.attemptsSoFar).isGreaterThan(2));
                assertThat(group.endpoints()).isEmpty();

                // Start to respond correctly.
                server.setResponses(ImmutableMap.of(
                        new DefaultDnsQuestion(""empty.com."", A),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""empty.com"", ""1.1.1.1"", 1)),
                        new DefaultDnsQuestion(""empty.com."", AAAA),
                        new DefaultDnsResponse(0)
                                .addRecord(ANSWER, newAddressRecord(""empty.com"", ""::1"", 1))));

                await().untilAsserted(() -> assertThat(group.endpoints()).containsExactly(
                        Endpoint.of(""empty.com"").withIpAddr(""1.1.1.1""),
                        Endpoint.of(""empty.com"").withIpAddr(""::1"")));
            }
        }
    }
",non-flaky,5
35680,cdapio_cdap,KafkaLogProcessorPipelineTest.testRegularFlush,"  @Test
  public void testRegularFlush() throws Exception {
    String topic = ""testFlush"";
    LoggerContext loggerContext = LogPipelineTestUtil.createLoggerContext(""WARN"",
                                                                          ImmutableMap.of(""test.logger"", ""INFO""),
                                                                          MockAppender.class.getName());
    final MockAppender appender = LogPipelineTestUtil.getAppender(loggerContext.getLogger(Logger.ROOT_LOGGER_NAME),
                                                                  ""Test"", MockAppender.class);
    TestCheckpointManager checkpointManager = new TestCheckpointManager();

    // Use a longer checkpoint time and a short event delay. Should expect flush called at least once
    // per event delay.
    KafkaPipelineConfig config = new KafkaPipelineConfig(topic, Collections.singleton(0), 1024, 100, 1048576, 2000);
    KAFKA_TESTER.createTopic(topic, 1);

    loggerContext.start();
    KafkaLogProcessorPipeline pipeline = new KafkaLogProcessorPipeline(
      new LogProcessorPipelineContext(CConfiguration.create(), ""test"", loggerContext, NO_OP_METRICS_CONTEXT, 0),
      checkpointManager,
      KAFKA_TESTER.getBrokerService(), config);

    pipeline.startAndWait();

    // Even when there is no event, the flush should still get called.
    Tasks.waitFor(5, appender::getFlushCount, 3, TimeUnit.SECONDS, 100, TimeUnit.MILLISECONDS);

    // Publish some logs
    long now = System.currentTimeMillis();
    publishLog(topic, ImmutableList.of(
      LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""0"", now - 500),
      LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""1"", now - 300),
      LogPipelineTestUtil.createLoggingEvent(""test.logger"", Level.INFO, ""2"", now + 100)
    ));

    // Wait until getting all logs.
    Tasks.waitFor(3, () -> appender.getEvents().size(), 3, TimeUnit.SECONDS, 200, TimeUnit.MILLISECONDS);

    pipeline.stopAndWait();

    // Should get at least 20 flush calls, since the checkpoint is every 2 seconds
    Assert.assertTrue(appender.getFlushCount() >= 20);
  }
",non-flaky,5
122561,vespa-engine_vespa,CommandLineTest.programFails,"    @Test
    public void programFails() {
        terminal.expectCommand(""foo 2>&1"", 1, """");
        try {
            commandLine.add(""foo"").execute();
            fail();
        } catch (ChildProcessFailureException e) {
            assertEquals(
                    ""Command 'foo 2>&1' terminated with exit code 1: stdout/stderr: ''"",
                    e.getMessage());
        }
    }
",non-flaky,5
133932,CorfuDB_CorfuDB,LayoutHandlerTest.testBootstrapLayout,"    @Test
    public void testBootstrapLayout() {
        ResponseMsg responseACK = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getBootstrapLayoutResponseMsg(true)
        );

        ResponseMsg responseNACK = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getBootstrapLayoutResponseMsg(false)
        );

        layoutHandler.handleMessage(responseACK, mockChannelHandlerContext);
        layoutHandler.handleMessage(responseNACK, mockChannelHandlerContext);

        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(responseACK.getHeader().getRequestId(), true);
        verify(mockClientRouter).completeRequest(responseNACK.getHeader().getRequestId(), false);
    }
",non-flaky,5
84571,apache_zookeeper,DistributedQueueTest.testTakeWait2,"    @Test
    public void testTakeWait2() throws Exception {
        String dir = ""/testTakeWait2"";
        final String testString = ""Hello World"";
        final int numClients = 1;
        final ZooKeeper[] clients = new ZooKeeper[numClients];
        final DistributedQueue[] queueHandles = new DistributedQueue[numClients];
        for (int i = 0; i < clients.length; i++) {
            clients[i] = createClient();
            queueHandles[i] = new DistributedQueue(clients[i], dir, null);
        }
        int numAttempts = 2;
        for (int i = 0; i < numAttempts; i++) {
            final byte[][] takeResult = new byte[1][];
            final String threadTestString = testString + i;
            Thread takeThread = new Thread(() -> {
                try {
                    takeResult[0] = queueHandles[0].take();
                } catch (KeeperException | InterruptedException ignore) {
                    // no op
                }
            });
            takeThread.start();

            Thread.sleep(1000);
            Thread offerThread = new Thread(() -> {
                try {
                    queueHandles[0].offer(threadTestString.getBytes());
                } catch (KeeperException | InterruptedException ignore) {
                    // no op
                }
            });
            offerThread.start();
            offerThread.join();

            takeThread.join();

            assertNotNull(takeResult[0]);
            assertEquals(new String(takeResult[0]), threadTestString);
        }
    }
",non-flaky,5
57202,apache_ozone,TestContainerKeyMapperTask.testReprocessOMDB,"  @Test
  public void testReprocessOMDB() throws Exception{

    Map<ContainerKeyPrefix, Integer> keyPrefixesForContainer =
        reconContainerMetadataManager.getKeyPrefixesForContainer(1);
    assertTrue(keyPrefixesForContainer.isEmpty());

    keyPrefixesForContainer = reconContainerMetadataManager
        .getKeyPrefixesForContainer(2);
    assertTrue(keyPrefixesForContainer.isEmpty());

    Pipeline pipeline = getRandomPipeline();

    List<OmKeyLocationInfo> omKeyLocationInfoList = new ArrayList<>();
    BlockID blockID1 = new BlockID(1, 1);
    OmKeyLocationInfo omKeyLocationInfo1 = getOmKeyLocationInfo(blockID1,
        pipeline);

    BlockID blockID2 = new BlockID(2, 1);
    OmKeyLocationInfo omKeyLocationInfo2
        = getOmKeyLocationInfo(blockID2, pipeline);

    omKeyLocationInfoList.add(omKeyLocationInfo1);
    omKeyLocationInfoList.add(omKeyLocationInfo2);

    OmKeyLocationInfoGroup omKeyLocationInfoGroup = new
        OmKeyLocationInfoGroup(0, omKeyLocationInfoList);

    writeDataToOm(reconOMMetadataManager,
        ""key_one"",
        ""bucketOne"",
        ""sampleVol"",
        Collections.singletonList(omKeyLocationInfoGroup));

    ContainerKeyMapperTask containerKeyMapperTask =
        new ContainerKeyMapperTask(reconContainerMetadataManager);
    containerKeyMapperTask.reprocess(reconOMMetadataManager);

    keyPrefixesForContainer =
        reconContainerMetadataManager.getKeyPrefixesForContainer(1);
    assertEquals(1, keyPrefixesForContainer.size());
    String omKey = omMetadataManager.getOzoneKey(""sampleVol"",
        ""bucketOne"", ""key_one"");
    ContainerKeyPrefix containerKeyPrefix = new ContainerKeyPrefix(1,
        omKey, 0);
    assertEquals(1,
        keyPrefixesForContainer.get(containerKeyPrefix).intValue());

    keyPrefixesForContainer =
        reconContainerMetadataManager.getKeyPrefixesForContainer(2);
    assertEquals(1, keyPrefixesForContainer.size());
    containerKeyPrefix = new ContainerKeyPrefix(2, omKey,
        0);
    assertEquals(1,
        keyPrefixesForContainer.get(containerKeyPrefix).intValue());

    // Test if container key counts are updated
    assertEquals(1, reconContainerMetadataManager.getKeyCountForContainer(1L));
    assertEquals(1, reconContainerMetadataManager.getKeyCountForContainer(2L));
    assertEquals(0, reconContainerMetadataManager.getKeyCountForContainer(3L));

    // Test if container count is updated
    assertEquals(2, reconContainerMetadataManager.getCountForContainers());
  }
",non-flaky,5
135031,undertow-io_undertow,DateUtilsTestCase.testParseChromeDate,"    @Test
    public void testParseChromeDate() {

        String chromeHeader = ""Mon, 31 Mar 2014 09:44:00 GMT"";
        Date chromeDate = DateUtils.parseDate(chromeHeader);

        Assert.assertNotNull(chromeDate);

        Calendar calendar = Calendar.getInstance(TimeZone.getTimeZone(""GMT""));
        calendar.set(2014, Calendar.MARCH, 31, 9, 44, 00);
        calendar.set(Calendar.MILLISECOND, 0);

        Assert.assertEquals(calendar.getTime(), chromeDate);

    }
",non-flaky,5
78293,apache_beam,SideInputHandlerTest.testNewInputReplacesPreviousInput,"  @Test
  public void testNewInputReplacesPreviousInput() {
    // new input should completely replace old input
    // the creation of the Iterable that has the side input
    // contents happens upstream. this is also where
    // accumulation/discarding is decided.

    SideInputHandler sideInputHandler =
        new SideInputHandler(ImmutableList.of(view1), InMemoryStateInternals.<Void>forKey(null));

    IntervalWindow window = new IntervalWindow(new Instant(0), new Instant(WINDOW_MSECS_1));

    // add a first value for view1
    sideInputHandler.addSideInputValue(
        view1,
        valuesInWindow(materializeValuesFor(View.asIterable(), ""Hello""), new Instant(0), window));

    assertThat(sideInputHandler.get(view1, window), contains(""Hello""));

    // subsequent values should replace existing values
    sideInputHandler.addSideInputValue(
        view1,
        valuesInWindow(
            materializeValuesFor(View.asIterable(), ""Ciao"", ""Buongiorno""), new Instant(0), window));

    assertThat(sideInputHandler.get(view1, window), contains(""Ciao"", ""Buongiorno""));
  }
",non-flaky,5
135761,Netflix_Hystrix,HystrixPluginsTest.testDynamicSystemProperties,"    @Test
    public void testDynamicSystemProperties() throws Exception {
        //On the off chance this is the first test lets not screw up all the other tests
        HystrixPlugins.getInstance();
        
        System.setProperty(""hystrix.plugin.HystrixDynamicProperties.implementation"", 
                ""com.netflix.hystrix.strategy.properties.HystrixDynamicPropertiesSystemProperties"");
        
        HystrixPlugins plugins = setupMockServiceLoader();
        assertTrue(plugins.getDynamicProperties() instanceof HystrixDynamicPropertiesSystemProperties);
        
        HystrixDynamicProperties p = plugins.getDynamicProperties();
        //Some minimum testing of system properties wrapper
        //this probably should be in its own test class.
        assertTrue(p.getBoolean(""USE_DEFAULT"", true).get());
        assertEquals(""string"", p.getString(""USE_DEFAULT"", ""string"").get());
        assertEquals(1L, p.getLong(""USE_DEFAULT"", 1L).get().longValue());
        assertEquals(1, p.getInteger(""USE_DEFAULT"", 1).get().intValue());
        assertNotNull(p.getString(""path.separator"", null).get());
        
        assertEvents(""[debug: [Created HystrixDynamicProperties instance from System property named \""hystrix.plugin.HystrixDynamicProperties.implementation\"". Using class: {}, com.netflix.hystrix.strategy.properties.HystrixDynamicPropertiesSystemProperties]]"");

        System.clearProperty(""hystrix.plugin.HystrixDynamicProperties.implementation"");

    }
",non-flaky,5
38637,apache_pulsar,TestApplication.testFLUME1854,"    @Test
    public void testFLUME1854() throws Exception {
        File configFile = new File(baseDir, ""flume-conf.properties"");
        Files.copy(new File(getClass().getClassLoader()
                .getResource(""flume-conf.properties"").getFile()), configFile);
        Random random = new Random();
        for (int i = 0; i < 3; i++) {
            EventBus eventBus = new EventBus(""test-event-bus"");
            PollingPropertiesFileConfigurationProvider configurationProvider =
                    new PollingPropertiesFileConfigurationProvider(""host1"",
                            configFile, eventBus, 1);
            List<LifecycleAware> components = Lists.newArrayList();
            components.add(configurationProvider);
            Application application = new Application(components);
            eventBus.register(application);
            application.start();
            Thread.sleep(random.nextInt(10000));
            application.stop();
        }
    }
",non-flaky,5
77507,dropwizard_dropwizard,AuthFilterTest.filter,"    @Test
        public void filter(ContainerRequestContext requestContext) throws IOException {
            authenticate(requestContext, ""some-password"", ""SOME_SCHEME"");
        }
",non-flaky,5
150167,apache_hive,TestHplsqlLocal.testForRange,"  @Test
  public void testForRange() throws Exception {
    run(""for_range"");
  }
",non-flaky,5
76926,Tencent_Firestorm,RssShuffleDataIteratorTest.readTest5,"  @Test
  public void readTest5() throws Exception {
    String basePath = HDFS_URI + ""readTest5"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<String, String> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 5, expectedData,
        blockIdBitmap, ""key"", KRYO_SERIALIZER, 0);

    RssShuffleDataIterator rssShuffleDataIterator = getDataIterator(basePath, blockIdBitmap, taskIdBitmap);
    // index file is deleted after iterator initialization, it should be ok, all index infos are read already
    Path indexFile = new Path(basePath + ""/appId/0/0-1/test.index"");
    fs.delete(indexFile, true);
    // sleep to wait delete operation
    Thread.sleep(10000);
    try {
      fs.listStatus(indexFile);
      fail(""Index file should be deleted"");
    } catch (Exception e) {
    }
    validateResult(rssShuffleDataIterator, expectedData, 10);
  }
",non-flaky,5
89294,apache_samza,TestLocalStoreMonitor.shouldDeleteInActiveLocalStoresOfTheJob,"  @Test
  public void shouldDeleteInActiveLocalStoresOfTheJob() throws Exception {
    File inActiveStoreDir = new File(jobDir, ""inActiveStore"");
    FileUtils.forceMkdir(inActiveStoreDir);
    File inActiveTaskDir = new File(inActiveStoreDir, ""test-task"");
    FileUtils.forceMkdir(inActiveTaskDir);
    long inActiveTaskDirSize = inActiveTaskDir.getTotalSpace();
    localStoreMonitor.monitor();
    assertTrue(""Inactive task store directory should not exist."", !inActiveTaskDir.exists());
    assertEquals(taskStoreSize + inActiveTaskDirSize, localStoreMonitorMetrics.diskSpaceFreedInBytes.getCount());
    assertEquals(2, localStoreMonitorMetrics.noOfDeletedTaskPartitionStores.getCount());
    FileUtils.deleteDirectory(inActiveStoreDir);
  }
",non-flaky,5
91488,strapdata_elassandra,IndexRecoveryIT.testRerouteRecovery,"    @TestLogging(
    public void testRerouteRecovery() throws Exception {
        logger.info(""--> start node A"");
        final String nodeA = internalCluster().startNode();

        logger.info(""--> create index on node: {}"", nodeA);
        ByteSizeValue shardSize = createAndPopulateIndex(INDEX_NAME, 1, SHARD_COUNT, REPLICA_COUNT).getShards()[0].getStats().getStore().size();

        logger.info(""--> start node B"");
        final String nodeB = internalCluster().startNode();

        ensureGreen();

        logger.info(""--> slowing down recoveries"");
        slowDownRecovery(shardSize);

        logger.info(""--> move shard from: {} to: {}"", nodeA, nodeB);
        client().admin().cluster().prepareReroute()
                .add(new MoveAllocationCommand(INDEX_NAME, 0, nodeA, nodeB))
                .execute().actionGet().getState();

        logger.info(""--> waiting for recovery to start both on source and target"");
        final Index index = resolveIndex(INDEX_NAME);
        assertBusy(() -> {
            IndicesService indicesService = internalCluster().getInstance(IndicesService.class, nodeA);
            assertThat(indicesService.indexServiceSafe(index).getShard(0).recoveryStats().currentAsSource(),
                    equalTo(1));
            indicesService = internalCluster().getInstance(IndicesService.class, nodeB);
            assertThat(indicesService.indexServiceSafe(index).getShard(0).recoveryStats().currentAsTarget(),
                    equalTo(1));
        });

        logger.info(""--> request recoveries"");
        RecoveryResponse response = client().admin().indices().prepareRecoveries(INDEX_NAME).execute().actionGet();

        List<RecoveryState> recoveryStates = response.shardRecoveryStates().get(INDEX_NAME);
        List<RecoveryState> nodeARecoveryStates = findRecoveriesForTargetNode(nodeA, recoveryStates);
        assertThat(nodeARecoveryStates.size(), equalTo(1));
        List<RecoveryState> nodeBRecoveryStates = findRecoveriesForTargetNode(nodeB, recoveryStates);
        assertThat(nodeBRecoveryStates.size(), equalTo(1));

        assertRecoveryState(nodeARecoveryStates.get(0), 0, RecoverySource.EmptyStoreRecoverySource.INSTANCE, true, Stage.DONE, null, nodeA);
        validateIndexRecoveryState(nodeARecoveryStates.get(0).getIndex());

        assertOnGoingRecoveryState(nodeBRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, true, nodeA, nodeB);
        validateIndexRecoveryState(nodeBRecoveryStates.get(0).getIndex());

        logger.info(""--> request node recovery stats"");
        NodesStatsResponse statsResponse = client().admin().cluster().prepareNodesStats().clear().setIndices(new CommonStatsFlags(CommonStatsFlags.Flag.Recovery)).get();
        long nodeAThrottling = Long.MAX_VALUE;
        long nodeBThrottling = Long.MAX_VALUE;
        for (NodeStats nodeStats : statsResponse.getNodes()) {
            final RecoveryStats recoveryStats = nodeStats.getIndices().getRecoveryStats();
            if (nodeStats.getNode().getName().equals(nodeA)) {
                assertThat(""node A should have ongoing recovery as source"", recoveryStats.currentAsSource(), equalTo(1));
                assertThat(""node A should not have ongoing recovery as target"", recoveryStats.currentAsTarget(), equalTo(0));
                nodeAThrottling = recoveryStats.throttleTime().millis();
            }
            if (nodeStats.getNode().getName().equals(nodeB)) {
                assertThat(""node B should not have ongoing recovery as source"", recoveryStats.currentAsSource(), equalTo(0));
                assertThat(""node B should have ongoing recovery as target"", recoveryStats.currentAsTarget(), equalTo(1));
                nodeBThrottling = recoveryStats.throttleTime().millis();
            }
        }

        logger.info(""--> checking throttling increases"");
        final long finalNodeAThrottling = nodeAThrottling;
        final long finalNodeBThrottling = nodeBThrottling;
        assertBusy(() -> {
            NodesStatsResponse statsResponse1 = client().admin().cluster().prepareNodesStats().clear().setIndices(new CommonStatsFlags(CommonStatsFlags.Flag.Recovery)).get();
            assertThat(statsResponse1.getNodes(), hasSize(2));
            for (NodeStats nodeStats : statsResponse1.getNodes()) {
                final RecoveryStats recoveryStats = nodeStats.getIndices().getRecoveryStats();
                if (nodeStats.getNode().getName().equals(nodeA)) {
                    assertThat(""node A throttling should increase"", recoveryStats.throttleTime().millis(), greaterThan(finalNodeAThrottling));
                }
                if (nodeStats.getNode().getName().equals(nodeB)) {
                    assertThat(""node B throttling should increase"", recoveryStats.throttleTime().millis(), greaterThan(finalNodeBThrottling));
                }
            }
        });


        logger.info(""--> speeding up recoveries"");
        restoreRecoverySpeed();

        // wait for it to be finished
        ensureGreen();

        response = client().admin().indices().prepareRecoveries(INDEX_NAME).execute().actionGet();

        recoveryStates = response.shardRecoveryStates().get(INDEX_NAME);
        assertThat(recoveryStates.size(), equalTo(1));

        assertRecoveryState(recoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, true, Stage.DONE, nodeA, nodeB);
        validateIndexRecoveryState(recoveryStates.get(0).getIndex());
        Consumer<String> assertNodeHasThrottleTimeAndNoRecoveries = nodeName ->  {
            NodesStatsResponse nodesStatsResponse = client().admin().cluster().prepareNodesStats().setNodesIds(nodeName)
                .clear().setIndices(new CommonStatsFlags(CommonStatsFlags.Flag.Recovery)).get();
            assertThat(nodesStatsResponse.getNodes(), hasSize(1));
            NodeStats nodeStats = nodesStatsResponse.getNodes().get(0);
            final RecoveryStats recoveryStats = nodeStats.getIndices().getRecoveryStats();
            assertThat(recoveryStats.currentAsSource(), equalTo(0));
            assertThat(recoveryStats.currentAsTarget(), equalTo(0));
            assertThat(nodeName + "" throttling should be >0"", recoveryStats.throttleTime().millis(), greaterThan(0L));
        };
        // we have to use assertBusy as recovery counters are decremented only when the last reference to the RecoveryTarget
        // is decremented, which may happen after the recovery was done.
        assertBusy(() -> assertNodeHasThrottleTimeAndNoRecoveries.accept(nodeA));
        assertBusy(() -> assertNodeHasThrottleTimeAndNoRecoveries.accept(nodeB));

        logger.info(""--> bump replica count"");
        client().admin().indices().prepareUpdateSettings(INDEX_NAME)
                .setSettings(Settings.builder().put(""number_of_replicas"", 1)).execute().actionGet();
        ensureGreen();

        assertBusy(() -> assertNodeHasThrottleTimeAndNoRecoveries.accept(nodeA));
        assertBusy(() -> assertNodeHasThrottleTimeAndNoRecoveries.accept(nodeB));

        logger.info(""--> start node C"");
        String nodeC = internalCluster().startNode();
        assertFalse(client().admin().cluster().prepareHealth().setWaitForNodes(""3"").get().isTimedOut());

        logger.info(""--> slowing down recoveries"");
        slowDownRecovery(shardSize);

        logger.info(""--> move replica shard from: {} to: {}"", nodeA, nodeC);
        client().admin().cluster().prepareReroute()
                .add(new MoveAllocationCommand(INDEX_NAME, 0, nodeA, nodeC))
                .execute().actionGet().getState();

        response = client().admin().indices().prepareRecoveries(INDEX_NAME).execute().actionGet();
        recoveryStates = response.shardRecoveryStates().get(INDEX_NAME);

        nodeARecoveryStates = findRecoveriesForTargetNode(nodeA, recoveryStates);
        assertThat(nodeARecoveryStates.size(), equalTo(1));
        nodeBRecoveryStates = findRecoveriesForTargetNode(nodeB, recoveryStates);
        assertThat(nodeBRecoveryStates.size(), equalTo(1));
        List<RecoveryState> nodeCRecoveryStates = findRecoveriesForTargetNode(nodeC, recoveryStates);
        assertThat(nodeCRecoveryStates.size(), equalTo(1));

        assertRecoveryState(nodeARecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, false, Stage.DONE, nodeB, nodeA);
        validateIndexRecoveryState(nodeARecoveryStates.get(0).getIndex());

        assertRecoveryState(nodeBRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, true, Stage.DONE, nodeA, nodeB);
        validateIndexRecoveryState(nodeBRecoveryStates.get(0).getIndex());

        // relocations of replicas are marked as REPLICA and the source node is the node holding the primary (B)
        assertOnGoingRecoveryState(nodeCRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, false, nodeB, nodeC);
        validateIndexRecoveryState(nodeCRecoveryStates.get(0).getIndex());

        if (randomBoolean()) {
            // shutdown node with relocation source of replica shard and check if recovery continues
            internalCluster().stopRandomNode(InternalTestCluster.nameFilter(nodeA));
            ensureStableCluster(2);

            response = client().admin().indices().prepareRecoveries(INDEX_NAME).execute().actionGet();
            recoveryStates = response.shardRecoveryStates().get(INDEX_NAME);

            nodeARecoveryStates = findRecoveriesForTargetNode(nodeA, recoveryStates);
            assertThat(nodeARecoveryStates.size(), equalTo(0));
            nodeBRecoveryStates = findRecoveriesForTargetNode(nodeB, recoveryStates);
            assertThat(nodeBRecoveryStates.size(), equalTo(1));
            nodeCRecoveryStates = findRecoveriesForTargetNode(nodeC, recoveryStates);
            assertThat(nodeCRecoveryStates.size(), equalTo(1));

            assertRecoveryState(nodeBRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, true, Stage.DONE, nodeA, nodeB);
            validateIndexRecoveryState(nodeBRecoveryStates.get(0).getIndex());

            assertOnGoingRecoveryState(nodeCRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, false, nodeB, nodeC);
            validateIndexRecoveryState(nodeCRecoveryStates.get(0).getIndex());
        }

        logger.info(""--> speeding up recoveries"");
        restoreRecoverySpeed();
        ensureGreen();

        response = client().admin().indices().prepareRecoveries(INDEX_NAME).execute().actionGet();
        recoveryStates = response.shardRecoveryStates().get(INDEX_NAME);

        nodeARecoveryStates = findRecoveriesForTargetNode(nodeA, recoveryStates);
        assertThat(nodeARecoveryStates.size(), equalTo(0));
        nodeBRecoveryStates = findRecoveriesForTargetNode(nodeB, recoveryStates);
        assertThat(nodeBRecoveryStates.size(), equalTo(1));
        nodeCRecoveryStates = findRecoveriesForTargetNode(nodeC, recoveryStates);
        assertThat(nodeCRecoveryStates.size(), equalTo(1));

        assertRecoveryState(nodeBRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, true, Stage.DONE, nodeA, nodeB);
        validateIndexRecoveryState(nodeBRecoveryStates.get(0).getIndex());

        // relocations of replicas are marked as REPLICA and the source node is the node holding the primary (B)
        assertRecoveryState(nodeCRecoveryStates.get(0), 0, PeerRecoverySource.INSTANCE, false, Stage.DONE, nodeB, nodeC);
        validateIndexRecoveryState(nodeCRecoveryStates.get(0).getIndex());
    }
",non-flaky,5
98399,ONSdigital_rm-collection-exercise-service,MandatoryEventValidatorTest.testInvalidGoLiveEventUpdate,"  @Test
  public void testInvalidGoLiveEventUpdate() {
    final List<Event> events = createMandatoryEvents();

    final Event goLiveEvent = new Event();
    goLiveEvent.setTag(Tag.go_live.toString());
    goLiveEvent.setTimestamp(Timestamp.from(Instant.now().plus(8, ChronoUnit.DAYS)));

    CTPException actualException = null;
    try {
      mandatoryValidator.validate(events, goLiveEvent, CollectionExerciseState.SCHEDULED);
    } catch (CTPException expectedException) {
      actualException = expectedException;
    }
    assertNotNull(actualException);
    assertEquals(
        ""Collection exercise events must be set sequentially"", actualException.getMessage());
  }
",non-flaky,5
76921,Tencent_Firestorm,RssShuffleUtilsTest.odfsConfigurationTest,"  @Test
  public void odfsConfigurationTest() {
    SparkConf conf = new SparkConf();
    Configuration conf1 = RssShuffleUtils.newHadoopConfiguration(conf);
    assertFalse(conf1.getBoolean(""dfs.namenode.odfs.enable"", false));
    assertEquals(""org.apache.hadoop.fs.Hdfs"", conf1.get(""fs.AbstractFileSystem.hdfs.impl""));

    conf.set(RssClientConfig.RSS_OZONE_DFS_NAMENODE_ODFS_ENABLE, ""true"");
    conf1 = RssShuffleUtils.newHadoopConfiguration(conf);
    assertTrue(conf1.getBoolean(""dfs.namenode.odfs.enable"", false));
    assertEquals(""org.apache.hadoop.odfs.HdfsOdfsFilesystem"", conf1.get(""fs.hdfs.impl""));
    assertEquals(""org.apache.hadoop.odfs.HdfsOdfs"", conf1.get(""fs.AbstractFileSystem.hdfs.impl""));

    conf.set(RssClientConfig.RSS_OZONE_FS_HDFS_IMPL, ""expect_odfs_impl"");
    conf.set(RssClientConfig.RSS_OZONE_FS_ABSTRACT_FILE_SYSTEM_HDFS_IMPL, ""expect_odfs_abstract_impl"");
    conf1 = RssShuffleUtils.newHadoopConfiguration(conf);
    assertEquals(""expect_odfs_impl"", conf1.get(""fs.hdfs.impl""));
    assertEquals(""expect_odfs_abstract_impl"", conf1.get(""fs.AbstractFileSystem.hdfs.impl""));
  }
",non-flaky,5
60922,apache_druid,DoubleMeanNoNullAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new DoubleMeanNoNullAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(DoubleMeanNoNullAverager.class));
  }
",non-flaky,5
99735,apache_cassandra,FQLReplayTest.testCompare,"    @Test
    public void testCompare()
    {
        FQLQuery q1 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222, ""aaaa"", Collections.emptyList());
        FQLQuery q2 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222,""aaaa"", Collections.emptyList());

        assertEquals(0, q1.compareTo(q2));
        assertEquals(0, q2.compareTo(q1));

        FQLQuery q3 = new FQLQuery.Batch(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222, com.datastax.driver.core.BatchStatement.Type.UNLOGGED, Collections.emptyList(), Collections.emptyList());
        // single queries before batch queries
        assertTrue(q1.compareTo(q3) < 0);
        assertTrue(q3.compareTo(q1) > 0);

        // check that smaller query time
        FQLQuery q4 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 124, 111, 222, ""aaaa"", Collections.emptyList());
        assertTrue(q1.compareTo(q4) < 0);
        assertTrue(q4.compareTo(q1) > 0);

        FQLQuery q5 = new FQLQuery.Batch(""abc"", 0, QueryOptions.DEFAULT, 124, 111, 222, com.datastax.driver.core.BatchStatement.Type.UNLOGGED, Collections.emptyList(), Collections.emptyList());
        assertTrue(q1.compareTo(q5) < 0);
        assertTrue(q5.compareTo(q1) > 0);

        FQLQuery q6 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222, ""aaaa"", Collections.singletonList(ByteBufferUtil.bytes(10)));
        FQLQuery q7 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222, ""aaaa"", Collections.emptyList());
        assertTrue(q6.compareTo(q7) > 0);
        assertTrue(q7.compareTo(q6) < 0);

        FQLQuery q8 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222, ""aaaa"", Collections.singletonList(ByteBufferUtil.bytes(""a"")));
        FQLQuery q9 = new FQLQuery.Single(""abc"", 0, QueryOptions.DEFAULT, 123, 111, 222, ""aaaa"", Collections.singletonList(ByteBufferUtil.bytes(""b"")));
        assertTrue(q8.compareTo(q9) < 0);
        assertTrue(q9.compareTo(q8) > 0);
    }
",non-flaky,5
60920,apache_druid,DoubleMaxAveragerTest.testComputeResult,"  @Test
  public void testComputeResult()
  {
    BaseAverager<Number, Double> avg = new DoubleMaxAverager(3, ""test"", ""field"", 1);

    Assert.assertEquals(Double.NEGATIVE_INFINITY, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", -1.1e100), new HashMap<>());
    Assert.assertEquals(-1.1e100, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 1.0), new HashMap<>());
    Assert.assertEquals(1.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 1), new HashMap<>());
    Assert.assertEquals(1.0, avg.computeResult(), 0.0);

    avg.addElement(Collections.singletonMap(""field"", 5.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 3.0), new HashMap<>());
    avg.addElement(Collections.singletonMap(""field"", 2.0), new HashMap<>());
    Assert.assertEquals(5.0, avg.computeResult(), 0.0);

    avg.skip();
    Assert.assertEquals(3.0, avg.computeResult(), 0.0);
  }
",non-flaky,5
136506,doanduyhai_Achilles,FrozenNestedTypeStrategyTest.should_fail_for_non_frozen_map_list,"    @Test
    public void should_fail_for_non_frozen_map_list() throws Exception {
        setExec(aptUtils -> {
            final NestedTypeValidator2_1 strategy = new NestedTypeValidator2_1();
            final String className = TestEntityWithNestedTypes.class.getCanonicalName();
            final TypeName rawClass = ClassName.get(TestEntityWithNestedTypes.class);
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            // private Map<Integer, List<String>> mapList;
            VariableElement elm = findFieldInType(typeElement, ""mapList"");
            final AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils, globalParsingContext, elm);
            strategy.validate(aptUtils, annotationTree, ""mapList"", rawClass);
        });
        failTestWithMessage(""collections/array type/UDT "" +
                ""'java.util.List<java.lang.String>' "" +
                ""in 'mapList' "" +
                ""of class 'info.archinnov.achilles.internals.sample_classes.parser.strategy.TestEntityWithNestedTypes' "" +
                ""should be annotated with @Frozen"", TestEntityWithNestedTypes.class);
    }
",non-flaky,5
33863,apache_camel,FhirCreateIT.testCreateResource,"    @Test
    public void testCreateResource() throws Exception {
        Patient patient = new Patient().addName(new HumanName().addGiven(""Vincent"").setFamily(""Freeman""));

        MethodOutcome result = requestBody(""direct://RESOURCE"", patient);

        LOG.debug(""resource: "" + result);
        assertNotNull(result, ""resource result"");
        assertTrue(result.getCreated());
    }
",non-flaky,5
135799,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testSingleSuccess,"    @Test
    public void testSingleSuccess() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-B"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.SUCCESS, 20);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.SUCCESS.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
110143,Wikidata_wikidata-toolkit,ClientConfigurationTest.testLanguageFilterArguments,"	@Test
	public void testLanguageFilterArguments() {
		String[] args = new String[] { ""--fLang"", ""en,de"" };
		ClientConfiguration config = new ClientConfiguration(args);

		Set<String> langFilters = new HashSet<>();
		langFilters.add(""en"");
		langFilters.add(""de"");

		assertEquals(langFilters, config.getFilterLanguages());
	}
",non-flaky,5
77002,Tencent_Firestorm,ShuffleServerWithLocalTest.localWriteReadTest,"  @Test
  public void localWriteReadTest() throws Exception {
    String testAppId = ""localWriteReadTest"";
    RssRegisterShuffleRequest rrsr = new RssRegisterShuffleRequest(testAppId, 0,
        Lists.newArrayList(new PartitionRange(0, 1)));
    shuffleServerClient.registerShuffle(rrsr);
    rrsr = new RssRegisterShuffleRequest(testAppId, 0, Lists.newArrayList(new PartitionRange(2, 3)));
    shuffleServerClient.registerShuffle(rrsr);

    Map<Long, byte[]> expectedData = Maps.newHashMap();

    Roaring64NavigableMap[] bitmaps = new Roaring64NavigableMap[4];
    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = createTestData(bitmaps, expectedData);

    Set<Long> expectedBlockIds1 = transBitmapToSet(bitmaps[0]);
    Set<Long> expectedBlockIds2 = transBitmapToSet(bitmaps[1]);
    Set<Long> expectedBlockIds3 = transBitmapToSet(bitmaps[2]);
    Set<Long> expectedBlockIds4 = transBitmapToSet(bitmaps[3]);

    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);

    RssSendShuffleDataRequest rssdr = new RssSendShuffleDataRequest(
        testAppId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    RssSendCommitRequest rscr = new RssSendCommitRequest(testAppId, 0);
    shuffleServerClient.sendCommit(rscr);
    RssFinishShuffleRequest rfsr = new RssFinishShuffleRequest(testAppId, 0);
    shuffleServerClient.finishShuffle(rfsr);

    ShuffleDataResult sdr  = readShuffleData(
        shuffleServerClient, testAppId, 0, 0, 2,
        10, 1000, 0);
    validateResult(sdr, expectedBlockIds1, expectedData, 0);
    sdr  = readShuffleData(
        shuffleServerClient, testAppId, 0, 1, 2,
        10, 1000, 0);
    validateResult(sdr, expectedBlockIds2, expectedData, 1);
    sdr  = readShuffleData(
        shuffleServerClient, testAppId, 0, 2, 2,
        10, 1000, 0);
    validateResult(sdr, expectedBlockIds3, expectedData, 2);
    sdr  = readShuffleData(
        shuffleServerClient, testAppId, 0, 3, 2,
        10, 1000, 0);
    validateResult(sdr, expectedBlockIds4, expectedData, 3);

    assertEquals(4, shuffleServers.get(0).getShuffleTaskManager()
        .getServerReadHandlers().get(testAppId).size());
    assertNotNull(shuffleServers.get(0).getShuffleTaskManager()
        .getPartitionsToBlockIds().get(testAppId));
    Thread.sleep(8000);
    assertNull(shuffleServers.get(0).getShuffleTaskManager().getServerReadHandlers().get(testAppId));
    assertNull(shuffleServers.get(0).getShuffleTaskManager().getPartitionsToBlockIds().get(testAppId));
  }
",non-flaky,5
43062,trinodb_trino,BaseConnectorTest.testExplainAnalyze,"    @Test
    public void testExplainAnalyze()
    {
        assertExplainAnalyze(""EXPLAIN ANALYZE SELECT * FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SELECT count(*), clerk FROM orders GROUP BY clerk"");
        assertExplainAnalyze(
                ""EXPLAIN ANALYZE SELECT x + y FROM ("" +
                        ""   SELECT orderdate, COUNT(*) x FROM orders GROUP BY orderdate) a JOIN ("" +
                        ""   SELECT orderdate, COUNT(*) y FROM orders GROUP BY orderdate) b ON a.orderdate = b.orderdate"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SELECT count(*), clerk FROM orders GROUP BY clerk UNION ALL SELECT sum(orderkey), clerk FROM orders GROUP BY clerk"");

        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW COLUMNS FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE EXPLAIN SELECT count(*) FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE EXPLAIN ANALYZE SELECT count(*) FROM orders"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW FUNCTIONS"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW TABLES"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW SCHEMAS"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW CATALOGS"");
        assertExplainAnalyze(""EXPLAIN ANALYZE SHOW SESSION"");
    }
",non-flaky,5
113996,apache_struts,UploadedFileConverterTest.convertUploadedFileToFile,"    @Test
    public void convertUploadedFileToFile() throws Exception {
        // given
        UploadedFileConverter ufc = new UploadedFileConverter();
        UploadedFile uploadedFile = new StrutsUploadedFile(tempFile);

        // when
        Object result = ufc.convertValue(context, target, member, propertyName, uploadedFile, File.class);

        // then
        assertThat(result).isInstanceOf(File.class);
        File file = (File) result;
        assertThat(file.length()).isEqualTo(tempFile.length());
        assertThat(file.getAbsolutePath()).isEqualTo(tempFile.getAbsolutePath());
    }
",non-flaky,5
77450,opensearch-project_OpenSearch,DependencyLicensesTaskTests.givenProjectWithAIgnoreShaConfigurationAndNoShaFileThenShouldReturnSilently,"    @Test
    public void givenProjectWithAIgnoreShaConfigurationAndNoShaFileThenShouldReturnSilently() throws Exception {
        project.getDependencies().add(""compile"", dependency);

        File licensesDir = getLicensesDir(project);
        createFileIn(licensesDir, ""groovy-all-LICENSE.txt"", PERMISSIVE_LICENSE_TEXT);
        createFileIn(licensesDir, ""groovy-all-NOTICE.txt"", """");

        task.get().ignoreSha(""groovy-all"");
        task.get().checkDependencies();
    }
",non-flaky,5
170453,eclipse_jetty.project,ObjectMBeanTest.after,"    @AfterEach
    public void after()
    {
        container.destroy();
        container = null;
    }
",non-flaky,5
98406,ONSdigital_rm-collection-exercise-service,ReferencePeriodEventValidatorTest.testReferenceStartCanBeSetInThePast,"  @Test
  public void testReferenceStartCanBeSetInThePast() throws CTPException {
    final Event refStart = new Event();
    refStart.setTag((Tag.ref_period_start.toString()));
    refStart.setTimestamp(Timestamp.from(Instant.now().minus(1, ChronoUnit.DAYS)));

    final List<Event> events = new ArrayList<>();
    referencePeriodValidator.validate(events, refStart, CollectionExerciseState.CREATED);
  }
",non-flaky,5
33717,alibaba_fastjson,JSONPathTest.eq2,"  @Test
  public void eq2() throws Throwable {
    // Arrange
    Object a = null;
    Object b = null;
    // Act
    Class<?> c = Reflector.forName(""com.alibaba.fastjson.JSONPath"");
    Method m = c.getDeclaredMethod(""eq"", Reflector.forName(""java.lang.Object""), Reflector.forName(""java.lang.Object""));
    m.setAccessible(true);
    boolean retval = (Boolean)m.invoke(null, a, b);
    // Assert result
    Assert.assertEquals(true, retval);
  }
",non-flaky,5
136536,doanduyhai_Achilles,EntityMetaCodeGenTest.should_build_entity_with_static_annotations,"    @Test
    public void should_build_entity_with_static_annotations() throws Exception {
        setExec(aptUtils -> {
            final String className = TestEntityWithStaticAnnotations.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final List<FieldParser.FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, context);
            final TypeSpec typeSpec = builder.buildEntityMeta(EntityType.TABLE, typeElement, context, parsingResults, emptyList()).sourceCode;

            assertThat(buildSource(typeSpec)).isEqualTo(
                    readCodeBlockFromFile(""expected_code/entity_meta_builder/should_build_entity_with_static_annotations.txt""));
        });
        launchTest(TestEntityWithStaticAnnotations.class);
    }
",non-flaky,5
159686,liquibase_liquibase,MarkChangeSetRanExecuteTest.generateSql_insert,"    @Test
    public void generateSql_insert() throws Exception {
        this.statementUnderTest = new MarkChangeSetRanStatement(new ChangeSet(""a"", ""b"", false, false, ""c"", ""e"", ""f"",
                null), ChangeSet.ExecType.EXECUTED);
        String version = LiquibaseUtil.getBuildVersion().replaceAll(""SNAPSHOT"", ""SNP"");
        assertCorrect(""insert into [databasechangelog] ([id], [author], [filename], [dateexecuted], "" +
                        ""[orderexecuted], [md5sum], [description], [comments], [exectype], [contexts], [labels], "" +
                        ""[liquibase], [deployment_id]) values ('a', 'b', 'c', getdate(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                MSSQLDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', systimestamp, 1, '8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', "" +
                        ""'executed', 'e', null, '"" + version + ""', null)"",
                OracleDatabase.class);
        assertCorrect(""insert into [databasechangelog] ([id], [author], [filename], [dateexecuted], "" +
                        ""[orderexecuted], [md5sum], [description], [comments], [exectype], [contexts], [labels], "" +
                        ""[liquibase], [deployment_id]) values ('a', 'b', 'c', getdate(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                SybaseDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', "" +
                        ""current year to fraction(5), 1, '8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', "" +
                        ""'executed', "" +
                        ""'e', null, '"" + version + ""', null)"",
                InformixDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', current timestamp, 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                DB2Database.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', current_timestamp, 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                FirebirdDatabase.class, DerbyDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', now, 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                HsqlDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', now(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                SybaseASADatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, `description`, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', now(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                MySQLDatabase.class, MariaDBDatabase.class);
        assertCorrect(""insert into databasechangelog (id, author, filename, dateexecuted, orderexecuted, "" +
                        ""md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) values "" +
                        ""('a', 'b', 'c', now(), 1, "" +
                        ""'8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, '"" + version + ""',"" +
                        "" null)"",
                PostgresDatabase.class, H2Database.class);
        assertCorrectOnRest(""insert into databasechangelog (id, author, filename, dateexecuted, "" +
                ""orderexecuted, md5sum, description, comments, exectype, contexts, labels, liquibase, deployment_id) "" +
                ""values ('a', 'b', 'c', "" +
                ""current timestamp, 1, '8:d41d8cd98f00b204e9800998ecf8427e', 'empty', '', 'executed', 'e', null, "" +
                ""'"" + version + ""', null)"");
    }
",non-flaky,5
13897,neo4j_neo4j,BackupHaIT.makeSureBackupCanBePerformedFromClusterWithDefaultName,"    @Test
    public void makeSureBackupCanBePerformedFromClusterWithDefaultName() throws Throwable
    {
        testBackupFromCluster( null );
    }
",non-flaky,5
96887,apache_avro,TestSchemas.testGetJavaClassName,"  @Test
  public void testGetJavaClassName() {
    Assert.assertEquals(""N"", Schemas.getJavaClassName(
        new Schema.Parser().parse(""{\""type\"": \""fixed\"", \""name\"": \""N\"", \""size\"": 10}"")));
    Assert.assertEquals(""N"", Schemas.getJavaClassName(
        new Schema.Parser().parse(""{\""type\"": \""fixed\"", \""name\"": \""N\"", \""size\"": 10, \""namespace\"": \""\""}"")));
    Assert.assertEquals(""com.example.N"", Schemas.getJavaClassName(
        new Schema.Parser().parse(""{\""type\"": \""fixed\"", \""name\"": \""N\"", \""size\"": 10, \""namespace\"": \""com.example\""}"")));
  }
",non-flaky,5
78250,apache_beam,StateInternalsTest.testCombiningIsEmpty,"  @Test
  public void testCombiningIsEmpty() throws Exception {
    GroupingState<Integer, Integer> value = underTest.state(NAMESPACE_1, SUM_INTEGER_ADDR);

    assertThat(value.isEmpty().read(), Matchers.is(true));
    ReadableState<Boolean> readFuture = value.isEmpty();
    value.add(5);
    assertThat(readFuture.read(), Matchers.is(false));

    value.clear();
    assertThat(readFuture.read(), Matchers.is(true));
  }
",non-flaky,5
170532,eclipse_jetty.project,TestSecurityAnnotationConversions.testMethodAnnotation2,"    @Test
    public void testMethodAnnotation2() throws Exception
    {
        //A ServletSecurity annotation that has HttpConstraint of CONFIDENTIAL with defined roles, but a
        //HttpMethodConstraint for GET that permits all, but also requires CONFIDENTIAL
        WebAppContext wac = makeWebAppContext(Method2Servlet.class.getCanonicalName(), ""method2Servlet"", new String[]{
            ""/foo/*"", ""*.foo""
        });

        AnnotationIntrospector introspector = new AnnotationIntrospector(wac);
        ServletSecurityAnnotationHandler annotationHandler = new ServletSecurityAnnotationHandler(wac);
        introspector.registerHandler(annotationHandler);

        //set up the expected outcomes: - a Constraint for the RolesAllowed on the class
        //with userdata constraint of DC_CONFIDENTIAL
        //and mappings for each of the pathSpecs
        Constraint expectedConstraint1 = new Constraint();
        expectedConstraint1.setAuthenticate(true);
        expectedConstraint1.setRoles(new String[]{""tom"", ""dick"", ""harry""});
        expectedConstraint1.setDataConstraint(Constraint.DC_CONFIDENTIAL);

        //a Constraint for the Permit on the GET method with a userdata
        //constraint of DC_CONFIDENTIAL
        Constraint expectedConstraint2 = new Constraint();
        expectedConstraint2.setDataConstraint(Constraint.DC_CONFIDENTIAL);

        ConstraintMapping[] expectedMappings = new ConstraintMapping[4];
        expectedMappings[0] = new ConstraintMapping();
        expectedMappings[0].setConstraint(expectedConstraint1);
        expectedMappings[0].setPathSpec(""/foo/*"");
        expectedMappings[0].setMethodOmissions(new String[]{""GET""});
        expectedMappings[1] = new ConstraintMapping();
        expectedMappings[1].setConstraint(expectedConstraint1);
        expectedMappings[1].setPathSpec(""*.foo"");
        expectedMappings[1].setMethodOmissions(new String[]{""GET""});

        expectedMappings[2] = new ConstraintMapping();
        expectedMappings[2].setConstraint(expectedConstraint2);
        expectedMappings[2].setPathSpec(""/foo/*"");
        expectedMappings[2].setMethod(""GET"");
        expectedMappings[3] = new ConstraintMapping();
        expectedMappings[3].setConstraint(expectedConstraint2);
        expectedMappings[3].setPathSpec(""*.foo"");
        expectedMappings[3].setMethod(""GET"");

        introspector.introspect(new Method2Servlet(), null);
        compareResults(expectedMappings, ((ConstraintAware)wac.getSecurityHandler()).getConstraintMappings());
    }
",non-flaky,5
76942,Tencent_Firestorm,ShuffleReadClientImplTest.readTest2,"  @Test
  public void readTest2() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest2"";
    HdfsShuffleWriteHandler writeHandler1 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test2_1"", conf);
    HdfsShuffleWriteHandler writeHandler2 =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test2_2"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler1, 2, 30, 0, expectedData, blockIdBitmap);
    writeTestData(writeHandler2, 2, 30, 0, expectedData, blockIdBitmap);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());

    TestUtils.validateResult(readClient, expectedData);
    readClient.checkProcessedBlockIds();
    readClient.close();
  }
",non-flaky,5
77550,dropwizard_dropwizard,LogbackExcludedTest.testBuildConfigurationMetadata,"    @Test
    public void testBuildConfigurationMetadata(CheckedConsumer<String> classFilter) throws Exception {
        try (ByteArrayOutputStream byteStream = captureStderr();
                CustomClassLoader loader = new CustomClassLoader(classFilter)) {
            // create class objects from custom loader
            Class<ConfigurationMetadata> cmType = loader.reloadClass(ConfigurationMetadata.class);
            Class<ObjectMapper> omType = loader.reloadClass(ObjectMapper.class);
            Class<Configuration> confType = loader.reloadClass(Configuration.class);
            // construct ConfigurationMetadata object using class object associated with custom loader so that we can
            // simulate Logback not being in the classpath
            cmType.getConstructor(omType, Class.class).newInstance(omType.newInstance(), confType);

            // make sure nothing is emitted to stderr; previously the absence of Logback in the classpath would cause
            // ""class io.dropwizard.configuration.ConfigurationMetadata$1: Type ch.qos.logback.access.spi.IAccessEvent
            // not present"" to be emitted to stderr
            String err = byteStream.toString();
            assertThat(err).isEmpty();
        }
    }
",non-flaky,5
156127,soot-oss_soot,Issue1146Test.getVertrag2Test,"  @Test
  public void getVertrag2Test() {
    String testClass = ""soot.lambdaMetaFactory.Issue1146"";

    final SootMethod target = prepareTarget(
        methodSigFromComponents(testClass, ""soot.lambdaMetaFactory.Issue1146$Vertrag"", ""getVertrag2"", ""java.lang.String""),
        testClass, ""java.util.function.Function"");
    // if no exception is thrown, everything is working as intended
  }
",non-flaky,5
60943,apache_druid,RowBucketIterableTest.testApplyLastDayMultipleRows,"  @Test
  public void testApplyLastDayMultipleRows()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);

    List<Row> expectedDay1 = Arrays.asList(JAN_1_M_10, JAN_1_F_20);
    List<Row> expectedDay2 = Collections.singletonList(JAN_2_M_10);
    List<Row> expectedDay3 = Collections.singletonList(JAN_3_F_20);
    List<Row> expectedDay4 = Arrays.asList(JAN_4_M_10, JAN_4_F_20, JAN_4_U_30);

    rows = new ArrayList<>();
    rows.add(JAN_1_M_10);
    rows.add(JAN_1_F_20);
    rows.add(JAN_2_M_10);
    rows.add(JAN_3_F_20);
    rows.add(JAN_4_M_10);
    rows.add(JAN_4_F_20);
    rows.add(JAN_4_U_30);

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    RowBucket actual = iter.next();
    Assert.assertEquals(expectedDay1, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay2, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay3, actual.getRows());

    actual = iter.next();
    Assert.assertEquals(expectedDay4, actual.getRows());
  }
",non-flaky,5
170467,eclipse_jetty.project,PojoTest.testOpenPojo,"    @Test
    public void testOpenPojo()
    {
        Validator validator = ValidatorBuilder.create().with(new SetterTester()).with(new GetterTester()).build();
        List<Class> classes = Arrays.asList(MBeanContainer.class, ObjectMBean.class);
        for (Class clazz : classes)
        {
            validator.validate(PojoClassFactory.getPojoClass(clazz));
        }
    }
",non-flaky,5
135795,Netflix_Hystrix,CumulativeCollapserEventCounterStreamTest.testCollapsed,"    @Test
    public void testCollapsed() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-B"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(10).subscribe(getSubscriber(latch));

        for (int i = 0; i < 3; i++) {
            CommandStreamTest.Collapser.from(key, i).observe();
        }

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.Collapser.values().length];
        expected[HystrixEventType.Collapser.BATCH_EXECUTED.ordinal()] = 1;
        expected[HystrixEventType.Collapser.ADDED_TO_BATCH.ordinal()] = 3;
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
136494,doanduyhai_Achilles,SnakeCaseNamingTest.should_return_snake_case,"    @Test
    public void should_return_snake_case() throws Exception {
        //Given
        String name = ""theBigOne__andSmaller_One"";

        //When
        final String actual = strategy.apply(name);

        //Then
        assertThat(actual).isEqualTo(""the_big_one_and_smaller_one"");
    }
",non-flaky,5
59599,looly_hutool,PinyinUtilTest.getFirstLetterByBopomofo4jTest,"	@Test
	public void getFirstLetterByBopomofo4jTest(){
		final Bopomofo4jEngine engine = new Bopomofo4jEngine();
		final String result = engine.getFirstLetter(""ææµ·"", """");
		Assert.assertEquals(""lh"", result);
	}
",non-flaky,5
135046,undertow-io_undertow,NetworkUtilsAddressParsingTestCase.testIpV4AddressStartsWithDot,"    @Test(expected = IOException.class)
    public void testIpV4AddressStartsWithDot() throws IOException {
        NetworkUtils.parseIpv4Address("".1.123.255.2"");
    }
",non-flaky,5
160431,ConsenSys_teku,StateSelectorFactoryTest.finalizedSelector_shouldGetFinalizedState,"  @Test
  public void finalizedSelector_shouldGetFinalizedState()
      throws ExecutionException, InterruptedException {
    when(client.getFinalizedState()).thenReturn(Optional.of(state));
    Optional<BeaconState> result = factory.finalizedSelector().getState().get();
    assertThat(result).isEqualTo(Optional.of(state));
    verify(client).getFinalizedState();
  }
",non-flaky,5
59582,looly_hutool,MailTest.sendWithLongNameFileTest,"	@Test
	public void sendWithLongNameFileTest() {
		//éä»¶åé¿åº¦å¤§äº60æ¶çæµè¯
		MailUtil.send(""hutool@foxmail.com"", ""æµè¯"", ""<h1>é®ä»¶æ¥èªHutoolæµè¯</h1>"", true, FileUtil.file(""d:/6-LongLongä¸é¶æ®µå¹³å°å»ºè®¾å¨æ¥2018.3.12-3.16.xlsx""));
	}
",non-flaky,5
77001,Tencent_Firestorm,MultiStorageFaultToleranceTest.diskFaultTolerance,"  @Test
  public void diskFaultTolerance() {
    String appId = ""app_disk_fault_tolerance_data"";
    Map<Long, byte[]> expectedData = Maps.newHashMap();

    Map<Integer, List<Integer>> map = Maps.newHashMap();
    map.put(2, Lists.newArrayList(1, 3));
    map.put(3, Lists.newArrayList(1));
    registerShuffle(appId, map);

    Roaring64NavigableMap blockIdBitmap1 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap2 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap3 = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap blockIdBitmap4 = Roaring64NavigableMap.bitmapOf();

    List<ShuffleBlockInfo> blocks1 = createShuffleBlockList(
        2, 1, 1,11, 10 * 1024 * 1024, blockIdBitmap1, expectedData);

    List<ShuffleBlockInfo> blocks2 = createShuffleBlockList(
        3, 1, 2,9, 10 * 1024 * 1024, blockIdBitmap2, expectedData);

    List<ShuffleBlockInfo> blocks3 = createShuffleBlockList(
        2, 3, 2,9, 10 * 1024 * 1024, blockIdBitmap3, expectedData);

    List<ShuffleBlockInfo> blocks4 = createShuffleBlockList(
        2, 1, 1, 11, 10 * 1024 * 1024, blockIdBitmap4, expectedData);

    assertEquals(1, ShuffleStorageUtils.getStorageIndex(2, appId, 2, 1));
    assertEquals(1, ShuffleStorageUtils.getStorageIndex(2, appId, 3, 1));
    assertEquals(1, ShuffleStorageUtils.getStorageIndex(2, appId, 2, 3));
    assertEquals(1, ShuffleStorageUtils.getStorageIndex(2, appId, 2, 1));
    try {
      sendSinglePartitionToShuffleServer(appId, 2, 1, 1, blocks1);
      sendSinglePartitionToShuffleServer(appId, 3, 1,2, blocks2);
      sendSinglePartitionToShuffleServer(appId, 2, 3, 2, blocks3);
      sendSinglePartitionToShuffleServer(appId, 2, 1, 1, blocks4);
    } catch (Exception e) {
      e.printStackTrace();
      fail();
    }
    validateResult(appId, 2, 1, blockIdBitmap1, Roaring64NavigableMap.bitmapOf(1), expectedData);
    validateResult(appId, 3, 1, blockIdBitmap2, Roaring64NavigableMap.bitmapOf(2), expectedData);
    validateResult(appId, 2, 3, blockIdBitmap3, Roaring64NavigableMap.bitmapOf(2), expectedData);
  }
",non-flaky,5
26237,Ericsson_ecchronos,TestTableRepairJob.testPrevalidateUpdateThrowsException,"    @Test
    public void testPrevalidateUpdateThrowsException()
    {
        // mock
        doReturn(false).when(myRepairStateSnapshot).canRepair();
        doThrow(new RuntimeException(""Expected exception"")).when(myRepairState).update();

        assertThat(myRepairJob.runnable()).isFalse();

        verify(myRepairStateSnapshot, times(1)).canRepair();
    }
",non-flaky,5
88836,apache_ignite,RobinHoodBackwardShiftHashMapTest.testPutAndRefreshValue,"    @Test
    public void testPutAndRefreshValue() throws Exception {
        withMap(map -> {
            //fill with 1 space left;
            for (int i = 0; i < 99; i++) {
                int ver = i;
                int grpId = ver + 1;
                int val = grpId * grpId;
                int pageId = 1;
                map.put(grpId, pageId, val, ver);

                map.refresh(grpId, pageId, ver + 1);

                assertEquals(val, map.get(grpId, pageId, ver + 1, -1, -2));

            }

            doAddRemove(map);
        }, 100);
    }
",non-flaky,5
112090,apache_shardingsphere-elasticjob,AverageAllocationJobShardingStrategyTest.shardingForServersLessThanShardingCountAliquot,"    @Test
    public void shardingForServersLessThanShardingCountAliquot() {
        Map<JobInstance, List<Integer>> expected = new LinkedHashMap<>(3, 1);
        expected.put(new JobInstance(""host0@-@0""), Arrays.asList(0, 1, 2));
        expected.put(new JobInstance(""host1@-@0""), Arrays.asList(3, 4, 5));
        expected.put(new JobInstance(""host2@-@0""), Arrays.asList(6, 7, 8));
        assertThat(jobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""test_job"", 9), is(expected));
    }
",non-flaky,5
99749,apache_cassandra,AsyncStreamingInputPlusTest.read,"    @Test
    public void read() throws IOException
    {
        inputPlus = new AsyncStreamingInputPlus(channel);
        // put two buffers of 8 bytes each into the queue.
        // then read an int, then a long. the latter tests offset into the inputPlus, as well as spanning across queued buffers.
        // the values of those int/long will both be '42', but spread across both queue buffers.
        ByteBuf buf = channel.alloc().buffer(8);
        buf.writeInt(42);
        buf.writerIndex(8);
        inputPlus.append(buf);
        buf = channel.alloc().buffer(8);
        buf.writeInt(42);
        buf.writerIndex(8);
        inputPlus.append(buf);
        Assert.assertEquals(16, inputPlus.unsafeAvailable());

//        ByteBuffer out = ByteBuffer.allocate(4);
//        int readCount = inputPlus.read(out);
//        Assert.assertEquals(4, readCount);
//        out.flip();
//        Assert.assertEquals(42, out.getInt());
//        Assert.assertEquals(12, inputPlus.unsafeAvailable());

//        out = ByteBuffer.allocate(8);
//        readCount = inputPlus.read(out);
//        Assert.assertEquals(8, readCount);
//        out.flip();
//        Assert.assertEquals(42, out.getLong());
//        Assert.assertEquals(4, inputPlus.unsafeAvailable());
    }
",non-flaky,5
91590,apache_kylin,SourceConfigurationUtilTest.testHiveConf,"    @Test
    public void testHiveConf() {
        Properties properties = SourceConfigurationUtil.loadHiveJDBCProperties();
        assertTrue(properties.containsKey(""hiveconf:hive.auto.convert.join.noconditionaltask.size""));
    }
",non-flaky,5
13909,neo4j_neo4j,TestBlockLogBuffer.readSmallPortions,"    @Test
    public void readSmallPortions() throws IOException
    {
        byte[] bytes = new byte[255];
        ChannelBuffer wrappedBuffer = ChannelBuffers.wrappedBuffer( bytes );
        wrappedBuffer.resetWriterIndex();
        BlockLogBuffer buffer = new BlockLogBuffer( wrappedBuffer, new Monitors().newMonitor( ByteCounterMonitor.class ) );

        byte byteValue = 5;
        int intValue = 1234;
        long longValue = 574853;
        buffer.put( byteValue );
        buffer.putInt( intValue );
        buffer.putLong( longValue );
        buffer.close();

        ReadableByteChannel reader = new BlockLogReader( wrappedBuffer );
        ByteBuffer verificationBuffer = ByteBuffer.wrap( new byte[1] );
        reader.read( verificationBuffer );
        verificationBuffer.flip();
        assertEquals( byteValue, verificationBuffer.get() );
        verificationBuffer = ByteBuffer.wrap( new byte[4] );
        reader.read( verificationBuffer );
        verificationBuffer.flip();
        assertEquals( intValue, verificationBuffer.getInt() );
        verificationBuffer = ByteBuffer.wrap( new byte[8] );
        reader.read( verificationBuffer );
        verificationBuffer.flip();
        assertEquals( longValue, verificationBuffer.getLong() );
    }
",non-flaky,5
320,apache_hadoop,TestRpcProgramNfs3.testDeprecatedKeys,"  @Test
  public void testDeprecatedKeys() {
    NfsConfiguration conf = new NfsConfiguration();
    conf.setInt(""nfs3.server.port"", 998);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_SERVER_PORT_KEY, 0) == 998);

    conf.setInt(""nfs3.mountd.port"", 999);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_MOUNTD_PORT_KEY, 0) == 999);

    conf.set(""dfs.nfs.exports.allowed.hosts"", ""host1"");
    assertTrue(conf.get(CommonConfigurationKeys.NFS_EXPORTS_ALLOWED_HOSTS_KEY)
        .equals(""host1""));

    conf.setInt(""dfs.nfs.exports.cache.expirytime.millis"", 1000);
    assertTrue(conf.getInt(
        Nfs3Constant.NFS_EXPORTS_CACHE_EXPIRYTIME_MILLIS_KEY, 0) == 1000);

    conf.setInt(""hadoop.nfs.userupdate.milly"", 10);
    assertTrue(conf.getInt(IdMappingConstant.USERGROUPID_UPDATE_MILLIS_KEY, 0) == 10);

    conf.set(""dfs.nfs3.dump.dir"", ""/nfs/tmp"");
    assertTrue(conf.get(NfsConfigKeys.DFS_NFS_FILE_DUMP_DIR_KEY).equals(
        ""/nfs/tmp""));

    conf.setBoolean(""dfs.nfs3.enableDump"", false);
    assertTrue(conf.getBoolean(NfsConfigKeys.DFS_NFS_FILE_DUMP_KEY, true) == false);

    conf.setInt(""dfs.nfs3.max.open.files"", 500);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_MAX_OPEN_FILES_KEY, 0) == 500);

    conf.setInt(""dfs.nfs3.stream.timeout"", 6000);
    assertTrue(conf.getInt(NfsConfigKeys.DFS_NFS_STREAM_TIMEOUT_KEY, 0) == 6000);

    conf.set(""dfs.nfs3.export.point"", ""/dir1"");
    assertTrue(conf.get(NfsConfigKeys.DFS_NFS_EXPORT_POINT_KEY).equals(""/dir1""));
  }
",non-flaky,5
26743,MundaneImmortal_pair-distribution-app,DeveloperTest.testEqualsOfEqualInstances,"	@Test
	public void testEqualsOfEqualInstances() {
		Developer developer = new Developer(""developerId"");
		Developer sameDeveloper = new Developer(""developerId"");
		
		assertThat(developer.equals(sameDeveloper), is(true));
		assertThat(sameDeveloper.equals(developer), is(true));
	}
",non-flaky,5
43031,trinodb_trino,BaseDynamicPartitionPruningTest.testJoinLargeBuildSideRangeDynamicFiltering,"    @Test(timeOut = 30_000)
    public void testJoinLargeBuildSideRangeDynamicFiltering()
    {
        @Language(""SQL"") String selectQuery = ""SELECT * FROM partitioned_lineitem JOIN orders ON partitioned_lineitem.orderkey = orders.orderkey"";
        ResultWithQueryId<MaterializedResult> result = getDistributedQueryRunner().executeWithQueryId(
                getSession(),
                selectQuery);
        MaterializedResult expected = computeActual(withDynamicFilteringDisabled(), selectQuery);
        assertEqualsIgnoreOrder(result.getResult(), expected);

        OperatorStats probeStats = searchScanFilterAndProjectOperatorStats(result.getQueryId(), getQualifiedTableName(PARTITIONED_LINEITEM));
        // Probe-side is fully scanned because the build-side is too large for dynamic filtering
        assertEquals(probeStats.getInputPositions(), LINEITEM_COUNT);

        DynamicFiltersStats dynamicFiltersStats = getDynamicFilteringStats(result.getQueryId());
        assertEquals(dynamicFiltersStats.getTotalDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getLazyDynamicFilters(), 1L);
        assertEquals(dynamicFiltersStats.getReplicatedDynamicFilters(), 0L);
        assertEquals(dynamicFiltersStats.getDynamicFiltersCompleted(), 1L);

        DynamicFilterDomainStats domainStats = getOnlyElement(dynamicFiltersStats.getDynamicFilterDomainStats());
        assertEquals(
                domainStats.getSimplifiedDomain(),
                Domain.create(ValueSet.ofRanges(range(BIGINT, 1L, true, 60000L, true)), false)
                        .toString(getSession().toConnectorSession()));
    }
",non-flaky,5
26766,MundaneImmortal_pair-distribution-app,DayPairsTest.testCompareTo,"	@Test
	public void testCompareTo() {
		DayPairs todaysPairs = new DayPairs();
		todaysPairs.setDate(new Date());
		DayPairs yesterdayPairs = new DayPairs();
		yesterdayPairs.setDate(getYesterdayDate());
		
		assertThat(todaysPairs.compareTo(yesterdayPairs), is(equalTo(1)));
		assertThat(yesterdayPairs.compareTo(todaysPairs), is(equalTo(-1)));
		assertThat(todaysPairs.compareTo(todaysPairs), is(equalTo(0)));
	}
",non-flaky,5
70830,apache_kafka,WorkerConfigTest.testAdminListenersNotAllowingEmptyStrings,"    @Test(expected = ConfigException.class)
    public void testAdminListenersNotAllowingEmptyStrings() {
        Map<String, String> props = baseProps();
        props.put(WorkerConfig.ADMIN_LISTENERS_CONFIG, ""http://a.b:9999,"");
        new WorkerConfig(WorkerConfig.baseConfigDef(), props);
    }
",non-flaky,5
160383,ConsenSys_teku,ChainDataProviderTest.getGenesisTime_shouldThrowIfStoreNotAvailable,"  @Test
  public void getGenesisTime_shouldThrowIfStoreNotAvailable() {
    final ChainDataProvider provider =
        new ChainDataProvider(spec, null, mockCombinedChainDataClient);
    when(mockCombinedChainDataClient.isStoreAvailable()).thenReturn(false);
    assertThatThrownBy(provider::getGenesisTime).isInstanceOf(ChainDataUnavailableException.class);
  }
",non-flaky,5
20971,NationalSecurityAgency_timely,TestMemoryDataStore.testStorage,"    @Test
    public void testStorage() throws TimelyException {

        long now = System.currentTimeMillis();
        DataStoreCache mmStore = getMetricMemoryStore2(now);

        QueryRequest query = new QueryRequest();
        query.setStart(now);
        query.setEnd(now + 86400000);
        query.setMsResolution(true);
        QueryRequest.SubQuery subQuery = new QueryRequest.SubQuery();
        subQuery.setDownsample(Optional.of(""5m-avg""));
        subQuery.setMetric(""metric.number.1"");
        subQuery.addTag(""host"", "".*"");
        query.setQueries(Collections.singleton(subQuery));

        try {
            List<QueryResponse> responseList = mmStore.query(query);
            for (QueryResponse response : responseList) {
                System.out.println(response.toString());
            }
        } catch (TimelyException e) {
            e.printStackTrace();
        }
    }
",non-flaky,5
33880,apache_camel,FhirLoadPageIT.testPrevious,"    @Test
    public void testPrevious() throws Exception {
        String url = ""Patient?_count=2"";
        Bundle bundle = this.fhirClient.search()
                .byUrl(url)
                .returnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_NEXT));

        String nextPageLink = bundle.getLink(""next"").getUrl();
        bundle = this.fhirClient.loadPage().byUrl(nextPageLink).andReturnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_PREV));

        // using org.hl7.fhir.instance.model.api.IBaseBundle message body for single parameter ""bundle""
        Bundle result = requestBody(""direct://PREVIOUS"", bundle);

        LOG.debug(""previous: "" + result);
        assertNotNull(result, ""previous result"");
    }
",non-flaky,5
70845,apache_kafka,WorkerSourceTaskTest.testSendRecordsTaskCommitRecordFail,"    @Test
    public void testSendRecordsTaskCommitRecordFail() throws Exception {
        createWorkerTask();

        // Differentiate only by Kafka partition so we can reuse conversion expectations
        SourceRecord record1 = new SourceRecord(PARTITION, OFFSET, ""topic"", 1, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD);
        SourceRecord record2 = new SourceRecord(PARTITION, OFFSET, ""topic"", 2, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD);
        SourceRecord record3 = new SourceRecord(PARTITION, OFFSET, ""topic"", 3, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD);

        // Source task commit record failure will not cause the task to abort
        expectSendRecordOnce(false);
        expectSendRecordTaskCommitRecordFail(false, false);
        expectSendRecordOnce(false);

        PowerMock.replayAll();

        Whitebox.setInternalState(workerTask, ""toSend"", Arrays.asList(record1, record2, record3));
        Whitebox.invokeMethod(workerTask, ""sendRecords"");
        assertEquals(false, Whitebox.getInternalState(workerTask, ""lastSendFailed""));
        assertNull(Whitebox.getInternalState(workerTask, ""toSend""));

        PowerMock.verifyAll();
    }
",non-flaky,5
77156,networknt_json-schema-validator,V4JsonSchemaTest.testMinItemsValidator,"    @Test
    public void testMinItemsValidator() throws Exception {
        runTestFile(""draft4/minItems.json"");
    }
",non-flaky,5
177953,aosp-mirror_platform_frameworks_support,FileProviderTest.testStrategyUriJumpOutside,"    @Test
    public void testStrategyUriJumpOutside() throws Exception {
        final SimplePathStrategy strat = new SimplePathStrategy(""authority"");
        strat.addRoot(""tag"", mContext.getFilesDir());

        File file = buildPath(mContext.getFilesDir(), "".."", ""file.test"");
        try {
            strat.getUriForFile(file);
            fail(""file escaped!"");
        } catch (IllegalArgumentException e) {
        }
    }
",non-flaky,5
84601,apache_zookeeper,SimpleSysTest.testSimpleCase,"    @Test
    public void testSimpleCase() throws Exception {
        configureServers(serverCount);
        configureClients(clientCount, SimpleClient.class, getHostPort());
        Stat stat = new Stat();
        startServers();
        LOG.debug(""Connecting to "" + getHostPort());
        ZooKeeper zk = new ZooKeeper(getHostPort(), 15000, this);
        waitForConnect(zk, 10000);
        zk.create(""/simpleCase"", ""orig"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
        startClients();

        // Check that all clients connect properly
        for(int i = 0; i < getClientCount(); i++) {
            for(int j = 0; j < maxTries; j++) {
                try {
                    byte b[] = zk.getData(""/simpleCase/"" + i, false, stat);
                    Assert.assertEquals(""orig"", new String(b));
                } catch(NoNodeException e) {
                    if (j+1 == maxTries) {
                        Assert.fail(""Max tries exceeded on client "" + i);
                    }
                    Thread.sleep(1000);
                }
            }
        }

        // Kill half the servers, make a change, restart the dead
        // servers, and then bounce the other servers one by one
        for(int i = 0; i < getServerCount(); i++) {
            stopServer(i);
            if (i+1 > getServerCount()/2) {
                startServer(i);
            } else if (i+1 == getServerCount()/2) {
                Assert.assertTrue(""Connection didn't recover"", waitForConnect(zk, 10000));
                try {
                    zk.setData(""/simpleCase"", ""new"".getBytes(), -1);
                } catch(ConnectionLossException e) {
                    Assert.assertTrue(""Connection didn't recover"", waitForConnect(zk, 10000));
                    zk.setData(""/simpleCase"", ""new"".getBytes(), -1);
                }
                for(int j = 0; j < i; j++) {
                    LOG.info(""Starting server "" + j);
                    startServer(i);
                }
            }
        }
        Thread.sleep(100); // wait for things to stabilize
        Assert.assertTrue(""Servers didn't bounce"", waitForConnect(zk, 15000));
        try {
            zk.getData(""/simpleCase"", false, stat);
        } catch(ConnectionLossException e) {
            Assert.assertTrue(""Servers didn't bounce"", waitForConnect(zk, 15000));
        }

        // check that the change has propagated to everyone
        for(int i = 0; i < getClientCount(); i++) {
            for(int j = 0; j < maxTries; j++) {
                byte[] data = zk.getData(""/simpleCase/"" + i, false, stat);
                if (new String(data).equals(""new"")) {
                    break;
                }
                if (j+1 == maxTries) {
                    Assert.fail(""max tries exceeded for "" + i);
                }
                Thread.sleep(1000);
            }
        }

        // send out the kill signal
        zk.setData(""/simpleCase"", ""die"".getBytes(), -1);

        // watch for everyone to die
        for(int i = 0; i < getClientCount(); i++) {
            try {
                for(int j = 0; j < maxTries; j++) {
                    zk.getData(""/simpleCase/"" + i, false, stat);
                    if (j+1 == maxTries) {
                        Assert.fail(""max tries exceeded waiting for child "" + i + "" to die"");
                    }
                    Thread.sleep(200);
                }
            } catch(NoNodeException e) {
                // Great this is what we were hoping for!
            }
        }

        stopClients();
        stopServers();
    }
",non-flaky,5
110116,Wikidata_wikidata-toolkit,ClientTest.testDefaultLoggingConfig,"	@Test
	public void testDefaultLoggingConfig() throws ParseException, IOException {
		String[] args = new String[] {};
		Client client = new Client(mockDpc, args);
		client.performActions(); // print help

		assertEquals(Level.INFO, Client.consoleAppender.getThreshold());
		assertEquals(Level.WARN, Client.errorAppender.getThreshold());
	}
",non-flaky,5
77490,dropwizard_dropwizard,ConfigurationMetadataTest.shouldDiscoverAllFields,"    @ParameterizedTest
    public void shouldDiscoverAllFields(String name, boolean isPrimitive,
                                        boolean isCollectionOrArrayType,
",non-flaky,5
91455,strapdata_elassandra,RecoveryWhileUnderLoadIT.testRecoverWhileUnderLoadAllocateReplicasTest,"@TestLogging(""_root:DEBUG,org.elasticsearch.index.shard:TRACE,org.elasticsearch.cluster.service:TRACE,org.elasticsearch.index.seqno:TRACE,org.elasticsearch.indices.recovery:TRACE"")
    public void testRecoverWhileUnderLoadAllocateReplicasTest() throws Exception {
        logger.info(""--> creating test index ..."");
        int numberOfShards = numberOfShards();
        assertAcked(prepareCreate(""test"", 1, Settings.builder().put(SETTING_NUMBER_OF_SHARDS, numberOfShards).put(SETTING_NUMBER_OF_REPLICAS, 1).put(IndexSettings.INDEX_TRANSLOG_DURABILITY_SETTING.getKey(), Translog.Durability.ASYNC)));

        final int totalNumDocs = scaledRandomIntBetween(200, 10000);
        int waitFor = totalNumDocs / 10;
        int extraDocs = waitFor;
        try (BackgroundIndexer indexer = new BackgroundIndexer(""test"", ""type"", client(), extraDocs)) {
            logger.info(""--> waiting for {} docs to be indexed ..."", waitFor);
            waitForDocs(waitFor, indexer);
            indexer.assertNoFailures();
            logger.info(""--> {} docs indexed"", waitFor);

            extraDocs = totalNumDocs / 10;
            waitFor += extraDocs;
            indexer.continueIndexing(extraDocs);
            logger.info(""--> flushing the index ...."");
            // now flush, just to make sure we have some data in the index, not just translog
            client().admin().indices().prepareFlush().execute().actionGet();

            logger.info(""--> waiting for {} docs to be indexed ..."", waitFor);
            waitForDocs(waitFor, indexer);
            indexer.assertNoFailures();
            logger.info(""--> {} docs indexed"", waitFor);

            extraDocs = totalNumDocs - waitFor;
            indexer.continueIndexing(extraDocs);

            logger.info(""--> allow 2 nodes for index [test] ..."");
            // now start another node, while we index
            allowNodes(""test"", 2);

            logger.info(""--> waiting for GREEN health status ..."");
            // make sure the cluster state is green, and all has been recovered
            assertNoTimeout(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setTimeout(""5m"").setWaitForGreenStatus());

            logger.info(""--> waiting for {} docs to be indexed ..."", totalNumDocs);
            waitForDocs(totalNumDocs, indexer);
            indexer.assertNoFailures();
            logger.info(""--> {} docs indexed"", totalNumDocs);

            logger.info(""--> marking and waiting for indexing threads to stop ..."");
            indexer.stop();
            logger.info(""--> indexing threads stopped"");

            logger.info(""--> refreshing the index"");
            refreshAndAssert();
            logger.info(""--> verifying indexed content"");
            iterateAssertCount(numberOfShards, 10, indexer.getIds());
        }
    }
",non-flaky,5
59609,looly_hutool,ExpressionUtilTest.jfireELTest,"	@Test
	public void jfireELTest(){
		ExpressionEngine engine = new JfireELEngine();

		final Dict dict = Dict.create()
				.set(""a"", 100.3)
				.set(""b"", 45)
				.set(""c"", -199.100);
		final Object eval = engine.eval(""a-(b-c)"", dict);
		Assert.assertEquals(-143.8, (double)eval, 2);
	}
",non-flaky,5
70784,apache_kafka,StartAndStopLatchTest.shouldReturnFalseWhenAwaitingForStopToNeverComplete,"    @Test
    public void shouldReturnFalseWhenAwaitingForStopToNeverComplete() throws Throwable {
        latch = new StartAndStopLatch(1, 1, this::complete, dependents, clock);
        future = asyncAwait(100);
        latch.recordStart();
        clock.sleep(10);
        assertFalse(future.get(200, TimeUnit.MILLISECONDS));
        assertTrue(future.isDone());
    }
",non-flaky,5
91486,strapdata_elassandra,RemoteClusterConnectionTests.run,"    @TestLogging(""_root:DEBUG, org.elasticsearch.transport:TRACE"")
    public void testCloseWhileConcurrentlyConnecting() throws IOException, InterruptedException, BrokenBarrierException {
        List<DiscoveryNode> knownNodes = new CopyOnWriteArrayList<>();
        try (MockTransportService seedTransport = startTransport(""seed_node"", knownNodes, Version.CURRENT);
             MockTransportService seedTransport1 = startTransport(""seed_node_1"", knownNodes, Version.CURRENT);
             MockTransportService discoverableTransport = startTransport(""discoverable_node"", knownNodes, Version.CURRENT)) {
            DiscoveryNode seedNode = seedTransport.getLocalDiscoNode();
            DiscoveryNode seedNode1 = seedTransport1.getLocalDiscoNode();
            knownNodes.add(seedTransport.getLocalDiscoNode());
            knownNodes.add(discoverableTransport.getLocalDiscoNode());
            knownNodes.add(seedTransport1.getLocalDiscoNode());
            Collections.shuffle(knownNodes, random());
            List<Supplier<DiscoveryNode>> seedNodes = Arrays.asList(() -> seedNode1, () -> seedNode);
            Collections.shuffle(seedNodes, random());

            try (MockTransportService service = MockTransportService.createNewService(Settings.EMPTY, Version.CURRENT, threadPool, null)) {
                service.start();
                service.acceptIncomingRequests();
                try (RemoteClusterConnection connection = new RemoteClusterConnection(Settings.EMPTY, ""test-cluster"",
                    seedNodes, service, service.getConnectionManager(), Integer.MAX_VALUE, n -> true)) {
                    int numThreads = randomIntBetween(4, 10);
                    Thread[] threads = new Thread[numThreads];
                    CyclicBarrier barrier = new CyclicBarrier(numThreads + 1);
                    for (int i = 0; i < threads.length; i++) {
                        final int numConnectionAttempts = randomIntBetween(10, 100);
                        threads[i] = new Thread() {
                            @Override
                            public void run() {
                                try {
                                    barrier.await();
                                    CountDownLatch latch = new CountDownLatch(numConnectionAttempts);
                                    for (int i = 0; i < numConnectionAttempts; i++) {
                                        AtomicReference<Exception> executed = new AtomicReference<>();
                                        ActionListener<Void> listener = ActionListener.wrap(
                                            x -> {
                                                if (executed.compareAndSet(null, new RuntimeException())) {
                                                    latch.countDown();
                                                } else {
                                                    throw new AssertionError(""shit's been called twice"", executed.get());
                                                }
                                            },
                                            x -> {
                                                if (executed.compareAndSet(null, x)) {
                                                    latch.countDown();
                                                } else {
                                                    final String message = x.getMessage();
                                                    if ((executed.get().getClass() == x.getClass()
                                                        && ""operation was cancelled reason [connect handler is closed]"".equals(message)
                                                        && message.equals(executed.get().getMessage())) == false) {
                                                        // we do cancel the operation and that means that if timing allows it, the caller
                                                        // of a blocking call as well as the handler will get the exception from the
                                                        // ExecutionCancelledException concurrently. unless that is the case we fail
                                                        // if we get called more than once!
                                                        AssertionError assertionError = new AssertionError(""shit's been called twice"", x);
                                                        assertionError.addSuppressed(executed.get());
                                                        throw assertionError;
                                                    }
                                                }
                                                if (x instanceof RejectedExecutionException || x instanceof AlreadyClosedException
                                                    || x instanceof CancellableThreads.ExecutionCancelledException) {
                                                    // that's fine
                                                } else {
                                                    throw new AssertionError(x);
                                                }
                                            });
                                        try {
                                            connection.updateSeedNodes(null, seedNodes, listener);
                                        } catch (Exception e) {
                                            // it's ok if we're shutting down
                                            assertThat(e.getMessage(), containsString(""threadcontext is already closed""));
                                            latch.countDown();
                                        }
                                    }
                                    latch.await();
                                } catch (Exception ex) {
                                    throw new AssertionError(ex);
                                }
                            }
",non-flaky,5
99785,apache_cassandra,MessagingServiceTest.testDoesntApplyBackPressureToBroadcastAddress,"    @Test
    public void testDoesntApplyBackPressureToBroadcastAddress() throws UnknownHostException
    {
        DatabaseDescriptor.setBackPressureEnabled(true);
        messagingService.applyBackPressure(Arrays.asList(InetAddressAndPort.getByName(""127.0.0.1"")), ONE_SECOND);
        assertFalse(MockBackPressureStrategy.applied);
    }
",non-flaky,5
156167,soot-oss_soot,TypingMinimizeTest.testJavaInterfaceTyping,"  @Test
  public void testJavaInterfaceTyping() {

    List<Typing> typingList = new ArrayList<>();

    Local x1 = new JimpleLocal(""$x1"", null);

    Typing typing1 = new Typing(Arrays.asList(x1));
    typing1.set(x1, interfaceType);
    typingList.add(typing1);

    Typing typing2 = new Typing(Arrays.asList(x1));
    typing2.set(x1, integerType);
    typingList.add(typing2);

    Typing typing3 = new Typing(Arrays.asList(x1));
    typing3.set(x1, numberType);
    typingList.add(typing3);

    getTypingStrategy().minimize(typingList, new BytecodeHierarchy());

    assertEquals(2, typingList.size());
    assertThat(typingList, containsInAnyOrder(typing2, typing1));
  }
",non-flaky,5
43008,fabiomaffioletti_jsondoc,SpringPathBuilderTest.apply,"	@Test
	public void testPath4() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController4.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController4"", apiDoc.getName());

		boolean allRight = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
			@Override
			public boolean apply(ApiMethodDoc input) {
				boolean allRight =
								input.getPath().contains(""/path""); 
				return allRight;
			}
",non-flaky,5
89350,apache_samza,TestKafkaSystemDescriptor.testSDConfigsWithoutOverrides,"  @Test
  public void testSDConfigsWithoutOverrides() {
    KafkaSystemDescriptor sd = new KafkaSystemDescriptor(""kafka"");

    Map<String, String> generatedConfigs = sd.toConfig();
    assertEquals(""org.apache.samza.system.kafka.KafkaSystemFactory"", generatedConfigs.get(""systems.kafka.samza.factory""));
    assertEquals(1, generatedConfigs.size()); // verify that there are no other configs
  }
",non-flaky,5
98444,ONSdigital_rm-collection-exercise-service,EventServiceTest.givenNoEventsWhenScheduledIsCheckedThenFalse,"  @Test
  public void givenNoEventsWhenScheduledIsCheckedThenFalse() throws CTPException {
    UUID collexUuid = UUID.randomUUID();
    when(eventRepository.findByCollectionExerciseId(collexUuid)).thenReturn(new ArrayList<>());

    boolean scheduled = this.eventService.isScheduled(collexUuid);

    assertFalse(scheduled);
  }
",non-flaky,5
175818,GoogleCloudPlatform_google-cloud-eclipse,OpenUriSelectionListenerTest.testWidgetSelected_errorInvokingBrowser,"  @Test
  public void testWidgetSelected_errorInvokingBrowser() throws PartInitException {
    SelectionEvent selectionEvent = getEvent(VALID_URI);
    doThrow(new PartInitException(""fake exception"")).when(browser).openURL(any(URL.class));

    new OpenUriSelectionListener(queryParameterProvider, errorHandler, browserSupport).widgetSelected(selectionEvent);
    verify(errorHandler).handle(captor.capture(), any(URI.class));
    assertThat(captor.getValue(), instanceOf(PartInitException.class));
  }
",non-flaky,5
162441,testcontainers_testcontainers-java,ParameterizedDockerfileContainerTest.simpleTest,"    @Test
    public void simpleTest() throws Exception {
        final String release = container.execInContainer(""cat"", ""/etc/alpine-release"").getStdout();

        assertTrue(""/etc/alpine-release starts with "" + expectedVersion,
                release.startsWith(expectedVersion));
    }
",non-flaky,5
322,apache_hadoop,TestDFSClientCache.testEviction,"  @Test
  public void testEviction() throws IOException {
    NfsConfiguration conf = new NfsConfiguration();
    conf.set(FileSystem.FS_DEFAULT_NAME_KEY, ""hdfs://localhost"");

    // Only one entry will be in the cache
    final int MAX_CACHE_SIZE = 1;

    DFSClientCache cache = new DFSClientCache(conf, MAX_CACHE_SIZE);

    int namenodeId = Nfs3Utils.getNamenodeId(conf);
    DFSClient c1 = cache.getDfsClient(""test1"", namenodeId);
    assertTrue(cache.getDfsClient(""test1"", namenodeId)
        .toString().contains(""ugi=test1""));
    assertEquals(c1, cache.getDfsClient(""test1"", namenodeId));
    assertFalse(isDfsClientClose(c1));

    cache.getDfsClient(""test2"", namenodeId);
    assertTrue(isDfsClientClose(c1));
    assertTrue(""cache size should be the max size or less"",
        cache.getClientCache().size() <= MAX_CACHE_SIZE);
  }
",non-flaky,5
150132,apache_hive,TestHplsqlLocal.testBreak,"  @Test
  public void testBreak() throws Exception {
    run(""break"");
  }
",non-flaky,5
133910,cdancy_jenkins-rest,SystemApiLiveTest.testCancelQuietDown,"    @Test(dependsOnMethods = ""testAlreadyQuietDown"")
    public void testCancelQuietDown() {
        RequestStatus success = api().cancelQuietDown();
        assertNotNull(success);
        assertTrue(success.value());
    }
",non-flaky,5
76727,quarkusio_quarkus,JarRunnerIT.testPlatformPropertiesOverridenOnCommandLine,"    @Test
    public void testPlatformPropertiesOverridenOnCommandLine() throws Exception {
        final File testDir = initProject(""projects/platform-properties-overrides"",
                ""projects/platform-props-overriden-on-cmd-line"");
        final RunningInvoker running = new RunningInvoker(testDir, false);

        final MavenProcessInvocationResult result = running.execute(
                Arrays.asList(""install -Dquarkus.native.builder-image=commandline -DskipTests""),
                Collections.emptyMap());
        await().atMost(1, TimeUnit.MINUTES).until(() -> result.getProcess() != null && !result.getProcess().isAlive());
        assertThat(running.log()).containsIgnoringCase(""BUILD SUCCESS"");
        running.stop();

        File output = new File(testDir, ""app/target/output.log"");
        output.createNewFile();

        Process process = doLaunch(new File(testDir, ""app/target/quarkus-app""), Paths.get(""quarkus-run.jar""), output,
                Collections.emptyList()).start();
        try {
            Assertions.assertEquals(""builder-image is commandline"", DevModeTestUtils.getHttpResponse(""/hello""));
        } finally {
            process.destroy();
        }
    }
",non-flaky,5
38651,apache_pulsar,SolrGenericRecordSinkTest.TestOpenAndWriteSink,"    @Test
    public void TestOpenAndWriteSink() throws Exception {
        message = mock(MessageImpl.class);
        Map<String, Object> configs = new HashMap<>();
        configs.put(""solrUrl"", ""http://localhost:8983/solr"");
        configs.put(""solrMode"", ""Standalone"");
        configs.put(""solrCollection"", ""techproducts"");
        configs.put(""solrCommitWithinMs"", ""100"");
        configs.put(""username"", """");
        configs.put(""password"", """");
        GenericSchema<GenericRecord> genericAvroSchema;

        SolrGenericRecordSink sink = new SolrGenericRecordSink();

        // prepare a foo Record
        Foo obj = new Foo();
        obj.setField1(""FakeFiled1"");
        obj.setField2(""FakeFiled1"");
        AvroSchema<Foo> schema = AvroSchema.of(Foo.class);

        byte[] bytes = schema.encode(obj);
        AutoConsumeSchema autoConsumeSchema = new AutoConsumeSchema();
        autoConsumeSchema.setSchema(GenericSchemaImpl.of(schema.getSchemaInfo()));

        Record<GenericRecord> record = PulsarRecord.<GenericRecord>builder()
            .message(message)
            .topicName(""fake_topic_name"")
            .build();

        genericAvroSchema = new GenericAvroSchema(schema.getSchemaInfo());

        when(message.getValue())
                .thenReturn(genericAvroSchema.decode(bytes));

        log.info(""foo:{}, Message.getValue: {}, record.getValue: {}"",
            obj.toString(),
            message.getValue().toString(),
            record.getValue().toString());

        // open should success
        sink.open(configs, null);
    }
",non-flaky,5
60956,apache_druid,RowBucketIterableTest.testNodata,"  @Test
  public void testNodata()
  {
    intervals = new ArrayList<>();
    intervals.add(INTERVAL_JAN_1_4);
    intervals.add(INTERVAL_JAN_6_8);

    rows = new ArrayList<>();

    Sequence<Row> seq = Sequences.simple(rows);
    RowBucketIterable rbi = new RowBucketIterable(seq, intervals, ONE_DAY);
    Iterator<RowBucket> iter = rbi.iterator();

    Assert.assertTrue(iter.hasNext());
    RowBucket actual = iter.next();
    Assert.assertEquals(Collections.emptyList(), actual.getRows());
  }
",non-flaky,5
179416,abel533_Mapper,VersionTest.testVersion,"    @Test
    public void testVersion(){
        EntityHelper.initEntityNameMap(UserVersion.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserVersion.class);
        Assert.assertNotNull(entityTable);

        Set<EntityColumn> columns = entityTable.getEntityClassColumns();
        Assert.assertEquals(1, columns.size());

        for (EntityColumn column : columns) {
            Assert.assertTrue(column.getEntityField().isAnnotationPresent(Version.class));
        }
    }
",non-flaky,5
176880,OryxProject_oryx,IOUtilsTest.testReadLines,"  @Test
  public void testReadLines() throws IOException {
    Path tempDir = getTempDir();
    Path textFile = tempDir.resolve(""file.txt"");
    Files.write(textFile, Arrays.asList(""foo"", ""bar"", ""baz""), StandardCharsets.UTF_8);
    Iterator<String> it = IOUtils.readLines(textFile).iterator();
    assertTrue(it.hasNext());
    assertEquals(""foo"", it.next());
    assertTrue(it.hasNext());
    assertEquals(""bar"", it.next());
    assertTrue(it.hasNext());
    assertEquals(""baz"", it.next());
    assertFalse(it.hasNext());
  }
",non-flaky,5
92666,apache_dubbo,ModuleConfigTest.testVersion,"    @Test
    public void testVersion() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setName(""module-name"");
        module.setVersion(""1.0.0"");
        assertThat(module.getVersion(), equalTo(""1.0.0""));
        Map<String, String> parameters = new HashMap<String, String>();
        ModuleConfig.appendParameters(parameters, module);
        assertThat(parameters, hasEntry(""module.version"", ""1.0.0""));
    }
",non-flaky,5
135713,Netflix_Hystrix,HystrixSubclassCommandTest.testRequestCacheSubclassNoOverrides,"    @Test
    public void testRequestCacheSubclassNoOverrides() {
        HystrixCommand<Integer> subCmd1 = new SubCommandNoOverride(""cache"", true);
        assertEquals(1, subCmd1.execute().intValue());
        HystrixCommand<Integer> subCmd2 = new SubCommandNoOverride(""cache"", true);
        assertEquals(1, subCmd2.execute().intValue());
        HystrixCommand<Integer> subCmd3 = new SubCommandNoOverride(""no-cache"", true);
        assertEquals(1, subCmd3.execute().intValue());
        System.out.println(""REQ LOG : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        HystrixRequestLog reqLog = HystrixRequestLog.getCurrentRequest();
        assertEquals(3, reqLog.getAllExecutedCommands().size());
        List<HystrixInvokableInfo<?>> infos = new ArrayList<HystrixInvokableInfo<?>>(reqLog.getAllExecutedCommands());
        HystrixInvokableInfo<?> info1 = infos.get(0);
        assertEquals(""SubCommandNoOverride"", info1.getCommandKey().name());
        assertEquals(1, info1.getExecutionEvents().size());
        HystrixInvokableInfo<?> info2 = infos.get(1);
        assertEquals(""SubCommandNoOverride"", info2.getCommandKey().name());
        assertEquals(2, info2.getExecutionEvents().size());
        assertEquals(HystrixEventType.RESPONSE_FROM_CACHE, info2.getExecutionEvents().get(1));
        HystrixInvokableInfo<?> info3 = infos.get(2);
        assertEquals(""SubCommandNoOverride"", info3.getCommandKey().name());
        assertEquals(1, info3.getExecutionEvents().size());
    }
",non-flaky,5
38633,apache_pulsar,TestAbstractConfigurationProvider.testSinkSourceMismatchDuringConfiguration,"    @Test
    public void testSinkSourceMismatchDuringConfiguration() throws Exception {
        String agentName = ""agent1"";
        String sourceType = ""seq"";
        String channelType = ""memory"";
        String sinkType = ""avro"";
        Map<String, String> properties = getProperties(agentName, sourceType,
                channelType, sinkType);
        properties.put(agentName + "".channels.channel1.capacity"", ""1000"");
        properties.put(agentName + "".channels.channel1.transactionCapacity"", ""1000"");
        properties.put(agentName + "".sources.source1.batchSize"", ""1000"");
        properties.put(agentName + "".sinks.sink1.batch-size"", ""1000"");
        properties.put(agentName + "".sinks.sink1.hostname"", ""10.10.10.10"");
        properties.put(agentName + "".sinks.sink1.port"", ""1010"");

        MemoryConfigurationProvider provider =
                new MemoryConfigurationProvider(agentName, properties);
        MaterializedConfiguration config = provider.getConfiguration();
        assertEquals(config.getSourceRunners().size(), 1);
        assertEquals(config.getChannels().size(), 1);
        assertEquals(config.getSinkRunners().size(), 1);

        properties.put(agentName + "".sources.source1.batchSize"", ""1001"");
        properties.put(agentName + "".sinks.sink1.batch-size"", ""1000"");

        provider = new MemoryConfigurationProvider(agentName, properties);
        config = provider.getConfiguration();
        assertEquals(config.getSourceRunners().size(), 0);
        assertEquals(config.getChannels().size(), 1);
        assertEquals(config.getSinkRunners().size(), 1);

        properties.put(agentName + "".sources.source1.batchSize"", ""1000"");
        properties.put(agentName + "".sinks.sink1.batch-size"", ""1001"");

        provider = new MemoryConfigurationProvider(agentName, properties);
        config = provider.getConfiguration();
        assertEquals(config.getSourceRunners().size(), 1);
        assertEquals(config.getChannels().size(), 1);
        assertEquals(config.getSinkRunners().size(), 0);

        properties.put(agentName + "".sources.source1.batchSize"", ""1001"");
        properties.put(agentName + "".sinks.sink1.batch-size"", ""1001"");

        provider = new MemoryConfigurationProvider(agentName, properties);
        config = provider.getConfiguration();
        assertEquals(config.getSourceRunners().size(), 0);
        assertEquals(config.getChannels().size(), 0);
        assertEquals(config.getSinkRunners().size(), 0);
    }
",non-flaky,5
150135,apache_hive,TestHplsqlLocal.testCast2,"  @Test
  public void testCast2() throws Exception {
    run(""cast2"");
  }
",non-flaky,5
13903,neo4j_neo4j,RollingUpgradeIT.doRollingUpgradeFromPreviousVersionWithMasterLast,"    @Test
    public void doRollingUpgradeFromPreviousVersionWithMasterLast() throws Throwable
    {
        /* High level scenario:
         * 1   Have a cluster of 3 instances running <old version>
         * 1.1 Download a <old version> package
         * 1.2 Unpack the <old version> package
         * 1.4 Assembly classpath and start 3 JVMs running <old version>
         * 1.5 Create some data in the cluster
         * 2   Go over each one restarting into <this version>
         * 2.1 Grab a JVM and kill it
         * 2.2 Start that db inside this test JVM, which will run <this version>
         * 2.3 Perform a write transaction to the current master and see that it picks it up
         * 2.4 Perform a write transaction to to this instance and see that master picks it up
         * 3   Make sure the cluster functions after each one has been restarted
         * 3.1 Do basic transactions on master/slaves.
         * 3.2 Do a master switch
         * 3.3 Restart one slave
         * 3.4 Take down the instances and do consistency check */

        try
        {
            startOldVersionCluster();
            rollOverToNewVersion();
            shutdownAndDoConsistencyChecks();
        }
        catch ( Throwable e )
        {
            e.printStackTrace();
            throw e;
        }
    }
",non-flaky,5
163,pushtorefresh_storio,NotifyAboutChangesTest.notifyAboutChangesConcurrently,"@Test
public void notifyAboutChangesConcurrently() {
    final int numberOfThreads = 100;
    final TestSubscriber<Changes> testSubscriber = new TestSubscriber<Changes>();
    final Set<String> tables = new HashSet<String>();
    final List<Changes> expectedChanges = new ArrayList<Changes>();
    for (int i = 0; i < numberOfThreads; i++) {
        final String table = ""test_table"" + i;
        tables.add(table);
        expectedChanges.add(Changes.newInstance(table));
    }
    storIOSQLite.observeChanges(LATEST).subscribe(testSubscriber);
    final CountDownLatch startAllThreadsLock = new CountDownLatch(1);
    for (int i = 0; i < numberOfThreads; i++) {
        final int finalI = i;
        new Thread(new Runnable() {
            @Override
            public void run() {
                try {
                    startAllThreadsLock.await();
                } catch (InterruptedException e) {
                    throw new RuntimeException(e);
                }
                storIOSQLite.lowLevel().notifyAboutChanges(Changes.newInstance(""test_table"" + finalI));
            }
        }).start();
    }
    startAllThreadsLock.countDown();
    final long startTime = SystemClock.elapsedRealtime();
    while ((testSubscriber.valueCount() != tables.size()) && ((SystemClock.elapsedRealtime() - startTime) < 20000)) {
        Thread.yield();
    }
    testSubscriber.assertNoErrors();
    testSubscriber.assertValueCount(expectedChanges.size());
    assertThat(expectedChanges.containsAll(testSubscriber.values())).isTrue();
}",concurrency,1
98637,nutzam_nutz,SimpleAdaptorTest.test_multi_err_ctxs2,"    @Test
    public void test_multi_err_ctxs2() {
        get(""/adaptor/multi/err/ctxs2/a/b?id=ABC"");
        assertEquals(200, resp.getStatus());

        get(""/adaptor/multi/err/ctxs2/a/b/ABC"");
        assertEquals(200, resp.getStatus());
    }
",non-flaky,5
12,Ericsson_ecchronos,TestRepairGroup.testGetPartialRepairTasks,"@Test
public void testGetPartialRepairTasks() {
    Node node = mockNode(""DC1"");
    Node node2 = mockNode(""DC1"");
    ImmutableList<LongTokenRange> vnodes = ImmutableList.of(new LongTokenRange(1, 2), new LongTokenRange(2, 3), new LongTokenRange(4, 5));
    ReplicaRepairGroup replicaRepairGroup = new ReplicaRepairGroup(ImmutableSet.of(node, node2), vnodes);
    RepairGroup repairGroup = builderFor(replicaRepairGroup).build(priority);
    Collection<RepairTask> tasks = repairGroup.getRepairTasks();
    assertThat(tasks.size()).isEqualTo(3);
    Set<LongTokenRange> repairTaskRanges = new HashSet<>();
    for (RepairTask repairTask : tasks) {
        assertThat(repairTask.getTokenRanges().size()).isEqualTo(1);
        LongTokenRange range = repairTask.getTokenRanges().iterator().next();
        repairTaskRanges.add(range);
        assertThat(repairTask.getReplicas()).containsExactlyInAnyOrder(node, node2);
        assertThat(repairTask.getTableReference()).isEqualTo(tableReference);
        assertThat(repairTask.getRepairConfiguration().getRepairParallelism()).isEqualTo(PARALLEL);
    }
    assertThat(repairTaskRanges).containsExactlyElementsOf(vnodes);
}",unordered collections,3
118713,netty_netty,UnixChannelUtilTest.testUnPooledAllocatorIsBufferCopyNeededForWrite,"    @Test
    public void testUnPooledAllocatorIsBufferCopyNeededForWrite() {
        testIsBufferCopyNeededForWrite(UnpooledByteBufAllocator.DEFAULT);
    }
",non-flaky,5
91557,apache_kylin,ResourceToolTest.testCopy,"    @Test
    public void testCopy() throws IOException {
        KylinConfig dstConfig = KylinConfig.createInstanceFromUri(dstPath);
        ResourceStore srcStore = ResourceStore.getStore(KylinConfig.getInstanceFromEnv());
        ResourceStore dstStore = ResourceStore.getStore(dstConfig);

        //metadata under source path and destination path are not equal before copy
        Assert.assertNotEquals(srcStore.listResources(""/""), dstStore.listResources(""/""));

        new ResourceTool().copy(KylinConfig.getInstanceFromEnv(), dstConfig, ""/"");

        //After copy, two paths have same metadata
        NavigableSet<String> dstFiles = dstStore.listResourcesRecursively(""/"");
        NavigableSet<String> srcFiles = srcStore.listResourcesRecursively(""/"");
        Assert.assertTrue(srcFiles.containsAll(EXEC_FILES));
        Assert.assertFalse(dstFiles.containsAll(EXEC_FILES));
        srcFiles.removeAll(EXEC_FILES);
        Assert.assertEquals(srcFiles, dstFiles);
    }
",non-flaky,5
162689,OpenAPITools_openapi-generator,TypeHolderDefaultTest.numberItemTest,"    @Test
    public void numberItemTest() {
        // TODO: test numberItem
    }
",non-flaky,5
30989,camunda-cloud_zeebe,ObjectMappingTest.shouldNotDeserializePOJOWithWrongKeyType,"  @Test
  public void shouldNotDeserializePOJOWithWrongKeyType() {
    // given
    final POJO pojo = new POJO();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);

              w.writeInteger(123123L);
              w.writeFloat(123123.123123d);
            });

    // then
    exception.expect(RuntimeException.class);
    exception.expectMessage(
        ""Could not deserialize object [POJO]. Deserialization stuck at offset 2"");

    // when
    pojo.wrap(buffer);
  }
",non-flaky,5
176820,ctco_cukes,EntityFacadeTest.byteArrayValueIsCheckedAsString,"    @Test
    public void byteArrayValueIsCheckedAsString() throws Exception {
        BasicAttributes entity = new BasicAttributes(true);
        entity.put(""userPassword"", new byte[]{50, 82, 115, 48, 67, 99, 54, 74});

        Whitebox.setInternalState(entityFacade, ""entity"", entity);

        entityFacade.entityHasAttributeWithValue(""userpassword"", ""2Rs0Cc6J"");
    }
",non-flaky,5
78303,apache_beam,OutputAndTimeBoundedSplittableProcessElementInvokerTest.process,"  @Test
  public void testInvokeProcessElementOutputDisallowedBeforeTryClaim() throws Exception {
    DoFn<Void, String> brokenFn =
        new DoFn<Void, String>() {
          @ProcessElement
          public void process(ProcessContext c, OffsetRangeTracker tracker) {
            c.output(""foo"");
          }
",non-flaky,5
160373,ConsenSys_teku,MetadataTest.shouldSerializeMinimalFormat,"  @Test
  public void shouldSerializeMinimalFormat() throws JsonProcessingException {
    final Metadata metadata = new Metadata(INTERCHANGE_VERSION, root);
    assertThat(jsonProvider.objectToPrettyJSON(metadata)).isEqualToNormalizingNewlines(jsonData);
  }
",non-flaky,5
99778,apache_cassandra,MessagingServiceTest.testNegativeDCLatency,"    @Test
    public void testNegativeDCLatency()
    {
        MessagingMetrics.DCLatencyRecorder updater = MessagingService.instance().metrics.internodeLatencyRecorder(InetAddressAndPort.getLocalHost());

        // if clocks are off should just not track anything
        int latency = -100;

        long now = System.currentTimeMillis();
        long sentAt = now - latency;

        long count = updater.dcLatency.getCount();
        updater.accept(now - sentAt, MILLISECONDS);
        // negative value shoudln't be recorded
        assertEquals(count, updater.dcLatency.getCount());
    }
",non-flaky,5
33730,alibaba_fastjson,FastJsonHttpMessageConverterCase2Test.isInjectComponent,"    @Test
    public void isInjectComponent() {
        wac.getBean(JSONPResponseBodyAdvice.class);
        wac.getBean(FastJsonViewResponseBodyAdvice.class);
    }
",non-flaky,5
77462,opensearch-project_OpenSearch,LoggingListenerTests.annotatedTestMethod2,"        @TestLogging(value = ""abc:TRACE,xyz:DEBUG"", reason = ""testing TestLogging method annotations"")
        public void annotatedTestMethod2() {

        }
",non-flaky,5
88808,apache_ignite,FunctionalTest.testCacheManagement,"    @Test
    public void testCacheManagement() throws Exception {
        try (LocalIgniteCluster ignored = LocalIgniteCluster.start(2);
             IgniteClient client = Ignition.startClient(getClientConfiguration())
        ) {
            final String CACHE_NAME = ""testCacheManagement"";

            ClientCacheConfiguration cacheCfg = new ClientCacheConfiguration().setName(CACHE_NAME)
                .setCacheMode(CacheMode.REPLICATED)
                .setWriteSynchronizationMode(CacheWriteSynchronizationMode.FULL_SYNC);

            int key = 1;
            Person val = new Person(key, Integer.toString(key));

            ClientCache<Integer, Person> cache = client.getOrCreateCache(cacheCfg);

            cache.put(key, val);

            assertEquals(1, cache.size());
            assertEquals(2, cache.size(CachePeekMode.ALL));

            cache = client.cache(CACHE_NAME);

            Person cachedVal = cache.get(key);

            assertEquals(val, cachedVal);

            Object[] cacheNames = new TreeSet<>(client.cacheNames()).toArray();

            assertArrayEquals(new TreeSet<>(Arrays.asList(Config.DEFAULT_CACHE_NAME, CACHE_NAME)).toArray(), cacheNames);

            client.destroyCache(CACHE_NAME);

            cacheNames = client.cacheNames().toArray();

            assertArrayEquals(new Object[] {Config.DEFAULT_CACHE_NAME}, cacheNames);

            cache = client.createCache(CACHE_NAME);

            assertFalse(cache.containsKey(key));

            cacheNames = client.cacheNames().toArray();

            assertArrayEquals(new TreeSet<>(Arrays.asList(Config.DEFAULT_CACHE_NAME, CACHE_NAME)).toArray(), cacheNames);

            client.destroyCache(CACHE_NAME);

            cache = client.createCache(cacheCfg);

            assertFalse(cache.containsKey(key));

            assertArrayEquals(new TreeSet<>(Arrays.asList(Config.DEFAULT_CACHE_NAME, CACHE_NAME)).toArray(), cacheNames);
        }
    }
",non-flaky,5
30964,camunda-cloud_zeebe,POJOArrayTest.shouldSerializeAppendedEntry,"  @Test
  public void shouldSerializeAppendedEntry() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    pojo.wrap(buffer);
    final Iterator<MinimalPOJO> iterator = pojo.simpleArray().iterator();
    iterator.next();
    iterator.next();
    iterator.next();
    iterator.next();
    iterator.next();

    // when
    pojo.simpleArray().add().setLongProp(999L);

    // then
    final int writeLength = pojo.getLength();
    final UnsafeBuffer pojoBuffer = new UnsafeBuffer(new byte[writeLength]);
    pojo.write(pojoBuffer, 0);

    final Map<String, Object> msgPackMap = MsgPackUtil.asMap(pojoBuffer, 0, pojoBuffer.capacity());
    assertThat(msgPackMap)
        .containsOnly(
            entry(
                ""simpleArray"",
                ""[{longProp=123}, {longProp=456}, {longProp=789}, {longProp=555}, {longProp=777}, {longProp=999}]""));
  }
",non-flaky,5
77474,opensearch-project_OpenSearch,NodeConnectionsServiceTests.testDebugLogging,"    @TestLogging(reason=""testing that DEBUG-level logging is reasonable"", value=""org.opensearch.cluster.NodeConnectionsService:DEBUG"")
    public void testDebugLogging() throws IllegalAccessException {
        final DeterministicTaskQueue deterministicTaskQueue
            = new DeterministicTaskQueue(builder().put(NODE_NAME_SETTING.getKey(), ""node"").build(), random());

        MockTransport transport = new MockTransport(deterministicTaskQueue.getThreadPool());
        TestTransportService transportService = new TestTransportService(transport, deterministicTaskQueue.getThreadPool());
        transportService.start();
        transportService.acceptIncomingRequests();

        final NodeConnectionsService service
            = new NodeConnectionsService(Settings.EMPTY, deterministicTaskQueue.getThreadPool(), transportService);
        service.start();

        final List<DiscoveryNode> allNodes = generateNodes();
        final DiscoveryNodes targetNodes = discoveryNodesFromList(randomSubsetOf(allNodes));
        service.connectToNodes(targetNodes, () -> {});
        deterministicTaskQueue.runAllRunnableTasks();

        // periodic reconnections to unexpectedly-disconnected nodes are logged
        final Set<DiscoveryNode> disconnectedNodes = new HashSet<>(randomSubsetOf(allNodes));
        for (DiscoveryNode disconnectedNode : disconnectedNodes) {
            transportService.disconnectFromNode(disconnectedNode);
        }
        MockLogAppender appender = new MockLogAppender();
        try {
            appender.start();
            Loggers.addAppender(LogManager.getLogger(""org.opensearch.cluster.NodeConnectionsService""), appender);
            for (DiscoveryNode targetNode : targetNodes) {
                if (disconnectedNodes.contains(targetNode)) {
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""connecting to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connecting to "" + targetNode));
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""connected to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connected to "" + targetNode));
                } else {
                    appender.addExpectation(new MockLogAppender.UnseenEventExpectation(""connecting to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connecting to "" + targetNode));
                    appender.addExpectation(new MockLogAppender.UnseenEventExpectation(""connected to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connected to "" + targetNode));
                }
            }

            runTasksUntil(deterministicTaskQueue, CLUSTER_NODE_RECONNECT_INTERVAL_SETTING.get(Settings.EMPTY).millis());
            appender.assertAllExpectationsMatched();
        } finally {
            Loggers.removeAppender(LogManager.getLogger(""org.opensearch.cluster.NodeConnectionsService""), appender);
            appender.stop();
        }        for (DiscoveryNode disconnectedNode : disconnectedNodes) {
            transportService.disconnectFromNode(disconnectedNode);
        }

        // changes to the expected set of nodes are logged, including reconnections to any unexpectedly-disconnected nodes
        final DiscoveryNodes newTargetNodes = discoveryNodesFromList(randomSubsetOf(allNodes));
        for (DiscoveryNode disconnectedNode : disconnectedNodes) {
            transportService.disconnectFromNode(disconnectedNode);
        }
        appender = new MockLogAppender();
        try {
            appender.start();
            Loggers.addAppender(LogManager.getLogger(""org.opensearch.cluster.NodeConnectionsService""), appender);
            for (DiscoveryNode targetNode : targetNodes) {
                if (disconnectedNodes.contains(targetNode) && newTargetNodes.get(targetNode.getId()) != null) {
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""connecting to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connecting to "" + targetNode));
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""connected to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connected to "" + targetNode));
                } else {
                    appender.addExpectation(new MockLogAppender.UnseenEventExpectation(""connecting to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connecting to "" + targetNode));
                    appender.addExpectation(new MockLogAppender.UnseenEventExpectation(""connected to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connected to "" + targetNode));
                }
                if (newTargetNodes.get(targetNode.getId()) == null) {
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""disconnected from "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""disconnected from "" + targetNode));
                }
            }
            for (DiscoveryNode targetNode : newTargetNodes) {
                appender.addExpectation(new MockLogAppender.UnseenEventExpectation(""disconnected from "" + targetNode,
                    ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                    ""disconnected from "" + targetNode));
                if (targetNodes.get(targetNode.getId()) == null) {
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""connecting to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connecting to "" + targetNode));
                    appender.addExpectation(new MockLogAppender.SeenEventExpectation(""connected to "" + targetNode,
                        ""org.opensearch.cluster.NodeConnectionsService"", Level.DEBUG,
                        ""connected to "" + targetNode));
                }
            }

            service.disconnectFromNodesExcept(newTargetNodes);
            service.connectToNodes(newTargetNodes, () -> {});
            deterministicTaskQueue.runAllRunnableTasks();
            appender.assertAllExpectationsMatched();
        } finally {
            Loggers.removeAppender(LogManager.getLogger(""org.opensearch.cluster.NodeConnectionsService""), appender);
            appender.stop();
        }
    }
",non-flaky,5
176859,OryxProject_oryx,LangUtilsTest.testHashDouble,"  @Test
  public void testHashDouble() {
    for (int i = 0; i < 1000; i++) {
      assertEquals(Double.valueOf(i).hashCode(), LangUtils.hashDouble(i));
    }
  }
",non-flaky,5
88796,apache_ignite,LongRunningProcessPingTaskTest.testCallProcessIsDone,"    @Test
    public void testCallProcessIsDone() {
        UUID procId = UUID.randomUUID();

        Future<?> fut = mock(Future.class);
        doReturn(true).when(fut).isDone();
        metadataStorage.put(procId, fut);

        LongRunningProcessPingTask pingTask = createTask(procId);

        List<LongRunningProcessStatus> statuses = pingTask.call();

        assertEquals(1, statuses.size());

        LongRunningProcessStatus status = statuses.get(0);
        assertEquals(LongRunningProcessState.DONE, status.getState());
        assertNull(status.getException());

        assertEquals(1, metadataStorage.size());
    }
",non-flaky,5
156048,jReddit_jReddit,KindTest.testMatchSuccess,"    @Test
    public void testMatchSuccess() {
        Assert.assertEquals(Kind.COMMENT, Kind.match(Kind.COMMENT.value()));
    }
",non-flaky,5
77018,Tencent_Firestorm,ShuffleStorageUtilsTest.getShuffleDataPathWithRangeTest,"  @Test
  public void getShuffleDataPathWithRangeTest() {
    String result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 1, 3, 6);
    assertEquals(""appId/0/0-2"", result);
    result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 2, 3, 6);
    assertEquals(""appId/0/0-2"", result);
    result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 3, 3, 6);
    assertEquals(""appId/0/3-5"", result);
    result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 5, 3, 6);
    assertEquals(""appId/0/3-5"", result);
    try {
      ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 6, 3, 6);
      fail(""shouldn't be here"");
    } catch (Exception e) {
      assertTrue(e.getMessage().startsWith(""Can't generate ShuffleData Path""));
    }
    result = ShuffleStorageUtils.getShuffleDataPathWithRange(""appId"", 0, 6, 3, 7);
    assertEquals(""appId/0/6-8"", result);
  }
",non-flaky,5
77543,dropwizard_dropwizard,ResourceTestRuleTest.testGetPersonWithQueryParam,"    @Test
    public void testGetPersonWithQueryParam() {
        // Test to ensure that the dropwizard validator is registered so that
        // it can validate the ""ind"" IntParam.
        assertThat(resourceTestRule.target(""/person/blah/index"")
                .queryParam(""ind"", 0).request()
                .get(Person.class))
                .isEqualTo(person);
        verify(peopleStore).fetchPerson(""blah"");
    }
",non-flaky,5
159683,liquibase_liquibase,AddUniqueConstraintExecutorTest.execute_withSchema,"    @Test
    public void execute_withSchema() throws Exception {
        statementUnderTest = new AddUniqueConstraintStatement(
                DatabaseTestContext.ALT_CATALOG,
                DatabaseTestContext.ALT_SCHEMA,
                TABLE_NAME,
                new ColumnConfig[]
                        {new ColumnConfig().setName(COLUMN_NAME)},
                CONSTRAINT_NAME
        );

        assertCorrect(""ALTER TABLE liquibasec.adduqtest ADD CONSTRAINT uq_test UNIQUE (coltomakeuq)"", MySQLDatabase
                .class);
        /*
         * In Informix, this test case is actually impossible. While it is allowed to cross-select data from
          * different databases (using the database:schema.table notation), it is not allowed to send DDL to a
          * different database (even if the database is on the same instance). So, even as the following
          * statement is semantically false, it is syntactically correct.
         */
        assertCorrect(""ALTER TABLE liquibasec:liquibaseb.adduqtest ADD CONSTRAINT UNIQUE (coltomakeuq) CONSTRAINT "" +
                ""uq_test"", InformixDatabase.class);

        assertCorrect(""alter table liquibasec.adduqtest add constraint uq_test unique (coltomakeuq)"", OracleDatabase.class);
        assertCorrect(""alter table liquibaseb.\""adduqtest\"" add constraint uq_test unique (\""coltomakeuq\"")"", PostgresDatabase.class);
        assertCorrect(""alter table liquibasec.adduqtest add constraint uq_test unique (coltomakeuq)"", DerbyDatabase
                .class);
        assertCorrect(""alter table [liquibaseb].[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"",
                SybaseASADatabase.class, SybaseDatabase.class);
        assertCorrect(""alter table [liquibasec].[liquibaseb].[adduqtest] add constraint [uq_test] unique "" +
                ""([coltomakeuq])"", MSSQLDatabase.class);
        assertCorrect(""alter table [adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", FirebirdDatabase.class);

        assertCorrect(""alter table [liquibaseb].[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", HsqlDatabase.class);
        assertCorrect(""alter table \""liquibasec\"".[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", DB2Database.class, Db2zDatabase.class);
        assertCorrect(""alter table [liquibaseb].[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"", H2Database.class);
        assertCorrectOnRest(""alter table [liquibasec].[adduqtest] add constraint [uq_test] unique ([coltomakeuq])"");

    }
",non-flaky,5
122553,vespa-engine_vespa,ProcessFactoryImplTest.testSpawn,"    @Test
    public void testSpawn() {
        CommandLine commandLine = mock(CommandLine.class);
        when(commandLine.getArguments()).thenReturn(List.of(""program""));
        when(commandLine.getRedirectStderrToStdoutInsteadOfDiscard()).thenReturn(true);
        when(commandLine.programName()).thenReturn(""program"");
        Path outputPath;
        try (ChildProcess2Impl child = processFactory.spawn(commandLine)) {
            outputPath = child.getOutputPath();
            assertTrue(Files.exists(outputPath));
            assertEquals(""rw-------"", new UnixPath(outputPath).getPermissions());
            ArgumentCaptor<ProcessBuilder> processBuilderCaptor =
                    ArgumentCaptor.forClass(ProcessBuilder.class);
            verify(starter).start(processBuilderCaptor.capture());
            ProcessBuilder processBuilder = processBuilderCaptor.getValue();
            assertTrue(processBuilder.redirectErrorStream());
            ProcessBuilder.Redirect redirect = processBuilder.redirectOutput();
            assertEquals(ProcessBuilder.Redirect.Type.WRITE, redirect.type());
            assertEquals(outputPath.toFile(), redirect.file());
        }

        assertFalse(Files.exists(outputPath));
    }
",non-flaky,5
43006,fabiomaffioletti_jsondoc,SpringPathBuilderTest.apply,"	@Test
	public void testPath2() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController2.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController2"", apiDoc.getName());

		boolean none = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
			
			@Override
			public boolean apply(ApiMethodDoc input) {
				System.out.println(input.getPath());
				return input.getPath().contains(""/"");
			}
",non-flaky,5
104169,spring-cloud_spring-cloud-config,EnvironmentPrefixHelperTests.testStripPrefixWithEscape,"	@Test
	public void testStripPrefixWithEscape() {
		assertThat(this.helper.stripPrefix(""{plain}{key:foo}foo""))
				.isEqualTo(""{key:foo}foo"");
	}
",non-flaky,5
38678,apache_pulsar,RabbitMQSourceTest.TestOpenAndWriteSink,"    @Test
    public void TestOpenAndWriteSink() {
        Map<String, Object> configs = new HashMap<>();
        configs.put(""host"", ""localhost"");
        configs.put(""port"", ""5672"");
        configs.put(""virtualHost"", ""default"");
        configs.put(""username"", ""guest"");
        configs.put(""password"", ""guest"");
        configs.put(""queueName"", ""test-queue"");
        configs.put(""connectionName"", ""test-connection"");
        configs.put(""requestedChannelMax"", ""0"");
        configs.put(""requestedFrameMax"", ""0"");
        configs.put(""connectionTimeout"", ""60000"");
        configs.put(""handshakeTimeout"", ""10000"");
        configs.put(""requestedHeartbeat"", ""60"");
        configs.put(""prefetchCount"", ""0"");
        configs.put(""prefetchGlobal"", ""false"");
        configs.put(""passive"", ""false"");

        RabbitMQSource source = new RabbitMQSource();

        // open should success
        // rabbitmq service may need time to initialize
        Awaitility.await().ignoreExceptions().untilAsserted(() -> source.open(configs, null));
    }
",non-flaky,5
38243,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testTableMetadata,"    @Test
    public void testTableMetadata() {
        assertEquals(AtlasDbConstants.GENERIC_TABLE_METADATA.length, keyValueService.getMetadataForTable(TEST_TABLE).length);
        keyValueService.putMetadataForTable(TEST_TABLE, ArrayUtils.EMPTY_BYTE_ARRAY);
        assertEquals(0, keyValueService.getMetadataForTable(TEST_TABLE).length);
        keyValueService.putMetadataForTable(TEST_TABLE, metadata0);
        assertTrue(Arrays.equals(metadata0, keyValueService.getMetadataForTable(TEST_TABLE)));
    }
",non-flaky,5
113910,spring-projects_spring-data-couchbase,CouchbaseTemplateQueryCollectionIntegrationTests.removeByQuery,"	@Test
	public void removeByQuery() { // 8
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.one(vie);
		List<RemoveResult> removeResults = couchbaseTemplate.removeByQuery(Airport.class)
				.withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(scopeName).inCollection(collectionName)
				.withOptions(options).matching(Query.query(QueryCriteria.where(""iata"").is(vie.getIata()))).all();
		assertEquals(saved.getId(), removeResults.get(0).getId());
	}
",non-flaky,5
84654,apache_zookeeper,ZooKeeperTest.testParseWithEmptyQuotes,"    @Test
    public void testParseWithEmptyQuotes() throws Exception {
        final ZooKeeper zk = createClient();
        ZooKeeperMain zkMain = new ZooKeeperMain(zk);
        String cmdstring = ""create /node ''"";
        zkMain.cl.parseCommand(cmdstring);
        assertEquals(zkMain.cl.getNumArguments(), 3, ""empty quotes should produce arguments"");
        assertEquals(zkMain.cl.getCmdArgument(0), ""create"", ""create is not taken as first argument"");
        assertEquals(zkMain.cl.getCmdArgument(1), ""/node"", ""/node is not taken as second argument"");
        assertEquals(zkMain.cl.getCmdArgument(2), """", ""empty string is not taken as third argument"");
    }
",non-flaky,5
70849,apache_kafka,WorkerSourceTaskTest.testHeaders,"    @Test
    public void testHeaders() throws Exception {
        Headers headers = new RecordHeaders();
        headers.add(""header_key"", ""header_value"".getBytes());

        org.apache.kafka.connect.header.Headers connectHeaders = new ConnectHeaders();
        connectHeaders.add(""header_key"", new SchemaAndValue(Schema.STRING_SCHEMA, ""header_value""));

        createWorkerTask();

        List<SourceRecord> records = new ArrayList<>();
        records.add(new SourceRecord(PARTITION, OFFSET, ""topic"", null, KEY_SCHEMA, KEY, RECORD_SCHEMA, RECORD, null, connectHeaders));

        Capture<ProducerRecord<byte[], byte[]>> sent = expectSendRecord(true, false, true, true, true, headers);

        PowerMock.replayAll();

        Whitebox.setInternalState(workerTask, ""toSend"", records);
        Whitebox.invokeMethod(workerTask, ""sendRecords"");
        assertEquals(SERIALIZED_KEY, sent.getValue().key());
        assertEquals(SERIALIZED_RECORD, sent.getValue().value());
        assertEquals(headers, sent.getValue().headers());

        PowerMock.verifyAll();
    }
",non-flaky,5
26785,MundaneImmortal_pair-distribution-app,CompanyTest.testIsDevOpsRotationWeekly,"	@Test
	public void testIsDevOpsRotationWeekly() {
		Company company = new Company(""Company"");

		company.setDevOpsRotationStrategy(""weekly"");

		assertThat(company.isDevOpsRotationWeekly(), is(true));
	}
",non-flaky,5
176867,OryxProject_oryx,ClassUtilsTest.testNoSuchMethod,"  @Test(expected = IllegalArgumentException.class)
  public void testNoSuchMethod() {
    ClassUtils.loadInstanceOf(Long.class.getName(), Long.class);
  }
",non-flaky,5
104151,spring-cloud_spring-cloud-config,EncryptionControllerTests.sunnyDayRsaKey,"	@Test
	public void sunnyDayRsaKey() {
		this.controller = new EncryptionController(
				new SingleTextEncryptorLocator(new RsaSecretEncryptor()));
		String cipher = this.controller.encrypt(""foo"", MediaType.TEXT_PLAIN);
		assertThat(this.controller.decrypt(cipher, MediaType.TEXT_PLAIN))
				.isEqualTo(""foo"");
	}
",non-flaky,5
118779,netty_netty,AbstractReferenceCountedByteBufTest.testRetainOverflow2,"    @Test(expected = IllegalReferenceCountException.class)
    public void testRetainOverflow2() {
        AbstractReferenceCountedByteBuf referenceCounted = newReferenceCounted();
        assertEquals(1, referenceCounted.refCnt());
        referenceCounted.retain(Integer.MAX_VALUE);
    }
",non-flaky,5
104629,apache_pinot,OfflineClusterIntegrationTest.testInstancesStarted,"  @Test
  public void testInstancesStarted() {
    assertEquals(_serviceStatusCallbacks.size(), getNumBrokers() + getNumServers());
    for (ServiceStatus.ServiceStatusCallback serviceStatusCallback : _serviceStatusCallbacks) {
      assertEquals(serviceStatusCallback.getServiceStatus(), ServiceStatus.Status.GOOD);
    }
  }
",non-flaky,5
59635,looly_hutool,TokenizerUtilTest.ikAnalyzerTest,"	@Test
	public void ikAnalyzerTest() {
		TokenizerEngine engine = new IKAnalyzerEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""è¿ä¸¤ä¸ª æ¹æ³ ç åºå« å¨äº è¿åå¼"", resultStr);
	}
",non-flaky,5
88802,apache_ignite,LoadTest.testMultithreading,"    @Test
    public void testMultithreading() throws Exception {
        final int THREAD_CNT = 8;
        final int ITERATION_CNT = 20;
        final int BATCH_SIZE = 1000;
        final int PAGE_CNT = 3;

        IgniteConfiguration srvCfg = Config.getServerConfiguration();

        // No peer class loading from thin clients: we need the server to know about this class to deserialize
        // ScanQuery filter.
        srvCfg.setBinaryConfiguration(new BinaryConfiguration().setTypeConfigurations(Arrays.asList(
            new BinaryTypeConfiguration(getClass().getName()),
            new BinaryTypeConfiguration(SerializedLambda.class.getName())
        )));

        try (Ignite ignored = Ignition.start(srvCfg);
             IgniteClient client = Ignition.startClient(new ClientConfiguration().setAddresses(Config.SERVER))
        ) {
            ClientCache<Integer, String> cache = client.createCache(""testMultithreading"");

            AtomicInteger cnt = new AtomicInteger(1);

            AtomicReference<Throwable> error = new AtomicReference<>();

            Runnable assertion = () -> {
                try {
                    int rangeStart = cnt.getAndAdd(BATCH_SIZE);
                    int rangeEnd = rangeStart + BATCH_SIZE;

                    Map<Integer, String> data = IntStream.range(rangeStart, rangeEnd).boxed()
                        .collect(Collectors.toMap(i -> i, i -> String.format(""String %s"", i)));

                    cache.putAll(data);

                    Query<Cache.Entry<Integer, String>> qry = new ScanQuery<Integer, String>()
                        .setPageSize(data.size() / PAGE_CNT)
                        .setFilter((i, s) -> i >= rangeStart && i < rangeEnd);

                    try (QueryCursor<Cache.Entry<Integer, String>> cur = cache.query(qry)) {
                        List<Cache.Entry<Integer, String>> res = cur.getAll();

                        assertEquals(""Unexpected number of entries"", data.size(), res.size());

                        Map<Integer, String> act = res.stream()
                            .collect(Collectors.toMap(Cache.Entry::getKey, Cache.Entry::getValue));

                        assertEquals(""Unexpected entries"", data, act);
                    }
                }
                catch (Throwable ex) {
                    error.set(ex);
                }
            };

            CountDownLatch complete = new CountDownLatch(THREAD_CNT);

            Runnable manyAssertions = () -> {
                for (int i = 0; i < ITERATION_CNT && error.get() == null; i++)
                    assertion.run();

                complete.countDown();
            };

            ExecutorService threadPool = Executors.newFixedThreadPool(THREAD_CNT);

            IntStream.range(0, THREAD_CNT).forEach(t -> threadPool.submit(manyAssertions));

            assertTrue(""Timeout"", complete.await(180, TimeUnit.SECONDS));

            String errMsg = error.get() == null ? """" : error.get().getMessage();

            assertNull(errMsg, error.get());
        }
    }
",non-flaky,5
162731,OpenAPITools_openapi-generator,XmlItemTest.prefixNamespaceBooleanTest,"    @Test
    public void prefixNamespaceBooleanTest() {
        // TODO: test prefixNamespaceBoolean
    }
",non-flaky,5
98467,ONSdigital_rm-collection-exercise-service,EventServiceTest.testTagShouldHaveNudge1AsAnActionableTag,"  @Test
  public void testTagShouldHaveNudge1AsAnActionableTag() {
    assertThat(Tag.nudge_email_1.isActionable(), Matchers.is(true));
  }
",non-flaky,5
170471,eclipse_jetty.project,ObjectMBeanUtilTest.testGetAttributeAttributeNotFoundException,"    @Test
    public void testGetAttributeAttributeNotFoundException()
    {
        AttributeNotFoundException e = assertThrows(AttributeNotFoundException.class, () -> objectMBean.getAttribute(""ffname""));

        assertNotNull(e, ""An AttributeNotFoundException must have occurred by now as there is no attribute with the name ffname in bean"");
    }
",non-flaky,5
113954,spring-projects_spring-data-couchbase,CouchbaseRepositoryKeyValueIntegrationTests.getConnectionString,"	@Test
		public String getConnectionString() {
			return connectionString();
		}
",non-flaky,5
114101,aws_aws-sdk-java-v2,TableSchemaTest.fromClass_invalidClassThrowsException,"    @Test
    public void fromClass_invalidClassThrowsException() {
        exception.expect(IllegalArgumentException.class);
        exception.expectMessage(""InvalidBean"");
        TableSchema.fromClass(InvalidBean.class);
    }
",non-flaky,5
98347,Kong_unirest-java,UriFormatterTest.basicBoringUri,"    @Test
    public void basicBoringUri() {
        assertLinkSurvives(""http://localhost/test?a=b"");
    }
",non-flaky,5
38204,palantir_atlasdb,RocksDbKeyValueServiceTest.testReadGood4,"    @Test
    public void testReadGood4() {
        final Cell cell = Cell.create(""r,1"".getBytes(), "",c,1,"".getBytes());
        db.put(TABLE, ImmutableMap.of(cell, ""v,1"".getBytes()), 1);
        final Map<Cell, Value> res = db.get(TABLE, ImmutableMap.of(cell, 2L));
        final Value value = res.get(cell);
        assertEquals(1, value.getTimestamp());
        assertEquals(""v,1"", new String(value.getContents()));
    }
",non-flaky,5
133949,CorfuDB_CorfuDB,BaseHandlerTest.testHandleWrongEpochError,"    @Test
    public void testHandleWrongEpochError() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.IGNORE),
                getWrongEpochErrorMsg(2L)
        );

        ArgumentCaptor<WrongEpochException> exceptionCaptor = ArgumentCaptor.forClass(WrongEpochException.class);
        baseHandler.handleMessage(response, mockChannelHandlerContext);

        // Verify that the correct request was completed exceptionally (once)
        // with the expected exception
        verify(mockClientRouter, never()).completeRequest(anyLong(), any());
        verify(mockClientRouter).completeExceptionally(
                eq(response.getHeader().getRequestId()), exceptionCaptor.capture());

        assertEquals(2L, exceptionCaptor.getValue().getCorrectEpoch());
    }
",non-flaky,5
104104,spring-cloud_spring-cloud-config,DiscoveryClientConfigServiceBootstrapConfigurationTests.onWhenHeartbeat,"	@Test
	public void onWhenHeartbeat() throws Exception {
		setup(""spring.cloud.config.discovery.enabled=true"");

		expectDiscoveryClientConfigServiceBootstrapConfigurationIsSetup();

		givenDiscoveryClientReturnsInfo();
		verifyDiscoveryClientCalledOnce();

		this.context.publishEvent(new HeartbeatEvent(this.context, ""new""));

		expectConfigClientPropertiesHasConfigurationFromEureka();
	}
",non-flaky,5
91547,apache_kylin,JdbcExplorerTest.testGetRelatedKylinResources,"    @Test
    public void testGetRelatedKylinResources() {
        Assert.assertTrue(explorer.getRelatedKylinResources(null).isEmpty());
    }
",non-flaky,5
162414,testcontainers_testcontainers-java,DockerNetworkModeTest.testHostNetworkContainer,"    @Test
    public void testHostNetworkContainer() throws TimeoutException {
        String output = getContainerOutput(hostNetwork);

        assertTrue(""'host' network can access the internet"", output.contains(""seq=1""));
    }
",non-flaky,5
38260,palantir_atlasdb,AbstractSerializableTransactionTest.testClassicWriteSkewCell,"    @Test
    public void testClassicWriteSkewCell() {
        Transaction t0 = startTransaction();
        put(t0, ""row1"", ""col1"", ""100"");
        put(t0, ""row2"", ""col1"", ""100"");
        t0.commit();

        Transaction t1 = startTransaction();
        Transaction t2 = startTransaction();
        withdrawMoney(t1, true, true);
        withdrawMoney(t2, false, true);

        t1.commit();
        try {
            t2.commit();
            fail();
        } catch (TransactionSerializableConflictException e) {
            // this is expectecd to throw because it is a write skew
        }
    }
",non-flaky,5
88801,apache_ignite,ProcessManagerWrapperTest.testClear,"    @Test
    public void testClear() {
        Map<UUID, List<UUID>> procIds = Collections.emptyMap();
        wrapper.clear(procIds);

        verify(delegate).clear(eq(procIds));
    }
",non-flaky,5
110892,pushtorefresh_storio,InterceptorTest.putContentValuesIterable,"    @Test
    public void putContentValuesIterable() {
        storIOSQLite.put()
                .contentValues(createContentValues(), createContentValues())
                .withPutResolver(createCVPutResolver())
                .prepare()
                .executeAsBlocking();
        checkInterceptorsCalls();
    }
",non-flaky,5
96902,apache_avro,TestIdl.writeTests,"  @Test
  public void writeTests() throws Exception {
    if (! ""write"".equals(TEST_MODE)) return;

    for (GenTest t : tests) {
      t.write();
    }
  }
",non-flaky,5
175766,GoogleCloudPlatform_google-cloud-eclipse,FlexDeployPreferencesPanelTest.testDefaultAppYamlPathSet,"  @Test
  public void testDefaultAppYamlPathSet() {
    FlexDeployPreferencesPanel panel = createPanel(true /* requireValues */);

    Text appYamlField = findAppYamlField(panel);
    assertEquals(""src/main/appengine/app.yaml"", appYamlField.getText());
    assertTrue(getAppYamlPathValidationStatus(panel).isOK());
  }
",non-flaky,5
38244,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRange,"    @Test
    public void testGetRange() {
        testGetRange(reverseRangesSupported());
    }
",non-flaky,5
89316,apache_samza,TestKafkaSystemAdminWithMock.testGetSystemStreamPartitionCountsShouldTerminateAfterFiniteRetriesOnException,"  @Test(expected = SamzaException.class)
  public void testGetSystemStreamPartitionCountsShouldTerminateAfterFiniteRetriesOnException() throws Exception {
    final Set<String> streamNames = ImmutableSet.of(VALID_TOPIC);
    final long cacheTTL = 100L;

    when(mockKafkaConsumer.partitionsFor(VALID_TOPIC)).thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException())
        .thenThrow(new RuntimeException());

    kafkaSystemAdmin.getSystemStreamPartitionCounts(streamNames, cacheTTL);
  }
",non-flaky,5
135754,Netflix_Hystrix,HystrixConcurrencyStrategyTest.call,"    @Test
    public void testThreadContextOnTimeout() {
        final AtomicBoolean isInitialized = new AtomicBoolean();
        new TimeoutCommand().toObservable()
                .doOnError(new Action1<Throwable>() {
                    @Override
                    public void call(Throwable throwable) {
                        isInitialized.set(HystrixRequestContext.isCurrentThreadInitialized());
                    }
",non-flaky,5
89320,apache_samza,TestKafkaSystemConsumer.testFetchThresholdShouldDivideEvenlyAmongPartitions,"  @Test
  public void testFetchThresholdShouldDivideEvenlyAmongPartitions() {
    final KafkaSystemConsumer consumer = createConsumer(FETCH_THRESHOLD_MSGS, FETCH_THRESHOLD_BYTES);
    final int partitionsNum = 50;
    for (int i = 0; i < partitionsNum; i++) {
      consumer.register(new SystemStreamPartition(TEST_SYSTEM, TEST_STREAM, new Partition(i)), ""0"");
    }

    consumer.start();

    Assert.assertEquals(Long.valueOf(FETCH_THRESHOLD_MSGS) / partitionsNum, consumer.perPartitionFetchThreshold);
    Assert.assertEquals(Long.valueOf(FETCH_THRESHOLD_BYTES) / 2 / partitionsNum,
        consumer.perPartitionFetchThresholdBytes);

    consumer.stop();
  }
",non-flaky,5
135785,Netflix_Hystrix,CollapsedRequestSubjectTest.testUnsubscribeAfterSetResponse,"    @Test
    public void testUnsubscribeAfterSetResponse() throws InterruptedException, ExecutionException {
        CollapsedRequestSubject<String, String> cr = new CollapsedRequestSubject<String, String>(""hello"");
        Observable<String> o = cr.toObservable();
        Future<String> v = o.toBlocking().toFuture();

        cr.setResponse(""theResponse"");

        // unsubscribe after the value is sent
        v.cancel(true);

        // still get value as it was set before canceling
        assertEquals(""theResponse"", v.get());
    }
",non-flaky,5
162380,testcontainers_testcontainers-java,TestEnvironmentTest.testCompareVersionIgnoresExcessLength,"    @Test
    public void testCompareVersionIgnoresExcessLength() {
        assertTrue(""1.20 == 1.20.3"", new ComparableVersion(""1.20"").compareTo(new ComparableVersion(""1.20.3"")) == 0);
    }
",non-flaky,5
38235,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRowsAllColumns,"    @Test
    public void testGetRowsAllColumns() {
        putTestDataForSingleTimestamp();
        Map<Cell, Value> values = keyValueService.getRows(TEST_TABLE,
                                                          Arrays.asList(row1, row2),
                                                          ColumnSelection.all(),
                                                          TEST_TIMESTAMP + 1);
        assertEquals(4, values.size());
        assertEquals(null, values.get(Cell.create(row1, column1)));
        assertArrayEquals(value10, values.get(Cell.create(row1, column0)).getContents());
        assertArrayEquals(value12, values.get(Cell.create(row1, column2)).getContents());
        assertArrayEquals(value21, values.get(Cell.create(row2, column1)).getContents());
        assertArrayEquals(value22, values.get(Cell.create(row2, column2)).getContents());
    }
",non-flaky,5
92634,apache_dubbo,ApplicationConfigTest.testMonitor,"    @Test
    public void testMonitor() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setMonitor(new MonitorConfig(""monitor-addr""));
        assertThat(application.getMonitor().getAddress(), equalTo(""monitor-addr""));
        application.setMonitor(""monitor-addr"");
        assertThat(application.getMonitor().getAddress(), equalTo(""monitor-addr""));
    }
",non-flaky,5
98365,Kong_unirest-java,InterceptorTest.setUp,"    @BeforeEach
    public void setUp() {
        super.setUp();
        interceptor = new UniInterceptor(""x-custom"", ""foo"");
    }
",non-flaky,5
78296,apache_beam,LateDataDroppingDoFnRunnerTest.testLateDataFilter,"  @Test
  public void testLateDataFilter() throws Exception {
    MetricsContainerImpl container = new MetricsContainerImpl(""any"");
    MetricsEnvironment.setCurrentContainer(container);
    when(mockTimerInternals.currentInputWatermarkTime()).thenReturn(new Instant(15L));

    LateDataFilter lateDataFilter =
        new LateDataFilter(WindowingStrategy.of(WINDOW_FN), mockTimerInternals);

    Iterable<WindowedValue<Integer>> actual =
        lateDataFilter.filter(
            ""a"",
            ImmutableList.of(
                createDatum(13, 13L),
                createDatum(5, 5L), // late element, earlier than 4L.
                createDatum(16, 16L),
                createDatum(18, 18L)));

    Iterable<WindowedValue<Integer>> expected =
        ImmutableList.of(createDatum(13, 13L), createDatum(16, 16L), createDatum(18, 18L));
    assertThat(expected, containsInAnyOrder(Iterables.toArray(actual, WindowedValue.class)));
    long droppedValues =
        container
            .getCounter(
                MetricName.named(
                    LateDataDroppingDoFnRunner.class,
                    LateDataDroppingDoFnRunner.DROPPED_DUE_TO_LATENESS))
            .getCumulative();
    assertEquals(1, droppedValues);
    // Ensure that reiterating returns the same results and doesn't increment the counter again.
    assertThat(expected, containsInAnyOrder(Iterables.toArray(actual, WindowedValue.class)));
    droppedValues =
        container
            .getCounter(
                MetricName.named(
                    LateDataDroppingDoFnRunner.class,
                    LateDataDroppingDoFnRunner.DROPPED_DUE_TO_LATENESS))
            .getCumulative();
    assertEquals(1, droppedValues);
  }
",non-flaky,5
43116,trinodb_trino,BaseConnectorSmokeTest.testJoin,"    @Test
    public void testJoin()
    {
        assertQuery(""SELECT n.name, r.name FROM nation n JOIN region r on n.regionkey = r.regionkey"");
    }
",non-flaky,5
178006,aosp-mirror_platform_frameworks_support,BrowseSupportFragmentTest.run,"    @Test
    public void activityRecreate_notCrash() throws Throwable {
        final long dataLoadingDelay = 1000;
        Intent intent = new Intent();
        intent.putExtra(BrowseSupportFragmentTestActivity.EXTRA_LOAD_DATA_DELAY, dataLoadingDelay);
        intent.putExtra(BrowseSupportFragmentTestActivity.EXTRA_ADD_TO_BACKSTACK , false);
        intent.putExtra(BrowseSupportFragmentTestActivity.EXTRA_SET_ADAPTER_AFTER_DATA_LOAD, true);
        mActivity = activityTestRule.launchActivity(intent);

        Thread.sleep(dataLoadingDelay + TRANSITION_LENGTH);

        InstrumentationRegistry.getInstrumentation().callActivityOnRestart(mActivity);
        activityTestRule.runOnUiThread(new Runnable() {
            @Override
            public void run() {
                mActivity.recreate();
            }
",non-flaky,5
110123,Wikidata_wikidata-toolkit,ClientTest.testSitesActionException,"	@Test
	public void testSitesActionException() throws ParseException, IOException {
		Mockito.doThrow(new IOException()).when(mockDpc).getSitesInformation();

		String[] args = new String[] { ""-a"", ""rdf"", ""--rdftasks"",
				""items,labels"" };
		Client client = new Client(mockDpc, args);
		client.performActions(); // print help

		Mockito.verify(mockDpc, Mockito.never()).processDump(
				Mockito.<MwDumpFile> any());
		Mockito.verify(mockDpc).getSitesInformation();
	}
",non-flaky,5
150202,apache_hive,TestJavaDataModel.testGetModelForSystemWhenSetTo64,"  @Test
  public void testGetModelForSystemWhenSetTo64() throws Exception {
    System.setProperty(DATA_MODEL_PROPERTY, ""64"");
    assertSame(JavaDataModel.JAVA64, JavaDataModel.getModelForSystem());
  }
",non-flaky,5
98613,nutzam_nutz,El2Test.run,"    @Test
    public void testIssue306() throws InterruptedException {
        int size = 100;
        final CountDownLatch count = new CountDownLatch(size);
        final List<Integer> error = new ArrayList<Integer>();
        for (int index = 0; index < size; index++) {
            new Thread() {
                public void run() {
                    try {
                        El.eval(""1+1"");
                    }
                    catch (Exception e) {
                        error.add(1);
                    }
                    finally {
                        count.countDown();
                    }
                }
",non-flaky,5
162729,OpenAPITools_openapi-generator,XmlItemTest.prefixNamespaceNumberTest,"    @Test
    public void prefixNamespaceNumberTest() {
        // TODO: test prefixNamespaceNumber
    }
",non-flaky,5
78306,apache_beam,InMemoryMultimapSideInputViewTest.testValueGrouping,"  @Test
  public void testValueGrouping() {
    MultimapView<String, String> view =
        InMemoryMultimapSideInputView.fromIterable(
            StringUtf8Coder.of(),
            ImmutableList.of(KV.of(""A"", ""a1""), KV.of(""A"", ""a2""), KV.of(""B"", ""b1"")));
    assertEquals(view.get(""A""), ImmutableList.of(""a1"", ""a2""));
    assertEquals(view.get(""B""), ImmutableList.of(""b1""));
    assertEquals(view.get(""C""), ImmutableList.of());
  }
",non-flaky,5
91572,apache_kylin,StringSplitterTest.testSplitWithNonEmptyString,"  @Test
  public void testSplitWithNonEmptyString() {
      String[] stringArray = StringSplitter.split(""]sZ}gR\""cws,8p#|m"", ""Fc8!v~f?aQL"");
",non-flaky,5
156054,jReddit_jReddit,JsonUtilsTest.testSafeJsonToBoolean,"    @Test
    public void testSafeJsonToBoolean() {
        Assert.assertNull(JsonUtils.safeJsonToBoolean(null));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""abcd""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""3522""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""25275738927589278572891""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""-25275738927589278572891""));
        Assert.assertTrue(JsonUtils.safeJsonToBoolean(""true""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""false""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""0""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""1""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""yes""));
        Assert.assertFalse(JsonUtils.safeJsonToBoolean(""no""));
    }
",non-flaky,5
76,swankjesse_dex,assertDurationIsInRange,"@Test
public void assertDurationIsInRange(long expectedMillis) {
    long minimum = (long) ((double) expectedMillis * 0.90);
    long maximum =
    Math.max((long) ((double) expectedMillis * 1.10), 10);
    long waitMillis = Math.max(expectedMillis * 10, 10);
    long duration = getDurationMillis(waitMillis);
    if (duration < minimum) {
        Assert.fail(""expected duration: "" + expectedMillis +
        "" minimum duration: "" + minimum +
        "" actual duration too short: "" + duration);
    } else if (duration > maximum) {
        Assert.fail(""expected duration: "" + expectedMillis +
        "" maximum duration: "" + maximum +
        "" actual duration too long: "" + duration);
    }
}",time,2
13917,neo4j_neo4j,MultipleClusterTest.runTwoClusters,"    @Test
    public void runTwoClusters() throws Throwable
    {
        File root = TargetDirectory.forTest( getClass() ).cleanDirectory( ""cluster"" );

        ClusterManager clusterManager = new ClusterManager(
                fromXml( getClass().getResource( ""/twoclustertest.xml"" ).toURI() ), root, MapUtil.stringMap() );

        try
        {
            clusterManager.start();
            ManagedCluster cluster1 = clusterManager.getCluster( ""neo4j.ha"" );

            long cluster1NodeId;
            {
                GraphDatabaseService master = cluster1.getMaster();
                logging.getLogger().info( ""CREATE NODE"" );
                Transaction tx = master.beginTx();
                Node node = master.createNode();
                node.setProperty( ""cluster"", ""neo4j.ha"" );
                cluster1NodeId = node.getId();
                logging.getLogger().info( ""CREATED NODE"" );
                tx.success();
                tx.finish();
            }

            ManagedCluster cluster2 = clusterManager.getCluster( ""neo4j.ha2"" );
            long cluster2NodeId;
            {
                GraphDatabaseService master = cluster2.getMaster();
                logging.getLogger().info( ""CREATE NODE"" );
                Transaction tx = master.beginTx();
                Node node = master.createNode();
                node.setProperty( ""cluster"", ""neo4j.ha2"" );
                cluster2NodeId = node.getId();
                logging.getLogger().info( ""CREATED NODE"" );
                tx.success();
                tx.finish();
            }

            // Verify properties in all cluster nodes
            for ( HighlyAvailableGraphDatabase highlyAvailableGraphDatabase : cluster1.getAllMembers() )
            {
                highlyAvailableGraphDatabase.getDependencyResolver().resolveDependency( UpdatePullerClient.class ).pullUpdates();

                Transaction transaction = highlyAvailableGraphDatabase.beginTx();
                assertEquals( ""neo4j.ha"", highlyAvailableGraphDatabase.getNodeById( cluster1NodeId ).getProperty(
                        ""cluster"" ) );
                transaction.finish();
            }

            for ( HighlyAvailableGraphDatabase highlyAvailableGraphDatabase : cluster2.getAllMembers() )
            {
                highlyAvailableGraphDatabase.getDependencyResolver().resolveDependency( UpdatePullerClient.class ).pullUpdates();

                Transaction transaction = highlyAvailableGraphDatabase.beginTx();
                assertEquals( ""neo4j.ha2"", highlyAvailableGraphDatabase.getNodeById( cluster2NodeId ).getProperty(
                        ""cluster"" ) );
                transaction.finish();
            }
        }
        finally
        {
            clusterManager.stop();
        }
    }
",non-flaky,5
114128,aws_aws-sdk-java-v2,LocalDateTimeAttributeConverterTest.localDateTimeAttributeConverterInvalidNanoSecondsTest,"    @Test
    public void localDateTimeAttributeConverterInvalidNanoSecondsTest() {
        assertFails(() -> transformTo(converter, EnhancedAttributeValue.fromString(""0-01-01T00:00:00.9999999999"")
                                                                       .toAttributeValue()));
    }
",non-flaky,5
162431,testcontainers_testcontainers-java,GenericContainerRuleTest.exceptionThrownWhenMappedPortNotFound,"    @Test
    public void exceptionThrownWhenMappedPortNotFound() throws IOException {
        assertThrows(""When the requested port is not mapped, getMappedPort() throws an exception"",
                IllegalArgumentException.class,
                () -> {
                    return redis.getMappedPort(666);
                });
    }
",non-flaky,5
136539,doanduyhai_Achilles,EntityMetaCodeGenTest.should_build_entity_with_complex_indices,"    @Test
    public void should_build_entity_with_complex_indices() throws Exception {
        setExec(aptUtils -> {
            final String className = TestEntityWithComplexIndices.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final List<FieldParser.FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, context);
            final TypeSpec typeSpec = builder.buildEntityMeta(EntityType.TABLE, typeElement, context, parsingResults, emptyList()).sourceCode;

            assertThat(buildSource(typeSpec)).isEqualTo(
                    readCodeBlockFromFile(""expected_code/entity_meta_builder/should_build_entity_with_complex_indices.txt""));
        });
        launchTest(TestEntityWithComplexIndices.class);
    }
",non-flaky,5
98020,vert-x3_vertx-mongo-client,UpdateOptionsTest.testOptions,"  @Test
  public void testOptions() {
    UpdateOptions options = new UpdateOptions();

    WriteOption writeOption = ACKNOWLEDGED;
    assertEquals(options, options.setWriteOption(writeOption));
    assertEquals(writeOption, options.getWriteOption());

    boolean multi = TestUtils.randomBoolean();
    assertEquals(options, options.setMulti(multi));
    assertEquals(multi, options.isMulti());

    boolean upsert = TestUtils.randomBoolean();
    assertEquals(options, options.setUpsert(upsert));
    assertEquals(upsert, options.isUpsert());

    JsonArray arrayFilters = new JsonArray().add(new JsonObject().put(TestUtils.randomAlphaString(5), TestUtils.randomAlphaString(5)));
    assertEquals(options, options.setArrayFilters(arrayFilters));
    assertEquals(arrayFilters, options.getArrayFilters());
  }
",non-flaky,5
77519,dropwizard_dropwizard,DropwizardAppRuleTest.returnsConfiguration,"    @Test
    public void returnsConfiguration() {
        final TestConfiguration config = RULE.getConfiguration();
        assertThat(config.getMessage()).isEqualTo(""Yes, it's here"");
    }
",non-flaky,5
33924,apache_camel,CordaConsumerVaultTrackByWithSortingIT.vaultTrackByWithSortingTest,"    @Test
    public void vaultTrackByWithSortingTest() throws Exception {
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
    }
",non-flaky,5
92672,apache_dubbo,ModuleConfigTest.testDefault,"    @Test
    public void testDefault() throws Exception {
        ModuleConfig module = new ModuleConfig();
        module.setDefault(true);
        assertThat(module.isDefault(), is(true));
    }
",non-flaky,5
135731,Netflix_Hystrix,HystrixCommandMetricsTest.onCompleted,"    @Test
    public void testCurrentConcurrentExecutionCount() throws InterruptedException {
        String key = ""cmd-metrics-C"";

        HystrixCommandMetrics metrics = null;
        List<Observable<Boolean>> cmdResults = new ArrayList<Observable<Boolean>>();

        int NUM_CMDS = 8;
        for (int i = 0; i < NUM_CMDS; i++) {
            HystrixCommand<Boolean> cmd = new SuccessCommand(key, 900);
            if (metrics == null) {
                metrics = cmd.metrics;
            }
            Observable<Boolean> eagerObservable = cmd.observe();
            cmdResults.add(eagerObservable);
        }

        try {
            Thread.sleep(150);
        } catch (InterruptedException ie) {
            fail(ie.getMessage());
        }
        System.out.println(""ReqLog: "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertEquals(NUM_CMDS, metrics.getCurrentConcurrentExecutionCount());

        final CountDownLatch latch = new CountDownLatch(1);
        Observable.merge(cmdResults).subscribe(new Subscriber<Boolean>() {
            @Override
            public void onCompleted() {
                System.out.println(""All commands done"");
                latch.countDown();
            }
",non-flaky,5
135059,undertow-io_undertow,PathMatcherTestCase.testSimpleMatchCase,"    @Test
    public void testSimpleMatchCase() {

        PathMatcher<String> pathMatcher = new PathMatcher<>();

        pathMatcher.addPrefixPath(""prefix"", ""response"");
        Assert.assertEquals(""response"", pathMatcher.match(""/prefix"").getValue());
        Assert.assertEquals(""response"", pathMatcher.match(""/prefix/"").getValue());

        pathMatcher.addPrefixPath(""/prefix"", ""new response"");
        Assert.assertEquals(""new response"", pathMatcher.match(""/prefix"").getValue());
        Assert.assertEquals(""new response"", pathMatcher.match(""/prefix/"").getValue());

        pathMatcher.addPrefixPath(""/prefix/"", ""different response"");
        Assert.assertEquals(""different response"", pathMatcher.match(""/prefix"").getValue());
        Assert.assertEquals(""different response"", pathMatcher.match(""/prefix/"").getValue());

        pathMatcher.addPrefixPath(""/prefix//////////////////////"", ""last response"");
        Assert.assertEquals(""last response"", pathMatcher.match(""/prefix"").getValue());
        Assert.assertEquals(""last response"", pathMatcher.match(""/prefix/"").getValue());

        pathMatcher.clearPaths();
        Assert.assertNull(pathMatcher.match(""/prefix"").getValue());
        Assert.assertNull(pathMatcher.match(""/prefix/"").getValue());
    }
",non-flaky,5
99706,apache_cassandra,DistributionGaussianTest.simpleGaussian,"    @Test
    public void simpleGaussian()
    {
        Distribution dist = OptionDistribution.get(""gaussian(1..10)"").get();
        assertTrue(dist instanceof DistributionBoundApache);

        assertEquals(1, dist.minValue());
        assertEquals(10, dist.maxValue());
        assertEquals(5, dist.average());

        assertEquals(1, dist.inverseCumProb(0d));
        assertEquals(10, dist.inverseCumProb(1d));

        int testCount = 100000;
        int[] results = new int[11];
        for (int i = 0; i < testCount; i++)
        {
            int val = toIntExact(dist.next());
            results[val]++;
        }

        // Increasing for the first half
        for (int i = toIntExact(dist.minValue()); i < dist.average(); i++)
        {
            assertTrue(results[i] < results[i + 1]);
        }

        // Decreasing for the second half
        for (int i = toIntExact(dist.average()) + 1; i < dist.maxValue(); i++)
        {
            assertTrue(results[i] > results[i + 1]);
        }
    }
",non-flaky,5
96880,apache_avro,TestSpecificCompiler.testConversionInstanceWithDecimalLogicalTypeDisabled,"  @Test
  public void testConversionInstanceWithDecimalLogicalTypeDisabled() throws Exception {
    SpecificCompiler compiler = createCompiler();
    compiler.setEnableDecimalLogicalType(false);

    Schema dateSchema = LogicalTypes.date()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timeSchema = LogicalTypes.timeMillis()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timestampSchema = LogicalTypes.timestampMillis()
        .addToSchema(Schema.create(Schema.Type.LONG));
    Schema decimalSchema = LogicalTypes.decimal(9,2)
        .addToSchema(Schema.create(Schema.Type.BYTES));
    Schema uuidSchema = LogicalTypes.uuid()
        .addToSchema(Schema.create(Schema.Type.STRING));

    Assert.assertEquals(""Should use DATE_CONVERSION for date type"",
        ""DATE_CONVERSION"", compiler.conversionInstance(dateSchema));
    Assert.assertEquals(""Should use TIME_CONVERSION for time type"",
        ""TIME_CONVERSION"", compiler.conversionInstance(timeSchema));
    Assert.assertEquals(""Should use TIMESTAMP_CONVERSION for date type"",
        ""TIMESTAMP_CONVERSION"", compiler.conversionInstance(timestampSchema));
    Assert.assertEquals(""Should use null for decimal if the flag is off"",
        ""null"", compiler.conversionInstance(decimalSchema));
    Assert.assertEquals(""Should use null for decimal if the flag is off"",
        ""null"", compiler.conversionInstance(uuidSchema));
  }
",non-flaky,5
159626,liquibase_liquibase,H2IntegrationTest.h2IsExcludedFromRunningChangeset,"    @Test
    public void h2IsExcludedFromRunningChangeset() throws Exception {
        runChangeLogFile(dbmsExcludeChangelog);
    }
",non-flaky,5
110173,Wikidata_wikidata-toolkit,TimerTest.enableCpuTimeTaking,"	@Test
	public void enableCpuTimeTaking() {
		ThreadMXBean tmxb = ManagementFactory.getThreadMXBean();
		tmxb.setThreadCpuTimeEnabled(false);

		Timer timer = new Timer(""Test timer"", Timer.RECORD_ALL);
		timer.start();
		doDummyComputation();
		timer.stop();

		assertTrue(""Timer should have measured a CPU time."",
				timer.getTotalCpuTime() > 0);
	}
",non-flaky,5
88861,apache_ignite,IteratorWithConcurrentModificationCheckerTest.testHasNextWhenIteratorHasMoreElementsThanExpected,"    @Test(expected = ConcurrentModificationException.class)
    public void testHasNextWhenIteratorHasMoreElementsThanExpected() {
        List<Integer> list = Arrays.asList(1, 2, 3);

        Iterator<Integer> iter = new IteratorWithConcurrentModificationChecker<>(list.iterator(), 2, ""Exception"");

        assertTrue(iter.hasNext());
        iter.next();
        assertTrue(iter.hasNext());
        iter.next();

        iter.hasNext(); // Should throw an exception.
    }
",non-flaky,5
84648,apache_zookeeper,ZooKeeperTest.testDeleteRecursiveCli,"    @Test
    public void testDeleteRecursiveCli() throws IOException, InterruptedException, CliException, KeeperException {
        final ZooKeeper zk = createClient();
        // making sure setdata works on /
        zk.setData(""/"", ""some"".getBytes(), -1);
        zk.create(""/a"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/b"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/b/v"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/b/v/1"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/c"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        zk.create(""/a/c/v"", ""some"".getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

        List<String> children = zk.getChildren(""/a"", false);

        assertEquals(children.size(), 2, ""2 children - b & c should be present "");
        assertTrue(children.contains(""b""));
        assertTrue(children.contains(""c""));

        ZooKeeperMain zkMain = new ZooKeeperMain(zk);
        String cmdstring1 = ""deleteall /a"";
        zkMain.cl.parseCommand(cmdstring1);
        assertFalse(zkMain.processZKCmd(zkMain.cl));
        assertNull(zk.exists(""/a"", null));
    }
",non-flaky,5
30992,camunda-cloud_zeebe,ObjectMappingTest.shouldFailDeserializationWithOversizedIntegerValue,"  @Test
  public void shouldFailDeserializationWithOversizedIntegerValue() {
    // given
    final POJO pojo = new POJO();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);

              w.writeString(wrapString(""intProp""));
              w.writeInteger(Integer.MAX_VALUE + 1L);
            });

    // then
    exception.expect(RuntimeException.class);
    exception.expectMessage(""Could not deserialize object"");

    // when
    pojo.wrap(buffer);
  }
",non-flaky,5
104099,spring-cloud_spring-cloud-config,DiscoveryClientConfigServiceBootstrapConfigurationNoSpringRetryTests.shouldFailWithExceptionGetConfigServerInstanceFromDiscoveryClient,"	@Test
	public void shouldFailWithExceptionGetConfigServerInstanceFromDiscoveryClient()
			throws Exception {
		givenDiscoveryClientReturnsNoInfo();

		expectNoInstancesOfConfigServerException();

		setup(""spring.cloud.config.discovery.enabled=true"",
				""spring.cloud.config.fail-fast=true"");
	}
",non-flaky,5
113875,spring-projects_spring-data-couchbase,ReactiveCouchbaseTemplateQueryCollectionIntegrationTests.insertById,"	@Test
	public void insertById() { // 6
		InsertOptions options = InsertOptions.insertOptions().timeout(Duration.ofSeconds(10));
		GetOptions getOptions = GetOptions.getOptions().timeout(Duration.ofSeconds(10));
		Airport saved = template.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.withOptions(options).one(vie.withIcao(""lowc"").withId(UUID.randomUUID().toString())).block();
		try {
			Airport found = template.findById(Airport.class).inScope(scopeName).inCollection(collectionName)
					.withOptions(getOptions).one(saved.getId()).block();
			assertEquals(saved, found);
		} finally {
			template.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId()).block();
		}
	}
",non-flaky,5
59596,looly_hutool,PinyinUtilTest.getPinyinUpperCaseTest,"	@Test
	public void getPinyinUpperCaseTest(){
		final String pinyin = PinyinUtil.getPinyin(""ä½ å¥½æ¡"", "" "");
		Assert.assertEquals(""ni hao yi"", pinyin);
	}
",non-flaky,5
30969,camunda-cloud_zeebe,POJOArrayTest.shouldFailOnRemovingEntryTwice,"  @Test
  public void shouldFailOnRemovingEntryTwice() {
    // given
    final POJOArray pojo = new POJOArray();

    final DirectBuffer buffer =
        encodeMsgPack(
            (w) -> {
              w.writeMapHeader(1);
              encodeSimpleArrayProp(w);
            });

    pojo.wrap(buffer);
    final Iterator<MinimalPOJO> iterator = pojo.simpleArray().iterator();
    iterator.next();
    iterator.remove();

    // then
    exception.expect(IllegalStateException.class);

    // when
    iterator.remove();
  }
",non-flaky,5
139,cdapio_cdap,WorkflowClientTestRun.testWorkflowClient,"@Test
public void testWorkflowClient() throws Exception {
    String outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath();
    Map<String, String> runtimeArgs = ImmutableMap.of(""inputPath"", createInput(""input""),
    ""outputPath"", outputPath);
    Id.Workflow workflowId = Id.Workflow.from(appId, AppWithWorkflow.SampleWorkflow.NAME);
    programClient.start(workflowId, false, runtimeArgs);
    programClient.waitForStatus(workflowId, ""STOPPED"", 60, TimeUnit.SECONDS);
    List<RunRecord> workflowRuns = programClient.getProgramRuns(workflowId, ProgramRunStatus.COMPLETED.name(), 0,
    Long.MAX_VALUE, 10);
    Assert.assertEquals(1, workflowRuns.size());
    Id.Run workflowRunId = new Id.Run(workflowId, workflowRuns.get(0).getPid());
    try {
        workflowClient.getWorkflowToken(new Id.Run(Id.Workflow.from(appId, ""random""), workflowRunId.getId()));
        Assert.fail(""Should not find a workflow token for a non-existing workflow"");
    } catch (NotFoundException expected) {
    }
    try {
        workflowClient.getWorkflowToken(new Id.Run(workflowId, RunIds.generate().getId()));
        Assert.fail(""Should not find a workflow token for a random run id"");
    } catch (NotFoundException expected) {
    }
    WorkflowTokenDetail workflowToken = workflowClient.getWorkflowToken(workflowRunId);
    Assert.assertEquals(3, workflowToken.getTokenData().size());
    workflowToken = workflowClient.getWorkflowToken(workflowRunId, WorkflowToken.Scope.SYSTEM);
    Assert.assertTrue(workflowToken.getTokenData().size() > 0);
    workflowToken = workflowClient.getWorkflowToken(workflowRunId, ""start_time"");
    Map<String, List<WorkflowTokenDetail.NodeValueDetail>> tokenData = workflowToken.getTokenData();
    Assert.assertEquals(AppWithWorkflow.WordCountMapReduce.NAME, tokenData.get(""start_time"").get(0).getNode());
    Assert.assertTrue(Long.parseLong(tokenData.get(""start_time"").get(0).getValue()) < System.currentTimeMillis());
    workflowToken = workflowClient.getWorkflowToken(workflowRunId, WorkflowToken.Scope.USER, ""action_type"");
    tokenData = workflowToken.getTokenData();
    Assert.assertEquals(AppWithWorkflow.WordCountMapReduce.NAME, tokenData.get(""action_type"").get(0).getNode());
    Assert.assertEquals(""MapReduce"", tokenData.get(""action_type"").get(0).getValue());
    String nodeName = AppWithWorkflow.SampleWorkflow.firstActionName;
    WorkflowTokenNodeDetail workflowTokenAtNode =
    workflowClient.getWorkflowTokenAtNode(workflowRunId, nodeName);
    Assert.assertEquals(AppWithWorkflow.DummyAction.TOKEN_VALUE,
    workflowTokenAtNode.getTokenDataAtNode().get(AppWithWorkflow.DummyAction.TOKEN_KEY));
    workflowTokenAtNode = workflowClient.getWorkflowTokenAtNode(workflowRunId, nodeName, WorkflowToken.Scope.SYSTEM);
    Assert.assertEquals(0, workflowTokenAtNode.getTokenDataAtNode().size());
    workflowTokenAtNode = workflowClient.getWorkflowTokenAtNode(workflowRunId, nodeName,
    AppWithWorkflow.DummyAction.TOKEN_KEY);
    Assert.assertEquals(AppWithWorkflow.DummyAction.TOKEN_VALUE,
    workflowTokenAtNode.getTokenDataAtNode().get(AppWithWorkflow.DummyAction.TOKEN_KEY));
    String reduceOutputRecordsCounter = ""org.apache.hadoop.mapreduce.TaskCounter.REDUCE_OUTPUT_RECORDS"";
    workflowTokenAtNode = workflowClient.getWorkflowTokenAtNode(workflowRunId, AppWithWorkflow.WordCountMapReduce.NAME,
    WorkflowToken.Scope.SYSTEM, reduceOutputRecordsCounter);
    Assert.assertEquals(6, Integer.parseInt(workflowTokenAtNode.getTokenDataAtNode().get(reduceOutputRecordsCounter)));
}",async wait,0
35691,cdapio_cdap,FileMetadataTest.testFileMetadataReadWrite,"  @Test
  public void testFileMetadataReadWrite() throws Exception {
    TransactionRunner transactionRunner = injector.getInstance(TransactionRunner.class);
    FileMetaDataWriter fileMetaDataWriter = new FileMetaDataWriter(transactionRunner);
    LogPathIdentifier logPathIdentifier =
      new LogPathIdentifier(NamespaceId.DEFAULT.getNamespace(), ""testApp"", ""testFlow"");
    LocationFactory locationFactory = injector.getInstance(LocationFactory.class);
    Location location = locationFactory.create(TMP_FOLDER.newFolder().getPath()).append(""/logs"");
    long currentTime = System.currentTimeMillis();
    for (int i = 10; i <= 100; i += 10) {
      // i is the event time
      fileMetaDataWriter.writeMetaData(logPathIdentifier, i, currentTime,
                                       location.append(Integer.toString(i)));
    }

    // for the timestamp 80, add new new log path id with different current time.

    fileMetaDataWriter.writeMetaData(logPathIdentifier, 80, currentTime + 1,
                                     location.append(""81""));

    fileMetaDataWriter.writeMetaData(logPathIdentifier, 80, currentTime + 2,
                                     location.append(""82""));

    // reader test
    FileMetaDataReader fileMetadataReader = injector.getInstance(FileMetaDataReader.class);

    Assert.assertEquals(12, fileMetadataReader.listFiles(logPathIdentifier, 0, 100).size());
    Assert.assertEquals(5, fileMetadataReader.listFiles(logPathIdentifier, 20, 50).size());
    Assert.assertEquals(2, fileMetadataReader.listFiles(logPathIdentifier, 100, 150).size());

    // should include the latest file with event start time 80.
    List<LogLocation> locationList = fileMetadataReader.listFiles(logPathIdentifier, 81, 85);
    Assert.assertEquals(1, locationList.size());
    Assert.assertEquals(80, locationList.get(0).getEventTimeMs());
    Assert.assertEquals(location.append(""82""), locationList.get(0).getLocation());

    Assert.assertEquals(1, fileMetadataReader.listFiles(logPathIdentifier, 150, 1000).size());
  }
",non-flaky,5
78286,apache_beam,TimerInternalsTest.testCompareByTimestamp,"  @Test
  public void testCompareByTimestamp() {
    Instant firstTimestamp = new Instant(100);
    Instant secondTimestamp = new Instant(200);
    StateNamespace namespace = StateNamespaces.global();

    TimerData firstTimer = TimerData.of(namespace, firstTimestamp, TimeDomain.EVENT_TIME);
    TimerData secondTimer = TimerData.of(namespace, secondTimestamp, TimeDomain.EVENT_TIME);

    assertThat(firstTimer, lessThan(secondTimer));
  }
",non-flaky,5
118688,netty_netty,SmtpCommandTest.getCommandFromCache,"    @Test
    public void getCommandFromCache() {
        assertSame(SmtpCommand.DATA, SmtpCommand.valueOf(""DATA""));
        assertSame(SmtpCommand.EHLO, SmtpCommand.valueOf(""EHLO""));
        assertNotSame(SmtpCommand.EHLO, SmtpCommand.valueOf(""ehlo""));
    }
",non-flaky,5
38694,apache_pulsar,ElasticSearchSinkTests.testStripNullNodes,"    @Test
    public void testStripNullNodes() throws Exception {
        map.put(""stripNulls"", true);
        sink.open(map, mockSinkContext);
        GenericRecord genericRecord = genericSchema.newRecordBuilder()
                .set(""name"", null)
                .set(""userName"", ""boby"")
                .set(""email"", null)
                .build();
        String json = sink.stringifyValue(valueSchema, genericRecord);
        assertEquals(json, ""{\""userName\"":\""boby\""}"");
    }
",non-flaky,5
42982,fabiomaffioletti_jsondoc,ApiObjectDocTest.testApiObjectDoc,"	@Test
	public void testApiObjectDoc() {
		Set<Class<?>> classes = new HashSet<Class<?>>();
		classes.add(TestObject.class);
		ApiObjectDoc childDoc = jsondocScanner.getApiObjectDocs(classes).iterator().next(); 
		Assert.assertEquals(""test-object"", childDoc.getName());
		Assert.assertEquals(14, childDoc.getFields().size());
		Assert.assertEquals(""1.0"", childDoc.getSupportedversions().getSince());
		Assert.assertEquals(""2.12"", childDoc.getSupportedversions().getUntil());
		Assert.assertEquals(ApiVisibility.PUBLIC, childDoc.getVisibility());
		Assert.assertEquals(ApiStage.PRE_ALPHA, childDoc.getStage());
		
		for (ApiObjectFieldDoc fieldDoc : childDoc.getFields()) {
			if(fieldDoc.getName().equals(""wildcardParametrized"")) {
				Assert.assertEquals(""list"", fieldDoc.getJsondocType().getType().get(0));
			}
			
			if(fieldDoc.getName().equals(""unparametrizedList"")) {
				Assert.assertEquals(""list"", fieldDoc.getJsondocType().getType().get(0));
			}
			
			if(fieldDoc.getName().equals(""parametrizedList"")) {
				Assert.assertEquals(""list of string"", fieldDoc.getJsondocType().getOneLineText());
			}
			
			if(fieldDoc.getName().equals(""name"")) {
				Assert.assertEquals(""string"", fieldDoc.getJsondocType().getType().get(0));
				Assert.assertEquals(""name"", fieldDoc.getName());
				Assert.assertEquals(""true"", fieldDoc.getRequired());
			}
			
			if(fieldDoc.getName().equals(""age"")) {
				Assert.assertEquals(""integer"", fieldDoc.getJsondocType().getType().get(0));
				Assert.assertEquals(""age"", fieldDoc.getName());
				Assert.assertEquals(""false"", fieldDoc.getRequired());
			}
			
			if(fieldDoc.getName().equals(""avg"")) {
				Assert.assertEquals(""long"", fieldDoc.getJsondocType().getType().get(0));
				Assert.assertEquals(""avg"", fieldDoc.getName());
				Assert.assertEquals(""false"", fieldDoc.getRequired());
			}
			
			if(fieldDoc.getName().equals(""map"")) {
				Assert.assertEquals(""map"", fieldDoc.getJsondocType().getType().get(0));
				Assert.assertEquals(""string"", fieldDoc.getJsondocType().getMapKey().getType().get(0));
				Assert.assertEquals(""integer"", fieldDoc.getJsondocType().getMapValue().getType().get(0));
			}
			
			if(fieldDoc.getName().equals(""LongArray"")) {
				Assert.assertEquals(""array of long"", fieldDoc.getJsondocType().getOneLineText());
				Assert.assertEquals(""LongArray"", fieldDoc.getName());
				Assert.assertEquals(""false"", fieldDoc.getRequired());
			}

			if(fieldDoc.getName().equals(""longArray"")) {
				Assert.assertEquals(""array of long"", fieldDoc.getJsondocType().getOneLineText());
				Assert.assertEquals(""longArray"", fieldDoc.getName());
				Assert.assertEquals(""false"", fieldDoc.getRequired());
			}
			
			if(fieldDoc.getName().equals(""fooBar"")) {
				Assert.assertEquals(""string"", fieldDoc.getJsondocType().getOneLineText());
				Assert.assertEquals(""foo_bar"", fieldDoc.getName());
				Assert.assertEquals(""false"", fieldDoc.getRequired());
			}
			
			if(fieldDoc.getName().equals(""version"")) {
				Assert.assertEquals(""string"", fieldDoc.getJsondocType().getOneLineText());
				Assert.assertEquals(""1.0"", fieldDoc.getSupportedversions().getSince());
				Assert.assertEquals(""2.12"", fieldDoc.getSupportedversions().getUntil());
			}
			
			if(fieldDoc.getName().equals(""test-enum"")) {
				Assert.assertEquals(""test-enum"", fieldDoc.getName());
				Assert.assertEquals(TestEnum.TESTENUM1.name(), fieldDoc.getAllowedvalues()[0]);
				Assert.assertEquals(TestEnum.TESTENUM2.name(), fieldDoc.getAllowedvalues()[1]);
				Assert.assertEquals(TestEnum.TESTENUM3.name(), fieldDoc.getAllowedvalues()[2]);
			}
			
			if(fieldDoc.getName().equals(""test-enum-with-allowed-values"")) {
				Assert.assertEquals(""A"", fieldDoc.getAllowedvalues()[0]);
				Assert.assertEquals(""B"", fieldDoc.getAllowedvalues()[1]);
				Assert.assertEquals(""C"", fieldDoc.getAllowedvalues()[2]);
			}

			if(fieldDoc.getName().equals(""orderedProperty"")) {
				Assert.assertEquals(""orderedProperty"", fieldDoc.getName());
				Assert.assertEquals(1, fieldDoc.getOrder().intValue());
			} else {
				Assert.assertEquals(Integer.MAX_VALUE, fieldDoc.getOrder().intValue());
			}

		}
	}
",non-flaky,5
33662,alibaba_fastjson,SerializeWriterTest.testWriteLargeSpecialStr,"    @Test
    public void testWriteLargeSpecialStr() throws UnsupportedEncodingException {

        String tmp = this.makeSpecialChars();
        StringBuilder builder = new StringBuilder();
        for (int i = 0; i < 200; i++) {
            builder.append(tmp);
        }
        this.doTestWrite(builder.toString());
    }
",non-flaky,5
98082,vert-x3_vertx-mongo-client,WriteConcernParserTest.testSimpleAndAdvancedWriteConcern,"  @Test
  public void testSimpleAndAdvancedWriteConcern() {
    WriteConcern expected = WriteConcern.JOURNALED;
    JsonObject config = new JsonObject();
    config.put(""w"", ""majority"");
    config.put(""wtimeoutMS"", 1);
    config.put(""j"", true);
    // this overwrites the other options
    config.put(""writeConcern"", ""journaled"");

    WriteConcern wc = new WriteConcernParser(null, config).writeConcern();
    assertNotNull(wc);
    assertEquals(expected, wc);
  }
",non-flaky,5
291,apache_hadoop,TestWrites.testCheckCommitAixCompatMode,"  @Test
  public void testCheckCommitAixCompatMode() throws IOException {
    DFSClient dfsClient = Mockito.mock(DFSClient.class);
    Nfs3FileAttributes attr = new Nfs3FileAttributes();
    HdfsDataOutputStream fos = Mockito.mock(HdfsDataOutputStream.class);

    NfsConfiguration conf = new NfsConfiguration();
    conf.setBoolean(NfsConfigKeys.LARGE_FILE_UPLOAD, false);
    // Enable AIX compatibility mode.
    OpenFileCtx ctx = new OpenFileCtx(fos, attr, ""/dumpFilePath"", dfsClient,
        new ShellBasedIdMapping(new NfsConfiguration()), true, conf);
    
    // Test fall-through to pendingWrites check in the event that commitOffset
    // is greater than the number of bytes we've so far flushed.
    Mockito.when(fos.getPos()).thenReturn((long) 2);
    COMMIT_STATUS status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_FINISHED);
    
    // Test the case when we actually have received more bytes than we're trying
    // to commit.
    ctx.getPendingWritesForTest().put(new OffsetRange(0, 10),
        new WriteCtx(null, 0, 0, 0, null, null, null, 0, false, null));
    Mockito.when(fos.getPos()).thenReturn((long) 10);
    ctx.setNextOffsetForTest((long)10);
    status = ctx.checkCommitInternal(5, null, 1, attr, false);
    Assert.assertTrue(status == COMMIT_STATUS.COMMIT_DO_SYNC);
  }
",non-flaky,5
150126,apache_hive,TestHplsqlOffline.testSelectTeradata,"  @Test
  public void testSelectTeradata() throws Exception {
    run(""select_teradata"");
  }
",non-flaky,5
159707,liquibase_liquibase,CDILiquibaseTest.shouldntRunWhenShouldRunIsFalse,"    @Test
    public void shouldntRunWhenShouldRunIsFalse() {
        System.setProperty(""liquibase.shouldRun"", ""false"");
        validateRunningState(false);
    }
",non-flaky,5
177211,line_armeria,Http2ClientWithPushPromiseTest.onSettingsRead,"    @Test
        public void onSettingsRead(ChannelHandlerContext ctx, Http2Settings settings) {
            assertThat(settings.pushEnabled()).isFalse();
        }
",non-flaky,5
104611,apache_pinot,SegmentPartitionLLCRealtimeClusterIntegrationTest.testPartitionMetadata,"  @Test
  public void testPartitionMetadata() {
    int[] numSegmentsForPartition = new int[2];
    String realtimeTableName = TableNameBuilder.REALTIME.tableNameWithType(getTableName());
    List<SegmentZKMetadata> segmentsZKMetadata = _helixResourceManager.getSegmentsZKMetadata(realtimeTableName);
    for (SegmentZKMetadata segmentZKMetadata : segmentsZKMetadata) {
      SegmentPartitionMetadata segmentPartitionMetadata = segmentZKMetadata.getPartitionMetadata();
      assertNotNull(segmentPartitionMetadata);
      Map<String, ColumnPartitionMetadata> columnPartitionMetadataMap =
          segmentPartitionMetadata.getColumnPartitionMap();
      assertEquals(columnPartitionMetadataMap.size(), 1);
      ColumnPartitionMetadata columnPartitionMetadata = columnPartitionMetadataMap.get(PARTITION_COLUMN);
      assertNotNull(columnPartitionMetadata);
      assertTrue(columnPartitionMetadata.getFunctionName().equalsIgnoreCase(""murmur""));
      assertEquals(columnPartitionMetadata.getNumPartitions(), 2);
      int partitionGroupId = new LLCSegmentName(segmentZKMetadata.getSegmentName()).getPartitionGroupId();
      assertEquals(columnPartitionMetadata.getPartitions(), Collections.singleton(partitionGroupId));
      numSegmentsForPartition[partitionGroupId]++;
    }

    // There should be 2 segments for partition 0, 2 segments for partition 1
    assertEquals(numSegmentsForPartition[0], 2);
    assertEquals(numSegmentsForPartition[1], 2);
  }
",non-flaky,5
20936,NationalSecurityAgency_timely,AuthCacheTest.testSessionIdNull,"    @Test(expected = IllegalArgumentException.class)
    public void testSessionIdNull() throws Exception {
        AuthCache.getAuthorizations("""");
    }
",non-flaky,5
110904,pushtorefresh_storio,ObserveChangesInTableTest.deleteEmission,"    @Test
    public void deleteEmission() {
        final List<User> users = putUsersBlocking(10);

        final Queue<Changes> expectedChanges = new LinkedList<Changes>();
        expectedChanges.add(Changes.newInstance(UserTableMeta.TABLE, UserTableMeta.NOTIFICATION_TAG));

        final EmissionChecker emissionChecker = new EmissionChecker(expectedChanges);
        final Subscription subscription = emissionChecker.subscribe();

        deleteUsersBlocking(users);

        // Should receive changes of Users table
        emissionChecker.awaitNextExpectedValue();

        emissionChecker.assertThatNoExpectedValuesLeft();

        subscription.unsubscribe();
    }
",non-flaky,5
98216,apache_jackrabbit,JsonWriterTest.answer,"    @Test
    public void testDoubleOutput() throws Exception {
        StringWriter writer = new StringWriter();
        JsonWriter jsonWriter = new JsonWriter(writer);

        Node parent = createMock(Node.class);
        Property doubleProperty = createMock(Property.class);
        Value doublePropertyValue = createMock(Value.class);
        expect(doubleProperty.getType()).andReturn(PropertyType.DOUBLE).anyTimes();
        expect(doubleProperty.getName()).andReturn(""singleValued"").anyTimes();
        expect(doubleProperty.isMultiple()).andReturn(false).anyTimes();
        expect(doubleProperty.getValue()).andReturn(doublePropertyValue).anyTimes();
        expect(doublePropertyValue.getType()).andReturn(PropertyType.DOUBLE).anyTimes();
        expect(doublePropertyValue.getDouble()).andReturn(5d).anyTimes();
        expect(doublePropertyValue.getString()).andReturn(""5"").anyTimes();

        Property mvDoubleProperty = createMock(Property.class);
        Value mvDoublePropertyValue1 = createMock(Value.class);
        Value mvDoublePropertyValue2 = createMock(Value.class);
        expect(mvDoubleProperty.getType()).andReturn(PropertyType.DOUBLE).anyTimes();
        expect(mvDoubleProperty.getName()).andReturn(""multiValued"").anyTimes();
        expect(mvDoubleProperty.isMultiple()).andReturn(true).anyTimes();
        expect(mvDoubleProperty.getValues()).andReturn(new Value[] { mvDoublePropertyValue1, mvDoublePropertyValue2}).anyTimes();
        expect(mvDoublePropertyValue1.getType()).andReturn(PropertyType.DOUBLE).anyTimes();
        expect(mvDoublePropertyValue1.getDouble()).andReturn(42d).anyTimes();
        expect(mvDoublePropertyValue1.getString()).andReturn(""42"").anyTimes();
        expect(mvDoublePropertyValue2.getType()).andReturn(PropertyType.DOUBLE).anyTimes();
        expect(mvDoublePropertyValue2.getDouble()).andReturn(98.6).anyTimes();
        expect(mvDoublePropertyValue2.getString()).andReturn(""98.6"").anyTimes();

        final List<Property> properties = new ArrayList<Property>();
        properties.add(doubleProperty);
        properties.add(mvDoubleProperty);
        expect(parent.getProperties()).andAnswer(new IAnswer<PropertyIterator>() {
            @Override
            public PropertyIterator answer() throws Throwable {
                return new PropertyIteratorAdapter(properties.iterator());
            }
",non-flaky,5
114093,aws_aws-sdk-java-v2,KeyTest.binaryKeys_convertsToCorrectAttributeValue,"    @Test
    public void binaryKeys_convertsToCorrectAttributeValue() {
        SdkBytes partition = SdkBytes.fromString(""one"", StandardCharsets.UTF_8);
        SdkBytes sort = SdkBytes.fromString(""two"", StandardCharsets.UTF_8);

        Key key = Key.builder().partitionValue(partition).sortValue(sort).build();

        assertThat(key.partitionKeyValue(), is(AttributeValue.builder().b(partition).build()));
        assertThat(key.sortKeyValue(), is(Optional.of(AttributeValue.builder().b(sort).build())));
    }
",non-flaky,5
59577,looly_hutool,CronTest.customCronTest,"	@Test
	public void customCronTest() {
		CronUtil.schedule(""*/2 * * * * *"", (Task) () -> Console.log(""Task excuted.""));

		// æ¯æç§çº§å«å®æ¶ä»»å¡
		CronUtil.setMatchSecond(true);
		CronUtil.start();

		ThreadUtil.waitForDie();
		Console.log(""Exit."");
	}
",non-flaky,5
114089,aws_aws-sdk-java-v2,KeyTest.getPartitionKeyValue_partitionOnly,"    @Test
    public void getPartitionKeyValue_partitionOnly() {
        assertThat(partitionOnlyKey.partitionKeyValue(),
                   is(AttributeValue.builder().s(""id123"").build()));
    }
",non-flaky,5
6,swankjesse_dex,test_parseLString,"@Test
public void test_parseLString() throws Exception {
    DateFormat format = DateFormat.getDateTimeInstance(DateFormat.FULL, DateFormat.FULL, Locale.US);
    try {
        Date date = format.parse(format.format(current).toString());
        assertEquals(current.getDate(), date.getDate());
        assertEquals(current.getDay(), date.getDay());
        assertEquals(current.getMonth(), date.getMonth());
        assertEquals(current.getYear(), date.getYear());
        assertEquals(current.getHours(), date.getHours());
        assertEquals(current.getMinutes(), date.getMinutes());
    } catch(ParseException pe) {
    fail(""ParseException was thrown for current Date.""); }
    try {
        format.parse(""January 16, 1970 8:03:52 PM CET"");
        fail(""ParseException was not thrown."");
    } catch(ParseException pe) { }
}",time,2
177994,aosp-mirror_platform_frameworks_support,GuidedStepFragmentTest.answer,"    @Test
    public void restoreFragments() throws Throwable {
        final String firstFragmentName = generateMethodTestName(""first"");
        final String secondFragmentName = generateMethodTestName(""second"");
        GuidedStepTestFragment.Provider first = mockProvider(firstFragmentName);
        doAnswer(new Answer<Void>() {
            public Void answer(InvocationOnMock invocation) {
                List actions = (List) invocation.getArguments()[0];
                actions.add(new GuidedAction.Builder().id(1000).title(""OK"").build());
                actions.add(new GuidedAction.Builder().id(1001).editable(true).title(""text"")
                        .build());
                actions.add(new GuidedAction.Builder().id(1002).editable(true).title(""text"")
                        .autoSaveRestoreEnabled(false).build());
                return null;
            }
",non-flaky,5
104137,spring-cloud_spring-cloud-config,ConfigClientPropertiesTests.testIfColonPresentAtTheEndInUriCreds,"	@Test
	public void testIfColonPresentAtTheEndInUriCreds() {
		this.locator.setUri(new String[] { ""http://foobar:@localhost:9999"" });
		this.locator.setPassword(""secret"");
		Credentials credentials = this.locator.getCredentials(0);
		assertThat(credentials.getUri()).isEqualTo(""http://localhost:9999"");
		assertThat(credentials.getUsername()).isEqualTo(""foobar"");
		assertThat(credentials.getPassword()).isEqualTo(""secret"");
	}
",non-flaky,5
114042,aws_aws-sdk-java-v2,PutItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNull() {
        Record record = new Record().setId(1).setId2(10);
        PutItemEnhancedRequest<Record> request = PutItemEnhancedRequest.builder(Record.class)
                                                                       .item(record)
                                                                       .build();

        PutItemEnhancedResponse<Record> response = mappedTable.putItemWithResponse(request);

        assertThat(response.itemCollectionMetrics()).isNull();
    }
",non-flaky,5
33907,apache_camel,DeleteProducerIntegrationIT.configure,"    @Test
            public void configure() {
                from(""direct:start"").to(""beanstalk:"" + tubeName + ""?command=delete"").to(""mock:result"");
            }
",non-flaky,5
176895,OryxProject_oryx,PairComparatorsTest.testByFirst,"  @Test
  public void testByFirst() {
    List<Pair<Integer,String>> pairs = Arrays.asList(
        new Pair<>(3, ""foo""),
        new Pair<>(4, ""bing""),
        new Pair<>(1, ""baz""),
        new Pair<>(2, ""whizz"")
    );
    Collections.sort(pairs, PairComparators.<Integer>byFirst());
    assertEquals(1, pairs.get(0).getFirst().intValue());
    assertEquals(2, pairs.get(1).getFirst().intValue());
    assertEquals(""baz"", pairs.get(0).getSecond());
    assertEquals(""whizz"", pairs.get(1).getSecond());
  }
",non-flaky,5
136554,doanduyhai_Achilles,EntityMetaCodeGenTest.should_fail_building_view_meta_with_counter_column,"    @Test
    public void should_fail_building_view_meta_with_counter_column() throws Exception {
        setExec(aptUtils -> {
            final String className = TestViewCounter.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final List<FieldParser.FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, context);
            builder.buildEntityMeta(EntityType.VIEW, typeElement, context, parsingResults, emptyList());

        });
        failTestWithMessage(
                ""The class 'info.archinnov.achilles.internals.sample_classes.parser.view.TestViewCounter' cannot have counter columns because it is a materialized view"",
                TestViewCounter.class);
    }
",non-flaky,5
122543,vespa-engine_vespa,SystemCtlTest.start,"    @Test
    public void start() {
        terminal.expectCommand(
                        ""systemctl show docker 2>&1"",
                        0,
                        ""a=b\n"" +
                                ""ActiveState=failed\n"" +
                                ""bar=zoo\n"")
                .expectCommand(""systemctl start docker 2>&1"", 0, """");

        SystemCtl.SystemCtlStart startDockerService = new SystemCtl(terminal).start(""docker"");
        assertTrue(startDockerService.converge(taskContext));
    }
",non-flaky,5
177982,aosp-mirror_platform_frameworks_support,BidiFormatterTest.testIsRtl,"    @Test
    public void testIsRtl() {
        assertEquals(true, BidiFormatter.getInstance(true).isRtl(HE));
        assertEquals(true, BidiFormatter.getInstance(false).isRtl(HE));

        assertEquals(false, BidiFormatter.getInstance(true).isRtl(EN));
        assertEquals(false, BidiFormatter.getInstance(false).isRtl(EN));
    }
",non-flaky,5
92638,apache_dubbo,ApplicationConfigTest.testQosEnable,"    @Test
    public void testQosEnable() throws Exception {
        ApplicationConfig application = new ApplicationConfig(""app"");
        application.setQosEnable(true);
        assertThat(application.getQosEnable(), is(true));
        Map<String, String> parameters = new HashMap<String, String>();
        ApplicationConfig.appendParameters(parameters, application);
        assertThat(parameters, hasEntry(Constants.QOS_ENABLE, ""true""));
    }
",non-flaky,5
122545,vespa-engine_vespa,SystemCtlTest.startCommandFailre,"    @Test
    public void startCommandFailre() {
        terminal.expectCommand(""systemctl show docker 2>&1"", 1, ""error"");
        SystemCtl.SystemCtlStart startDockerService = new SystemCtl(terminal).start(""docker"");
        try {
            startDockerService.converge(taskContext);
            fail();
        } catch (ChildProcessFailureException e) {
            // success
        }
    }
",non-flaky,5
76751,quarkusio_quarkus,CreateProjectMojoIT.testProjectGenerationAsModuleWithExistingPomFileWithPackagingPom,"    @Test
    public void testProjectGenerationAsModuleWithExistingPomFileWithPackagingPom() throws Exception {
        testDir = initProject(""projects/parent-pom-it"", ""projects/project-generation-from-parent-pom"");
        assertThat(testDir).isDirectory();
        invoker = initInvoker(testDir);

        String projectArtifactId = ""acme"";
        Properties properties = new Properties();
        properties.put(""projectGroupId"", ""io.acme.it"");
        properties.put(""projectArtifactId"", projectArtifactId);
        properties.put(""projectVersion"", ""1.0-SNAPSHOT"");
        InvocationResult result = setup(properties);

        assertThat(result.getExitCode()).isZero();

        Model parentPomModel = loadPom(testDir);
        assertThat(parentPomModel.getModules()).isNotEmpty();
        assertThat(parentPomModel.getModules()).contains(projectArtifactId);

        Model modulePomModel = loadPom(new File(testDir, projectArtifactId));
        assertThat(modulePomModel.getParent()).isNotNull();
        assertThat(modulePomModel.getParent().getGroupId()).isEqualTo(""io.acme.it"");
        assertThat(modulePomModel.getParent().getArtifactId()).isEqualTo(""acme-parent-pom"");
        assertThat(modulePomModel.getParent().getVersion()).isEqualTo(""0.0.1.BUILD-SNAPSHOT"");
    }
",non-flaky,5
96020,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher3,"  @Test
  public void testTokenSequenceMatcher3() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test sequence with groups
    TokenSequencePattern p = TokenSequencePattern.compile(
        new SequencePattern.SequencePatternExpr(
            new SequencePattern.GroupPatternExpr(
                new SequencePattern.RepeatPatternExpr(
                    getSequencePatternExpr(""[A-Za-z]+""), 1, 2)),
            getNodePatternExpr(""of""),
            new SequencePattern.GroupPatternExpr(
                new SequencePattern.RepeatPatternExpr(
                    getSequencePatternExpr(""[A-Za-z]+""), 1, 3))));

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""third Archbishop of Canterbury"", m.group());
    assertEquals(""third Archbishop"", m.group(1));
    assertEquals(""Canterbury"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""a member of the Gregorian mission"", m.group());
    assertEquals(""a member"", m.group(1));
    assertEquals(""the Gregorian mission"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""as Bishop of London in"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London in"", m.group(2));
    match = m.find();
    assertFalse(match);

    p = TokenSequencePattern.compile(
        new SequencePattern.SequencePatternExpr(
            new SequencePattern.GroupPatternExpr(
                new SequencePattern.RepeatPatternExpr(
                    getNodePatternExpr(""[A-Za-z]+""), 2, 2)),
            getNodePatternExpr(""of""),
            new SequencePattern.GroupPatternExpr(
                new SequencePattern.RepeatPatternExpr(
                    getNodePatternExpr(""[A-Za-z]+""), 1, 3, false))));

    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""first Bishop of London"", m.group());
    assertEquals(""first Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""third Archbishop of Canterbury"", m.group());
    assertEquals(""third Archbishop"", m.group(1));
    assertEquals(""Canterbury"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""a member of the"", m.group());
    assertEquals(""a member"", m.group(1));
    assertEquals(""the"", m.group(2));
    match = m.find();
    assertTrue(match);
    assertEquals(2, m.groupCount());
    assertEquals(""as Bishop of London"", m.group());
    assertEquals(""as Bishop"", m.group(1));
    assertEquals(""London"", m.group(2));
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
84632,apache_zookeeper,ZKClientConfigTest.testIntegerRetrievalFromProperty,"    @Test
    public void testIntegerRetrievalFromProperty() {
        ZKClientConfig conf = new ZKClientConfig();
        String prop = ""UnSetProperty"" + System.currentTimeMillis();
        int defaultValue = 100;
        // property is not set we should get the default value
        int result = conf.getInt(prop, defaultValue);
        assertEquals(defaultValue, result);

        // property is set but can not be parsed to int, we should get the
        // NumberFormatException
        conf.setProperty(ZKConfig.JUTE_MAXBUFFER, ""InvlaidIntValue123"");
        try {
            result = conf.getInt(ZKConfig.JUTE_MAXBUFFER, defaultValue);
            fail(""NumberFormatException is expected"");
        } catch (NumberFormatException exception) {
            // do nothing
        }
        assertEquals(defaultValue, result);

        // property is set to an valid int, we should get the set value
        int value = ZKClientConfig.CLIENT_MAX_PACKET_LENGTH_DEFAULT;
        conf.setProperty(ZKConfig.JUTE_MAXBUFFER, Integer.toString(value));
        result = conf.getInt(ZKConfig.JUTE_MAXBUFFER, defaultValue);
        assertEquals(value, result);

        // property is set but with white spaces
        value = 12345;
        conf.setProperty(ZKConfig.JUTE_MAXBUFFER, "" "" + value + "" "");
        result = conf.getInt(ZKConfig.JUTE_MAXBUFFER, defaultValue);
        assertEquals(value, result);
    }
",non-flaky,5
5,apache_hadoop,TestPathData.testToFile,"@Test
public void testToFile() throws Exception {
    item = new PathData(""."", conf);
    assertEquals(new File(testDir.toString()), item.toFile());
    item = new PathData(""d1/f1"", conf);
    assertEquals(new File(testDir + ""/d1/f1""), item.toFile());
    item = new PathData(testDir + ""/d1/f1"", conf);
    assertEquals(new File(testDir + ""/d1/f1""), item.toFile());
}",test order dependency,4
160426,ConsenSys_teku,ValidatorDataProviderTest.submitSignedBlock_shouldReturn202ForInvalidBlock,"  @TestTemplate
  public void submitSignedBlock_shouldReturn202ForInvalidBlock() {
    final SignedBeaconBlock internalSignedBeaconBlock =
        dataStructureUtil.randomSignedBeaconBlock(1);
    final tech.pegasys.teku.api.schema.SignedBeaconBlock signedBeaconBlock =
        tech.pegasys.teku.api.schema.SignedBeaconBlock.create(internalSignedBeaconBlock);
    final AtomicInteger failReasonCount = new AtomicInteger();

    Stream.of(FailureReason.values())
        .filter(failureReason -> !failureReason.equals(FailureReason.INTERNAL_ERROR))
        .forEach(
            failureReason -> {
              failReasonCount.getAndIncrement();

              final SafeFuture<SendSignedBlockResult> failImportResult =
                  completedFuture(SendSignedBlockResult.notImported(failureReason.name()));

              when(validatorApiChannel.sendSignedBlock(any())).thenReturn(failImportResult);

              final SafeFuture<ValidatorBlockResult> validatorBlockResultSafeFuture =
                  provider.submitSignedBlock(signedBeaconBlock);

              try {
                assertThat(validatorBlockResultSafeFuture.get().getResponseCode()).isEqualTo(202);
              } catch (final Exception e) {
                fail(""Exception while executing test."");
              }
            });

    // Assert that the check has run over each FailureReason except the 500.
    assertThat(failReasonCount.get()).isEqualTo(FailureReason.values().length - 1);
  }
",non-flaky,5
176883,OryxProject_oryx,ConfigUtilsTest.testDefaultConfig,"  @Test
  public void testDefaultConfig() {
    Config config = ConfigUtils.getDefault();
    assertEquals(""yarn-client"", config.getString(""oryx.batch.streaming.master""));
  }
",non-flaky,5
119,vert-x3_vertx-mongo-client,MongoClientTest.testWatch,"@Test
public void testWatch() throws Exception {
    final JsonArray operationTypes = new JsonArray(Arrays.asList(""insert"", ""update"", ""replace"", ""delete""));
    final JsonObject match = new JsonObject().put(""operationType"", new JsonObject().put(""$in"", operationTypes));
    final JsonArray pipeline = new JsonArray().add(new JsonObject().put(""$match"", match));
    final JsonObject fields = new JsonObject().put(""operationType"", true).put(""namespaceDocument"", true).put(""destinationNamespaceDocument"", true).put(""documentKey"", true).put(""updateDescription"", true).put(""fullDocument"", true);
    pipeline.add(new JsonObject().put(""$project"", fields));
    final String collection = randomCollection();
    final JsonObject doc = createDoc();
    final CountDownLatch latch = new CountDownLatch(4);
    final AtomicReference<ReadStream<ChangeStreamDocument<JsonObject>>> streamReference = new AtomicReference<>();
    mongoClient.createCollection(collection, onSuccess(( res) -> {
        ReadStream<ChangeStreamDocument<JsonObject>> stream = mongoClient.watch(collection, pipeline, true, 1).handler(( changeStreamDocument) -> {
            OperationType operationType = changeStreamDocument.getOperationType();
            assertNotNull(operationType);
            JsonObject fullDocument = changeStreamDocument.getFullDocument();
            switch (operationType.getValue()) {
                case ""insert"" :
                assertNotNull(fullDocument);
                assertNotNull(fullDocument.getString(MongoClientUpdateResult.ID_FIELD));
                assertEquals(""bar"", fullDocument.getString(""foo""));
                break;
                case ""update"" :
                assertNotNull(fullDocument);
                assertEquals(""updatedValue"", fullDocument.getString(""fieldToUpdate""));
                break;
                case ""replace"" :
                assertNotNull(fullDocument);
                assertEquals(""replacedValue"", fullDocument.getString(""fieldToReplace""));
                break;
                case ""delete"" :
                assertNull(fullDocument);
                break;
                default :
            }
            latch.countDown();
            if (latch.getCount() == 1) {
                mongoClient.removeDocuments(collection, new JsonObject());
            }
        }).endHandler(( v) -> assertEquals(0, latch.getCount())).exceptionHandler(this::fail).fetch(1);
        streamReference.set(stream);
        vertx.setTimer(50, ( v) -> {
            mongoClient.insert(collection, doc).compose(( idString) -> {
                doc.put(MongoClientUpdateResult.ID_FIELD, idString);
                doc.put(""fieldToUpdate"", ""updatedValue"");
                final JsonObject query = new JsonObject().put(MongoClientUpdateResult.ID_FIELD, idString);
                final JsonObject updateField = new JsonObject().put(""fieldToUpdate"", ""updatedValue"");
                return CompositeFuture.all(mongoClient.updateCollection(collection, query, new JsonObject().put(""$set"", updateField)), mongoClient.save(collection, doc.put(""fieldToReplace"", ""replacedValue"")));
            });
        });
    }));
    awaitLatch(latch);
    streamReference.get().handler(null);
}",time,2
134990,undertow-io_undertow,AnnotatedEndpointTest.testWebSocketInRootContext,"    @Test
    public void testWebSocketInRootContext() throws Exception {
        final byte[] payload = ""hello"".getBytes();
        final FutureResult latch = new FutureResult();

        WebSocketTestClient client = new WebSocketTestClient(WebSocketVersion.V13, new URI(""ws://"" + DefaultServer.getHostAddress(""default"") + "":"" + DefaultServer.getHostPort(""default"") + ""/ws""));
        client.connect();
        client.send(new TextWebSocketFrame(Unpooled.wrappedBuffer(payload)), new FrameChecker(TextWebSocketFrame.class, ""hello"".getBytes(), latch));
        latch.getIoFuture().get();
        client.destroy();
    }
",non-flaky,5
150150,apache_hive,TestHplsqlLocal.testCreateProcedure4,"  @Test
  public void testCreateProcedure4() throws Exception {
    run(""create_procedure4"");
  }
",non-flaky,5
122623,vespa-engine_vespa,IPAddressesTest.throws_when_multiple_private_ipv4_addresses,"    @Test(expected = RuntimeException.class)
    public void throws_when_multiple_private_ipv4_addresses() {
        mock.addAddress(""localhost"", ""38.3.4.2"")
                .addAddress(""localhost"", ""10.0.2.2"")
                .addAddress(""localhost"", ""10.0.2.3"");
        mock.getIPv4Address(""localhost"");
    }
",non-flaky,5
88777,apache_ignite,IgniteDataFrameSelfTest.testDataFrameWriteExample,"    @Test
    public void testDataFrameWriteExample() throws Exception {
        IgniteDataFrameWriteExample.main(EMPTY_ARGS);
    }
",non-flaky,5
112641,tbsalling_aismessages,BinaryBroadcastMessageTest.canDecodeUnknownApplicationSpecificMessage,"    @Test
    public void canDecodeUnknownApplicationSpecificMessage() {
        AISMessage aisMessage = AISMessage.create(NMEAMessage.fromString(""!AIVDM,1,1,,A,8@30oni?1j020@00,0*23""));

        System.out.println(aisMessage.toString());

        assertEquals(316, ((BinaryBroadcastMessage) aisMessage).getDesignatedAreaCode().intValue());
        assertEquals(7, ((BinaryBroadcastMessage) aisMessage).getFunctionalId().intValue());
        assertEquals(UnknownApplicationSpecificMessage.class, ((BinaryBroadcastMessage) aisMessage).getApplicationSpecificMessage().getClass());
    }
",non-flaky,5
114075,aws_aws-sdk-java-v2,EnhancedTypeTest.documentOf_withEnhancedTypeConfiguration,"    @Test
    public void documentOf_withEnhancedTypeConfiguration() {
        TableSchema<String> tableSchema = StaticTableSchema.builder(String.class).build();
        EnhancedType<String> type = EnhancedType.documentOf(String.class, tableSchema, b -> b.preserveEmptyObject(true));
        assertThat(type.documentConfiguration()).isPresent();
        assertThat(type.documentConfiguration().get().preserveEmptyObject()).isTrue();
    }
",non-flaky,5
76710,quarkusio_quarkus,RegisterForReflectionITCase.testSelfWithNested,"    @Test
    public void testSelfWithNested() {
        final String resourceB = BASE_PKG + "".ResourceB"";

        assertRegistration(""ResourceB"", resourceB);
        assertRegistration(""InnerClassOfB"", resourceB + ""$InnerClassOfB"");
        assertRegistration(""StaticClassOfB"", resourceB + ""$StaticClassOfB"");
        assertRegistration(""InterfaceOfB"", resourceB + ""$InterfaceOfB"");
        assertRegistration(""InnerInnerOfB"", resourceB + ""$InnerClassOfB$InnerInnerOfB"");
    }
",non-flaky,5
305,apache_ignite,IgnitePdsThreadInterruptionTest.testInterruptsOnLFSRead,"@Test
public void testInterruptsOnLFSRead() throws Exception {
    final Ignite ignite = startGrid();
    ignite.active(true);
    final int valLen = 8192;
    final byte[] payload = new byte[valLen];
    final int maxKey = 10000;
    Thread[] workers = new Thread[THREADS_CNT];
    final IgniteCache<Object, Object> cache = ignite.cache(CACHE_NAME);
    for (int i = 0; i < maxKey; i++) {
        cache.put(i, payload);
    }
    final AtomicReference<Throwable> fail = new AtomicReference<>();
    Runnable clo = new Runnable() {
        @Override
        public void run() {
            cache.get(ThreadLocalRandom.current().nextInt(maxKey / 5));
        }
    };
    for (int i = 0; i < workers.length; i++) {
        workers[i] = new Thread(clo);
        workers[i].setName(""reader-"" + i);
        workers[i].setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() {
            @Override
            public void uncaughtException(Thread t, Throwable e) {
                fail.compareAndSet(null, e);
            }
        });
    }
    for (Thread worker : workers) {
        worker.start();
    }
    for (int i = 0; i < (workers.length / 2); i++) {
        workers[i].interrupt();
    }
    Thread.sleep(3000);
    stop = true;
    for (Thread worker : workers) {
        worker.join();
    }
    Throwable t = fail.get();
    assertNull(t);
    int verifiedKeys = 0;
    for (int i = 0; i < maxKey; i++) {
        byte[] val = ((byte[]) (cache.get(i)));
        if (val != null) {
            assertEquals(""Illegal length"", valLen, val.length);
            verifiedKeys++;
        }
    }
}",concurrency,1
150173,apache_hive,TestHplsqlLocal.testInterval,"  @Test
  public void testInterval() throws Exception {
    run(""interval"");
  }
",non-flaky,5
38669,apache_pulsar,InfluxDBGenericRecordSinkTest.openInvalidInfluxConfig,"    @Test(expectedExceptions = Exception.class,
    public void openInvalidInfluxConfig() throws Exception {
        InfluxDBGenericRecordSink sink = new InfluxDBGenericRecordSink();
        sink.open(new HashMap<>(), mock(SinkContext.class));
    }
",non-flaky,5
59644,looly_hutool,ThymeleafTest.thymeleafEngineTest2,"	@Test
	public void thymeleafEngineTest2() {
		Map<String, Object> map1 = new HashMap<>();
		map1.put(""name"", ""a"");

		Map<String, Object> map2 = new HashMap<>();
		map2.put(""name"", ""b"");

		// æ¥ææµè¯
		Map<String, Object> map3 = new HashMap<>();
		map3.put(""name"", DateUtil.parse(""2019-01-01""));

		List<Map<String, Object>> list = new ArrayList<>();
		list.add(map1);
		list.add(map2);
		list.add(map3);

		LinkedHashMap<String, Object> map = new LinkedHashMap<>();
		map.put(""list"", list);

		 hutoolApi(map);
		thymeleaf(map);
	}
",non-flaky,5
135041,undertow-io_undertow,NetworkUtilsAddressParsingTestCase.testIpV4AddressToLarge,"    @Test(expected = IOException.class)
    public void testIpV4AddressToLarge() throws IOException {
        NetworkUtils.parseIpv4Address(""01.123.255.1.1"");
    }
",non-flaky,5
43019,fabiomaffioletti_jsondoc,SpringResponseBuilderTest.testApiVerb,"	@Test
	public void testApiVerb() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController.class), MethodDisplay.URI).iterator().next();
		Assert.assertEquals(""SpringController"", apiDoc.getName());
		Assert.assertEquals(3, apiDoc.getMethods().size());
		for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) {
			if (apiMethodDoc.getPath().contains(""/response-one"")) {
				Assert.assertEquals(""string"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
			}
			if (apiMethodDoc.getPath().contains(""/response-two"")) {
				Assert.assertEquals(""string"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
			}
			if (apiMethodDoc.getPath().contains(""/response-three"")) {
				Assert.assertEquals(""map[string, integer]"", apiMethodDoc.getResponse().getJsondocType().getOneLineText());
			}
		}
	}
",non-flaky,5
33844,apache_camel,FhirTransactionIT.testWithBundle,"    @Test
    public void testWithBundle() throws Exception {
        // using org.hl7.fhir.instance.model.api.IBaseBundle message body for single parameter ""bundle""
        Bundle result = requestBody(""direct://WITH_BUNDLE"", createTransactionBundle());

        assertNotNull(result, ""withBundle result"");
        assertTrue(result.getEntry().get(0).getResponse().getStatus().contains(""Created""));
        LOG.debug(""withBundle: "" + result);
    }
",non-flaky,5
113906,spring-projects_spring-data-couchbase,CouchbaseTemplateQueryCollectionIntegrationTests.findByQuery,"	@Test
	public void findByQuery() { // 4
		QueryOptions options = QueryOptions.queryOptions().timeout(Duration.ofSeconds(10));
		Airport saved = couchbaseTemplate.insertById(Airport.class).inScope(scopeName).inCollection(collectionName)
				.one(vie);
		try {
			List<Airport> found = couchbaseTemplate.findByQuery(Airport.class)
					.withConsistency(QueryScanConsistency.REQUEST_PLUS).inScope(scopeName).inCollection(collectionName)
					.withOptions(options).all();
			assertEquals(saved.getId(), found.get(0).getId());
		} finally {
			couchbaseTemplate.removeById().inScope(scopeName).inCollection(collectionName).one(saved.getId());
		}
	}
",non-flaky,5
78266,apache_beam,SplittableParDoProcessFnTest.testInvokesLifecycleMethods,"  @Test
  public void testInvokesLifecycleMethods() throws Exception {
    DoFn<Integer, String> fn = new LifecycleVerifyingFn();
    try (ProcessFnTester<Integer, String, SomeRestriction, Void, SomeRestrictionTracker> tester =
        new ProcessFnTester<>(
            Instant.now(),
            fn,
            BigEndianIntegerCoder.of(),
            SerializableCoder.of(SomeRestriction.class),
            MAX_OUTPUTS_PER_BUNDLE,
            MAX_BUNDLE_DURATION)) {
      tester.startElement(42, new SomeRestriction());
    }
  }
",non-flaky,5
160425,ConsenSys_teku,ValidatorDataProviderTest.submitSignedBlock_shouldReturn200ForSuccess,"  @TestTemplate
  public void submitSignedBlock_shouldReturn200ForSuccess()
      throws ExecutionException, InterruptedException {
    final SignedBeaconBlock internalSignedBeaconBlock =
        dataStructureUtil.randomSignedBeaconBlock(1);
    final tech.pegasys.teku.api.schema.SignedBeaconBlock signedBeaconBlock =
        tech.pegasys.teku.api.schema.SignedBeaconBlock.create(internalSignedBeaconBlock);

    final SafeFuture<SendSignedBlockResult> successImportResult =
        completedFuture(SendSignedBlockResult.success(internalSignedBeaconBlock.getRoot()));

    when(validatorApiChannel.sendSignedBlock(any())).thenReturn(successImportResult);

    final SafeFuture<ValidatorBlockResult> validatorBlockResultSafeFuture =
        provider.submitSignedBlock(signedBeaconBlock);

    assertThat(validatorBlockResultSafeFuture.get().getResponseCode()).isEqualTo(200);
  }
",non-flaky,5
30,apache_pulsar,ZKSessionTest.testReacquireLocksAfterSessionLost,"@Test
public void testReacquireLocksAfterSessionLost() throws Exception {
    @Cleanup
    MetadataStoreExtended store = MetadataStoreExtended.create(zks.getConnectionString(), MetadataStoreConfig.builder().sessionTimeoutMillis(2000).build());
    BlockingQueue<SessionEvent> sessionEvents = new LinkedBlockingQueue<>();
    store.registerSessionListener(sessionEvents::add);
    @Cleanup
    CoordinationService coordinationService = new CoordinationServiceImpl(store);
    @Cleanup
    LockManager<String> lm1 = coordinationService.getLockManager(String.class);
    String path = newKey();
    ResourceLock<String> lock = lm1.acquireLock(path, ""value-1"").join();
    zks.expireSession(((ZKMetadataStore) (store)).getZkSessionId());
    SessionEvent e = sessionEvents.poll(5, TimeUnit.SECONDS);
    assertEquals(e, ConnectionLost);
    e = sessionEvents.poll(10, TimeUnit.SECONDS);
    assertEquals(e, SessionLost);
    e = sessionEvents.poll(10, TimeUnit.SECONDS);
    assertEquals(e, Reconnected);
    e = sessionEvents.poll(10, TimeUnit.SECONDS);
    assertEquals(e, SessionReestablished);
    Awaitility.await().untilAsserted(() -> {
        assertFalse(lock.getLockExpiredFuture().isDone());
    });
    assertTrue(store.get(path).join().isPresent());
}",async wait,0
122587,vespa-engine_vespa,FileFinderTest.all_files_recursive_with_prune_relative,"        @Test
        public void all_files_recursive_with_prune_relative() {
            assertFileHelper(FileFinder.files(testRoot()).prune(fileSystem.getPath(""test"")),

                    of(""file-1.json"", ""test.json"", ""test.txt""),
                    of(""test"", ""test/file.txt"", ""test/data.json"", ""test/subdir-1"", ""test/subdir-1/test"", ""test/subdir-2""));
        }
",non-flaky,5
104617,apache_pinot,ChaosMonkeyIntegrationTest.testShortZookeeperFreeze,"  @Test(enabled = false)
  public void testShortZookeeperFreeze()
      throws Exception {
    testFreezeZookeeper(10000L);
  }
",non-flaky,5
91404,OpenLCB_OpenLCB_Java,DefaultPropertyListenerSupportTest.testCTor,"    @Test
    public void testCTor() {
        Assume.assumeFalse(GraphicsEnvironment.isHeadless());
        DefaultPropertyListenerSupport t = new DefaultPropertyListenerSupport();
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
26236,Ericsson_ecchronos,TestTableRepairJob.testPrevalidateUpdateThrowsOverloadException,"    @Test
    public void testPrevalidateUpdateThrowsOverloadException()
    {
        // mock
        doReturn(false).when(myRepairStateSnapshot).canRepair();
        doThrow(new OverloadedException(null, ""Expected exception"")).when(myRepairState).update();

        assertThat(myRepairJob.runnable()).isFalse();

        verify(myRepairStateSnapshot, times(1)).canRepair();
    }
",non-flaky,5
77453,opensearch-project_OpenSearch,LooksLikeATestWithoutNamingConvention1.annotatedTestMethod,"    @Test
    public void annotatedTestMethod() {

    }
",non-flaky,5
282,apache_hadoop,TestOffsetRange.testConstructor2,"  @Test(expected = IllegalArgumentException.class)
  public void testConstructor2() throws IOException {
    new OffsetRange(-1, 0);
  }
",non-flaky,5
78300,apache_beam,OutputAndTimeBoundedSplittableProcessElementInvokerTest.testInvokeProcessElementTimeBoundedWithStartupDelay,"  @Test
  public void testInvokeProcessElementTimeBoundedWithStartupDelay() throws Exception {
    SplittableProcessElementInvoker<Void, String, OffsetRange, OffsetRangeTracker>.Result res =
        runTest(10000, Duration.standardSeconds(3), Integer.MAX_VALUE, Duration.millis(100));
    assertFalse(res.getContinuation().shouldResume());
    OffsetRange residualRange = res.getResidualRestriction();
    // Same as above, but this time it counts from the time of the first tryClaim() call
    assertThat(residualRange.getFrom(), greaterThan(10L));
    assertThat(residualRange.getFrom(), lessThan(100L));
    assertEquals(10000, residualRange.getTo());
  }
",non-flaky,5
329,apache_hadoop,TestViewfsWithNfs3.testNfsAccessNN2,"  @Test (timeout = 60000)
  public void testNfsAccessNN2() throws Exception {
    HdfsFileStatus status = nn2.getRpcServer().getFileInfo(""/user2/dir2"");
    int namenodeId = Nfs3Utils.getNamenodeId(config, hdfs2.getUri());
    testNfsGetAttrResponse(status.getFileId(), namenodeId, Nfs3Status.NFS3_OK);
  }
",non-flaky,5
26245,Ericsson_ecchronos,TestTableRepairJob.testIteratorWithTargetSize,"    @Test
    public void testIteratorWithTargetSize()
    {
        List<LongTokenRange> expectedTokenRanges = Arrays.asList(
                new LongTokenRange(0, 1),
                new LongTokenRange(1, 2),
                new LongTokenRange(2, 3),
                new LongTokenRange(3, 4),
                new LongTokenRange(4, 5),
                new LongTokenRange(5, 6),
                new LongTokenRange(6, 7),
                new LongTokenRange(7, 8),
                new LongTokenRange(8, 9),
                new LongTokenRange(9, 10)
        );

        LongTokenRange tokenRange = new LongTokenRange(0, 10);
        ImmutableSet<Node> replicas = ImmutableSet.of(mock(Node.class), mock(Node.class));
        ImmutableList<LongTokenRange> vnodes = ImmutableList.of(tokenRange);

        VnodeRepairStates vnodeRepairStates = VnodeRepairStatesImpl.newBuilder(ImmutableList.of(new VnodeRepairState(tokenRange, replicas, 1234L))).build();
        ReplicaRepairGroup replicaRepairGroup = new ReplicaRepairGroup(replicas, vnodes);

        RepairStateSnapshot repairStateSnapshot = RepairStateSnapshot.newBuilder()
                .withReplicaRepairGroups(Collections.singletonList(replicaRepairGroup))
                .withLastCompletedAt(1234L)
                .withVnodeRepairStates(vnodeRepairStates)
                .build();
        when(myRepairState.getSnapshot()).thenReturn(repairStateSnapshot);
        // 100 MB target size, 1000MB in table
        when(myTableStorageStates.getDataSize(eq(myTableReference))).thenReturn(THOUSAND_MB_IN_BYTES);

        Iterator<ScheduledTask> iterator = myRepairJob.iterator();

        ScheduledTask task = iterator.next();
        assertThat(task).isInstanceOf(RepairGroup.class);
        Collection<RepairTask> repairTasks = ((RepairGroup)task).getRepairTasks();

        assertThat(repairTasks).hasSize(expectedTokenRanges.size());

        Iterator<RepairTask> repairTaskIterator = repairTasks.iterator();
        for (LongTokenRange expectedRange : expectedTokenRanges)
        {
            assertThat(repairTaskIterator.hasNext()).isTrue();
            RepairTask repairTask = repairTaskIterator.next();
            assertThat(repairTask.getReplicas()).containsExactlyInAnyOrderElementsOf(replicas);
            assertThat(repairTask.getRepairConfiguration()).isEqualTo(myRepairConfiguration);
            assertThat(repairTask.getTableReference()).isEqualTo(myTableReference);

            assertThat(repairTask.getTokenRanges()).containsExactly(expectedRange);
        }
    }
",non-flaky,5
162413,testcontainers_testcontainers-java,DockerNetworkModeTest.testNoNetworkContainer,"    @Test
    public void testNoNetworkContainer() throws TimeoutException {
        String output = getContainerOutput(noNetwork);

        assertTrue(""'none' network causes a network access error"", output.contains(""bad address""));
    }
",non-flaky,5
26770,MundaneImmortal_pair-distribution-app,DayPairsTest.testToString,"	@Test
	public void testToString() {
		DayPairs pairs = new DayPairs();
		Pair pair = new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")));
		pairs.addPair(""track"", pair);
		
		assertThat(pairs.toString(), is(equalTo(""Pairs [pairs="" + pairs.getPairs() + "", date="" + pairs.format(pairs.getDate()) + ""]"")));
	}
",non-flaky,5
162724,OpenAPITools_openapi-generator,XmlItemTest.namespaceIntegerTest,"    @Test
    public void namespaceIntegerTest() {
        // TODO: test namespaceInteger
    }
",non-flaky,5
118768,netty_netty,ByteBufUtilTest.testToStringDoesNotThrowIndexOutOfBounds,"    @Test
    public void testToStringDoesNotThrowIndexOutOfBounds() {
        CompositeByteBuf buffer = Unpooled.compositeBuffer();
        try {
            byte[] bytes = ""1234"".getBytes(CharsetUtil.UTF_8);
            buffer.addComponent(Unpooled.buffer(bytes.length).writeBytes(bytes));
            buffer.addComponent(Unpooled.buffer(bytes.length).writeBytes(bytes));
            assertEquals(""1234"", buffer.toString(bytes.length, bytes.length, CharsetUtil.UTF_8));
        } finally {
            buffer.release();
        }
    }
",non-flaky,5
364,apache_hadoop,TestPermissionSymlinks.testFileStatus,"  @Test(timeout = 5000)
  public void testFileStatus() throws Exception {
    fs.setPermission(target, new FsPermission((short) 0000));
    doGetFileLinkStatusTargetNotReadable();
  }
",non-flaky,5
59615,looly_hutool,SpringUtilTest.getBeanWithTypeReferenceTest,"	@Test
	public void getBeanWithTypeReferenceTest() {
		Map<String, Object> mapBean = SpringUtil.getBean(new TypeReference<Map<String, Object>>() {});
		Assert.assertNotNull(mapBean);
		Assert.assertEquals(""value1"", mapBean.get(""key1""));
		Assert.assertEquals(""value2"", mapBean.get(""key2""));
	}
",non-flaky,5
114032,apache_struts,FileDownloadActionTest.testSanitizeInputPathShouldReturnNullForNonLeadingWebInf,"	@Test
	public void testSanitizeInputPathShouldReturnNullForNonLeadingWebInf() throws Exception {
		assertNull(fileDownloadAction.sanitizeInputPath(""./WEB-INF/foo""));
	}
",non-flaky,5
96885,apache_avro,TestSchemas.testCloningError2,"  @Test(expected = IllegalStateException.class)
  public void testCloningError2() {
    // After visit Non-terminal with int
    Schema recordSchema = new Schema.Parser().parse(
        ""{\""type\"": \""record\"", \""name\"": \""R\"", \""fields\"":[{\""name\"": \""f1\"", \""type\"": \""int\""}]}"");
    new CloningVisitor(recordSchema).afterVisitNonTerminal(recordSchema.getField(""f1"").schema());
  }
",non-flaky,5
99777,apache_cassandra,MessagingServiceTest.testDCLatency,"    @Test
    public void testDCLatency() throws Exception
    {
        int latency = 100;
        ConcurrentHashMap<String, MessagingMetrics.DCLatencyRecorder> dcLatency = MessagingService.instance().metrics.dcLatency;
        dcLatency.clear();

        long now = System.currentTimeMillis();
        long sentAt = now - latency;
        assertNull(dcLatency.get(""datacenter1""));
        addDCLatency(sentAt, now);
        assertNotNull(dcLatency.get(""datacenter1""));
        assertEquals(1, dcLatency.get(""datacenter1"").dcLatency.getCount());
        long expectedBucket = bucketOffsets[Math.abs(Arrays.binarySearch(bucketOffsets, MILLISECONDS.toNanos(latency))) - 1];
        assertEquals(expectedBucket, dcLatency.get(""datacenter1"").dcLatency.getSnapshot().getMax());
    }
",non-flaky,5
89373,apache_samza,TestKafkaCheckpointManager.testReadMultipleCheckpointsUpgradeCheckpointVersion,"  @Test
  public void testReadMultipleCheckpointsUpgradeCheckpointVersion() throws InterruptedException {
    Config config = config(ImmutableMap.of(TaskConfig.CHECKPOINT_READ_VERSIONS, ""2,1""));
    setupSystemFactory(config);
    KafkaCheckpointManager kafkaCheckpointManager = buildKafkaCheckpointManager(true, config);
    kafkaCheckpointManager.register(TASK0);
    kafkaCheckpointManager.register(TASK1);

    List<IncomingMessageEnvelope> checkpointEnvelopesV1 =
        ImmutableList.of(newCheckpointV1Envelope(TASK0, buildCheckpointV1(INPUT_SSP0, ""0""), ""0""),
            newCheckpointV1Envelope(TASK1, buildCheckpointV1(INPUT_SSP1, ""0""), ""1""));
    CheckpointV2 ssp0CheckpointV2 = buildCheckpointV2(INPUT_SSP0, ""10"");
    CheckpointV2 ssp1CheckpointV2 = buildCheckpointV2(INPUT_SSP1, ""11"");
    List<IncomingMessageEnvelope> checkpointEnvelopesV2 =
        ImmutableList.of(newCheckpointV2Envelope(TASK0, ssp0CheckpointV2, ""2""),
            newCheckpointV2Envelope(TASK1, ssp1CheckpointV2, ""3""));
    setupConsumerMultiplePoll(ImmutableList.of(checkpointEnvelopesV1, checkpointEnvelopesV2));
    assertEquals(ssp0CheckpointV2, kafkaCheckpointManager.readLastCheckpoint(TASK0));
    assertEquals(ssp1CheckpointV2, kafkaCheckpointManager.readLastCheckpoint(TASK1));
    // 2 polls for actual checkpoints, 1 final empty poll
    verify(this.systemConsumer, times(3)).poll(ImmutableSet.of(CHECKPOINT_SSP),
        SystemConsumer.BLOCK_ON_OUTSTANDING_MESSAGES);
  }
",non-flaky,5
134028,CorfuDB_CorfuDB,OrchestratorTest.testAddNodeRequestWithoutExisting,"    @Test
    public void testAddNodeRequestWithoutExisting() {
        // We expect a new workflow to be created and prepare the required mocked behaviour.
        ArgumentCaptor<AddNodeRequest> requestArgumentCaptor = ArgumentCaptor.forClass(AddNodeRequest.class);
        AddNodeWorkflow mockWorkflow = mock(AddNodeWorkflow.class);
        doReturn(WORKFLOW_ID_2).when(mockWorkflow).getId();
        doReturn(mockWorkflow).when(workflowFactory).getAddNode(any(AddNodeRequest.class));

        sendAndValidateWorkflowDispatch(getAddNodeRequestMsg(ENDPOINT_2), WORKFLOW_ID_2);

        // Verify that a single AddNodeWorkflow was built for the given endpoint, and
        // that the corresponding workflowId was added to the activeWorkflows map.
        verify(workflowFactory).getAddNode(requestArgumentCaptor.capture());
        assertEquals(ENDPOINT_2, requestArgumentCaptor.getValue().getEndpoint());
        assertTrue(orchestrator.activeWorkflows.containsKey(WORKFLOW_ID_2));

        // Verify that run() was invoked with the newly created workflow.
        verify(orchestrator).run(eq(mockWorkflow), anyInt());
    }
",non-flaky,5
38220,palantir_atlasdb,TextUtilsTest.testRemoveAllWhitespace,"    @Test
    public void testRemoveAllWhitespace() {
        String before = ""  \r\n\n\r  \t FOOOooo\r\n\n\n\r\t\r o   \n"";
        String after = TextUtils.removeAllWhitespace(before);
        assertEquals(""FOOOoooo"", after);
    }
",non-flaky,5
76767,quarkusio_quarkus,PackageIT.testCustomPackaging,"    @Test
    public void testCustomPackaging()
            throws Exception {
        testDir = getTargetDir(""projects/custom-packaging-plugin"");

        running = new RunningInvoker(testDir, false);
        MavenProcessInvocationResult result = running.execute(Collections.singletonList(""install""),
                Collections.emptyMap());
        assertThat(result.getProcess().waitFor()).isEqualTo(0);

        testDir = getTargetDir(""projects/custom-packaging-app"");

        running = new RunningInvoker(testDir, false);
        result = running.execute(Collections.singletonList(""package""),
                Collections.emptyMap());
        assertThat(result.getProcess().waitFor()).isEqualTo(0);

        final File targetDir = getTargetDir();
        final File[] files = targetDir.listFiles(f -> f.getName().endsWith("".jar""));
        Set<String> jarNames = new HashSet<>(files.length);
        for (File f : files) {
            jarNames.add(f.getName());
        }

        final Path runnerJar = getTargetDir().toPath().resolve(""quarkus-app"").resolve(""quarkus-run.jar"");
        Assertions.assertTrue(Files.exists(runnerJar), ""Runner jar "" + runnerJar + "" is missing"");
        assertZipEntriesCanBeOpenedAndClosed(runnerJar);
    }
",non-flaky,5
98243,apache_jackrabbit,UtilsGetPathTest.testGetOrCreateByPathNoRoot,"    @Test
    public void testGetOrCreateByPathNoRoot() throws RepositoryException {
        String base = testRoot + ""/foo"";
        Node inter = JcrUtils.getOrCreateByPath(base, ""nt:unstructured"", superuser);
        assertEquals(base, inter.getPath());
        superuser.save();

        // test what happens if getRootNode() throws
        Session mockedSession = Mockito.spy(superuser);
        Mockito.when(mockedSession.getRootNode()).thenThrow(new AccessDeniedException(""access denied""));
        Mockito.when(mockedSession.getNode(""/"")).thenThrow(new AccessDeniedException(""access denied""));
        Mockito.when(mockedSession.getItem(""/"")).thenThrow(new AccessDeniedException(""access denied""));
        Mockito.when(mockedSession.nodeExists(""/"")).thenReturn(false);

        Node result = JcrUtils.getOrCreateByPath(base + ""/bar"", false, null, null, mockedSession, false);
        mockedSession.save();
        assertEquals(base + ""/bar"", result.getPath());

        // already exists -> nop
        Node result2 = JcrUtils.getOrCreateByPath(base + ""/bar"", false, null, null, mockedSession, false);
        mockedSession.save();
        assertEquals(base + ""/bar"", result2.getPath());

        // create unique
        Node result3 = JcrUtils.getOrCreateByPath(base + ""/bar"", true, null, null, mockedSession, false);
        mockedSession.save();
        assertEquals(base + ""/bar0"", result3.getPath());

        // already exists with createUnique == false should pass even when parent isn't readable
        Mockito.when(mockedSession.getNode(base)).thenThrow(new AccessDeniedException(""access denied""));
        Mockito.when(mockedSession.getItem(base)).thenThrow(new AccessDeniedException(""access denied""));
        Mockito.when(mockedSession.nodeExists(base)).thenReturn(false);
        Node result4 = JcrUtils.getOrCreateByPath(base + ""/bar"", false, null, null, mockedSession, false);
        mockedSession.save();
        assertEquals(base + ""/bar"", result4.getPath());
    }
",non-flaky,5
98386,ONSdigital_rm-collection-exercise-service,MandatoryEventValidatorTest.testValidMpsEventCreation,"  @Test
  public void testValidMpsEventCreation() throws CTPException {
    final Event mpsEvent = new Event();
    mpsEvent.setTag((Tag.mps.toString()));
    mpsEvent.setTimestamp(Timestamp.from(Instant.now().plus(2, ChronoUnit.DAYS)));
    final List<Event> events = new ArrayList<>();
    mandatoryValidator.validate(events, mpsEvent, CollectionExerciseState.CREATED);
  }
",non-flaky,5
91566,apache_kylin,RestClientTest.basicTests,"    @Test
    public void basicTests() throws IOException {
        RestClient a = new RestClient(""prod01:80"");
        //a.wipeCache(""metadata"", ""a"", ""a"");
        //String aa = a.getKylinProperties();
        //System.out.println(aa);
        RestClient b = new RestClient(""sandbox.hortonworks.com:7070"");
        //b.wipeCache(""metadata"", ""a"", ""a"");
        //String bb = b.getKylinProperties();
        //System.out.println(bb);

    }
",non-flaky,5
38222,palantir_atlasdb,TextUtilsTest.testTruncateLabelString,"    @Test
    public void testTruncateLabelString() {
        // TODO(nackner): Add in more tests with UTF-8 characters, but they won't play nice with the
        // build or people's Eclipse clients even if commented out.
        String string = ""abcde"";
        assertEquals(string, TextUtils.truncateLabelString(string, 5));
        assertEquals(string, TextUtils.truncateLabelString(string, 6, ""...""));
        assertEquals(""a..."", TextUtils.truncateLabelString(string, 4, ""...""));
    }
",non-flaky,5
162439,testcontainers_testcontainers-java,GenericContainerRuleTest.addExposedPortAfterWithExposedPortsTest,"    @Test
    public void addExposedPortAfterWithExposedPortsTest() {
        redis.addExposedPort(8987);
        assertThat(""Both ports should be exposed"", redis.getExposedPorts().size(), equalTo(2));
        assertTrue(""withExposedPort should be exposed"", redis.getExposedPorts().contains(REDIS_PORT));
        assertTrue(""addExposedPort should be exposed"", redis.getExposedPorts().contains(8987));
    }
",non-flaky,5
177986,aosp-mirror_platform_frameworks_support,CustomTabsIntentTest.testToolbarColor,"    @Test
    public void testToolbarColor() {
        int color = Color.RED;
        Intent intent = new CustomTabsIntent.Builder().setToolbarColor(color).build().intent;
        assertTrue(intent.hasExtra(CustomTabsIntent.EXTRA_TOOLBAR_COLOR));
        assertEquals(color, intent.getIntExtra(CustomTabsIntent.EXTRA_TOOLBAR_COLOR, 0));
    }
",non-flaky,5
30945,camunda-cloud_zeebe,ElasticsearchExporterTest.shouldNotHandleFlushException,"  @Test
  public void shouldNotHandleFlushException() {
    // given
    when(esClient.shouldFlush()).thenReturn(true);
    doThrow(new ElasticsearchExporterException(""expected"")).when(esClient).flush();

    createAndOpenExporter();

    // when
    assertThatThrownBy(() -> testHarness.export())
        .isInstanceOf(ElasticsearchExporterException.class)
        .withFailMessage(""expected"");

    // then
    verify(esClient, times(1)).flush();
  }
",non-flaky,5
114051,aws_aws-sdk-java-v2,AsyncDeleteItemWithResponseIntegrationTest.delete_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void delete_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Key key = Key.builder().partitionValue(1).sortValue(10).build();

        DeleteItemEnhancedResponse<Record> response =
            mappedTable.deleteItemWithResponse(r -> r.key(key).returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE))
                       .join();

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
77534,dropwizard_dropwizard,ResourceTestRuleWithGrizzlyTest.testResource,"    @Test
    public void testResource() {
        assertThat(resourceTestRule.target(""test"").request()
                .get(String.class))
                .isEqualTo(""test"");
    }
",non-flaky,5
91369,OpenLCB_OpenLCB_Java,TractionProxyRequestMessageTest.testCTor,"    @Test
    public void testCTor() {
        NodeID src = new NodeID(new byte[]{6,5,5,4,4,3});
        NodeID dst = new NodeID(new byte[]{2,2,2,4,4,4});
        byte[] payload = new byte[]{0x40,0x01,0x00}; // Traciton Management Reply message
        TractionProxyRequestMessage t = new TractionProxyRequestMessage(src,dst,payload);
        Assert.assertNotNull(""exists"",t);
    }
",non-flaky,5
77492,dropwizard_dropwizard,Issue3796Test.deserialize,"    @Test
        public CustomProperty deserialize(JsonParser parser, DeserializationContext context) throws IOException {
            assertThat(parser.getCodec()).isNotNull();

            TreeNode treeNode = parser.readValueAsTree();
            final TextNode custom = (TextNode) treeNode.path(""custom"");
            return new CustomProperty(custom.asText());
        }
",non-flaky,5
33752,alibaba_fastjson,FastJsonpHttpMessageConverter4Case2Test.test3_2,"    @Test
    public void test3_2() throws Exception {
        ResultActions actions = this.mockMvc.perform(post(""/fastjson/test3?jsonp=fnUpdateSome""));
        actions.andDo(print());
        actions.andExpect(status().isOk()).andExpect(content().contentType(APPLICATION_JAVASCRIPT))
                .andExpect(content().string(""/**/fnUpdateSome({})""));
    }
",non-flaky,5
43011,fabiomaffioletti_jsondoc,SpringPathBuilderTest.apply,"	@Test
	public void testPathWithMethodDisplayMethod() {
		ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>> newHashSet(SpringController5.class), MethodDisplay.METHOD).iterator().next();
		boolean allRight = FluentIterable.from(apiDoc.getMethods()).anyMatch(new Predicate<ApiMethodDoc>() {
			@Override
			public boolean apply(ApiMethodDoc input) {
				boolean allRight = input.getPath().contains(""/path"") && input.getPath().contains(""/path2"") && input.getDisplayedMethodString().contains(""none"");
				return allRight;
			}
",non-flaky,5
160400,ConsenSys_teku,ChainDataProviderTest.filteredValidatorsList_shouldFilterByValidatorIndex,"  @Test
  public void filteredValidatorsList_shouldFilterByValidatorIndex() {

    final tech.pegasys.teku.spec.datastructures.state.beaconstate.BeaconState internalState =
        data.randomBeaconState(1024);
    final ChainDataProvider provider =
        new ChainDataProvider(spec, recentChainData, combinedChainDataClient);
    List<Integer> indexes =
        provider.getFilteredValidatorList(internalState, List.of(""1"", ""33""), emptySet()).stream()
            .map(v -> v.index.intValue())
            .collect(toList());
    assertThat(indexes).containsExactly(1, 33);
  }
",non-flaky,5
122579,vespa-engine_vespa,FileSnapshotTest.fileRemoval,"    @Test
    public void fileRemoval() {
        path.createParents().writeUtf8File(""file content"");
        fileSnapshot = fileSnapshot.snapshot();
        assertTrue(fileSnapshot.exists());
        path.deleteIfExists();
        fileSnapshot = fileSnapshot.snapshot();
        assertFalse(fileSnapshot.exists());
    }
",non-flaky,5
122542,vespa-engine_vespa,SystemCtlTest.enableCommandFailure,"    @Test
    public void enableCommandFailure() {
        terminal.expectCommand(""systemctl --quiet is-enabled docker 2>&1"", 1, """")
                .expectCommand(""systemctl enable docker 2>&1"", 1, ""error enabling service"");
        SystemCtl.SystemCtlEnable enableDockerService = new SystemCtl(terminal).enable(""docker"");
        try {
            enableDockerService.converge(taskContext);
            fail();
        } catch (ChildProcessFailureException e) {
            // success
        }
    }
",non-flaky,5
33707,alibaba_fastjson,JSONScannerTest.checkTime13,"  @Test
  public void checkTime13() throws Throwable {

    // Arrange
    JSONScanner objectUnderTest = ((JSONScanner)Reflector.getInstance(""com.alibaba.fastjson.parser.JSONScanner""));
    objectUnderTest.hasSpecial = false;
    objectUnderTest.token = 0;
    objectUnderTest.locale = null;
    objectUnderTest.np = 0;
    objectUnderTest.features = 0;
    Reflector.setField(objectUnderTest, ""text"", """");
    objectUnderTest.calendar = null;
    objectUnderTest.matchStat = 0;
    objectUnderTest.bp = 0;
    Reflector.setField(objectUnderTest, ""len"", 0);
    objectUnderTest.stringDefaultValue = """";
    objectUnderTest.pos = 0;
    objectUnderTest.sp = 0;
    objectUnderTest.sbuf = null;
    objectUnderTest.ch = '\u0000';
    objectUnderTest.timeZone = null;
    objectUnderTest.eofPos = 0;
    char h0 = '1';
    char h1 = '9';
    char m0 = '6';
    char m1 = '0';
    char s0 = '>';
    char s1 = '\u0430';

    // Act
    Class<?> c = Reflector.forName(""com.alibaba.fastjson.parser.JSONScanner"");
    Method m = c.getDeclaredMethod(""checkTime"", Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""));
    m.setAccessible(true);
    boolean retval = (Boolean)m.invoke(objectUnderTest, h0, h1, m0, m1, s0, s1);

    // Assert result
    Assert.assertEquals(false, retval);

  }
",non-flaky,5
77166,networknt_json-schema-validator,V4JsonSchemaTest.testRefRemoteValidator,"    @Test
    public void testRefRemoteValidator() throws Exception {
        runTestFile(""draft4/refRemote.json"");
    }
",non-flaky,5
179450,abel533_Mapper,IdListMapperTest.testDeleteByEmptyIdList,"    @Test(expected = Exception.class)
    public void testDeleteByEmptyIdList() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.deleteByIdList(new ArrayList<Long>());
        } finally {
            sqlSession.close();
        }
    }
",non-flaky,5
91554,apache_kylin,JdbcSourceTest.testBasics,"    @Test
    public void testBasics() throws IOException {
        ISource source = SourceManager.getSource(new JdbcSourceAware());
        ISourceMetadataExplorer explorer = source.getSourceMetadataExplorer();
        ISampleDataDeployer deployer = source.getSampleDataDeployer();

        Assert.assertTrue(source instanceof JdbcSource);
        Assert.assertTrue(explorer instanceof JdbcExplorer);
        Assert.assertTrue(deployer instanceof JdbcExplorer);

        IMRInput input = source.adaptToBuildEngine(IMRInput.class);
        Assert.assertNotNull(input);

        Class adaptTo = Object.class;
        expectedCannotAdaptEx.expect(RuntimeException.class);
        expectedCannotAdaptEx.expectMessage(""Cannot adapt to "" + adaptTo);
        source.adaptToBuildEngine(adaptTo);

        TableMetadataManager tblManager = TableMetadataManager.getInstance(getTestConfig());
        IReadableTable table = source.createReadableTable(tblManager.getTableDesc(""test_kylin_fact"", ""default""), null);
        Assert.assertTrue(table instanceof JdbcTable);

        source.close();
    }
",non-flaky,5
33878,apache_camel,FhirLoadPageIT.testByUrl,"    @Test
    public void testByUrl() throws Exception {
        String url = ""Patient?_count=2"";
        Bundle bundle = this.fhirClient.search()
                .byUrl(url)
                .returnBundle(Bundle.class).execute();
        assertNotNull(bundle.getLink(IBaseBundle.LINK_NEXT));

        String nextPageLink = bundle.getLink(""next"").getUrl();

        final Map<String, Object> headers = new HashMap<>();
        // parameter type is String
        headers.put(""CamelFhir.url"", nextPageLink);
        // parameter type is Class
        headers.put(""CamelFhir.returnType"", Bundle.class);

        IBaseBundle result = requestBodyAndHeaders(""direct://BY_URL"", null, headers);

        LOG.debug(""byUrl: "" + result);
        assertNotNull(result, ""byUrl result"");
    }
",non-flaky,5
118765,netty_netty,ByteBufUtilTest.testWriteUtf8Wrapped,"    @Test
    public void testWriteUtf8Wrapped() {
        String usAscii = ""Some UTF-8 like Ã¤ÃâÅÅ"";
        ByteBuf buf = unreleasableBuffer(Unpooled.buffer(16));
        assertWrapped(buf);
        buf.writeBytes(usAscii.getBytes(CharsetUtil.UTF_8));
        ByteBuf buf2 = unreleasableBuffer(Unpooled.buffer(16));
        assertWrapped(buf2);
        ByteBufUtil.writeUtf8(buf2, usAscii);

        assertEquals(buf, buf2);

        buf.release();
        buf2.release();
    }
",non-flaky,5
176852,OryxProject_oryx,DoubleWeightedMeanTest.testCopyEquals,"  @Test
  public void testCopyEquals() {
    DoubleWeightedMean mean = new DoubleWeightedMean();
    mean.increment(0.2, 4.0);
    mean.increment(-0.1, 2.0);
    DoubleWeightedMean copy = mean.copy();
    assertEquals(copy, mean);
    assertEquals(copy.hashCode(), mean.hashCode());
    DoubleWeightedMean zero = new DoubleWeightedMean();
    mean.clear();
    assertEquals(zero, mean);
  }
",non-flaky,5
20976,NationalSecurityAgency_timely,WebSocketRequestDeserializationTest.testAddDeserialization,"    @Test
    public void testAddDeserialization() throws Exception {
        // @formatter:off
		String json = ""{"" +
						""\""operation\"" : \""add\"","" +
						""\""sessionId\"" : \""1234\"","" +
					    "" \""metric\"" : \""sys.cpu.user\"""" +
					  ""}"";
		// @formatter:on
        WebSocketRequest request = JsonUtil.getObjectMapper().readValue(json.getBytes(), WebSocketRequest.class);
        Assert.assertNotNull(request);
        Assert.assertEquals(AddSubscription.class, request.getClass());
        Assert.assertEquals(""1234"", ((AddSubscription) request).getSessionId());
        Assert.assertEquals(""sys.cpu.user"", ((AddSubscription) request).getMetric());
        Assert.assertEquals(false, ((AddSubscription) request).getTags().isPresent());
        Assert.assertEquals(false, ((AddSubscription) request).getStartTime().isPresent());
    }
",non-flaky,5
179417,abel533_Mapper,VersionTest.testVersionError,"    @Test(expected = VersionException.class)
    public void testVersionError(){
        EntityHelper.initEntityNameMap(UserVersionError.class, config);
        EntityTable entityTable = EntityHelper.getEntityTable(UserVersionError.class);
        Assert.assertNotNull(entityTable);
        SqlHelper.wherePKColumns(UserVersionError.class, true);
    }
",non-flaky,5
57287,apache_ozone,TestReconCodecs.testContainerKeyPrefixCodec,"  @Test
  public void testContainerKeyPrefixCodec() throws IOException {
    ContainerKeyPrefix containerKeyPrefix = new ContainerKeyPrefix(
        System.currentTimeMillis(), ""TestKeyPrefix"", 0);

    Codec<ContainerKeyPrefix> codec = new ContainerKeyPrefixCodec();
    byte[] persistedFormat = codec.toPersistedFormat(containerKeyPrefix);
    Assert.assertTrue(persistedFormat != null);
    ContainerKeyPrefix fromPersistedFormat =
        codec.fromPersistedFormat(persistedFormat);
    Assert.assertEquals(containerKeyPrefix, fromPersistedFormat);
  }
",non-flaky,5
113862,spring-projects_spring-data-couchbase,FluxTest.flatMapCB,"	@Test
	public void flatMapCB() throws Exception {
		System.out.println(""Start flatMapCB"");
		ParallelFlux<GetResult> concat = Flux.fromIterable(keyList).parallel(2).runOn(Schedulers.parallel())
				.flatMap(item -> cbGet(item) /* rCollection.get(item) */
						.doOnSubscribe((x) -> System.out.println("" +"" + rCat.incrementAndGet()))
						.doOnTerminate(() -> System.out.println("" -"" + rCat.decrementAndGet())));
		System.out.println(concat.sequential().collectList().block());
	}
",non-flaky,5
20965,NationalSecurityAgency_timely,TestWrappedGorillaCompressor.testHDFSWrite,"    @Test
    public void testHDFSWrite() throws Exception {

        try {
            Configuration configuration = new Configuration();
            FileSystem fs = FileSystem.get(new URI(""hdfs://localhost:8020""), configuration);
            GorillaStore store = new GorillaStore(fs, ""mymetric"", new timely.Configuration());

            long start = System.currentTimeMillis();
            WrappedGorillaCompressor originalCompressor = new WrappedGorillaCompressor(start);
            long t = start;

            for (int x = 1; x <= 10; x++) {
                originalCompressor.addValue(t, 10);
                t = t + 1000;
            }
            originalCompressor.close();

            store.writeCompressor(""mymetric"", originalCompressor);

            List<WrappedGorillaCompressor> archived = store.readCompressors(fs, new Path(""/timely/cache/mymetric""));

            for (WrappedGorillaCompressor c : archived) {

                GorillaDecompressor d = new GorillaDecompressor(new LongArrayInput(c.getCompressorOutput()));
                LinkedList<Pair> q = new LinkedList<>();
                Pair p = null;
                while ((p = d.readPair()) != null) {
                    q.add(p);
                }
            }
        } catch (Exception e) {
            System.out.println(e.getMessage());
        }
    }
",non-flaky,5
43048,trinodb_trino,BaseConnectorTest.testIsNullPredicate,"    @Test
    public void testIsNullPredicate()
    {
        assertQueryReturnsEmptyResult(""SELECT * FROM orders WHERE orderkey IS NULL"");
        assertQueryReturnsEmptyResult(""SELECT * FROM orders WHERE orderkey = 10 OR orderkey IS NULL"");

        // filtered column is selected
        assertQuery(""SELECT custkey, orderkey FROM orders WHERE orderkey = 32 OR orderkey IS NULL"", ""VALUES (1301, 32)"");

        // filtered column is not selected
        assertQuery(""SELECT custkey FROM orders WHERE orderkey = 32 OR orderkey IS NULL"", ""VALUES (1301)"");
    }
",non-flaky,5
136492,doanduyhai_Achilles,SnakeCaseNamingTest.should_return_blank_name,"    @Test
    public void should_return_blank_name() throws Exception {
        //Given
        String name = ""     "";

        //When
        final String actual = strategy.apply(name);

        //Then
        assertThat(actual).isEmpty();
    }
",non-flaky,5
170506,eclipse_jetty.project,MBeanContainerTest.testDump,"    @Test
    public void testDump()
    {
        assertNotNull(mbeanContainer.dump(), ""Dump operation shouldn't return null if operation is success"");
    }
",non-flaky,5
76966,Tencent_Firestorm,RssUtilsTest.testShuffleIndexSegment,"  @Test
  public void testShuffleIndexSegment() {
    ShuffleIndexResult shuffleIndexResult = new ShuffleIndexResult();
    List<ShuffleDataSegment> shuffleDataSegments =
        RssUtils.transIndexDataToSegments(shuffleIndexResult, 1000);
    assertTrue(shuffleDataSegments.isEmpty());

    int readBufferSize = 32;
    int totalLength = 0;
    List<BufferSegment> bufferSegments = Lists.newArrayList();
    int[] dataSegmentLength = new int[]{32, 16, 10, 32, 6};

    for (int i = 0; i < dataSegmentLength.length; ++i) {
      long offset = totalLength;
      int length = dataSegmentLength[i];
      bufferSegments.add(new BufferSegment(i, offset, length, i, i, i));
      totalLength += length;
    }

    // those 5 segment's data length are [32, 16, 10, 32, 6] so the index should be
    // split into 3 ShuffleDataSegment, which are [32, 16 + 10 + 32, 6]
    int expectedTotalSegmentNum = 3;
    ByteBuffer byteBuffer = ByteBuffer.allocate(5 * 40);

    for (BufferSegment bufferSegment : bufferSegments) {
      byteBuffer.putLong(bufferSegment.getOffset());
      byteBuffer.putInt(bufferSegment.getLength());
      byteBuffer.putInt(bufferSegment.getUncompressLength());
      byteBuffer.putLong(bufferSegment.getCrc());
      byteBuffer.putLong(bufferSegment.getBlockId());
      byteBuffer.putLong(bufferSegment.getTaskAttemptId());
    }

    byte[] data = byteBuffer.array();
    shuffleDataSegments = RssUtils.transIndexDataToSegments(new ShuffleIndexResult(data), readBufferSize);
    assertEquals(expectedTotalSegmentNum, shuffleDataSegments.size());

    assertEquals(0, shuffleDataSegments.get(0).getOffset());
    assertEquals(32, shuffleDataSegments.get(0).getLength());
    assertEquals(1, shuffleDataSegments.get(0).getBufferSegments().size());

    assertEquals(32, shuffleDataSegments.get(1).getOffset());
    assertEquals(58, shuffleDataSegments.get(1).getLength());
    assertEquals(3,shuffleDataSegments.get(1).getBufferSegments().size());

    assertEquals(90, shuffleDataSegments.get(2).getOffset());
    assertEquals(6, shuffleDataSegments.get(2).getLength());
    assertEquals(1, shuffleDataSegments.get(2).getBufferSegments().size());
  }
",non-flaky,5
179482,abel533_Mapper,SafeUpdateByMethodTest.testSafeUpdateNull,"    @Test(expected = PersistenceException.class)
    public void testSafeUpdateNull() {
        SqlSession sqlSession = getSqlSession();
        try {
            CountryMapper mapper = sqlSession.getMapper(CountryMapper.class);
            mapper.updateByExample(new Country(), null);
        } finally {
            sqlSession.close();
        }
    }
",non-flaky,5
96028,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcher5,"  @Test
  public void testTokenSequenceMatcher5() throws IOException {
    CoreMap doc = createDocument(testText1);

    // Test simple sequence
    TokenSequencePattern p = TokenSequencePattern.compile("" [ { word:\""Archbishop\"" } ]  [ { word:\""of\"" } ]  [ { word:\""Canterbury\"" } ]"");
    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    boolean match = m.find();
    assertTrue(match);
    assertEquals(""Archbishop of Canterbury"", m.group());
    match = m.find();
    assertFalse(match);

    m.reset();
    match = m.find();
    assertTrue(match);
    assertEquals(""Archbishop of Canterbury"", m.group());

    m.reset();
    match = m.matches();
    assertFalse(match);


    p = TokenSequencePattern.compile("" [ \""Archbishop\"" ]  [ \""of\""  ]  [ \""Canterbury\""  ]"");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(""Archbishop of Canterbury"", m.group());
    match = m.find();
    assertFalse(match);

    m.reset();
    match = m.find();
    assertTrue(match);
    assertEquals(""Archbishop of Canterbury"", m.group());

    m.reset();
    match = m.matches();
    assertFalse(match);

    // Test sequence with or
    p = TokenSequencePattern.compile("" [ \""Archbishop\""] [\""of\""] [\""Canterbury\""] |  [ \""Bishop\"" ] [ \""of\"" ]  [ \""London\"" ] "");
    m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Bishop of London"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Archbishop of Canterbury"", m.group());
    match = m.find();
    assertTrue(match);
    assertEquals(0, m.groupCount());
    assertEquals(""Bishop of London"", m.group());
    match = m.find();
    assertFalse(match);

  }
",non-flaky,5
91546,apache_kylin,JdbcExplorerTest.testValidateSql,"    @Test
    public void testValidateSql() throws Exception {
        explorer.validateSQL(""select 1"");
        validateSQLInvalidEx.expect(Exception.class);
        explorer.validateSQL(""select"");
    }
",non-flaky,5
76912,spring-projects_spring-data-envers,QueryDslRepositoryIntegrationTests.testWithRevisions,"	@Test
	public void testWithRevisions() {

		Country de = new Country();
		de.code = ""de"";
		de.name = ""Deutschland"";

		countryRepository.save(de);

		de.name = ""Germany"";

		countryRepository.save(de);

		Revisions<Integer, Country> revisions = countryRepository.findRevisions(de.id);

		assertThat(revisions).hasSize(2);

		Iterator<Revision<Integer, Country>> iterator = revisions.iterator();

		Integer firstRevisionNumber = iterator.next().getRevisionNumber().get();
		Integer secondRevisionNumber = iterator.next().getRevisionNumber().get();

		assertThat(countryRepository.findRevision(de.id, firstRevisionNumber).get().getEntity().name)
				.isEqualTo(""Deutschland"");
		assertThat(countryRepository.findRevision(de.id, secondRevisionNumber).get().getEntity().name).isEqualTo(""Germany"");
	}
",non-flaky,5
96085,stanfordnlp_CoreNLP,StanfordCoreNLPServerITest.testLive,"  @Test
  public void testLive() {
    String result = IOUtils.slurpURLNoExceptions(""http://localhost:"" + port + ""/live"");
    Assert.assertNotNull(result);
    Assert.assertEquals(""live"", result.trim());
  }
",non-flaky,5
33678,alibaba_fastjson,JSONScannerTest.checkDate1,"  @Test
  public void checkDate1() throws Throwable {

    // Arrange
    char y0 = '2';
    char y1 = '1';
    char y2 = '1';
    char y3 = '1';
    char M0 = '1';
    char M1 = '0';
    int d0 = 51;
    int d1 = 48;

    // Act
    Class<?> c = Reflector.forName(""com.alibaba.fastjson.parser.JSONScanner"");
    Method m = c.getDeclaredMethod(""checkDate"", Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""int""), Reflector.forName(""int""));
    m.setAccessible(true);
    boolean retval = (Boolean)m.invoke(null, y0, y1, y2, y3, M0, M1, d0, d1);

    // Assert result
    Assert.assertEquals(true, retval);

  }
",non-flaky,5
91551,apache_kylin,JdbcHiveMRInputTest.testGenSqoopCmd_Partition,"    @Test
    public void testGenSqoopCmd_Partition() throws IOException {
        ISource source = SourceManager.getSource(new JdbcSourceAware());
        IMRInput input = source.adaptToBuildEngine(IMRInput.class);
        Assert.assertNotNull(input);

        CubeManager cubeManager = CubeManager.getInstance(getTestConfig());
        CubeDesc cubeDesc = CubeDescManager.getInstance(getTestConfig()).getCubeDesc(""ci_inner_join_cube"");
        CubeSegment seg = cubeManager.appendSegment(cubeManager.getCube(cubeDesc.getName()),
                new SegmentRange.TSRange(System.currentTimeMillis() - 100L, System.currentTimeMillis() + 100L));
        CubeJoinedFlatTableDesc flatDesc = new CubeJoinedFlatTableDesc(seg);
        JdbcHiveMRInput.JdbcMRBatchCubingInputSide inputSide = (JdbcHiveMRInput.JdbcMRBatchCubingInputSide) input
                .getBatchCubingInputSide(flatDesc);

        AbstractExecutable executable = new MockInputSide(flatDesc, inputSide).createSqoopToFlatHiveStep(""/tmp"",
                cubeDesc.getName());
        Assert.assertNotNull(executable);

        String cmd = executable.getParam(""cmd"");
        Assert.assertTrue(cmd.contains(""org.h2.Driver""));
        Assert.assertTrue(cmd.contains(
                ""--boundary-query \""SELECT MIN(\\\""TEST_KYLIN_FACT\\\"".\\\""LEAF_CATEG_ID\\\""), MAX(\\\""TEST_KYLIN_FACT\\\"".\\\""LEAF_CATEG_ID\\\"")"" + System.lineSeparator()
                        + ""FROM \\\""DEFAULT\\\"".\\\""TEST_KYLIN_FACT\\\"" AS \\\""TEST_KYLIN_FACT\\\""""));
        source.close();
    }
",non-flaky,5
84633,apache_zookeeper,ZKClientConfigTest.testIntegerRetrievalFromHexadecimalProperty,"    @Test
    public void testIntegerRetrievalFromHexadecimalProperty() {
        int hexaValue = 0x3000000;
        String wrongValue = ""0xwel"";
        int defaultValue = 100;
        // property is set in hexadecimal value
        ZKClientConfig zkClientConfig = new ZKClientConfig();
        zkClientConfig.setProperty(ZKConfig.JUTE_MAXBUFFER,
                Integer.toString(hexaValue));
        int result = zkClientConfig.getInt(ZKConfig.JUTE_MAXBUFFER, defaultValue);
        assertEquals(result, hexaValue);
        zkClientConfig.setProperty(ZKConfig.JUTE_MAXBUFFER,
                wrongValue);
        try {
            result = zkClientConfig.getInt(ZKConfig.JUTE_MAXBUFFER, defaultValue);
            fail(""NumberFormatException is expected"");
        } catch (NumberFormatException exception) {
            // do nothing
        }
        zkClientConfig.setProperty(ZKConfig.JUTE_MAXBUFFER,
                "" "" + hexaValue + "" "");
        result = zkClientConfig.getInt(ZKConfig.JUTE_MAXBUFFER, defaultValue);
        assertEquals(result, hexaValue);
    }
",non-flaky,5
175775,GoogleCloudPlatform_google-cloud-eclipse,AppYamlValidatorTest.testValidate_absolutePathInvalidFileName,"  @Test
  public void testValidate_absolutePathInvalidFileName() {
    String absolutePath = basePath + ""/sub/directory/my-app.yaml"";
    when(appYamlPath.getValue()).thenReturn(absolutePath);

    IStatus result = pathValidator.validate();
    assertEquals(IStatus.ERROR, result.getSeverity());
    assertEquals(""File name is not app.yaml: ""
        + new Path(basePath + ""/sub/directory/my-app.yaml"").toOSString(),
        result.getMessage());
  }
",non-flaky,5
89311,apache_samza,TestKafkaSystemAdminWithMock.testGetSSPMetadataEmptyPartition,"  @Test
  public void testGetSSPMetadataEmptyPartition() {
    SystemStreamPartition ssp = new SystemStreamPartition(TEST_SYSTEM, VALID_TOPIC, new Partition(0));
    SystemStreamPartition otherSSP = new SystemStreamPartition(TEST_SYSTEM, ""otherTopic"", new Partition(1));
    TopicPartition topicPartition = new TopicPartition(VALID_TOPIC, 0);
    TopicPartition otherTopicPartition = new TopicPartition(""otherTopic"", 1);
    when(mockKafkaConsumer.beginningOffsets(ImmutableList.of(topicPartition, otherTopicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 1L));
    when(mockKafkaConsumer.endOffsets(ImmutableList.of(topicPartition, otherTopicPartition))).thenReturn(
        ImmutableMap.of(topicPartition, 11L));

    Map<SystemStreamPartition, SystemStreamMetadata.SystemStreamPartitionMetadata> expected =
        ImmutableMap.of(ssp, new SystemStreamMetadata.SystemStreamPartitionMetadata(""1"", ""10"", ""11""), otherSSP,
            new SystemStreamMetadata.SystemStreamPartitionMetadata(null, null, null));
    assertEquals(expected, kafkaSystemAdmin.getSSPMetadata(ImmutableSet.of(ssp, otherSSP)));
  }
",non-flaky,5
98103,vert-x3_vertx-mongo-client,ParsingStreamTypeTest.should_not_include_any_stream_type_by_default_for_backwards_compatibility,"  @Test
  public void should_not_include_any_stream_type_by_default_for_backwards_compatibility() {
    // given
    final JsonObject noStreamTypeProvided = new JsonObject().put(
      ""connection_string"", ""mongodb://localhost:27017/mydb?replicaSet=myRs""
    );

    // when
    final MongoClientSettings parsedSettings = new MongoClientOptionsParser(vertx, noStreamTypeProvided).settings();

    // then
    assertNull(parsedSettings.getStreamFactoryFactory());
  }
",non-flaky,5
162353,epimorphics_appbase,TestJsonActions.testErrorHander,"    @Test
    public void testErrorHander() throws InterruptedException {
        ActionExecution ae = runAction(""testErrorHandler"", """");
//        dumpState(ae);
        ProgressMonitorReporter pm = ae.getMonitor();
        assertFalse(pm.succeeded());
        assertEquals(2, pm.getMessages().size());
        assertTrue( pm.getMessages().get(0).getMessage().contains(""Forcing error from CreateErrorAction"") );
        assertEquals( ""Error detected"", pm.getMessages().get(1).getMessage() );

        ae = runAction(""testErrorTimeout"", """");
        Thread.sleep(10);  // Allow time out processing to complete, more robust way?
        pm = ae.getMonitor();
        assertFalse(pm.succeeded());
        List<ProgressMessage> messages = pm.getMessages();
        assertEquals( ""Timeout detected"", messages.get(messages.size() - 1).getMessage());
    }
",non-flaky,5
57234,apache_ozone,TestContainerHealthTaskRecordGenerator.testCorrectRecordsGenerated,"  @Test
  public void testCorrectRecordsGenerated() {
    Set<ContainerReplica> replicas =
        generateReplicas(container, CLOSED, CLOSED, CLOSED);

    // HEALTHY container - no records generated.
    ContainerHealthStatus status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    List<UnhealthyContainers> records =
        ContainerHealthTask.ContainerHealthRecords
            .generateUnhealthyRecords(status, (long)1234567);
    assertEquals(0, records.size());

    // Over-replicated - expect 1 over replicated record
    replicas =
        generateReplicas(container, CLOSED, CLOSED, CLOSED, CLOSED, CLOSED);
    status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    records = ContainerHealthTask.ContainerHealthRecords
        .generateUnhealthyRecords(status, (long)1234567);
    assertEquals(1, records.size());
    UnhealthyContainers rec = records.get(0);
    assertEquals(UnHealthyContainerStates.OVER_REPLICATED.toString(),
        rec.getContainerState());
    assertEquals(3, rec.getExpectedReplicaCount().intValue());
    assertEquals(5, rec.getActualReplicaCount().intValue());
    assertEquals(-2, rec.getReplicaDelta().intValue());

    // Under and Mis Replicated - expect 2 records - mis and under replicated
    replicas =
        generateReplicas(container, CLOSED, CLOSED);
    when(placementPolicy.validateContainerPlacement(
        Mockito.anyList(), Mockito.anyInt()))
        .thenReturn(new ContainerPlacementStatusDefault(1, 2, 5));
    status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    records = ContainerHealthTask.ContainerHealthRecords
        .generateUnhealthyRecords(status, (long)1234567);
    assertEquals(2, records.size());

    rec = findRecordForState(records, UnHealthyContainerStates.MIS_REPLICATED);
    assertEquals(UnHealthyContainerStates.MIS_REPLICATED.toString(),
        rec.getContainerState());
    assertEquals(2, rec.getExpectedReplicaCount().intValue());
    assertEquals(1, rec.getActualReplicaCount().intValue());
    assertEquals(1, rec.getReplicaDelta().intValue());
    assertNotNull(rec.getReason());

    rec = findRecordForState(records,
        UnHealthyContainerStates.UNDER_REPLICATED);
    assertEquals(UnHealthyContainerStates.UNDER_REPLICATED.toString(),
        rec.getContainerState());
    assertEquals(3, rec.getExpectedReplicaCount().intValue());
    assertEquals(2, rec.getActualReplicaCount().intValue());
    assertEquals(1, rec.getReplicaDelta().intValue());

    // Missing Record - expect just a single missing record even though
    // it is mis-replicated too
    replicas.clear();
    when(placementPolicy.validateContainerPlacement(
        Mockito.anyList(), Mockito.anyInt()))
        .thenReturn(new ContainerPlacementStatusDefault(1, 2, 5));
    status =
        new ContainerHealthStatus(container, replicas, placementPolicy);
    records = ContainerHealthTask.ContainerHealthRecords
        .generateUnhealthyRecords(status, (long)1234567);
    assertEquals(1, records.size());
    rec = records.get(0);
    assertEquals(UnHealthyContainerStates.MISSING.toString(),
        rec.getContainerState());
    assertEquals(3, rec.getExpectedReplicaCount().intValue());
    assertEquals(0, rec.getActualReplicaCount().intValue());
    assertEquals(3, rec.getReplicaDelta().intValue());
  }
",non-flaky,5
118729,netty_netty,BigEndianHeapByteBufTest.shouldNotAllowNullInConstructor2,"    @Test(expected = NullPointerException.class)
    public void shouldNotAllowNullInConstructor2() {
        new UnpooledHeapByteBuf(UnpooledByteBufAllocator.DEFAULT, null, 0);
    }
",non-flaky,5
33926,apache_camel,CordaConsumerVaultTrackIT.vaultTrackTest,"    @Test
    public void vaultTrackTest() throws Exception {
        mockResult.expectedMinimumMessageCount(1);
        mockError.expectedMessageCount(0);
        MockEndpoint.assertIsSatisfied(context);
    }
",non-flaky,5
91437,strapdata_elassandra,PreBuiltTransportClientTests.testInstallPluginTwice,"    @Test
    public void testInstallPluginTwice() {
        for (Class<? extends Plugin> plugin :
                Arrays.asList(ParentJoinPlugin.class, ReindexPlugin.class, PercolatorPlugin.class,
                    MustachePlugin.class)) {
            try {
                new PreBuiltTransportClient(Settings.EMPTY, plugin);
                fail(""exception expected"");
            } catch (IllegalArgumentException ex) {
                assertTrue(""Expected message to start with [plugin already exists: ] but was instead ["" + ex.getMessage() + ""]"",
                        ex.getMessage().startsWith(""plugin already exists: ""));
            }
        }
    }
",non-flaky,5
91433,strapdata_elassandra,WatchAckTests.indexTestDocument,"@TestLogging(""org.elasticsearch.xpack.watcher:DEBUG"")
    public void indexTestDocument() {
        IndexResponse eventIndexResponse = client().prepareIndex(""events"", ""event"", id)
                .setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE)
                .setSource(""level"", ""error"")
                .get();
        assertEquals(DocWriteResponse.Result.CREATED, eventIndexResponse.getResult());
    }
",non-flaky,5
156120,soot-oss_soot,AbstractLambdaMetaFactoryCGTest.publicMethodRef,"  @Test
  public void publicMethodRef() {
    String testClass = ""soot.lambdaMetaFactory.PublicMethodRef"";

    final SootMethod target
        = prepareTarget(methodSigFromComponents(testClass, TEST_METHOD_RET, TEST_METHOD_NAME), testClass);

    final CallGraph cg = Scene.v().getCallGraph();

    final String referencedMethodName = ""publicMethod"";

    final String metaFactoryClass = getMetaFactoryNameMethodRef(testClass, referencedMethodName);

    final SootMethod bootstrap = Scene.v()
        .getMethod(methodSigFromComponents(metaFactoryClass, ""java.util.function.Supplier"", ""bootstrap$"", testClass));
    final SootMethod metaFactoryConstructor
        = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""void"", ""<init>"", testClass));
    final SootMethod get = Scene.v().getMethod(methodSigFromComponents(metaFactoryClass, ""java.lang.Object"", ""get""));
    final SootMethod referencedMethod = Scene.v().getMethod(methodSigFromComponents(testClass, ""int"", referencedMethodName));

    final List<Edge> edgesFromTarget = newArrayList(cg.edgesOutOf(target));

    assertTrue(""There should be an edge from main to the bootstrap method of the synthetic LambdaMetaFactory"",
        edgesFromTarget.stream().anyMatch(e -> e.tgt().equals(bootstrap) && e.isStatic()));
    assertTrue(""There should be an edge to the constructor of the LambdaMetaFactory in the bootstrap method"",
        newArrayList(cg.edgesOutOf(bootstrap)).stream()
            .anyMatch(e -> e.tgt().equals(metaFactoryConstructor) && e.isSpecial()));
    assertTrue(
        ""There should be an interface invocation on the synthetic LambdaMetaFactory's implementation of the functional interface in the main method"",
        edgesFromTarget.stream().anyMatch(e -> e.getTgt().equals(get) && e.kind() == Kind.INTERFACE));
    assertTrue(""There should be a virtual call to the referenced method"",
        newArrayList(cg.edgesOutOf(get)).stream().anyMatch(e -> e.getTgt().equals(referencedMethod) && e.isVirtual()));

    validateAllBodies(target.getDeclaringClass(), bootstrap.getDeclaringClass());
  }
",non-flaky,5
99765,apache_cassandra,RateBasedBackPressureTest.testWindowSizeMustBeBiggerEqualThanTen,"    @Test(expected = IllegalArgumentException.class)
    public void testWindowSizeMustBeBiggerEqualThanTen() throws Exception
    {
        new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""0.9"", FACTOR, ""5"", FLOW, ""FAST""), new TestTimeSource(), 1);
    }
",non-flaky,5
135009,undertow-io_undertow,WebsocketStressTestCase.onOpen,"    @Test
    public void webSocketStringStressTestCase() throws Exception {
        List<CountDownLatch> latches = new ArrayList<>();
        for (int i = 0; i < NUM_THREADS; ++i) {
            final CountDownLatch latch = new CountDownLatch(1);
            latches.add(latch);
            final Session session = deployment.connectToServer(new Endpoint() {
                @Override
                public void onOpen(Session session, EndpointConfig config) {
                }
",non-flaky,5
76987,Tencent_Firestorm,SparkFallbackReadTest.resultCompareTest,"  @Test
  public void resultCompareTest() throws Exception {
    run();
    checkShuffleData();
  }
",non-flaky,5
92651,apache_dubbo,RegistryConfigTest.testTimeout,"    @Test
    public void testTimeout() throws Exception {
        RegistryConfig registry = new RegistryConfig();
        registry.setTimeout(10);
        assertThat(registry.getTimeout(), is(10));
    }
",non-flaky,5
77522,dropwizard_dropwizard,DropwizardAppRuleTest.canPerformAdminTask,"    @Test
    public void canPerformAdminTask() {
        final String response
            = RULE.client().target(""http://localhost:""
            + RULE.getAdminPort() + ""/tasks/hello?name=test_user"")
            .request()
            .post(Entity.entity("""", MediaType.TEXT_PLAIN), String.class);

        assertThat(response).isEqualTo(""Hello has been said to test_user"");
    }
",non-flaky,5
76945,Tencent_Firestorm,ShuffleReadClientImplTest.readTest5,"  @Test
  public void readTest5() throws Exception {
    String basePath = HDFS_URI + ""clientReadTest5"";
    HdfsShuffleWriteHandler writeHandler =
        new HdfsShuffleWriteHandler(""appId"", 0, 0, 1, basePath, ""test"", conf);

    Map<Long, byte[]> expectedData = Maps.newHashMap();
    Roaring64NavigableMap blockIdBitmap = Roaring64NavigableMap.bitmapOf();
    Roaring64NavigableMap taskIdBitmap = Roaring64NavigableMap.bitmapOf(0);
    writeTestData(writeHandler, 2, 30, 0, expectedData, blockIdBitmap);

    ShuffleReadClientImpl readClient = new ShuffleReadClientImpl(StorageType.HDFS.name(),
        ""appId"", 0, 1, 100, 2, 10, 1000,
        basePath, blockIdBitmap, taskIdBitmap, Lists.newArrayList(), new Configuration());
    // index file is deleted after iterator initialization, it should be ok, all index infos are read already
    Path indexFile = new Path(basePath + ""/appId/0/0-1/test.index"");
    fs.delete(indexFile, true);
    readClient.close();

    assertNull(readClient.readShuffleBlockData());
  }
",non-flaky,5
92680,apache_dubbo,ProviderConfigTest.testPort,"    @Test
    public void testPort() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setPort(8080);
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.getPort(), is(8080));
        assertThat(parameters, not(hasKey(""port"")));
    }
",non-flaky,5
162433,testcontainers_testcontainers-java,GenericContainerRuleTest.testExecInContainer,"    @Test
    public void testExecInContainer() throws Exception {

        // The older ""lxc"" execution driver doesn't support ""exec"". At the time of writing (2016/03/29),
        // that's the case for CircleCI.
        // Once they resolve the issue, this clause can be removed.
        Assume.assumeTrue(TestEnvironment.dockerExecutionDriverSupportsExec());

        final GenericContainer.ExecResult result = redis.execInContainer(""redis-cli"", ""role"");
        assertTrue(""Output for \""redis-cli role\"" command should start with \""master\"""", result.getStdout().startsWith(""master""));
        assertEquals(""Stderr for \""redis-cli role\"" command should be empty"", """", result.getStderr());
        // We expect to reach this point for modern Docker versions.
    }
",non-flaky,5
135802,Netflix_Hystrix,CumulativeCommandEventCounterStreamTest.testSingleBadRequest,"    @Test
    public void testSingleBadRequest() {
        HystrixCommandKey key = HystrixCommandKey.Factory.asKey(""CMD-CumulativeCounter-E"");
        stream = CumulativeCommandEventCounterStream.getInstance(key, 10, 500);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(5).subscribe(getSubscriber(latch));

        Command cmd = Command.from(groupKey, key, HystrixEventType.BAD_REQUEST);

        cmd.observe();

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.values().length];
        expected[HystrixEventType.BAD_REQUEST.ordinal()] = 1;
        expected[HystrixEventType.EXCEPTION_THROWN.ordinal()] = 1;
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
170548,eclipse_jetty.project,TestResourceAnnotations.destroy,"    @AfterEach
    public void destroy() throws Exception
    {
        comp.destroySubcontext(""env"");
    }
",non-flaky,5
84563,apache_zookeeper,DistributedQueueTest.testRemove1,"    @Test
    public void testRemove1() throws Exception {
        String dir = ""/testRemove1"";
        final int numClients = 1;
        ZooKeeper[] clients = new ZooKeeper[numClients];
        DistributedQueue[] queueHandles = new DistributedQueue[numClients];
        for (int i = 0; i < clients.length; i++) {
            clients[i] = createClient();
            queueHandles[i] = new DistributedQueue(clients[i], dir, null);
        }

        try {
            queueHandles[0].remove();
        } catch (NoSuchElementException e) {
            return;
        }

        fail();
    }
",non-flaky,5
135028,undertow-io_undertow,HttpStringTestCase.testCompare,"    @Test
    public void testCompare() {
        HttpString contentType =  new HttpString(Headers.CONTENT_TYPE_STRING);
        Assert.assertEquals(contentType.compareTo(Headers.COOKIE), Headers.CONTENT_TYPE.compareTo(Headers.COOKIE));

        HttpString cookie =  new HttpString(Headers.COOKIE_STRING);
        Assert.assertEquals(cookie.compareTo(Headers.CONTENT_TYPE), Headers.COOKIE.compareTo(Headers.CONTENT_TYPE));
    }
",non-flaky,5
43105,trinodb_trino,AbstractTestIntegrationSmokeTest.testShowCreateTable,"    @Test
    public void testShowCreateTable()
    {
        assertThat((String) computeScalar(""SHOW CREATE TABLE orders""))
                // If the connector reports additional column properties, the expected value needs to be adjusted in the test subclass
                .matches(""CREATE TABLE \\w+\\.\\w+\\.orders \\Q(\n"" +
                        ""   orderkey bigint,\n"" +
                        ""   custkey bigint,\n"" +
                        ""   orderstatus varchar(1),\n"" +
                        ""   totalprice double,\n"" +
                        ""   orderdate date,\n"" +
                        ""   orderpriority varchar(15),\n"" +
                        ""   clerk varchar(15),\n"" +
                        ""   shippriority integer,\n"" +
                        ""   comment varchar(79)\n"" +
                        "")"");
    }
",non-flaky,5
38250,palantir_atlasdb,AbstractAtlasDbKeyValueServiceTest.testGetRangeWithTimestamps,"    @Test
    public void testGetRangeWithTimestamps() {
        testGetRangeWithTimestamps(false);
        if (reverseRangesSupported()) {
            testGetRangeWithTimestamps(true);
        }
    }
",non-flaky,5
99763,apache_cassandra,RateBasedBackPressureTest.testHighRatioMustBeSmallerEqualThanOne,"    @Test(expected = IllegalArgumentException.class)
    public void testHighRatioMustBeSmallerEqualThanOne() throws Exception
    {
        new RateBasedBackPressure(ImmutableMap.of(HIGH_RATIO, ""2"", FACTOR, ""2"", FLOW, ""FAST""), new TestTimeSource(), 10);
    }
",non-flaky,5
98668,nutzam_nutz,BaseTest.test_http_method_override,"    @Test
    public void test_http_method_override() {
        Response resp = post(""/common/httpmethods?_method=DELETE"", new NutMap(""_method"", ""DELETE""));
        assertEquals(200, resp.getStatus());
        assertEquals(""DELETE"", resp.getContent());
    }
",non-flaky,5
150117,apache_hive,TestHplsqlOffline.testCreateTableMysql,"  @Test
  public void testCreateTableMysql() throws Exception {
    run(""create_table_mysql"");
  }
",non-flaky,5
113950,spring-projects_spring-data-couchbase,ReactiveCouchbaseRepositoryQueryCollectionIntegrationTests.afterEach,"	@AfterEach
	public void afterEach() {
		// first do processing for this class
		// no-op
		// then call the super method
		super.afterEach();
	}
",non-flaky,5
60913,apache_druid,DoubleMinAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new DoubleMinAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(DoubleMinAverager.class));
  }
",non-flaky,5
162421,testcontainers_testcontainers-java,GenericContainerRuleTest.simpleRedisTest,"//    @Test
//    public void simpleRedisTest() {
//        String ipAddress = redis.getContainerIpAddress();
//        Integer port = redis.getMappedPort(REDIS_PORT);
//
//        // Use Redisson to obtain a List that is backed by Redis
//        Config redisConfig = new Config();
//        redisConfig.useSingleServer().setAddress(ipAddress + "":"" + port);
//
//        Redisson redisson = Redisson.create(redisConfig);
//
//        List<String> testList = redisson.getList(""test"");
//        testList.add(""foo"");
//        testList.add(""bar"");
//        testList.add(""baz"");
//
//        List<String> testList2 = redisson.getList(""test"");
//        assertEquals(""The list contains the expected number of items (redis is working!)"", 3, testList2.size());
//        assertTrue(""The list contains an item that was put in (redis is working!)"", testList2.contains(""foo""));
//        assertTrue(""The list contains an item that was put in (redis is working!)"", testList2.contains(""bar""));
//        assertTrue(""The list contains an item that was put in (redis is working!)"", testList2.contains(""baz""));
//    }
",non-flaky,5
38670,apache_pulsar,InfluxDBSinkTest.testJsonSchema,"    @Test
    public void testJsonSchema() {
        JSONSchema<Cpu> schema = JSONSchema.of(Cpu.class);

        AutoConsumeSchema autoConsumeSchema = new AutoConsumeSchema();
        autoConsumeSchema.setSchema(GenericSchemaImpl.of(schema.getSchemaInfo()));
        GenericSchema<GenericRecord> genericSchema = GenericSchemaImpl.of(autoConsumeSchema.getSchemaInfo());

        assertFalse(genericSchema instanceof GenericAvroSchema);

        byte[] bytes = schema.encode(cpu);
        GenericRecord record = genericSchema.decode(bytes);

        assertEquals(record.getField(""measurement""), ""cpu"");

        // compare the String type
        assertEquals(record.getField(""timestamp"").toString(), timestamp + """");

        assertEquals(((GenericRecord)record.getField(""tags"")).getField(""host""), ""server-1"");
        assertEquals(((GenericRecord)record.getField(""fields"")).getField(""value""), 10);
    }
",non-flaky,5
162394,testcontainers_testcontainers-java,DockerComposeWaitStrategyTest.testWaitOnListeningPort,"    @Test
    public void testWaitOnListeningPort() {
        final DockerComposeContainer environment = new DockerComposeContainer(new File(""src/test/resources/compose-test.yml""))
            .withExposedService(""redis_1"", REDIS_PORT, Wait.forListeningPort());

        try {
            environment.starting(Description.createTestDescription(Object.class, ""name""));
            VisibleAssertions.pass(""Docker compose should start after waiting for listening port"");
        } catch (RuntimeException e) {
            VisibleAssertions.fail(""Docker compose should start after waiting for listening port with failed with: "" + e);
        }
    }
",non-flaky,5
177207,line_armeria,HBaseClientCompatibilityTest.testGuavaConflict,"    @Test(expected = NotAllMetaRegionsOnlineException.class)
    public void testGuavaConflict() throws Exception {
        // Make sure Armeria is available in the class path.
        assertThat(Version.getAll(Server.class.getClassLoader())).isNotNull();
        // Make sure newer Guava is available in the class path.
        assertThat(Stopwatch.class.getDeclaredConstructor().getModifiers()).is(new Condition<>(
                value -> !Modifier.isPublic(value),
                ""Recent Guava Stopwatch should have non-public default constructor.""));

        final MetaTableLocator locator = new MetaTableLocator();
        final ZooKeeperWatcher zkw = mock(ZooKeeperWatcher.class);
        final RecoverableZooKeeper zk = mock(RecoverableZooKeeper.class);
        when(zkw.getRecoverableZooKeeper()).thenReturn(zk);
        when(zk.exists(any(), any())).thenReturn(new Stat(0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0));

        locator.waitMetaRegionLocation(zkw, 100);
    }
",non-flaky,5
38195,palantir_atlasdb,SchemasTest.testCreateTables,"    @Test
    public void testCreateTables() {
        TableReference tableName1 = TableReference.createWithEmptyNamespace(TABLE_NAME + ""1"");
        TableReference tableName2 = TableReference.createWithEmptyNamespace(TABLE_NAME + ""2"");
        mockery.checking(new Expectations(){{
            oneOf(kvs).createTables(with(tableMapContainsEntry(tableName1, getSimpleTableDefinitionAsBytes(tableName1))));
            oneOf(kvs).createTables(with(tableMapContainsEntry(tableName2, getSimpleTableDefinitionAsBytes(tableName2))));
        }});
        Map<TableReference, TableDefinition> tables = Maps.newHashMap();
        tables.put(tableName1, getSimpleTableDefinition(tableName1));
        tables.put(tableName2, getSimpleTableDefinition(tableName2));
        Schemas.createTables(kvs, tables);
    }
",non-flaky,5
92679,apache_dubbo,ProviderConfigTest.testHost,"    @Test
    public void testHost() throws Exception {
        ProviderConfig provider = new ProviderConfig();
        provider.setHost(""demo-host"");
        Map<String, String> parameters = new HashMap<String, String>();
        ProviderConfig.appendParameters(parameters, provider);
        assertThat(provider.getHost(), equalTo(""demo-host""));
        assertThat(parameters, not(hasKey(""host"")));
    }
",non-flaky,5
133973,CorfuDB_CorfuDB,LogUnitHandlerTest.testCompact,"    @Test
    public void testCompact() {
        ResponseMsg response = getResponseMsg(
                getBasicHeader(ClusterIdCheck.CHECK, EpochCheck.CHECK),
                getCompactResponseMsg()
        );

        logUnitHandler.handleMessage(response, mockChannelHandlerContext);
        // Verify that the correct request was completed (once) with the appropriate value,
        // and that we did not complete exceptionally.
        verify(mockClientRouter, never()).completeExceptionally(anyLong(), any(Throwable.class));
        verify(mockClientRouter).completeRequest(response.getHeader().getRequestId(), true);
    }
",non-flaky,5
38656,apache_pulsar,ByteBufferSchemaWrapperTest.testGetBytesOffsetZeroDifferentLen,"    @Test
    public void testGetBytesOffsetZeroDifferentLen() throws Exception {
        byte[] originalArray = {1, 2, 3};
        ByteBuffer wrapped = ByteBuffer.wrap(originalArray, 1, 2);
        assertEquals(0, wrapped.arrayOffset());
        assertEquals(2, wrapped.remaining());
        byte[] result = ByteBufferSchemaWrapper.getBytes(wrapped);
        assertNotSame(result, originalArray);
        assertArrayEquals(result, new byte[] {2,3});
    }
",non-flaky,5
98439,ONSdigital_rm-collection-exercise-service,CollectionExerciseServiceTest.testFindCollectionExercisesForSurveysByState,"  @Test
  public void testFindCollectionExercisesForSurveysByState() throws Exception {
    final UUID SURVEY_ID_1 = UUID.fromString(""31ec898e-f370-429a-bca4-eab1045aff4e"");

    List<UUID> surveys = Arrays.asList(SURVEY_ID_1);

    List<CollectionExercise> existing = FixtureHelper.loadClassFixtures(CollectionExercise[].class);

    given(
            collexRepo.findBySurveyIdInAndStateOrderBySurveyId(
                surveys, CollectionExerciseDTO.CollectionExerciseState.LIVE))
        .willReturn(existing);

    HashMap<UUID, List<CollectionExercise>> result =
        this.collectionExerciseService.findCollectionExercisesForSurveysByState(
            surveys, CollectionExerciseDTO.CollectionExerciseState.LIVE);

    assertEquals(result.get(SURVEY_ID_1).size(), 2);
  }
",non-flaky,5
114097,aws_aws-sdk-java-v2,TableSchemaTest.fromBean_constructsBeanTableSchema,"    @Test
    public void fromBean_constructsBeanTableSchema() {
        BeanTableSchema<SimpleBean> beanBeanTableSchema = TableSchema.fromBean(SimpleBean.class);
        assertThat(beanBeanTableSchema).isNotNull();
    }
",non-flaky,5
60914,apache_druid,DoubleSumAveragerFactoryTest.testCreateAverager,"  @Test
  public void testCreateAverager()
  {
    AveragerFactory<?, ?> fac = new DoubleSumAveragerFactory(""test"", 5, 1, ""field"");
    Assert.assertThat(fac.createAverager(), IsInstanceOf.instanceOf(DoubleSumAverager.class));
  }
",non-flaky,5
96872,apache_avro,TestSpecificCompiler.testJavaTypeWithDecimalLogicalTypeDisabled,"  @Test
  public void testJavaTypeWithDecimalLogicalTypeDisabled() throws Exception {
    SpecificCompiler compiler = createCompiler();
    compiler.setEnableDecimalLogicalType(false);

    Schema dateSchema = LogicalTypes.date()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timeSchema = LogicalTypes.timeMillis()
        .addToSchema(Schema.create(Schema.Type.INT));
    Schema timestampSchema = LogicalTypes.timestampMillis()
        .addToSchema(Schema.create(Schema.Type.LONG));
    Schema decimalSchema = LogicalTypes.decimal(9,2)
        .addToSchema(Schema.create(Schema.Type.BYTES));
    Schema uuidSchema = LogicalTypes.uuid()
        .addToSchema(Schema.create(Schema.Type.STRING));

    // Date/time types should always use upper level java classes
    // Decimal type target class depends on configuration
    // UUID should always be CharSequence since we haven't added its
    // support in SpecificRecord
    Assert.assertEquals(""Should use Joda LocalDate for date type"",
        ""org.joda.time.LocalDate"", compiler.javaType(dateSchema));
    Assert.assertEquals(""Should use Joda LocalTime for time-millis type"",
        ""org.joda.time.LocalTime"", compiler.javaType(timeSchema));
    Assert.assertEquals(""Should use Joda DateTime for timestamp-millis type"",
        ""org.joda.time.DateTime"", compiler.javaType(timestampSchema));
    Assert.assertEquals(""Should use ByteBuffer type"",
        ""java.nio.ByteBuffer"", compiler.javaType(decimalSchema));
    Assert.assertEquals(""Should use Java CharSequence type"",
        ""java.lang.CharSequence"", compiler.javaType(uuidSchema));
  }
",non-flaky,5
76929,Tencent_Firestorm,WriteBufferManagerTest.addRecordTest,"  @Test
  public void addRecordTest() {
    SparkConf conf = getConf();
    WriteBufferManager wbm = createManager(conf);
    wbm.setShuffleWriteMetrics(new ShuffleWriteMetrics());
    String testKey = ""Key"";
    String testValue = ""Value"";
    List<ShuffleBlockInfo> result = wbm.addRecord(0, testKey, testValue);
    // single buffer is not full, there is no data return
    assertEquals(0, result.size());
    assertEquals(512, wbm.getAllocatedBytes());
    assertEquals(32, wbm.getUsedBytes());
    assertEquals(0, wbm.getInSendListBytes());
    assertEquals(1, wbm.getBuffers().size());
    wbm.addRecord(0, testKey, testValue);
    wbm.addRecord(0, testKey, testValue);
    wbm.addRecord(0, testKey, testValue);
    result = wbm.addRecord(0, testKey, testValue);
    // single buffer is full
    assertEquals(1, result.size());
    assertEquals(512, wbm.getAllocatedBytes());
    assertEquals(96, wbm.getUsedBytes());
    assertEquals(96, wbm.getInSendListBytes());
    assertEquals(0, wbm.getBuffers().size());
    wbm.addRecord(0, testKey, testValue);
    wbm.addRecord(1, testKey, testValue);
    wbm.addRecord(2, testKey, testValue);
    // single buffer is not full, and less than spill size
    assertEquals(512, wbm.getAllocatedBytes());
    assertEquals(192, wbm.getUsedBytes());
    assertEquals(96, wbm.getInSendListBytes());
    assertEquals(3, wbm.getBuffers().size());
    // all buffer size > spill size
    wbm.addRecord(3, testKey, testValue);
    wbm.addRecord(4, testKey, testValue);
    result = wbm.addRecord(5, testKey, testValue);
    assertEquals(6, result.size());
    assertEquals(512, wbm.getAllocatedBytes());
    assertEquals(288, wbm.getUsedBytes());
    assertEquals(288, wbm.getInSendListBytes());
    assertEquals(0, wbm.getBuffers().size());
    // free memory
    wbm.freeAllocatedMemory(96);
    assertEquals(416, wbm.getAllocatedBytes());
    assertEquals(192, wbm.getUsedBytes());
    assertEquals(192, wbm.getInSendListBytes());

    assertEquals(11, wbm.getShuffleWriteMetrics().recordsWritten());
    assertTrue(wbm.getShuffleWriteMetrics().bytesWritten() > 0);

    wbm.freeAllocatedMemory(192);
    wbm.addRecord(0, testKey, testValue);
    wbm.addRecord(1, testKey, testValue);
    wbm.addRecord(2, testKey, testValue);
    result = wbm.clear();
    assertEquals(3, result.size());
    assertEquals(224, wbm.getAllocatedBytes());
    assertEquals(96, wbm.getUsedBytes());
    assertEquals(96, wbm.getInSendListBytes());
  }
",non-flaky,5
77176,networknt_json-schema-validator,V4JsonSchemaTest.testUUIDValidator,"    @Test
    public void testUUIDValidator() throws Exception {
        runTestFile(""draft4/uuid.json"");
    }
",non-flaky,5
89352,apache_samza,TestKafkaCheckpointManagerFactory.testGetCheckpointTopicProperties,"  @Test
  public void testGetCheckpointTopicProperties() {
    Map<String, String> config = new HashMap<>();
    Properties properties = new KafkaConfig(new MapConfig(config)).getCheckpointTopicProperties();

    assertEquals(properties.getProperty(""cleanup.policy""), ""compact"");
    assertEquals(properties.getProperty(""segment.bytes""), String.valueOf(KafkaConfig.DEFAULT_CHECKPOINT_SEGMENT_BYTES()));

    config.put(ApplicationConfig.APP_MODE, ApplicationConfig.ApplicationMode.BATCH.name());
    properties = new KafkaConfig(new MapConfig(config)).getCheckpointTopicProperties();

    assertEquals(properties.getProperty(""cleanup.policy""), ""compact,delete"");
    assertEquals(properties.getProperty(""segment.bytes""), String.valueOf(KafkaConfig.DEFAULT_CHECKPOINT_SEGMENT_BYTES()));
    assertEquals(properties.getProperty(""retention.ms""), String.valueOf(KafkaConfig.DEFAULT_RETENTION_MS_FOR_BATCH()));
  }
",non-flaky,5
33849,apache_camel,FhirCapabilitiesIT.testEncodeJSON,"    @Test
    public void testEncodeJSON() throws Exception {
        Map<String, Object> headers = new HashMap<>();
        headers.put(ExtraParameters.ENCODE_JSON.getHeaderName(), Boolean.TRUE);

        org.hl7.fhir.instance.model.api.IBaseConformance result
                = requestBodyAndHeaders(""direct://OF_TYPE"", CapabilityStatement.class, headers);

        LOG.debug(""ofType: "" + result);
        assertNotNull(result, ""ofType result"");
        assertEquals(Enumerations.PublicationStatus.ACTIVE, ((CapabilityStatement) result).getStatus());
    }
",non-flaky,5
112092,apache_shardingsphere-elasticjob,AverageAllocationJobShardingStrategyTest.shardingForServersLessThanShardingCountAliquantFor10ShardingCountAnd3Servers,"    @Test
    public void shardingForServersLessThanShardingCountAliquantFor10ShardingCountAnd3Servers() {
        Map<JobInstance, List<Integer>> expected = new LinkedHashMap<>(3, 1);
        expected.put(new JobInstance(""host0@-@0""), Arrays.asList(0, 1, 2, 9));
        expected.put(new JobInstance(""host1@-@0""), Arrays.asList(3, 4, 5));
        expected.put(new JobInstance(""host2@-@0""), Arrays.asList(6, 7, 8));
        assertThat(jobShardingStrategy.sharding(Arrays.asList(new JobInstance(""host0@-@0""), new JobInstance(""host1@-@0""), new JobInstance(""host2@-@0"")), ""test_job"", 10), is(expected));
    }
",non-flaky,5
38202,palantir_atlasdb,RocksDbKeyValueServiceTest.testReadGood2,"    @Test
    public void testReadGood2() {
        final Cell cell = Cell.create(""r1"".getBytes(), ""2"".getBytes());
        final Cell cell2 = Cell.create(""r"".getBytes(), ""12"".getBytes());
        db.put(TABLE, ImmutableMap.of(cell, ""v1"".getBytes()), 1000);
        db.put(TABLE, ImmutableMap.of(cell2, ""v2"".getBytes()), 1000);
        final Map<Cell, Value> res = db.get(TABLE, ImmutableMap.of(cell, 1001L));
        final Value value = res.get(cell);
        assertEquals(1000, value.getTimestamp());
        assertEquals(""v1"", new String(value.getContents()));
    }
",non-flaky,5
70785,apache_kafka,StartAndStopLatchTest.shouldReturnTrueWhenAwaitingForStartAndStopToComplete,"    @Test
    public void shouldReturnTrueWhenAwaitingForStartAndStopToComplete() throws Throwable {
        latch = new StartAndStopLatch(1, 1, this::complete, dependents, clock);
        future = asyncAwait(100);
        latch.recordStart();
        latch.recordStop();
        clock.sleep(10);
        assertTrue(future.get(200, TimeUnit.MILLISECONDS));
        assertTrue(future.isDone());
    }
",non-flaky,5
110893,pushtorefresh_storio,InterceptorTest.putObject,"    @Test
    public void putObject() {
        storIOSQLite.put()
                .object(createTweet())
                .prepare()
                .executeAsBlocking();
        checkInterceptorsCalls();
    }
",non-flaky,5
26750,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testGetPairsReturnOnlyDevPairs,"	@Test
	public void testGetPairsReturnOnlyDevPairs() {
		List<DayPairs> pairsListFromDevs = getPairsListFromDevs(getStandardDevs());
		Pair opsPair = pairsListFromDevs.get(0).getPairByTrack(""track1"");
		opsPair.setOpsPair(true);
		
		List<Pair> pairs = new DevPairCombinations(pairsListFromDevs).getPairs();
		
		assertThat(pairs.size(), is(5));
		for (Pair pair : pairs) {
			assertThat(pair.isOpsPair(), is(false));
		}
	}
",non-flaky,5
133984,CorfuDB_CorfuDB,ManagementViewTest.testNodeStatusMap,"    @Test
    public void testNodeStatusMap() {
        final String server1 = ""server1"";
        final String server2 = ""server2"";
        final String server3 = ""server3"";
        Layout layout = layoutUtil.getLayout(Arrays.asList(server1, server2, server3));
        layout.setUnresponsiveServers(Arrays.asList(server1, server2));

        Map<String, NodeStatus> status = managementView.getNodeStatusMap(layout);
        assertThat(status.get(server1)).isEqualTo(NodeStatus.DOWN);
        assertThat(status.get(server2)).isEqualTo(NodeStatus.DOWN);
        assertThat(status.get(server3)).isEqualTo(NodeStatus.UP);
    }
",non-flaky,5
110872,pushtorefresh_storio,RxQueryTest.queryOneNonExistedObjectObservable,"    @Test
    public void queryOneNonExistedObjectObservable() {
        putUsersBlocking(3);

        final Observable<User> userObservable = storIOSQLite
                .get()
                .object(User.class)
                .withQuery(Query.builder()
                        .table(UserTableMeta.TABLE)
                        .where(UserTableMeta.COLUMN_EMAIL + ""=?"")
                        .whereArgs(""some arg"")
                        .build())
                .prepare()
                .asRxObservable()
                .take(1);

        TestSubscriber<User> testSubscriber = new TestSubscriber<User>();
        userObservable.subscribe(testSubscriber);

        testSubscriber.awaitTerminalEvent(5, SECONDS);
        testSubscriber.assertNoErrors();
        testSubscriber.assertValue(null);
    }
",non-flaky,5
222,apache_struts,13d9053050c9e4fb2ef049db6a37d3f6eebf48fa.testProcessAction_ok,"@Test
public void testProcessAction_ok() {
    final Mock mockResponse = mock(ActionResponse.class);
    PortletMode mode = PortletMode.VIEW;
    Map<String, String> initParams = new HashMap<String, String>();
    initParams.put(""viewNamespace"", ""/view"");
    Map<String, String[]> requestParams = new HashMap<String, String[]>();
    requestParams.put(ACTION_PARAM, new String[]{""/view/testAction""});
    requestParams.put(MODE_PARAM, new String[]{mode.toString()});
    initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true"");
    initPortletConfig(initParams, new HashMap<String, Object>());
    initRequest(requestParams, new HashMap<String, Object>(), new HashMap<String, Object>(), PortletMode.VIEW, WindowState.NORMAL, true, null);
    setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class));
    try {
        dispatcher
        .setActionProxyFactory((ActionProxyFactory) mockActionFactory
        .proxy());
        dispatcher.init((PortletConfig) mockConfig.proxy());
        dispatcher.processAction((ActionRequest) mockRequest.proxy(),
        (ActionResponse) mockResponse.proxy());
    } catch (Exception e) {
        e.printStackTrace();
        fail(""Error occured"");
    }
}",test order dependency,4
114061,aws_aws-sdk-java-v2,EnhancedTypeTest.dequeOf_ReturnsRawClassOfDeque_WhenSpecifyingEnhancedType,"    @Test
    public void dequeOf_ReturnsRawClassOfDeque_WhenSpecifyingEnhancedType() {
        EnhancedType<Deque<String>> type = EnhancedType.dequeOf(EnhancedType.of(String.class));

        assertThat(type.rawClass()).isEqualTo(Deque.class);
        assertThat(type.rawClassParameters()).containsExactly(EnhancedType.of(String.class));
    }
",non-flaky,5
76741,quarkusio_quarkus,RemoteDevMojoIT.testThatTheApplicationIsReloadedOnConfigChange,"    @Test
    public void testThatTheApplicationIsReloadedOnConfigChange() throws MavenInvocationException, IOException {
        testDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-config-change-remote"");
        agentDir = initProject(""projects/classic-remote-dev"", ""projects/project-classic-run-config-change-local"");
        assertThat(testDir).isDirectory();
        runAndCheck();

        String resp = DevModeTestUtils.getHttpResponse();
        runningAgent = new RunningInvoker(agentDir, false);
        runningAgent.execute(Arrays.asList(""compile"", ""quarkus:remote-dev""), Collections.emptyMap());

        assertThat(resp).containsIgnoringCase(""ready"").containsIgnoringCase(""application"").containsIgnoringCase(""org.acme"")
                .containsIgnoringCase(""1.0-SNAPSHOT"");

        String greeting = DevModeTestUtils.getHttpResponse(""/app/hello/greeting"");
        assertThat(greeting).containsIgnoringCase(""bonjour"");

        File source = new File(agentDir, ""src/main/resources/application.properties"");
        await()
                .pollDelay(1, TimeUnit.SECONDS)
                .pollInterval(1, TimeUnit.SECONDS)
                .until(source::isFile);

        String uuid = UUID.randomUUID().toString();
        filter(source, Collections.singletonMap(""bonjour"", uuid));

        // Wait until we get ""uuid""
        await()
                .pollDelay(1, TimeUnit.SECONDS)
                .atMost(1, TimeUnit.MINUTES)
                .until(() -> DevModeTestUtils.getHttpResponse(""/app/hello/greeting"").contains(uuid));
    }
",non-flaky,5
78287,apache_beam,TimerInternalsTest.testCompareByDomain,"  @Test
  public void testCompareByDomain() {
    Instant timestamp = new Instant(100);
    StateNamespace namespace = StateNamespaces.global();

    TimerData eventTimer = TimerData.of(namespace, timestamp, TimeDomain.EVENT_TIME);
    TimerData procTimer = TimerData.of(namespace, timestamp, TimeDomain.PROCESSING_TIME);
    TimerData synchronizedProcTimer =
        TimerData.of(namespace, timestamp, TimeDomain.SYNCHRONIZED_PROCESSING_TIME);

    assertThat(eventTimer, lessThan(procTimer));
    assertThat(eventTimer, lessThan(synchronizedProcTimer));
    assertThat(procTimer, lessThan(synchronizedProcTimer));
  }
",non-flaky,5
98055,vert-x3_vertx-mongo-client,GridFsTest.testDownloadStreamById,"  @Test
  public void testDownloadStreamById() {
    long fileLength = (1027) + 7000;
    String fileName = createTempFileWithContent(fileLength);
    String downloadFileName = createTempFile();

    AtomicReference<MongoGridFsClient> gridFsClient = new AtomicReference<>();
    AtomicReference<String> idCreated = new AtomicReference<>();

    Promise<MongoGridFsClient> gridFsClientPromise = Promise.promise();

    mongoClient.createDefaultGridFsBucketService(gridFsClientPromise);

    gridFsClientPromise.future().compose(mongoGridFsClient -> {
      assertNotNull(mongoGridFsClient);
      gridFsClient.set(mongoGridFsClient);
      Promise<Void> dropPromise = Promise.promise();
      mongoGridFsClient.drop(dropPromise);
      return dropPromise.future();
    }).compose(dropped -> {
      Promise<String> uploadPromise = Promise.promise();
      gridFsClient.get().uploadFile(fileName, uploadPromise);
      return uploadPromise.future();
    }).compose(id -> {
      assertNotNull(id);
      idCreated.set(id);
      Promise<AsyncFile> openPromise = Promise.promise();
      vertx.fileSystem().open(downloadFileName, new OpenOptions().setWrite(true), openPromise);
      return openPromise.future();
    }).compose(asyncFile -> {
      Promise<Long> downloadedPromise = Promise.promise();
      gridFsClient.get().downloadById(asyncFile, idCreated.get(), downloadedPromise);
      return downloadedPromise.future();
    }).compose(length -> {
      assertTrue(fileLength == length);
      testComplete();
      return Future.succeededFuture();
    }).onComplete(event -> {
      if (event.failed()) {
        fail(event.cause());
      }
    });
    await();
  }
",non-flaky,5
114095,aws_aws-sdk-java-v2,KeyTest.nullPartitionKey_shouldThrowException,"    @Test
    public void nullPartitionKey_shouldThrowException() {
        AttributeValue attributeValue = null;
        assertThatThrownBy(() ->  Key.builder().partitionValue(attributeValue).build())
         .isInstanceOf(IllegalArgumentException.class).hasMessageContaining(""partitionValue should not be null"");

        assertThatThrownBy(() ->  Key.builder().partitionValue(AttributeValue.builder().nul(true).build()).build())
            .isInstanceOf(IllegalArgumentException.class).hasMessageContaining(""partitionValue should not be null"");
    }
",non-flaky,5
134988,undertow-io_undertow,AnnotatedEndpointTest.testStringOnMessage,"    @Test
    public void testStringOnMessage() throws Exception {
        final byte[] payload = ""hello"".getBytes();
        final FutureResult latch = new FutureResult();

        WebSocketTestClient client = new WebSocketTestClient(WebSocketVersion.V13, new URI(""ws://"" + DefaultServer.getHostAddress(""default"") + "":"" + DefaultServer.getHostPort(""default"") + ""/ws/chat/Stuart""));
        client.connect();
        client.send(new TextWebSocketFrame(Unpooled.wrappedBuffer(payload)), new FrameChecker(TextWebSocketFrame.class, ""hello Stuart"".getBytes(), latch));
        latch.getIoFuture().get();
        client.destroy();
    }
",non-flaky,5
135797,Netflix_Hystrix,CumulativeCollapserEventCounterStreamTest.testCollapsedAndResponseFromCacheAgeOutOfCumulativeWindow,"    @Test
    public void testCollapsedAndResponseFromCacheAgeOutOfCumulativeWindow() {
        HystrixCollapserKey key = HystrixCollapserKey.Factory.asKey(""CumulativeCollapser-D"");
        stream = CumulativeCollapserEventCounterStream.getInstance(key, 10, 100);
        stream.startCachingStreamValuesIfUnstarted();

        final CountDownLatch latch = new CountDownLatch(1);
        stream.observe().take(30).subscribe(getSubscriber(latch));

        for (int i = 0; i < 3; i++) {
            CommandStreamTest.Collapser.from(key, i).observe();
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
            CommandStreamTest.Collapser.from(key, i).observe(); //same arg - should get a response from cache
        }

        try {
            assertTrue(latch.await(10000, TimeUnit.MILLISECONDS));
        } catch (InterruptedException ex) {
            fail(""Interrupted ex"");
        }
        assertEquals(HystrixEventType.Collapser.values().length, stream.getLatest().length);
        long[] expected = new long[HystrixEventType.Collapser.values().length];
        expected[HystrixEventType.Collapser.BATCH_EXECUTED.ordinal()] = 1;
        expected[HystrixEventType.Collapser.ADDED_TO_BATCH.ordinal()] = 3;
        expected[HystrixEventType.Collapser.RESPONSE_FROM_CACHE.ordinal()] = 6;
        System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString());
        assertArrayEquals(expected, stream.getLatest());
    }
",non-flaky,5
134,nutzam_nutz,JsonTest.test_empty_obj_toJson,"@Test
public void test_empty_obj_toJson() {
    String j = Json.toJson(new Person(), JsonFormat.compact().setQuoteName(true));
    assertEquals(""{\""age\"":0,\""num\"":0}"", j);
}",unordered collections,3
33905,apache_camel,BuryProducerIntegrationIT.configure,"    @Test
            public void configure() {
                from(""direct:start"").to(""beanstalk:"" + tubeName + ""?command=bury"").to(""mock:result"");
            }
",non-flaky,5
31002,camunda-cloud_zeebe,ArrayValueTest.shouldSerializeValuesAfterPartialRead,"  @Test
  public void shouldSerializeValuesAfterPartialRead() {
    // given
    addIntValues(array, 1, 2, 3);

    // when
    final Iterator<IntegerValue> iterator = array.iterator();
    iterator.next();
    iterator.next();

    // then
    encodeAndDecode(array);
    assertIntValues(array, 1, 2, 3);
  }
",non-flaky,5
60931,apache_druid,BaseAveragerTest.testAddElement,"  @Test
  public void testAddElement()
  {
    BaseAverager<Integer, Integer> avg = new TestAverager(Integer.class, 3, ""test"", ""field"", 1);
    Object[] buckets = avg.getBuckets();

    avg.addElement(Collections.singletonMap(""field"", 1), Collections.emptyMap());
    Assert.assertEquals(1, buckets[0]);
    Assert.assertNull(buckets[1]);
    Assert.assertNull(buckets[2]);

    avg.addElement(Collections.singletonMap(""field"", 2), Collections.emptyMap());
    Assert.assertEquals(1, buckets[0]);
    Assert.assertEquals(2, buckets[1]);
    Assert.assertNull(buckets[2]);

    avg.addElement(Collections.singletonMap(""field"", 3), Collections.emptyMap());
    Assert.assertEquals(1, buckets[0]);
    Assert.assertEquals(2, buckets[1]);
    Assert.assertEquals(3, buckets[2]);

    avg.addElement(Collections.singletonMap(""field"", 4), Collections.emptyMap());
    Assert.assertEquals(4, buckets[0]);
    Assert.assertEquals(2, buckets[1]);
    Assert.assertEquals(3, buckets[2]);
  }
",non-flaky,5
176926,OryxProject_oryx,AbstractRescorerProviderTest.testDefault,"  @Test
  public void testDefault() {
    RescorerProvider noop = new NullProvider1();
    assertNull(noop.getMostActiveUsersRescorer(null));
    assertNull(noop.getMostPopularItemsRescorer(null));
    assertNull(noop.getMostSimilarItemsRescorer(null));
    assertNull(noop.getRecommendRescorer(null, null));
    assertNull(noop.getRecommendToAnonymousRescorer(null, null));
  }
",non-flaky,5
150212,apache_hive,TestStructColumnVector.testSet,"  @Test
  public void testSet() throws Exception {
    LongColumnVector input1 = new LongColumnVector(10);
    LongColumnVector input2 = new LongColumnVector(10);
    StructColumnVector input = new StructColumnVector(10, input1, input2);
    input.init();
    LongColumnVector output1 = new LongColumnVector(10);
    LongColumnVector output2 = new LongColumnVector(10);
    StructColumnVector output = new StructColumnVector(10, output1, output2);
    output.init();
    input1.isRepeating = true;
    input2.noNulls = false;
    input2.isNull[5] = true;
    input.noNulls = false;
    input.isNull[6] = true;
    for(int i=0; i < 10; ++i) {
      input1.vector[i] = i + 1;
      input2.vector[i] = i + 2;
    }
    output.isNull[3] = false;
    output.setElement(3, 6, input);
    StringBuilder buf = new StringBuilder();
    output.stringifyValue(buf, 3);
    assertEquals(""null"", buf.toString());
    output.isNull[3] = false;
    output.setElement(3, 5, input);
    buf = new StringBuilder();
    output.stringifyValue(buf, 3);
    assertEquals(""[1, null]"", buf.toString());
    output.isNull[3] = false;
    output.setElement(3, 4, input);
    buf = new StringBuilder();
    output.stringifyValue(buf, 3);
    assertEquals(""[1, 6]"", buf.toString());
    input.reset();
    assertEquals(false, input1.isRepeating);
    assertEquals(true, input.noNulls);
  }
",non-flaky,5
26759,MundaneImmortal_pair-distribution-app,DevPairsCombinationsTest.testIsRotationTimeForNewDevUnconformPair,"	@Test
	public void testIsRotationTimeForNewDevUnconformPair() {
		List<Developer> standardDevs = getStandardDevs();
		standardDevs.stream().forEach(developer -> developer.setNew(true));
		List<DayPairs> pastPairs = getPairsListFromDevs(standardDevs);
		pastPairs.remove(2);
		pastPairs.remove(1);		
		DevPairCombinations devPairCombinations = new DevPairCombinations(pastPairs);
		
		
		assertThat(devPairCombinations.isRotationTime(Arrays.asList(""track1"", ""track2""), standardDevs, false), is(true));
	}
",non-flaky,5
33831,apache_camel,TwoTimerWithJMXIssue.testFromWithNoOutputs,"    @Test
    public void testFromWithNoOutputs() throws Exception {
        MockEndpoint mock = getMockEndpoint(""mock:result"");
        mock.expectedMinimumMessageCount(2);

        assertMockEndpointsSatisfied();

        assertTrue(counter >= 2, ""Counter should be 2 or higher"");
    }
",non-flaky,5
159631,liquibase_liquibase,SQLiteIntegrationTest.smartDataLoad,"    @Test
    public void smartDataLoad() throws Exception {
        if (this.getDatabase() == null) {
            return;
        }

        Liquibase liquibase = createLiquibase(""changelogs/common/smartDataLoad.changelog.xml"");
        clearDatabase();

        try {
            liquibase.update(this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }

        // check that the automatically rollback now works too
        try {
            liquibase.rollback(new Date(0), this.contexts);
        } catch (ValidationFailedException e) {
            e.printDescriptiveError(System.out);
            throw e;
        }
    }
",non-flaky,5
104626,apache_pinot,MergeRollupMinionClusterIntegrationTest.testSingleLevelConcat,"  @Test
  public void testSingleLevelConcat()
      throws Exception {
    // The original segments are time partitioned by month:
    // segmentName (totalDocs)
    // myTable1_16071_16101_3 (9746)
    // myTable1_16102_16129_4 (8690)
    // myTable1_16130_16159_5 (9621)
    // myTable1_16160_16189_6 (9454)
    // myTable1_16190_16220_7 (10329)
    // myTable1_16221_16250_8 (10468)
    // myTable1_16251_16281_9 (10499)
    // myTable1_16282_16312_10 (10196)
    // myTable1_16313_16342_11 (9136)
    // myTable1_16343_16373_0 (9292)
    // myTable1_16374_16404_1 (8736)
    // myTable1_16405_16435_2 (9378)

    // Expected merge tasks and result segments:
    // 1.
    //    {myTable1_16071_16101_3}
    //      -> {merged_100days_T1_0_myTable1_16071_16099_0, merged_100days_T1_0_myTable1_16100_16101_1}
    // 2.
    //    {merged_100days_T1_0_myTable1_16100_16101_1, myTable1_16102_16129_4, myTable1_16130_16159_5}
    //      -> {merged_100days_T2_0_myTable1_16100_???_0(15000), merged_100days_T2_0_myTable1_???_16159_1}
    //    {myTable1_16160_16189_6, myTable1_16190_16220_7}
    //      -> {merged_100days_T2_1_myTable1_16160_16199_0, merged_100days_T2_1_myTable1_16200_16220_1}
    // 3.
    //    {merged_100days_T2_1_myTable1_16200_16220_1, myTable1_16221_16250_8}
    //      -> {merged_100days_T3_0_myTable1_16200_???_0(15000), merged_100days_T3_0_myTable1_???_16250_1}
    //    {myTable1_16251_16281_9, myTable1_16282_16312_10}
    //      -> {merged_100days_T3_1_myTable1_16251_???_0(15000), merged_100days_T3_1_myTable1_???_16299_1,
    //      merged_100days_T3_1_myTable1_16300_16312_2}
    // 4.
    //    {merged_100days_T3_1_myTable1_16300_16312_2, myTable1_16313_16342_11, myTable1_16343_16373_0}
    //      -> {merged_100days_T4_0_myTable1_16300_???_0(15000), merged_100days_T4_0_myTable1_???_16373_1}
    //    {myTable1_16374_16404_1}
    //      -> {merged_100days_T4_1_16374_16399_0, merged_100days_T4_1_16400_16404_1}
    // 5.
    //    {merged_100days_T4_1_16400_16404_1, myTable1_16405_16435_2}
    //      -> {merged_100days_T5_0_myTable1_16400_16435_0}

    String sqlQuery = ""SELECT count(*) FROM myTable1""; // 115545 rows for the test table
    JsonNode expectedJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
    int[] expectedNumSubTasks = {1, 2, 2, 2, 1};
    int[] expectedNumSegmentsQueried = {13, 12, 13, 13, 12};
    long expectedWatermark = 16000 * 86_400_000L;
    String offlineTableName = TableNameBuilder.OFFLINE.tableNameWithType(SINGLE_LEVEL_CONCAT_TEST_TABLE);
    int numTasks = 0;
    for (String tasks = _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE);
        tasks != null; tasks =
        _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.MergeRollupTask.TASK_TYPE), numTasks++) {
      assertEquals(_helixTaskResourceManager.getTaskConfigs(tasks).size(), expectedNumSubTasks[numTasks]);
      assertTrue(_helixTaskResourceManager.getTaskQueues()
          .contains(PinotHelixTaskResourceManager.getHelixJobQueueName(MinionConstants.MergeRollupTask.TASK_TYPE)));
      // Will not schedule task if there's incomplete task
      assertNull(
          _taskManager.scheduleTasks(offlineTableName).get(MinionConstants.RealtimeToOfflineSegmentsTask.TASK_TYPE));
      waitForTaskToComplete();

      // Check watermark
      MergeRollupTaskMetadata minionTaskMetadata = MergeRollupTaskMetadata
          .fromZNRecord(_taskManager.getClusterInfoAccessor().getMinionMergeRollupTaskZNRecord(offlineTableName));
      assertNotNull(minionTaskMetadata);
      assertEquals((long) minionTaskMetadata.getWatermarkMap().get(""100days""), expectedWatermark);
      expectedWatermark += 100 * 86_400_000L;

      // Check metadata of merged segments
      for (SegmentZKMetadata metadata : _pinotHelixResourceManager.getSegmentsZKMetadata(offlineTableName)) {
        if (metadata.getSegmentName().startsWith(""merged"")) {
          // Check merged segment zk metadata
          assertNotNull(metadata.getCustomMap());
          assertEquals(""100days"",
              metadata.getCustomMap().get(MinionConstants.MergeRollupTask.SEGMENT_ZK_METADATA_MERGE_LEVEL_KEY));
          // Check merged segments are time partitioned
          assertEquals(metadata.getEndTimeMs() / (86_400_000L * 100), metadata.getStartTimeMs() / (86_400_000L * 100));
        }
      }

      // Check num total doc of merged segments are the same as the original segments
      JsonNode actualJson = postSqlQuery(sqlQuery, _brokerBaseApiUrl);
      SqlResultComparator.areEqual(actualJson, expectedJson, sqlQuery);
      // Check query routing
      int numSegmentsQueried = actualJson.get(""numSegmentsQueried"").asInt();
      assertEquals(numSegmentsQueried, expectedNumSegmentsQueried[numTasks]);
    }
    // Check total tasks
    assertEquals(numTasks, 5);

    assertTrue(_controllerStarter.getControllerMetrics()
        .containsGauge(""mergeRollupTaskDelayInNumBuckets.myTable1_OFFLINE.100days""));

    // Drop the table
    dropOfflineTable(SINGLE_LEVEL_CONCAT_TEST_TABLE);

    // Check if the task metadata is cleaned up on table deletion
    verifyTableDelete(offlineTableName);
  }
",non-flaky,5
340,apache_dubbo,737f7a7ea67832d7f17517326fb2491d0a086dd7.testListDetail,"@Test
public void testListDetail() throws RemotingException {
    String result = port.telnet(null, ""-l"");
    assertEquals(""dubbo://127.0.0.1:20887"", result);
}",test order dependency,4
162446,testcontainers_testcontainers-java,HttpWaitStrategyTest.testWaitUntilReadyWithManyStatusCodesAndLambda,"    @Test
    public void testWaitUntilReadyWithManyStatusCodesAndLambda() {
        waitUntilReadyAndSucceed(startContainerWithCommand(createShellCommand(""401 UNAUTHORIZED"", GOOD_RESPONSE_BODY),
            createHttpWaitStrategy(ready)
                .forStatusCode(300)
                .forStatusCode(500)
                .forStatusCodeMatching(it -> it == 401)
        ));
    }
",non-flaky,5
26716,MundaneImmortal_pair-distribution-app,PairTest.testIsOpsPairTrue,"	@Test
	public void testIsOpsPairTrue()  {
		Pair subject = new Pair();
		
		subject.setOpsPair(true);
		
		assertThat(subject.isOpsPair(), is(true));
	}
",non-flaky,5
77129,networknt_json-schema-validator,Issue396Test.testComplexPropertyNamesV7,"    @Test
    public void testComplexPropertyNamesV7() throws Exception {
        String schemaPath = ""/schema/issue396-v7.json"";
        String dataPath = ""/data/issue396.json"";
        InputStream schemaInputStream = getClass().getResourceAsStream(schemaPath);
        JsonSchema schema = getJsonSchemaFromStreamContentV7(schemaInputStream);
        InputStream dataInputStream = getClass().getResourceAsStream(dataPath);
        JsonNode node = getJsonNodeFromStreamContent(dataInputStream);

        final Set<String> invalidPaths = new HashSet<>();
        node.fields().forEachRemaining(entry -> {
            if (!entry.getValue().asBoolean())
                invalidPaths.add(""$."" + entry.getKey());
        });

        Set<ValidationMessage> errors = schema.validate(node);
        final Set<String> failedPaths = errors.stream().map(ValidationMessage::getPath).collect(Collectors.toSet());
        Assertions.assertEquals(failedPaths, invalidPaths);
    }
",non-flaky,5
77008,Tencent_Firestorm,ShuffleServerGrpcTest.rpcMetricsTest,"  @Test
  public void rpcMetricsTest() {
    String appId = ""rpcMetricsTest"";
    int shuffleId = 0;
    double oldGrpcTotal = shuffleServers.get(0).getGrpcMetrics().getCounterGrpcTotal().get();
    double oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().
        get(ShuffleServerGrpcMetrics.REGISTER_SHUFFLE_METHOD).get();
    shuffleServerClient.registerShuffle(new RssRegisterShuffleRequest(appId, shuffleId,
        Lists.newArrayList(new PartitionRange(0, 1))));
    double newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap()
        .get(ShuffleServerGrpcMetrics.REGISTER_SHUFFLE_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.REGISTER_SHUFFLE_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.APP_HEARTBEAT_METHOD).get();
    shuffleServerClient.sendHeartBeat(new RssAppHeartBeatRequest(appId, 10000));
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.APP_HEARTBEAT_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.APP_HEARTBEAT_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.REQUIRE_BUFFER_METHOD).get();
    shuffleServerClient.requirePreAllocation(100, 10, 1000);
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.REQUIRE_BUFFER_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.REQUIRE_BUFFER_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.SEND_SHUFFLE_DATA_METHOD).get();
    List<ShuffleBlockInfo> blockInfos = Lists.newArrayList(new ShuffleBlockInfo(shuffleId, 0, 0, 100, 0,
        new byte[]{}, Lists.newArrayList(), 0, 100, 0));
    Map<Integer, List<ShuffleBlockInfo>> partitionToBlocks = Maps.newHashMap();
    partitionToBlocks.put(0, blockInfos);
    Map<Integer, Map<Integer, List<ShuffleBlockInfo>>> shuffleToBlocks = Maps.newHashMap();
    shuffleToBlocks.put(0, partitionToBlocks);
    RssSendShuffleDataRequest rssdr = new RssSendShuffleDataRequest(
        appId, 3, 1000, shuffleToBlocks);
    shuffleServerClient.sendShuffleData(rssdr);
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.SEND_SHUFFLE_DATA_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.SEND_SHUFFLE_DATA_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.COMMIT_SHUFFLE_TASK_METHOD).get();
    shuffleServerClient.sendCommit(new RssSendCommitRequest(appId, shuffleId));
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.COMMIT_SHUFFLE_TASK_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.COMMIT_SHUFFLE_TASK_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.FINISH_SHUFFLE_METHOD).get();
    shuffleServerClient.finishShuffle(new RssFinishShuffleRequest(appId, shuffleId));
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.FINISH_SHUFFLE_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.FINISH_SHUFFLE_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.REPORT_SHUFFLE_RESULT_METHOD).get();
    Map<Integer, List<Long>> partitionToBlockIds = Maps.newHashMap();
    List<Long> blockIds1 = getBlockIdList(1, 3);
    List<Long> blockIds2 = getBlockIdList(2, 2);
    List<Long> blockIds3 = getBlockIdList(3, 1);
    partitionToBlockIds.put(1, blockIds1);
    partitionToBlockIds.put(2, blockIds2);
    partitionToBlockIds.put(3, blockIds3);
    RssReportShuffleResultRequest request =
        new RssReportShuffleResultRequest(appId, shuffleId, 0L, partitionToBlockIds, 1);
    shuffleServerClient.reportShuffleResult(request);
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.REPORT_SHUFFLE_RESULT_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.REPORT_SHUFFLE_RESULT_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_RESULT_METHOD).get();
    shuffleServerClient.getShuffleResult(new RssGetShuffleResultRequest(appId, shuffleId, 1));
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_RESULT_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.GET_SHUFFLE_RESULT_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_INDEX_METHOD).get();
    try {
      shuffleServerClient.getShuffleIndex(new RssGetShuffleIndexRequest(
          appId, shuffleId, 1, 1, 3));
    } catch (Exception e) {
      // ignore the exception, just test metrics value
    }
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_INDEX_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.GET_SHUFFLE_INDEX_METHOD).get(), 0.5);

    oldValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_DATA_METHOD).get();
    try {
      shuffleServerClient.getShuffleData(new RssGetShuffleDataRequest(
          appId, shuffleId, 0, 1, 3,
          0, 100));
    } catch (Exception e) {
      // ignore the exception, just test metrics value
    }
    newValue = shuffleServers.get(0).getGrpcMetrics().getCounterMap().get(
        ShuffleServerGrpcMetrics.GET_SHUFFLE_DATA_METHOD).get();
    assertEquals(oldValue + 1, newValue, 0.5);
    assertEquals(0,
        shuffleServers.get(0).getGrpcMetrics().getGaugeMap().get(
            ShuffleServerGrpcMetrics.GET_SHUFFLE_DATA_METHOD).get(), 0.5);

    double newGrpcTotal = shuffleServers.get(0).getGrpcMetrics().getCounterGrpcTotal().get();
    // require buffer will be called one more time when send data
    assertEquals(oldGrpcTotal + 11, newGrpcTotal, 0.5);
    assertEquals(0, shuffleServers.get(0).getGrpcMetrics().getGaugeGrpcOpen().get(), 0.5);
  }
",non-flaky,5
26727,MundaneImmortal_pair-distribution-app,OpsPairsCombinationsTest.testGetPastPairByTrackForMissingHistory,"	@Test
	public void testGetPastPairByTrackForMissingHistory() {
		OpsPairCombinations devPairCombinations = new OpsPairCombinations(getPairsListFromDevs(getStandardDevs()));
		
		
		assertThat(devPairCombinations.getPastPairByTrack(3, ""track1""), is(nullValue()));
	}
",non-flaky,5
96025,stanfordnlp_CoreNLP,TokenSequenceMatcherITest.testTokenSequenceMatcherAll2,"  @Test
  public void testTokenSequenceMatcherAll2() throws IOException {
    String text = ""DATE1 PROD1 PRICE1 PROD2 PRICE2 PROD3 PRICE3 DATE2 PROD4 PRICE4 PROD5 PRICE5 PROD6 PRICE6"";
    CoreMap doc = createDocument(text);
    TokenSequencePattern p = TokenSequencePattern.compile(
        ""(/DATE.*/) (?: /PROD.*/ /PRICE.*/)* (/PROD.*/) (/PRICE.*/)"");

    TokenSequenceMatcher m = p.getMatcher(doc.get(CoreAnnotations.TokensAnnotation.class));
    m.setFindType(SequenceMatcher.FindType.FIND_ALL);
    // Test finding of ALL matching sequences
    boolean match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE1"", m.group(1));
    assertEquals(""PROD3"", m.group(2));
    assertEquals(""PRICE3"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE1"", m.group(1));
    assertEquals(""PROD2"", m.group(2));
    assertEquals(""PRICE2"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE1"", m.group(1));
    assertEquals(""PROD1"", m.group(2));
    assertEquals(""PRICE1"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE2"", m.group(1));
    assertEquals(""PROD6"", m.group(2));
    assertEquals(""PRICE6"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE2"", m.group(1));
    assertEquals(""PROD5"", m.group(2));
    assertEquals(""PRICE5"", m.group(3));
    match = m.find();
    assertTrue(match);
    assertEquals(3, m.groupCount());
    assertEquals(""DATE2"", m.group(1));
    assertEquals(""PROD4"", m.group(2));
    assertEquals(""PRICE4"", m.group(3));
    match = m.find();
    assertFalse(match);
  }
",non-flaky,5
160337,triplea-game_triplea,ChannelMessengerTest.testNoParams,"  @Test
    public void testNoParams() {
      incrementCount();
    }
",non-flaky,5
96897,apache_avro,TestSchemas.visitTerminal,"  @Test(expected = UnsupportedOperationException.class)
  public void testVisit10() {
    String s10 = ""{\""type\"": \""record\"", \""name\"": \""c1\"", \""fields\"": ["" +
        ""{\""name\"": \""f1\"", \""type\"": {\""type\"": \""record\"", \""name\"": \""ct2\"", \""fields\"": "" +
        ""[{\""name\"": \""f11\"", \""type\"": \""int\""}]}},"" +
        ""{\""name\"": \""f2\"", \""type\"": \""int\""}"" +
        ""]}"";
    Schemas.visit(new Schema.Parser().parse(s10),
        new TestVisitor() {
          public SchemaVisitorAction visitTerminal(Schema terminal) {
            return SchemaVisitorAction.SKIP_SUBTREE;
          }
",non-flaky,5
30994,camunda-cloud_zeebe,ObjectMappingTest.shouldFailSerializationWithMissingRequiredValues,"  @Test
  public void shouldFailSerializationWithMissingRequiredValues() {
    // given
    final POJO pojo = new POJO();

    final UnsafeBuffer buf = new UnsafeBuffer(new byte[1024]);

    // then
    exception.expect(MsgpackPropertyException.class);
    exception.expectMessage(
        ""Property 'enumProp' is invalid: Expected a value or default value to be set before writing, but has nothing"");

    // when
    pojo.write(buf, 0);
  }
",non-flaky,5
176785,ctco_cukes,BaseContextHandlerTest.shouldExtractGroupsInPatternWithUnderscoreInName,"    @Test
    public void shouldExtractGroupsInPatternWithUnderscoreInName() throws Exception {
        List<String> groups = capturer.extractGroups(""{(hello_world)}"");
        assertThat(groups, contains(""hello_world""));
    }
",non-flaky,5
176898,OryxProject_oryx,TextUtilsTest.testParseJSON,"  @Test
  public void testParseJSON() throws Exception {
    assertArrayEquals(new String[] {""a"", ""1"", ""foo""},
                      TextUtils.parseJSONArray(""[\""a\"",\""1\"",\""foo\""]""));
    assertArrayEquals(new String[] {""a"", ""1"", ""foo"", """"},
                      TextUtils.parseJSONArray(""[\""a\"",\""1\"",\""foo\"",\""\""]""));
    assertArrayEquals(new String[] {""2.3""}, TextUtils.parseJSONArray(""[\""2.3\""]""));
    assertArrayEquals(new String[] {}, TextUtils.parseJSONArray(""[]""));
  }
",non-flaky,5
177163,line_armeria,SamlRequestIdManagerTest.shouldBeExpired,"    @Test
    public void shouldBeExpired() throws InterruptedException, UnsupportedEncodingException {
        final SamlRequestIdManager manager =
                SamlRequestIdManager.ofJwt(""me"", ""test"", 1, 0);

        final Instant started = Instant.now();
        final String id = manager.newId();
        assertThat(manager.validateId(id)).isTrue();

        await().pollDelay(Durations.TWO_HUNDRED_MILLISECONDS)
               .atMost(Durations.FIVE_SECONDS)
               .untilAsserted(() -> assertThat(manager.validateId(id)).isFalse());

        assertThat(java.time.Duration.between(started, Instant.now()).toMillis())
                .isGreaterThan(TimeUnit.SECONDS.toMillis(1));
    }
",non-flaky,5
59639,looly_hutool,TokenizerUtilTest.smartcnTest,"	@Test
	public void smartcnTest() {
		TokenizerEngine engine = new SmartcnEngine();
		Result result = engine.parse(text);
		String resultStr = IterUtil.join((Iterator<Word>)result, "" "");
		Assert.assertEquals(""è¿ ä¸¤ ä¸ª æ¹æ³ ç åºå« å¨äº è¿å å¼"", resultStr);
	}
",non-flaky,5
159655,liquibase_liquibase,AbstractIntegrationTest.testAbsolutePathChangeLog,"    @Test
    public void testAbsolutePathChangeLog() throws Exception {
        assumeNotNull(this.getDatabase());

        String fileUrlToChangeLog = getClass().getResource(""/"" + includedChangeLog).toString();
        assertTrue(fileUrlToChangeLog.startsWith(""file:/""));

        String absolutePathOfChangeLog = fileUrlToChangeLog.replaceFirst(""file:\\/"", """");
        if (System.getProperty(""os.name"").startsWith(""Windows "")) {
            absolutePathOfChangeLog = absolutePathOfChangeLog.replace('/', '\\');
        } else {
            absolutePathOfChangeLog = ""/"" + absolutePathOfChangeLog;
        }
        Liquibase liquibase = createLiquibase(absolutePathOfChangeLog, new FileSystemResourceAccessor());
        clearDatabase();

        liquibase.update(this.contexts);

        liquibase.update(this.contexts); //try again, make sure there are no errors

        clearDatabase();
    }
",non-flaky,5
38648,apache_pulsar,KinesisSinkTest.testDefaultCredentialProvider,"    @Test
    public void testDefaultCredentialProvider() throws Exception {
        KinesisSink sink = new KinesisSink();
        Map<String, String> credentialParam = Maps.newHashMap();
        String awsCredentialPluginParam = new Gson().toJson(credentialParam);
        try {
            sink.defaultCredentialProvider(awsCredentialPluginParam);
            Assert.fail(""accessKey and SecretKey validation not applied"");
        } catch (IllegalArgumentException ie) {
            // Ok..
        }

        final String accesKey = ""ak"";
        final String secretKey = ""sk"";
        credentialParam.put(KinesisSink.ACCESS_KEY_NAME, accesKey);
        credentialParam.put(KinesisSink.SECRET_KEY_NAME, secretKey);
        awsCredentialPluginParam = new Gson().toJson(credentialParam);
        AWSCredentialsProvider credentialProvider = sink.defaultCredentialProvider(awsCredentialPluginParam)
                .getCredentialProvider();
        Assert.assertNotNull(credentialProvider);
        Assert.assertEquals(credentialProvider.getCredentials().getAWSAccessKeyId(), accesKey);
        Assert.assertEquals(credentialProvider.getCredentials().getAWSSecretKey(), secretKey);

        sink.close();
    }
",non-flaky,5
77167,networknt_json-schema-validator,V4JsonSchemaTest.testRefIdReference,"    @Test
    public void testRefIdReference() throws Exception {
        runTestFile(""draft4/idRef.json"");
    }
",non-flaky,5
38624,apache_pulsar,SqliteJdbcSinkTest.TestDeleteAction,"    @Test
    public void TestDeleteAction() throws Exception {

        AvroSchema<Foo> schema = AvroSchema.of(SchemaDefinition.<Foo>builder().withPojo(Foo.class).build());

        Foo deleteObj = new Foo();
        deleteObj.setField3(5);

        byte[] deleteBytes = schema.encode(deleteObj);
        Message<GenericRecord> deleteMessage = mock(MessageImpl.class);
        CompletableFuture<Void> future = new CompletableFuture<>();
        Record<GenericRecord> deleteRecord = PulsarRecord.<GenericRecord>builder()
                .message(deleteMessage)
                .topicName(""fake_topic_name"")
                .ackFunction(() -> future.complete(null))
                .build();

        GenericSchema<GenericRecord> deleteGenericAvroSchema = new GenericAvroSchema(schema.getSchemaInfo());

        Map<String, String> deleteProperties = Maps.newHashMap();
        deleteProperties.put(""ACTION"", ""DELETE"");
        when(deleteMessage.getValue()).thenReturn(deleteGenericAvroSchema.decode(deleteBytes));
        when(deleteMessage.getProperties()).thenReturn(deleteProperties);
        log.info(""foo:{}, Message.getValue: {}, record.getValue: {}"",
                deleteObj.toString(),
                deleteMessage.getValue().toString(),
                deleteRecord.getValue().toString());

        jdbcSink.write(deleteRecord);
        future.get(1, TimeUnit.SECONDS);

        // value has been written to db, read it out and verify.
        String deleteQuerySql = ""SELECT * FROM "" + tableName + "" WHERE field3=5"";
        Assert.assertEquals(sqliteUtils.select(deleteQuerySql, (resultSet) -> {}), 0);
    }
",non-flaky,5
114086,aws_aws-sdk-java-v2,KeyTest.getSortKeyValue,"    @Test
    public void getSortKeyValue() {
        assertThat(key.sortKeyValue(), is(Optional.of(AttributeValue.builder().s(""id456"").build())));
    }
",non-flaky,5
190,apache_dubbo,737f7a7ea67832d7f17517326fb2491d0a086dd7.testChangeServiceNotExport,"@Test
public void testChangeServiceNotExport() throws RemotingException {
    String result = change.telnet(mockChannel, ""demo"");
    assertEquals(""No such service demo"", result);
}",test order dependency,4
38200,palantir_atlasdb,RocksDbKeyValueServiceTest.testReadNoExist,"    @Test
    public void testReadNoExist() {
        final Cell cell = Cell.create(""r1"".getBytes(), COMMIT_TS_COLUMN);
        final Map<Cell, Value> res = db.get(TABLE, ImmutableMap.of(cell, 1L));
        assertTrue(res.isEmpty());
    }
",non-flaky,5
113987,apache_struts,BeanConfigTest.testConstructor2,"    @Test
    public void testConstructor2() throws Exception {
        Class<TestBean> expectedClass = TestBean.class;
        String expectedName = ""expectedBeanName"";
        Class<Object> expectedType = Object.class;
        Scope expectedScope = Scope.PROTOTYPE;
        boolean expectedOnlyStatic = true;
        boolean expectedOptional = true;

        BeanConfig beanConfig = new BeanConfig(expectedClass, expectedName, expectedType, expectedScope,
                expectedOnlyStatic, expectedOptional);

        Assert.assertEquals(expectedClass, beanConfig.getClazz());
        Assert.assertEquals(expectedName, beanConfig.getName());
        Assert.assertEquals(expectedScope, beanConfig.getScope());
        Assert.assertEquals(expectedType, beanConfig.getType());
        Assert.assertEquals(expectedOnlyStatic, beanConfig.isOnlyStatic());
        Assert.assertEquals(expectedOptional, beanConfig.isOptional());
    }
",non-flaky,5
77510,dropwizard_dropwizard,DropwizardAppRuleWithExplicitTest.runWithExplicitConfig,"    @Test
    public void runWithExplicitConfig() {
        Map<String, String> response = RULE.client().target(""http://localhost:"" + RULE.getLocalPort() + ""/test"")
            .request()
            .get(new GenericType<Map<String, String>>() {
            });
        assertThat(response).containsOnly(entry(""message"", ""stuff!""));
    }
",non-flaky,5
42976,fabiomaffioletti_jsondoc,ApiMethodDocTest.testNotEqualMultipleVerbs,"	@Test
	public void testNotEqualMultipleVerbs() {
		first = new ApiMethodDoc();
		first.setPath(Sets.newHashSet(""/first""));
		first.setVerb(Sets.newHashSet(ApiVerb.GET, ApiVerb.POST));
		second = new ApiMethodDoc();
		second.setPath(Sets.newHashSet(""/second""));
		second.setVerb(Sets.newHashSet(ApiVerb.GET, ApiVerb.POST));
		Assert.assertNotEquals(0, first.compareTo(second));
		
		second.setPath(Sets.newHashSet(""/first""));
		second.setVerb(Sets.newHashSet(ApiVerb.PUT, ApiVerb.POST));
		Assert.assertNotEquals(0, first.compareTo(second));
	}
",non-flaky,5
33918,apache_camel,LdifRouteIT.addOne,"    @Test
    public void addOne() throws Exception {
        camel.addRoutes(createRouteBuilder(ENDPOINT_LDIF));
        camel.start();

        Endpoint endpoint = camel.getEndpoint(ENDPOINT_START);
        Exchange exchange = endpoint.createExchange();

        // then we set the LDAP filter on the in body
        URL loc = this.getClass().getResource(""/org/apache/camel/component/ldif/AddOne.ldif"");
        exchange.getIn().setBody(loc.toString());

        // now we send the exchange to the endpoint, and receives the response
        // from Camel
        Exchange out = template.send(endpoint, exchange);

        // Check the results
        List<String> ldifResults = defaultLdapModuleOutAssertions(out);
        assertThat(ldifResults, notNullValue());
        assertThat(ldifResults.size(), equalTo(2)); // Container and user
        assertThat(ldifResults.get(0), equalTo(""success""));
        assertThat(ldifResults.get(1), equalTo(""success""));

        // Check LDAP
        SearchResult sr;
        NamingEnumeration<SearchResult> searchResults = ldapContext.search(""dc=example,dc=org"", ""(uid=test*)"", SEARCH_CONTROLS);
        assertNotNull(searchResults);

        checkDN(""uid=test1"", searchResults);
    }
",non-flaky,5
104139,spring-cloud_spring-cloud-config,ConfigClientPropertiesTests.testIfColonPresentAtTheStartAndEndInUriCreds,"	@Test
	public void testIfColonPresentAtTheStartAndEndInUriCreds() {
		this.locator.setUri(new String[] { ""http://:foobar:@localhost:9999"" });
		Credentials credentials = this.locator.getCredentials(0);
		assertThat(credentials.getUri()).isEqualTo(""http://localhost:9999"");
		assertThat(credentials.getUsername()).isEqualTo("""");
		assertThat(credentials.getPassword()).isEqualTo(""foobar:"");
	}
",non-flaky,5
98105,vert-x3_vertx-mongo-client,ParsingStreamTypeTest.only_valid_stream_type_values_allowed_as_config_property,"  @Test(expected = IllegalArgumentException.class)
  public void only_valid_stream_type_values_allowed_as_config_property() {
    // given
    final JsonObject withInvalidStreamType = new JsonObject().put(""streamType"", ""unrecognized"");

    // expect thrown
    new MongoClientOptionsParser(vertx, withInvalidStreamType).settings();
  }
",non-flaky,5
170474,eclipse_jetty.project,ObjectMBeanUtilTest.testSetAttributeAttributeWithWrongAttrName,"    @Test
    public void testSetAttributeAttributeWithWrongAttrName()
    {
        attribute = new Attribute(""fnameee"", ""charu"");

        AttributeNotFoundException e = assertThrows(AttributeNotFoundException.class, () -> objectMBean.setAttribute(attribute));

        assertNotNull(e, ""An AttributeNotFoundException must have occurred by now as there is no attribute "" + ""with the name ffname in bean"");
    }
",non-flaky,5
114041,aws_aws-sdk-java-v2,UpdateItemWithResponseIntegrationTest.putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull,"    @Test
    public void putItem_returnItemCollectionMetrics_set_itemCollectionMetricsNotNull() {
        Record record = new Record().setId(1).setId2(10);
        UpdateItemEnhancedRequest<Record> request = UpdateItemEnhancedRequest.builder(Record.class)
                                                                             .item(record)
                                                                             .returnItemCollectionMetrics(ReturnItemCollectionMetrics.SIZE)
                                                                             .build();

        UpdateItemEnhancedResponse<Record> response = mappedTable.updateItemWithResponse(request);

        assertThat(response.itemCollectionMetrics()).isNotNull();
    }
",non-flaky,5
